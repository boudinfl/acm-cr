@article{10.1137/140998949,
author = {Navarro, Gonzalo and Nekrich, Yakov},
title = {Time-Optimal Top-$k$ Document Retrieval},
year = {2017},
issue_date = {2017},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {46},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/140998949},
doi = {10.1137/140998949},
abstract = {Let $mathcal D$ be a collection of $D$ documents, which are
strings over an alphabet of size $sigma$, of total length $n$.
We describe a data structure that uses linear space
and reports $k$ most relevant documents that contain a query
pattern $P$, which is a string of length $p$ packed in $p/log_sigma n$
words, in time $O(p/log_sigma n+k)$.
This is optimal in the RAM model in the general case where $log D =
Theta(log n)$, and involves a novel RAM-optimal suffix tree search.
Our construction supports an ample set of important relevance
measures, such as the number of times $P$ appears in a document (called term
frequency), a fixed document importance, and the minimal distance
between two occurrences of $P$ in a document.
When $log D = o(log n)$, we show how to reduce the space
of the data structure from $O(nlog n)$ to $O(n(logsigma+log D+loglog n))$
bits, and to $O(n(logsigma+log D))$ bits in the case of the popular
term frequency measure of relevance, at the price of an additive term
$O(log^varepsilon_sigma n)$ in the query time, for any constant $varepsilon&gt;0$.
We also consider the dynamic scenario, where documents
can be inserted and deleted from the collection. We obtain linear space and
query time $O(p(loglog n)^2/log_sigma n+log n + kloglog k)$,
whereas insertions and deletions require $O(log^{1+varepsilon} n)$ time per symbol,
for any constant $varepsilon&gt;0$.
Finally, we consider an extended static scenario where an extra parameter
$mathtt{par}(P,d)$ is defined, and the query must retrieve only documents $d$
such that $mathtt{par}(P,d)in [tau_1,tau_2]$, where this range is specified at
query time. We solve these queries using linear space and
$O(p/log_sigma n + log^{1+varepsilon} n + klog^varepsilon n)$ time, for any constant
$varepsilon&gt;0$.
Our technique is to translate these top-$k$ problems into multidimensional
geometric search problems. As a bonus, we describe some
improvements to those problems.},
journal = {SIAM J. Comput.},
month = feb,
pages = {80–113},
numpages = {34},
keywords = {text retrieval, suffix trees, 68W32, geometric data structures, string collections}
}

@article{10.1137/130938438,
author = {Haitner, Iftach and Hoch, Jonathan J. and Reingold, Omer and Segev, Gil},
title = {Finding Collisions in Interactive Protocols---Tight Lower Bounds on the Round and Communication Complexities of Statistically Hiding Commitments},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/130938438},
doi = {10.1137/130938438},
abstract = {We study the round and communication complexities of various cryptographic protocols. We give tight lower
bounds on the round and communication complexities of any fully black-box reduction of a statistically hiding
commitment scheme from one-way permutations and from trapdoor permutations. As a corollary, we derive similar
tight lower bounds for several
other cryptographic protocols, such as single-server private information retrieval, interactive hashing, and
oblivious transfer that guarantees
statistical security for one of the parties.
Our techniques extend the collision-finding oracle due to Simon [Advances in Cryptology---EUROCRYPT'98,
Lecture Notes in Comput. Sci. 1403, Springer, Berlin,
1998, pp. 334--345] to the setting of
interactive protocols and the reconstruction paradigm of Gennaro and Trevisan [Proceedings of the 41st Annual
Symposium on Foundations of
Computer Science (FOCS), IEEE Press, Piscataway, NJ, 2000, pp. 305--313].},
journal = {SIAM J. Comput.},
month = feb,
pages = {193–242},
numpages = {50},
keywords = {black-box impossibility results, private information retrieval, one-way functions, 94A60, statistically hiding commitments, 68P25}
}

@article{10.1137/130914140,
author = {Baswana, Surender and Gupta, Manoj and Sen, Sandeep},
title = {Fully Dynamic Maximal Matching in $O(\log n)$ Update Time},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/130914140},
doi = {10.1137/130914140},
abstract = {We present an algorithm for maintaining maximal matching in a graph under addition and deletion of edges. Our algorithm is randomized and it takes expected amortized $O(log n)$ time for each edge update, where $n$ is the number of vertices in the graph. While there exists a trivial $O(n)$ time algorithm for each edge update, the previous best known result for this problem is due to Ivkovicundefined and Lloyd [Lecture Notes in Comput. Sci. 790, Springer-Verlag, London, 1994, pp. 99--111]. For a graph with $n$ vertices and $m$ edges, they gave an $O( {(n+ m)}^{0.7072})$ update time algorithm which is sublinear only for a sparse graph. For the related problem of maximum matching, Onak and Rubinfeld [Proceedings of STOC'10, Cambridge, MA, 2010, pp. 457--464] designed a randomized algorithm that achieves expected amortized $O(log^2 n)$ time for each update for maintaining a $c$-approximate maximum matching for some unspecified large constant $c$. In contrast, we can maintain a factor 2 approximate maximum matching in expected amortized $O(log n )$ time per update as a direct corollary of the maximal matching scheme. This in turn also implies a 2-approximate vertex cover maintenance scheme that takes expected amortized $O(log n )$ time per update.},
journal = {SIAM J. Comput.},
month = feb,
pages = {88–113},
numpages = {26},
keywords = {68W20, 68W05, matching, 68W40, 05C70, dynamic graph algorithm, 05C85}
}

@article{10.1137/120892234,
author = {Grohe, Martin and Marx, Daundefinedniel},
title = {Structure Theorem and Isomorphism Test for Graphs with Excluded Topological Subgraphs},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/120892234},
doi = {10.1137/120892234},
abstract = {We generalize the structure theorem of Robertson and Seymour for
graphs excluding a fixed graph $H$ as a minor to graphs excluding
$H$ as a topological subgraph. We prove that for a fixed $H$, every
graph excluding $H$ as a topological subgraph has a tree
decomposition where each part is either “almost embeddable” to a
fixed surface or has bounded degree with the exception of a bounded
number of vertices. Furthermore, we prove that such a decomposition
is computable by an algorithm that is fixed-parameter tractable with
parameter $|H|$. We present two algorithmic applications of our structure theorem. To
illustrate the mechanics of a “typical” application of the
structure theorem, we show that on graphs excluding $H$ as a
topological subgraph, Partial Dominating Set (find $k$
vertices whose closed neighborhood has maximum size) can be solved
in time $f(H,k)cdot n^{O(1)}$. More significantly, we show
that on graphs excluding $H$ as a topological subgraph,
Graph Isomorphism can be solved in time $n^{f(H)}$.  This
result unifies and generalizes two previously known important
polynomial time solvable cases of Graph Isomorphism:
bounded-degree graphs [E. M. Luks,
J. Comput. System Sci., 25 (1982),
pp. 42--65] and $H$-minor free graphs
[I. N. Ponomarenko,  Zap. Nauchn. Sem. Leningrad.  Otdel. Mat. Inst. Steklov. (LOMI),
174 (1988), pp. 147--177, 182]. The proof of this result needs a generalization of our
structure theorem to the context of invariant treelike
decomposition.},
journal = {SIAM J. Comput.},
month = feb,
pages = {114–159},
numpages = {46},
keywords = {graph isomorphism, 95C75, 05C60, topological minors, 68R10, 05C83, 05C85, fixed-parameter tractability}
}

@article{10.1137/120884390,
author = {Abraham, Ittai and Bartal, Yair and Neiman, Ofer},
title = {Embedding Metrics into Ultrametrics and Graphs into Spanning Trees with Constant Average Distortion},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/120884390},
doi = {10.1137/120884390},
abstract = {This paper addresses the basic question of how well a tree can approximate distances of a metric space or a graph. Given a graph, the problem of constructing a spanning tree in a graph which strongly preserves distances in the graph is a fundamental problem in network design. We present scaling distortion embeddings where the distortion scales as a function of $\epsilon$, with the guarantee that for each $\epsilon$ simultaneously, the distortion of a fraction $1-\epsilon$ of all pairs is bounded accordingly. Quantitatively, we prove that any finite metric space embeds into an ultrametric with scaling distortion $O(\sqrt{1/\epsilon})$. For the graph setting, we prove that any weighted graph contains a spanning tree with scaling distortion $O(\sqrt{1/\epsilon})$. These bounds are tight even for embedding into arbitrary trees. These results imply that the average distortion of the embedding is constant and that the $\ell_2$ distortion is $O(\sqrt{\log n})$. For probabilistic embedding into spanning trees we prove a scaling distortion of $\tilde{O}(\log^2 (1/\epsilon))$, which implies constant $\ell_q$-distortion for every fixed $q<\infty$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {160–192},
numpages = {32},
keywords = {embedding, constant average distortion, 30L05, spanning tree}
}

@article{10.1137/140964801,
author = {Fomin, Fedor V. and Todinca, Ioan and Villanger, Yngve},
title = {Large Induced Subgraphs via Triangulations and CMSO},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/140964801},
doi = {10.1137/140964801},
abstract = {We obtain an   algorithmic metatheorem for the following    optimization problem. Let
$varphi$ be   a counting monadic second order logic  (CMSO) formula and $tgeq 0$ be an integer. For a given graph
$G=(V,E)$, the task is to maximize
$|X|$ subject to the following: there is a set $  Fsubseteq V$ such that $Xsubseteq F $,
the subgraph $G[F]$ induced by $F$ is of treewidth at most $t$,   and the structure $(G[F],X)$ models $varphi$,
i.e.,  $(G[F],X)modelsvarphi$.
We give an algorithm solving this optimization  problem on any $n$-vertex graph $G$ in time
${cal O}(|Pi_G| cdot n^{t+4}cdot f(t,varphi))$, where  $Pi_G$ is the set of all potential maximal cliques
in $G$ and  $f$ is a function of $t$ and $varphi$  only.  Pipelined with the known bounds on the number of
potential maximal cliques in different graph classes, there are a plethora of algorithmic consequences
extending and subsuming many known results on polynomial-time algorithms for graph classes.
We also show that all  potential maximal cliques of $G$ can be enumerated in time ${cal O}(1.7347^n)$.
This implies the existence of an exact exponential algorithm of running time ${cal O}(1.7347^n)$ for many
NP-hard problems related to finding maximum induced subgraphs with different properties.},
journal = {SIAM J. Comput.},
month = feb,
pages = {54–87},
numpages = {34},
keywords = {05C85, 68R10, potential maximal cliques, minimal triangulations, CMSO, treewidth, graph algorithms}
}

@article{10.1137/130930984,
author = {Chan, T.-H. Hubert and Li, Mingfei and Ning, Li and Solomon, Shay},
title = {New Doubling Spanners},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/130930984},
doi = {10.1137/130930984},
abstract = {In a seminal STOC 1995 paper,  Arya et al. conjectured that spanners for
low-dimensional Euclidean spaces
with constant maximum degree, hop-diameter $O(log n)$, and lightness $O(log n)$ (i.e.,
weight $O(log n) cdot w({MST}))$ can be constructed in $O(n log n)$ time.
This conjecture, which became a central open question in this area,
was resolved in the affirmative by Elkin and Solomon in STOC 2013.
In fact, Elkin and Solomon proved that the conjecture of Arya et al. holds even in doubling metrics.
However, Elkin and Solomon's spanner construction is complicated.
In this work we present a significantly simpler construction of spanners for doubling metrics
with the same guarantees as above.
Our construction is based on the basic net-tree spanner framework.
However, by employing well-known properties of the net-tree spanner in conjunction with numerous new ideas,
we managed to get significantly stronger results.
First and foremost, our construction extends in a simple and natural way to provide $k$-fault tolerant spanners
with maximum degree $O(k^2)$,
hop-diameter $O(log n)$,  and lightness $O(k^2 log n)$. This is the first construction of fault-tolerant
spanners (even for Euclidean metrics) that achieves good bounds (polylogarithmic in $n$ and polynomial in $k$)
on all
the involved parameters simultaneously.
Second, we show that the lightness bound of our construction can be improved to $O(k^2)$ (with high probability),
for random points in
$[0,1]^D$, where $2 le D = O(1)$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {37–53},
numpages = {17},
keywords = {optimal hop-diameter, Arya et al. STOC 1995 Conjecture, 05C12, lightness, fault-tolerant doubling spanners, small degree}
}

@article{10.1137/130945648,
author = {Kolmogorov, Vladimir and Thapper, Johan and Zundefinedivnyundefined, Stanislav},
title = {The Power of Linear Programming for General-Valued CSPs},
year = {2015},
issue_date = {2015},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {44},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/130945648},
doi = {10.1137/130945648},
abstract = {Let $D$, called the domain, be a fixed finite set and let $Gamma$,
called the valued constraint language, be a fixed set of functions of the
form $f:D^mtomathbb{Q}cup{infty}$, where different functions might have
different arity $m$. We study the valued constraint satisfaction problem
parametrized by $Gamma$, denoted by VCSP$(Gamma)$. These are minimization
problems given by $n$ variables and the objective function given by a sum of
functions from $Gamma$, each depending on a subset of the $n$ variables.
For example, if $D={0,1}$ and $Gamma$ contains all ternary ${0,infty}$-valued
functions, VCSP($Gamma$) corresponds to 3-SAT.
More generally, if $Gamma$ contains only ${0,infty}$-valued functions,
VCSP($Gamma$) corresponds to
CSP($Gamma$).
If $D={0,1}$ and $Gamma$ contains all ternary ${0,1}$-valued
functions, VCSP($Gamma$) corresponds to Min-3-SAT, in which the goal is to
minimize the number of unsatisfied clauses in a 3-CNF instance.
Finite-valued constraint languages contain functions that take on
only rational values and not infinite values.
Our main result is a precise algebraic characterization of valued constraint
languages whose instances can be solved exactly by the basic linear
programming relaxation (BLP). For a valued constraint language
$Gamma$, BLP is a decision procedure for $Gamma$ if and only if $Gamma$
admits a symmetric fractional polymorphism of every arity.
For a finite-valued constraint language $Gamma$, BLP is a decision procedure if
and only if $Gamma$ admits a symmetric fractional polymorphism of some
arity, or equivalently, if $Gamma$ admits a symmetric fractional polymorphism
of arity 2.
Using these results, we obtain tractability of several novel classes of problems, including problems over valued constraint
languages that are (1) submodular on arbitrary lattices; (2)
$k$-submodular on arbitrary finite domains;
(3) weakly (and hence strongly) tree submodular on arbitrary trees.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–36},
numpages = {36},
keywords = {submodularity, fractional polymorphisms, 68Q25, 90C27, 08A70, 68Q17, valued constraint satisfaction, linear programming, bisubmodularity}
}

@article{10.1137/11083976X,
author = {\v{S}tefankovi\v{c}, Daniel and Vempala, Santosh and Vigoda, Eric},
title = {A Deterministic Polynomial-Time Approximation Scheme for Counting Knapsack Solutions},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/11083976X},
doi = {10.1137/11083976X},
abstract = {Given $n$ elements with nonnegative integer weights $w_1, ldots, w_n$ and an integer capacity $C$, we consider the counting version of the classic knapsack problem: find the number of distinct subsets whose weights add up to at most the given capacity. We give a deterministic algorithm that estimates the number of solutions to within relative error $1pmvarepsilon$ in time polynomial in $n$ and $1/varepsilon$ (fully polynomial approximation scheme). More precisely, our algorithm takes time $O(n^3varepsilon^{-1}log(n/varepsilon))$. Our algorithm is based on dynamic programming. Previously, randomized polynomial-time approximation schemes were known first by Morris and Sinclair via Markov chain Monte Carlo techniques and subsequently by Dyer via dynamic programming and rejection sampling.},
journal = {SIAM J. Comput.},
month = apr,
pages = {356–366},
numpages = {11},
keywords = {dynamic programming, knapsack, approximate counting}
}

@article{10.1137/110835918,
author = {Rubin, Natan and Kaplan, Haim and Sharir, Micha},
title = {Improved Bounds for Geometric Permutations},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/110835918},
doi = {10.1137/110835918},
abstract = {We show that the number of geometric permutations of an arbitrary collection of $n$ pairwise disjoint convex sets in ${mathbb R}^d$, for $dgeq 3$, is $O(n^{2d-3}log n)$, improving Wenger's 20-year-old bound of $O(n^{2d-2})$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {367–390},
numpages = {24},
keywords = {lines in space, line transversals, geometric permutations, combinatorial complexity, convex sets}
}

@article{10.1137/100816705,
author = {Gilbert, Anna C. and Li, Yi and Porat, Ely and Strauss, Martin J.},
title = {Approximate Sparse Recovery: Optimizing Time and Measurements},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/100816705},
doi = {10.1137/100816705},
abstract = {A Euclidean approximate sparse recovery system consists of parameters $k,N$, an $m$-by-$N$ measurement matrix, $bm{Phi}$, and a decoding algorithm, $mathcal{D}$. Given a vector, ${mathbf x}$, the system approximates ${mathbf x}$ by $widehat {mathbf x}=mathcal{D}(bm{Phi} {mathbf x})$, which must satisfy $|widehat {mathbf x} - {mathbf x}|_2le C |{mathbf x} - {mathbf x}_k|_2$, where ${mathbf x}_k$ denotes the optimal $k$-term approximation to ${mathbf x}$. (The output $widehat{mathbf x}$ may have more than $k$ terms.) For each vector ${mathbf x}$, the system must succeed with probability at least 3/4. Among the goals in designing such systems are minimizing the number $m$ of measurements and the runtime of the decoding algorithm, $mathcal{D}$. In this paper, we give a system with $m=O(k log(N/k))$ measurements—matching a lower bound, up to a constant factor—and decoding time $klog^{O(1)} N$, matching a lower bound up to a polylog$(N)$ factor. We also consider the encode time (i.e., the time to multiply $bm{Phi}$ by $x$), the time to update measurements (i.e., the time to multiply $bm{Phi}$ by a 1-sparse $x$), and the robustness and stability of the algorithm (resilience to noise before and after the measurements). Our encode and update times are optimal up to $log(k)$ factors. The columns of $bm{Phi}$ have at most $O(log^2(k)log(N/k))$ nonzeros, each of which can be found in constant time. Our full result, a fully polynomial randomized approximation scheme, is as follows. If ${mathbf x}={mathbf x}_k+nu_1$, where $nu_1$ and $nu_2$ (below) are arbitrary vectors (regarded as noise), then setting $widehat {mathbf x} = mathcal{D}(Phi {mathbf x} + nu_2)$, and for properly normalized $bm{Phi}$, we get $left|{mathbf x} - widehat {mathbf x}right|_2^2 le (1+epsilon)left|nu_1right|_2^2 + epsilonleft|nu_2right|_2^2$ using $O((k/epsilon)log(N/k))$ measurements and $(k/epsilon)log^{O(1)}(N)$ time for decoding.},
journal = {SIAM J. Comput.},
month = apr,
pages = {436–453},
numpages = {18},
keywords = {approximation, embedding, sublinear algorithms, sparse approximation, sketching}
}

@article{10.1137/100806709,
author = {Moore, Cristopher and Russell, Alexander},
title = {Approximating the Permanent via Nonabelian Determinants},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/100806709},
doi = {10.1137/100806709},
abstract = {Since the celebrated work of Jerrum, Sinclair, and Vigoda [J. ACM, 51 (2004), pp. 671-697], we have known that the permanent of a matrix with entries in ${0,1}$ can be approximated in randomized polynomial time by using a rapidly mixing Markov chain to sample perfect matchings of a bipartite graph. A separate strand of the literature has pursued the possibility of an alternate, algebraic polynomial-time approximation scheme. These schemes work by replacing each 1 with a random element of an algebra $mathcal{A}$ and considering the determinant of the resulting matrix. In the case where $mathcal{A}$ is noncommutative, this determinant can be defined in several ways. We show that for some estimators based on the conventional determinant, the critical ratio of the second moment to the square of the first—and therefore the number of trials we need to obtain a good estimate of the permanent—is $(1 + O(1/d))^n$ when $mathcal{A}$ is the algebra of $d times d$ matrices. These results can be extended to group algebras and semisimple algebras in general. We also study the symmetrized determinant of Barvinok, showing that the resulting estimator has small variance when $d$ is large enough. However, if $d$ is constant—the only case in which an efficient algorithm is known—we show that the critical ratio exceeds $2^{n} / n^{O(d)}$. Thus our results do not provide a new polynomial-time approximation scheme for the permanent. Indeed, they suggest that the algebraic approach to approximating the permanent faces significant obstacles. We obtain these results using diagrammatic techniques in which we express matrix products as contractions of tensor products. When these matrices are chosen randomly according to the Gaussian distribution, we can evaluate the trace of these products in terms of the cycle structure of a suitably random permutation. In the symmetrized case, our estimates are then derived by a connection with the character theory of the symmetric group.},
journal = {SIAM J. Comput.},
month = apr,
pages = {332–355},
numpages = {24},
keywords = {determinant, approximation algorithm, permanent}
}

@article{10.1137/100800774,
author = {Thorup, Mikkel and Zhang, Yin},
title = {Tabulation-Based 5-Independent Hashing with Applications to Linear Probing and Second Moment Estimation},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/100800774},
doi = {10.1137/100800774},
abstract = {In the framework of Wegman and Carter, a $k$-independent hash function maps any $k$ keys independently. It is known that 5-independent hashing provides good expected performance in applications such as linear probing and second moment estimation for data streams. The classic $5$-independent hash function evaluates a degree 4 polynomial over a prime field containing the key domain $[n]={0,ldots,n-1}$. Here we present an efficient 5-independent hash function that uses no multiplications. Instead, for any parameter $c$, we make $2c-1$ lookups in tables of size $O(n^{1/c})$. In experiments on different computers, our scheme gained factors of 1.8 to 10 in speed over the polynomial method. We also conducted experiments on the performance of hash functions inside the above applications. In particular, we give realistic examples of inputs that make the most popular 2-independent hash function perform quite poorly. This illustrates the advantage of using schemes with provably good expected performance for all inputs.},
journal = {SIAM J. Comput.},
month = apr,
pages = {293–331},
numpages = {39},
keywords = {$k$-independence, hashing, tabulation}
}

@article{10.1137/090779000,
author = {Bansal, Nikhil and Buchbinder, Niv and Naor, Joseph (Seffi)},
title = {Randomized Competitive Algorithms for Generalized Caching},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090779000},
doi = {10.1137/090779000},
abstract = {We consider online algorithms for the generalized caching problem. Here we are given a cache of size $k$ and pages with arbitrary sizes and fetching costs. Given a request sequence of pages, the goal is to minimize the total cost of fetching the pages into the cache. Our main result is an online algorithm with competitive ratio $O(log^2k)$, which gives the first $o(k)$ competitive algorithm for the problem. We also give improved $O(log k)$-competitive algorithms for the special cases of the bit model and fault model, improving upon the previous $O(log^2k)$ guarantees due to Irani [Proceedings of the 29th Annual ACM Symposium on Theory of Computing, 1997, pp. 701-710]. Our algorithms are based on an extension of the online primal-dual framework introduced by Buchbinder and Naor [Math. Oper. Res., 34 (2009), pp. 270-286] and involve two steps. First, we obtain an $O(log k)$-competitive fractional algorithm based on solving online an LP formulation strengthened with exponentially many knapsack cover constraints. Second, we design a suitable online rounding procedure to convert this online fractional algorithm into a randomized algorithm. Our techniques provide a unified framework for caching algorithms and are substantially simpler than those previously used.},
journal = {SIAM J. Comput.},
month = apr,
pages = {391–414},
numpages = {24},
keywords = {competitive analysis, generalized caching, paging, randomization}
}

@article{10.1137/090776512,
author = {Dolev, Danny and Hoch, Ezra N. and Moses, Yoram},
title = {An Optimal Self-Stabilizing Firing Squad},
year = {2012},
issue_date = {April 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090776512},
doi = {10.1137/090776512},
abstract = {Consider a fully connected network where up to $t$ processes may crash and all processes start in an arbitrary memory state. The self-stabilizing firing squad problem consists of eventually guaranteeing simultaneous response to an external input. This is modeled by requiring that the noncrashed processes “fire” simultaneously if some correct process received an external “go” input, and that they only fire as a response to some process receiving such an input. This paper presents FireSquad, the first self-stabilizing firing squad algorithm. A firing squad algorithm facilitates the use of algorithms that need to start in the same round. It allows a smooth transition between algorithms whose executions need to be disjoint. The FireSquad algorithm combines two forms of fault-tolerance properties: self-stabilization to allow recovery from arbitrary transient errors and resilience to crash failures to handle permanent ones. The FireSquad algorithm is optimal in two respects: (a) once the algorithm is in a safe state, it fires in response to a go input as fast as any other algorithm does, and (b) starting from an arbitrary state, it converges to a safe state as fast as any other algorithm does.},
journal = {SIAM J. Comput.},
month = apr,
pages = {415–435},
numpages = {21},
keywords = {simultaneity, firing squad, distributed algorithms, common knowledge, synchronous system, self-stabilization}
}

@article{10.1137/110828812,
author = {Karnin, Zohar S. and Rabani, Yuval and Shpilka, Amir},
title = {Explicit Dimension Reduction and Its Applications},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/110828812},
doi = {10.1137/110828812},
abstract = {We construct a small set of explicit linear transformations mapping $mathbb{R}^n$ to $mathbb{R}^t$, where $t=O(log (gamma^{-1}) epsilon^{-2})$, such that the $L_2$ norm of any vector in $mathbb{R}^n$ is distorted by at most $1pm epsilon$ in at least a fraction of $1 - gamma$ of the transformations in the set. Albeit the tradeoff between the size of the set and the success probability is suboptimal compared with probabilistic arguments, we nevertheless are able to apply our construction to a number of problems. In particular, we use it to construct an $epsilon$-sample (or pseudorandom generator) for linear threshold functions on $mathbb{S}^{n-1}$ for $epsilon = o(1)$. We also use it to construct an $epsilon$-sample for spherical digons in $mathbb{S}^{n-1}$ for $epsilon = o(1)$. This construction leads to an efficient oblivious derandomization of the Goemans-Williamson Max-Cut algorithm and similar approximation algorithms (i.e., we construct a small set of hyperplanes such that for any instance we can choose one of them to generate a good solution). Our technique for constructing an $epsilon$-sample for linear threshold functions on the sphere is considerably different than previous techniques that rely on $k$-wise independent sample spaces.},
journal = {SIAM J. Comput.},
month = feb,
pages = {219–249},
numpages = {31},
keywords = {digons, Johnson Lindenstrauss, Max-Cut, pseudorandom generator, dimension reduction, linear threshold functions}
}

@article{10.1137/100814998,
author = {Viola, Emanuele},
title = {The Complexity of Distributions},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100814998},
doi = {10.1137/100814998},
abstract = {Complexity theory typically studies the complexity of computing a function $h(x) : {0, 1}^m to {0, 1}^n$ of a given input $x$. A few works have suggested studying the complexity of generating—or sampling—the distribution $h(x)$ for uniform $x$, given random bits. We further advocate this study, with a new emphasis on lower bounds for restricted computational models. Our main results are the following: (1) Any function $f : {0, 1}^ell to {0, 1}^n$ such that (i) each output bit $f_i$ depends on $o(log n)$ input bits, and (ii) $ell le log_2 binom{n}{alpha n} + n^{0.99}$ has output distribution $f(U)$ at statistical distance $ge 1 - 1/n^{0.49}$ from the uniform distribution over $n$-bit strings of hamming weight $alpha n$. We also prove lower bounds for generating $(X,b(X))$ for Boolean $b$, and in the case in which each bit $f_i$ is a small-depth decision tree. These lower bounds seem to be the first of their kind; the proofs use anticoncentration results for the sum of random variables. (2) Lower bounds for succinct data structures. As a corollary of (1), we obtain the first lower bound for the membership problem of representing a set $S subseteq [n]$ of size $alpha n$, in the case where $1/alpha$ is a power of $2$: If queries “$i in S$?” are answered by nonadaptively probing $o(log n)$ bits, then the representation uses $ge log_2 binom{n}{alpha n} + Omega(log n)$ bits. (3) Upper bounds complementing the bounds in (1) for various settings of parameters. (4) Uniform randomized $mathrm{AC}^0$ circuits of $mathrm{poly}(n)$ size and depth $d = O(1)$ with error $epsilon$ can be simulated by uniform randomized $mathrm{AC}^0$ circuits of $mathrm{poly}(n)$ size and depth $d+1$ with error $epsilon + o(1)$ using $le (log n)^{O( log log n)}$ random bits. Previous derandomizations [M. Ajtai and A. Wigderson, Adv. Comput. Res., 5 (1989), pp. 199-223], [N. Nisan, Combinatorica, 11 (1991), pp. 63-70] increase the depth by a constant factor, or else have poor seed length.},
journal = {SIAM J. Comput.},
month = feb,
pages = {191–218},
numpages = {28},
keywords = {distribution, pseudorandom generator, local, lower bound, succinct data structure, decision tree, sampling}
}

@article{10.1137/100811489,
author = {Jansson, Jesper and Lemence, Richard S. and Lingas, Andrzej},
title = {The Complexity of Inferring A Minimally Resolved Phylogenetic Supertree},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100811489},
doi = {10.1137/100811489},
abstract = {A recursive algorithm by Aho et al. [SIAM J. Comput., 10 (1981), pp. 405-421] forms the basis for many modern rooted supertree methods employed in Phylogenetics. However, as observed by Bryant [Building Trees, Hunting for Trees, and Comparing Trees: Theory and Methods in Phylogenetic Analysis, Ph.D. thesis, University of Canterbury, Christchurch, New Zealand, 1997], the tree output by the algorithm of Aho et al. is not always minimal; there may exist other trees which contain fewer nodes yet are still consistent with the input. In this paper, we prove strong polynomial-time inapproximability results for the problem of inferring a minimally resolved supertree from a given consistent set of rooted triplets (MinRS). Furthermore, we show that the decision version of MinRS is NP-hard for any fixed positive integer $qgeq4$, where $q$ is the number of allowed internal nodes, but linear-time solvable for $qleq3$. In contrast, MinRS becomes polynomial-time solvable for any $q$ when restricted to caterpillars. We also present an exponential-time algorithm based on tree separators for solving MinRS exactly. It runs in $2^{O(nlog p)}$ time when every node may have at most $p$ children that are internal nodes and where $n$ is the cardinality of the leaf label set. Finally, we demonstrate that augmenting the algorithm of Aho et al. with an algorithm for optimal graph coloring to help merge certain blocks of leaves during the execution does not improve the output solution much in the worst case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {272–291},
numpages = {20},
keywords = {phylogenetic tree, NP-hardness, tree separator, minimally resolved supertree, rooted triplet, graph coloring}
}

@article{10.1137/090780304,
author = {Arora, Sanjeev and Lov\'{a}sz, L\'{a}szl\'{o} and Newman, Ilan and Rabani, Yuval and Rabinovich, Yuri and Vempala, Santosh},
title = {Local Versus Global Properties of Metric Spaces},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090780304},
doi = {10.1137/090780304},
abstract = {Motivated by applications in combinatorial optimization, we study the extent to which the global properties of a metric space, and especially its embeddability into $ell_1$ with low distortion, are determined by the properties of its small subspaces. We establish both upper and lower bounds on the distortion of embedding locally constrained metrics into various target spaces. Other aspects of locally constrained metrics are studied as well, in particular, how far are those metrics from general metrics.},
journal = {SIAM J. Comput.},
month = feb,
pages = {250–271},
numpages = {22},
keywords = {dimension-reduction, sparsification}
}

@article{10.1137/100816833,
author = {Pitassi, Toniann and Segerlind, Nathan},
title = {Exponential Lower Bounds and Integrality Gaps for Tree-Like Lov\'{a}Sz-Schrijver Procedures},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100816833},
doi = {10.1137/100816833},
abstract = {The matrix cuts of Lov\'{a}sz and Schrijver are methods for tightening linear relaxations of zero-one programs by the addition of new linear inequalities. We address the question of how many new inequalities are necessary to approximate certain combinatorial problems, and we solve certain instances of Boolean satisfiability. Our first result is a size/rank tradeoff for tree-like Lov\'{a}sz-Schrijver refutations, showing that any refutation that has small size also has small rank. This allows us to immediately derive exponential-size lower bounds for tree-like refutations of many unsatisfiable systems of inequalities where, prior to our work, only strong rank bounds were known. Unfortunately, we show that this tradeoff does not hold more generally for derivations of arbitrary inequalities. We give a very simple example showing that derivations can be very small but nonetheless require maximal rank. This rules out a generic argument for obtaining a size-based integrality gap from the corresponding rank-based integrality gap. Our second contribution is to show that a modified argument can often be used to prove size-based integrality gaps from rank-based integrality gaps. We apply this method to prove size-based integrality gaps for several prominent examples where, prior to our work, only rank-based integrality gaps were known. Our third contribution is to prove new separation results. Using our machinery for converting rank-based lower bounds and integrality gaps into size-based lower bounds, we show that tree-like $mbox{LS}_+$ cannot polynomially simulate tree-like cutting planes, and that tree-like $mbox{LS}_+$ cannot polynomially simulate resolution.},
journal = {SIAM J. Comput.},
month = jan,
pages = {128–159},
numpages = {32},
keywords = {matrix-cut systems, linear programming, proof complexity, semidefinite programming}
}

@article{10.1137/100814196,
author = {Gelade, Wouter and Gyssens, Marc and Martens, Wim},
title = {Regular Expressions with Counting: Weak versus Strong Determinism},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100814196},
doi = {10.1137/100814196},
abstract = {We study deterministic regular expressions extended with the counting operator. There exist two notions of determinism, strong and weak determinism, which are equally expressive for standard regular expressions. This, however, changes dramatically in the presence of counting. In particular, we show that weakly deterministic expressions with counting are exponentially more succinct and strictly more expressive than strongly deterministic ones, even though they still do not capture all regular languages. In addition, we present a finite automaton model with counters, study its properties, and investigate the natural extension of the Glushkov construction translating expressions with counting into such counting automata. This translation yields a deterministic automaton if and only if the expression is strongly deterministic. These results then also allow us to derive upper bounds for decision problems for strongly deterministic expressions with counting.},
journal = {SIAM J. Comput.},
month = jan,
pages = {160–190},
numpages = {31},
keywords = {numerical occurrence indicators, automata, counters, determinism, regular expressions}
}

@article{10.1137/100801597,
author = {Cohen, Edith and Feldman, Michal and Fiat, Amos and Kaplan, Haim and Olonetsky, Svetlana},
title = {Envy-Free Makespan Approximation},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100801597},
doi = {10.1137/100801597},
abstract = {We study envy-free mechanisms for assigning tasks to agents, where every task may take a different amount of time to perform by each agent, and the goal is to get all the tasks done as soon as possible (i.e., minimize the makespan). For indivisible tasks, we put forward an envy-free polynomial mechanism that approximates the minimal makespan to within a factor of $O(log m)$, where $m$ is the number of machines. This bound is almost tight, as we also show that no envy-free mechanism can achieve a better bound than $Omega(log m / loglog m)$. This improves the recent result of Mu'alem [On multi-dimensional envy-free mechanisms, in Proceedings of the First International Conference on Algorithmic Decision Theory, F. Rossi and A. Tsoukias, eds., Lecture Notes in Comput. Sci. 5783, Springer, Berlin, 2009, pp. 120-131] who introduced the model and gave an upper bound of $(m+1)/2$ and a lower bound of $2-1/m$. For divisible tasks, we show that there always exists an envy-free poly-time mechanism with optimal makespan. Finally, we demonstrate how our mechanism for envy-free makespan minimization can be interpreted as a market clearing problem.},
journal = {SIAM J. Comput.},
month = jan,
pages = {12–25},
numpages = {14},
keywords = {envy-free, algorithmic mechanism design, scheduling}
}

@article{10.1137/100798144,
author = {Gibson, Matt and Kanade, Gaurav and Krohn, Erik and Pirwani, Imran A. and Varadarajan, Kasturi},
title = {On Clustering to Minimize the Sum of Radii},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100798144},
doi = {10.1137/100798144},
abstract = {Let $P$ be a set of $n$ points in the plane. Consider the problem of finding $k$ disks, each centered at a point in $P$, whose union covers $P$ with the objective of minimizing the sum of the radii of the disks. We present an exact algorithm for this well-studied problem with polynomial running time, under the assumption that two candidate solutions can be compared efficiently. The algorithm generalizes in a straightforward manner to any fixed dimension and to some other related problems.},
journal = {SIAM J. Comput.},
month = jan,
pages = {47–60},
numpages = {14},
keywords = {$k$-clustering, minimum sum of radii cover, min-cost $k$-cover}
}

@article{10.1137/100797916,
author = {Izumi, Taisuke and Souissi, Samia and Katayama, Yoshiaki and Inuzuka, Nobuhiro and D\'{e}fago, Xavier and Wada, Koichi and Yamashita, Masafumi},
title = {The Gathering Problem for Two Oblivious Robots with Unreliable Compasses},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100797916},
doi = {10.1137/100797916},
abstract = {Anonymous mobile robots are often classified into synchronous, semi-synchronous, and asynchronous robots when discussing the pattern formation problem. For semi-synchronous robots, all patterns formable with memory are also formable without memory, with the single exception of forming a point (i.e., the gathering) by two robots. (All patterns formable with memory are formable without memory for synchronous robots, and little is known for asynchronous robots.) However, the gathering problem for two semi-synchronous robots without memory (called oblivious robots in this paper) is trivially solvable when their local coordinate systems are consistent, and the impossibility proof essentially uses the inconsistencies in their coordinate systems. Motivated by this, this paper investigates the magnitude of consistency between the local coordinate systems necessary and sufficient to solve the gathering problem for two oblivious robots under semi-synchronous and asynchronous models. To discuss the magnitude of consistency, we assume that each robot is equipped with an unreliable compass, the bearings of which may deviate from an absolute reference direction, and that the local coordinate system of each robot is determined by its compass. We consider two families of unreliable compasses, namely, static compasses with (possibly incorrect) constant bearings and dynamic compasses the bearings of which can change arbitrarily (immediately before a new look-compute-move cycle starts and after the last cycle ends). For each of the combinations of robot and compass models, we establish the condition on deviation $phi$ that allows an algorithm to solve the gathering problem, where the deviation is measured by the largest angle formed between the $x$-axis of a compass and the reference direction of the global coordinate system: $phi &lt; pi/2$ for semi-synchronous and asynchronous robots with static compasses, $phi &lt; pi/4$ for semi-synchronous robots with dynamic compasses, and $phi &lt; pi/6$ for asynchronous robots with dynamic compasses. Except for asynchronous robots with dynamic compasses, these sufficient conditions are also necessary.},
journal = {SIAM J. Comput.},
month = jan,
pages = {26–46},
numpages = {21},
keywords = {gathering problem, mobile robot, distributed algorithm}
}

@article{10.1137/10078791X,
author = {Agarwal, Pankaj K. and Arge, Lars and Kaplan, Haim and Molad, Eyal and Tarjan, Robert E. and Yi, Ke},
title = {An Optimal Dynamic Data Structure for Stabbing-Semigroup Queries},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/10078791X},
doi = {10.1137/10078791X},
abstract = {Let $S$ be a set of $n$ intervals in $mathbb{R}$, and let $(mathbf{S}, +)$ be any commutative semigroup. We assign a weight $omega(s) in mathbf{S}$ to each interval in $S$. For a point $x in mathbb{R}$, let $S(x) subseteq S$ be the set of intervals that contain $x$. Given a point $q in mathbb{R}$, the stabbing-semigroup query asks for computing $sum_{s in S(q)} omega(s)$. We propose a linear-size dynamic data structure, under the pointer-machine model, that answers queries in worst-case $O(log n)$ time and supports both insertions and deletions of intervals in amortized $O(log n)$ time. It is the first data structure that attains the optimal $O(log n)$ bound for all three operations. Furthermore, our structure can easily be adapted to external memory, where we obtain a linear-size structure that answers queries and supports updates in $O(log_B n)$ I/Os, where $B$ is the disk block size. For the restricted case of a nested family of intervals (either every pair of intervals is disjoint or one contains the other), we present a simpler solution based on dynamic trees.},
journal = {SIAM J. Comput.},
month = jan,
pages = {104–127},
numpages = {24},
keywords = {dynamic data structures, stabbing queries, semigroup queries}
}

@article{10.1137/090766632,
author = {Devroye, Luc},
title = {Simulating Size-Constrained Galton-Watson Trees},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090766632},
doi = {10.1137/090766632},
abstract = {We discuss various methods for generating random Galton-Watson trees conditional on their sizes being equal to $n$. A linear expected time algorithm is proposed.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1–11},
numpages = {11},
keywords = {random variate generation, random trees, simulation, Cayley trees, Catalan trees, Galton-Watson branching process, expected time analysis}
}

@article{10.1137/080732572,
author = {Gabow, Harold N. and Gallagher, Suzanne R.},
title = {Iterated Rounding Algorithms for the Smallest <i>k</i>-Edge Connected Spanning Subgraph},
year = {2012},
issue_date = {January 2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {41},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/080732572},
doi = {10.1137/080732572},
abstract = {We present the best known algorithms for approximating the minimum-size undirected $k$-edge connected spanning subgraph. For simple graphs our approximation ratio is $1+ {1}/(2k) + O({1}/{k^2})$. The more precise version of this bound requires $kge 7$, and for all such $k$ it improves the long-standing performance ratio of Cheriyan and Thurimella [SIAM J. Comput., 30 (2000), pp. 528-560], $1+2/(k+1)$. The improvement comes in two steps. First we show that for simple $k$-edge connected graphs, any laminar family of degree $k$ sets is smaller than the general bound ($n(1+ {3}/{k} + O(1/ksqrt k))$ versus $2n$). This immediately implies that iterated rounding improves the performance ratio of Cheriyan and Thurimella. The second step carefully chooses good edges for rounding. For multigraphs our approximation ratio is $1+(21/11)k &lt;1+1.91/k$ for any $k&gt;1$. This improves the previous ratio $1+2/k$ [H. N. Gabow, M. X. Goemans, E. Tardos, and D. P. Williamson, Networks, 53 (2009), pp. 345-357]. It is of interest since it is known that for some constant $c&gt;0$, an approximation ratio $le 1+c/k$ implies $P=NP$. Our approximation ratio extends to the minimum-size Steiner network problem, where $k$ denotes the average vertex demand. The algorithm exploits rounding properties of the first two linear programs in iterated rounding.},
journal = {SIAM J. Comput.},
month = jan,
pages = {61–103},
numpages = {43},
keywords = {approximation algorithms, graph connectivity, edge connectivity, linear programming, graph algorithms, network design}
}

@article{10.1137/SMJCAT000040000006001738000001,
author = {Chawla, Shuchi and Dwork, Cynthia and Guruswami, Venkat},
title = {Special Section on the Fortieth Annual ACM},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000040000006001738000001},
doi = {10.1137/SMJCAT000040000006001738000001},
abstract = {In keeping with an annual tradition, this issue of the SIAM Journal on Computing contains extended versions of selected papers from the Fortieth Annual ACM Conference on Theory of Computing (STOC 2008), held in Victoria, British Columbia, May 17-20, 2008.The committee, comprising James Aspnes, Shai Ben-David, Shuchi Chawla, Bernard Chazelle, Steve Chien, Xiaotie Deng, Cynthia Dwork (chair), Martin Dyer, Ronald Fagin, Joan Feigenbaum, Anupam Gupta, Venkatesan Guruswami, Konstantin Makarychev, Elchanan Mossel, Rafael Pass, Oded Regev, Omer Reingold, Ronitt Rubinfeld, David Shmoys, Luca Trevisan, and Andrew Chi-Chih Yao, selected 80 papers from 320 submissions under consideration.Nine of these papers appear in this special section, each one expanded and then refereed according to the journal's exacting standards. The papers cover a diverse set of topics:We thank the authors, the referees, and the full program committee for all the work that lead to this volume.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1738},
numpages = {1}
}

@article{10.1137/100811465,
author = {Pass, Rafael and Tseng, Wei-Lung Dustin and Wikstr\"{o}m, Douglas},
title = {On the Composition of Public-Coin Zero-Knowledge Protocols},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/100811465},
doi = {10.1137/100811465},
abstract = {We show that only languages in BPP have public-coin black-box zero-knowledge protocols that are secure under an unbounded (polynomial) number of parallel repetitions. This result holds both in the plain model (without any setup) and in the bare public key model (where the prover and the verifier have registered public keys). We complement this result by constructing a public-coin black-box zero-knowledge proof based on one-way functions that remains secure under any a priori bounded number of concurrent executions. A key step (of independent interest) in the analysis of our lower bound shows that any public-coin protocol, when repeated sufficiently in parallel, satisfies a notion of “resettable soundness” if the verifier picks its random coins using a pseudorandom function.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1529–1553},
numpages = {25},
keywords = {zero-knowledge, parallel repetition, public-coin interactive protocols}
}

@article{10.1137/100808459,
author = {Kaplan, Haim and Katz, Matthew J. and Morgenstern, Gila and Sharir, Micha},
title = {Optimal Cover of Points by Disks in a Simple Polygon},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/100808459},
doi = {10.1137/100808459},
abstract = {Let $P$ be a simple polygon, and let $Q$ be a set of points in $P$. We present an almost-linear time algorithm for computing a minimum cover of $Q$ by disks that are contained in $P$. We then generalize the algorithm so that it can compute a minimum cover of $Q$ by homothets of any fixed compact convex set ${cal O}$ of constant description complexity that are contained in $P$. This improves previous results of Katz and Morgenstern [Lecture Notes in Comput. Sci. 5664, 2009, pp. 447-458]. We also consider the minimum disk-cover problem when $Q$ is contained in a (sufficiently narrow) annulus and present a nearly linear algorithm for this case, too.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1647–1661},
numpages = {15},
keywords = {minimum disk cover, chordal graphs, geometric covering}
}

@article{10.1137/100806126,
author = {Shalev-Shwartz, Shai and Shamir, Ohad and Sridharan, Karthik},
title = {Learning Kernel-Based Halfspaces with the 0-1 Loss},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/100806126},
doi = {10.1137/100806126},
abstract = {We describe and analyze a new algorithm for agnostically learning kernel-based halfspaces with respect to the 0-1 loss function. Unlike most of the previous formulations, which rely on surrogate convex loss functions (e.g., hinge-loss in support vector machines (SVMs) and log-loss in logistic regression), we provide finite time/sample guarantees with respect to the more natural 0-1 loss function. The proposed algorithm can learn kernel-based halfspaces in worst-case time poly$(exp(Llog(L/epsilon)))$, for any distribution, where $L$ is a Lipschitz constant (which can be thought of as the reciprocal of the margin), and the learned classifier is worse than the optimal halfspace by at most $epsilon$. We also prove a hardness result, showing that under a certain cryptographic assumption, no algorithm can learn kernel-based halfspaces in time polynomial in $L$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1623–1646},
numpages = {24},
keywords = {learning halfspaces, kernel methods, learning theory}
}

@article{10.1137/10080484X,
author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
title = {Bisimulation Metrics for Continuous Markov Decision Processes},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/10080484X},
doi = {10.1137/10080484X},
abstract = {In recent years, various metrics have been developed for measuring the behavioral similarity of states in probabilistic transition systems [J. Desharnais et al., Proceedings of CONCUR'99, Springer-Verlag, London, 1999, pp. 258-273; F. van Breugel and J. Worrell, Proceedings of ICALP'01, Springer-Verlag, London, 2001, pp. 421-432]. In the context of finite Markov decision processes (MDPs), we have built on these metrics to provide a robust quantitative analogue of stochastic bisimulation [N. Ferns, P. Panangaden, and D. Precup, Proceedings of UAI-04, AUAI Press, Arlington, VA, 2004, pp. 162-169] and an efficient algorithm for its calculation [N. Ferns, P. Panangaden, and D. Precup, Proceedings of UAI-06, AUAI Press, Arlington, VA, 2006, pp. 174-181]. In this paper, we seek to properly extend these bisimulation metrics to MDPs with continuous state spaces. In particular, we provide the first distance-estimation scheme for metrics based on bisimulation for continuous probabilistic transition systems. Our work, based on statistical sampling and infinite dimensional linear programming, is a crucial first step in formally guiding real-world planning, where tasks are usually continuous and highly stochastic in nature, e.g., robot navigation, and often a substitution with a parametric model or crude finite approximation must be made. We show that the optimal value function associated with a discounted infinite-horizon planning task is continuous with respect to metric distances. Thus, our metrics allow one to reason about the quality of solution obtained by replacing one model with another. Alternatively, they may potentially be used directly for state aggregation.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1662–1714},
numpages = {53},
keywords = {Markov decision process, continuous, bisimulation, reinforcement learning, metrics}
}

@article{10.1137/100783352,
author = {Svitkina, Zoya and Fleischer, Lisa},
title = {Submodular Approximation: Sampling-Based Algorithms and Lower Bounds},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/100783352},
doi = {10.1137/100783352},
abstract = {We introduce several generalizations of classical computer science problems obtained by replacing simpler objective functions with general submodular functions. The new problems include submodular load balancing, which generalizes load balancing or minimum-makespan scheduling, submodular sparsest cut and submodular balanced cut, which generalize their respective graph cut problems, as well as submodular function minimization with a cardinality lower bound. We establish upper and lower bounds for the approximability of these problems with a polynomial number of queries to a function-value oracle. The approximation guarantees that most of our algorithms achieve are of the order of $sqrt{{n}/{ln n}}$. We show that this is the inherent difficulty of the problems by proving matching lower bounds. We also give an improved lower bound for the problem of approximating a monotone submodular function everywhere. In addition, we present an algorithm for approximating submodular functions with a special structure, whose guarantee is close to the lower bound. Although quite restrictive, the class of functions with this structure includes the ones that are used for lower bounds both by us and in previous work.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1715–1737},
numpages = {23},
keywords = {submodular functions, approximation algorithms, information-theoretic lower bounds}
}

@article{10.1137/090772988,
author = {Briest, Patrick and Krysta, Piotr and V\"{o}cking, Berthold},
title = {Approximation Techniques for Utilitarian Mechanism Design},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/090772988},
doi = {10.1137/090772988},
abstract = {This paper deals with the design of efficiently computable incentive-compatible mechanisms for combinatorial optimization problems with single-minded agents each possibly having multiple private parameters. We focus on approximation algorithms for NP-hard mechanism design problems. These algorithms need to satisfy certain monotonicity properties to ensure truthfulness. Since most of the known approximation techniques do not fulfill these properties, we study alternative techniques. Our first contribution is a quite general method to transform a pseudopolynomial algorithm into a monotone fully polynomial time approximation scheme (FPTAS). This can be applied to various problems like, e.g., knapsack, constrained shortest path, or job scheduling with deadlines. For example, the monotone FPTAS for the knapsack problem gives a very efficient, truthful mechanism for single-minded multiunit auctions. The best previous result for such auctions was a 2-appro-xi-ma-tion. In addition, we present a monotone PTAS for the generalized assignment problem with any constant number of private parameters per agent. The most efficient way to solve packing integer programs (PIPs) is linear programming-based randomized rounding, which also is in general not monotone. We show that primal-dual greedy algorithms achieve almost the same approximation ratios for PIPs as randomized rounding. The advantage is that these algorithms are inherently monotone. This way, we can significantly improve the approximation ratios of truthful mechanisms for various fundamental mechanism design problems like single-minded combinatorial auctions (CAs), unsplittable flow routing, and multicast routing. Our primal-dual approximation algorithms can also be used for the winner determination in CAs with general bidders specifying their bids through an oracle.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1587–1622},
numpages = {36},
keywords = {unsplittable multicommodity flow routing problem, algorithmic mechanism design, multiunit auctions, approximation algorithms, combinatorial auctions, truthful mechanisms}
}

@article{10.1137/090752353,
author = {Briest, Patrick and Krysta, Piotr},
title = {Buying Cheap Is Expensive: Approximability of Combinatorial Pricing Problems},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/090752353},
doi = {10.1137/090752353},
abstract = {We investigate nonparametric multiproduct pricing problems, in which we want to find revenue maximizing prices for products $mathcal{P}$ based on a set of customer samples $mathcal{C}$. We mostly focus on the unit-demand case, in which products constitute strict substitutes and each customer aims to purchase a single product. In this setting a customer sample consists of a number of nonzero values for different products and possibly an additional product ranking. Once prices are fixed, each customer chooses to buy one of the products she can afford based on some predefined selection rule. We distinguish between the min-buying, max-buying, and rank-buying models. Some of our results also extend to single-minded pricing, in which case products are strict complements and every customer seeks to buy a single set of products, which she purchases if the sum of prices is below her valuation for that set. For the min-buying model we show that the revenue maximization problem is not approximable within factor $mathcal{O}(log^{varepsilon}|mathcal{C}|)$ for some constant $varepsilon&gt;0$, unless $mathrm{NP}subseteqmathrm{DTIME}(n^{mathcal{O}(loglog n)})$, thereby almost closing the gap between the known algorithmic results and previous lower bounds. We also prove inapproximability within $mathcal{O}(ell^{varepsilon})$, $ell$ being an upper bound on the number of nonzero values per customer, and $mathcal{O}(|mathcal{P}|^{varepsilon})$ under slightly stronger assumptions and provide matching upper bounds. Surprisingly, these hardness results hold even if a price ladder constraint, i.e., a predefined order on the prices of all products, is given. Without the price ladder constraint we obtain similar hardness results for the special case of uniform valuations, i.e., the case that every customer has identical values for all the products she is interested in, assuming specific hardness of the balanced bipartite independent set problem in constant degree graphs or hardness of refuting random 3CNF formulas. Introducing a slightly more general problem definition in which customers are given as an explicit probability distribution, we obtain inapproximability within $mathcal{O}(|mathcal{P}|^{varepsilon})$ assuming $mathrm{NP}nsubseteqbigcap_{delta&gt;0}mathrm{BPTIME}(2^{mathcal{O}(n^{delta})})$. These results apply to single-minded pricing as well. For the max-buying model a polynomial-time approximation scheme exists if a price ladder is given. We give a matching lower bound by proving strong NP-hardness. Assuming limited product supply, we analyze a generic local search algorithm and prove that it is 2-approximate. Finally, we discuss implications for the rank-buying model.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1554–1586},
numpages = {33},
keywords = {approximation algorithms, hardness of approximation, combinatorial pricing}
}

@article{10.1137/08073408X,
author = {Kedlaya, Kiran S. and Umans, Christopher},
title = {Fast Polynomial Factorization and Modular Composition},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/08073408X},
doi = {10.1137/08073408X},
abstract = {We obtain randomized algorithms for factoring degree $n$ univariate polynomials over $mathbb{F}_q$ requiring $O(n^{1.5 + o(1)},{rm log}^{1+o(1)} q+ n^{1 + o(1)},{rm log}^{2+o(1)} q)$ bit operations. When ${rm log}, q &lt; n$, this is asymptotically faster than the best previous algorithms [J. von zur Gathen and V. Shoup, Comput. Complexity, 2 (1992), pp. 187-224; E. Kaltofen and V. Shoup, Math. Comp., 67 (1998), pp. 1179-1197]; for ${rm log}, q ge n$, it matches the asymptotic running time of the best known algorithms. The improvements come from new algorithms for modular composition of degree $n$ univariate polynomials, which is the asymptotic bottleneck in fast algorithms for factoring polynomials over finite fields. The best previous algorithms for modular composition use $O(n^{(omega + 1)/2})$ field operations, where $omega$ is the exponent of matrix multiplication [R. P. Brent and H. T. Kung, J. Assoc. Comput. Mach., 25 (1978), pp. 581-595], with a slight improvement in the exponent achieved by employing fast rectangular matrix multiplication [X. Huang and V. Y. Pan, J. Complexity, 14 (1998), pp. 257-299]. We show that modular composition and multipoint evaluation of multivariate polynomials are essentially equivalent, in the sense that an algorithm for one achieving exponent $alpha$ implies an algorithm for the other with exponent $alpha + o(1)$, and vice versa. We then give two new algorithms that solve the problem near-optimally: an algebraic algorithm for fields of characteristic at most $n^{o(1)}$, and a nonalgebraic algorithm that works in arbitrary characteristic. The latter algorithm works by lifting to characteristic 0, applying a small number of rounds of multimodular reduction, and finishing with a small number of multidimensional FFTs. The final evaluations are reconstructed using the Chinese remainder theorem. As a bonus, this algorithm produces a very efficient data structure supporting polynomial evaluation queries, which is of independent interest. Our algorithms use techniques that are commonly employed in practice, in contrast to all previous subquadratic algorithms for these problems, which relied on fast matrix multiplication.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1767–1802},
numpages = {36},
keywords = {modular composition, multimodular reduction, polynomial factorization, multivariate multipoint evaluation}
}

@article{10.1137/080734066,
author = {Valiant, Paul},
title = {Testing Symmetric Properties of Distributions},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080734066},
doi = {10.1137/080734066},
abstract = {We introduce the notion of a canonical tester for a class of properties on distributions, that is, a tester strong and general enough that “a distribution property in the class is testable if and only if the canonical tester tests it.” We construct a canonical tester for the class of properties of one or two distributions that are symmetric and satisfy a certain weak continuity condition. Analyzing the performance of the canonical tester on specific properties resolves two open problems, establishing lower bounds that match known upper bounds: we show that distinguishing between entropy $<alpha$ or="" $="">beta$ on distributions over $[n]$ requires $n^{alpha/beta- o(1)}$ samples, and distinguishing whether a pair of distributions has statistical distance $<alpha$ or="" $="">beta$ requires $n^{1- o(1)}$ samples. Our techniques also resolve a conjecture about a property that our canonical tester does not apply to: distinguishing identical distributions from those with statistical distance $&gt;frac{1}{2}$ requires $Omega(n^{2/3})$ samples.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1927–1968},
numpages = {42},
keywords = {Poissonization, $L_1$ distance approximation, entropy approximation, approximation algorithms, statistical properties, lower bounds, Vandermonde matrices}
}</alpha$></alpha$>

@article{10.1137/080734042,
author = {Rao, Anup},
title = {Parallel Repetition in Projection Games and a Concentration Bound},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080734042},
doi = {10.1137/080734042},
abstract = {A two-player game is played by cooperating players who are not allowed to communicate. A referee asks the players questions sampled from some known distribution and decides whether they win or not based on a known predicate of the questions and the players' answers. The parallel repetition of the game is the game in which the referee samples $n$ independent pairs of questions and sends the corresponding questions to the players simultaneously. If the players cannot win the original game with probability better than $(1-epsilon)$, what's the best they can do in the repeated game? We improve earlier results of [R. Raz, SIAM J. Comput., 27 (1998), pp. 763-803] and [T. Holenstein, Theory Comput., 5 (2009), pp. 141-172], who showed that the players cannot win all copies in the repeated game with probability better than $(1-epsilon/2)^{Omega(nepsilon^2/c)}$ (here $c$ is the length of the answers in the game), in the following ways: (i) We show that the probability of winning all copies is $(1-epsilon/2)^{Omega(epsilon n)}$ as long as the game is a “projection game,” the type of game most commonly used in hardness of approximation results. (ii) We prove a concentration bound for parallel repetition (of general games) showing that for any constant $0<delta <epsilon$,="" the="" probability="" that="" players="" win="" a="" $(1-epsilon+delta)$="" fraction="" of="" games="" in="" parallel="" repetition="" is="" at="" most="" $expleft(-omega_{epsilon}(delta^3="" n="" c)right)$="" (here="" constant="" may="" depend="" on="" $epsilon$);="" our="" result="" has="" applications="" to="" testing="" bell="" inequalities,="" since="" it="" implies="" chsh="" game="" can="" be="" used="" get="" an="" experiment="" very="" large="" classical="" versus="" quantum="" gap.="" first="" bound="" independent="" answer="" length="" and="" better="" dependence="" $epsilon$.="" by="" recent="" work="" raz="" [proceedings="" $49$th="" annual="" ieee="" symposium="" foundations="" computer="" science,="" 2008,="" pp.="" 369-373],="" this="" tight.="" gives="" generic="" way="" improve="" soundness="" probabilistically="" checkable="" proof="" (pcp),="" pcp.="" using="" it,="" for="" every="" $k$,="" one="" convert="" any="" $q$="" query="" pcp="" with="" $c$,="" size="" $sc$,="" $(1-epsilon)$="" into="" two-query="" $ck$,="" $o(ck="" (2s)^k)$,="" $(1-epsilon="" 2q)^{omega(epsilon="" k="" q)}$.="" another="" consequence="" unique="" conjecture="" khot="" $34$th="" acm="" theory="" computing,="" 2002,="" 767-775]="" now="" shown="" equivalent="" following="" priori="" weaker="" conjecture:="" there="" unbounded="" increasing="" function="" $f:mathbb{r}^+rightarrow="" mathbb{r}^+$="" such="" $epsilon=""> 0$, there exists an alphabet size $M(epsilon)$ for which it is NP-hard to distinguish a unique game with alphabet size $M$ in which a $(1-epsilon^2)$ fraction of the constraints can be satisfied from one in which a $(1-epsilon f(1/epsilon))$ fraction of the constraints can be satisfied.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1871–1891},
numpages = {21},
keywords = {parallel repetition, CHSH game, concentration}
}</delta>

@article{10.1137/080734029,
author = {Spielman, Daniel A. and Srivastava, Nikhil},
title = {Graph Sparsification by Effective Resistances},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080734029},
doi = {10.1137/080734029},
abstract = {We present a nearly linear time algorithm that produces high-quality spectral sparsifiers of weighted graphs. Given as input a weighted graph $G=(V,E,w)$ and a parameter $epsilon&gt;0$, we produce a weighted subgraph $H=(V,tilde{E},tilde{w})$ of $G$ such that $|tilde{E}|=O(nlog n/epsilon^2)$ and all $xinmathbb{R}^V$ satisfy $(1-epsilon)sum_{uvin E},(x(u)-x(v))^2w_{uv}leqsum_{uvintilde{E}},(x(u)-x(v))^2tilde{w}_{uv}leq(1+epsilon)sum_{uvin E},(x(u)-x(v))^2w_{uv}$. This improves upon the spectral sparsifiers constructed by Spielman and Teng, which had $O(nlog^{c}n)$ edges for some large constant $c$, and upon the cut sparsifiers of Bencz\'{u}r and Karger, which only satisfied these inequalities for $xin{0,1}^V$. A key ingredient in our algorithm is a subroutine of independent interest: a nearly linear time algorithm that builds a data structure from which we can query the approximate effective resistance between any two vertices in a graph in $O(log n)$ time.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1913–1926},
numpages = {14},
keywords = {sparsification, spectral graph theory, electrical flows}
}

@article{10.1137/080734017,
author = {Levin, Hagay and Schapira, Michael and Zohar, Aviv},
title = {Interdomain Routing and Games},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080734017},
doi = {10.1137/080734017},
abstract = {We present a game-theoretic model that captures many of the intricacies of interdomain routing in today's Internet. In this model, the strategic agents are source nodes located on a network, who aim to send traffic to a unique destination node. The interaction between the agents is dynamic and complex—asynchronous, sequential, and based on partial information. Best-reply dynamics in this model capture crucial aspects of the de facto standard interdomain routing protocol, namely, the Border Gateway Protocol (BGP). We study complexity and incentive-related issues in this model. Our main results show that in realistic and well-studied settings, BGP is incentive-compatible. That is, not only does myopic behavior of all players converge to a “stable” routing outcome, but no player has motivation to unilaterally deviate from BGP. Moreover, we show that even coalitions of players of any size cannot improve their routing outcomes by collaborating. Unlike the vast majority of works in mechanism design, our results do not require any monetary transfers (to or by the agents).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1892–1912},
numpages = {21},
keywords = {communication complexity, distributed algorithmic mechanism design, Border Gateway Protocol (BGP), interdomain routing, security}
}

@article{10.1137/080733991,
author = {Calinescu, Gruia and Chekuri, Chandra and P\'{a}l, Martin and Vondr\'{a}k, Jan},
title = {Maximizing a Monotone Submodular Function Subject to a Matroid Constraint},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080733991},
doi = {10.1137/080733991},
abstract = {Let $f:2^X rightarrow cal R_+$ be a monotone submodular set function, and let $(X,cal I)$ be a matroid. We consider the problem ${rm max}_{S in cal I} f(S)$. It is known that the greedy algorithm yields a $1/2$-approximation [M. L. Fisher, G. L. Nemhauser, and L. A. Wolsey, Math. Programming Stud., no. 8 (1978), pp. 73-87] for this problem. For certain special cases, e.g., ${rm max}_{|S| leq k} f(S)$, the greedy algorithm yields a $(1-1/e)$-approximation. It is known that this is optimal both in the value oracle model (where the only access to $f$ is through a black box returning $f(S)$ for a given set $S$) [G. L. Nemhauser and L. A. Wolsey, Math. Oper. Res., 3 (1978), pp. 177-188] and for explicitly posed instances assuming $P neq NP$ [U. Feige, J. ACM, 45 (1998), pp. 634-652]. In this paper, we provide a randomized $(1-1/e)$-approximation for any monotone submodular function and an arbitrary matroid. The algorithm works in the value oracle model. Our main tools are a variant of the pipage rounding technique of Ageev and Sviridenko [J. Combin. Optim., 8 (2004), pp. 307-328], and a continuous greedy process that may be of independent interest. As a special case, our algorithm implies an optimal approximation for the submodular welfare problem in the value oracle model [J. Vondr\'{a}k, Proceedings of the $38$th ACM Symposium on Theory of Computing, 2008, pp. 67-74]. As a second application, we show that the generalized assignment problem (GAP) is also a special case; although the reduction requires $|X|$ to be exponential in the original problem size, we are able to achieve a $(1-1/e-o(1))$-approximation for GAP, simplifying previously known algorithms. Additionally, the reduction enables us to obtain approximation algorithms for variants of GAP with more general constraints.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1740–1766},
numpages = {27},
keywords = {social welfare, matroid, monotone submodular set function, approximation algorithm, generalized assignment problem}
}

@article{10.1137/080733954,
author = {Peikert, Chris and Waters, Brent},
title = {Lossy Trapdoor Functions and Their Applications},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080733954},
doi = {10.1137/080733954},
abstract = {We propose a general cryptographic primitive called lossy trapdoor functions (lossy TDFs), and we use it to develop new approaches for constructing several important cryptographic tools, including (injective) trapdoor functions, collision-resistant hash functions, oblivious transfer, and chosen ciphertext-secure cryptosystems (in the standard model). All of these constructions are simple, efficient, and black-box. We realize lossy TDFs based on a variety of cryptographic assumptions, including the hardness of the decisional Diffie-Hellman (DDH) problem and the hardness of the “learning with errors” problem (which is implied by the worst-case hardness of various lattice problems). Taken together, our results resolve some long-standing open problems in cryptography. They give the first injective TDFs based on problems not directly related to integer factorization and provide the first chosen ciphertext-secure cryptosystem based solely on worst-case complexity assumptions.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1803–1844},
numpages = {42},
keywords = {chosen-ciphertext security, lossiness, lattices, trapdoor functions}
}

@article{10.1137/080733772,
author = {Mironov, Ilya and Naor, Moni and Segev, Gil},
title = {Sketching in Adversarial Environments},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080733772},
doi = {10.1137/080733772},
abstract = {We formalize a realistic model for computations over massive data sets. The model, referred to as the adversarial sketch model, unifies the well-studied sketch and data stream models together with a cryptographic flavor that considers the execution of protocols in “hostile environments,” and provides a framework for studying the complexity of tasks involving massive data sets. In the adversarial sketch model several parties are interested in computing a joint function in the presence of an adversary that dynamically chooses their inputs. These inputs are provided to the parties in an on-line manner, and each party incrementally updates a compressed sketch of its input. The parties are not allowed to communicate, they do not share any secret information, and any public information they share is known to the adversary in advance. Then, the parties engage in a protocol in order to evaluate the function on their current inputs using only their sketches. In this paper we settle the complexity of two fundamental problems in this model: testing whether two massive data sets are equal, and approximating the size of their symmetric difference. For these problems we construct explicit protocols that are optimal up to polylogarithmic factors. Our main technical contribution is an explicit and deterministic encoding scheme that enjoys two seemingly conflicting properties: incrementality and high distance, which may be of independent interest.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1845–1870},
numpages = {26},
keywords = {data stream model, communication complexity, sketch model}
}

@article{10.1137/080733644,
author = {Sherstov, Alexander A.},
title = {The Pattern Matrix Method},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080733644},
doi = {10.1137/080733644},
abstract = {We develop a novel technique for communication lower bounds, the pattern matrix method. Specifically, fix an arbitrary function $f: {0,1}^n to{0,1}$, and let $A_f$ be the matrix whose columns are each an application of $f$ to some subset of the variables $x_1,x_2,ldots,x_{4n}.$ We prove that $A_f$ has bounded-error communication complexity $Omega(d),$ where $d$ is the approximate degree of $f.$ This result remains valid in the quantum model, regardless of prior entanglement. In particular, it gives a new and simple proof of Razborov's breakthrough quantum lower bounds for disjointness and other symmetric predicates. We further characterize the discrepancy, approximate rank, and approximate trace norm of $A_f$ in terms of well-studied analytic properties of $f,$ broadly generalizing several recent results on small-bias communication and agnostic learning. The method of this paper has also enabled important progress in multiparty communication complexity.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1969–2000},
numpages = {32},
keywords = {pattern matrix method, discrepancy, linear programming duality, bounded-error communication complexity, approximation and sign-representation of Boolean functions by real polynomials, approximate trace norm, approximate rank, Degree/Discrepancy Theorem, quantum communication complexity}
}

@article{10.1137/080721820,
author = {Haitner, Iftach and Harnik, Danny and Reingold, Omer},
title = {On the Power of the Randomized Iterate},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080721820},
doi = {10.1137/080721820},
abstract = {We consider two of the most fundamental theorems in cryptography. The first, due to H\r{a}stad et al. [SIAM J. Comput., 28 (1999), pp. 1364-1396] is that pseudorandom generators can be constructed from any one-way function. The second, due to Yao [Proceedings of the $23$rd Annual Symposium on Foundations of Computer Science (FOCS), 1982, pp. 80-91], states that the existence of weak one-way functions implies the existence of full-fledged one-way functions. These powerful plausibility results shape our understanding of hardness and randomness in cryptography, but unfortunately their proofs are not as tight (i.e., security preserving) as one may desire. This work revisits a technique that we call the randomized iterate, introduced by Goldreich, Krawczyk, and Luby [SIAM J. Comput., 22 (1993), pp. 1163-1175]. This technique was used by Goldreich, Krawczyk, and Luby [SIAM J. Comput., 22 (1993), pp. 1163-1175] to give a construction of pseudorandom generators from regular one-way functions. We simplify and strengthen this technique in order to obtain a similar construction, where the seed length of the resulting generators is as short as $Theta(n log n)$ (rather than $Theta(n^3)$ achieved by Goldreich, Krawczyk, and Luby [SIAM J. Comput., 22 (1993), pp. 1163-1175]). Our technique has the potential of implying seed length $Theta(n)$, and the only bottleneck for such a result are the parameters of current generators against bounded-space computations. We give a construction with similar parameters for security amplification of regular one-way functions. This improves upon the construction of Goldreich et al. [Proceedings of the $31$st Annual Symposium on Foundations of Computer Science, (FOCS), 1990, pp. 318-326] in that the construction does not need to “know" the regularity parameter of the functions (in terms of security, the two reductions are incomparable). In addition, we use the randomized iterate to show a construction of a pseudorandom generator based on an exponentially hard one-way function that has a seed length of only $Theta(n^2)$. This improves a recent result of Holenstein [Proceedings of the Theory of Cryptography, Third Theory of Cryptography Conference (TCC), 2006] that shows a construction with seed length $Theta(n^5)$ based on such one-way functions. Finally, we show that the randomized iterate may even be useful in the general context of H\r{a}stad et al. [SIAM J. Comput., 28 (1999), pp. 1364-1396]. In particular, we use the randomized iterate to replace the basic building block of the H\r{a}stad et al. [SIAM J. Comput., 28 (1999), pp. 1364-1396] construction. Interestingly, this modification improves efficiency by an $Theta(n^2)$ factor and reduces the seed length to $Theta(n^7)$ (which also implies improvement in the security of the construction).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1486–1528},
numpages = {43},
keywords = {one-way functions, pseudorandom generator, cryptography, hardness amplification}
}

@article{10.1137/100785351,
author = {Haeupler, Bernhard and Sen, Siddhartha and Tarjan, Robert E.},
title = {Rank-Pairing Heaps},
year = {2011},
issue_date = {November 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/100785351},
doi = {10.1137/100785351},
abstract = {We introduce the rank-pairing heap, an implementation of heaps that combines the asymptotic efficiency of Fibonacci heaps with much of the simplicity of pairing heaps. Other heap implementations that match the bounds of Fibonacci heaps do so by maintaining a balance condition on the trees representing the heap. In contrast to these structures but like pairing heaps, our trees can evolve to have arbitrary (unbalanced) structure. Also like pairing heaps, our structure requires at most one cut and no other restructuring per key decrease, in the worst case: the only changes that can cascade during a key decrease are changes in node ranks. Although our data structure is simple, its analysis is not.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1463–1485},
numpages = {23},
keywords = {priority queue, amortized analysis, algorithm, heap, data structure}
}

@article{10.1137/0214015,
title = {Factoring Polynomials over Algebraic Number Fields},
year = {2011},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214015},
doi = {10.1137/0214015},
abstract = {We show that if $f(x)$ is a polynomial in $Z [ alpha ][ x ]$, where $alpha $ satisfies a monic irreducible polynomial over $Z$, then $f(x)$ can be factored over $Q(alpha )[ x ]$ in polynomial time. We also show that the splitting field of $f(x)$ can be determined in time polynomial in ([Splitting field of $f(x): Q $], $log | (x) |$).},
journal = {SIAM J. Comput.},
month = oct,
pages = {184–195},
numpages = {12}
}

@article{10.1137/090778274,
author = {Gopalan, Parikshit and Guruswami, Venkatesan and Raghavendra, Prasad},
title = {List Decoding Tensor Products and Interleaved Codes},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/090778274},
doi = {10.1137/090778274},
abstract = {We design the first efficient algorithms and prove new combinatorial bounds for list decoding tensor products of codes and interleaved codes. We show that for every code, the ratio of its list decoding radius (LDR) to its minimum distance stays unchanged under the tensor product operation (rather than squaring, as one might expect). This gives the first efficient list decoders and new combinatorial bounds for some natural codes including multivariate polynomials where the degree in each variable is bounded. We show that for every code, its LDR remains unchanged under $m$-wise interleaving for an integer $m$. This generalizes a recent result of Dinur et al. [in Proceedings of the 40th ACM Symposium on Theory of Computing (STOC '08), 2008, pp. 275-284], who proved such a result for interleaved Hadamard codes (equivalently, linear transformations). Using the notion of generalized Hamming weights, we give better list size bounds for both the tensoring and interleaving of binary linear codes. By analyzing the weight distribution of these codes, we reduce the task of bounding the list size to one of bounding the number of close-by low-rank codewords. For decoding linear transformations, using rank reduction together with other ideas, we obtain list size bounds that are tight over small fields. Our results give better bounds on the LDR than what is obtained from the Johnson bound, and yield rather general families of codes decodable beyond the Johnson radius.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1432–1462},
numpages = {31},
keywords = {list decoding, tensor product codes, Johnson bound, error-correcting codes, generalized Hamming weights}
}

@article{10.1137/100810502,
author = {Svensson, Ola},
title = {Hardness of Precedence Constrained Scheduling on Identical Machines},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/100810502},
doi = {10.1137/100810502},
abstract = {In 1966, Graham showed that a simple procedure called list scheduling yields a 2-approximation algorithm for the central problem of scheduling precedence constrained jobs on identical machines to minimize makespan. To date this has remained the best algorithm, and whether it can or cannot be improved has become a major open problem in scheduling theory. We address this problem by establishing a quite surprising relation between the approximability of the considered problem and that of scheduling precedence constrained jobs on a single machine to minimize weighted completion time. More specifically, we prove that if the single machine problem is hard to approximate within a factor of $2-epsilon$, then the considered parallel machine problem, even in the case of unit processing times, is hard to approximate within a factor of $2-zeta$, where $zeta$ tends to 0 as $epsilon$ tends to 0. Combining this with Bansal and Khot's recent hardness result for the single machine problem gives that it is NP-hard to improve upon the approximation ratio obtained by Graham, assuming a new variant of the unique games conjecture.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1258–1274},
numpages = {17},
keywords = {hardness of approximation, scheduling}
}

@article{10.1137/100806886,
author = {Ailon, Nir and Charikar, Moses},
title = {Fitting Tree Metrics: Hierarchical Clustering and Phylogeny},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/100806886},
doi = {10.1137/100806886},
abstract = {Given dissimilarity data on pairs of objects in a set, we study the problem of fitting a tree metric to this data so as to minimize additive error (i.e., some measure of the difference between the tree metric and the given data). This problem arises in constructing an $M$-level hierarchical clustering of objects (or an ultrametric on objects) so as to match the given dissimilarity data—a basic problem in statistics. Viewed in this way, the problem is a generalization of the correlation clustering problem (which corresponds to $M=1$). We give a very simple randomized combinatorial algorithm for the $M$-level hierarchical clustering problem that achieves an approximation ratio of $M+2$. This is a generalization of a previous factor 3 algorithm for correlation clustering on complete graphs. The problem of fitting tree metrics also arises in phylogeny where the objective is to learn the evolution tree by fitting a tree to dissimilarity data on taxa. The quality of the fit is measured by taking the $ell_p$ norm of the difference between the tree metric constructed and the given data. Previous results obtained a factor 3 approximation for finding the closest tree metric under the $ell_infty$ norm. No nontrivial approximation for general $ell_p$ norms was known before. We present a novel linear program formulation for this problem and obtain an $O((log n log log n)^{1/p})$-approximation to the closest ultrametric under the $ell_p$ norm using this. Our techniques are based on representing and viewing an ultrametric as a hierarchy of clusterings and may be useful in other contexts.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1275–1291},
numpages = {17},
keywords = {approximation algorithms, hierarchical clustering, phylogenic reconstructions}
}

@article{10.1137/10080395X,
author = {K\"{o}bler, Johannes and Kuhnert, Sebastian and Laubner, Bastian and Verbitsky, Oleg},
title = {Interval Graphs: Canonical Representations in Logspace},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/10080395X},
doi = {10.1137/10080395X},
abstract = {We present a logspace algorithm for computing a canonical labeling, in fact, a canonical interval representation, for interval graphs. To achieve this, we compute canonical interval representations of interval hypergraphs. This approach also yields a canonical labeling of convex graphs. As a consequence, the isomorphism and automorphism problems for these graph classes are solvable in logspace. For proper interval graphs we also design logspace algorithms computing their canonical representations by proper and by unit interval systems.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1292–1315},
numpages = {24},
keywords = {graph isomorphism, logspace, interval hypergraphs, unit interval graphs, convex graphs, graph canonization, interval graphs, proper interval graphs}
}

@article{10.1137/10079817X,
author = {Cohen, Edith and Duffield, Nick and Kaplan, Haim and Lund, Carsten and Thorup, Mikkel},
title = {Efficient Stream Sampling for Variance-Optimal Estimation of Subset Sums},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/10079817X},
doi = {10.1137/10079817X},
abstract = {From a high volume stream of weighted items, we want to maintain a generic sample of a certain limited size $k$ that we can later use to estimate the total weight of arbitrary subsets. This is the classic context of on-line reservoir sampling, thinking of the generic sample as a reservoir. We present an efficient reservoir sampling scheme, $textnormal{sc VarOpt$k$}$, that dominates all previous schemes in terms of estimation quality. $textnormal{sc VarOpt$k$}$ provides variance optimal unbiased estimation of subset sums. More precisely, if we have seen $n$ items of the stream, then for any subset size $m$, our scheme based on $k$ samples minimizes the average variance over all subsets of size $m$. In fact, the optimality is against any off-line scheme with $k$ samples tailored for the concrete set of items seen. In addition to optimal average variance, our scheme provides tighter worst-case bounds on the variance of particular subsets than previously possible. It is efficient, handling each new item of the stream in $O(log k)$ time. Finally, it is particularly well suited for combinations of samples from different streams in a distributed setting.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1402–1431},
numpages = {30},
keywords = {sampling without replacement, subset sum estimation, weighted sampling, reservoir sampling}
}

@article{10.1137/100797473,
author = {Jiang, Tao and Miller, Zevi and Pritikin, Dan},
title = {Near Optimal Bounds for Steiner Trees in the Hypercube},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/100797473},
doi = {10.1137/100797473},
abstract = {Given a set $S$ of vertices in a connected graph $G$, the classic Steiner tree problem asks for the minimum number of edges of a connected subgraph of $G$ that contains $S$. We study this problem in the hypercube. Given a set $S$ of vertices in the $n$-dimensional hypercube $Q_n$, the Steiner cost of $S$, denoted by $cost(S)$, is the minimum number of edges among all connected subgraphs of $Q_n$ that contain $S$. We obtain the following results on $cost(S)$. Let $epsilon$ be any given small, positive constant, and set $k=|S|$. (1) [upper bound] For every set $S$ we have $cost(S) &lt; (frac{1}{3}k + 1 + frac{1}{2}ln k)n.$ In particular, there is a constant $c_1$ depending only on $epsilon$ such that if $k &gt; c_1$, then $cost(S) &lt; (frac{1}{3} + epsilon)kn.$ (2) We develop a randomized algorithm of running time $O(kn)$ that produces a connected subgraph $H$ of $Q_n$ containing $S$ such that with probability approaching $1$ as $k,ntoinfty$ we have $|E(H)| &lt; (frac{1}{3} + epsilon)kn$. (3) [lower bound] There are constants $c_2$ and $b$ (with $1<b<2$) depending="" only="" on="" $epsilon$="" such="" that="" if="" $c_2<="" k="" <="" b^n$,="" then="" as="" $ntoinfty$="" almost="" all="" sets="" $s$="" of="" size="" $k$="" in="" $q_n$="" satisfy="" $cost(s)=""> (frac{1}{3} - epsilon)kn$. Thus for $k$ in this range with $kto infty$, the upper bound (1) is asymptotically tight. We also show that for fixed $k$, as $nto infty$, almost always a random family of $k$ vertices in $Q_n$ satisfies $[frac{k}{3}+frac{2}{9}(-1+(-frac{1}{2})^k)] n - sqrt{nln n}leq cost (S)leq [frac{k}{3}+frac{2}{9}(-1+(-frac{1}{2})^k)] n + sqrt{nln n}.$},
journal = {SIAM J. Comput.},
month = sep,
pages = {1340–1360},
numpages = {21},
keywords = {hypercube, Steiner trees}
}</b<2$)>

@article{10.1137/100791506,
author = {King, James and Krohn, Erik},
title = {Terrain Guarding is NP-Hard},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/100791506},
doi = {10.1137/100791506},
abstract = {A set $G$ of points on a terrain, also known as an $x$-monotone polygonal chain, is said to guard the terrain if every point on the terrain is seen by a point in $G$. Two points on the terrain see each other if and only if the line segment between them is never strictly below the terrain. The minimum terrain guarding problem asks for a minimum guarding set for the given input terrain. Using a reduction from PLANAR 3-SAT we prove that the decision version of this problem is NP-hard. This solves a significant open problem and complements recent positive approximability results for the optimization problem.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1316–1339},
numpages = {24},
keywords = {guarding monotone chains, art gallery problem, terrain guarding, visibility graph, NP-completeness}
}

@article{10.1137/090780328,
author = {Mertzios, George B. and Sau, Ignasi and Zaks, Shmuel},
title = {The Recognition of Tolerance and Bounded Tolerance Graphs},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/090780328},
doi = {10.1137/090780328},
abstract = {Tolerance graphs model interval relations in such a way that intervals can tolerate a certain degree of overlap without being in conflict. This subclass of perfect graphs has been extensively studied, due to both its interesting structure and its numerous applications (in bioinformatics, constraint-based temporal reasoning, resource allocation, and scheduling problems, among others). Several efficient algorithms for optimization problems that are NP-hard in general graphs have been designed for tolerance graphs. In spite of this, the recognition of tolerance graphs—namely, the problem of deciding whether a given graph is a tolerance graph—as well as the recognition of their main subclass of bounded tolerance graphs, have been the most fundamental open problems on this class of graphs (cf. the book on tolerance graphs [M. C. Golumbic and A. N. Trenk, Tolerance Graphs, Cambridge Stud. Adv. Math. 89, Cambridge University Press, Cambridge, UK, 2004]) since their introduction in 1982 [M. C. Golumbic and C. L. Monma, Proceedings of the 13th Southeastern Conference on Combinatorics, Graph Theory and Computing, Congr. Numer., 35 (1982), pp. 321-331]. In this article we prove that both recognition problems are NP-complete, even in the case where the input graph is a trapezoid graph. The presented results are surprising because, on the one hand, most subclasses of perfect graphs admit polynomial recognition algorithms and, on the other hand, bounded tolerance graphs were believed to be efficiently recognizable as they are a natural special case of trapezoid graphs (which can be recognized in polynomial time) and share a very similar structure with them. For our reduction we extend the notion of an acyclic orientation of permutation and trapezoid graphs. Our main tool is a new algorithm that uses vertex splitting to transform a given trapezoid graph into a permutation graph, while preserving this new acyclic orientation property. This method of vertex splitting is of independent interest; very recently, it was also proved a powerful tool in the design of efficient recognition algorithms for other classes of graphs [G. B. Mertzios and D. G. Corneil, Discrete Appl. Math., 159 (2011), pp. 1131-1147].},
journal = {SIAM J. Comput.},
month = sep,
pages = {1234–1257},
numpages = {24},
keywords = {tolerance graphs, NP-complete, bounded tolerance graphs, recognition, vertex splitting, trapezoid graphs, permutation graphs}
}

@article{10.1137/090748986,
author = {Aland, Sebastian and Dumrauf, Dominic and Gairing, Martin and Monien, Burkhard and Schoppmann, Florian},
title = {Exact Price of Anarchy for Polynomial Congestion Games},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/090748986},
doi = {10.1137/090748986},
abstract = {We show exact values for the worst-case price of anarchy in weighted and unweighted (atomic unsplittable) congestion games, provided that all cost functions are bounded-degree polynomials with nonnegative coefficients. The given values also hold for weighted and unweighted network congestion games.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1211–1233},
numpages = {23},
keywords = {atomic unsplittable congestion games, price of anarchy, selfish routing}
}

@article{10.1137/080732250,
author = {Gupta, Anupam and P\'{a}l, Martin and Ravi, R. and Sinha, Amitabh},
title = {Sampling and Cost-Sharing: Approximation Algorithms for Stochastic Optimization Problems},
year = {2011},
issue_date = {September 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/080732250},
doi = {10.1137/080732250},
abstract = {We consider two- and multistage versions of stochastic combinatorial optimization problems with recourse: in this framework, the instance for the combinatorial optimization problem is drawn from a known probability distribution $pi$ and is only revealed to the algorithm over two (or multiple) stages. At each stage, on receiving some more information about the instance, the algorithm is allowed to build some partial solution. Since the costs of elements increase with each passing stage, there is a natural tension between waiting for later stages, to gain more information about the instance, and purchasing elements in earlier stages, to take advantages of lower costs. We provide approximation algorithms for stochastic combinatorial optimization problems (such as the Steiner tree problem, the Steiner network problem, and the vertex cover problem) by means of a simple sampling-based algorithm. In every stage, our algorithm samples the probability distribution of the requirements and constructs a partial solution to serve the resulting sample. We show that if one can construct cost-sharing functions associated with the algorithms used to construct these partial solutions, then this strategy results in provable approximation guarantees for the overall stochastic optimization problem. We also extend this approach to provide an approximation algorithm for the stochastic version of the uncapacitated facility location problem, a problem that does not fit into the simpler framework of our main model.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1361–1401},
numpages = {41},
keywords = {stochastic optimization, combinatorial optimization, cost-sharing functions, approximation algorithms}
}

@article{10.1137/100804322,
author = {Dvir, Zeev and Gopalan, Parikshit and Yekhanin, Sergey},
title = {Matching Vector Codes},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/100804322},
doi = {10.1137/100804322},
abstract = {An $(r,delta,epsilon)$-locally decodable code encodes a $k$-bit message $x$ to an $N$-bit codeword $C(x)$, such that for every $iin[k]$, the $i$th message bit can be recovered with probability $1-epsilon$, by a randomized decoding procedure that queries only $r$ bits, even if the codeword $C(x)$ is corrupted in up to $delta N$ locations. Recently a new class of locally decodable codes (LDCs), based on families of vectors with restricted dot products, has been discovered. We refer to those codes as matching vector (MV) codes. Several families of $(r,delta,Theta(rdelta))$-locally decodable MV codes have been obtained. While codes in those families were shorter than codes of earlier generations, they suffered from having large values of $epsilon=Omega(rdelta)$, which meant that $r$-query MV codes could only handle error rates below $frac{1}{r}$. Thus larger query complexity gave shorter length codes but at the price of less error tolerance. No MV codes of a superconstant number of queries capable of tolerating a constant fraction of errors were known to exist. In this paper we present a new view of matching vector codes and uncover certain similarities between MV codes and classical Reed-Muller (RM) codes. Our view allows us to obtain deeper insights into the power and limitations of MV codes. Specifically, we obtain the following: (1) We show that existing families of MV codes can be enhanced to tolerate a large constant fraction of errors, independent of the number of queries. Such enhancement comes at a price of a moderate increase in the number of queries. (2) Our construction yields the first families of MV codes of superconstant query complexity that can tolerate a constant fraction of errors. Our codes are shorter than RM LDCs for all values of $rleqlog k/(loglog k)^c$, for some constant $c$. (3) We show that any MV code encodes messages of length $k$ to codewords of length at least $k2^{Omega(sqrt{log k})}$. Therefore MV codes do not improve upon RM LDCs for $rgeq(log k)^{Omega(sqrt{log k})}$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1154–1178},
numpages = {25},
keywords = {matching vectors, Reed-Muller codes, locally decodable codes}
}

@article{10.1137/090765328,
author = {B\"{u}rgisser, Peter and Landsberg, J. M. and Manivel, Laurent and Weyman, Jerzy},
title = {An Overview of Mathematical Issues Arising in the Geometric Complexity Theory Approach to $\mathbf{VP}\neq\mathbf{VNP}$},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/090765328},
doi = {10.1137/090765328},
abstract = {We discuss the geometry of orbit closures and the asymptotic behavior of Kronecker coefficients in the context of the geometric complexity theory program to prove a variant of Valiant's algebraic analogue of the $mathbf{P}neqmathbf{NP}$ conjecture. We also describe the precise separation of complexity classes that their program proposes to demonstrate.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1179–1209},
numpages = {31},
keywords = {orbit closure, determinant, geometric complexity theory, $mathbf{P}$ vs. $mathbf{NP}$, permanent, geometric invariant theory, Kronecker coefficient}
}

@article{10.1137/100814585,
author = {Cai, Jin-Yi and Lu, Pinyan and Xia, Mingji},
title = {Computational Complexity of Holant Problems},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/100814585},
doi = {10.1137/100814585},
abstract = {We propose and explore a novel alternative framework to study the complexity of counting problems, called Holant problems. Compared to counting constraint satisfaction problems (#CSP), it is a refinement with a more explicit role for the constraint functions. Both graph homomorphism and #CSP can be viewed as special cases of Holant problems. We prove complexity dichotomy theorems in this framework. Our dichotomy theorems apply to local constraint functions, which are symmetric functions on Boolean input variables and evaluate to arbitrary real or complex values. We discover surprising tractable subclasses of counting problems, which could not easily be specified in the #CSP framework. When all unary functions are assumed to be free ($mathrm{Holant}^*$ problems), the tractable ones consist of functions that are degenerate, or of arity at most two, or holographic transformations of Fibonacci gates. When only two special unary functions, the constant zero and constant one functions, are assumed to be free ($mathrm{Holant}^c$ problems), we further identify three special families of tractable cases. Then we prove that all other cases are #P-hard. The main technical tool we use and develop is holographic reductions. Another technical tool used in combination with holographic reductions is polynomial interpolations.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1101–1132},
numpages = {32},
keywords = {#P-hardness, holographic reduction, polynomial interpolation, Holant problems}
}

@article{10.1137/100800245,
author = {Dey, Tamal K. and Hirani, Anil N. and Krishnamoorthy, Bala},
title = {Optimal Homologous Cycles, Total Unimodularity, and Linear Programming},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/100800245},
doi = {10.1137/100800245},
abstract = {Given a simplicial complex with weights on its simplices, and a nontrivial cycle on it, we are interested in finding the cycle with minimal weight which is homologous to the given one. Assuming that the homology is defined with integer ($mathbb{Z}$) coefficients, we show the following (Theorem 5.2): For a finite simplicial complex $K$ of dimension greater than $p$, the boundary matrix $[partial_{p+1}]$ is totally unimodular if and only if $H_p(L, L_0)$ is torsion-free for all pure subcomplexes $L_0, L$ in $K$ of dimensions $p$ and $p+1$, respectively, where $L_0 subsetL$. Because of the total unimodularity of the boundary matrix, we can solve the optimization problem, which is inherently an integer programming problem, as a linear program and obtain an integer solution. Thus, the problem of finding optimal cycles in a given homology class can be solved in polynomial time. This result is surprising in the backdrop of a recent result which says that the problem is NP-hard under $mathbb{Z}_2$ coefficients which, being a field, is in general easier to deal with. Our result implies, among other things, that one can compute in polynomial time an optimal $(d-1)$-cycle in a given homology class for any triangulation of an orientable compact $d$-manifold or for any finite simplicial complex embedded in $mathbb{R}^d$. Our optimization approach can also be used for various related problems, such as finding an optimal chain homologous to a given one when these are not cycles. Our result can also be viewed as providing a topological characterization of total unimodularity.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1026–1044},
numpages = {19},
keywords = {computational topology, optimal chain, homology localization, simplicial complex}
}

@article{10.1137/100785429,
author = {Gopalan, Parikshit and O'Donnell, Ryan and Servedio, Rocco A. and Shpilka, Amir and Wimmer, Karl},
title = {Testing Fourier Dimensionality and Sparsity},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/100785429},
doi = {10.1137/100785429},
abstract = {We present a range of new results for testing properties of Boolean functions that are defined in terms of the Fourier spectrum. Broadly speaking, our results show that the property of a Boolean function having a concise Fourier representation is locally testable. We give the first efficient algorithms for testing whether a Boolean function has a sparse Fourier spectrum (small number of nonzero coefficients) and for testing whether the Fourier spectrum of a Boolean function is supported in a low-dimensional subspace of $mathbb{F}_2^n$. In both cases we also prove lower bounds showing that any testing algorithm—even an adaptive one—must have query complexity within a polynomial factor of our algorithms, which are nonadaptive. Building on these results, we give an “implicit learning” algorithm that lets us test any subproperty of Fourier concision. We also present some applications of these results to exact learning and decoding. Our technical contributions include new structural results about sparse Boolean functions and new analysis of the pairwise independent hashing of Fourier coefficients from [V. Feldman, P. Gopalan, S. Khot, and A. Ponnuswami, Proceedings of the 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS), 2006, pp. 563-576].},
journal = {SIAM J. Comput.},
month = jul,
pages = {1075–1100},
numpages = {26},
keywords = {discrete Fourier analysis, Fourier spectrum, local testability, property testing}
}

@article{10.1137/090779346,
author = {Feige, Uriel and Mirrokni, Vahab S. and Vondr\'{a}k, Jan},
title = {Maximizing Non-Monotone Submodular Functions},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/090779346},
doi = {10.1137/090779346},
abstract = {Submodular maximization generalizes many important problems including Max Cut in directed and undirected graphs and hypergraphs, certain constraint satisfaction problems, and maximum facility location problems. Unlike the problem of minimizing submodular functions, the problem of maximizing submodular functions is NP-hard. In this paper, we design the first constant-factor approximation algorithms for maximizing nonnegative (non-monotone) submodular functions. In particular, we give a deterministic local-search $frac{1}{3}$-approximation and a randomized $frac{2}{5}$-approximation algorithm for maximizing nonnegative submodular functions. We also show that a uniformly random set gives a $frac{1}{4}$-approximation. For symmetric submodular functions, we show that a random set gives a $frac{1}{2}$-approximation, which can also be achieved by deterministic local search. These algorithms work in the value oracle model, where the submodular function is accessible through a black box returning $f(S)$ for a given set $S$. We show that in this model, a $(frac{1}{2}+epsilon)$-approximation for symmetric submodular functions would require an exponential number of queries for any fixed $epsilon&gt;0$. In the model where $f$ is given explicitly (as a sum of nonnegative submodular functions, each depending only on a constant number of elements), we prove NP-hardness of $(frac{5}{6}+epsilon)$-approximation in the symmetric case and NP-hardness of $(frac{3}{4}+epsilon)$-approximation in the general case.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1133–1153},
numpages = {21},
keywords = {combinatorial optimization, information-theoretic lower bounds, local search algorithms, submodular function maximization, approximation algorithms, submodular functions}
}

@article{10.1137/090765092,
author = {Sharir, Micha and Shaul, Hayim},
title = {Semialgebraic Range Reporting and Emptiness Searching with Applications},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/090765092},
doi = {10.1137/090765092},
abstract = {In a typical range-emptiness searching (resp., reporting) problem, we are given a set $P$ of $n$ points in $mathbb{R}^d$, and we wish to preprocess it into a data structure that supports efficient range-emptiness (resp., reporting) queries, in which we specify a range $sigma$, which, in general, is a semialgebraic set in $mathbb{R}^d$ of constant description complexity, and we wish to determine whether $Pcapsigma=emptyset$, or to report all the points in $Pcapsigma$. Range-emptiness searching and reporting arise in many applications and have been treated by Matou\v{s}ek [Comput. Geom. Theory Appl., 2 (1992), pp. 169-186] in the special case where the ranges are half-spaces bounded by hyperplanes. As shown in Matou\v{s}ek's work, the two problems are closely related, and they have solutions (for the case of half-spaces) with similar performance bounds. In this paper we extend the analysis to general semialgebraic ranges and show how to adapt Matou\v{s}ek's technique without the need to linearize the ranges into a higher-dimensional space. This yields more efficient solutions to several useful problems, and we demonstrate the new technique in four applications with the following results: (i) An algorithm for ray shooting amid balls in $mathbb{R}^3$, which uses $O(n)$ storage and $O^*(n)$ preprocessing (we use the notation $O^*(n^gamma)$ to mean an upper bound of the form $C(varepsilon)n^{gamma+varepsilon}$, which holds for any $varepsilon&gt;0$, where $C(varepsilon)$ is a constant that depends on $varepsilon$) and answers a query in $O^*(n^{2/3})$ time, improving the previous bound of $O^*(n^{3/4})$. (ii) An algorithm that preprocesses, in $O^*(n)$ time, a set $P$ of $n$ points in $mathbb{R}^3$ into a data structure with $O(n)$ storage, so that, for any query line $ell$ (or, for that matter, any simply shaped convex set), the point of $P$ farthest from $ell$ can be computed in $O^*(n^{1/2})$ time. This in turn yields an algorithm that computes the largest-area triangle spanned by $P$ in time $O^*(n^{26/11})$, as well as nontrivial algorithms for computing the largest-perimeter or largest-height triangle spanned by $P$. (iii) An algorithm that preprocesses, in $O^*(n)$ time, a set $P$ of $n$ points in $mathbb{R}^2$ into a data structure with $O(n)$ storage, so that, for any query $alpha$-fat triangle $Delta$, we can determine, in $O^*(1)$ time, whether $Deltacap P$ is empty. Alternatively, we can report, in $O^*(1)+O(k)$ time, the points of $Deltacap P$, where $k=|Deltacap P|$. (iv) An algorithm that preprocesses, in $O^*(n)$ time, a set $P$ of $n$ points in $mathbb{R}^2$ into a data structure with $O(n)$ storage, so that, given any query semidisk $c$, or a circular cap larger than a semidisk, we can determine, in $O^*(1)$ time, whether $ccap P$ is empty, or report the $k$ points in $ccap P$ in $O^*(1)+O(k)$ time. Adapting the recent techniques of [B. Aronov and S. Har-Peled, SIAM J. Comput., 38 (2008), pp. 899-921, B. Aronov, S. Har-Peled, and M. Sharir, On approximate halfspace range counting and relative epsilon-approximations, in Proceedings of the 23rd ACM Symposium Comput. Geom., 2007, pp. 327-336, B. Aronov and M. Sharir, SIAM J. Comput., 39 (2010), pp. 2704-2725], we can turn our solutions into efficient algorithms for approximate range counting (with small relative error) for the cases mentioned above. Our technique is closely related to the notions of nearest- or farthest-neighbor generalized Voronoi diagrams and of the union or intersection of geometric objects, where sharper bounds on the combinatorial complexity of (decompositions of complements of) these structures yield faster range-emptiness searching or reporting algorithms.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1045–1074},
numpages = {30},
keywords = {range emptiness, elementary cell partition, range searching, semialgebraic sets, random sampling, epsilon nets, range reporting, ray shooting}
}

@article{10.1137/090746495,
author = {Chan, Yuk Hei and Fung, Wai Shing and Lau, Lap Chi and Yung, Chun Kong},
title = {Degree Bounded Network Design with Metric Costs},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/090746495},
doi = {10.1137/090746495},
abstract = {Given a complete undirected graph, a cost function on edges, and a degree bound $B$, the degree bounded network design problem is to find a minimum cost simple subgraph with maximum degree $B$ satisfying given connectivity requirements. Even for a simple connectivity requirement such as finding a spanning tree, computing a feasible solution for the degree bounded network design problem is already NP-hard, and thus there is no polynomial factor approximation algorithm for this problem. In this paper, we show that when the cost function satisfies the triangle inequality, there are constant factor approximation algorithms for various degree bounded network design problems. In global edge-connectivity, there is a $(2+frac{1}{k})$-approximation algorithm for the minimum bounded degree $k$-edge-connected subgraph problem. In local edge-connectivity, there is a 4-approximation algorithm for the minimum bounded degree Steiner network problem when $r_{max}$ is even, and a 5.5-approximation algorithm when $r_{max}$ is odd, where $r_{max}$ is the maximum connectivity requirement. In global vertex-connectivity, there is a $(2+frac{k-1}{n}+frac{1}{k})$-approximation algorithm for the minimum bounded degree $k$-vertex-connected subgraph problem when $ngeq2k$, where $n$ is the number of vertices. For spanning tree, there is a $(1+frac{1}{B-1})$-approximation algorithm for the minimum bounded degree spanning tree problem. These approximation algorithms return solutions with the smallest possible maximum degree, and in most cases the cost guarantee is obtained by comparing to the optimal cost when there are no degree constraints. This demonstrates that degree constraints can be incorporated into network design problems with metric costs. Our algorithms can be seen as a generalization of Christofides' algorithm for the metric traveling salesman problem. The main technical tool is a simplicity-preserving edge splitting-off operation, which is used to “short-cut” vertices with high degree while maintaining connectivity requirements and preserving simplicity of the solutions.},
journal = {SIAM J. Comput.},
month = jul,
pages = {953–980},
numpages = {28},
keywords = {network design, edge splitting-off, graph connectivity}
}

@article{10.1137/08074489X,
author = {Spielman, Daniel A. and Teng, Shang-Hua},
title = {Spectral Sparsification of Graphs},
year = {2011},
issue_date = {July 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/08074489X},
doi = {10.1137/08074489X},
abstract = {We introduce a new notion of graph sparsification based on spectral similarity of graph Laplacians: spectral sparsification requires that the Laplacian quadratic form of the sparsifier approximate that of the original. This is equivalent to saying that the Laplacian of the sparsifier is a good preconditioner for the Laplacian of the original. We prove that every graph has a spectral sparsifier of nearly linear size. Moreover, we present an algorithm that produces spectral sparsifiers in time $O(mlog^{c}m)$, where $m$ is the number of edges in the original graph and $c$ is some absolute constant. This construction is a key component of a nearly linear time algorithm for solving linear equations in diagonally dominant matrices. Our sparsification algorithm makes use of a nearly linear time algorithm for graph partitioning that satisfies a strong guarantee: if the partition it outputs is very unbalanced, then the larger part is contained in a subgraph of high conductance.},
journal = {SIAM J. Comput.},
month = jul,
pages = {981–1025},
numpages = {45},
keywords = {graph partitioning, sparsification, graph Laplacian}
}

@article{10.1137/SMJCAT000040000003000770000001,
author = {Aaronson, Scott and Erickson, Jeff and Mahdian, Mohammad and Ravi, R. and Viola, Emanuele},
title = {Special Section on Foundations of Computer Science},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000040000003000770000001},
doi = {10.1137/SMJCAT000040000003000770000001},
abstract = {This special section comprises eight fully refereed papers whose extended abstracts were presented at the 49th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2008) in Philadelphia, Pennsylvania, October 26-28, 2008. The unrefereed conference versions of these papers were published by IEEE in the FOCS 2008 proceedings. The regular conference program consisted of 79 papers chosen from among 276 submissions. These were selected by a program committee consisting of Scott Aaronson, Yossi Azar, Avrim Blum, Harry Buhrman, Artur Czumaj, Yevgeniy Dodis, David Eppstein, Jeff Erickson, Naveen Garg, Tom Hayes, Sampath Kannan, Jonathan Katz, Valerie King, Mohammad Mahdian, Yury Makarychev, Yishay Mansour, Rafail Ostrovsky, Toniann Pitassi, Harald Raecke, R. Ravi (chair), Madhu Sudan, and Emanuele Viola. The papers invited to this special section were also selected with the input of the program committee. The eight papers in this section span a broad range of topics, including algorithmic game theory, computational complexity, hardness of approximation, learning theory, pseudorandomness, and quantum algorithms. Each paper underwent an extensive refereeing process; we thank both the authors and the anonymous referees for their efforts. In addition, we would like to thank Eva Tardos, who was SICOMP's editor-in-chief as this project began, and SIAM staff member Cherie Trebisky for their help in preparing this special section.},
journal = {SIAM J. Comput.},
month = jun,
pages = {770},
numpages = {1}
}

@article{10.1137/100802980,
author = {Kale, Satyen and Seshadhri, C.},
title = {An Expansion Tester for Bounded Degree Graphs},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/100802980},
doi = {10.1137/100802980},
abstract = {We consider the problem of testing graph expansion (either vertex or edge) in the bounded degree model [O. Goldreich and D. Ron, On Testing Expansion in Bounded-Degree Graphs, Technical report TR00-020, ECCC, Potsdam, Germany, 2000]. We give a property tester that takes as input a graph with degree bound $d$, an expansion bound $alpha$, and a parameter $varepsilon&gt;0$. The tester accepts the graph with high probability if its expansion is more than $alpha$, and rejects it with high probability if it is $varepsilon$-far from any graph with expansion $alpha'$ with degree bound $d$, where $alpha'<alpha$ is="" a="" function="" of="" $alpha$.="" for="" edge="" expansion,="" we="" obtain="" $alpha'="Omega(frac{alpha^2}{d})$," and="" vertex="" in="" either="" case,="" the="" algorithm="" runs="" time="" $widetilde{o}(frac{n^{(1+mu)="" 2}d^2}{varepsilonalpha^2})$="" any="" fixed="" $mu="">0$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {709–720},
numpages = {12},
keywords = {graph expansion, sublinear algorithms, random walks}
}</alpha$>

@article{10.1137/100790082,
author = {Bodirsky, Manuel and Fusy, \'{E}ric and Kang, Mihyun and Vigerske, Stefan},
title = {Boltzmann Samplers, P\'{o}Lya Theory, and Cycle Pointing},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/100790082},
doi = {10.1137/100790082},
abstract = {We introduce a general method to count unlabeled combinatorial structures and to efficiently generate them at random. The approach is based on pointing unlabeled structures in an “unbiased” way so that a structure of size $n$ gives rise to $n$ pointed structures. We extend P\'{o}lya theory to the corresponding pointing operator and present a random sampling framework based on both the principles of Boltzmann sampling and P\'{o}lya operators. All previously known unlabeled construction principles for Boltzmann samplers are special cases of our new results. Our method is illustrated in several examples: in each case, we provide enumerative results and efficient random samplers. The approach applies to unlabeled families of plane and nonplane unrooted trees, and tree-like structures in general, but also to families of graphs (such as cacti graphs and outerplanar graphs) and families of planar maps.},
journal = {SIAM J. Comput.},
month = jun,
pages = {721–769},
numpages = {49},
keywords = {random generation, maps, P\'{o}lya theory, unlabeled enumeration, graphs, Boltzmann, trees}
}

@article{10.1137/09076787X,
author = {Ta-Shma, Amnon},
title = {Short Seed Extractors against Quantum Storage},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/09076787X},
doi = {10.1137/09076787X},
abstract = {In this paper we show that a construction of Trevisan, solving the privacy amplification problem in the classical setting, also solves the problem when the adversary may keep quantum storage, thereby giving the first such construction with logarithmic seed length. The technique we use is a combination of Trevisan's approach of constructing an extractor from a black-box pseudorandom generator, together with locally list-decodable codes and previous work done on quantum random access codes.},
journal = {SIAM J. Comput.},
month = jun,
pages = {664–677},
numpages = {14},
keywords = {quantum storage, list-decodable code, random access codes, extractors}
}

@article{10.1137/090762932,
author = {Niyogi, P. and Smale, S. and Weinberger, S.},
title = {A Topological View of Unsupervised Learning from Noisy Data},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090762932},
doi = {10.1137/090762932},
abstract = {In this paper, we take a topological view of unsupervised learning. From this point of view, clustering may be interpreted as trying to find the number of connected components of any underlying geometrically structured probability distribution in a certain sense that we will make precise. We construct a geometrically structured probability distribution that seems appropriate for modeling data in very high dimensions. A special case of our construction is the mixture of Gaussians where there is Gaussian noise concentrated around a finite set of points (the means). More generally we consider Gaussian noise concentrated around a low dimensional manifold and discuss how to recover the homology of this underlying geometric core from data that do not lie on it. We show that if the variance of the Gaussian noise is small in a certain sense, then the homology can be learned with high confidence by an algorithm that has a weak (linear) dependence on the ambient dimension. Our algorithm has a natural interpretation as a spectral learning algorithm using a combinatorial Laplacian of a suitable data-derived simplicial complex.},
journal = {SIAM J. Comput.},
month = jun,
pages = {646–663},
numpages = {18},
keywords = {topology, manifolds, data}
}

@article{10.1137/090756740,
author = {Friedgut, Ehud and Kalai, Gil and Keller, Nathan and Nisan, Noam},
title = {A Quantitative Version of the Gibbard-Satterthwaite Theorem for Three Alternatives},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090756740},
doi = {10.1137/090756740},
abstract = {The Gibbard-Satterthwaite theorem states that every nondictatorial election rule among at least three alternatives can be strategically manipulated. We prove a quantitative version of the Gibbard-Satterthwaite theorem: a random manipulation by a single random voter will succeed with a nonnegligible probability for any election rule among three alternatives that is far from being a dictatorship and from having only two alternatives in its range.},
journal = {SIAM J. Comput.},
month = jun,
pages = {934–952},
numpages = {19},
keywords = {Gibbard-Satterthwaite theorem, algorithmic game theory, Arrow theorem}
}

@article{10.1137/090756144,
author = {Guruswami, Venkatesan and H\r{A}stad, Johan and Manokaran, Rajsekar and Raghavendra, Prasad and Charikar, Moses},
title = {Beating the Random Ordering Is Hard: Every Ordering CSP Is Approximation Resistant},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090756144},
doi = {10.1137/090756144},
abstract = {We prove that, assuming the Unique Games conjecture (UGC), every problem in the class of ordering constraint satisfaction problems (OCSPs) where each constraint has constant arity is approximation resistant. In other words, we show that if $rho$ is the expected fraction of constraints satisfied by a random ordering, then obtaining a $rho'$ approximation for any $rho'&gt;rho$ is UG-hard. For the simplest OCSP, the Maximum Acyclic Subgraph (MAS) problem, this implies that obtaining a $rho$-approximation for any constant $rho&gt;1/2$ is UG-hard. Specifically, for every constant $varepsilon&gt;0$ the following holds: given a directed graph $G$ that has an acyclic subgraph consisting of a fraction $(1-varepsilon)$ of its edges, it is UG-hard to find one with more than $(1/2+varepsilon)$ of its edges. Note that it is trivial to find an acyclic subgraph with $1/2$ the edges by taking either the forward or backward edges in an arbitrary ordering of the vertices of $G$. The MAS problem has been well studied, and beating the random ordering for MAS has been a basic open problem. An OCSP of arity $k$ is specified by a subset $Pisubseteq S_k$ of permutations on ${1,2,dots,k}$. An instance of such an OCSP is a set $V$ and a collection of constraints, each of which is an ordered $k$-tuple of $V$. The objective is to find a global linear ordering of $V$ while maximizing the number of constraints ordered as in $Pi$. A random ordering of $V$ is expected to satisfy a $rho=frac{|Pi|}{k!}$ fraction. We show that, for any fixed $k$, it is hard to obtain a $rho'$-approximation for $Pi$-OCSP for any $rho'&gt;rho$. The result is in fact stronger: we show that for every $LambdasubseteqPisubseteq S_k$, and an arbitrarily small $varepsilon$, it is hard to distinguish instances where a $(1-varepsilon)$ fraction of the constraints can be ordered according to $Lambda$ from instances where at most a $(rho+varepsilon)$ fraction can be ordered as in $Pi$. A special case of our result is that the Betweenness problem is hard to approximate beyond a factor $1/3$. The results naturally generalize to OCSPs which assign a payoff to the different permutations. Finally, our results imply (unconditionally) that a simple semidefinite relaxation for MAS does not suffice to obtain a better approximation.},
journal = {SIAM J. Comput.},
month = jun,
pages = {878–914},
numpages = {37},
keywords = {Unique Games conjecture, feedback arc set, Maximum Acyclic Subgraph, hardness of approximation, integrality gaps}
}

@article{10.1137/090756090,
author = {Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
title = {What Can We Learn Privately?},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090756090},
doi = {10.1137/090756090},
abstract = {Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets. We ask, What concept classes can be learned privately, namely, by an algorithm whose output does not depend too heavily on any one input or specific training example? More precisely, we investigate learning algorithms that satisfy differential privacy, a notion that provides strong confidentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals. Our goal is a broad understanding of the resources required for private learning in terms of samples, computation time, and interaction. We demonstrate that, ignoring computational constraints, it is possible to privately agnostically learn any concept class using a sample size approximately logarithmic in the cardinality of the concept class. Therefore, almost anything learnable is learnable privately: specifically, if a concept class is learnable by a (nonprivate) algorithm with polynomial sample complexity and output size, then it can be learned privately using a polynomial number of samples. We also present a computationally efficient private probabilistically approximately correct learner for the class of parity functions. This result dispels the similarity between learning with noise and private learning (both must be robust to small changes in inputs), since parity is thought to be very hard to learn given random classification noise. Local (or randomized response) algorithms are a practical class of private algorithms that have received extensive investigation. We provide a precise characterization of local private learning algorithms. We show that a concept class is learnable by a local algorithm if and only if it is learnable in the statistical query (SQ) model. Therefore, for local private learning algorithms, the similarity to learning with noise is stronger: local learning is equivalent to SQ learning, and SQ algorithms include most known noise-tolerant learning algorithms. Finally, we present a separation between the power of interactive and noninteractive local learning algorithms. Because of the equivalence to SQ learning, this result also separates adaptive and nonadaptive SQ learning.},
journal = {SIAM J. Comput.},
month = jun,
pages = {793–826},
numpages = {34},
keywords = {statistical query learning, probabilistically approximately correct learning, differential privacy, data privacy}
}

@article{10.1137/09075336X,
author = {Paˇtra\c{s}cu, Mihai},
title = {Unifying the Landscape of Cell-Probe Lower Bounds},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/09075336X},
doi = {10.1137/09075336X},
abstract = {We show that a large fraction of the data-structure lower bounds known today in fact follow by reduction from the communication complexity of lopsided (asymmetric) set disjointness. This includes lower bounds for (i) high-dimensional problems, where the goal is to show large space lower bounds; (ii) constant-dimensional geometric problems, where the goal is to bound the query time for space $O(ncdotmathrm{polylog}n)$; and (iii) dynamic problems, where we are looking for a trade-off between query and update time. (In the last case, our bounds are slightly weaker than the originals, losing a $lglg n$ factor.) Our reductions also imply the following new results: (i) an $Omega(lg n/lglg n)$ bound for four-dimensional range reporting, given space $O(ncdotmathrm{polylog}n)$ (this is quite timely, since a recent result [Y. Nekrich, in Proceedings of the 23rd ACM Symposium on Computational Geometry (SoCG), 2007, pp. 344-353] solved three-dimensional reporting in $O(lg^2lg n)$ time, raising the prospect that higher dimensions could also be easy); (ii) a tight space lower bound for the partial match problem, for constant query time; and (iii) the first lower bound for reachability oracles. In the process, we prove optimal randomized lower bounds for lopsided set disjointness.},
journal = {SIAM J. Comput.},
month = jun,
pages = {827–847},
numpages = {21},
keywords = {range queries, data structures, lower bounds, cell-probe complexity}
}

@article{10.1137/090752699,
author = {Anshelevich, Elliot and Karagiozova, Adriana},
title = {Terminal Backup, 3D Matching, and Covering Cubic Graphs},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090752699},
doi = {10.1137/090752699},
abstract = {We define a problem called Simplex Matching and show that it is solvable in polynomial time. While Simplex Matching is interesting in its own right as a nontrivial extension of nonbipartite min-cost matching, its main value lies in many (seemingly very different) problems that can be solved using our algorithm. For example, suppose that we are given a graph with terminal nodes, nonterminal nodes, and edge costs. Then, the Terminal Backup problem, which consists of finding the cheapest forest connecting every terminal to at least one other terminal, is reducible to Simplex Matching. Simplex Matching is also useful for various tasks that involve forming groups of at least two members, such as project assignment and variants of facility location. In an instance of Simplex Matching, we are given a hypergraph $H$ with edge costs and edge size at most 3. We show how to find the min-cost perfect matching of $H$ efficiently if the edge costs obey a simple and realistic inequality that we call the Simplex Condition. The algorithm we provide is relatively simple to understand and implement but difficult to prove correct. In the process of this proof we show some powerful new results about covering cubic graphs with simple combinatorial objects.},
journal = {SIAM J. Comput.},
month = jun,
pages = {678–708},
numpages = {31},
keywords = {Simplex Matching, network design, graph packing, cycle cover}
}

@article{10.1137/090751293,
author = {Kempe, Julia and Kobayashi, Hirotada and Matsumoto, Keiji and Toner, Ben and Vidick, Thomas},
title = {Entangled Games Are Hard to Approximate},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090751293},
doi = {10.1137/090751293},
abstract = {We establish the first hardness results for the problem of computing the value of one-round games played by a verifier and a team of provers who can share quantum entanglement. In particular, we show that it is NP-hard to approximate within an inverse polynomial the value of a one-round game with (i) a quantum verifier and two entangled provers or (ii) a classical verifier and three entangled provers. Previously it was not even known if computing the value exactly is NP-hard. We also describe a mathematical conjecture, which, if true, would imply hardness of approximation of entangled-prover games to within a constant. Using our techniques we also show that every language in PSPACE has a two-prover one-round interactive proof system with perfect completeness and soundness $1-1/,mathrm{poly}$ even against entangled provers. We start our proof by describing two ways to modify classical multiprover games to make them resistant to entangled provers. We then show that a strategy for the modified game that uses entanglement can be “rounded” to one that does not. The results then follow from classical inapproximability bounds. Our work implies that, unless $mathrm{P}=mathrm{NP}$, the values of entangled-prover games cannot be computed by semidefinite programs that are polynomial in the size of the verifier's system, a method that has been successful for more restricted quantum games.},
journal = {SIAM J. Comput.},
month = jun,
pages = {848–877},
numpages = {30},
keywords = {almost-commuting matrices, entanglement, interactive proofs, quantum computing}
}

@article{10.1137/090748731,
author = {Dvir, Zeev and Wigderson, Avi},
title = {Kakeya Sets, New Mergers, and Old Extractors},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090748731},
doi = {10.1137/090748731},
abstract = {A merger is a probabilistic procedure which extracts the randomness out of any (arbitrarily correlated) set of random variables, as long as one of them is uniform. Our main result is an efficient, simple, and optimal (to constant factors) merger, which, for $k$ random variables on $n$ bits each, uses an $O(log(nk))$ seed, and whose error is $1/nk$. Our merger can be viewed as a derandomized version of the merger of Lu et al. [Extractors: Optimal up to constant factors, in Proceedings of the 35th Annual ACM Symposium on Theory of Computing, ACM, New York, 2003, pp. 602-611]. Its analysis generalizes the recent resolution of the Kakeya problem in finite fields of Dvir [J. Amer. Math. Soc., 22 (2009), pp. 1093-1097]. Following the plan set forth by Ta-Shma [Refining Randomness, Ph.D. thesis, The Hebrew University, Jerusalem, Israel, 1996] who defined mergers as part of this plan, our merger provides the last “missing link” to a simple and modular construction of extractors for all entropies, which is optimal to constant factors in all parameters. This complements the elegant construction of such extractors given by Guruswami, Umans, and Vadhan [Unbalanced expanders and randomness extractors from Parvaresh-Vardy codes, in CCC '07: Proceedings of the Twenty-Second Annual IEEE Conference on Computaional Complexity, IEEE Computer Society, Washington, DC, 2007, pp. 96-108]. We also give simple extensions of our merger in two directions. First, we generalize it to handle the case where no source is uniform—in that case the merger will extract the entropy present in the most random of the given sources. Second, we observe that the merger works just as well in the computational setting, when the sources are efficiently samplable, and computational notions of entropy replace the information theoretic ones.},
journal = {SIAM J. Comput.},
month = jun,
pages = {778–792},
numpages = {15},
keywords = {extractors, Kakeya, derandomization}
}

@article{10.1137/090747270,
author = {Raz, Ran},
title = {A Counterexample to Strong Parallel Repetition},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/090747270},
doi = {10.1137/090747270},
abstract = {The parallel repetition theorem states that, for any two-prover game with value $1-epsilon$ (for, say, $epsilonleq1/2$), the value of the game repeated in parallel $n$ times is at most $(1-epsilon^c)^{Omega(n/s)}$, where $s$ is the answer's length (of the original game) and $c$ is a universal constant [R. Raz, SIAM J. Comput., 27 (1998), pp. 763-803]. Several researchers asked whether this bound could be improved to $(1-epsilon)^{Omega(n/s)}$; this question is usually referred to as the strong parallel repetition problem. We show that the answer to this question is negative. More precisely, we consider the odd cycle game of size $m$, a two-prover game with value $1-1/2m$. We show that the value of the odd cycle game repeated in parallel $n$ times is at least $1-(1/m)cdot O(sqrt{n})$. This implies that, for large enough $n$ (say, $ngeqOmega(m^2)$), the value of the odd cycle game repeated in parallel $n$ times is at least $(1-1/4m^2)^{O(n)}$. Thus the following hold. 1. For parallel repetition of general games, the bounds of $(1-epsilon^c)^{Omega(n/s)}$ given in [R. Raz, SIAM J. Comput., 27 (1998), pp. 763-803; T. Holenstein, in Proceedings of STOC 2002, ACM, New York, 2002, pp. 767-775] are of the right form, up to determining the exact value of the constant $cgeq2$. 2. For parallel repetition of XOR games, unique games, and projection games, the bounds of $(1-epsilon^2)^{Omega(n)}$ given in [U. Feige, G. Kindler, and R. O'Donnell, in Proceedings of CCC 2007, IEEE Computer Society, Washington, DC, 2007, pp. 179-192] (for XOR games) and in [A. Rao, in Proceedings of STOC 2008, ACM, New York, 2008, pp. 1-10] (for unique and projection games) are tight. 3. For parallel repetition of the odd cycle game, the bound of $1-(1/m)cdottilde{Omega}(sqrt{n})$ given in [U. Feige, G. Kindler, and R. O'Donnell, in Proceedings of CCC 2007, IEEE Computer Society, Washington, DC, 2007, pp. 179-192] is almost tight. A major motivation for the recent interest in the strong parallel repetition problem is that a strong parallel repetition theorem would have implied that the unique game conjecture is equivalent to the NP hardness of distinguishing between instances of Max-Cut that are at least $1-epsilon^2$ satisfiable from instances that are at most $1-(2/pi)cdotepsilon$ satisfiable. Our results suggest that this cannot be proved just by improving the known bounds on parallel repetition.},
journal = {SIAM J. Comput.},
month = jun,
pages = {771–777},
numpages = {7},
keywords = {parallel repetition theorem, two-prover games, odd cycle game}
}

@article{10.1137/080744992,
author = {Dhangwatnotai, Peerapong and Dobzinski, Shahar and Dughmi, Shaddin and Roughgarden, Tim},
title = {Truthful Approximation Schemes for Single-Parameter Agents},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/080744992},
doi = {10.1137/080744992},
abstract = {We present the first monotone randomized polynomial-time approximation scheme (PTAS) for minimizing the makespan of parallel related machines ($Q||C_{max}$), the paradigmatic problem in single-parameter algorithmic mechanism design. This result immediately gives a polynomial-time, truthful (in expectation) mechanism whose approximation guarantee attains the best-possible one for all polynomial-time algorithms (assuming $Pneq NP$). Our algorithmic techniques are flexible and also yield a monotone deterministic quasi-PTAS for $Q||C_{max}$ and a monotone randomized PTAS for max-min scheduling on related machines.},
journal = {SIAM J. Comput.},
month = jun,
pages = {915–933},
numpages = {19},
keywords = {scheduling, algorithm game theory, algorithmic mechanism design}
}

@article{10.1137/080740970,
author = {Chen, Ning and Ghosh, Arpita and Vassilvitskii, Sergei},
title = {Optimal Envy-Free Pricing with Metric Substitutability},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/080740970},
doi = {10.1137/080740970},
abstract = {We study the unit-demand envy-free pricing problem faced by a profit-maximizing seller with unlimited supply when there is metric substitutability among the items—consumer $i$'s value for item $j$ is $v_i-c_{i,j}$, and the substitution costs, ${c_{i,j}}$, form a metric. Our model is motivated by the observation that sellers often sell the same product at different prices in different locations, and rational consumers optimize the tradeoff between prices and substitution costs. While the general envy-free pricing problem is hard to approximate, we show that the problem of maximizing revenue with metric substitutability among items can be solved exactly in polynomial time. We do this by first showing that in any optimal price vector, the set of nodes that pay exactly their value uniquely determines which nodes buy an item and what price they pay, and therefore the revenue. We transform the problem of finding an optimal set of such nodes to an instance of weighted independent set on a perfect graph which can be solved in polynomial time by the strong perfect graph theorem, proving the result. We then analyze the computational tractability of various extensions to our model. We begin with relaxing the metric substitutability requirement and show that when the substitution costs do not form a metric, even if a $(1+epsilon)$-approximate triangle inequality holds, the problem becomes NP-hard. Thus the triangle inequality characterizes the threshold at which the problem goes from “tractable” to “hard.” We then relax assumptions on the supply and demand. We consider restricting supplies to a subset of locations, or the amount of supplies, or allowing buyers to demand more than one unit. In all cases, the problem becomes NP-hard. In addition, the multiunit demand case illustrates an interesting paradoxical nonmonotonicity: The optimal revenue the seller can extract can actually decrease when consumers' demands increase. We show the revenue maximization problem with multiunit demand is APX-hard even for the simplest valuations with equal marginal values for all items up to the demand constraint, and demands of at most 3.},
journal = {SIAM J. Comput.},
month = may,
pages = {623–645},
numpages = {23},
keywords = {strong perfect graph theorem, envy-free pricing, algorithm}
}

@article{10.1137/070697720,
author = {Daskalakis, Constantinos and Karp, Richard M. and Mossel, Elchanan and Riesenfeld, Samantha J. and Verbin, Elad},
title = {Sorting and Selection in Posets},
year = {2011},
issue_date = {May 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070697720},
doi = {10.1137/070697720},
abstract = {Classical problems of sorting and searching assume an underlying linear ordering of the objects being compared. In this paper, we study these problems in the context of partially ordered sets, in which some pairs of objects are incomparable. This generalization is interesting from a combinatorial perspective, and it has immediate applications in ranking scenarios where there is no underlying linear ordering, e.g., conference submissions. It also has applications in reconstructing certain types of networks, including biological networks. Our results represent significant progress over previous results from two decades ago by Faigle and Tur\'{a}n. In particular, we present the first algorithm that sorts a width-$w$ poset of size $n$ with query complexity $O(n(w+log n))$ and prove that this query complexity is asymptotically optimal. We also describe a variant of Mergesort with query complexity $O(wnlogfrac{n}{w})$ and total complexity $O(w^{2}nlogfrac{n}{w})$; an algorithm with the same query complexity was given by Faigle and Tur\'{a}n, but no efficient implementation of that algorithm is known. Both our sorting algorithms can be applied with negligible overhead to the more general problem of reconstructing transitive relations. We also consider two related problems: finding the minimal elements, and its generalization to finding the bottom $k$ “levels,” called the $k$-selection problem. We give efficient deterministic and randomized algorithms for finding the minimal elements with query complexity and total complexity $O(wn)$. We provide matching lower bounds for the query complexity up to a factor of 2 and generalize the results to the $k$-selection problem. Finally, we present efficient algorithms for computing a linear extension of a poset and computing the heights of all elements.},
journal = {SIAM J. Comput.},
month = may,
pages = {597–622},
numpages = {26},
keywords = {partially ordered sets, transitive relations, sorting, selection, chain decomposition, query complexity}
}

@article{10.1137/100789646,
author = {Goldreich, Oded and Ron, Dana},
title = {On Proximity-Oblivious Testing},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/100789646},
doi = {10.1137/100789646},
abstract = {We initiate a systematic study of a special type of property testers. These testers consist of repeating a basic test for a number of times that depends on the proximity parameter, whereas the basic test is oblivious of the proximity parameter. We refer to such basic tests by the term proximity-oblivious testers. While proximity-oblivious testers were studied before—most notably in the algebraic setting—the current study seems to be the first one to focus on graph properties. We provide a mix of positive and negative results, and in particular characterizations of the graph properties that have constant-query proximity-oblivious testers in the two standard models (i.e., the adjacency matrix and the bounded-degree models). Furthermore, we show that constant-query proximity-oblivious testers do not exist for many easily testable properties, and that even when proximity-oblivious testers exist, repeating them does not necessarily yield the best standard testers for the corresponding property.},
journal = {SIAM J. Comput.},
month = apr,
pages = {534–566},
numpages = {33},
keywords = {graph properties, property testing}
}

@article{10.1137/090779759,
author = {Fischer, Johannes and Heun, Volker},
title = {Space-Efficient Preprocessing Schemes for Range Minimum Queries on Static Arrays},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090779759},
doi = {10.1137/090779759},
abstract = {Given a static array of $n$ totally ordered objects, the range minimum query problem is to build a data structure that allows us to answer efficiently subsequent on-line queries of the form “what is the position of a minimum element in the subarray ranging from $i$ to $j$?”. We focus on two settings, where (1) the input array is available at query time, and (2) the input array is available only at construction time. In setting (1), we show new data structures (a) of size $\frac{2n}{c(n)}-\Theta\bigl(\frac{n\lg\lg n}{c(n)\lg n}\bigr)$ bits and query time $O(c(n))$ for any positive integer function $c(n)\in O\bigl(n^\varepsilon\bigr)$ for an arbitrary constant $0<\varepsilon<1$, or (b) with $O(nH_k)+o(n)$ bits and $O(1)$ query time, where $H_k$ denotes the empirical entropy of $k$th order of the input array. In setting (2), we give a data structure of size $2n+o(n)$ bits and query time $O(1)$. All data structures can be constructed in linear time and almost in-place.},
journal = {SIAM J. Comput.},
month = apr,
pages = {465–492},
numpages = {27},
keywords = {lowest common ancestors, trees, arrays, range queries}
}

@article{10.1137/090777669,
author = {Gim\'{e}nez, Omer and Godoy, Guillem and Maneth, Sebastian},
title = {Deciding Regularity of the Set of Instances of a Set of Terms with Regular Constraints is EXPTIME-Complete},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090777669},
doi = {10.1137/090777669},
abstract = {Finite-state tree automata are a well-studied formalism for representing term languages. This paper studies the problem of determining the regularity of the set of instances of a finite set of terms with variables, where each variable is restricted to instantiations of a regular set given by a tree automaton. The problem was recently proved decidable, but with an unknown complexity. Here, the exact complexity of the problem is determined by proving EXPTIME-completeness. The main contribution is a new, exponential time algorithm that performs various exponential transformations on the involved terms and tree automata and decides regularity by analyzing formulas over inequation and height predicates.},
journal = {SIAM J. Comput.},
month = apr,
pages = {446–464},
numpages = {19},
keywords = {terms with variables, EXPTIME complexity, regularity, regular constraints, pattern matching}
}

@article{10.1137/090766437,
author = {Ailon, Nir and Chazelle, Bernard and Clarkson, Kenneth L. and Liu, Ding and Mulzer, Wolfgang and Seshadhri, C.},
title = {Self-Improving Algorithms},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090766437},
doi = {10.1137/090766437},
abstract = {We investigate ways in which an algorithm can improve its expected performance by fine-tuning itself automatically with respect to an unknown input distribution $mathcal{D}$. We assume here that $mathcal{D}$ is of product type. More precisely, suppose that we need to process a sequence $I_1,I_2,ldots$ of inputs $I=(x_1,x_2,ldots,x_n)$ of some fixed length $n$, where each $x_i$ is drawn independently from some arbitrary, unknown distribution $mathcal{D}_i$. The goal is to design an algorithm for these inputs so that eventually the expected running time will be optimal for the input distribution $mathcal{D}=prod_imathcal{D}_i$. We give such self-improving algorithms for two problems: (i) sorting a sequence of numbers and (ii) computing the Delaunay triangulation of a planar point set. Both algorithms achieve optimal expected limiting complexity. The algorithms begin with a training phase during which they collect information about the input distribution, followed by a stationary regime in which the algorithms settle to their optimized incarnations.},
journal = {SIAM J. Comput.},
month = apr,
pages = {350–375},
numpages = {26},
keywords = {low entropy, Delaunay triangulation, sorting, average case analysis}
}

@article{10.1137/090751670,
author = {Chan, Timothy M. and Paˇtra\c{s}cu, Mihai and Roditty, Liam},
title = {Dynamic Connectivity: Connecting to Networks and Geometry},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090751670},
doi = {10.1137/090751670},
abstract = {Dynamic connectivity is a well-studied problem, but so far the most compelling progress has been confined to the edge-update model: maintain an understanding of connectivity in an undirected graph, subject to edge insertions and deletions. In this paper, we study two more challenging, yet equally fundamental, problems. Subgraph connectivity asks us to maintain an understanding of connectivity under vertex updates: updates can turn vertices on and off, and queries refer to the subgraph induced by on vertices. (For instance, this is closer to applications in networks of routers, where node faults may occur.) We describe a data structure supporting vertex updates in $widetilde{O}(m^{2/3})$ amortized time, where $m$ denotes the number of edges in the graph. This greatly improves upon the previous result [T. M. Chan, in Proceedings of the 34th Annual ACM Symposium on Theory of Computing (STOC), 2002, pp. 7-13], which required fast matrix multiplication and had an update time of $O(m^{0.94})$. The new data structure is also simpler. Geometric connectivity asks us to maintain a dynamic set of $n$ geometric objects and query connectivity in their intersection graph. (For instance, the intersection graph of balls describes connectivity in a network of sensors with bounded transmission radius.) Previously, nontrivial fully dynamic results were known only for special cases like axis-parallel line segments and rectangles. We provide similarly improved update times, $widetilde{O}(n^{2/3})$, for these special cases. Moreover, we show how to obtain sublinear update bounds for virtually all families of geometric objects which allow sublinear time range queries. In particular, we obtain the first sublinear update time for arbitrary two-dimensional line segments: $O^*(n^{9/10})$; for $d$-dimensional simplices: $O^*(n^{1-frac{1}{d(2d+1)}})$; and for $d$-dimensional balls: $O^*(n^{1-frac{1}{(d+1)(2d+3)}})$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {333–349},
numpages = {17},
keywords = {computational geometry, dynamic graph algorithms, data structures, connectivity}
}

@article{10.1137/090751062,
author = {Cachin, Christian and Keidar, Idit and Shraer, Alexander},
title = {Fail-Aware Untrusted Storage},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090751062},
doi = {10.1137/090751062},
abstract = {We consider a set of clients collaborating through an online service provider that is subject to attacks and hence not fully trusted by the clients. We introduce the abstraction of a fail-aware untrusted service, with meaningful semantics even when the provider is faulty. In the common case, when the provider is correct, such a service guarantees consistency (linearizability) and liveness (wait-freedom) of all operations. In addition, the service always provides accurate and complete consistency and failure detection. We illustrate our new abstraction by presenting a Fail-Aware Untrusted STorage service (FAUST). Existing storage protocols in this model guarantee so-called forking semantics. We observe, however, that none of the previously suggested protocols suffices for implementing fail-aware untrusted storage with the desired liveness and consistency properties (at least wait-freedom and linearizability when the server is correct). We present a new storage protocol, which does not suffer from this limitation, and implements a new consistency notion, called weak fork-linearizability. We show how to extend this protocol to provide eventual consistency and failure awareness in FAUST.},
journal = {SIAM J. Comput.},
month = apr,
pages = {493–533},
numpages = {41},
keywords = {forking semantics, hashing, cloud storage, consistency, integrity}
}

@article{10.1137/090749621,
author = {Goldreich, Oded and Ron, Dana},
title = {Algorithmic Aspects of Property Testing in the Dense Graphs Model},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090749621},
doi = {10.1137/090749621},
abstract = {In this paper we consider two basic questions regarding the query complexity of testing graph properties in the adjacency matrix model. The first question refers to the relation between adaptive and nonadaptive testers, whereas the second question refers to testability within complexity that is inversely proportional to the proximity parameter, denoted $epsilon$. The study of these questions reveals the importance of algorithmic design in this model. The highlights of our study are as follows: (a) A gap between the complexity of adaptive and nonadaptive testers. Specifically, there exists a natural graph property that can be tested using $widetilde{O}(epsilon^{-1})$ adaptive queries but cannot be tested using $o(epsilon^{-3/2})$ nonadaptive queries. (b) In contrast, there exist natural graph properties that can be tested using $widetilde{O}(epsilon^{-1})$ nonadaptive queries, whereas $Omega(epsilon^{-1})$ queries are required even in the adaptive case. We mention that the properties used in the foregoing conflicting results have a similar flavor, although they are of course different.},
journal = {SIAM J. Comput.},
month = apr,
pages = {376–445},
numpages = {70},
keywords = {property testing, adaptivity versus nonadaptivity, graph properties}
}

@article{10.1137/080729256,
author = {Amb\"{u}hl, Christoph and Mastrolilli, Monaldo and Svensson, Ola},
title = {Inapproximability Results for Maximum Edge Biclique, Minimum Linear Arrangement, and Sparsest Cut},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/080729256},
doi = {10.1137/080729256},
abstract = {We consider the Minimum Linear Arrangement problem and the (Uniform) Sparsest Cut problem. So far, these two notorious NP-hard graph problems have resisted all attempts to prove inapproximability results. We show that they have no polynomial time approximation scheme, unless NP-complete problems can be solved in randomized subexponential time. Furthermore, we show that the same techniques can be used for the Maximum Edge Biclique problem, for which we obtain a hardness factor similar to previous results but under a more standard assumption.},
journal = {SIAM J. Comput.},
month = apr,
pages = {567–596},
numpages = {30},
keywords = {hardness of approximation, graph theory}
}

@article{10.1137/100790537,
author = {Haitner, Iftach and Ishai, Yuval and Kushilevitz, Eyal and Lindell, Yehuda and Petrank, Erez},
title = {Black-Box Constructions of Protocols for Secure Computation},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/100790537},
doi = {10.1137/100790537},
abstract = {In this paper, we study the question of whether or not it is possible to construct protocols for general secure computation in the setting of malicious adversaries and no honest majority that use the underlying primitive (e.g., enhanced trapdoor permutation) in a black-box way only. Until now, all known general constructions for this setting were inherently non-black-box since they required the parties to prove zero-knowledge statements that are related to the computation of the underlying primitive. Our main technical result is a fully black-box reduction from oblivious transfer with security against malicious parties to oblivious transfer with security against semihonest parties. As a corollary, we obtain the first constructions of general multiparty protocols (with security against malicious adversaries and without an honest majority) which make only a black-box use of semihonest oblivious transfer, or alternatively a black-box use of lower-level primitives such as enhanced trapdoor permutations or homomorphic encryption. In order to construct this reduction we introduce a new notion of security called privacy in the presence of defensible adversaries. This notion states that if an adversary can produce (retroactively, after the protocol terminates) an input and random tape that make its actions appear to be honest, then it is guaranteed that it learned nothing more than its prescribed output. We then show how to construct defensible oblivious transfer from semihonest oblivious transfer, and malicious oblivious transfer from defensible oblivious transfer, all in a black-box way.},
journal = {SIAM J. Comput.},
month = mar,
pages = {225–266},
numpages = {42},
keywords = {black-box reductions, theory of cryptography, secure computation, oblivious transfer}
}

@article{10.1137/090771429,
author = {Archer, Aaron and Bateni, MohammadHossein and Hajiaghayi, MohammadTaghi and Karloff, Howard},
title = {Improved Approximation Algorithms for Prize-Collecting Steiner Tree and TSP},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090771429},
doi = {10.1137/090771429},
abstract = {We study the prize-collecting Steiner tree (PCST), prize-collecting traveling salesman (PCTSP), and prize-collecting path (PC-Path) problems. Given a graph $(V,E)$ with a cost on each edge and a penalty (a.k.a. prize) on each node, the goal is to find a tree (for PCST), cycle (for PCTSP), or path (for PC-Path) that minimizes the sum of the edge costs in the tree/cycle/path and the penalties of the nodes not spanned by it. In addition to being a useful theoretical tool for helping to solve other optimization problems, PCST has been applied fruitfully by AT&amp;T to the optimization of real-world telecommunications networks. The most recent improvements for the first two problems, a 2-approximation algorithm for each, appeared first in 1992; a 2-approximation for PC-Path appeared in 2003. The natural linear programming relaxation of PCST has an integrality gap of 2, which has been a barrier to further improvements for this problem. We present $(2-epsilon)$-approximation algorithms for all three problems, connected by a unified technique for improving prize-collecting algorithms that allows us to circumvent the integrality gap barrier. Specifically, our approximation ratio for prize-collecting Steiner tree is below 1.9672.},
journal = {SIAM J. Comput.},
month = mar,
pages = {309–332},
numpages = {24},
keywords = {prize-collecting, traveling salesman, Steiner tree, approximation algorithms}
}

@article{10.1137/090770928,
author = {Frieze, Alan and Melsted, P\'{a}ll and Mitzenmacher, Michael},
title = {An Analysis of Random-Walk Cuckoo Hashing},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/090770928},
doi = {10.1137/090770928},
abstract = {In this paper, we provide a polylogarithmic bound that holds with high probability on the insertion time for cuckoo hashing under the random-walk insertion method. Cuckoo hashing provides a useful methodology for building practical, high-performance hash tables. The essential idea of cuckoo hashing is to combine the power of schemes that allow multiple hash locations for an item with the power to dynamically change the location of an item among its possible locations. Previous work on the case where the number of choices is larger than two has analyzed breadth-first search, which is both inefficient in practice and currently has only a polynomial upper bound on the insertion time that holds with high probability. On the other hand, it does have expected constant amortized insertion time. Here we significantly advance the state of the art by proving a polylogarithmic bound that holds with high probability on the more efficient random-walk method, where items repeatedly kick out random blocking items until a free location for an item is found.},
journal = {SIAM J. Comput.},
month = mar,
pages = {291–308},
numpages = {18},
keywords = {random walk, cuckoo, hashing}
}

@article{10.1137/080732651,
author = {Ben-Aroya, Avraham and Ta-Shma, Amnon},
title = {A Combinatorial Construction of Almost-Ramanujan Graphs Using the Zig-Zag Product},
year = {2011},
issue_date = {March 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/080732651},
doi = {10.1137/080732651},
abstract = {Reingold, Vadhan, and Wigderson [Ann. of Math. (2), 155 (2002), pp. 157-187] introduced the graph zig-zag product. This product combines a large and a small graph into one, such that the resulting graph inherits its size from the large graph, its degree from the small graph, and its spectral gap from both. Using this product, they gave a fully explicit combinatorial construction of $D$-regular graphs having spectral gap $1-O(D^{-frac{1}{3}})$. In the same paper, they posed the open problem of whether a similar graph product could be used to achieve the almost optimal spectral gap $1-O(D^{-frac{1}{2}})$. In this paper we propose a generalization of the zig-zag product that combines a large graph and several small graphs. The new product gives a better relation between the degree and the spectral gap of the resulting graph. We use the new product to give a fully explicit combinatorial construction of $D$-regular graphs having spectral gap $1-D^{-frac{1}{2}+o(1)}$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {267–290},
numpages = {24},
keywords = {zig-zag product, expander graphs, combinatorial construction}
}

@article{10.1137/100783224,
author = {Ishai, Yuval and Katz, Jonathan and Kushilevitz, Eyal and Lindell, Yehuda and Petrank, Erez},
title = {On Achieving the “Best of Both Worlds” in Secure Multiparty Computation},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100783224},
doi = {10.1137/100783224},
abstract = {Two settings are traditionally considered for secure multiparty computation, depending on whether or not a majority of the parties are assumed to be honest. Existing protocols that assume an honest majority provide “full security” (and, in particular, guarantee output delivery and fairness) when this assumption holds, but are completely insecure if this assumption is violated. On the other hand, known protocols tolerating an arbitrary number of corruptions do not guarantee fairness or output delivery even if only a single party is dishonest. It is natural to wonder whether it is possible to achieve the “best of both worlds”: namely, a single protocol that simultaneously achieves the best possible security in both the above settings. Here, we rule out this possibility (at least for general functionalities) and show some positive results regarding what can be achieved.},
journal = {SIAM J. Comput.},
month = feb,
pages = {122–141},
numpages = {20},
keywords = {secure computation, theory of cryptography}
}

@article{10.1137/090772897,
author = {Urquhart, Alasdair},
title = {A Near-Optimal Separation of Regular and General Resolution},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090772897},
doi = {10.1137/090772897},
abstract = {This paper gives a near-optimal separation between regular and unrestricted resolution. The main result is that there is a sequence of sets of clauses $Pi_1,Pi_2,ldots,Pi_i,ldots$ for which the minimum regular resolution refutation of $Pi_i$ has size $2^{Omega(R_i/(log R_i)^7loglog R_i)}$, where $R_i$ is the minimum size of an unrestricted resolution refutation of $Pi_i$. This improves earlier lower bounds for which the separations proved were of the form $2^{Omega(sqrt[3]{R})}$ and $2^{Omega(sqrt[4]{R}/(log R)^3)}$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {107–121},
numpages = {15},
keywords = {resolution, lower bounds, proof complexity}
}

@article{10.1137/090770679,
author = {Saxena, Nitin and Seshadhri, C.},
title = {An Almost Optimal Rank Bound for Depth-3 Identities},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090770679},
doi = {10.1137/090770679},
abstract = {We study the problem of polynomial identity testing for depth-3 circuits of degree $d$ and top fanin $k$. The rank of any such identity is essentially the minimum number of independent variables present. Small bounds on this quantity imply fast deterministic identity testers for these circuits. Dvir and Shpilka [SIAM J. Comput., 36 (2007), pp. 1404-1434] initiated the study of the rank and showed that any depth-3 identity (barring some uninteresting corner cases) has a rank of $2^{O(k^2)}(log d)^{k-2}$. We show that the rank of a depth-3 identity is at most $O(k^3log d)$. This bound is almost tight, since we also provide an identity of rank $Omega(klog d)$. Our rank bound significantly improves (dependence on $k$ exponentially reduced) the best known deterministic black-box identity tests for depth-3 circuits by Karnin and Shpilka [Z. Karnin and A. Shpilka, in Proceedings of the 23rd CCC, 2008, pp. 280-291]. Our techniques also shed light on the factorization pattern of nonzero depth-3 circuits: the rank of linear factors of a simple, minimal, and nonzero depth-3 circuit (over any field) is at most $O(k^3log d)$. The novel feature of this work is a new notion of maps between sets of linear forms, called ideal matchings, used to study depth-3 circuits. We prove interesting structural results about depth-3 identities using these techniques. We believe that these ideas may lead to the goal of a deterministic polynomial time identity test for these circuits.},
journal = {SIAM J. Comput.},
month = feb,
pages = {200–224},
numpages = {25},
keywords = {polynomial identity testing, derandomization, depth-3 circuits}
}

@article{10.1137/090756466,
author = {O'Donnell, Ryan and Servedio, Rocco A.},
title = {The Chow Parameters Problem},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090756466},
doi = {10.1137/090756466},
abstract = {In [Proceedings of the Second Symposium on Switching Circuit Theory and Logical Design (FOCS), 1961, pp. 34-38], Chow proved that every Boolean threshold function is uniquely determined by its degree-0 and degree-1 Fourier coefficients. These numbers became known as the Chow parameters. Providing an algorithmic version of Chow's theorem—i.e., efficiently constructing a representation of a threshold function given its Chow parameters—has remained open ever since. This problem has received significant study in the fields of circuit complexity, game theory and the design of voting systems, and learning theory. In this paper we effectively solve the problem, giving a randomized polynomial-time approximation scheme with the following behavior: Given the Chow parameters of a Boolean threshold function $f$ over $n$ bits and any constant $epsilon&gt;0$, the algorithm runs in time $O(n^2log^2n)$ and with high probability outputs a representation of a threshold function $f'$ which is $epsilon$-close to $f$. Along the way we prove several new results of independent interest about Boolean threshold functions. In addition to various structural results, these include $tilde{O}(n^2)$-time learning algorithms for threshold functions under the uniform distribution in the following models: (i) the restricted focus of attention model, answering an open question of Birkendorf et al.; (ii) an agnostic-type model. This contrasts with recent results of Guruswami and Raghavendra who show NP-hardness for the problem under general distributions; (iii) the PAC model, with constant $epsilon$. Our $tilde{O}(n^2)$-time algorithm substantially improves on the previous best known running time and nearly matches the $Omega(n^2)$ bits of training data that any successful learning algorithm must use.},
journal = {SIAM J. Comput.},
month = feb,
pages = {165–199},
numpages = {35},
keywords = {learning theory, Chow parameters, threshold functions, approximation}
}

@article{10.1137/090753498,
author = {Ackermann, Heiner and Goldberg, Paul W. and Mirrokni, Vahab S. and R\"{o}glin, Heiko and V\"{o}cking, Berthold},
title = {Uncoordinated Two-Sided Matching Markets},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090753498},
doi = {10.1137/090753498},
abstract = {Various economic interactions can be modeled as two-sided markets. A central solution concept for these markets is stable matchings, introduced by Gale and Shapley. It is well known that stable matchings can be computed in polynomial time, but many real-life markets lack a central authority to match agents. In those markets, matchings are formed by actions of self-interested agents. Knuth introduced uncoordinated two-sided markets and showed that the uncoordinated better response dynamics may cycle. However, Roth and Vande Vate showed that the random better response dynamics converges to a stable matching with probability one, but they did not address the question of convergence time. In this paper, we give an exponential lower bound for the convergence time of the random better response dynamics in two-sided markets. We also extend the results for the better response dynamics to the best response dynamics; i.e., we present a cycle of best responses and prove that the random best response dynamics converges to a stable matching with probability one, but its convergence time is exponential. Additionally, we identify the special class of correlated matroid two-sided markets with real-life applications for which we prove that the random best response dynamics converges in expected polynomial time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {92–106},
numpages = {15},
keywords = {stable marriage problem, response dynamics, convergence, Nash equilibrium}
}

@article{10.1137/090745854,
author = {Magniez, Fr\'{e}d\'{e}ric and Nayak, Ashwin and Roland, J\'{e}r\'{e}mie and Santha, Miklos},
title = {Search via Quantum Walk},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090745854},
doi = {10.1137/090745854},
abstract = {We propose a new method for designing quantum search algorithms for finding a “marked” element in the state space of a classical Markov chain. The algorithm is based on a quantum walk \`{a} la Szegedy [Quantum speed-up of Markov chain based algorithms, in Proceedings of the 45th IEEE Symposium on Foundations of Computer Science, IEEE Computer Society Press, 2004, pp. 32-41] that is defined in terms of the Markov chain. The main new idea is to apply quantum phase estimation to the quantum walk in order to implement an approximate reflection operator. This operator is then used in an amplitude amplification scheme. As a result we considerably expand the scope of the previous approaches of Ambainis [Quantum walk algorithm for Element Distinctness, in Proceedings of the 45th IEEE Symposium on Foundations of Computer Science, IEEE Computer Society Press, 2004, pp. 22-31] and Szegedy (2004). Our algorithm combines the benefits of these approaches in terms of being able to find marked elements, incurring the smaller cost of the two, and being applicable to a larger class of Markov chains. In addition, it is conceptually simple and avoids some technical difficulties in the previous analyses of several algorithms based on quantum walk.},
journal = {SIAM J. Comput.},
month = feb,
pages = {142–164},
numpages = {23},
keywords = {search, amplitude amplification, hitting time, phase estimation, quantum walk, Markov chain}
}

@article{10.1137/100783534,
author = {Austrin, Per and H\r{A}stad, Johan},
title = {Randomly Supported Independence and Resistance},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/100783534},
doi = {10.1137/100783534},
abstract = {We prove that for any positive integers $q$ and $k$ there is a constant $c_{q,k}$ such that a uniformly random set of $c_{q,k}n^klog n$ vectors in $[q]^n$ with high probability supports a balanced $k$-wise independent distribution. In the case of $kleq2$ a more elaborate argument gives the stronger bound, $c_{q,k}n^k$. Using a recent result by Austrin and Mossel, this shows that a predicate on $t$ bits, chosen at random among predicates accepting $c_{q,2}t^2$ input vectors, is, assuming the unique games conjecture, likely to be approximation resistant. These results are close to tight: we show that there are other constants, $c_{q,k}'$, such that a randomly selected set of cardinality $c_{q,k}'n^k$ points is unlikely to support a balanced $k$-wise independent distribution and, for some $c&gt;0$, a random predicate accepting $ct^2/log t$ input vectors is nontrivially approximable with high probability. In a different application of the result of Austrin and Mossel we prove that, again assuming the unique games conjecture, any predicate on $t$ Boolean inputs accepting at least $(32/33)cdot2^t$ inputs is approximation resistant. The results extend from balanced distributions to arbitrary product distributions.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1–27},
numpages = {27},
keywords = {$k$-wise independence, constraint satisfaction, approximation resistance}
}

@article{10.1137/090766991,
author = {Hazan, Elad and Krauthgamer, Robert},
title = {How Hard Is It to Approximate the Best Nash Equilibrium?},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/090766991},
doi = {10.1137/090766991},
abstract = {The quest for a polynomial-time approximation scheme (PTAS) for Nash equilibrium in a two-player game, which emerged as a major open question in algorithmic game theory, seeks to circumvent the PPAD-completeness of finding an (exact) Nash equilibrium by finding an approximate equilibrium. The closely related problem of finding an equilibrium maximizing a certain objective, such as social welfare, was shown to be NP-hard [Gilboa and Zemel, Games Econom. Behav., 1 (1989), pp. 80-93]. However, this NP-hardness is unlikely to extend to approximate equilibria, since the latter admits a quasi-polynomial time algorithm [Lipton, Markakis, and Mehta, in Proceedings of the 4th ACM Conference on Electronic Commerce, ACM, New York, 2003, pp. 36-41]. We show that this optimization problem, namely, finding in a two-player game an approximate equilibrium achieving a large social welfare, is unlikely to have a polynomial-time algorithm. One interpretation of our results is that a PTAS for Nash equilibrium (if it exists) should not extend to a PTAS for finding the best Nash equilibrium. Technically, our result is a reduction from the notoriously difficult problem in modern combinatorics, of finding a planted (but hidden) clique in a random graph $G(n,1/2)$. Our reduction starts from an instance with planted clique size $O(log n)$. For comparison, the currently known algorithms are effective only for a much larger clique size $Omega(sqrt{n})$.},
journal = {SIAM J. Comput.},
month = jan,
pages = {79–91},
numpages = {13},
keywords = {hidden clique, game theory, Nash equilibrium, logarithmically-restricted NP}
}

@article{10.1137/07071158X,
author = {Shao, Cheng and Welch, Jennifer L. and Pierce, Evelyn and Lee, Hyunyoung},
title = {Multiwriter Consistency Conditions for Shared Memory Registers},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/07071158X},
doi = {10.1137/07071158X},
abstract = {Regularity is a shared memory consistency condition that has received considerable attention. Lamport's original definition of regularity assumed a single-writer model, however, and is not well defined when the shared register may have multiple writers. In this paper, we consider four possible definitions of multiwriter regularity. The definitions are motivated by variations on a quorum-based algorithm schema for implementing them. We study the relationships between these definitions and a number of other well-known consistency conditions, and we give a partial order describing the relative strengths of these consistency conditions. Finally, we provide a practical context for our results by studying the correctness of two well-known algorithms for mutual exclusion under each of our proposed consistency conditions.},
journal = {SIAM J. Comput.},
month = jan,
pages = {28–62},
numpages = {35},
keywords = {shared memory consistency, mutual exclusion, multiwriter registers, regularity, quorum systems}
}

@article{10.1137/050640746,
author = {Gafni, Eli and Guerraoui, Rachid and Pochon, Bastian},
title = {The Complexity of Early Deciding Set Agreement},
year = {2011},
issue_date = {February 2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {40},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050640746},
doi = {10.1137/050640746},
abstract = {In the $k$-set agreement problem, each processor starts with a private input value and eventually decides on an output value. At most $k$ distinct output values may be chosen, and every processor's output value must be one of the proposed values. We consider a synchronous message passing system, and we prove a tight bound of $lfloor f/krfloor+2$ rounds of communication for all processors to decide in every run in which at most $f$ processors fail. The lower bound proof proceeds through a simulation of a synchronous solution to $k$-set agreement in message passing, in an asynchronous shared memory system in which $k-1$ processors may fail, and which was proven to be impossible using topological approaches. In contrast to past complexity results on set agreement, our lower bound proof is purely algorithmic. It does not use any direct topological argument but uses instead the impossibility of asynchronous set agreement to encapsulate the needed topology. We thus derive an adaptive complexity lower bound for a message passing system from a static impossibility in a shared memory system.},
journal = {SIAM J. Comput.},
month = jan,
pages = {63–78},
numpages = {16},
keywords = {message passing system, shared memory system, lower bound, simulation, distributed algorithm, set agreement}
}

@article{10.1137/090781231,
author = {Ivanyos, G\'{a}bor and Karpinski, Marek and Saxena, Nitin},
title = {Deterministic Polynomial Time Algorithms for Matrix Completion Problems},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090781231},
doi = {10.1137/090781231},
abstract = {We present new deterministic algorithms for several cases of the maximum rank matrix completion problem (for short matrix completion), i.e., the problem of assigning values to the variables in a given symbolic matrix to maximize the resulting matrix rank. Matrix completion is one of the fundamental problems in computational complexity. It has numerous important algorithmic applications, among others, in computing dynamic transitive closures or multicast network codings [N. J. A. Harvey, D. R. Karger, and K. Murota, Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms, 2005, pp. 489-498; N. J. A. Harvey, D. R. Karger, and S. Yekhanin, Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms, 2006, pp. 1103-1111]. We design efficient deterministic algorithms for common generalizations of the results of Lov\'{a}sz and Geelen on this problem by allowing linear polynomials in the entries of the input matrix such that the submatrices corresponding to each variable have rank one. Our methods are algebraic and quite different from those of Lov\'{a}sz and Geelen. We look at the problem of matrix completion in the more general setting of linear spaces of linear transformations and find a maximum rank element there using a greedy method. Matrix algebras and modules play a crucial role in the algorithm. We show (hardness) results for special instances of matrix completion naturally related to matrix algebras; i.e., in contrast to computing isomorphisms of modules (for which there is a known deterministic polynomial time algorithm), finding a surjective or an injective homomorphism between two given modules is as hard as the general matrix completion problem. The same hardness holds for finding a maximum dimension cyclic submodule (i.e., generated by a single element). For the “dual” task, i.e., finding the minimal number of generators of a given module, we present a deterministic polynomial time algorithm. The proof methods developed in this paper apply to fairly general modules and could also be of independent interest.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3736–3751},
numpages = {16},
keywords = {matrix completion, identity testing, morphisms, generators, modules}
}

@article{10.1137/090769752,
author = {Gurevich, Maxim and Keidar, Idit},
title = {Correctness of Gossip-Based Membership under Message Loss},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090769752},
doi = {10.1137/090769752},
abstract = {Due to their simplicity and effectiveness, gossip-based membership protocols have become the method of choice for maintaining partial membership in large peer-to-peer systems. A variety of gossip-based membership protocols were proposed. Some were shown to be effective empirically, lacking analytic understanding of their properties. Others were analyzed under simplifying assumptions, such as lossless and delayless network. It is not clear whether the analysis results hold in dynamic networks, where both nodes and network links can fail. In this paper we try to bridge this gap. We first enumerate the desirable properties of a gossip-based membership protocol, such as view uniformity, independence, and load balance. We then propose a simple send &amp; forget protocol, and show that even in the presence of message loss, it achieves the desirable properties.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3830–3859},
numpages = {30},
keywords = {membership, gossip, random sampling, peer-to-peer}
}

@article{10.1137/090761653,
author = {de Verdi\`{e}re, \'{E}ric Colin and Erickson, Jeff},
title = {Tightening Nonsimple Paths and Cycles on Surfaces},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090761653},
doi = {10.1137/090761653},
abstract = {We describe algorithms to compute the shortest path homotopic to a given path, or the shortest cycle freely homotopic to a given cycle, on an orientable combinatorial surface. Unlike earlier results, our algorithms do not require the input path or cycle to be simple. Given a surface with complexity $n$, genus $ggeq2$, and no boundary, we construct in $O(gnlog n)$ time a tight octagonal decomposition of the surface—a set of simple cycles, each as short as possible in its free homotopy class, that decompose the surface into a complex of octagons meeting four at a vertex. After the surface is preprocessed, we can compute the shortest path homotopic to a given path of complexity $k$ in $O(gnk)$ time, or the shortest cycle homotopic to a given cycle of complexity $k$ in $O(gnklog(nk))$ time. A similar algorithm computes shortest homotopic curves on surfaces with boundary or with genus 1. We also prove that the recent algorithms of Colin de Verdi\`{e}re and Lazarus for shortening embedded graphs and sets of cycles have running times polynomial in the complexity of the surface and the input curves, regardless of the surface geometry.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3784–3813},
numpages = {30},
keywords = {topological graph theory, homotopy, embedded graph, computational topology, combinatorial surface}
}

@article{10.1137/090759112,
author = {Eppstein, David and Goodrich, Michael T. and Strash, Darren},
title = {Linear-Time Algorithms for Geometric Graphs with Sublinearly Many Edge Crossings},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090759112},
doi = {10.1137/090759112},
abstract = {We provide linear-time algorithms for geometric graphs with sublinearly many edge crossings. That is, we provide algorithms running in $O(n)$ time on connected geometric graphs having $n$ vertices and $k$ pairwise crossings, where $k$ is smaller than $n$ by an iterated logarithmic factor. Specific problems that we study include Voronoi diagrams and single-source shortest paths. Our algorithms all run in linear time in the standard comparison-based computational model; hence, we make no assumptions about the distribution or bit complexities of edge weights, nor do we utilize unusual bit-level operations on memory words. Instead, our algorithms are based on a planarization method that “zeros in” on edge crossings, together with methods for applying planar separator decompositions to geometric graphs with sublinearly many crossings. Incidentally, our planarization algorithm also solves an open computational geometry problem of Chazelle for triangulating a self-intersecting polygonal chain having $n$ segments and $k$ crossings in linear time, for the case when $k$ is sublinear in $n$ by an iterated logarithmic factor.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3814–3829},
numpages = {16},
keywords = {epsilon-cuttings, arrangements, shortest paths, geometric graphs, trapezoidal maps, Voronoi diagrams}
}

@article{10.1137/090757010,
author = {Dutta, Partha and Guerraoui, Rachid and Levy, Ron R. and Vukoli\'{c}, Marko},
title = {Fast Access to Distributed Atomic Memory},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090757010},
doi = {10.1137/090757010},
abstract = {We study efficient and robust implementations of an atomic read-write data structure over an asynchronous distributed message-passing system made of reader and writer processes, as well as a number of servers implementing the data structure. We determine the exact conditions under which every read and write involves one round of communication with the servers. These conditions relate the number of readers to the tolerated number of faulty servers and the nature of these failures.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3752–3783},
numpages = {32},
keywords = {shared-memory emulations, fault-tolerance, time-complexity, Byzantine failures, distributed algorithms, atomic registers}
}

@article{10.1137/090751906,
author = {Attiya, Hagit and Censor-Hillel, Keren},
title = {Lower Bounds for Randomized Consensus under a Weak Adversary},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090751906},
doi = {10.1137/090751906},
abstract = {This paper studies the inherent trade-off between termination probability and total step complexity of randomized consensus algorithms. It shows that for every integer $k$, the probability that an $f$-resilient randomized consensus algorithm of $n$ processes does not terminate with agreement within $k(n-f)$ steps is at least $frac{1}{c^k}$, for some constant $c$. A corresponding result is proved for Monte-Carlo algorithms that may terminate in disagreement. The lower bound holds for asynchronous systems, where processes communicate either by message passing or through shared memory, under a very weak adversary that determines the schedule in advance, without observing the algorithm's actions. This complements algorithms of Kapron et al. [Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), ACM, New York, SIAM, Philadelphia, 2008, pp. 1038-1047] for message-passing systems, and of Aumann [Proceedings of the 16th Annual ACM Symposium on Principles of Distributed Computing (PODC), ACM, New York, 1997, pp. 209-218] and Aumann and Bender [Distrib. Comput., 17 (2005), pp. 191-207] for shared-memory systems.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3885–3904},
numpages = {20},
keywords = {lower bound, randomized algorithms, consensus, shared memory, distributed computing, message passing}
}

@article{10.1137/090746720,
author = {Fischer, Simon and R\"{a}cke, Harald and V\"{o}cking, Berthold},
title = {Fast Convergence to Wardrop Equilibria by Adaptive Sampling Methods},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090746720},
doi = {10.1137/090746720},
abstract = {We study the question of whether a large population of agents in a traffic network is able to converge to an equilibrium quickly. To that end, we consider a round-based variant of the Wardrop model. Every agent is allowed to reroute its traffic once in a while with the aim of finding a path with minimal latency. As a first result we find that using a replication policy which allows agents to imitate others gives rise to a bicriterial approximate equilibrium very quickly. In particular, the time bound depends logarithmically on the ratio between minimum and maximum latency but is otherwise independent of the network size. In the single-commodity case, this bicriteria approximate equilibrium has an intuitive interpretation as a state in which almost all agents are almost happy. This kind of approximate equilibrium, however, is transient. In order to reach a global approximation, we need to add an exploration component which enables the agents to explore the strategy space independently of the other agents. Although it can be shown that, when used exclusively, exploration policies imply an exponential lower bound, applying exploration carefully allows the population to approximate the global Wardrop equilibrium in polynomial time. Since the distributed and concurrent fashion of our policies bears the risk of oscillating behavior, we must take into account the steepness of the latency functions. We show that the relevant parameter is elasticity, a parameter closely related to the polynomial degree. This improves significantly over earlier results which depend on the absolute slope and therefore have a pseudopolynomial flavor.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3700–3735},
numpages = {36},
keywords = {Wardrop equilibria, convergence time, adaptive routing}
}

@article{10.1137/080723090,
author = {Lipman, Julia and Stout, Quentin F.},
title = {Analysis of Delays Caused by Local Synchronization},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/080723090},
doi = {10.1137/080723090},
abstract = {Synchronization is often necessary in parallel computing, but it can create delays whenever the receiving processor is idle, waiting for the information to arrive. This is especially true for barrier, or global, synchronization, in which every processor must synchronize with every other processor. Nonetheless, barriers are the only form of synchronization explicitly supplied in OpenMP, and they occur whenever collective communication operations are used in MPI. Many applications do not actually require global synchronization; local synchronization, in which a processor synchronizes only with those processors from or to which information or resources are needed, is often adequate. However, when tasks take varying amounts of time, the behavior of a system under local synchronization is more difficult to analyze since processors do not start tasks at the same time. We show that when the synchronization dependencies form a directed cycle and the task times are geometrically distributed with $p=0.5$, then as the number of processors tends to infinity the processors are working $2-sqrt{2}approx0.59%$ of the time. Under global synchronization, however, the time to complete each task is unbounded, increasing logarithmically with the number of processors. Similar results apply for $pneq0.5$. We also present some of the combinatorial properties of the synchronization problem with geometrically distributed tasks on an undirected cycle. Nondeterministic synchronization is also examined, where processors decide randomly at the beginning of each task which neighbors(s) to synchronize with. We show that the expected number of task dependencies for random synchronization on an undirected cycle is the same as for deterministic synchronization on a directed cycle. Simulations are included to extend the analytic results. They show that more heavy-tailed distributions can actually create fewer delays than less heavy-tailed ones if the number of processors is small for some random-neighbor synchronization models. The results also show the rate of convergence to the steady state for various task distributions and synchronization graphs.},
journal = {SIAM J. Comput.},
month = dec,
pages = {3860–3884},
numpages = {25},
keywords = {stochastic delay, combinatorics, parallel synchronization, performance bounds}
}

@article{10.1137/080744463,
author = {Duris, David},
title = {Extension Preservation Theorems on Classes of Acyclic Finite Structures},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/080744463},
doi = {10.1137/080744463},
abstract = {A class of structures satisfies the extension preservation theorem if, on this class, every first-order sentence is preserved under extensions iff it is equivalent to an existential sentence. We consider different acyclicity notions for hypergraphs ($gamma$-, $beta$-, and $alpha$-acyclicity and also acyclicity on hypergraph quotients) and estimate their influence on the validity of the extension preservation theorem on classes of finite structures. More precisely, we prove that the extension preservation theorem is satisfied for classes of finite structures having a $gamma$-acyclic $k$-quotient that are closed under induced substructures and disjoint unions. We show that this is not the case for classes of $beta$-acyclic structures. To achieve this, we make logical reductions from finite structures to their $k$-quotients and from $gamma$-acyclic hypergraphs to acyclic graphs.},
journal = {SIAM J. Comput.},
month = nov,
pages = {3670–3681},
numpages = {12},
keywords = {hypergraph acyclicity, finite model theory, preservation theorem}
}

@article{10.1137/080725209,
author = {Bodirsky, Manuel and Chen, Hubie},
title = {Quantified Equality Constraints},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/080725209},
doi = {10.1137/080725209},
abstract = {An equality template is a relational structure with infinite universe whose relations can be defined by Boolean combinations of equalities. We prove a complexity classification for quantified constraint satisfaction problems (QCSPs) over equality templates: These problems are in L (decidable in logarithmic space), NP-hard, or coNP-hard. To establish our classification theorem we combine methods from universal algebra with concepts from model theory.},
journal = {SIAM J. Comput.},
month = nov,
pages = {3682–3699},
numpages = {18},
keywords = {quantified constraint satisfaction, omega-categorical structures, computational complexity}
}

@article{10.1137/070698257,
author = {Lin, Guolong and Nagarajan, Chandrashekhar and Rajaraman, Rajmohan and Williamson, David P.},
title = {A General Approach for Incremental Approximation and Hierarchical Clustering},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/070698257},
doi = {10.1137/070698257},
abstract = {We present a general framework and algorithmic approach for incremental approximation algorithms. The framework handles cardinality constrained minimization problems, such as the $k$-median and $k$-MST problems. Given some notion of ordering on solutions of different cardinalities $k$, we give solutions for all values of $k$ such that the solutions respect the ordering and such that for any $k$, our solution is close in value to the value of an optimal solution of cardinality $k$. For instance, for the $k$-median problem, the notion of ordering is set inclusion, and our incremental algorithm produces solutions such that for any $k$ and $k'$, $k<k'$, our solution of size $k$ is a subset of our solution of size $k'$. We show that our framework applies to this incremental version of the $k$-median problem (introduced by Mettu and Plaxton [R. R. Mettu and C. G. Plaxton, SIAM J. Comput., 32 (2003), pp. 816-832]) and incremental versions of the $k$-MST problem, $k$-vertex cover problem, $k$-set cover problem, as well as the uncapacitated facility location problem (which is not cardinality-constrained). For these problems we get either new incremental algorithms or improvements over what was previously known. We also show that the framework applies to hierarchical clustering problems. In particular, we give an improved algorithm for a hierarchical version of the $k$-median problem introduced by Plaxton [C. G. Plaxton, J. Comput. System Sci., 72 (2006), pp. 425-443].},
journal = {SIAM J. Comput.},
month = oct,
pages = {3633–3669},
numpages = {36},
keywords = {hierarchical clustering, incremental approximation, $k$-median problem, approximation algorithms, facility location}
}

@article{10.1137/090767108,
author = {Fleischer, Lisa and K\"{o}nemann, Jochen and Leonardi, Stefano and Sch\"{a}fer, Guido},
title = {Strict Cost Sharing Schemes for Steiner Forest},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090767108},
doi = {10.1137/090767108},
abstract = {Gupta et al. [J. ACM, 54 (2007), article 11] and Gupta, Kumar, and Roughgarden [in Proceedings of the ACM Symposium on Theory of Computing, ACM, New York, 2003, pp. 365-372] recently developed an elegant framework for the development of randomized approximation algorithms for rent-or-buy network design problems. The essential building block of this framework is an approximation algorithm for the underlying network design problem that admits a strict cost sharing scheme. Such cost sharing schemes have also proven to be useful in the development of approximation algorithms in the context of two-stage stochastic optimization with recourse. The main contribution of this paper is to show that the Steiner forest problem admits cost shares that are 3-strict and 4-group-strict. As a consequence, we derive surprisingly simple approximation algorithms for the multicommodity rent-or-buy and the multicast rent-or-buy problems with approximation ratios 5 and 6, improving over the previous best approximation ratios of 6.828 and 12.8, respectively. We also show that no approximation ratio better than 4.67 can be achieved using the sample-and-augment framework in combination with the currently best known Steiner forest approximation algorithms. In the context of two-stage stochastic optimization, our result leads to a 6-approximation algorithm for the stochastic Steiner tree problem in the black-box model and a 5-approximation algorithm for the stochastic Steiner forest problem in the independent decision model.},
journal = {SIAM J. Comput.},
month = oct,
pages = {3616–3632},
numpages = {17},
keywords = {rent-or-buy problems, approximation algorithms, stochastic optimization, strict cost shares, Steiner forests}
}

@article{10.1137/080736491,
author = {Jansen, Klaus and Th\"{o}le, Ralf},
title = {Approximation Algorithms for Scheduling Parallel Jobs},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/080736491},
doi = {10.1137/080736491},
abstract = {In this paper we study variants of the nonpreemptive parallel job scheduling problem in which the number of machines is polynomially bounded in the number of jobs. For this problem we show that a schedule with length at most $(1+varepsilon),mathrm{OPT}$ can be calculated in polynomial time. Unless $P=NP$, this is the best possible result (in the sense of approximation ratio), since the problem is strongly NP-hard. For the case where all jobs must be allotted to a subset of consecutive machines, a schedule with length at most $(1.5+varepsilon),mathrm{OPT}$ can be calculated in polynomial time. The previously best known results are algorithms with absolute approximation ratio 2. Furthermore, we extend both algorithms to the case of malleable jobs with the same approximation ratios.},
journal = {SIAM J. Comput.},
month = oct,
pages = {3571–3615},
numpages = {45},
keywords = {approximation algorithms, malleable tasks, scheduling, parallel tasks}
}

@article{10.1137/080721479,
author = {Georgiou, Konstantinos and Magen, Avner and Pitassi, Toniann and Tourlakis, Iannis},
title = {Integrality Gaps of $2-o(1)$ for Vertex Cover SDPs in the Lov\'{a}Sz-Schrijver Hierarchy},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/080721479},
doi = {10.1137/080721479},
abstract = {Linear and semidefinite programming are highly successful approaches for obtaining good approximations for NP-hard optimization problems. For example, breakthrough approximation algorithms for Max Cut and Sparsest Cut use semidefinite programming. Perhaps the most prominent NP-hard problem whose exact approximation factor is still unresolved is Vertex Cover. Probabilistically checkable proof (PCP)-based techniques of Dinur and Safra [Ann. of Math./ (2), 162 (2005), pp. 439-486] show that it is not possible to achieve a factor better than 1.36; on the other hand no known algorithm does better than the factor of 2 achieved by the simple greedy algorithm. There is a widespread belief that semidefinite programming (SDP) techniques are the most promising methods available for improving upon this factor of 2. Following a line of study initiated by Arora et al. [Theory Comput., 2 (2006), pp. 19-51], our aim is to show that a large family of linear programming (LP)- and SDP-based algorithms fail to produce an approximation for Vertex Cover better than 2. Lov\'{a}sz and Schrijver [SIAM J. Optim., 1 (1991), pp. 166-190] introduced the systems $LS$ and $LS_+$ for systematically tightening LP and SDP relaxations, respectively, over many rounds. These systems naturally capture large classes of LP and SDP relaxations; indeed, $LS_+$ captures the celebrated SDP-based algorithms for Max Cut and Sparsest Cut mentioned above. We rule out polynomial-time SDP-based $2-Omega(1)$ approximations for Vertex Cover using $LS_+$. In particular, for every $epsilon&gt;0$ we prove an integrality gap of $2-epsilon$ for Vertex Cover SDPs obtained by tightening the standard LP relaxation with $Omega(sqrt{log n/loglog n})$ rounds of $LS_+$. While tight integrality gaps were known for Vertex Cover in the weaker $LS$ system [G. Schoenebeck, L. Trevisan, and M. Tulsiani, Proceedings of the 39th Annual ACM Symposium on Theory of Computing, ACM Press, New York, 2007, pp. 302-310], previous results did not rule out a $2-Omega(1)$ approximation after even two rounds of $LS_+$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {3553–3570},
numpages = {18},
keywords = {Lov\'{a}sz-Schrijver semidefinite programming hierarchy, vertex cover, integrality gap}
}

@article{10.1137/090779152,
author = {Doty, David},
title = {Randomized Self-Assembly for Exact Shapes},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090779152},
doi = {10.1137/090779152},
abstract = {Working in Winfree's abstract tile assembly model, we show that a constant-sized tile assembly system can be programmed through relative tile concentrations to build an $ntimes n$ square with high probability for any sufficiently large $n$. This answers an open question of Kao and Schweller [Automata, Languages and Programming, Lecture Notes in Comput. Sci. 5125, Springer, Berlin, 2008, pp. 370-384], who showed how to build an approximately $ntimes n$ square using tile concentration programming and asked whether the approximation could be made exact with high probability. We show how this technique can be modified to answer another question of Kao and Schweller by showing that a constant-sized tile assembly system can be programmed through tile concentrations to assemble arbitrary finite scaled shapes, which are shapes modified by replacing each point with a $ctimes c$ block of points for some integer $c$. Furthermore, we exhibit a smooth trade-off between specifying bits of $n$ via tile concentrations versus specifying them via hard-coded tile types, which allows tile concentration programming to be employed for specifying a fraction of the bits of “input” to a tile assembly system, under the constraint that concentrations can be specified to only a limited precision. Finally, to account for some unrealistic aspects of the tile concentration programming model, we show how to modify the construction to use only concentrations that are arbitrarily close to uniform.},
journal = {SIAM J. Comput.},
month = sep,
pages = {3521–3552},
numpages = {32},
keywords = {randomized algorithm, self-assembly, molecular computation, tile concentration programming}
}

@article{10.1137/100783030,
author = {Diakonikolas, Ilias and Gopalan, Parikshit and Jaiswal, Ragesh and Servedio, Rocco A. and Viola, Emanuele},
title = {Bounded Independence Fools Halfspaces},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/100783030},
doi = {10.1137/100783030},
abstract = {We show that any distribution on ${-1,+1}^n$ that is $k$-wise independent fools any halfspace (or linear threshold function) $h:{-1,+1}^nto{-1,+1}$, i.e., any function of the form $h(x)=operatorname{sign}(sum_{i=1}^{n}w_{i}x_{i}-theta)$, where the $w_1,dots,w_n$ and $theta$ are arbitrary real numbers, with error $epsilon$ for $k=O(epsilon^{-2}log^2(1/epsilon))$. Our result is tight up to $log(1/epsilon)$ factors. Using standard constructions of $k$-wise independent distributions, we obtain the first explicit pseudorandom generators $G:{-1,+1}^sto{-1,+1}^n$ that fool halfspaces. Specifically, we fool halfspaces with error $epsilon$ and seed length $s=kcdotlog n=O(log ncdotepsilon^{-2}log^2(1/epsilon))$. Our approach combines classical tools from real approximation theory with structural results on halfspaces by Servedio [Comput. Complexity, 16 (2007), pp. 180-209].},
journal = {SIAM J. Comput.},
month = aug,
pages = {3441–3462},
numpages = {22},
keywords = {$k$-wise independent distribution, linear threshold function, pseudorandom generator, halfspace}
}

@article{10.1137/090771296,
author = {Hierons, Robert M.},
title = {Reaching and Distinguishing States of Distributed Systems},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090771296},
doi = {10.1137/090771296},
abstract = {Some systems interact with their environment at physically distributed interfaces, called ports, and in testing such a system it is normal to place a tester at each port. Each tester observes only the events at its port and it is known that this limited observational power introduces additional controllability and observability problems into testing. Given a multiport finite state machine (FSM) $M$, we consider the problems of defining strategies for the testers either to reach a given state of $M$ or to distinguish two states of $M$. These are important problems since most techniques for testing from a single-port FSM use sequences that reach and distinguish states. Both problems can be solved in low-order polynomial time for single-port FSMs but we prove that the corresponding decision problems are undecidable for multiport FSMs. However, we also show that they can be solved in low-order polynomial times for deterministic FSMs if we restrict our attention to controllable tests. These results have important ramifications for testing from a multiport FSM since they suggest that methods for testing from a single-port FSM cannot be easily adapted. In addition, two FSMs can be distinguished if and only if their initial states can be distinguished and so the results suggest that, in contrast to single-port FSMs, we cannot expect to produce general complete test generation methods for multiport FSMs.},
journal = {SIAM J. Comput.},
month = aug,
pages = {3480–3500},
numpages = {21},
keywords = {finite state machine, multiport systems, distributed systems, testing}
}

@article{10.1137/090770801,
author = {G\'{a}l, Anna and Gopalan, Parikshit},
title = {Lower Bounds on Streaming Algorithms for Approximating the Length of the Longest Increasing Subsequence},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090770801},
doi = {10.1137/090770801},
abstract = {We show that any deterministic streaming algorithm that makes a constant number of passes over the input and gives a constant factor approximation of the length of the longest increasing subsequence in a sequence of length $n$ must use space $Omega(sqrt{n})$. This proves a conjecture made by Gopalan et al. [Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms, 2007, pp. 318-327] who proved a matching upper bound. Our results yield asymptotically tight lower bounds for all approximation factors, thus resolving the main open problem from their paper. Our proof is based on analyzing a related communication problem and proving a direct sum type property for it.},
journal = {SIAM J. Comput.},
month = aug,
pages = {3463–3479},
numpages = {17},
keywords = {streaming algorithms, communication complexity, longest increasing subsequence, direct sum problem}
}

@article{10.1137/090764190,
author = {Rabani, Yuval and Shpilka, Amir},
title = {Explicit Construction of a Small $\epsilon$-Net for Linear Threshold Functions},
year = {2010},
issue_date = {August 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {8},
issn = {0097-5397},
url = {https://doi.org/10.1137/090764190},
doi = {10.1137/090764190},
abstract = {We give explicit constructions of $epsilon$-nets for linear threshold functions on the binary cube and on the unit sphere. The size of the constructed nets is polynomial in the dimension $n$ and in $frac{1}{epsilon}$. To the best of our knowledge no such constructions were previously known. Our results match, up to the exponent of the polynomial, the bounds that are achieved by probabilistic arguments. As a corollary we also construct subsets of the binary cube that have size polynomial in $n$ and a covering radius of $frac{n}{2}-csqrt{nlog n}$ for any constant $c$. This improves upon the well-known construction of dual BCH codes that guarantee only a covering radius of $frac{n}{2}-csqrt{n}$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {3501–3520},
numpages = {20},
keywords = {explicit construction, derandomization, $epsilon$-net, hitting sets}
}

@article{10.1137/090758039,
author = {Chechik, S. and Langberg, M. and Peleg, D. and Roditty, L.},
title = {Fault Tolerant Spanners for General Graphs},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090758039},
doi = {10.1137/090758039},
abstract = {This paper concerns graph spanners that are resistant to vertex or edge failures. In the failure-free setting, it is known how to efficiently construct a $(2k-1)$-spanner of size $O(n^{1+1/k})$, and this size-stretch trade-off is conjectured to be tight. The notion of fault tolerant spanners was introduced a decade ago in the geometric setting [C. Levcopoulos, G. Narasimhan, and M. Smid, in Proceedings of the 30th Annual ACM Symposium on Theory of Computing, 1998, pp. 186-195]. A subgraph $H$ is an $f$-vertex fault tolerant $k$-spanner of the graph $G$ if for any set $Fsubseteq V$ of size at most $f$ and any pair of vertices $u,vin Vsetminus F$, the distances in $H$ satisfy $delta_{Hsetminus F}(u,v)leq kcdotdelta_{Gsetminus F}(u,v)$. A fault tolerant geometric spanner with optimal maximum degree and total weight was presented in [A. Czumaj and H. Zhao, Discrete Comput. Geom., 32 (2004), pp. 207-230]. This paper also raised as an open problem the question of whether it is possible to obtain a fault tolerant spanner for an arbitrary undirected weighted graph. The current paper answers this question in the affirmative, presenting an $f$-vertex fault tolerant $(2k-1)$-spanner of size $O(f^{2}k^{f+1}cdot n^{1+1/k}log^{1-1/k}n)$. Interestingly, the stretch of the spanner remains unchanged, while the size of the spanner increases only by a factor that depends on the stretch $k$, on the number of potential faults $f$, and on logarithmic terms in $n$. In addition, we consider the simpler setting of $f$-edge fault tolerant spanners (defined analogously). We present an $f$-edge fault tolerant $(2k-1)$-spanner with edge set of size $O(fcdot n^{1+1/k})$ (only $f$ times larger than standard spanners). For both edge and vertex faults, our results are shown to hold when the given graph $G$ is weighted.},
journal = {SIAM J. Comput.},
month = aug,
pages = {3403–3423},
numpages = {21},
keywords = {spanners, fault tolerance, graphs}
}

@article{10.1137/090757496,
author = {Goldberg, Leslie Ann and Grohe, Martin and Jerrum, Mark and Thurley, Marc},
title = {A Complexity Dichotomy for Partition Functions with Mixed Signs},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090757496},
doi = {10.1137/090757496},
abstract = {Partition functions, also known as homomorphism functions, form a rich family of graph invariants that contain combinatorial invariants such as the number of $k$-colorings or the number of independent sets of a graph and also the partition functions of certain “spin glass” models of statistical physics such as the Ising model. Building on earlier work by Dyer and Greenhill [Random Structures Algorithms, 17 (2000), pp. 260-289] and Bulatov and Grohe [Theoret. Comput. Sci., 348 (2005), pp. 148-186], we completely classify the computational complexity of partition functions. Our main result is a dichotomy theorem stating that every partition function is either computable in polynomial time or #P-complete. Partition functions are described by symmetric matrices with real entries, and we prove that it is decidable in polynomial time in terms of the matrix whether a given partition function is in polynomial time or #P-complete. While in general it is very complicated to give an explicit algebraic or combinatorial description of the tractable cases, for partition functions described by Hadamard matrices (these turn out to be central in our proofs) we obtain a simple algebraic tractability criterion, which says that the tractable cases are those “representable” by a quadratic polynomial over the field $mathbb{F}_2$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {3336–3402},
numpages = {67},
keywords = {computational complexity, partition functions, counting complexity, graph homomorphisms}
}

@article{10.1137/080734881,
author = {Boros, Endre and Elbassioni, Khaled and Makino, Kazuhisa},
title = {Left-to-Right Multiplication for Monotone Boolean Dualization},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080734881},
doi = {10.1137/080734881},
abstract = {Given the prime conjunctive normal form (CNF) representation $phi$ of a monotone Boolean function $f:{0,1}^nto{0,1}$, the dualization problem calls for finding the corresponding prime disjunctive normal form representation $psi$ of $f$. A very simple method works by multiplying out the clauses of $phi$ from left to right in some order, simplifying whenever possible by using the absorption law. We show that for any monotone CNF $phi$, left-to-right multiplication can be done in subexponential time, and for many interesting subclasses of monotone CNFs such as those with bounded size, bounded degree, bounded intersection, bounded conformality, and read-once formula, it can be done in polynomial or quasi-polynomial time.},
journal = {SIAM J. Comput.},
month = aug,
pages = {3424–3439},
numpages = {16},
keywords = {monotone Boolean function, dualization, enumerating minimal hypergraph transversals}
}

@article{10.1137/090779875,
author = {Ben-Sasson, Eli and Guruswami, Venkatesan and Kaufman, Tali and Sudan, Madhu and Viderman, Michael},
title = {Locally Testable Codes Require Redundant Testers},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090779875},
doi = {10.1137/090779875},
abstract = {Locally testable codes (LTCs) are error-correcting codes for which membership, in the code, of a given word can be tested by examining it in very few locations. Most known constructions of LTCs are linear codes and give error-correcting codes whose duals have (superlinearly) many small weight codewords. Examining this feature appears to be one of the promising approaches to proving limitation results for (i.e., upper bounds on the rate of) LTCs. Unfortunately, until now it has not even been known whether LTCs need to be nontrivially redundant, i.e., need to have one linear dependency among the low-weight codewords in their dual. In this paper we give the first lower bound of this form, by showing that every positive rate constant query strong LTC must have linearly many redundant low-weight codewords in its dual. We actually prove the stronger claim that the actual test itself must use a linear number of redundant dual codewords (beyond the minimum number of basis elements required to characterize the code); in other words, nonredundant (in fact, low redundancy) local testing is impossible. Our main theorem is a special case of a more general theorem that applies to any tester for an arbitrary linear LTC $mathcal{C}$. The general theorem can be used, for instance, to provide an arguably simpler proof of the main result of Ben-Sasson, Harsha, and Raskhodnikova [SIAM J. Comput., 35 (2005), pp. 1-21], which says that testing random low density parity check (LDPC) codes requires linear query complexity. Informally, our more general theorem says the following. Take any basis $B$ for the dual code of $mathcal{C}$ that is composed of words of small support; i.e., every element of $B$ has very few nonzero entries. Then the dual code of $mathcal{C}$ must contain many words that (i) are not in $B$, (ii) have small support, and, most importantly, (iii) are a linear combination of a constant fraction of $B$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3230–3247},
numpages = {18},
keywords = {linear codes, lower bounds, dual codes, low density parity check codes, property testing}
}

@article{10.1137/090772885,
author = {Kempe, Julia and Regev, Oded and Toner, Ben},
title = {Unique Games with Entangled Provers Are Easy},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090772885},
doi = {10.1137/090772885},
abstract = {We consider one-round games between a classical verifier and two provers who share entanglement. We show that when the constraints enforced by the verifier are “unique” constraints (i.e., permutations), the value of the game can be well approximated by a semidefinite program (SDP). Essentially the only algorithm known previously was for the special case of binary answers, as follows from the work of Tsirelson in 1980. Among other things, our result implies that the variant of the unique games conjecture where we allow the provers to share entanglement is false. Our proof is based on a novel “quantum rounding technique,” showing how to take a solution to an SDP and transform it into a strategy for entangled provers. Using our approximation by an SDP, we also show a parallel repetition theorem for unique entangled games.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3207–3229},
numpages = {23},
keywords = {quantum entanglement, semidefinite programming, two-prover one-round games, parallel repetition}
}

@article{10.1137/090772228,
author = {Bansal, Nikhil and Pruhs, Kirk R.},
title = {Server Scheduling to Balance Priorities, Fairness, and Average Quality of Service},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090772228},
doi = {10.1137/090772228},
abstract = {Often server systems do not implement the best known algorithms for optimizing average Quality of Service (QoS) out of concern that these algorithms may be insufficiently fair to individual jobs. The standard method for balancing average QoS and fairness is to optimize the $\ell_p$ norm, $1<p<\infty$. Thus we consider server scheduling strategies to optimize the $\ell_p$ norms of the standard QoS measures, flow and stretch. We first show that there is no $n^{o(1)}$-competitive online algorithm for the $\ell_p$ norms of either flow or stretch. We then show that the standard clairvoyant algorithms for optimizing average QoS, Shortest Job First (SJF), and Shortest Remaining Processing Time (SRPT), are scalable for the $\ell_p$ norms of flow and stretch. We then show that the standard nonclairvoyant algorithm for optimizing average QoS, Shortest Elapsed Time First (SETF), is also scalable for the $\ell_p$ norms of flow. We then show that the online algorithm, Highest Density First (HDF), and the nonclairvoyant algorithm, Weighted Shortest Elapsed Time First (WSETF), are scalable for the weighted $\ell_p$ norms of flow. These results suggest that the concern that these standard algorithms may unnecessarily starve jobs is unfounded. In contrast, we show that the Round Robin, or Processor Sharing, algorithm, which is sometimes adopted because of its seeming fairness properties, is not $O(1+\epsilon)$-speed, $n^{o(1)}$-competitive for sufficiently small $\epsilon$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3311–3335},
numpages = {24},
keywords = {shortest elapsed time first, resource augmentation, flow time, multilevel feedback, shortest remaining processing time, shortest job first, scheduling}
}

@article{10.1137/090762968,
author = {Aronov, Boris and Ezra, Esther and Sharir, Micha},
title = {Small-Size $\eps$-Nets for Axis-Parallel Rectangles and Boxes},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090762968},
doi = {10.1137/090762968},
abstract = {We show the existence of $varepsilon$-nets of size $Oleft(frac{1}{varepsilon}loglogfrac{1}{varepsilon}right)$ for planar point sets and axis-parallel rectangular ranges. The same bound holds for points in the plane and “fat” triangular ranges and for point sets in $boldsymbol{R}^3$ and axis-parallel boxes; these are the first known nontrivial bounds for these range spaces. Our technique also yields improved bounds on the size of $varepsilon$-nets in the more general context considered by Clarkson and Varadarajan. For example, we show the existence of $varepsilon$-nets of size $Oleft(frac{1}{varepsilon}logloglogfrac{1}{varepsilon}right)$ for the dual range space of “fat” regions and planar point sets (where the regions are the ground objects and the ranges are subsets stabbed by points). Plugging our bounds into the technique of Br\"{o}nnimann and Goodrich or of Even, Rawitz, and Shahar, we obtain improved approximation factors (computable in expected polynomial time by a randomized algorithm) for the hitting set or the set cover problems associated with the corresponding range spaces.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3248–3282},
numpages = {35},
keywords = {set cover, hitting set, Exponential Decay Lemma, $varepsilon$-nets, geometric range spaces}
}

@article{10.1137/080744694,
author = {Kaplan, Haim and Rubin, Natan and Sharir, Micha},
title = {Line Transversals of Convex Polyhedra in $\mathbb{R}^3$},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080744694},
doi = {10.1137/080744694},
abstract = {We establish a bound of $O(n^2k^{1+varepsilon})$, for any $varepsilon&gt;0$, on the combinatorial complexity of the set $mathcal{T}$ of line transversals of a collection $mathcal{P}$ of $k$ convex polyhedra in $mathbb{R}^3$ with a total of $n$ facets, and we present a randomized algorithm which computes the boundary of $mathcal{T}$ in comparable expected time. Thus, when $kll n$, the new bounds on the complexity (and construction cost) of $mathcal{T}$ improve upon the previously best known bounds, which are nearly cubic in $n$. To obtain the above result, we study the set $mathcal{T}_{ell_0}$ of line transversals which emanate from a fixed line $ell_0$, establish an almost tight bound of $O(nk^{1+varepsilon})$ on the complexity of $mathcal{T}_{ell_0}$, and provide a randomized algorithm which computes $mathcal{T}_{ell_0}$ in comparable expected time. Slightly improved combinatorial bounds for the complexity of $mathcal{T}_{ell_0}$ and comparable improvements in the cost of constructing this set are established for two special cases, both assuming that the polyhedra of $mathcal{P}$ are pairwise disjoint: the case where $ell_0$ is disjoint from the polyhedra of $mathcal{P}$, and the case where the polyhedra of $mathcal{P}$ are unbounded in a direction parallel to $ell_0$. Our result is related to the problem of bounding the number of geometric permutations of a collection $mathcal{C}$ of $k$ pairwise-disjoint convex sets in $mathbb{R}^3$, namely, the number of distinct orders in which the line transversals of $mathcal{C}$ visit its members. We obtain a new partial result on this problem.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3283–3310},
numpages = {28},
keywords = {combinatorial complexity, extremal stabbing lines, convex polyhedra, lines in space, line transversals}
}

@article{10.1137/080741811,
author = {McKenzie, Pierre and Thomas, Michael and Vollmer, Heribert},
title = {Extensional Uniformity for Boolean Circuits},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080741811},
doi = {10.1137/080741811},
abstract = {Imposing an extensional uniformity condition on a nonuniform circuit complexity class $mathcal{C}$ means simply intersecting $mathcal{C}$ with a uniform class $mathcal{L}$. By contrast, the usual intensional uniformity conditions require that a resource-bounded machine be able to exhibit the circuits in the circuit family defining $mathcal{C}$. We say that $(mathcal{C},mathcal{L})$ has the uniformity duality property if the extensionally uniform class $mathcal{C}capmathcal{L}$ can be captured intensionally by means of adding so-called $mathcal{L}$-numerical predicates to the first-order descriptive complexity apparatus describing the connection language of the circuit family defining $mathcal{C}$. This paper exhibits positive instances and negative instances of the uniformity duality property.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3186–3206},
numpages = {21},
keywords = {Boolean circuits, descriptive complexity, uniformity}
}

@article{10.1137/080735096,
author = {Shaltiel, Ronen and Viola, Emanuele},
title = {Hardness Amplification Proofs Require Majority},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080735096},
doi = {10.1137/080735096},
abstract = {Hardness amplification is the fundamental task of converting a $delta$-hard function $f:{0,1}^nto{0,1}$ into a $(1/2-epsilon)$-hard function $mathit{Amp}(f)$, where $f$ is $gamma$-hard if small circuits fail to compute $f$ on at least a $gamma$ fraction of the inputs. In this paper we study the complexity of black-box proofs of hardness amplification. A class of circuits $mathcal{D}$ proves a hardness amplification result if for any function $h$ that agrees with $mathit{Amp}(f)$ on a $1/2+epsilon$ fraction of the inputs there exists an oracle circuit $Dinmathcal{D}$ such that $D^h$ agrees with $f$ on a $1-delta$ fraction of the inputs. We focus on the case where every $Dinmathcal{D}$ makes nonadaptive queries to $h$. This setting captures most hardness amplification techniques. We prove two main results: (1) The circuits in $mathcal{D}$ “can be used” to compute the majority function on $1/epsilon$ bits. In particular, when $epsilonleq1/log^{omega(1)}n$, $mathcal{D}$ cannot consist of oracle circuits that have unbounded fan-in, size $mathrm{poly}(n)$, and depth $O(1)$. (2) The circuits in $mathcal{D}$ must make $Omegaleft(log(1/delta)/epsilon^2right)$ oracle queries. Both our bounds on the depth and on the number of queries are tight up to constant factors. Our results explain why hardness amplification techniques have failed to transform known lower bounds against constant-depth circuit classes into strong average-case lower bounds. Our results reveal a contrast between Yao's XOR lemma ($mathit{Amp}(f):=f(x_1)opluscdotsoplus f(x_t)in{0,1}$) and the direct-product lemma ($mathit{Amp}(f):=f(x_1)circcdotscirc f(x_t)in{0,1}^t$; here $mathit{Amp}(f)$ is non-Boolean). Our results (1) and (2) apply to Yao's XOR lemma, whereas known proofs of the direct-product lemma violate both (1) and (2). One of our contributions is a new technique for handling “nonuniform” reductions, i.e., the case when $mathcal{D}$ contains many circuits.},
journal = {SIAM J. Comput.},
month = jul,
pages = {3122–3154},
numpages = {33},
keywords = {hardness amplification, natural proofs, decoding, circuit, majority, lower bound, small-depth circuit}
}

@article{10.1137/080717584,
author = {Fischer, Eldar and Matsliah, Arie and Shapira, Asaf},
title = {Approximate Hypergraph Partitioning and Applications},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080717584},
doi = {10.1137/080717584},
abstract = {Szemer\'{e}di's regularity lemma is a cornerstone result in extremal combinatorics. It (roughly) asserts that any dense graph is composed of a finite number of pseudorandom graphs. The regularity lemma has found many applications in theoretical computer science, and thus a lot of attention was given to designing algorithmic versions of this lemma. Our main results in this paper are the following: (i) We introduce a new approach to the problem of constructing regular partitions of graphs, which results in a surprisingly simple $O(n)$ time algorithmic version of the regularity lemma, thus improving over the previous $O(n^2)$ time algorithms. Furthermore, unlike all the previous approaches for this problem (see [N. Alon and A. Naor, SIAM J. Comput., 35 (2006), pp. 787-803], [R. A. Duke, H. Lefmann, and V. R\"{o}dl, SIAM J. Comput., 24 (1995), pp. 598-620], [A. Frieze and R. Kannan, Electron. J. Combin., 6 (1999), article 17], [A. Frieze and R. Kannan, “The regularity lemma and approximation schemes for dense problems,” in Proceedings of the 37th Annual Symposium on Foundations of Computer Science (Burlington, VT, 1996), IEEE Computer Society Press, Los Alamitos, CA, 1996, pp. 12-20], and [Y. Kohayakawa, V. R\"{o}dl, and L. Thoma, SIAM J. Comput., 32 (2003), pp. 1210-1235]), which only guaranteed to find tower-size partitions, our algorithm will find a small regular partition, if one exists in the graph. (ii) For any constant $rgeq3$ we give an $O(n)$ time randomized algorithm for constructing regular partitions of $r$-uniform hypergraphs, thus improving the previous $O(n^{2r-1})$ time (deterministic) algorithms [A. Czygrinow and V. R\"{o}dl, SIAM J. Comput., 30 (2000), pp. 1041-1066], [A. Frieze and R. Kannan, “The regularity lemma and approximation schemes for dense problems,” in Proceedings of the 37th Annual Symposium on Foundations of Computer Science (Burlington, VT, 1996), IEEE Computer Society Press, Los Alamitos, CA, 1996, pp. 12-20]. These two results are obtained as an application of an efficient algorithm for approximating partition problems of hypergraphs which we obtain here: Given a (directed) hypergraph with bounded edge arities, a set of constraints on the set sizes and densities of a possible partition of its vertex set, and an approximation parameter, we provide in $O(n)$ time a partition approximating the constraints if a partition satisfying them exists. We can also test in $O(1)$ time for the existence of such a partition given the approximation parameter. This algorithm extends the result of Goldreich, Goldwasser, and Ron for graph partition problems [O. Goldreich, S. Goldwasser, and D. Ron, J. ACM, 45 (1998), pp. 653-750] and encompasses more recent hypergraph-related results such as the maximal constraint satisfaction approximation of [G. Andersson and L. Engebretsen, Random Structures Algorithms, 21 (2002), pp. 14-32].},
journal = {SIAM J. Comput.},
month = jul,
pages = {3155–3185},
numpages = {31},
keywords = {regularity lemma, partitioning, property testing, hypergraph}
}

@article{10.1137/100782929,
author = {Rosen, Alon and Segev, Gil},
title = {Chosen-Ciphertext Security via Correlated Products},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/100782929},
doi = {10.1137/100782929},
abstract = {We initiate the study of one-wayness under correlated products. We are interested in identifying necessary and sufficient conditions for a function $f$ and a distribution on inputs $(x_1,dots,x_k)$ so that the function $(f(x_1),dots,f(x_k))$ is one-way. The main motivation of this study is the construction of public-key encryption schemes that are secure against chosen-ciphertext attacks (CCAs). We show that any collection of injective trapdoor functions that is secure under a very natural correlated product can be used to construct a CCA-secure public-key encryption scheme. The construction is simple, black-box, and admits a direct proof of security. It can be viewed as a simplification of the seminal work of Dolev, Dwork, and Naor [SIAM J. Comput., 30 (2000), pp. 391-437], while relying on a seemingly incomparable assumption. We provide evidence that security under correlated products is achievable by demonstrating that lossy trapdoor functions [Peikert and Waters, Proceedings of the 40th Annual ACM Symposium on Theory of Computing, 2008, pp. 187-196] yield injective trapdoor functions that are secure under the above-mentioned correlated product. Although we currently base security under correlated products on existing constructions of lossy trapdoor functions, we argue that the former notion is potentially weaker as a general assumption. Specifically, there is no fully black-box construction of lossy trapdoor functions from trapdoor functions that are secure under correlated products.},
journal = {SIAM J. Comput.},
month = jun,
pages = {3058–3088},
numpages = {31},
keywords = {public-key encryption, trapdoor functions, chosen-ciphertext attacks}
}

@article{10.1137/090775646,
author = {Idziak, Paweundefined and Markovi\'{c}, Petar and McKenzie, Ralph and Valeriote, Matthew and Willard, Ross},
title = {Tractability and Learnability Arising from Algebras with Few Subpowers},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090775646},
doi = {10.1137/090775646},
abstract = {A constraint language $Gamma$ on a finite set $A$ has been called polynomially expressive if the number of $n$-ary relations expressible by $existswedge$-atomic formulas over $Gamma$ is bounded by $exp(O(n^k))$ for some constant $k$. It has recently been discovered that this property is characterized by the existence of a $(k+1)$-ary polymorphism satisfying certain identities; such polymorphisms are called $k$-edge operations and include Mal'cev and near-unanimity operations as special cases. We prove that if $Gamma$ is any constraint language which, for some $k&gt;1$, has a $k$-edge operation as a polymorphism, then the constraint satisfaction problem for $langleGammarangle$ (the closure of $Gamma$ under $existswedge$-atomic expressibility) is globally tractable. We also show that the set of relations definable over $Gamma$ using quantified generalized formulas is polynomially exactly learnable using improper equivalence queries.},
journal = {SIAM J. Comput.},
month = jun,
pages = {3023–3037},
numpages = {15},
keywords = {constraint satisfaction, complexity, polynomially expressive, Mal'cev, polymorphism, near-unanimity, learnability, few subpowers}
}

@article{10.1137/090753620,
author = {van Kreveld, Marc and L\"{o}ffler, Maarten and Mitchell, Joseph S. B.},
title = {Preprocessing Imprecise Points and Splitting Triangulations},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090753620},
doi = {10.1137/090753620},
abstract = {Traditional algorithms in computational geometry assume that the input points are given precisely. In practice, data is usually imprecise, but information about the imprecision is often available. In this context, we investigate what the value of this information is. We show here how to preprocess a set of disjoint regions in the plane of total complexity $n$ in $O(nlog n)$ time so that if one point per set is specified with precise coordinates, a triangulation of the points can be computed in linear time. In our solution, we solve another problem which we believe to be of independent interest. Given a triangulation with red and blue vertices, we show how to compute a triangulation of only the blue vertices in linear time.},
journal = {SIAM J. Comput.},
month = jun,
pages = {2990–3000},
numpages = {11},
keywords = {computational geometry, data imprecision, preprocessing, triangulations}
}

@article{10.1137/080739379,
author = {Arad, Itai and Landau, Zeph},
title = {Quantum Computation and the Evaluation of Tensor Networks},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080739379},
doi = {10.1137/080739379},
abstract = {We present a quantum algorithm that additively approximates the value of a tensor network to a certain scale. When combined with existing results, this provides a complete problem for quantum computation. The result is a simple new way of looking at quantum computation in which unitary gates are replaced by tensors and time is replaced by the order in which the tensor network is “swallowed.” We use this result to derive new quantum algorithms that approximate the partition function of a variety of classical statistical mechanical models, including the Potts model.},
journal = {SIAM J. Comput.},
month = jun,
pages = {3089–3121},
numpages = {33},
keywords = {statistical mechanical models, quantum algorithms, tensor networks}
}

@article{10.1137/080731712,
author = {Mestre, Juli\'{a}n},
title = {Adaptive Local Ratio},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080731712},
doi = {10.1137/080731712},
abstract = {Local ratio is a well-known paradigm for designing approximation algorithms for combinatorial optimization problems. At a very high level, a local-ratio algorithm first decomposes the input weight function $w$ into a positive linear combination of simpler weight functions or models. Guided by this process, a solution $S$ is constructed such that $S$ is $alpha$-approximate with respect to each model used in the decomposition. As a result, $S$ is $alpha$-approximate under $w$ as well. These models usually have a very simple structure that remains “unchanged” throughout the execution of the algorithm. In this work we show that adaptively choosing a model from a richer spectrum of functions can lead to a better local ratio. Indeed, by turning the search for a good model into an optimization problem of its own, we get improved approximations for a data migration problem.},
journal = {SIAM J. Comput.},
month = jun,
pages = {3038–3057},
numpages = {20},
keywords = {approximation algorithms, primal-dual schema, local-ratio technique, scheduling problems}
}

@article{10.1137/080729645,
author = {Nutov, Zeev},
title = {Approximating Steiner Networks with Node-Weights},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080729645},
doi = {10.1137/080729645},
abstract = {The (undirected) Steiner Network problem is as follows: given a graph $G=(V,E)$ with edge/node-weights and edge-connectivity requirements ${r(u,v):u,vin Usubseteq V}$, find a minimum-weight subgraph $H$ of $G$ containing $U$ so that the $uv$-edge-connectivity in $H$ is at least $r(u,v)$ for all $u,vin U$. The seminal paper of Jain [Combinatorica, 21 (2001), pp. 39-60], and numerous papers preceding it, considered the Edge-Weighted Steiner Network problem, with weights on the edges only, and developed novel tools for approximating minimum-weight edge-covers of several types of set functions and families. However, for the Node-Weighted Steiner Network (NWSN) problem, nontrivial approximation algorithms were known only for $0,1$ requirements. We make an attempt to change this situation by giving the first nontrivial approximation algorithm for NWSN with arbitrary requirements. Our approximation ratio for NWSN is $r_{max}cdot O(ln|U|)$, where $r_{max}=max_{u,vin U}r(u,v)$. This generalizes the result of Klein and Ravi [J. Algorithms, 19 (1995), pp. 104-115] for the case $r_{max}=1$. We also give an $O(ln|U|)$-approximation algorithm for the node-connectivity variant of NWSN (when the paths are required to be internally disjoint) for the case $r_{max}=2$. Our results are based on a much more general approximation algorithm for the problem of finding a minimum node-weighted edge-cover of an uncrossable set-family. Finally, we give evidence that a polylogarithmic approximation ratio for NWSN with large $r_{max}$ might not exist even for $|U|=2$ and unit weights.},
journal = {SIAM J. Comput.},
month = jun,
pages = {3001–3022},
numpages = {22},
keywords = {Steiner networks, approximation algorithms, intersecting families, node-weights}
}

@article{10.1137/09076516X,
author = {Coja-Oghlan, Amin},
title = {A Better Algorithm for Random $k$-SAT},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/09076516X},
doi = {10.1137/09076516X},
abstract = {Let $boldsymbol{Phi}$ be a uniformly distributed random $k$-SAT formula with $n$ variables and $m$ clauses. We present a polynomial time algorithm that finds a satisfying assignment of $boldsymbol{Phi}$ with high probability for constraint densities $m/n&lt;(1-varepsilon_k)2^kln(k)/k$, where $varepsilon_krightarrow0$. Previously no efficient algorithm was known to find satisfying assignments with a nonvanishing probability beyond $m/n=1.817cdot2^k/k$ [A. Frieze and S. Suen, J. Algorithms, 20 (1996), pp. 312-355].},
journal = {SIAM J. Comput.},
month = may,
pages = {2823–2864},
numpages = {42},
keywords = {$k$-SAT, random structures, phase transitions, efficient algorithms}
}

@article{10.1137/090759860,
author = {Cardinal, Jean and Fiorini, Samuel and Joret, Gwena\"{e}l and Jungers, Rapha\"{e}l M. and Munro, J. Ian},
title = {An Efficient Algorithm for Partial Order Production},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/090759860},
doi = {10.1137/090759860},
abstract = {We consider the problem of partial order production: arrange the elements of an unknown totally ordered set $T$ into a target partially ordered set $S$ by comparing a minimum number of pairs in $T$. Special cases include sorting by comparisons, selection, multiple selection, and heap construction. We give an algorithm performing $ITLB+o(ITLB)+O(n)$ comparisons in the worst case. Here, $n$ denotes the size of the ground sets, and $ITLB$ denotes a natural information-theoretic lower bound on the number of comparisons needed to produce the target partial order. Our approach is to replace the target partial order by a weak order (that is, a partial order with a layered structure) extending it, without increasing the information-theoretic lower bound too much. We then solve the problem by applying an efficient multiple selection algorithm. The overall complexity of our algorithm is polynomial. This answers a question of Yao [SIAM J. Comput., 18 (1989), pp. 679-689]. We base our analysis on the entropy of the target partial order, a quantity that can be efficiently computed and provides a good estimate of the information-theoretic lower bound.},
journal = {SIAM J. Comput.},
month = may,
pages = {2927–2940},
numpages = {14},
keywords = {partial order, graph entropy}
}

@article{10.1137/080737174,
author = {Baswana, Surender and Kavitha, Telikepalli},
title = {Faster Algorithms for All-Pairs Approximate Shortest Paths in Undirected Graphs},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080737174},
doi = {10.1137/080737174},
abstract = {Let $G=(V,E)$ be a weighted undirected graph having nonnegative edge weights. An estimate $hat{delta}(u,v)$ of the actual distance $delta(u,v)$ between $u,vin V$ is said to be of stretch $t$ if and only if $delta(u,v)leqhat{delta}(u,v)leq tcdotdelta(u,v)$. Computing all-pairs small stretch distances efficiently (both in terms of time and space) is a well-studied problem in graph algorithms. We present a simple, novel, and generic scheme for all-pairs approximate shortest paths. Using this scheme and some new ideas and tools, we design faster algorithms for all-pairs $t$-stretch distances for a whole range of stretch $t$, and we also answer an open question posed by Thorup and Zwick in their seminal paper [J. ACM, 52 (2005), pp. 1-24].},
journal = {SIAM J. Comput.},
month = may,
pages = {2865–2896},
numpages = {32},
keywords = {distance, oracle, approximate distance, randomization, shortest path}
}

@article{10.1137/080736600,
author = {Aronov, Boris and Sharir, Micha},
title = {Approximate Halfspace Range Counting},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080736600},
doi = {10.1137/080736600},
abstract = {We present a simple scheme extending the shallow partitioning data structures of Matou\v{s}ek, which supports efficient approximate halfspace range-counting queries in $mathbb{R}^d$ with relative error $varepsilon$. Specifically, the problem is, given a set $P$ of $n$ points in $mathbb{R}^d$, to preprocess them into a data structure that returns, for a query halfspace $h$, a number $t$ so that $(1-varepsilon)|hcap P|leq tleq(1+varepsilon)|hcap P|$. One of our data structures requires linear storage and $O(n^{1+delta})$ preprocessing time, for any $delta&gt;0$, and answers a query in time $O(varepsilon^{-gamma}n^{1-1/lfloor d/2rfloor}2^{blog^ast n})$ for any $gamma&gt;2/lfloor d/2rfloor$; the choice of $gamma$ and $delta$ affects $b$ and the implied constants. Several variants and extensions are also discussed. As presented, the construction of the structure is mostly deterministic, except for one critical randomized step, and so are the query, storage, and preprocessing costs. The quality of approximation, for every query, is guaranteed with high probability. The construction can also be fully derandomized, at the expense of increasing preprocessing time.},
journal = {SIAM J. Comput.},
month = may,
pages = {2704–2725},
numpages = {22},
keywords = {partition trees, hyperplane arrangements, relative approximations, approximation algorithms, shallow cuttings, range searching, range counting, cuttings, geometric algorithms, geometric sampling, shallow partition trees}
}

@article{10.1137/080728561,
author = {Saks, Michael and Seshadhri, C.},
title = {Local Monotonicity Reconstruction},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080728561},
doi = {10.1137/080728561},
abstract = {We investigate the problem of monotonicity reconstruction, as defined by Ailon et al. (2004) in a localized setting. We have oracle access to a nonnegative real-valued function $f$ defined on the domain $[n]^d={1,dots,n}^d$ (where $d$ is viewed as a constant). We would like to closely approximate $f$ by a monotone function $g$. This should be done by a procedure (a filter) that given as input a point $xin[n]^d$ outputs the value of $g(x)$, and runs in time that is polylogarithmic in $n$. The procedure can (indeed must) be randomized, but we require that all of the randomness be specified in advance by a single short random seed. We construct such an implementation where the time and space per query is $(log n)^{O(1)}$ and the size of the seed is polynomial in $log n$ and $d$. Furthermore, with high probability, the ratio of the (Hamming) distance between $g$ and $f$ to the minimum possible Hamming distance between a monotone function and $f$ is bounded above by a function of $d$ (independent of $n$). This allows for a local implementation: one can initialize many copies of the filter with the same short random seed, and they can autonomously handle queries, while producing outputs that are consistent with the same approximating function $g$.},
journal = {SIAM J. Comput.},
month = may,
pages = {2897–2926},
numpages = {30},
keywords = {local reconstruction, property testing, monotonicity, sublinear algorithms}
}

@article{10.1137/080723491,
author = {Asadpour, Arash and Saberi, Amin},
title = {An Approximation Algorithm for Max-Min Fair Allocation of Indivisible Goods},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080723491},
doi = {10.1137/080723491},
abstract = {In this paper, we give the first approximation algorithm for the problem of max-min fair allocation of indivisible goods. An instance of this problem consists of a set of $k$ people and $m$ indivisible goods. Each person has a known linear utility function over the set of goods which might be different from the utility functions of other people. The goal is to distribute the goods among the people and maximize the minimum utility received by them. The approximation ratio of our algorithm is $Omega(frac{1}{sqrt{k}log^{3}k})$. As a crucial part of our algorithm, we design and analyze an iterative method for rounding a fractional matching on a tree which might be of independent interest. We also provide better bounds when we are allowed to exclude a small fraction of the people from the problem.},
journal = {SIAM J. Comput.},
month = may,
pages = {2970–2989},
numpages = {20},
keywords = {approximation algorithm, game theory, randomized rounding}
}

@article{10.1137/080722771,
author = {Goldreich, Oded and Goldwasser, Shafi and Nussboim, Asaf},
title = {On the Implementation of Huge Random Objects},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080722771},
doi = {10.1137/080722771},
abstract = {We initiate a general study of the feasibility of implementing (huge) random objects, and demonstrate its applicability to a number of areas in which random objects occur naturally. We highlight two types of measures of the quality of the implementation (with respect to the desired specification): The first type corresponds to various standard notions of indistinguishability (applied to function ensembles), whereas the second type is a novel notion that we call truthfulness. Intuitively, a truthful implementation of a random object of Type T must (always) be an object of Type T, and not merely be indistinguishable from a random object of Type T. Our formalism allows for the consideration of random objects that satisfy some fixed property (or have some fixed structure) as well as the consideration of objects supporting complex queries. For example, we consider the truthful implementation of random Hamiltonian graphs as well as supporting complex queries regarding such graphs (e.g., providing the next vertex along a fixed Hamiltonian path in such a graph).},
journal = {SIAM J. Comput.},
month = may,
pages = {2761–2822},
numpages = {62},
keywords = {random walks on regular graphs, random codes, random graphs, pseudorandomness, monotone graph properties, random functions}
}

@article{10.1137/080716840,
author = {Kawachi, Akinori and Yamakami, Tomoyuki},
title = {Quantum Hardcore Functions by Complexity-Theoretical Quantum List Decoding},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/080716840},
doi = {10.1137/080716840},
abstract = {Hardcore functions have been used as a technical tool to construct secure cryptographic systems; however, little is known on their quantum counterpart, called quantum hardcore functions. With a new insight into fundamental properties of quantum hardcores, we present three new quantum hardcore functions for any (strong) quantum one-way function. We also give a “quantum” solution to Damg\r{a}rd's question [Advances in Cryptology, Lecture Notes in Comput. Sci. 403, Springer, Berlin, 1990, pp. 163-172] on a classical hardcore property of his pseudorandom generator by proving its quantum hardcore property. Our major technical tool is the new notion of quantum list-decoding of “classical” error-correcting codes (rather than “quantum” error-correcting codes), which is defined on the platform of computational complexity theory and computational cryptography (rather than information theory). In particular, we give a simple but powerful criterion that makes a polynomial-time computable classical block code (seen as a function) a quantum hardcore for all quantum one-way functions. On their own interest, we construct efficient quantum list-decoding algorithms for classical block codes whose associated quantum states (called codeword states) form a nearly phase-orthogonal basis.},
journal = {SIAM J. Comput.},
month = may,
pages = {2941–2969},
numpages = {29},
keywords = {quantum hardcore, quantum one-way, codeword state, presence, quantum list-decoding, phase orthogonal, Johnson bound}
}

@article{10.1137/070686445,
author = {Golab, Wojciech and Hendler, Danny and Woelfel, Philipp},
title = {An $O(1)$ RMRs Leader Election Algorithm},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/070686445},
doi = {10.1137/070686445},
abstract = {The leader election problem is a fundamental coordination problem. We present leader election algorithms for multiprocessor systems where processes communicate by reading and writing shared memory asynchronously and do not fail. In particular, we consider the cache-coherent (CC) and distributed shared memory (DSM) models of such systems. We present leader election algorithms that perform a constant number of remote memory references (RMRs) in the worst case. Our algorithms use splitter-like objects [J. Anderson and M. Moir, Sci. Comput. Programming, 25 (1995), pp. 1-39; H. Attiya and A. Fouren, Theory Comput. Syst., 31 (2001), pp. 642-664] in a novel way, by organizing active processes into teams that share work. As there is an $Omega(log n)$ lower bound on the RMR complexity of mutual exclusion for $n$ processes using reads and writes only [H. Attiya, D. Hendler, and W. Woelfel, in Proceedings of the ACM Symposium on Theory of Computing, ACM, New York, 2008, pp. 217-226], our result separates the mutual exclusion and leader election problems in terms of RMR complexity in both the CC and DSM models. Our result also implies that any algorithm using reads, writes, and one-time test-and-set objects can be simulated by an algorithm using reads and writes with only a constant blowup of the RMR complexity; proving this is easy in the CC model but presents subtle challenges in the DSM model, as we explain later. Anderson, Herman, and Kim raise the question of whether conditional primitives such as test-and-set and compare-and-swap can be used, along with reads and writes, to solve mutual exclusion with better worst-case RMR complexity than is possible using reads and writes only [Distributed Computing, 16 (2003), pp. 75-110]. We provide a negative answer to this question in the case of implementing one-time test-and-set.},
journal = {SIAM J. Comput.},
month = may,
pages = {2726–2760},
numpages = {35},
keywords = {multiprocessor, remote memory references (RMRs), distributed shared memory, synchronization, test-and-set, leader election, cache-coherent shared memory}
}

@article{10.1137/060650544,
author = {Cryan, Mary and Dyer, Martin and Randall, Dana},
title = {Approximately Counting Integral Flows and Cell-Bounded Contingency Tables},
year = {2010},
issue_date = {May 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {7},
issn = {0097-5397},
url = {https://doi.org/10.1137/060650544},
doi = {10.1137/060650544},
abstract = {We consider the problem of approximately counting integral flows in a network. We show that there is a fully polynomial randomized approximation scheme (FPRAS) based on volume estimation if all capacities are sufficiently large, generalizing a result of Dyer, Kannan, and Mount [Random Structures Algorithms, 10 (1997), pp. 487-506]. We apply this to approximating the number of contingency tables with prescribed cell bounds when the number of rows is constant, but the row sums, column sums, and cell bounds may be arbitrary. We provide an FPRAS for this problem via a combination of dynamic programming and volume estimation. This generalizes an algorithm of Cryan and Dyer [J. Comput. System Sci., 67 (2003), pp. 291-310] for standard contingency tables, but the analysis here is considerably more intricate.},
journal = {SIAM J. Comput.},
month = may,
pages = {2683–2703},
numpages = {21},
keywords = {lattice points, polytope, approximate counting, cell-bounded contingency tables, sampling}
}

@article{10.5555/1958033.1958054,
author = {Hertel, Philipp and Pitassi, Toniann},
title = {The PSPACE-Completeness of Black-White Pebbling},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {The complexity of the black-white pebbling game has remained an open problem for 30 years. In this paper we show that the black-white pebbling game is PSPACE-complete.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2622–2682},
numpages = {61},
keywords = {black pebbling, pebbling, black-white pebbling, PSPACE-completeness, complexity}
}

@article{10.5555/1958033.1958053,
author = {Gopalan, Parikshit and Khot, Subhash and Saket, Rishi},
title = {Hardness of Reconstructing Multivariate Polynomials over Finite Fields},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We study the polynomial reconstruction problem for low-degree multivariate polynomials over finite field $mathbb{F}[2]$. In this problem, we are given a set of points $mathbf{x}in{0,1}^n$ and target values $f(mathbf{x})in{0,1}$ for each of these points, with the promise that there is a polynomial over $mathbb{F}[2]$ of degree at most $d$ that agrees with $f$ at $1-varepsilon$ fraction of the points. Our goal is to find a degree $d$ polynomial that has good agreement with $f$. We show that it is NP-hard to find a polynomial that agrees with $f$ on more than $1-2^{-d}+delta$ fraction of the points for any $epsilon,delta&gt;0$. This holds even with the stronger promise that the polynomial that fits the data is in fact linear, whereas the algorithm is allowed to find a polynomial of degree $d$. Previously the only known hardness of approximation (or even NP-completeness) was for the case when $d =1$, which follows from a celebrated result of H\r{a}stad [J. ACM, 48 (2001), pp. 798-859]. In the setting of Computational Learning, our result shows the hardness of nonproper agnostic learning of parities, where the learner is allowed a low-degree polynomial over $mathbb{F}[2]$ as a hypothesis. This is the first nonproper hardness result for this central problem in computational learning. Our results can be extended to multivariate polynomial reconstruction over any finite field.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2598–2621},
numpages = {24},
keywords = {finite fields, polynomials, coding theory, hardness of approximation, computational learning}
}

@article{10.5555/1958033.1958052,
author = {Etessami, Kousha and Yannakakis, Mihalis},
title = {On the Complexity of Nash Equilibria and Other Fixed Points},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We reexamine what it means to compute Nash equilibria and, more generally, what it means to compute a fixed point of a given Brouwer function, and we investigate the complexity of the associated problems. Specifically, we study the complexity of the following problem: given a finite game, $Gamma$, with 3 or more players, and given $epsilon&gt;0$, compute an approximation within $epsilon$ of some (actual) Nash equilibrium. We show that approximation of an actual Nash equilibrium, even to within any nontrivial constant additive factor $epsilon&lt;1/2$ in just one desired coordinate, is at least as hard as the long-standing square-root sum problem, as well as a more general arithmetic circuit decision problem that characterizes P-time in a unit-cost model of computation with arbitrary precision rational arithmetic; thus, placing the approximation problem in P, or even NP, would resolve major open problems in the complexity of numerical computation.We show similar results for market equilibria: it is hard to estimate with any nontrivial accuracy the equilibrium prices in an exchange economy with a unique equilibrium, where the economy is given by explicit algebraic formulas for the excess demand functions.We define a class, FIXP, which captures search problems that can be cast as fixed point computation problems for functions represented by algebraic circuits (straight line programs) over basis ${+,*,-,/,max,min}$ with rational constants. We show that the (exact or approximate) computation of Nash equilibria for 3 or more players is complete for FIXP. The price equilibrium problem for exchange economies with algebraic demand functions is another FIXP-complete problem. We show that the piecewise linear fragment of FIXP equals PPAD.Many other problems in game theory, economics, and probability theory can be cast as fixed point problems for such algebraic functions. We discuss several important such problems: computing the value of Shapley's stochastic games and the simpler games of Condon, extinction probabilities of branching processes, probabilities of stochastic context-free grammars, and termination probabilities of recursive Markov chains. We show that for some of them, the approximation, or even exact computation, problem can be placed in PPAD, while for others, they are at least as hard as the square-root sum and arithmetic circuit decision problems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2531–2597},
numpages = {67},
keywords = {complexity, games, fixed points, market equilibria, Nash equilibria}
}

@article{10.5555/1958033.1958051,
author = {Ambainis, A. and Childs, A. M. and Reichardt, B. W. and \v{S}palek, R. and Zhang, S.},
title = {Any AND-OR Formula of Size $N$ Can Be Evaluated in Time $N^{1/2+o(1)}$ on a Quantum Computer},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {Consider the problem of evaluating an AND-OR formula on an $N$-bit black-box input. We present a bounded-error quantum algorithm that solves this problem in time $N^{1/2+o(1)}$. In particular, approximately balanced formulas can be evaluated in $O(sqrt{N})$ queries, which is optimal. The idea of the algorithm is to apply phase estimation to a discrete-time quantum walk on a weighted tree whose spectrum encodes the value of the formula.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2513–2530},
numpages = {18},
keywords = {quantum computation, quantum walk, quantum query complexity, AND-OR trees, formula evaluation}
}

@article{10.5555/1958033.1958050,
author = {Charikar, Moses and Makarychev, Konstantin and Makarychev, Yury},
title = {Local Global Tradeoffs in Metric Embeddings},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {Suppose that every $k$ points in a $n$ point metric space $X$ are $D$-distortion embeddable into $ell_1$. We give upper and lower bounds on the distortion required to embed the entire space $X$ into $ell_1$. This is a natural mathematical question and is also motivated by the study of relaxations obtained by lift-and-project methods for graph partitioning problems. In this setting, we show that $X$ can be embedded into $ell_1$ with distortion $O(Dtimeslog(n/k))$. Moreover, we give a lower bound showing that this result is tight if $D$ is bounded away from 1. For $D=1+delta$ we give a lower bound of $Omega(log(n/k)/log(1/delta))$; and for $D=1$, we give a lower bound of $Omega(log n/(log k+loglog n))$. Our bounds significantly improve on the results of Arora et al. who initiated a study of these questions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2487–2512},
numpages = {26},
keywords = {lift and project, global local properties, metric embeddings}
}

@article{10.5555/1958033.1958049,
author = {Bogdanov, Andrej and Viola, Emanuele},
title = {Pseudorandom Bits for Polynomials},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We present a new approach to constructing pseudorandom generators that fool low-degree polynomials over finite fields, based on the Gowers norm. Using this approach, we obtain the following main constructions of explicitly computable generators $G:mathbb{F}^stomathbb{F}^n$ that fool polynomials over a finite field $mathbb{F}$: We stress that the results in (1) and (2) are unconditional, i.e., do not rely on any unproven assumption. Moreover, the results in (3) rely on a special case of the conjecture which may be easier to prove.Our generator for degree-$d$ polynomials is the componentwise sum of $d$ generators for degree-1 polynomials (on independent seeds).Prior to our work, generators with logarithmic seed length were only known for degree-1 (i.e., linear) polynomials [J. Naor and M. Naor, SIAM J. Comput., 22 (1993), pp. 838-856]. In fact, over small fields such as $mathbb{F}_2={0,1}$, our results constitute the first progress on these problems since the long-standing generator by Luby, Veli\v{c}kovi\'{c}, and Wigderson [Deterministic approximate counting of depth-2 circuits, in Proceedings of the 2nd Israeli Symposium on Theoretical Computer Science (ISTCS), 1993, pp. 18-24], whose seed length is much bigger: $s=expleft(Omegaleft(sqrt{log n}right)right)$, even for the case of degree-2 polynomials over $mathbb{F}_2$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2464–2486},
numpages = {23},
keywords = {degree, polynomial, Gowers norm, pseudorandom generator, bias}
}

@article{10.5555/1958033.1958048,
author = {Austrin, Per},
title = {Towards Sharp Inapproximability for Any 2-CSP},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We continue the recent line of work on the connection between semidefinite programming (SDP)-based approximation algorithms and the unique games conjecture. Given any Boolean 2-CSP (or, more generally, any Boolean 2-CSP with real-valued “predicates”), we show how to reduce the search for a good inapproximability result to a certain numeric minimization problem. Furthermore, we give an SDP-based approximation algorithm and show that the approximation ratio of this algorithm on a certain restricted type of instances is exactly the inapproximability ratio yielded by our hardness result. We conjecture that the restricted type required for the hardness result is in fact no restriction, which would imply that these upper and lower bounds match exactly. This conjecture is supported by all existing results for specific 2-CSPs. As an application, we show that Max 2-And is unique games-hard to approximate within 0.87435. This improves upon the best previous hardness of $alpha_{GW}+epsilonapprox0.87856$ and comes very close to matching the approximation ratio of the best algorithm known, 0.87401. It also establishes that balanced instances of Max 2-And, i.e., instances in which each variable occurs positively and negatively equally often, are not the hardest to approximate, as these can be approximated within a factor $alpha_{GW}$ and that Max Cut is not the hardest 2-CSP.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2430–2463},
numpages = {34},
keywords = {approximation algorithms, unique games conjecture, constraint satisfaction problems, semidefinite programming}
}

@article{10.5555/1958033.1958047,
author = {Andoni, Alexandr and Krauthgamer, Robert},
title = {The Computational Hardness of Estimating Edit Distance},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We prove the first nontrivial communication complexity lower bound for the problem of estimating the edit distance (aka Levenshtein distance) between two strings. To the best of our knowledge, this is the first computational setting in which the complexity of estimating the edit distance is provably larger than that of Hamming distance. Our lower bound exhibits a trade-off between approximation and communication, asserting, for example, that protocols with $O(1)$ bits of communication can obtain only approximation $alphageqOmega(log d/loglog d)$, where $d$ is the length of the input strings. This case of $O(1)$ communication is of particular importance since it captures constant-size sketches as well as embeddings into spaces like $l_1$ and squared-$l_2$, two prevailing algorithmic approaches for dealing with edit distance. Indeed, the known nontrivial communication upper bounds are all derived from embeddings into $l_1$. By excluding low-communication protocols for edit distance, we rule out a strictly richer class of algorithms than previous results. Furthermore, our lower bound holds not only for strings over a binary alphabet but also for strings that are permutations (aka the Ulam metric). For this case, our bound nearly matches an upper bound known via embedding the Ulam metric into $l_1$. Our proof uses a new technique that relies on Fourier analysis in a rather elementary way.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2398–2429},
numpages = {32},
keywords = {Fourier analysis, edit distance, embedding, communication complexity, sketching, Ulam metric}
}

@article{10.5555/1958033.1958046,
author = {Lee, James R. and Umans, Chris},
title = {Special Section On Foundations of Computer Science},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {This special section comprises eight fully refereed papers whose extended abstracts were presented at the 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2007) in Providence, Rhode Island, October 21-23, 2007. The unrefereed conference versions of these papers were published by IEEE in the FOCS 2007 proceedings.The regular conference program consisted of 63 papers chosen from among 302 submissions. These were selected by a program committee consisting of Dimitris Achlioptas, Timothy Chan, Julia Chuzhoy, Faith Ellen, Piotr Indyk, Kamal Jain, T. S. Jayram, Robert Kleinberg, James R. Lee, Anna Lysyanskaya, Daniele Micciancio, Gary Miller, Moni Naor, Alexander Razborov, Yaoyun Shi, Alistair Sinclair (chair), Luca Trevisan, Chris Umans, and Uri Zwick. The papers invited to this special section were also selected with the input of the program committee.The eight papers in this section span a broad range of topics, including algorithmic game theory, communication complexity, hardness of approximation, metric embeddings, proof complexity, pseudorandomness, and quantum algorithms. Each paper underwent an extensive refereeing process; we thank both the authors and the anonymous referees for their efforts. In addition, we would like to thank Eva Tardos, who was SICOMP's editor-in-chief during the course of this project, and SIAM staff members Mitch Chernoff and Cherie Trebisky for their help in preparing this special section.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2397},
numpages = {1}
}

@article{10.5555/1958033.1958045,
author = {Moore, Cristopher and Russell, Alexander and undefinedniady, Piotr},
title = {On the Impossibility of a Quantum Sieve Algorithm for Graph Isomorphism},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {It is known that any quantum algorithm for graph isomorphism that works within the framework of the hidden subgroup problem (HSP) must perform highly entangled measurements across $Omega(nlog n)$ coset states. One of the only known models for how such a measurement could be carried out efficiently is Kuperberg's algorithm for the HSP in the dihedral group, in which quantum states are adaptively combined and measured according to the decomposition of tensor products into irreducible representations. This “quantum sieve” starts with coset states and works its way down toward representations whose probabilities differ depending on, for example, whether the hidden subgroup is trivial or nontrivial. In this paper we show that no such approach can produce a polynomial-time quantum algorithm for graph isomorphism. Specifically, we consider the natural reduction of graph isomorphism to the HSP over the wreath product $S_nwrmathbb{Z}_2$. Using a recently proved bound on the irreducible characters of $S_n$, we show that no algorithm in this family can solve graph isomorphism in less than $mathrm{e}^{Omega(sqrt{n})}$ time, no matter what adaptive rule it uses to select and combine quantum states. In particular, algorithms of this type can offer essentially no improvement over the best known classical algorithms, which run in time $mathrm{e}^{O(sqrt{nlog n})}$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2377–2396},
numpages = {20},
keywords = {quantum computing, symmetric group, graph isomorphism, algorithm, representation theory}
}

@article{10.5555/1958033.1958044,
author = {Roditty, Liam},
title = {On the $k$ Shortest Simple Paths Problem in Weighted Directed Graphs},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We present the first approximation algorithm for finding the $k$ shortest simple paths connecting a pair of vertices in a weighted directed graph that breaks the barrier of $mn$. It is deterministic and has a running time of $O(k(msqrt{n}+n^{3/2}log n))$, where $m$ is the number of edges in the graph and $n$ is the number of vertices. Let $s,tin V$; the length of the $i$th simple path from $s$ to $t$ computed by our algorithm is at most $frac{3}{2}$ times the length of the $i$th shortest simple path from $s$ to $t$. The best algorithms for computing the exact $k$ shortest simple paths connecting a pair of vertices in a weighted directed graph are due to Yen [Management Sci., 17 (1970/1971), pp. 712-716] and Lawler [Management Sci., 18 (1971/1972), pp. 401-405]. The running time of their algorithms, using modern data structures, is $O(k(mn+n^2log n))$. Both algorithms are from the early 70s. Although this problem and other variants of the $k$ shortest path problem has drawn a lot of attention during the last three and a half decades, the $O(k(mn+n^2log n))$ bound is still unbeaten.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2363–2376},
numpages = {14},
keywords = {graph algorithms, second shortest path, $k$ shortest simple path, shortest path}
}

@article{10.5555/1958033.1958043,
author = {Alon, Noga and Coja-Oghlan, Amin and H\`{a}n, Hi\^{e}p and Kang, Mihyun and R\"{o}dl, Vojt\v{e}ch and Schacht, Mathias},
title = {Quasi-Randomness and Algorithmic Regularity for Graphs with General Degree Distributions},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We deal with two intimately related subjects: quasi-randomness and regular partitions. The purpose of the concept of quasi-randomness is to express how much a given graph “resembles” a random one. Moreover, a regular partition approximates a given graph by a bounded number of quasi-random graphs. Regarding quasi-randomness, we present a new spectral characterization of low discrepancy, which extends to sparse graphs. Concerning regular partitions, we introduce a concept of regularity that takes into account vertex weights, and show that if $G=(V,E)$ satisfies a certain boundedness condition, then $G$ admits a regular partition. In addition, building on the work of Alon and Naor [Proceedings of the 36th ACM Symposium on Theory of Computing (STOC), Chicago, IL, ACM, New York, 2004, pp. 72-80], we provide an algorithm that computes a regular partition of a given (possibly sparse) graph $G$ in polynomial time. As an application, we present a polynomial time approximation scheme for MAX CUT on (sparse) graphs without “dense spots.”},
journal = {SIAM J. Comput.},
month = apr,
pages = {2336–2362},
numpages = {27},
keywords = {Laplacian eigenvalues, Grothendieck's inequality, regularity lemma, quasi-random graphs}
}

@article{10.5555/1958033.1958042,
author = {Esparza, Javier and Kiefer, Stefan and Luttenberger, Michael},
title = {Computing the Least Fixed Point of Positive Polynomial Systems},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We consider equation systems of the form $X_1=f_1(X_1,dots,X_n)$, $dots$, $X_n = f_n(X_1,dots,X_n)$, where $f_1,dots,f_n$ are polynomials with positive real coefficients. In vector form we denote such an equation system by ${bf X}={bf f}({bf X})$ and call ${bf f}$ a system of positive polynomials (SPP). Equation systems of this kind appear naturally in the analysis of stochastic models like stochastic context-free grammars (with numerous applications to natural language processing and computational biology), probabilistic programs with procedures, web-surfing models with back buttons, and branching processes. The least nonnegative solution $mu{bf f}$ of an SPP equation ${bf X}={bf f}({bf X})$ is of central interest for these models. Etessami and Yannakakis [J. ACM, 56 (2009), pp. 1-66] have suggested a particular version of Newton's method to approximate $mu{bf f}$. We extend a result of Etessami and Yannakakis and show that Newton's method starting at ${bf 0}$ always converges to $mu{bf f}$. We obtain lower bounds on the convergence speed of the method. For so-called strongly connected SPPs we prove the existence of a threshold $k_{{bf f}}inmathbb{N}$ such that for every $igeq0$ the $(k_{{bf f}}+i)$th iteration of Newton's method has at least $i$ valid bits of $mu{bf f}$. The proof yields an explicit bound for $k_{{bf f}}$ depending only on syntactic parameters of ${bf f}$. We further show that for arbitrary SPP equations, Newton's method still converges linearly: there exists a threshold $k_{{bf f}}$ and an $alpha_{{bf f}}&gt;0$ such that for every $igeq0$ the $(k_{{bf f}}+alpha_{{bf f}}cdot i)$th iteration of Newton's method has at least $i$ valid bits of $mu{bf f}$. The proof yields an explicit bound for $alpha_{{bf f}}$; the bound is exponential in the number of equations in ${bf X}={bf f}({bf X})$, but we also show that it is essentially optimal. The proof does not yield any bound for $k_{{bf f}}$, but only proves its existence. Constructing a bound for $k_{{bf f}}$ is still an open problem. Finally, we also provide a geometric interpretation of Newton's method for SPPs.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2282–2335},
numpages = {54},
keywords = {numerical analysis, fixed-point equations, convergence speed, Newton's method, polynomial equations}
}

@article{10.5555/1958033.1958041,
author = {Fischer, Eldar and Magniez, Fr\'{e}d\'{e}ric and de Rougemont, Michel},
title = {Approximate Satisfiability and Equivalence},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {Inspired by property testing, for every $varepsilon&gt;0$ we relax the classical satisfiability $Umodels F$ between a finite structure $U$ of a class $mathbf{K}$ and a formula $F$, to a notion of $varepsilon$-satisfiability $Umodels_{varepsilon}F$, and relax the classical equivalence $F_1equiv F_2$ between two formulas $F_1$ and $F_2$ to $varepsilon$-equivalence $F_1equiv_{varepsilon}F_2$. We consider strings and trees with the norm of the edit distance with moves, and show that, unlike their exact counterparts, these approximate notions can be efficiently decided. We use a statistical embedding of words (resp., trees) into $ell_1$, which generalizes the original Parikh mapping, obtained by sampling $O(f(varepsilon))$ finite samples of the words (resp., trees). We give a tester for equality and membership in any regular language, in time independent of the size of the structure. Using our geometrical embedding, we can also test the equivalence between two regular properties over words, defined by regular expressions or monadic second-order formulas. Our equivalence tester has polynomial time complexity in the size of the automaton (or regular expression), for any fixed $varepsilon$, whereas the exact version of the equivalence problem is PSPACE-complete. We also prove versions of some of these results for trees, but with worse time complexity. Last, we extend the geometric embedding, and hence the testing algorithms, to infinite regular languages and to context-free languages. For context-free languages, the equivalence tester has an exponential time complexity for any fixed $varepsilon$, whereas the exact version is not even decidable.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2251–2281},
numpages = {31},
keywords = {approximation, equivalence testing, automata}
}

@article{10.5555/1958033.1958040,
author = {Chierichetti, Flavio and Vattani, Andrea},
title = {The Local Nature of List Colorings for Graphs of High Girth},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We consider list coloring problems for graphs $mathcal{G}$ of girth larger than $clog_{Delta-1}n$, where $n$ and $Deltageq3$ are, respectively, the order and the maximum degree of $mathcal{G}$, and $c$ is a suitable constant. First, we determine that the edge and total list chromatic numbers of these graphs are $chi'_l(mathcal{G})=Delta$ and $chi”_l(mathcal{G})=Delta+1$. This proves that the general conjectures of Bollob\'{a}s and Harris [Graphs Combin., 1 (1985), pp. 115-127], Behzad [The total chromatic number, in Combinatorial Mathematics and Its Applications (Proc. Conf., Oxford, 1969), Academic Press, London, 1971, pp. 1-8], Vizing [Diskret. Analiz., 3 (1964), pp. 25-30], and Juvan, Mohar, and \v{S}krekovski [Combin. Probab. Comput., 7 (1998), pp. 181-188] hold for this particular class of graphs. Moreover, our proofs exhibit a certain degree of “locality,” which we exploit to obtain an efficient distributed algorithm able to compute both kinds of optimal list colorings. Also, using an argument similar to one of Erd\"{o}s, we show that our algorithm can compute $k$-list vertex colorings of graphs having girth larger than $clog_{k-1}n$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2232–2250},
numpages = {19},
keywords = {graph coloring, algorithms, girth}
}

@article{10.5555/1958033.1958039,
author = {Byrka, Jaroslaw and Aardal, Karen},
title = {An Optimal Bifactor Approximation Algorithm for the Metric Uncapacitated Facility Location Problem},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We obtain a 1.5-approximation algorithm for the metric uncapacitated facility location (UFL) problem, which improves on the previously best known 1.52-approximation algorithm by Mahdian, Ye, and Zhang. Note that the approximability lower bound by Guha and Khuller is $1.463dots$. An algorithm is a ($lambda_f$,$lambda_c$)-approximation algorithm if the solution it produces has total cost at most $lambda_fcdot F^*+lambda_ccdot C^*$, where $F^*$ and $C^*$ are the facility and the connection cost of an optimal solution. Our new algorithm, which is a modification of the $(1+2/e)$-approximation algorithm of Chudak and Shmoys, is a $(1.6774,1.3738)$-approximation algorithm for the UFL problem and is the first one that touches the approximability limit curve $(gamma_f,1+2e^{-gamma_f})$ established by Jain, Mahdian, and Saberi. As a consequence, we obtain the first optimal approximation algorithm for instances dominated by connection costs. When combined with a $(1.11,1.7764)$-approximation algorithm proposed by Jain et al., and later analyzed by Mahdian et al., we obtain the overall approximation guarantee of 1.5 for the metric UFL problem. We also describe how to use our algorithm to improve the approximation ratio for the 3-level version of UFL.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2212–2231},
numpages = {20},
keywords = {facility location, LP-rounding, approximation algorithms}
}

@article{10.5555/1958033.1958038,
author = {Chakrabarty, Deeparnab and Goel, Gagan},
title = {On the Approximability of Budgeted Allocations and Improved Lower Bounds for Submodular Welfare Maximization and GAP},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {In this paper we consider the following maximum budgeted allocation (MBA) problem: Given a set of $m$ indivisible items and $n$ agents, with each agent $i$ willing to pay $b_{ij}$ on item $j$ and with a maximum budget of $B_i$, the goal is to allocate items to agents to maximize revenue. The problem naturally arises as auctioneer revenue maximization in budget-constrained auctions and as the winner determination problem in combinatorial auctions when utilities of agents are budgeted-additive. Our main results are as follows: (i) We give a $3/4$-approximation algorithm for MBA improving upon the previous best of $simeq0.632$ [N. Andelman and Y. Mansour, Proceedings of the 9th Scandinavian Workshop on Algorithm Theory (SWAT), 2004, pp. 26-38], [J. Vondr\'{a}k, Proceedings of the 40th Annual ACM Symposium on the Theory of Computing (STOC), 2008, pp. 67-74] (also implied by the result of [U. Feige and J. Vondr\'{a}k, Proceedings of the 47th IEEE Symposium on Foundations of Computer Science (FOCS), 2006, pp. 667-676]). Our techniques are based on a natural LP relaxation of MBA, and our factor is optimal in the sense that it matches the integrality gap of the LP. (ii) We prove it is NP-hard to approximate MBA to any factor better than $15/16$; previously only NP-hardness was known [T. Sandholm and S. Suri, Games Econom. Behav., 55 (2006), pp. 321-330], [B. Lehmann, D. Lehmann, and N. Nisan, Proceedings of the 3rd ACM Conference on Electronic Commerce (EC), 2001, pp. 18-28]. Our result also implies NP-hardness of approximating maximum submodular welfare with demand oracle to a factor better than $15/16$, improving upon the best known hardness of $275/276$ [U. Feige and J. Vondr\'{a}k, Proceedings of the 47th IEEE Symposium on Foundations of Computer Science (FOCS), 2006, pp. 667-676]. (iii) Our hardness techniques can be modified to prove that it is NP-hard to approximate the generalized assignment problem (GAP) to any factor better than $10/11$. This improves upon the $422/423$ hardness of [C. Chekuri and S. Khanna, Proceedings of the 11th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2000, pp. 213-222], [M. Chleb\'{\i}k and J. Chleb\'{\i}kov\'{a}, Proceedings of the 8th Scandinavian Workshop on Algorithm Theory (SWAT), 2002, pp. 170-179]. We use iterative rounding on a natural LP relaxation of the MBA problem to obtain the $3/4$-approximation. We also give a $(3/4-epsilon)$-factor algorithm based on the primal-dual schema which runs in $tilde{O}(nm)$ time, for any constant $epsilon&gt;0$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2189–2211},
numpages = {23},
keywords = {allocation problems, approximation algorithms, linear programs}
}

@article{10.5555/1958033.1958037,
author = {Mossel, Elchanan and Roch, Sebastien},
title = {Submodularity of Influence in Social Networks: From Local to Global},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {Social networks are often represented as directed graphs, where the nodes are individuals and the edges indicate a form of social relationship. A simple way to model the diffusion of ideas, innovative behavior, or “word-of-mouth” effects on such a graph is to consider an increasing process of “infected” (or active) nodes: each node becomes infected once an activation function of the set of its infected neighbors crosses a certain threshold value. Such a model was introduced by Kempe, Kleinberg, and Tardos (KKT) in [Maximizing the spread of influence through a social network, in Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2003, pp. 137-146] and [Influential nodes in a diffusion model for social networks, in Proceedings of the 32nd International Colloquium on Automata, Languages and Programming (ICALP), 2005], where the authors also impose several natural assumptions: the threshold values are random and the activation functions are monotone and submodular. The monotonicity condition indicates that a node is more likely to become active if more of its neighbors are active, while the submodularity condition indicates that the marginal effect of each neighbor is decreasing when the set of active neighbors increases. For an initial set of active nodes $S$, let $sigma(S)$ denote the expected number of active nodes at termination. Here, we prove a conjecture of KKT: we show that the function $sigma(S)$ is submodular under the assumptions above. We prove the same result for the expected value of any monotone, submodular function of the set of active nodes at termination. Roughly, our results demonstrate that “local” submodularity is preserved “globally” under this diffusion process. This is of natural computational interest, as many optimization problems have good approximation algorithms for submodular functions.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2176–2188},
numpages = {13},
keywords = {viral marketing, social networks, submodularity, coupling method, growth process}
}

@article{10.5555/1958033.1958036,
author = {De Marco, Gianluca},
title = {Distributed Broadcast in Unknown Radio Networks},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We consider the problem of broadcasting in an unknown radio network modeled as a directed graph $G=(V,E)$, where $|V|=n$. In unknown networks, every node knows only its own label, while it is unaware of any other parameter of the network, including its neighborhood and even any upper bound on the number of nodes. We show an $mathcal{O}(nlog nloglog n)$ upper bound on the time complexity of deterministic broadcasting. This is an improvement over the currently best upper bound $mathcal{O}(nlog^2n)$ for arbitrary networks, thus shrinking exponentially the existing gap between the lower bound $Omega(nlog n)$ and the upper bound from $mathcal{O}(log n)$ to $mathcal{O}(loglog n)$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2162–2175},
numpages = {14},
keywords = {communication networks, distributed algorithms, probabilistic methods}
}

@article{10.5555/1958033.1958035,
author = {Kanj, Iyad A. and Perkovi\'{c}, Ljubomir and Xia, Ge},
title = {On Spanners and Lightweight Spanners of Geometric Graphs},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {We consider the problem of computing spanners of Euclidean and unit disk graphs embedded in the two-dimensional Euclidean plane. We are particularly interested in spanners that possess useful properties such as planarity, bounded degree, and/or light weight. Such spanners have been extensively studied in the area of computational geometry and have been used as the building block for constructing efficient and reliable wireless network communication topologies. We study the above problem under two computational models: the centralized and the distributed model. In the distributed model we focus on algorithms that are local. Such algorithms are suitable for the relevant applications (e.g., wireless computing). Under the centralized model, we present an $O(nlg n)$ time algorithm that computes a bounded-degree plane spanner of a complete Euclidean graph, where $n$ is the number of points in the graph. Both upper bounds on the degree and the stretch factor significantly improve the previous bounds. We extend this algorithm to compute a bounded-degree plane lightweight spanner of a complete Euclidean graph. Under the distributed model, we give the first local algorithm for computing a spanner of a unit disk graph that is of bounded degree and plane. The upper bounds on the degree, stretch factor, and the locality of the algorithm dramatically improve the previous results, as shown in the paper. This algorithm can also be extended to compute a bounded-degree plane lightweight spanner of a unit disk graph. Our algorithms rely on structural and geometric results that we develop in this paper.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2132–2161},
numpages = {30},
keywords = {local distributed algorithms, spanners, lightweight, bounded degree, Delaunay triangulations, unit disk graphs}
}

@article{10.5555/1958033.1958034,
author = {Braverman, Vladimir and Ostrovsky, Rafail},
title = {Effective Computations on Sliding Windows},
year = {2010},
issue_date = {March 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {6},
issn = {0097-5397},
abstract = {In the streaming model, elements arrive sequentially and can be observed only once. Maintaining statistics and aggregates is an important and nontrivial task in this model. These tasks become even more challenging in the sliding windows model, where statistics must be maintained only over the most recent $n$ elements. In their pioneering paper, Datar et al. [SIAM J. Comput., 31 (2002), pp. 1794-1813] presented the exponential histogram, an effective method for estimating statistics on sliding windows. In this paper we present a novel smooth histogram method that is more general and achieves stronger bounds than the exponential histogram. In particular, the smooth histogram method improves the approximation error rate obtained via exponential histograms. Furthermore, the smooth histogram method not only captures and improves multiple previous results on sliding windows but also extends the class of functions that can be approximated on sliding windows. In particular, we provide the first approximation algorithms for the following functions: $L_p$ norms, frequency moments, the length of the increasing subsequence, and the geometric mean.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2113–2131},
numpages = {19},
keywords = {smooth histograms, data streams, randomized algorithms, sliding windows}
}

@article{10.5555/1958016.1958032,
author = {Kushilevitz, Eyal and Lindell, Yehuda and Rabin, Tal},
title = {Information-Theoretically Secure Protocols and Security under Composition},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We investigate the question of whether the security of protocols in the information-theoretic setting (where the adversary is computationally unbounded) implies the security of these protocols under concurrent composition. This question is motivated by the folklore that all known protocols that are secure in the information-theoretic setting are indeed secure under concurrent composition. We provide answers to this question for a number of different settings (i.e., considering perfect versus statistical security, and concurrent composition with adaptive versus fixed inputs). Our results enhance the understanding of what is necessary for obtaining security under composition, as well as providing tools (i.e., composition theorems) that can be used for proving the security of protocols under composition while considering only the standard stand-alone definitions of security.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2090–2112},
numpages = {23},
keywords = {security under composition, information-theoretic security, theory of cryptography, secure multiparty computation}
}

@article{10.5555/1958016.1958031,
author = {Chan, Timothy M.},
title = {More Algorithms for All-Pairs Shortest Paths in Weighted Graphs},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {In the first part of the paper, we reexamine the all-pairs shortest path (APSP) problem and present a new algorithm with running time $O(n^3log^3log n/log^2n)$, which improves all known algorithms for general real-weighted dense graphs. In the second part of the paper, we use fast matrix multiplication to obtain truly subcubic APSP algorithms for a large class of “geometrically weighted” graphs, where the weight of an edge is a function of the coordinates of its vertices. For example, for graphs embedded in Euclidean space of a constant dimension $d$, we obtain a time bound near $O(n^{3-(3-omega)/(2d+4)})$, where $omega&lt;2.376$; in two dimensions, this is $O(n^{2.922})$. Our framework greatly extends the previously considered case of small-integer-weighted graphs, and incidentally also yields the first truly subcubic result (near $O(n^{3-(3-omega)/4})=O(n^{2.844})$ time) for APSP in real-vertex-weighted graphs, as well as an improved result (near $O(n^{(3+omega)/2})=O(n^{2.688})$ time) for the all-pairs lightest shortest path problem for small-integer-weighted graphs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2075–2089},
numpages = {15},
keywords = {matrix multiplication, graph algorithms, shortest paths, computational geometry}
}

@article{10.5555/1958016.1958030,
author = {Cohen, Edith and Kaplan, Haim and Milo, Tova},
title = {Labeling Dynamic XML Trees},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We consider online algorithms to label the nodes of an XML tree which is subject to insertions and deletions of nodes. The labeling is done such that (1) each node is assigned a label immediately when it is inserted and this label remains unchanged, and (2) from a pair of labels alone, one can decide whether one node is an ancestor of the other. This problem arises in the context of XML databases that support queries on the structure of the documents as well as on the changes made to the documents over time. We consider here the length of the assigned labels. We prove lower bounds on the length of labels which satisfy these requirements and provide labeling algorithms that match these bounds (up to a constant factor). We also consider the same problem when “clues” that provide guarantees on possible future insertions are given together with newly inserted nodes. Such clues can be derived from the DTD/XML Schema or from statistics on similar XML trees. We present algorithms that use the clues to assign shorter labels. We also prove that the length of our labels is close to the minimum possible.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2048–2074},
numpages = {27},
keywords = {labeling schemes, XML, ancestor queries, updates}
}

@article{10.5555/1958016.1958029,
author = {Matulef, Kevin and O'Donnell, Ryan and Rubinfeld, Ronitt and Servedio, Rocco A.},
title = {Testing Halfspaces},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {This paper addresses the problem of testing whether a Boolean-valued function $f$ is a halfspace, i.e., a function of the form $f(x)=mathrm{sgn}(wcdot x-theta)$. We consider halfspaces over the continuous domain $mathbf{R}^n$ (endowed with the standard multivariate Gaussian distribution) as well as halfspaces over the Boolean cube ${-1,1}^n$ (endowed with the uniform distribution). In both cases we give an algorithm that distinguishes halfspaces from functions that are $epsilon$-far from any halfspace using only $mathrm{poly}(frac{1}{epsilon})$ queries, independent of the dimension $n$. Two simple structural results about halfspaces are at the heart of our approach for the Gaussian distribution: The first gives an exact relationship between the expected value of a halfspace $f$ and the sum of the squares of $f$'s degree-1 Hermite coefficients, and the second shows that any function that approximately satisfies this relationship is close to a halfspace. We prove analogous results for the Boolean cube ${-1,1}^n$ (with Fourier coefficients in place of Hermite coefficients) for balanced halfspaces in which all degree-1 Fourier coefficients are small. Dealing with general halfspaces over ${-1,1}^n$ poses significant additional complications and requires other ingredients. These include “cross-consistency” versions of the results mentioned above for pairs of halfspaces with the same weights but different thresholds; new structural results relating the largest degree-1 Fourier coefficient and the largest weight in unbalanced halfspaces; and algorithmic techniques from recent work on testing juntas [E. Fischer, G. Kindler, D. Ron, S. Safra, and A. Samorodnitsky, Proceedings of the 43rd IEEE Symposium on Foundations of Computer Science, 2002, pp. 103-112].},
journal = {SIAM J. Comput.},
month = feb,
pages = {2004–2047},
numpages = {44},
keywords = {halfspaces, Fourier analysis, property testing, linear threshold functions}
}

@article{10.5555/1958016.1958028,
author = {Kaufman, Tali and Litsyn, Simon and Xie, Ning},
title = {Breaking the $\epsilon$-Soundness Bound of the Linearity Test over GF(2)},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {For Boolean functions that are $epsilon$-far from the set of linear functions, we study the lower bound on the rejection probability (denoted by $textsc{rej}(epsilon)$) of the linearity test suggested by Blum, Luby, and Rubinfeld [J. Comput. System Sci., 47 (1993), pp. 549-595]. This problem is arguably the most fundamental and extensively studied problem in property testing of Boolean functions. The previously best bounds for $textsc{rej}(epsilon)$ were obtained by Bellare et al. [IEEE Trans. Inform. Theory, 42 (1996), pp. 1781-1795]. They used Fourier analysis to show that $textsc{rej}(epsilon)geqepsilon$ for every $0leqepsilonleq1/2$. They also conjectured that this bound might not be tight for $epsilon$'s which are close to $1/2$. In this paper we show that this indeed is the case. Specifically, we improve the lower bound of $textsc{rej}(epsilon)geqepsilon$ by an additive constant that depends only on $epsilon$: $textsc{rej}(epsilon)geqepsilon+min{1376epsilon^{3}(1-2epsilon)^{12},frac{1}{4}epsilon(1-2epsilon)^{4}}$, for every $0leqepsilonleq1/2$. Our analysis is based on a relationship between $textsc{rej}(epsilon)$ and the weight distribution of a coset code of the Hadamard code. We use both Fourier analysis and coding theory tools to estimate this weight distribution.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1988–2003},
numpages = {16},
keywords = {property testing, coding theory, linearity test, Fourier analysis}
}

@article{10.5555/1958016.1958027,
author = {Czumaj, Artur and Krysta, Piotr and V\"{o}cking, Berthold},
title = {Selfish Traffic Allocation for Server Farms},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We study the price of selfish routing in noncooperative networks like the Internet. In particular, we investigate the price of selfish routing using the price of anarchy (a.k.a. the coordination ratio) and other (e.g., bicriteria) measures in the recently introduced game theoretic parallel links network model of Koutsoupias and Papadimitriou. We generalize this model toward general, monotone families of cost functions and cost functions from queueing theory. A summary of our main results for general, monotone cost functions is as follows: 1. We give an exact characterization of all cost functions having a bounded/unbounded price of anarchy. For example, the price of anarchy for cost functions describing the expected delay in queueing systems is unbounded. 2. We show that an unbounded price of anarchy implies an extremely high performance degradation under bicriteria measures. In fact, the price of selfish routing can be as high as a bandwidth degradation by a factor that is linear in the network size. 3. We separate the game theoretic (integral) allocation model from the (fractional) flow model by demonstrating that even a very small or negligible amount of integrality can lead to a dramatic performance degradation. 4. We unify recent results on selfish routing under different objectives by showing that an unbounded price of anarchy under the min-max objective implies an unbounded price of anarchy under the average cost objective and vice versa. Our special focus lies on cost functions describing the behavior of Web servers that can open only a limited number of Transmission Control Protocol (TCP) connections. In particular, we compare the performance of queueing systems that serve all incoming requests with servers that reject requests in case of overload. Our analysis indicates that all queueing systems without rejection cannot give any reasonable guarantee on the expected delay of requests under selfish routing even when the injected load is far away from the capacity of the system. In contrast, Web server farms that are allowed to reject requests can guarantee a high quality of service for every individual request stream even under relatively high injection rates.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1957–1987},
numpages = {31},
keywords = {traffic allocation, server farms, game theory, selfish routing, price of anarchy}
}

@article{10.5555/1958016.1958026,
author = {Fomin, Fedor V. and Golovach, Petr A. and Lokshtanov, Daniel and Saurabh, Saket},
title = {Intractability of Clique-Width Parameterizations},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We show that Edge Dominating Set, Hamiltonian Cycle, and Graph Coloring are $W[1]$-hard parameterized by clique-width. It was an open problem, explicitly mentioned in several papers, whether any of these problems is fixed parameter tractable when parameterized by the clique-width, that is, solvable in time $g(k)cdot n^{O(1)}$ on $n$-vertex graphs of clique-width $k$, where $g$ is some function of $k$ only. Our results imply that the running time $O(n^{f(k)})$ of many clique-width-based algorithms is essentially the best we can hope for (up to a widely believed assumption from parameterized complexity, namely $FPTneq W[1]$).},
journal = {SIAM J. Comput.},
month = feb,
pages = {1941–1956},
numpages = {16},
keywords = {clique-width, Hamiltonian cycle, parameterized complexity, edge domination, chromatic number, tree-width}
}

@article{10.5555/1958016.1958025,
author = {Chakrabarti, Amit and Regev, Oded},
title = {An Optimal Randomized Cell Probe Lower Bound for Approximate Nearest Neighbor Searching},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We consider the approximate nearest neighbor search problem on the Hamming cube ${0,1}^d$. We show that a randomized cell probe algorithm that uses polynomial storage and word size $d^{O(1)}$ requires a worst case query time of $Omega({rm log},{rm log},d/{rm log},{rm log},{rm log},d)$. The approximation factor may be as loose as $2^{{rm log}^{1-eta}d}$ for any fixed $eta&gt;0$. Our result fills a major gap in the study of this problem since all earlier lower bounds either did not allow randomization [A. Chakrabarti et al., A lower bound on the complexity of approximate nearest-neighbor searching on the Hamming cube, in Discrete and Computational Geometry, Springer, Berlin, 2003, pp. 313-328; D. Liu, Inform. Process. Lett., 92 (2004), pp. 23-29] or did not allow approximation [A. Borodin, R. Ostrovsky, and Y. Rabani, Proceedings of the 31st Annual ACM Symposium on Theory of Computing, 1999, pp. 312-321; O. Barkol and Y. Rabani, Proceedings of the 32nd Annual ACM Symposium on Theory of Computing, 2000, pp. 388-396; T. S. Jayram et al., J. Comput. System Sci., 69 (2004), pp. 435-447]. We also give a cell probe algorithm that proves that our lower bound is optimal. Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the “richness technique” [P. B. Miltersen et al., J. Comput. System Sci., 57 (1998), pp. 37-49] used in a lot of recent research around this problem would not have helped here. Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [A. Chakrabarti et al., Proceedings of the 42nd Annual IEEE Symposium on Foundations of Computer Science, 2001, pp. 270-278; Z. Bar-Yossef et al., Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002, pp. 209-218; P. Sen, Proceedings of the 18th Annual IEEE Conference on Computational Complexity, 2003, pp. 73-83; R. Jain, J. Radhakrishnan, and P. Sen, Proceedings of the 30th International Colloquium on Automata, Languages and Programming, 2003, pp. 300-315].},
journal = {SIAM J. Comput.},
month = feb,
pages = {1919–1940},
numpages = {22},
keywords = {round elimination, nearest neighbor search, cell probe model}
}

@article{10.5555/1958016.1958024,
author = {Cheng, Siu-Wing and Na, Hyeon-Suk and Vigneron, Antoine and Wang, Yajun},
title = {Querying Approximate Shortest Paths in Anisotropic Regions},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We present a data structure for answering approximate shortest path queries in a planar subdivision from a fixed source. Let $rhogeqslant1$ be a real number. Distances in each face of this subdivision are measured by a possibly asymmetric convex distance function whose unit disk is contained in a concentric unit Euclidean disk and contains a concentric Euclidean disk with radius $1/rho$. Different convex distance functions may be used for different faces, and obstacles are allowed. Let $varepsilon$ be any number strictly between 0 and 1. Our data structure returns a $(1+varepsilon)$ approximation of the shortest path cost from the fixed source to a query destination in $O(logfrac{rho n}{varepsilon})$ time. Afterwards, a $(1+varepsilon)$-approximate shortest path can be reported in $O(log n)$ time plus the complexity of the path. The data structure uses $O(frac{rho^2n^3}{varepsilon^2}logfrac{rho n}{varepsilon})$ space and can be built in $O(frac{rho^2n^3}{varepsilon^2}(logfrac{rho n}{varepsilon})^2)$ time. Our time and space bounds do not depend on any other parameter; in particular, they do not depend on any geometric parameter of the subdivision such as the minimum angle.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1888–1918},
numpages = {31},
keywords = {convex distance functions, anisotropic regions, shortest path, approximation algorithms}
}

@article{10.5555/1958016.1958023,
author = {Rao, Satish and Zhou, Shuheng},
title = {Edge Disjoint Paths in Moderately Connected Graphs},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We study the edge disjoint paths (EDP) problem in undirected graphs: Given a graph $G$ with $n$ nodes and a set $mathcal{T}$ of pairs of terminals, connect as many terminal pairs as possible using paths that are mutually edge disjoint. This leads to a variety of classic NP-complete problems, for which approximability is not well understood. We show a polylogarithmic approximation algorithm for the undirected EDP problem in general graphs with a moderate restriction on graph connectivity; we require the global minimum cut of $G$ to be $Omega(log^5n)$. Previously, constant or polylogarithmic approximation algorithms were known for trees with parallel edges, expanders, grids, grid-like graphs, and, most recently, even-degree planar graphs. These graphs either have special structure (e.g., they exclude minors) or have large numbers of short disjoint paths. Our algorithm extends previous techniques in that it applies to graphs with high diameters and asymptotically large minors.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1856–1887},
numpages = {32},
keywords = {edge disjoint paths, polylogarithmic approximation, random sampling in cuts}
}

@article{10.5555/1958016.1958022,
author = {Razborov, Alexander A. and Sherstov, Alexander A.},
title = {The Sign-Rank of AC$^0$},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {The sign-rank of a matrix $A=[A_{ij}]$ with $pm1$ entries is the least rank of a real matrix $B=[B_{ij}]$ with $A_{ij}B_{ij}&gt;0$ for all $i,j$. We obtain the first exponential lower bound on the sign-rank of a function in $mathsf{AC}^0$. Namely, let $f(x,y)=bigwedge_{i=1,dots,m}bigvee_{j=1,dots,m^2}(x_{ij}wedge y_{ij})$. We show that the matrix $[f(x,y)]_{x,y}$ has sign-rank $exp(Omega(m))$. This in particular implies that $Sigma_2^{cc}notsubseteqmathsf{UPP}^{cc}$, which solves a longstanding open problem in communication complexity posed by Babai, Frankl, and Simon [Proceedings of the 27th Symposium on Foundations of Computer Science (FOCS), 1986, pp. 337-347]. Our result additionally implies a lower bound in learning theory. Specifically, let $phi_1,dots,phi_r:{0,1}^ntomathbb{R}$ be functions such that every DNF formula $f:{0,1}^nto{-1,+1}$ of polynomial size has the representation $fequivmathrm{sgn}(a_1phi_1+dots+a_rphi_r)$ for some reals $a_1,dots,a_r$. We prove that then $rgeqslantexp(Omega(n^{1/3}))$, which essentially matches an upper bound of $exp(tilde{O}(n^{1/3}))$, due to Klivans and Servedio [J. Comput. System Sci., 68 (2004), pp. 303-318]. Finally, our work yields the first exponential lower bound on the size of threshold-of-majority circuits computing a function in $mathsf{AC}^0$. This substantially generalizes and strengthens the results of Krause and Pudl\'{a}k [Theoret. Comput. Sci., 174 (1997), pp. 137-156].},
journal = {SIAM J. Comput.},
month = jan,
pages = {1833–1855},
numpages = {23},
keywords = {communication complexity, constant-depth AND/OR/NOT circuits, $Pi_2^{cc}$, sign-rank, complexity classes $Sigma_2^{cc}$, and $mathsf{UPP}^{cc}$}
}

@article{10.5555/1958016.1958021,
author = {Chen, Ho-Lin and Roughgarden, Tim and Valiant, Gregory},
title = {Designing Network Protocols for Good Equilibria},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {Designing and deploying a network protocol determines the rules by which end users interact with each other and with the network. We consider the problem of designing a protocol to optimize the equilibrium behavior of a network with selfish users. We consider network cost-sharing games, where the set of Nash equilibria depends fundamentally on the choice of an edge cost-sharing protocol. Previous research focused on the Shapley protocol, in which the cost of each edge is shared equally among its users. We systematically study the design of optimal cost-sharing protocols for undirected and directed graphs, single-sink and multicommodity networks, and different measures of the inefficiency of equilibria. Our primary technical tool is a precise characterization of the cost-sharing protocols that induce only network games with pure-strategy Nash equilibria. We use this characterization to prove, among other results, that the Shapley protocol is optimal in directed graphs and that simple priority protocols are essentially optimal in undirected graphs.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1799–1832},
numpages = {34},
keywords = {network design, game theory, cost sharing, Nash equilibrium, price of anarchy}
}

@article{10.5555/1958016.1958020,
author = {Chekuri, C. and Hajiaghayi, M. T. and Kortsarz, G. and Salavatipour, M. R.},
title = {Approximation Algorithms for Nonuniform Buy-at-Bulk Network Design},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {Buy-at-bulk network design problems arise in settings where the costs for purchasing or installing equipment exhibit economies of scale. The objective is to build a network of cheapest cost to support a given multicommodity flow demand between node pairs. We present approximation algorithms for buy-at-bulk network design problems with costs on both edges and nodes of an undirected graph. Our main result is the first poly-logarithmic approximation ratio for the non-uniform problem that allows different cost functions on each edge and node; the ratio we achieve is $O(log^4 h)$, where $h$ is the number of demand pairs. In addition we present an $O(log h)$ approximation for the single sink problem. Poly-logarithmic ratios for some related problems are also obtained. Our algorithm for the multicommodity problem is obtained via a reduction to the single source problem using the notion of junction trees. We believe that this presents a simple yet useful general technique for network design problems.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1772–1798},
numpages = {27},
keywords = {approximation algorithm, network flow, concave cost, network design, nonuniform buy-at-bulk, economies of scale}
}

@article{10.5555/1958016.1958019,
author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
title = {$O(\sqrt{\logn})$ Approximation to SPARSEST CUT in $\tilde{O}(N^2)$ Time},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {This paper shows how to compute $O(sqrt{log n})$-approximations to the Sparsest Cut and Balanced Separator problems in $tilde{O}(n^2)$ time, thus improving upon the recent algorithm of Arora, Rao, and Vazirani [Proceedings of the 36th Annual ACM Symposium on Theory of Computing, 2004, pp. 222-231]. Their algorithm uses semidefinite programming and requires $tilde{O}(n^{9.5})$ time. Our algorithm relies on efficiently finding expander flows in the graph and does not solve semidefinite programs. The existence of expander flows was also established by Arora, Rao, and Vazirani [Proceedings of the 36th Annual ACM Symposium on Theory of Computing, 2004, pp. 222-231].},
journal = {SIAM J. Comput.},
month = jan,
pages = {1748–1771},
numpages = {24},
keywords = {graph partitioning, multiplicative weights, expander flows}
}

@article{10.5555/1958016.1958018,
author = {Kirschmer, Markus and Voight, John},
title = {Algorithmic Enumeration of Ideal Classes for Quaternion Orders},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We provide algorithms to count and enumerate representatives of the (right) ideal classes of an Eichler order in a quaternion algebra defined over a number field. We analyze the run time of these algorithms and consider several related problems, including the computation of two-sided ideal classes, isomorphism classes of orders, connecting ideals for orders, and ideal principalization. We conclude by giving the complete list of definite Eichler orders with class number at most 2.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1714–1747},
numpages = {34},
keywords = {maximal orders, number theory, ideal classes, quaternion algebras}
}

@article{10.5555/1958016.1958017,
author = {Harnik, Danny and Naor, Moni},
title = {On the Compressibility of $\mathcal{NP}$ Instances and Cryptographic Applications},
year = {2010},
issue_date = {January 2010},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {5},
issn = {0097-5397},
abstract = {We study compression that preserves the solution to an instance of a problem rather than preserving the instance itself. Our focus is on the compressibility of $mathcal{NP}$ decision problems. We consider $mathcal{NP}$ problems that have long instances but relatively short witnesses. The question is whether one can efficiently compress an instance and store a shorter representation that maintains the information of whether the original input is in the language or not. We want the length of the compressed instance to be polynomial in the length of the witness and polylog in the length of original input. Such compression enables succinctly storing instances until a future setting will allow solving them, either via a technological or algorithmic breakthrough or simply until enough time has elapsed. In this paper, we first develop the basic complexity theory of compression, including reducibility, completeness, and a stratification of $mathcal{NP}$ with respect to compression. We then show that compressibility (say, of SAT) would have vast implications for cryptography, including constructions of one-way functions and collision resistant hash functions from any hard-on-average problem in $mathcal{NP}$ and cryptanalysis of key agreement protocols in the “bounded storage model” when mixed with (time) complexity-based cryptography.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1667–1713},
numpages = {47},
keywords = {collision resistant hash, NP problems, cryptography, compression, bounded storage model, witness length}
}

@article{10.5555/1957995.1958015,
author = {Impagliazzo, Russell and Jaiswal, Ragesh and Kabanets, Valentine and Wigderson, Avi},
title = {Uniform Direct Product Theorems: Simplified, Optimized, and Derandomized},
year = {2010},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {The classical direct product theorem for circuits says that if a Boolean function $f:{0,1}^nto{0,1}$ is somewhat hard to compute on average by small circuits, then the corresponding $k$-wise direct product function $f^k(x_1,dots,x_k)=(f(x_1),dots,f(x_k))$ (where each $x_iin{0,1}^n$) is significantly harder to compute on average by slightly smaller circuits. We prove a fully uniform version of the direct product theorem with information-theoretically optimal parameters, up to constant factors. Namely, we show that for given $k$ and $epsilon$, there is an efficient randomized algorithm $A$ with the following property. Given a circuit $C$ that computes $f^k$ on at least $epsilon$ fraction of inputs, the algorithm $A$ outputs with probability at least $3/4$ a list of $O(1/epsilon)$ circuits such that at least one of the circuits on the list computes $f$ on more than $1-delta$ fraction of inputs, for $delta=O((log1/epsilon)/k)$; moreover, each output circuit is an $mathsf{AC}^0$ circuit (of size $mathrm{poly}(n,k,log1/delta,1/epsilon)$), with oracle access to the circuit $C$. Using the Goldreich-Levin decoding algorithm [O. Goldreich and L. A. Levin, A hard-core predicate for all one-way functions, in Proceedings of the Twenty-First Annual ACM Symposium on Theory of Computing, Seattle, 1989, pp. 25-32], we also get a fully uniform version of Yao's XOR lemma [A. C. Yao, Theory and applications of trapdoor functions, in Proceedings of the Twenty-Third Annual IEEE Symposium on Foundations of Computer Science, Chicago, 1982, pp. 80-91] with optimal parameters, up to constant factors. Our results simplify and improve those in [R. Impagliazzo, R. Jaiswal, and V. Kabanets, Approximately list-decoding direct product codes and uniform hardness amplification, in Proceedings of the Forty-Seventh Annual IEEE Symposium on Foundations of Computer Science, Berkeley, CA, 2006, pp. 187-196]. Our main result may be viewed as an efficient approximate, local, list-decoding algorithm for direct product codes (encoding a function by its values on all $k$-tuples) with optimal parameters. We generalize it to a family of “derandomized” direct product codes, which we call intersection codes, where the encoding provides values of the function only on a subfamily of $k$-tuples. The quality of the decoding algorithm is then determined by sampling properties of the sets in this family and their intersections. As a direct consequence of this generalization we obtain the first derandomized direct product result in the uniform setting, allowing hardness amplification with only constant (as opposed to a factor of $k$) increase in the input length. Finally, this general setting naturally allows the decoding of concatenated codes, which further yields nearly optimal derandomized amplification.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1637–1665},
numpages = {29},
keywords = {error-correcting code, direct product code, direct product theorem, Yao's XOR lemma, list-decoding algorithms}
}

@article{10.5555/1957995.1958014,
author = {Kenyon, Claire and Rabani, Yuval and Sinclair, Alistair},
title = {Low Distortion Maps Between Point Sets},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We initiate the study of the minimum distortion problem: Given as input two $n$-point metric spaces, find a bijection between them with minimum distortion. This is an abstraction of certain geometric problems in shape and image matching and is also a natural variation and extension of the fundamental problems of graph isomorphism and bandwidth. Our focus is on algorithms that find an optimal (or near-optimal) bijection when the distortion is fairly small. We present a polynomial time algorithm that finds an optimal bijection between two line metrics, provided the distortion is less than $5+2sqrt{6}approx9.9$. We also give a parameterized polynomial time algorithm that finds an optimal bijection between an arbitrary unweighted graph metric and a bounded-degree tree metric.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1617–1636},
numpages = {20},
keywords = {permutations, low distortion embeddings, dynamic programming, metric spaces, shape matching}
}

@article{10.5555/1957995.1958013,
author = {Schulman, Rebecca and Winfree, Erik},
title = {Programmable Control of Nucleation for Algorithmic Self-Assembly},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {Algorithmic self-assembly, a generalization of crystal growth processes, has been proposed as a mechanism for autonomous DNA computation and for bottom-up fabrication of complex nanostructures. A “program” for growing a desired structure consists of a set of molecular “tiles” designed to have specific binding interactions. A key challenge to making algorithmic self-assembly practical is designing tile set programs that make assembly robust to errors that occur during initiation and growth. One method for the controlled initiation of assembly, often seen in biology, is the use of a seed or catalyst molecule that reduces an otherwise large kinetic barrier to nucleation. Here we show how to program algorithmic self-assembly similarly, such that seeded assembly proceeds quickly but there is an arbitrarily large kinetic barrier to unseeded growth. We demonstrate this technique by introducing a family of tile sets for which we rigorously prove that, under the right physical conditions, linearly increasing the size of the tile set exponentially reduces the rate of spurious nucleation. Simulations of these “zig-zag” tile sets suggest that under plausible experimental conditions, it is possible to grow large seeded crystals in just a few hours such that less than 1 percent of crystals are spuriously nucleated. Simulation results also suggest that zig-zag tile sets could be used for detection of single DNA strands. Together with prior work showing that tile sets can be made robust to errors during properly initiated growth, this work demonstrates that growth of objects via algorithmic self-assembly can proceed both efficiently and with an arbitrarily low error rate, even in a model where local growth rules are probabilistic.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1581–1616},
numpages = {36},
keywords = {algorithmic self-assembly, nucleation theory, DNA nanotechnology}
}

@article{10.5555/1957995.1958012,
author = {Regev, Oded and Toner, Ben},
title = {Simulating Quantum Correlations with Finite Communication},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {Assume Alice and Bob share some bipartite $d$-dimensional quantum state. A well-known result in quantum mechanics says that by performing two-outcome measurements, Alice and Bob can produce correlations that cannot be obtained locally, i.e., with shared randomness alone. We show that by using only two bits of communication, Alice and Bob can classically simulate any such correlations. All previous protocols for exact simulation required the communication to grow to infinity with the dimension $d$. Our protocol and analysis are based on a power series method, resembling Krivine's bound on Grothendieck's constant, and on the computation of volumes of spherical tetrahedra.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1562–1580},
numpages = {19},
keywords = {communication complexity, quantum entanglement}
}

@article{10.5555/1957995.1958011,
author = {Kirsch, Adam and Mitzenmacher, Michael and Wieder, Udi},
title = {More Robust Hashing: Cuckoo Hashing with a Stash},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {Cuckoo hashing holds great potential as a high-performance hashing scheme for real applications. Up to this point, the greatest drawback of cuckoo hashing appears to be that there is a polynomially small but practically significant probability that a failure will occur during the insertion of an item, requiring an expensive rehashing of all items in the table. In this paper, we show that this failure probability can be dramatically reduced by the addition of a very small constant-sized stash. We demonstrate both analytically and through simulations that stashes of size equivalent to only three or four items yield tremendous improvements, enhancing cuckoo hashing's practical viability in both hardware and software. Our analysis naturally extends previous analyses of multiple cuckoo hashing variants, and the approach may prove useful in further related schemes.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1543–1561},
numpages = {19},
keywords = {cuckoo hashing, probabilistic analysis, hash table}
}

@article{10.5555/1957995.1958010,
author = {Barto, Libor and Kozik, Marcin},
title = {Congruence Distributivity Implies Bounded Width},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We show that a constraint language with compatible J\'{o}nsson terms (or, equivalently, associated with an algebra generating a congruence distributive variety) defines a constraint satisfaction problem solvable by the local consistency checking algorithm.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1531–1542},
numpages = {12},
keywords = {J\'{o}nsson terms, constraint satisfaction problem, congruence distributive variety, local consistency, bounded width}
}

@article{10.5555/1957995.1958009,
author = {Martens, Wim and Neven, Frank and Schwentick, Thomas},
title = {Complexity of Decision Problems for XML Schemas and Chain Regular Expressions},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We study the complexity of the inclusion, equivalence, and intersection problem of extended chain regular expressions (eCHAREs). These are regular expressions with a very simple structure: they basically consist of the concatenation of factors, where each factor is a disjunction of strings, possibly extended with “$*$”, “$+$”, or “$?$”. Though of a very simple form, the usage of such expressions is widespread as eCHAREs, for instance, constitute a super class of the regular expressions most frequently used in practice in schema languages for XML. In particular, we show that all our lower and upper bounds for the inclusion and equivalence problem carry over to the corresponding decision problems for extended context-free grammars, and to single-type and restrained competition tree grammars. These grammars form abstractions of document type definitions (DTDs), XML schema definitions (XSDs) and the class of one-pass preorder typeable XML Schemas, respectively. For the intersection problem, we show that obtained complexities only carry over to DTDs. In this respect, we also study two other classes of regular expressions related to XML: deterministic expressions and expressions where the number of occurrences of alphabet symbols is bounded by a constant.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1486–1530},
numpages = {45},
keywords = {inclusion, complexity, intersection, equivalence, XML schemas, regular expressions}
}

@article{10.5555/1957995.1958008,
author = {Bravyi, Sergey and Terhal, Barbara},
title = {Complexity of Stoquastic Frustration-Free Hamiltonians},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We study several problems related to properties of nonnegative matrices that arise at the boundary between quantum and classical probabilistic computation. Our results are twofold. First, we identify a large class of quantum Hamiltonians describing systems of qubits for which the adiabatic evolution can be efficiently simulated on a classical probabilistic computer. These are stoquastic local Hamiltonians with a “frustration-free” ground-state. A Hamiltonian belongs to this class iff it can be represented as $H=sum_{a}H_{a}$ where (1) every term $H_{a}$ acts nontrivially on a constant number of qubits, (2) every term $H_{a}$ has real nonpositive off-diagonal matrix elements in the standard basis, and (3) the ground-state of $H$ is a ground-state of every term $H_{a}$. Second, we generalize the Cook-Levin theorem proving NP-completeness of the satisfiability problem to the complexity class MA (Merlin-Arthur games)—a probabilistic analogue of NP. Specifically, we construct a quantum version of the $k$-SAT problem which we call “stoquastic $k$-SAT” such that stoquastic $k$-SAT is contained in MA for any constant $k$, and any promise problem in MA is Karp-reducible to stoquastic 6-SAT. This result provides the first nontrivial example of a MA-complete promise problem.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1462–1485},
numpages = {24},
keywords = {Merlin-Arthur games, adiabatic quantum computing, randomized algorithms, nonnegative matrices}
}

@article{10.5555/1957995.1958007,
author = {Amir, Amihood and Hartman, Tzvika and Kapah, Oren and Levy, Avivit and Porat, Ely},
title = {On the Cost of Interchange Rearrangement in Strings},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {Consider the following optimization problem: given two strings over the same alphabet, transform one into another by a succession of interchanges of two elements. In each interchange the two participating elements exchange positions. An interchange is given a weight that depends on the distance in the string between the two exchanged elements. The object is to minimize the total weight of the interchanges. This problem is a generalization of a classical problem on permutations (where every element appears once). The generalization considers general strings with possibly repeating elements, and a function assigning weights to the interchanges. The generalization to general strings (with unit weights) was mentioned by Cayley in the 19th century, and its complexity has been an open question since. We solve this open problem and consider various weight functions as well.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1444–1461},
numpages = {18},
keywords = {interchange distance, string rearrangement metrics, rearrangement cost models}
}

@article{10.5555/1957995.1958006,
author = {Ma, Bin and Sun, Xiaoming},
title = {More Efficient Algorithms for Closest String and Substring Problems},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {The closest string problem and the closest substring problem are all natural theoretical computer science problems and find important applications in computational biology. Given $n$ input strings, the closest string (substring) problem finds a new string within distance $d$ to (a substring of) each input string and such that $d$ is minimized. Both problems are NP-complete. In this paper we propose new algorithms for these two problems. For the closest string problem, we developed an exact algorithm with time complexity $O(n|Sigma|^{O(d)})$, where $Sigma$ is the alphabet. This improves the previously best known result $O(nd^{O(d)})$ and results into a polynomial time algorithm when $d=O(log n)$. By using this algorithm, a polynomial time approximation scheme (PTAS) for the closest string problem is also given with time complexity $O(n^{O(epsilon^{-2})})$, improving the previously best known $O(n^{O(epsilon^{-2}logfrac{1}{epsilon})})$ PTAS. A new algorithm for the closest substring problem is also proposed. Finally, we prove that a restricted version of the closest substring problem has the same parameterized complexity as the closest substring, answering an open question in the literature.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1432–1443},
numpages = {12},
keywords = {closest substring, fixed-parameter algorithm, approximation algorithms, closest string}
}

@article{10.5555/1957995.1958005,
author = {Bansal, Nikhil and Khandekar, Rohit and Nagarajan, Viswanath},
title = {Additive Guarantees for Degree-Bounded Directed Network Design},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We present polynomial-time approximation algorithms for some degree-bounded directed network design problems. Our main result is for intersecting supermodular connectivity requirements with degree bounds: given a directed graph $G=(V,E)$ with nonnegative edge-costs, a connectivity requirement specified by an intersecting supermodular function $f$, and upper bounds ${a_v,b_v}_{vin V}$ on in-degrees and out-degrees of vertices, find a minimum-cost $f$-connected subgraph of $G$ that satisfies the degree bounds. We give a bicriteria approximation algorithm for this problem using the natural LP relaxation and show that our guarantee is the best possible relative to this LP relaxation. We also obtain similar results for the (more general) class of crossing supermodular requirements. In the absence of edge-costs, our result gives the first additive $O(1)$-approximation guarantee for degree-bounded intersecting/crossing supermodular connectivity problems. We also consider the minimum crossing spanning tree problem: Given an undirected edge-weighted graph $G$, edge-subsets ${E_i}_{i=1}^k$, and nonnegative integers ${b_i}_{i=1}^k$, find a minimum-cost spanning tree (if it exists) in $G$ that contains at most $b_i$ edges from each set $E_i$. We obtain a $+(r-1)$ additive approximation for this problem, when each edge lies in at most $r$ sets. A special case of this problem is the degree-bounded minimum spanning tree, and our techniques give a substantially shorter proof of the recent $+1$ approximation of Singh and Lau [in Proceedings of the 40th Annual ACM Symposium on Theory of Computing, 2007, pp. 661-670].},
journal = {SIAM J. Comput.},
month = oct,
pages = {1413–1431},
numpages = {19},
keywords = {network design, directed graphs, approximation algorithms}
}

@article{10.5555/1957995.1958004,
author = {Jansen, Klaus},
title = {Parameterized Approximation Scheme for the Multiple Knapsack Problem},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {The multiple knapsack problem (MKP) is a well-known generalization of the classical knapsack problem. We are given a set $A$ of $n$ items and set $B$ of $m$ bins (knapsacks) such that each item $a in A$ has a size $size(a)$ and a profit value $profit(a)$, and each bin $b in B$ has a capacity $c(b)$. The goal is to find a subset $U subset A$ of maximum total profit such that $U$ can be packed into $B$ without exceeding the capacities. The decision version of MKP is strongly NP-complete, since it is a generalization of the classical knapsack and bin packing problem. Furthermore, MKP does not admit a fully time polynomial time approximation scheme (FPTAS) even if the number $m$ of bins is two. Kellerer gave a polynomial time approximation scheme (PTAS) for MKP with identical capacities and Chekuri and Khanna presented a PTAS for MKP with general capacities with running time $n^{O(log(1/epsilon)/epsilon^8)}$. In this paper we propose an efficient PTAS (EPTAS) with parameterized running time $2^{O(log(1/epsilon)/epsilon^5)} cdot poly(n) + O(m)$ for MKP. This also solves an open question by Chekuri and Khanna.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1392–1412},
numpages = {21},
keywords = {knapsack problem, parameterized complexity, approximation algorithms}
}

@article{10.5555/1957995.1958003,
author = {Blumrosen, Liad and Nisan, Noam},
title = {On the Computational Power of Demand Queries},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We study the computational power of iterative combinatorial auctions. Most existing iterative combinatorial auctions are based on repeatedly suggesting prices for bundles of items and querying the bidders for their “demand” under these prices. We prove several results regarding such auctions that use a polynomial number of demand queries: (1) that such auctions can simulate several other natural types of queries; (2) that they can approximate the optimal allocation as well as generally possible using polynomial communication or computation, while weaker types of queries cannot do so; (3) that such auctions that use only item prices may solve allocation problems in communication cost that is exponentially lower than the cost incurred by auctions that use prices for bundles. For the latter result, we initiate the study of how prices of bundles can be represented when they are not linear and show that the “default” representation has severe limitations. Our results hold for any series of demand queries with polynomial length, without any additional restrictions on the queries (e.g., to ascending prices).},
journal = {SIAM J. Comput.},
month = oct,
pages = {1372–1391},
numpages = {20},
keywords = {communication complexity, iterative auctions, demand queries, combinatorial auctions}
}

@article{10.5555/1957995.1958002,
author = {Diakonikolas, Ilias and Yannakakis, Mihalis},
title = {Small Approximate Pareto Sets for Biobjective Shortest Paths and Other Problems},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We investigate the problem of computing a minimum set of solutions that approximates within a specified accuracy $epsilon$ the Pareto curve of a multiobjective optimization problem. We show that for a broad class of biobjective problems (containing many important widely studied problems such as shortest paths, spanning tree, matching, and many others), we can compute in polynomial time an $epsilon$-Pareto set that contains at most twice as many solutions as the minimum set. Furthermore we show that the factor of 2 is tight for these problems; i.e., it is NP-hard to do better. We present upper and lower bounds for three or more objectives, as well as for the dual problem of computing a specified number $k$ of solutions which provide a good approximation to the Pareto curve.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1340–1371},
numpages = {32},
keywords = {biobjective shortest path, multiobjective optimization, approximate Pareto set}
}

@article{10.5555/1957995.1958001,
author = {Cormode, Graham and Tirthapura, Srikanta and Xu, Bojian},
title = {Time-Decaying Sketches for Robust Aggregation of Sensor Data},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We present a new sketch for summarizing network data. The sketch has the following properties which make it useful in communication-efficient aggregation in distributed streaming scenarios, such as sensor networks: the sketch is duplicate insensitive, i.e., reinsertions of the same data will not affect the sketch and hence the estimates of aggregates. Unlike previous duplicate-insensitive sketches for sensor data aggregation [S. Nath et al., Synposis diffusion for robust aggregation in sensor networks, in Proceedings of the 2nd International Conference on Embedded Network Sensor Systems, (2004), pp. 250-262], [J. Considine et al., Approximate aggregation techniques for sensor databases, in Proceedings of the 20th International Conference on Data Engineering (ICDE), 2004, pp. 449-460], it is also time decaying, so that the weight of a data item in the sketch can decrease with time according to a user-specified decay function. The sketch can give provably approximate guarantees for various aggregates of data, including the sum, median, quantiles, and frequent elements. The size of the sketch and the time taken to update it are both polylogarithmic in the size of the relevant data. Further, multiple sketches computed over distributed data can be combined without loss of accuracy. To our knowledge, this is the first sketch that combines all the above properties.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1309–1339},
numpages = {31},
keywords = {duplicates, sensor network, data aggregation, time decay, data streams, asynchrony}
}

@article{10.5555/1957995.1958000,
author = {Bansal, Nikhil and Pruhs, Kirk and Stein, Cliff},
title = {Speed Scaling for Weighted Flow Time},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {Intel's SpeedStep and AMD's PowerNOW technologies allow the Windows XP operating system to dynamically change the speed of the processor to prolong battery life. In this setting, the operating system must not only have a job selection policy to determine which job to run, but also a speed scaling policy to determine the speed at which the job will be run. We give an online speed scaling algorithm that is $O(1)$-competitive for the objective of weighted flow time plus energy. This algorithm also allows us to efficiently construct an $O(1)$-approximate schedule for minimizing weighted flow time subject to an energy constraint.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1294–1308},
numpages = {15},
keywords = {online algorithms, speed scaling, energy minimization, flow time}
}

@article{10.5555/1957995.1957999,
author = {Dvir, Zeev and Shpilka, Amir and Yehudayoff, Amir},
title = {Hardness-Randomness Tradeoffs for Bounded Depth Arithmetic Circuits},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {In this paper we show that lower bounds for bounded depth arithmetic circuits imply derandomization of polynomial identity testing for bounded depth arithmetic circuits. More formally, if there exists an explicit polynomial $f$ that cannot be computed by a depth $d$ arithmetic circuit of small size, then there exists an efficient deterministic black-box algorithm to test whether a given depth $d-5$ circuit that computes a polynomial of relatively small individual degrees is identically zero or not. In particular, if we are guaranteed that the tested circuit computes a multilinear polynomial, then we can perform the identity test efficiently. To the best of our knowledge this is the first hardness-randomness tradeoff for bounded depth arithmetic circuits. The above results are obtained using the arithmetic Nisan-Wigderson generator of Kabanets and Impagliazzo together with a new theorem on bounded depth circuits, which is the main technical contribution of our work. This theorem deals with polynomial equations of the form $P(x_1,dots,x_n,y)equiv0$ and shows that if $P$ has a circuit of depth $d$ and size $s$ and if the polynomial $f(x_1,dots,x_n)$ satisfies $P(x_1,dots,x_n,f)equiv0$, then $f$ has a circuit of depth $d+3$ and size $mathrm{poly}(s,m^r)$, where $m$ is the total degree of $f$ and $r$ is the degree of $y$ in $P$. This circuit for $f$ can be found probabilistically in time $mathrm{poly}(s,m^r)$. In the other direction we observe that the methods of Kabanets and Impagliazzo can be used to show that derandomizing identity testing for bounded depth circuits implies lower bounds for the same class of circuits. More formally, if we can derandomize polynomial identity testing for bounded depth circuits, then NEXP does not have bounded depth arithmetic circuits. That is, either $mathrm{NEXP}notsubseteq P/mathrm{poly}$ or the Permanent is not computable by polynomial size bounded depth arithmetic circuits.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1279–1293},
numpages = {15},
keywords = {hardness, polynomial factoring, polynomial identity testing, derandomization, randomness}
}

@article{10.5555/1957995.1957998,
author = {Bansal, Nikhil and Caprara, Alberto and Sviridenko, Maxim},
title = {A New Approximation Method for Set Covering Problems, with Applications to Multidimensional Bin Packing},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {In this paper we introduce a new general approximation method for set covering problems, based on the combination of randomized rounding of the (near-) optimal solution of the linear programming (LP) relaxation, leading to a partial integer solution and the application of a well-behaved approximation algorithm to complete this solution. If the value of the solution returned by the latter can be bounded in a suitable way, as is the case for the most relevant generalizations of bin packing, the method leads to improved approximation guarantees, along with a proof of tighter integrality gaps for the LP relaxation. For $d$-dimensional vector packing, we obtain a polynomial-time randomized algorithm with asymptotic approximation guarantee arbitrarily close to $ln d + 1$. For $d=2$, this value is $1.693dots$; i.e., we break the natural 2 “barrier” for this case. Moreover, for small values of $d$ this is a notable improvement over the previously known $O(ln d)$ guarantee by Chekuri and Khanna [SIAM J. Comput., 33 (2004), pp. 837-851]. For two-dimensional bin packing with and without rotations, we obtain polynomial-time randomized algorithms with asymptotic approximation guarantee $1.525dots$, improving upon previous algorithms with asymptotic performance guarantees arbitrarily close to 2 by Jansen and van Stee [On strip packing with rotations, in Proceedings of the 37th Annual ACM Symposium on the Theory of Computing, 2005, pp. 755-761] for the problem with rotations and $1.691ldots$ by Caprara [Math. Oper. Res., 33 (2008), pp. 203-215] for the problem without rotations. The previously unknown key property used in our proofs follows from a retrospective analysis of the implications of the landmark bin packing approximation scheme by Fernandez de la Vega and Lueker [Combinatorica, 1 (1981), pp. 349-355]. We prove that their approximation scheme is “subset oblivious,” which leads to numerous applications.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1256–1278},
numpages = {23},
keywords = {approximation algorithm, set cover, bin packing}
}

@article{10.5555/1957995.1957997,
author = {Broder, Andrei Z. and Kirsch, Adam and Kumar, Ravi and Mitzenmacher, Michael and Upfal, Eli and Vassilvitskii, Sergei},
title = {The Hiring Problem and Lake Wobegon Strategies},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We introduce the hiring problem, in which a growing company continuously interviews and decides whether to hire applicants. This problem is similar in spirit but quite different from the well-studied secretary problem. Like the secretary problem, it captures fundamental aspects of decision making under uncertainty and has many possible applications. We analyze natural strategies of hiring above the current average, considering both the mean and the median averages; we call these Lake Wobegon strategies. Like the hiring problem itself, our strategies are intuitive, simple to describe, and amenable to mathematically and economically significant modifications. We demonstrate several intriguing behaviors of the two strategies. Specifically, we show dramatic differences between hiring above the mean and above the median. We also show that both strategies are intrinsically connected to the lognormal distribution, leading to only very weak concentration results, and the marked importance of the first few hires on the overall outcome.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1233–1255},
numpages = {23},
keywords = {Lake Wobegon strategies, lognormal distributions, secretary problem, martingale analysis}
}

@article{10.5555/1957995.1957996,
author = {Abam, Mohammad Ali and de Berg, Mark and Speckmann, Bettina},
title = {Kinetic Kd-Trees and Longest-Side Kd-Trees},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {4},
issn = {0097-5397},
abstract = {We propose a simple variant of kd-trees, called rank-based kd-trees, for sets of $n$ points in $mathbb{R}^d$. We show that a rank-based kd-tree, like an ordinary kd-tree, supports orthogonal range queries in $O(n^{1-1/d}+k)$ time, where $k$ is the output size. The main advantage of rank-based kd-trees is that they can be efficiently kinetized: the kinetic data structure (KDS) processes $O(n^2)$ events in the worst case, assuming that the points follow constant-degree algebraic trajectories; each event can be handled in $O(log n)$ time, and each point is involved in $O(1)$ certificates. We also propose a variant of longest-side kd-trees, called rank-based longest-side kd-trees, for sets of points in $mathbb{R}^2$. Rank-based longest-side kd-trees can be kinetized efficiently as well, and like longest-side kd-trees, they support $varepsilon$-approximate nearest-neighbor, $varepsilon$-approximate farthest-neighbor, and $varepsilon$-approximate range queries with convex ranges in $O((1/epsilon)log^2n)$ time. The KDS processes $O(n^3log n)$ events in the worst case, assuming that the points follow constant-degree algebraic trajectories; each event can be handled in $O(log^2n)$ time, and each point is involved in $O(log n)$ certificates.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1219–1232},
numpages = {14},
keywords = {computational geometry, kinetic data structures, range searching, kd-trees}
}

@article{10.1137/SMJCAT000039000003000978000001,
author = {Allender, Eric and Koltun, Vladlen and Sviridenko, Maxim},
title = {Special Section On The Thirty-Ninth Annual ACM Symposium On Theory Of Computing (STOC 2007)},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000039000003000978000001},
doi = {10.1137/SMJCAT000039000003000978000001},
abstract = {This issue contains the polished, extended, and fully refereed versions of a selection of papers that were presented at the Thirty-Ninth Annual ACM Symposium on Theory of Computing (STOC 2007), which was held June 11-13, 2007, in San Diego, California, in conjunction with the Federated Computing Research Conference (FCRC 2007). Unrefereed preliminary versions of these papers were published by ACM in the proceedings of the meeting, along with the other papers presented at the symposium.The conference program included 77 papers, selected from among a record 312 submissions by a program committee chaired by Uriel Feige and consisting of Eric Allender, Andris Ambainis, Chandra Chekuri, Artur Czumaj, Yevgeniy Dodis, Michel Goemans, Martin Grohe, Russell Impagliazzo, Valerie King, Robert Kleinberg, Vladlen Koltun, Robi Krauthgamer, Ji\v{r}\'{\i} Matou\v{s}ek, Milena Mihail, Ryan O'Donnell, Vijaya Ramachandran, Leonard Schulman, Maxim Sviridenko, Mikkel Thorup, Salil Vadhan, and Santosh Vempala.The authors of 14 of these 77 papers were invited to submit revised versions for this special section; nine accepted the invitation, although one paper was not completed in time to appear in this volume. One paper that appears in this special issue (by Haitner et al.) is the result of merging a STOC 2007 paper with a FOCS 2006 paper that had been invited for the special issue of SIAM Journal on Computing devoted to FOCS 2006; the authors felt that a single, streamlined paper would be more beneficial to the community, and the editors concurred.The paper by Martin F\"{u}rer appearing in this issue is one of two papers that shared the award for best paper in STOC 2007.All of these papers were refereed in accordance with the stringent standards of SIAM Journal on Computing. We thank the anonymous referees and the authors for their efforts, resulting in substantial improvements in the end product. We also thank the rest of the program committee members for their help in the selection process. The three of us listed below are honored to have had the opportunity to serve as guest editors in preparing this special issue.},
journal = {SIAM J. Comput.},
month = sep,
pages = {978},
numpages = {1}
}

@article{10.1137/080725404,
author = {Haitner, Iftach and Nguyen, Minh-Huyen and Ong, Shien Jin and Reingold, Omer and Vadhan, Salil},
title = {Statistically Hiding Commitments and Statistical Zero-Knowledge Arguments from Any One-Way Function},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/080725404},
doi = {10.1137/080725404},
abstract = {We give a construction of statistically hiding commitment schemes (those in which the hiding property holds against even computationally unbounded adversaries) under the minimal complexity assumption that one-way functions exist. Consequently, one-way functions suffice to give statistical zero-knowledge arguments for any NP statement (whereby even a computationally unbounded adversarial verifier learns nothing other than the fact that the assertion being proven is true, and no polynomial-time adversarial prover can convince the verifier of a false statement). These results resolve an open question posed by Naor et al. [J. Cryptology, 11 (1998), pp. 87-108].},
journal = {SIAM J. Comput.},
month = sep,
pages = {1153–1218},
numpages = {66},
keywords = {one-way functions, cryptography, statistical zero-knowledge argument systems, interactive hashing, statistically hiding commitments}
}

@article{10.1137/080725398,
author = {Ishai, Yuval and Kushilevitz, Eyal and Ostrovsky, Rafail and Sahai, Amit},
title = {Zero-Knowledge Proofs from Secure Multiparty Computation},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/080725398},
doi = {10.1137/080725398},
abstract = {A zero-knowledge proof allows a prover to convince a verifier of an assertion without revealing any further information beyond the fact that the assertion is true. Secure multiparty computation allows $n$ mutually suspicious players to jointly compute a function of their local inputs without revealing to any $t$ corrupted players additional information beyond the output of the function. We present a new general connection between these two fundamental notions. Specifically, we present a general construction of a zero-knowledge proof for an NP relation $R(x,w)$, which makes only a black-box use of any secure protocol for a related multiparty functionality $f$. The latter protocol is required only to be secure against a small number of “honest but curious” players. We also present a variant of the basic construction that can leverage security against a large number of malicious players to obtain better efficiency. As an application, one can translate previous results on the efficiency of secure multiparty computation to the domain of zero-knowledge, improving over previous constructions of efficient zero-knowledge proofs. In particular, if verifying $R$ on a witness of length $m$ can be done by a circuit $C$ of size $s$, and assuming that one-way functions exist, we get the following types of zero-knowledge proof protocols: (1) Approaching the witness length. If $C$ has constant depth over $wedge,vee,oplus,neg$ gates of unbounded fan-in, we get a zero-knowledge proof protocol with communication complexity $mcdot{poly}(k)cdot{polylog}(s)$, where $k$ is a security parameter. (2) “Constant-rate” zero-knowledge. For an arbitrary circuit $C$ of size $s$ and a bounded fan-in, we get a zero-knowledge protocol with communication complexity $O(s)+{poly}(k,log s)$. Thus, for large circuits, the ratio between the communication complexity and the circuit size approaches a constant. This improves over the $O(ks)$ complexity of the best previous protocols.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1121–1152},
numpages = {32},
keywords = {black-box reductions, secure computation, cryptography, zero-knowledge}
}

@article{10.1137/070711761,
author = {F\"{u}rer, Martin},
title = {Faster Integer Multiplication},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070711761},
doi = {10.1137/070711761},
abstract = {For more than 35 years, the fastest known method for integer multiplication has been the Sch\"{o}nhage-Strassen algorithm running in time $O(nlog nloglog n)$. Under certain restrictive conditions, there is a corresponding $Omega(nlog n)$ lower bound. All this time, the prevailing conjecture has been that the complexity of an optimal integer multiplication algorithm is $Theta(nlog n)$. We take a major step towards closing the gap between the upper bound and the conjectured lower bound by presenting an algorithm running in time $nlog n,2^{O(log^*n)}$. The running time bound holds for multitape Turing machines. The same bound is valid for the size of Boolean circuits.},
journal = {SIAM J. Comput.},
month = sep,
pages = {979–1005},
numpages = {27},
keywords = {FFT, integer multiplication, discrete Fourier transform, complexity, computer arithmetic}
}

@article{10.1137/070702680,
author = {Santhanam, Rahul},
title = {Circuit Lower Bounds for Merlin-Arthur Classes},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070702680},
doi = {10.1137/070702680},
abstract = {We show that for each $k&gt;0$, $mathsf{MA}/1$ ($mathsf{MA}$ with 1 bit of advice) does not have circuits of size $n^k$. This implies the first superlinear circuit lower bounds for the promise versions of the classes $mathsf{MA}$, $mathsf{AM}$, and $mathsf{ZPP}_{parallel}^{mathsf{NP}}$. We extend our main result in several ways. For each $k$, we give an explicit language in $(mathsf{MA}capmathsf{coMA})/1$ which does not have circuits of size $n^k$. We also adapt our lower bound to the average-case setting; i.e., we show that $mathsf{MA}/1$ cannot be solved on more than $1/2+1/n^k$ fraction of inputs of length $n$ by circuits of size $n^k$. Furthermore, we prove that $mathsf{MA}$ does not have arithmetic circuits of size $n^k$ for any $k$. As a corollary to our main result, we obtain that derandomization of $mathsf{MA}/O(1)$ implies the existence of pseudorandom generators computable using $O(1)$ bits of advice.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1038–1061},
numpages = {24},
keywords = {Merlin-Arthur classes, complexity theory, circuit lower bounds, average-case lower bounds, derandomization, classes with advice}
}

@article{10.1137/070702278,
author = {Pagh, Anna and Pagh, Rasmus and Ru\v{z}i\'{c}, Milan},
title = {Linear Probing with Constant Independence},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070702278},
doi = {10.1137/070702278},
abstract = {Hashing with linear probing dates back to the 1950s and is among the most widely studied algorithms. In recent years, it has become one of the most important hash table organizations because it uses the cache of modern computers very well. Unfortunately, previous analyses relied either on complicated and space-consuming hash functions, or on the unrealistic assumption of free access to a hash function with random and independent function values. Carter and Wegman, in their seminal paper on universal hashing, have already raised the question of extending their analysis to linear probing. However, we show in this paper that linear probing using a pairwise independent family may have expected logarithmic cost per operation. On the positive side, we show that 5-wise independence is enough to ensure constant expected time per operation. This resolves the question of finding a space- and time-efficient hash function that provably ensures good performance for linear probing.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1107–1120},
numpages = {14},
keywords = {hashing, linear probing}
}

@article{10.1137/070701704,
author = {Kakade, Sham M. and Kalai, Adam Tauman and Ligett, Katrina},
title = {Playing Games with Approximation Algorithms},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070701704},
doi = {10.1137/070701704},
abstract = {In an online linear optimization problem, on each period $t$, an online algorithm chooses $s_tinmathcal{S}$ from a fixed (possibly infinite) set $mathcal{S}$ of feasible decisions. Nature (who may be adversarial) chooses a weight vector $w_tinmathbb{R}^n$, and the algorithm incurs cost $c(s_t,w_t)$, where $c$ is a fixed cost function that is linear in the weight vector. In the full-information setting, the vector $w_t$ is then revealed to the algorithm, and in the bandit setting, only the cost experienced, $c(s_t,w_t)$, is revealed. The goal of the online algorithm is to perform nearly as well as the best fixed $sinmathcal{S}$ in hindsight. Many repeated decision-making problems with weights fit naturally into this framework, such as online shortest-path, online traveling salesman problem (TSP), online clustering, and online weighted set cover. Previously, it was shown how to convert any efficient exact offline optimization algorithm for such a problem into an efficient online algorithm in both the full-information and the bandit settings, with average cost nearly as good as that of the best fixed $sinmathcal{S}$ in hindsight. However, in the case where the offline algorithm is an approximation algorithm with ratio $alpha &gt;1$, the previous approach worked only for special types of approximation algorithms. We show how to convert any offline approximation algorithm for a linear optimization problem into a corresponding online approximation algorithm, with a polynomial blowup in runtime. If the offline algorithm has an $alpha$-approximation guarantee, then the expected cost of the online algorithm on any sequence is not much larger than $alpha$ times that of the best $sinmathcal{S}$, where the best is chosen with the benefit of hindsight. Our main innovation is combining Zinkevich's algorithm for convex optimization with a geometric transformation that can be applied to any approximation algorithm. Standard techniques generalize the above result to the bandit setting, except that a “barycentric spanner” for the problem is also (provably) necessary as input. Our algorithm can also be viewed as a method for playing large repeated games, where one can compute only approximate best responses, rather than best responses.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1088–1106},
numpages = {19},
keywords = {approximation algorithms, regret minimization, online linear optimization, online algorithms}
}

@article{10.1137/070700620,
author = {Lau, Lap Chi and Naor, Joseph Seffi and Salavatipour, Mohammad R. and Singh, Mohit},
title = {Survivable Network Design with Degree or Order Constraints},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070700620},
doi = {10.1137/070700620},
abstract = {We present algorithmic and hardness results for network design problems with degree or order constraints. The first problem we consider is the Survivable Network Design problem with degree constraints on vertices. The objective is to find a minimum cost subgraph which satisfies connectivity requirements between vertices and also degree upper bounds $B_v$ on the vertices. This includes the well-studied Minimum Bounded Degree Spanning Tree problem as a special case. Our main result is a $(2,2B_v+3)$-approximation algorithm for the edge-connectivity Survivable Network Design problem with degree constraints, where the cost of the returned solution is at most twice the cost of an optimum solution (satisfying the degree bounds) and the degree of each vertex $v$ is at most $2B_v+3$. This implies the first constant factor (bicriteria) approximation algorithms for many degree constrained network design problems, including the Minimum Bounded Degree Steiner Forest problem. Our results also extend to directed graphs and provide the first constant factor (bicriteria) approximation algorithms for the Minimum Bounded Degree Arborescence problem and the Minimum Bounded Degree Strongly $k$-Edge-Connected Subgraph problem. In contrast, we show that the vertex-connectivity Survivable Network Design problem with degree constraints is hard to approximate, even when the cost of every edge is zero. A striking aspect of our algorithmic result is its simplicity. It is based on the iterative relaxation method, which is an extension of Jain's iterative rounding method. This provides an elegant and unifying algorithmic framework for a broad range of network design problems. We also study the problem of finding a minimum cost $lambda$-edge-connected subgraph with at least $k$ vertices, which we call the $(k,lambda)$-subgraph problem. This generalizes some well-studied classical problems such as the $k$-MST and the minimum cost $lambda$-edge-connected subgraph problems. We give a polylogarithmic approximation for the $(k,2)$-subgraph problem. However, by relating it to the Densest $k$-Subgraph problem, we provide evidence that the $(k,lambda)$-subgraph problem might be hard to approximate for arbitrary $lambda$.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1062–1087},
numpages = {26},
keywords = {approximation algorithms, degree bounded, survivable network design, $k$-subgraph, $lambda$-edge-connected}
}

@article{10.1137/070698348,
author = {Shaltiel, Ronen and Umans, Christopher},
title = {Low-End Uniform Hardness versus Randomness Tradeoffs for AM},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070698348},
doi = {10.1137/070698348},
abstract = {Impagliazzo and Wigderson [Proceedings of the 39th Annual IEEE Symposium on Foundations of Computer Science, IEEE Computer Society, Washington, DC, 1998, pp. 734-743] proved a hardness versus randomness tradeoff for BPP in the uniform setting, which was subsequently extended to give optimal tradeoffs for the full range of possible hardness assumptions (in slightly weaker settings). Gutfreund, Shaltiel, and Ta-Shma [Comput. Complexity, 12 (2003), pp. 85-130] proved a uniform hardness versus randomness tradeoff for AM, but that result worked only on the “high end” of possible hardness assumptions. In this work, we give uniform hardness versus randomness tradeoffs for AM that are near-optimal for the full range of possible hardness assumptions. Following Gutfreund, Shaltiel, and Ta-Shma, we do this by constructing a hitting-set-generator (HSG) for AM with “resilient reconstruction.” Our construction is a recursive variant of the Miltersen-Vinodchandran HSG [Comput. Complexity, 14 (2005), pp. 256-279], the only known HSG construction with this required property. The main new idea is to have the reconstruction procedure operate implicitly and locally on superpolynomially large objects, using tools from PCPs (low-degree testing, self-correction) together with a novel use of extractors that are built from Reed-Muller codes for a sort of locally computable error-reduction. As a consequence we obtain gap theorems for AM (and AM $cap$ coAM) that state, roughly, that either AM (or AM $cap$ coAM) protocols running in time $t(n)$ can simulate all of EXP (“Arthur-Merlin games are powerful”) or else all of AM (or AM $cap$ coAM) can be simulated in nondeterministic time $s(n)$ (“Arthur-Merlin games can be derandomized”) for a near-optimal relationship between $t(n)$ and $s(n)$. As in Gutfreund, Shatiel, and Ta-Shma, the case of AM $cap$ coAM yields a particularly clean theorem that is of special interest due to the wide array of cryptographic and other problems that lie in this class.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1006–1037},
numpages = {32},
keywords = {Arthur-Merlin, derandomization, hitting-set-generator, hardness versus randomness}
}

@article{10.1137/06066775X,
author = {Zhang, Shengyu},
title = {Tight Bounds for Randomized and Quantum Local Search},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/06066775X},
doi = {10.1137/06066775X},
abstract = {The problem Local Search, which finds a local minimum of a black-box function on a given graph, is of both practical and theoretical importance to combinatorial optimization, complexity theory, and many other areas in theoretical computer science. In this paper, we study the problem in both the randomized and the quantum query models and give new lower and upper bound techniques in both models. The lower bound technique works for any graph that contains a product graph as a subgraph. Applying it to the Boolean hypercube ${0,1}^n$ and the constant-dimensional grids $[n]^d$, two particular product graphs that recently drew much attention, we get the following tight results: $text{{it RLS/}}({0,1}^n)=Theta(2^{n/2}n^{1/2})$, $text{{it QLS/}}({0,1}^n)=Theta(2^{n/3}n^{1/6})$, $text{{it RLS/}}([n]^d)=Theta(n^{d/2})$ for $dgeq4$, $text{{it QLS/}}([n]^d)=Theta(n^{d/3})$ for $dgeq6$. Here $text{{it RLS/}}(G)$ and $text{{it QLS/}}(G)$ are the randomized and quantum query complexities of Local Search on $G$, respectively. These improve the previous results by Aaronson [in Proceedings of the Thirty-Sixth Annual ACM Symposium on Theory of Computing, 2004, pp. 465-474], Ambainis (unpublished), and Santha and Szegedy [in Proceedings of the Thirty-Sixth Annual ACM Symposium on Theory of Computing, 2004, pp. 494-501]. Our new algorithms work well when the underlying graph expands slowly. As an application to $[n]^2$, a new quantum algorithm using $O(sqrt{n}(loglog n)^{1.5})$ queries is given. This improves the previously best known upper bound of $O(n^{2/3})$ (see Aaronson [in Proceedings of the Thirty-Sixth Annual ACM Symposium on Theory of Computing, 2004, pp. 465-474]), and implies that Local Search on grids exhibits different properties in low dimensions.},
journal = {SIAM J. Comput.},
month = sep,
pages = {948–977},
numpages = {30},
keywords = {optimization, randomized algorithm, randomized decision tree complexity, quantum algorithm, local search, quantum query complexity}
}

@article{10.1137/070705702,
author = {Nguyen, Phong Q. and Stehl\'{e}, Damien},
title = {An LLL Algorithm with Quadratic Complexity},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070705702},
doi = {10.1137/070705702},
abstract = {The Lenstra-Lenstra-Lov\'{a}sz lattice basis reduction algorithm (called LLL or ${rm L}^3$) is a fundamental tool in computational number theory and theoretical computer science, which can be viewed as an efficient algorithmic version of Hermite's inequality on Hermite's constant. Given an integer $d$-dimensional lattice basis with vectors of Euclidean norm less than $B$ in an $n$-dimensional space, the ${rm L}^3$ algorithm outputs a reduced basis in $O(d^3n,{rm log},Bcdotmathcal{M}(d,{rm log},B))$ bit operations, where $mathcal{M}(k)$ denotes the time required to multiply $k$-bit integers. This worst-case complexity is problematic for applications where $d$ or/and ${rm log},B$ are often large. As a result, the original ${rm L}^3$ algorithm is almost never used in practice, except in tiny dimension. Instead, one applies floating-point variants where the long-integer arithmetic required by Gram-Schmidt orthogonalization is replaced by floating-point arithmetic. Unfortunately, this is known to be unstable in the worst case: the usual floating-point ${rm L}^3$ algorithm is not even guaranteed to terminate, and the output basis may not be ${rm L}^3$-reduced at all. In this article, we introduce the ${rm L}^2$ algorithm, a new and natural floating-point variant of the ${rm L}^3$ algorithm which provably outputs ${rm L}^3$-reduced bases in polynomial time $O(d^2n(d+{rm log},B),{rm log},Bcdotmathcal{M}(d))$. This is the first ${rm L}^3$ algorithm whose running time (without fast integer arithmetic) provably grows only quadratically with respect to ${rm log},B$, like Euclid's gcd algorithm and Lagrange's two-dimensional algorithm.},
journal = {SIAM J. Comput.},
month = aug,
pages = {874–903},
numpages = {30},
keywords = {${rm L}^3$, lattice reduction, floating-point arithmetic}
}

@article{10.1137/070701649,
author = {Raskhodnikova, Sofya and Ron, Dana and Shpilka, Amir and Smith, Adam},
title = {Strong Lower Bounds for Approximating Distribution Support Size and the Distinct Elements Problem},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070701649},
doi = {10.1137/070701649},
abstract = {We consider the problem of approximating the support size of a distribution from a small number of samples, when each element in the distribution appears with probability at least $frac{1}{n}$. This problem is closely related to the problem of approximating the number of distinct elements in a sequence of length $n$. Charikar, Chaudhuri, Motwani, and Narasayya [in Proceedings of the Nineteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, 2000, pp. 268-279] and Bar-Yossef, Kumar, and Sivakumar [in Proceedings of the Thirty-Third Annual ACM Symposium on Theory of Computing, ACM Press, New York, 2001, pp. 266-275] proved that multiplicative approximation for these problems within a factor $alpha&gt;1$ requires $Theta(frac{n}{alpha^2})$ queries to the input sequence. Their lower bound applies only when the number of distinct elements (or the support size of a distribution) is very small. For both problems, we prove a nearly linear in $n$ lower bound on the query complexity, applicable even when the number of distinct elements is large (up to linear in $n$) and even for approximation with additive error. At the heart of the lower bound is a construction of two positive integer random variables, $mathsf{X}_1$ and $mathsf{X}_2$, with very different expectations and the following condition on the first $k$ moments: $mathsf{E}[mathsf{X}_1]/mathsf{E}[mathsf{X}_2] = mathsf{E}[mathsf{X}_1^2]/mathsf{E}[mathsf{X}_2^2] = cdots = mathsf{E}[mathsf{X}_1^k]/E[mathsf{X}_2^k]$. It is related to a well-studied mathematical question, the truncated Hamburger problem, but differs in the requirement that our random variables have to be supported on integers. Our lower bound method is also applicable to other problems and, in particular, gives a new lower bound for the sample complexity of approximating the entropy of a distribution.},
journal = {SIAM J. Comput.},
month = aug,
pages = {813–842},
numpages = {30},
keywords = {distinct elements problem, lower bounds, approximation algorithms, Poissonization, distribution support size}
}

@article{10.1137/070699007,
author = {Chen, Ke},
title = {On Coresets for $k$-Median and $k$-Means Clustering in Metric and Euclidean Spaces and Their Applications},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070699007},
doi = {10.1137/070699007},
abstract = {We present new approximation algorithms for the $k$-median and $k$-means clustering problems. To this end, we obtain small coresets for $k$-median and $k$-means clustering in general metric spaces and in Euclidean spaces. In $mathbb{R}^d$, these coresets are of size with polynomial dependency on the dimension $d$. This leads to $(1+varepsilon)$-approximation algorithms to the optimal $k$-median and $k$-means clustering in $mathbb{R}^d$, with running time $O(ndk+2^{(k/varepsilon)^{O(1)}}d^2log^{k+2}n)$, where $n$ is the number of points. This improves over previous results. We use those coresets to maintain a $(1+varepsilon)$-approximate $k$-median and $k$-means clustering of a stream of points in $mathbb{R}^d$, using $O(d^2k^2varepsilon^{-2}log^8n)$ space. These are the first streaming algorithms, for those problems, that have space complexity with polynomial dependency on the dimension.},
journal = {SIAM J. Comput.},
month = aug,
pages = {923–947},
numpages = {25},
keywords = {high dimensions, $k$-median clustering, approximation algorithms, coreset, $k$-means clustering, random sampling}
}

@article{10.1137/07068062X,
author = {Dinur, Irit and Mossel, Elchanan and Regev, Oded},
title = {Conditional Hardness for Approximate Coloring},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/07068062X},
doi = {10.1137/07068062X},
abstract = {We study the AprxColoring$(q,Q)$ problem: Given a graph $G$, decide whether $\chi(G)\le q$ or $\chi(G)\ge Q$. We present hardness results for this problem for any constants $3\le q<Q$. For $q\ge4$, our result is based on Khot's 2-to-1 label cover, which is conjectured to be NP-hard [S. Khot, Proceedings of the 34th Annual ACM Symposium on Theory of Computing, 2002, pp. 767-775]. For $q=3$, we base our hardness result on a certain “${\rhd\hskip-0.5em<}$-shaped” variant of his conjecture. Previously no hardness result was known for $q=3$ and $Q\ge6$. At the heart of our proof are tight bounds on generalized noise-stability quantities, which extend the recent work of Mossel, O'Donnell, and Oleszkiewicz [“Noise stability of functions with low influences: Invariance and optimality,” Ann. of Math. (2), to appear] and should have wider applicability.},
journal = {SIAM J. Comput.},
month = aug,
pages = {843–873},
numpages = {30},
keywords = {graph coloring, unique games, hardness of approximation}
}

@article{10.1137/060678890,
author = {Chang, Kevin L. and Kannan, Ravi},
title = {Pass-Efficient Algorithms for Learning Mixtures of Uniform Distributions},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060678890},
doi = {10.1137/060678890},
abstract = {We present multiple pass streaming algorithms for a basic statistical clustering problem for massive data sets. If our algorithm is allotted $2ell$ passes, it will produce an approximation with error at most $epsilon$ using $tilde{O}(k^3/epsilon^{2/ell})$ bits of memory, the most critical resource for streaming computation. We demonstrate that this tradeoff between passes and memory allotted is intrinsic to the problem and model of computation by proving lower bounds on the memory requirements of any $ell$ pass randomized algorithm that are nearly matched by our upper bounds. In this problem, we are given a set of $n$ points drawn randomly according to a mixture of $k$ uniform distributions and wish to approximate the density function of the mixture. The points are placed in a data stream (possibly in adversarial order), which may only be read in sequential passes by the algorithm. The algorithm is quite general and can be adapted to solve the problems of learning a mixture of linear distributions in $mathbb{R}$ and a mixture of uniform distributions in $mathbb{R}^2$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {783–812},
numpages = {30},
keywords = {streaming, massive data set, machine learning, algorithm}
}

@article{10.1137/060672121,
author = {Czumaj, Artur and Sohler, Christian},
title = {Estimating the Weight of Metric Minimum Spanning Trees in Sublinear Time},
year = {2009},
issue_date = {September 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060672121},
doi = {10.1137/060672121},
abstract = {In this paper we present a sublinear-time $(1+varepsilon)$-approximation randomized algorithm to estimate the weight of the minimum spanning tree of an $n$-point metric space. The running time of the algorithm is $widetilde{mathcal{O}}(n/varepsilon^{mathcal{O}(1)})$. Since the full description of an $n$-point metric space is of size $Theta(n^2)$, the complexity of our algorithm is sublinear with respect to the input size. Our algorithm is almost optimal as it is not possible to approximate in $o(n)$ time the weight of the minimum spanning tree to within any factor. We also show that no deterministic algorithm can achieve a $B$-approximation in $o(n^2/B^3)$ time. Furthermore, it has been previously shown that no $o(n^2)$ algorithm exists that returns a spanning tree whose weight is within a constant times the optimum.},
journal = {SIAM J. Comput.},
month = aug,
pages = {904–922},
numpages = {19},
keywords = {randomized algorithms, sublinear-time algorithms, approximation algorithms}
}

@article{10.1137/SMJCAT000039000002000545000001,
author = {Andrew, Matthew and Nayak, Ashwin and Rajaraman, Rajmohan},
title = {Special Section on Foundations of Computer Science},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000039000002000545000001},
doi = {10.1137/SMJCAT000039000002000545000001},
abstract = {This section comprises fully refereed versions of nine papers that were presented at the Forty-Seventh Annual IEEE Symposium on Foundations of Computer Science (FOCS 2006), held in Berkeley, California, October 22-24, 2006. The FOCS 2006 Program Committee consisted of Sanjeev Arora (chair), Rajeev Alur, Matthew Andrews, Avrim Blum, Moses Charikar, Shuchi Chawla, Jeff Erickson, Lisa Fleischer, Lance Fortnow, Ravi Kannan, Sampath Kannan, Haim Kaplan, Anna Karlin, Joe Kilian, Guy Kindler, Ashwin Nayak, Christos Papadimitriou, Harald R\"{a}cke, Rajmohan Rajaraman, Dana Randall, Michael Saks, Daniel Spielman, and Peter Winkler. The committee selected 71 of 240 papers to be presented at the symposium, and unrefereed preliminary versions of these papers appeared in the conference proceedings, which were published by IEEE.The nine papers selected for this section cover a number of topics and problems in theoretical computer science, including computational geometry, smoothed complexity, learning, list decoding, set partitioning and matching. Each paper was extensively reviewed, and most underwent multiple revisions. We would like to thank all those who contributed to this special section, including the anonymous referees; the SIAM Journal on Computing Editor-in-Chief, Eva Tardos; and SIAM staff members Melissa Buono, Mitch Chernoff, and Cherie Trebisky.},
journal = {SIAM J. Comput.},
month = jul,
pages = {545},
numpages = {1}
}

@article{10.1137/080729967,
author = {Meir, Or},
title = {Combinatorial Construction of Locally Testable Codes},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/080729967},
doi = {10.1137/080729967},
abstract = {An error correcting code is said to be locally testable if there is a test that checks whether a given string is a codeword, or rather far from the code, by reading only a constant number of symbols of the string. While the best known construction of locally testable codes (LTCs) by Ben-Sasson and Sudan [SIAM J. Comput., 38 (2008), pp. 551-607] and Dinur [J. ACM, 54 (2007), article 12] achieves very efficient parameters, it relies heavily on algebraic tools and on probabilistically checkable proof (PCP) machinery. In this work we present a new and arguably simpler construction of LTCs that is purely combinatorial, does not rely on PCP machinery, and matches the parameters of the best known construction. However, unlike the latter construction, our construction is not entirely explicit.},
journal = {SIAM J. Comput.},
month = jul,
pages = {491–544},
numpages = {54},
keywords = {probabilistically checkable proofs (PCPs), PCPs of proximity (PCPPs), locally testable codes (LTCs)}
}

@article{10.1137/07068669X,
author = {Chan, Timothy M. and Paˇtra\c{s}cu, Mihai},
title = {Transdichotomous Results in Computational Geometry, I: Point Location in Sublogarithmic Time},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/07068669X},
doi = {10.1137/07068669X},
abstract = {Given a planar subdivision whose coordinates are integers bounded by $Uleq2^w$, we present a linear-space data structure that can answer point-location queries in $O(min{lg n/lglg n,$ $sqrt{lg U/lglg U}})$ time on the unit-cost random access machine (RAM) with word size $w$. This is the first result to beat the standard $Theta(lg n)$ bound for infinite precision models. As a consequence, we obtain the first $o(nlg n)$ (randomized) algorithms for many fundamental problems in computational geometry for arbitrary integer input on the word RAM, including: constructing the convex hull of a three-dimensional (3D) point set, computing the Voronoi diagram or the Euclidean minimum spanning tree of a planar point set, triangulating a polygon with holes, and finding intersections among a set of line segments. Higher-dimensional extensions and applications are also discussed. Though computational geometry with bounded precision input has been investigated for a long time, improvements have been limited largely to problems of an orthogonal flavor. Our results surpass this long-standing limitation, answering, for example, a question of Willard (SODA'92).},
journal = {SIAM J. Comput.},
month = jul,
pages = {703–729},
numpages = {27},
keywords = {searching, convex hulls, data structures, word-RAM algorithms, segment intersection, sorting, computational geometry, Voronoi diagrams}
}

@article{10.1137/070685798,
author = {Guruswami, Venkatesan and Raghavendra, Prasad},
title = {Hardness of Learning Halfspaces with Noise},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070685798},
doi = {10.1137/070685798},
abstract = {Learning an unknown halfspace (also called a perceptron) from labeled examples is one of the classic problems in machine learning. In the noise-free case, when a halfspace consistent with all the training examples exists, the problem can be solved in polynomial time using linear programming. However, under the promise that a halfspace consistent with a fraction $(1-varepsilon)$ of the examples exists (for some small constant $varepsilon&gt;0$), it was not known how to efficiently find a halfspace that is correct on even 51% of the examples. Nor was a hardness result that ruled out getting agreement on more than 99.9% of the examples known. In this work, we close this gap in our understanding and prove that even a tiny amount of worst-case noise makes the problem of learning halfspaces intractable in a strong sense. Specifically, for arbitrary $epsilon,delta &gt; 0$, we prove that given a set of examples-label pairs from the hypercube, a fraction $(1-varepsilon)$ of which can be explained by a halfspace, it is NP-hard to find a halfspace that correctly labels a fraction $(1/2+delta)$ of the examples. The hardness result is tight since it is trivial to get agreement on $1/2$ the examples. In learning theory parlance, we prove that weak proper agnostic learning of halfspaces is hard. This settles a question that was raised by Blum et al., in their work on learning halfspaces in the presence of random classification noise [Algorithmica, 22 (1998), pp. 35-52], and raised by authors of some more recent works as well. Along the way, we also obtain a strong hardness result for another basic computational problem: solving a linear system over the rationals.},
journal = {SIAM J. Comput.},
month = jul,
pages = {742–765},
numpages = {24},
keywords = {perceptron, hardness of approximation, computational learning}
}

@article{10.1137/070684914,
author = {Feldman, Vitaly and Gopalan, Parikshit and Khot, Subhash and Ponnuswami, Ashok Kumar},
title = {On Agnostic Learning of Parities, Monomials, and Halfspaces},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070684914},
doi = {10.1137/070684914},
abstract = {We study the learnability of several fundamental concept classes in the agnostic learning framework of [D. Haussler, Inform. and Comput., 100 (1992), pp. 78-150] and [M. Kearns, R. Schapire, and L. Sellie, Machine Learning, 17 (1994), pp. 115-141]. We show that under the uniform distribution, agnostically learning parities reduce to learning parities with random classification noise, commonly referred to as the noisy parity problem. Together with the parity learning algorithm of [A. Blum, A. Kalai, and H. Wasserman, J. ACM, 50 (2003), pp. 506-519], this gives the first nontrivial algorithm for agnostic learning of parities. We use similar techniques to reduce learning of two other fundamental concept classes under the uniform distribution to learning of noisy parities. Namely, we show that learning of disjunctive normal form (DNF) expressions reduces to learning noisy parities of just logarithmic number of variables, and learning of $k$-juntas reduces to learning noisy parities of $k$ variables. We give essentially optimal hardness results for agnostic learning of monomials over ${0,1}^n$ and halfspaces over $mathbb{Q}^n$. We show that for any constant $epsilon$ finding a monomial (halfspace) that agrees with an unknown function on $1/2+epsilon$ fraction of the examples is NP-hard even when there exists a monomial (halfspace) that agrees with the unknown function on $1-epsilon$ fraction of the examples. This resolves an open question due to Blum and significantly improves on a number of previous hardness results for these problems. We extend these results to $epsilon=2^{-log^{1-lambda}n}$ ($epsilon=2^{-sqrt{log n}}$ in the case of halfspaces) for any constant $lambda&gt;0$ under stronger complexity assumptions.},
journal = {SIAM J. Comput.},
month = jul,
pages = {606–645},
numpages = {40},
keywords = {parities, halfspaces, monomials, random noise, agnostic learning}
}

@article{10.1137/070684859,
author = {Paˇtra\c{s}cu, Mihai and Thorup, Mikkel},
title = {Higher Lower Bounds for Near-Neighbor and Further Rich Problems},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070684859},
doi = {10.1137/070684859},
abstract = {We convert cell-probe lower bounds for polynomial space into stronger lower bounds for near-linear space. Our technique applies to any lower bound proved through the richness method. For example, it applies to partial match and to near-neighbor problems, either for randomized exact search or for deterministic approximate search (which are thought to exhibit the curse of dimensionality). These problems are motivated by searching in large databases, so near-linear space is the most relevant regime. Typically, richness has been used to imply $Omega(d/lg n)$ lower bounds for polynomial-space data structures, where $d$ is the number of bits of a query. This is the highest lower bound provable through the classic reduction to communication complexity. However, for space $nlg^{O(1)}n$, we now obtain bounds of $Omega(d/lg d)$. This is a significant improvement for natural values of $d$, such as $lg^{O(1)}n$. In the most important case of $d=Theta(lg n)$, we have the first superconstant lower bound. From a complexity-theoretic perspective, our lower bounds are the highest known for any static data structure problem, significantly improving on previous records.},
journal = {SIAM J. Comput.},
month = jul,
pages = {730–741},
numpages = {12},
keywords = {lower bounds, nearest neighbor, cell-probe complexity, data structures}
}

@article{10.1137/070684008,
author = {Harvey, Nicholas J. A.},
title = {Algebraic Algorithms for Matching and Matroid Problems},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070684008},
doi = {10.1137/070684008},
abstract = {We present new algebraic approaches for two well-known combinatorial problems: nonbipartite matching and matroid intersection. Our work yields new randomized algorithms that exceed or match the efficiency of existing algorithms. For nonbipartite matching, we obtain a simple, purely algebraic algorithm with running time $O(n^omega)$ where $n$ is the number of vertices and $omega$ is the matrix multiplication exponent. This resolves the central open problem of Mucha and Sankowski (2004). For matroid intersection, our algorithm has running time $O(nr^{omega-1})$ for matroids with $n$ elements and rank $r$ that satisfy some natural conditions.},
journal = {SIAM J. Comput.},
month = jul,
pages = {679–702},
numpages = {24},
keywords = {nonbipartite matching, fast matrix multiplication, matroid intersection, algebraic algorithms}
}

@article{10.1137/070683994,
author = {Impagliazzo, Russell and Jaiswal, Ragesh and Kabanets, Valentine},
title = {Approximate List-Decoding of Direct Product Codes and Uniform Hardness Amplification},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070683994},
doi = {10.1137/070683994},
abstract = {Given a message $msgin{0,1}^N$, its $k$-wise direct product encoding is the sequence of $k$-tuples $(msg(i_1),dots,msg(i_k))$ over all possible $k$-tuples of indices $(i_1,dots,i_k)in{1,dots,N}^k$. We give an efficient randomized algorithm for approximate local list-decoding of direct product codes. That is, given oracle access to a word which agrees with a $k$-wise direct product encoding of some message $msgin{0,1}^N$ in at least $epsilongeqslant{poly}(1/k)$ fraction of positions, our algorithm outputs a list of ${poly}(1/epsilon)$ strings that contains at least one string $msg'$ which is equal to $msg$ in all but at most $k^{-Omega(1)}$ fraction of positions. The decoding is local in that our algorithm outputs a list of Boolean circuits so that the $j$th bit of the $i$th output string can be computed by running the $i$th circuit on input $j$. The running time of the algorithm is polynomial in $log N$ and $1/epsilon$. In general, when $epsilon&gt;e^{-k^{alpha}}$ for a sufficiently small constant $alpha&gt;0$, we get a randomized approximate list-decoding algorithm that runs in time quasi-polynomial in $1/epsilon$, i.e., $(1/epsilon)^{{poly}log1/epsilon}$. As an application of our decoding algorithm, we get uniform hardness amplification for ${P}^{{NP}_{parallel}}$, the class of languages reducible to ${NP}$ through one round of parallel oracle queries: If there is a language in ${P}^{{NP}_{parallel}}$ that cannot be decided by any ${BPP}$ algorithm on more than $1-1/n^{Omega(1)}$ fraction of inputs, then there is another language in ${P}^{{NP}_{parallel}}$ that cannot be decided by any ${BPP}$ algorithm on more than $1/2+1/n^{omega(1)}$ fraction of inputs.},
journal = {SIAM J. Comput.},
month = jul,
pages = {564–605},
numpages = {42},
keywords = {error-correcting codes, Yao's XOR lemma, approximately list-decodable codes, uniform hardness amplification, direct product theorems}
}

@article{10.1137/070683933,
author = {Bj\"{o}rklund, Andreas and Husfeldt, Thore and Koivisto, Mikko},
title = {Set Partitioning via Inclusion-Exclusion},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070683933},
doi = {10.1137/070683933},
abstract = {Given a set $N$ with $n$ elements and a family $mathcal{F}$ of subsets, we show how to partition $N$ into $k$ such subsets in $2^n n^{O(1)}$ time. We also consider variations of this problem where the subsets may overlap or are weighted, and we solve the decision, counting, summation, and optimization versions of these problems. Our algorithms are based on the principle of inclusion-exclusion and the zeta transform. In effect we get exact algorithms in $2^n n^{O(1)}$ time for several well-studied partition problems including domatic number, chromatic number, maximum $k$-cut, bin packing, list coloring, and the chromatic polynomial. We also have applications to Bayesian learning with decision graphs and to model-based data clustering. If only polynomial space is available, our algorithms run in time $3^n n^{O(1)}$ if membership in $mathcal{F}$ can be decided in polynomial time. We solve chromatic number in $O(2.2461^n)$ time and domatic number in $O(2.8718^n)$ time. Finally, we present a family of polynomial space approximation algorithms that find a number between $chi(G)$ and $lceil(1+epsilon)chi(G)rceil$ in time $O(1.2209^n+2.2461^{e^{-epsilon}n})$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {546–563},
numpages = {18},
keywords = {set partition, inclusion-exclusion, exact algorithm, zeta transform, graph coloring}
}

@article{10.1137/070683921,
author = {Arthur, David and Vassilvitskii, Sergei},
title = {Worst-Case and Smoothed Analysis of the ICP Algorithm, with an Application to the k-Means Method},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070683921},
doi = {10.1137/070683921},
abstract = {We show a worst-case lower bound and a smoothed upper bound on the number of iterations performed by the Iterative Closest Point (ICP) algorithm. First proposed by Besl and McKay, the algorithm is widely used in computational geometry, where it is known for its simplicity and its observed speed. The theoretical study of ICP was initiated by Ezra, Sharir, and Efrat, who showed that the worst-case running time to align two sets of $n$ points in $mathbb{R}^d$ is between $Omega(nlog n)$ and $O(n^2d)^d$. We substantially tighten this gap by improving the lower bound to $Omega(n/d)^{d+1}$. To help reconcile this bound with the algorithm's observed speed, we also show that the smoothed complexity of ICP is polynomial, independent of the dimensionality of the data. Using similar methods, we improve the best known smoothed upper bound for the popular k-means method to $n^{O(k)}$, once again independent of the dimension.},
journal = {SIAM J. Comput.},
month = jul,
pages = {766–782},
numpages = {17},
keywords = {smoothed analysis, k-means, ICP}
}

@article{10.1137/070683386,
author = {Vershynin, Roman},
title = {Beyond Hirsch Conjecture: Walks on Random Polytopes and Smoothed Complexity of the Simplex Method},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070683386},
doi = {10.1137/070683386},
abstract = {The smoothed analysis of algorithms is concerned with the expected running time of an algorithm under slight random perturbations of arbitrary inputs. Spielman and Teng proved that the shadow vertex simplex method has polynomial smoothed complexity. On a slight random perturbation of an arbitrary linear program, the simplex method finds the solution after a walk on polytope(s) with expected length polynomial in the number of constraints $n$, the number of variables $d$, and the inverse standard deviation of the perturbation $1/sigma$. We show that the length of walk in the simplex method is actually polylogarithmic in the number of constraints $n$. Spielman-Teng's bound on the walk was $O^*(n^{86}d^{55}sigma^{-30})$, up to logarithmic factors. We improve this to $O(log^7n(d^9+d^3sigma^{-4}))$. This shows that the tight Hirsch conjecture $n-d$ on the length of walk on polytopes is not a limitation for the smoothed linear programming. Random perturbations create short paths between vertices. We propose a randomized Phase-I for solving arbitrary linear programs, which is of independent interest. Instead of finding a vertex of a feasible set, we add a vertex at random to the feasible set. This does not affect the solution of the linear program with constant probability. So, in expectation it takes a constant number of independent trials until a correct solution is found. This overcomes one of the major difficulties of smoothed analysis of the simplex method—one can now statistically decouple the walk from the smoothed linear program. This yields a much better reduction of the smoothed complexity to a geometric quantity—the size of planar sections of random polytopes. We also improve upon the known estimates for that size, showing that it is polylogarithmic in the number of vertices.},
journal = {SIAM J. Comput.},
month = jul,
pages = {646–678},
numpages = {33},
keywords = {random polytopes, simplex algorithm, smoothed analysis}
}

@article{10.1137/080714403,
author = {Lotker, Zvi and Patt-Shamir, Boaz and Ros\'{e}n, Adi},
title = {Distributed Approximate Matching},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/080714403},
doi = {10.1137/080714403},
abstract = {We consider distributed algorithms for approximate maximum matching on general graphs. Our main result is a randomized $(4+epsilon)$-approximation distributed algorithm for maximum weighted matching, whose running time is $O(log n)$ for any constant $epsilon&gt;0$, where $n$ is the number of nodes in the graph. This is, to the best of our knowledge, the first log-time distributed algorithm that achieves constant approximation for maximum weighted matching on general graphs. In addition, we consider the dynamic case, where nodes are inserted and deleted one at a time. For unweighted dynamic graphs, we give a distributed algorithm that maintains a $(1+epsilon)$-approximation in $O(1/epsilon)$ time for each node insertion or deletion for any constant $epsilon&gt;0$. For weighted dynamic graphs we give a constant-factor approximation distributed algorithm that runs in constant time for each insertion or deletion.},
journal = {SIAM J. Comput.},
month = jun,
pages = {445–460},
numpages = {16},
keywords = {distributed algorithms, dynamic algorithms, distributed approximation algorithms, graph algorithms, maximum matching}
}

@article{10.1137/070700371,
author = {Semaev, Igor},
title = {Sparse Algebraic Equations over Finite Fields},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070700371},
doi = {10.1137/070700371},
abstract = {A system of algebraic equations over a finite field is called sparse if each equation depends on a low number of variables. Efficiently finding solutions to the system is an underlying hard problem in cryptanalysis of modern ciphers. In this paper the deterministic Agreeing-Gluing algorithm introduced earlier by Raddum and Semaev for solving such equations is studied. Its expected running time on uniformly random instances of the problem is rigorously estimated. The estimate is at present the best theoretical bound on the complexity of solving average instances of the problem. In sparse Boolean equations we observe an exciting difference with the worst-case complexity provided by SAT solving methods.},
journal = {SIAM J. Comput.},
month = jun,
pages = {388–409},
numpages = {22},
keywords = {sparse algebraic equations, agreeing, gluing, finite fields}
}

@article{10.1137/070699160,
author = {Maletti, Andreas and Graehl, Jonathan and Hopkins, Mark and Knight, Kevin},
title = {The Power of Extended Top-Down Tree Transducers},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070699160},
doi = {10.1137/070699160},
abstract = {Extended top-down tree transducers (transducteurs g\'{e}n\'{e}ralis\'{e}s descendants; see [A. Arnold and M. Dauchet, Bi-transductions de for\^{e}ts, in Proceedings of the 3rd International Colloquium on Automata, Languages and Programming, Edinburgh University Press, Edinburgh, 1976, pp. 74-86]) received renewed interest in the field of natural language processing. Here those transducers are extensively and systematically studied. Their main properties are identified and their relation to classical top-down tree transducers is exactly characterized. The obtained properties completely explain the Hasse diagram of the induced classes of tree transformations. In addition, it is shown that most interesting classes of transformations computed by extended top-down tree transducers are not closed under composition.},
journal = {SIAM J. Comput.},
month = jun,
pages = {410–430},
numpages = {21},
keywords = {hierarchy, composition closure, natural language processing, tree transducer}
}

@article{10.1137/070695149,
author = {Czumaj, Artur and Lingas, Andrzej},
title = {Finding a Heaviest Vertex-Weighted Triangle Is Not Harder than Matrix Multiplication},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070695149},
doi = {10.1137/070695149},
abstract = {We show that a maximum-weight triangle in an undirected graph with $n$ vertices and real weights assigned to vertices can be found in time $mathcal{O}(n^{omega}+n^{2+o(1)})$, where $omega$ is the exponent of the fastest matrix multiplication algorithm. By the currently best bound on $omega$, the running time of our algorithm is $mathcal{O}(n^{2.376})$. Our algorithm substantially improves the previous time-bounds for this problem, and its asymptotic time complexity matches that of the fastest known algorithm for finding any triangle (not necessarily a maximum-weight one) in a graph. We can extend our algorithm to improve the upper bounds on finding a maximum-weight triangle in a sparse graph and on finding a maximum-weight subgraph isomorphic to a fixed graph. We can find a maximum-weight triangle in a vertex-weighted graph with $m$ edges in asymptotic time required by the fastest algorithm for finding any triangle in a graph with $m$ edges, i.e., in time $mathcal{O}(m^{1.41})$. Our algorithms for a maximum-weight fixed subgraph (in particular any clique of constant size) are asymptotically as fast as the fastest known algorithms for a fixed subgraph.},
journal = {SIAM J. Comput.},
month = jun,
pages = {431–444},
numpages = {14},
keywords = {vertex-weighted graph, graph triangle, time complexity, graph algorithms, matrix multiplication}
}

@article{10.1137/070685671,
author = {Karloff, Howard and Khot, Subhash and Mehta, Aranyak and Rabani, Yuval},
title = {On Earthmover Distance, Metric Labeling, and 0-Extension},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070685671},
doi = {10.1137/070685671},
abstract = {We study the fundamental classification problems 0-Extension and Metric Labeling. A generalization of Multiway Cut, 0-Extension is closely related to partitioning problems in graph theory and to Lipschitz extensions in Banach spaces; its generalization Metric Labeling is motivated by applications in computer vision. Researchers had proposed using earthmover metrics to get polynomial-time-solvable relaxations for these problems. A conjecture that has attracted much attention recently is that the integrality ratio for these relaxations is constant. We prove (1) that the integrality ratio of the earthmover relaxation for Metric Labeling is $Omega(log k)$ (which is asymptotically tight), $k$ being the number of labels, whereas the best previous lower bound on the integrality ratio was only constant; (2) that the integrality ratio of the earthmover relaxation for 0-Extension is $Omega(sqrt{log k})$, $k$ being the number of terminals (it was known to be $O((log k)/loglog k)$), whereas the best previous lower bound was only constant; (3) that for no $epsilon&gt;0$ is there a polynomial-time $O((log n)^{1/4-epsilon})$-approximation algorithm for 0-Extension, $n$ being the number of vertices, unless NP$subseteq$DTIME$(n^{mathrm{poly}(log n)})$, whereas the strongest inapproximability result known before was only MAX SNP-hardness; and (4) that there is a polynomial-time approximation algorithm for 0-Extension with performance ratio $O(sqrt{mathrm{diam}(d)})$, where $mathrm{diam}(d)$ is the ratio of the largest to smallest nonzero distances in the terminal metric.},
journal = {SIAM J. Comput.},
month = jun,
pages = {371–387},
numpages = {17},
keywords = {metric labeling, earthmover distance, multiway cut, 0-extension}
}

@article{10.1137/070682885,
author = {Koenig, Sven and Mitchell, Joseph S. B. and Mudgal, Apurva and Tovey, Craig},
title = {A Near-Tight Approximation Algorithm for the Robot Localization Problem},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/070682885},
doi = {10.1137/070682885},
abstract = {Localization is a fundamental problem in robotics. The “kidnapped robot” possesses a compass and map of its environment; it must determine its location at a minimum cost of travel distance. The problem is NP-hard [G. Dudek, K. Romanik, and S. Whitesides, SIAM J. Comput., 27 (1998), pp. 583-604] even to minimize within factor $clog n$ [C. Tovey and S. Koenig, Proceedings of the National Conference on Artificial Intelligence, Austin, TX, 2000, pp. 819-824], where $n$ is the map size. No approximation algorithm has been known. We give an $O(log^3n)$-factor algorithm. The key idea is to plan travel in a “majority-rule” map, which eliminates uncertainty and permits a link to the $frac{1}{2}$-Group Steiner (not Group Steiner) problem. The approximation factor is not far from optimal: we prove a $clog^{2-epsilon}n$ lower bound, assuming $NPnotsubseteq ZTIME(n^{polylog(n)})$, for the grid graphs commonly used in practice. We also extend the algorithm to polygonal maps by discretizing the problem using novel geometric techniques.},
journal = {SIAM J. Comput.},
month = jun,
pages = {461–490},
numpages = {30},
keywords = {approximation algorithm, kidnapped robot, computational geometry, localization, robotics, hardness of approximation}
}

@article{10.1137/060661946,
author = {Alon, Noga and Awerbuch, Baruch and Azar, Yossi and Buchbinder, Niv and Naor, Joseph Seffi},
title = {The Online Set Cover Problem},
year = {2009},
issue_date = {June 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/060661946},
doi = {10.1137/060661946},
abstract = {Let $X={1,2,ldots,n}$ be a ground set of $n$ elements, and let ${cal S}$ be a family of subsets of $X$, $|{cal S}|=m$, with a positive cost $c_S$ associated with each $Sin{cal S}$. Consider the following online version of the set cover problem, described as a game between an algorithm and an adversary. An adversary gives elements to the algorithm from $X$ one by one. Once a new element is given, the algorithm has to cover it by some set of ${cal S}$ containing it. We assume that the elements of $X$ and the members of ${cal S}$ are known in advance to the algorithm; however, the set $X'subseteq X$ of elements given by the adversary is not known in advance to the algorithm. (In general, $X'$ may be a strict subset of $X$.) The objective is to minimize the total cost of the sets chosen by the algorithm. Let ${cal C}$ denote the family of sets in ${cal S}$ that the algorithm chooses. At the end of the game the adversary also produces (offline) a family of sets ${cal C}_{OPT}$ that covers $X'$. The performance of the algorithm is the ratio between the cost of ${cal C}$ and the cost of ${cal C}_{OPT}$. The maximum ratio, taken over all input sequences, is the competitive ratio of the algorithm. We present an $O(log mlog n)$ competitive deterministic algorithm for the problem and establish a nearly matching $Omegabigl(frac{log nlog m}{loglog m+loglog n}bigr)$ lower bound for all interesting values of $m$ and $n$. The techniques used are motivated by similar techniques developed in computational learning theory for online prediction (e.g., the WINNOW algorithm) together with a novel way of converting a fractional solution into a deterministic online algorithm.},
journal = {SIAM J. Comput.},
month = jun,
pages = {361–370},
numpages = {10},
keywords = {online, competitive factor, set cover}
}

@article{10.5555/1654708.1654720,
author = {Aaronson, Scott and Guha, Sudipto and Kleinberg, Jon and McSherry, Frank and van Melkebeek, Dieter and Sahai, Amit},
title = {Special Issue On The Thirty-Eighth Annual ACM Symposium On Theory Of Computing (STOC 2006)},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
abstract = {In keeping with an annual tradition, this issue of the SIAM Journal on Computing contains extended versions of selected papers from the Thirty-Eighth Annual ACM Symposium on Theory of Computing (STOC 2006), which was held May 21-23, 2006, in Seattle, Washington.The conference program included 78 papers selected by a program committee consisting of Scott Aaronson, Eli Ben-Sasson, Allan Borodin, David Eppstein, Sudipto Guha, Piotr Indyk, Jon Kleinberg, Tal Malkin, Frank McSherry, Dieter van Melkebeek, Michael Mitzenmacher, Assaf Naor, Rafail Ostrovsky, Toniann Pitassi, R. Ravi, Dana Ron, Amin Saberi, Amit Sahai, Rocco Servedio, and Madhu Sudan. Preliminary versions of these papers appeared in the conference proceedings published by ACM Press.This special issue contains 11 of these papers; the authors were invited by the program committee to prepare extended versions of their papers, which were then refereed according to the journal's high standards. In the process, these papers were considerably revised and expanded. Collectively, they represent some of the recent highlights from a broad cross-section of active areas within theoretical computer science, including randomness in computation, approximation algorithms and inapproximability, proof complexity, property testing, constraint satisfaction, quantum computing, algorithmic game theory, and high-dimensional geometric algorithms.In total, the six of us listed below handled the editing of these papers. We would like to thank all of the referees and the full program committee for their contributions to the preparation of this special issue.},
journal = {SIAM J. Comput.},
month = may,
pages = {.7},
numpages = {1}
}

@article{10.1137/080723880,
author = {Ben-Sasson, Eli},
title = {Size-Space Tradeoffs for Resolution},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080723880},
doi = {10.1137/080723880},
abstract = {We investigate tradeoffs of various basic complexity measures such as size, space, and width. We show examples of formulas that have optimal proofs with respect to any one of these parameters, but optimizing one parameter must cost an increase in the other. These results have implications to the efficiency (or rather, inefficiency) of some commonly used SAT solving heuristics. Our proof relies on a novel connection of the variable space of a proof to the black-white pebbling measure of an underlying graph.},
journal = {SIAM J. Comput.},
month = may,
pages = {2511–2525},
numpages = {15},
keywords = {proof length, automated theorem provers, resolution, propositional proof complexity}
}

@article{10.1137/070699652,
author = {Daskalakis, Constantinos and Goldberg, Paul W. and Papadimitriou, Christos H.},
title = {The Complexity of Computing a Nash Equilibrium},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/070699652},
doi = {10.1137/070699652},
abstract = {In 1951, John F. Nash proved that every game has a Nash equilibrium [Ann. of Math. (2), 54 (1951), pp. 286-295]. His proof is nonconstructive, relying on Brouwer's fixed point theorem, thus leaving open the questions, Is there a polynomial-time algorithm for computing Nash equilibria? And is this reliance on Brouwer inherent? Many algorithms have since been proposed for finding Nash equilibria, but none known to run in polynomial time. In 1991 the complexity class PPAD (polynomial parity arguments on directed graphs), for which Brouwer's problem is complete, was introduced [C. Papadimitriou, J. Comput. System Sci., 48 (1994), pp. 489-532], motivated largely by the classification problem for Nash equilibria; but whether the Nash problem is complete for this class remained open. In this paper we resolve these questions: We show that finding a Nash equilibrium in three-player games is indeed PPAD-complete; and we do so by a reduction from Brouwer's problem, thus establishing that the two problems are computationally equivalent. Our reduction simulates a (stylized) Brouwer function by a graphical game [M. Kearns, M. Littman, and S. Singh, Graphical model for game theory, in 17th Conference in Uncertainty in Artificial Intelligence (UAI), 2001], relying on “gadgets,” graphical games performing various arithmetic and logical operations. We then show how to simulate this graphical game by a three-player game, where each of the three players is essentially a color class in a coloring of the underlying graph. Subsequent work [X. Chen and X. Deng, Setting the complexity of 2-player Nash-equilibrium, in 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS), 2006] established, by improving our construction, that even two-player games are PPAD-complete; here we show that this result follows easily from our proof.},
journal = {SIAM J. Comput.},
month = may,
pages = {195–259},
numpages = {65},
keywords = {Nash equilibrium, PPAD-completeness, complexity, game theory}
}

@article{10.1137/070681612,
author = {Samorodnitsky, Alex and Trevisan, Luca},
title = {Gowers Uniformity, Influence of Variables, and PCPs},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/070681612},
doi = {10.1137/070681612},
abstract = {We study the relation of query complexity and soundness in probabilistically checkable proofs (PCPs). We present a PCP verifier for languages that are Unique-Games-Hard and such that the verifier makes $q$ queries, has almost perfect completeness, and has soundness error at most $2q/2^q+varepsilon$ for arbitrarily small $varepsilon&gt;0$. For values of $q$ of the form $2^t-1$, the soundness error is $(q+1)/2^q+varepsilon$. Charikar, Makarychev, and Makarychev show that there is a constant $beta$ such that every language that has a verifier of query complexity $q$ and a ratio of soundness error to completeness smaller than $beta q/2^q$ is decidable in polynomial time. Up to the value of the multiplicative constant and to the validity of the Unique Games Conjecture, our result is therefore tight. As a corollary, we show that approximating the Maximum Independent Set problem in graphs of degree $Delta$ within a factor better than $Delta/(logDelta)^alpha$ is Unique-Games-Hard for a certain constant $alpha&gt;0$. Our main technical results are (i) a connection between the Gowers uniformity of a boolean function and the influence of its variables and (ii) the proof that “Gowers uniform” functions pass the “hypergraph linearity test” approximately with the same probability of a random function. The connection between Gowers uniformity and influence might have other applications.},
journal = {SIAM J. Comput.},
month = may,
pages = {323–360},
numpages = {38},
keywords = {Gowers uniformity, computational complexity, influence of variables, probabilistically checkable proofs (PCPs)}
}

@article{10.1137/070680977,
author = {Feige, Uriel},
title = {On Maximizing Welfare When Utility Functions Are Subadditive},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/070680977},
doi = {10.1137/070680977},
abstract = {We consider the problem of maximizing welfare when allocating $m$ items to $n$ players with subadditive utility functions. Our main result is a way of rounding any fractional solution to a linear programming relaxation to this problem so as to give a feasible solution of welfare at least $1/2$ that of the value of the fractional solution. This approximation ratio of $1/2$ is an improvement over an $Omega(1/log m)$ ratio of Dobzinski, Nisan, and Schapira [Proceedings of the 37th Annual ACM Symposium on Theory of Computing (Baltimore, MD), ACM, New York, 2005, pp. 610-618]. We also show an approximation ratio of $1-1/e$ when utility functions are fractionally subadditive. A result similar to this last result was previously obtained by Dobzinski and Schapira [Proceedings of the 17th Annual ACM-SIAM Symposium on Discrete Algorithms (Miami, FL), SIAM, Philadelphia, 2006, pp. 1064-1073], but via a different rounding technique that requires the use of a so-called “XOS oracle.” The randomized rounding techniques that we use are oblivious in the sense that they only use the primal solution to the linear program relaxation, but have no access to the actual utility functions of the players.},
journal = {SIAM J. Comput.},
month = may,
pages = {122–142},
numpages = {21},
keywords = {randomized rounding, linear programming, combinatorial auctions, approximation algorithms}
}

@article{10.1137/070680382,
author = {Achlioptas, Dimitris and Ricci-Tersenghi, Federico},
title = {Random Formulas Have Frozen Variables},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/070680382},
doi = {10.1137/070680382},
abstract = {For a large number of random constraint satisfaction problems, such as random $k$-SAT and random graph and hypergraph coloring, there exist very good estimates of the largest constraint density for which solutions exist. All known polynomial-time algorithms for these problems, though, fail to find solutions even at much lower densities. To understand the origin of this gap one can study how the structure of the space of solutions evolves in such problems as constraints are added. In particular, it is known that much before solutions disappear, they organize into an exponential number of clusters, each of which is relatively small and far apart from all other clusters. Here we further prove that inside every cluster the vast majority of variables are frozen, i.e., take only one value. The existence of such frozen variables gives a satisfying intuitive explanation for the failure of the polynomial-time algorithms analyzed so far. At the same time, our results lend support to one of the two main hypotheses underlying Survey Propagation, a heuristic introduced by physicists in recent years that appears to perform extraordinarily well on random constraint satisfaction problems.},
journal = {SIAM J. Comput.},
month = may,
pages = {260–280},
numpages = {21},
keywords = {phase transitions, frozen variables, random formulas, satisfiability}
}

@article{10.1137/060674442,
author = {Chekuri, Chandra and Khanna, Sanjeev and Shepherd, F. Bruce},
title = {Edge-Disjoint Paths in Planar Graphs with Constant Congestion},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060674442},
doi = {10.1137/060674442},
abstract = {We study the maximum edge-disjoint paths problem in undirected planar graphs: given a graph $G$ and node pairs (demands) $s_1t_1$, $s_2t_2$, $dots$, $s_kt_k$, the goal is to maximize the number of demands that can be connected (routed) by edge-disjoint paths. The natural multicommodity flow relaxation has an $Omega(sqrt{n})$ integrality gap, where $n$ is the number of nodes in $G$. Motivated by this, we consider solutions with small constant congestion $c&gt;1$, that is, solutions in which up to $c$ paths are allowed to use an edge (alternatively, each edge has a capacity of $c$). In previous work we obtained an $O(log n)$ approximation with congestion 2 via the flow relaxation. This was based on a method of decomposing into well-linked subproblems. In this paper we obtain an $O(1)$ approximation with congestion 4. To obtain this improvement we develop an alternative decomposition that is specific to planar graphs. The decomposition produces instances that we call Okamura-Seymour (OS) instances. These have the property that all terminals lie on a single face. Another ingredient we develop is a constant factor approximation for the all-or-nothing flow problem on OS instances via the flow relaxation.},
journal = {SIAM J. Comput.},
month = may,
pages = {281–301},
numpages = {21},
keywords = {edge-disjoint paths, multicommodity flow, planar graphs, congestion}
}

@article{10.1137/060673096,
author = {Ailon, Nir and Chazelle, Bernard},
title = {The Fast Johnson-Lindenstrauss Transform and Approximate Nearest Neighbors},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060673096},
doi = {10.1137/060673096},
abstract = {We introduce a new low-distortion embedding of $ell_2^d$ into $ell_p^{O(log n)}$ ($p=1,2$) called the fast Johnson-Lindenstrauss transform (FJLT). The FJLT is faster than standard random projections and just as easy to implement. It is based upon the preconditioning of a sparse projection matrix with a randomized Fourier transform. Sparse random projections are unsuitable for low-distortion embeddings. We overcome this handicap by exploiting the “Heisenberg principle” of the Fourier transform, i.e., its local-global duality. The FJLT can be used to speed up search algorithms based on low-distortion embeddings in $ell_1$ and $ell_2$. We consider the case of approximate nearest neighbors in $ell_2^d$. We provide a faster algorithm using classical projections, which we then speed up further by plugging in the FJLT. We also give a faster algorithm for searching over the hypercube.},
journal = {SIAM J. Comput.},
month = may,
pages = {302–322},
numpages = {21},
keywords = {random matrices, dimension reduction, approximate nearest neighbors}
}

@article{10.1137/060671218,
author = {Rao, Anup},
title = {Extractors for a Constant Number of Polynomially Small Min-Entropy Independent Sources},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060671218},
doi = {10.1137/060671218},
abstract = {We consider the problem of randomness extraction from independent sources. We construct an extractor that can extract from a constant number of independent sources of length $n$, each of which have min-entropy $n^gamma$, for an arbitrarily small constant $gamma&gt;0$. Our extractor is obtained by composing seeded extractors in simple ways. We introduce a new technique to condense independent somewhere-random sources which looks like a useful way to manipulate independent sources. Our techniques are different from those used in recent work [B. Barak, R. Impagliazzo, and A. Wigderson, SIAM J. Comput., 36 (2006), pp. 1095-1118; B. Barak, G. Kindler, R. Shaltiel, B. Sudakov, and A. Wigderson, Simulating independence: New constructions of condensers, Ramsey graphs, dispersers, and extractors, in Proceedings of the 37th Annual ACM Symposium on Theory of Computing, ACM, New York, 2005, pp. 1-10; R. Raz, Extractors with weak random seeds, in Proceedings of the 37th Annual ACM Symposium on Theory of Computing, ACM, New York, 2005, pp. 11-20; J. Bourgain, Int. J. Number Theory, 1 (2005), pp. 1-32] for this problem in the sense that they do not rely on any results from arithmetic combinatorics. Using an extractor of Bourgain's [Int. J. Number Theory, 1 (2005), pp. 1-32] as a black box, we obtain a new extractor for two independent block sources with few blocks, even when the min-entropy is as small as $operatorname{polylog}(n)$. We also show how to modify the 2 source disperser for linear min-entropy of Barak et al. [Simulating independence: New constructions of condensers, Ramsey graphs, dispersers, and extractors, in Proceedings of the 37th Annual ACM Symposium on Theory of Computing, ACM, New York, 2005, pp. 1-10] and the three source extractor of Raz [Extractors with weak random seeds, in Proceedings of the 37th Annual ACM Symposium on Theory of Computing, ACM, New York, 2005, pp. 11-20] to get dispersers/extractors with exponentially small error and linear output length where previously both were constant.},
journal = {SIAM J. Comput.},
month = may,
pages = {168–194},
numpages = {27},
keywords = {extractor, Ramsey graphs, independent sources}
}

@article{10.1137/060670997,
author = {Watrous, John},
title = {Zero-Knowledge against Quantum Attacks},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060670997},
doi = {10.1137/060670997},
abstract = {This paper proves that several interactive proof systems are zero-knowledge against general quantum attacks. This includes the well-known Goldreich-Micali-Wigderson classical zero-knowledge protocols for graph isomorphism and graph 3-coloring (assuming the existence of quantum computationally concealing commitment schemes in the second case). Also included is a quantum interactive proof system for a complete problem for the complexity class of problems having honest verifier quantum statistical zero-knowledge proofs, which therefore establishes that honest verifier and general quantum statistical zero-knowledge are equal: $mathrm{QSZK}= mathrm{QSZK}_{mathrm{HV}}$. Previously no nontrivial interactive proof systems were known to be zero-knowledge against quantum attacks, except in restricted settings such as the honest verifier and common reference string models. This paper therefore establishes for the first time that true zero-knowledge is indeed possible in the presence of quantum information and computation.},
journal = {SIAM J. Comput.},
month = may,
pages = {25–58},
numpages = {34},
keywords = {interactive proof systems, quantum cryptography, zero-knowledge}
}

@article{10.1137/060668250,
author = {Nordstr\"{o}m, Jakob},
title = {Narrow Proofs May Be Spacious:Separating Space and Width in Resolution},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060668250},
doi = {10.1137/060668250},
abstract = {The width of a resolution proof is the maximal number of literals in any clause of the proof. The space of a proof is the maximal number of clauses kept in memory simultaneously if the proof is only allowed to infer new clauses from clauses currently in memory. Both of these measures have previously been studied and related to the resolution refutation size of unsatisfiable conjunctive normal form (CNF) formulas. Also, the minimum refutation space of a formula has been proven to be at least as large as the minimum refutation width, but it has been open whether space can be separated from width or the two measures coincide asymptotically. We prove that there is a family of $k$-CNF formulas for which the refutation width in resolution is constant but the refutation space is nonconstant, thus solving a problem mentioned in several previous papers.},
journal = {SIAM J. Comput.},
month = may,
pages = {59–121},
numpages = {63},
keywords = {separation, pebble game, width, resolution, lower bound, pebbling contradiction, proof complexity, space}
}

@article{10.1137/060667177,
author = {Alon, Noga and Fischer, Eldar and Newman, Ilan and Shapira, Asaf},
title = {A Combinatorial Characterization of the Testable Graph Properties: It's All About Regularity},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060667177},
doi = {10.1137/060667177},
abstract = {A common thread in all of the recent results concerning the testing of dense graphs is the use of Szemer\'{e}di's regularity lemma. In this paper we show that in some sense this is not a coincidence. Our first result is that the property defined by having any given Szemer\'{e}di-partition is testable with a constant number of queries. Our second and main result is a purely combinatorial characterization of the graph properties that are testable with a constant number of queries. This characterization (roughly) says that a graph property ${cal P}$ can be tested with a constant number of queries if and only if testing ${cal P}$ can be reduced to testing the property of satisfying one of finitely many Szemer\'{e}di-partitions. This means that in some sense, testing for Szemer\'{e}di-partitions is as hard as testing any testable graph property. We thus resolve one of the main open problems in the area of property-testing, which was first raised by Goldreich, Goldwasser, and Ron [J. ACM, 45 (1998), pp. 653-750] in the paper that initiated the study of graph property-testing. This characterization also gives an intuitive explanation as to what makes a graph property testable.},
journal = {SIAM J. Comput.},
month = may,
pages = {143–167},
numpages = {25},
keywords = {testable, characterization, property testing, regularity lemma}
}

@article{10.1137/060665798,
author = {Gavinsky, Dmitry and Kempe, Julia and Regev, Oded and de Wolf, Ronald},
title = {Bounded-Error Quantum State Identification and Exponential Separations in Communication Complexity},
year = {2009},
issue_date = {May 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {39},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060665798},
doi = {10.1137/060665798},
abstract = {We consider the following problem of bounded-error quantum state identification: Given either state $alpha_0$ or state $alpha_1$, we are required to output “0”, “1”, or “?” (“don't know"), such that conditioned on outputting “0” or “1”, our guess is correct with high probability. The goal is to maximize the probability of not outputting “?”. We prove the following direct product theorem: If we are given two such problems, with optimal probabilities $a$ and $b$, respectively, and the states in the first problem are pure, then the optimal probability for the joint bounded-error state identification problem is $O(ab)$. Our proof is based on semidefinite programming duality. Using this result, we present two exponential separations in the simultaneous message passing model of communication complexity. First, we describe a relation that can be computed with $O(log n)$ classical bits of communication in the presence of shared randomness, but needs $Omega(n^{1/3})$ communication if the parties don't share randomness, even if communication is quantum. This shows the optimality of Yao's recent exponential simulation of shared-randomness protocols by quantum protocols without shared randomness. Combined with an earlier separation in the other direction due to Bar-Yossef, Jayram, and Kerenidis, this shows that the quantum simultaneous message passing (SMP) model is incomparable with the classical shared-randomness SMP model. Second, we describe a relation that can be computed with $O(log n)$ classical bits of communication in the presence of shared entanglement, but needs $Omega((n/log n)^{1/3})$ communication if the parties share randomness but no entanglement, even if communication is quantum. This is the first example in communication complexity of a situation where entanglement buys much more than quantum communication.},
journal = {SIAM J. Comput.},
month = may,
pages = {1–24},
numpages = {24},
keywords = {communication complexity, quantum communication, entanglement, semidefinite programs, exponential separations, duality, state identification}
}

@article{10.1137/080717651,
author = {Awerbuch, Baruch and Khandekar, Rohit},
title = {Stateless Distributed Gradient Descent for Positive Linear Programs},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080717651},
doi = {10.1137/080717651},
abstract = {We develop a framework of distributed and stateless solutions for packing and covering linear programs (LPs), which are solved by multiple agents operating in a cooperative but uncoordinated manner. Our model has a separate “agent” controlling each variable, and an agent is allowed to read off the current values only of those constraints in which it has nonzero coefficients. This is a natural model for many distributed applications like flow control, maximum bipartite matching, and dominating sets. The most appealing features of our algorithms are their simplicity and polylogarithmic convergence. For the packing LP $max{ccdot xmid Axleq b,$ $xgeq0}$, the algorithm associates a dual variable $y_i=exp[frac{1}{epsilon}(frac{A_ix}{b_i}-1)]$ for each constraint $i$, and each agent $j$ iteratively increases (resp., decreases) $x_j$ multiplicatively if $A_j^top y$ is too small (resp., large) as compared to $c_j$. Our algorithm, starting from a feasible solution, always maintains feasibility and computes a $(1+epsilon)$ approximation in $mathrm{poly}(frac{ln(mncdot A_{max})}{epsilon})$ rounds. Here $m$ and $n$ are number of rows and columns of $A$, and $A_{max}$, also known as the “width” of the LP, is the ratio of the maximum and the minimum nonzero values taken by the expression $A_{ij}/(b_ic_j)$ as the pair $i,j$ varies over the matrix. A similar algorithm works for the covering LP $min{bcdot ymid A^top ygeq c,$ $ygeq0}$ as well. While exponential dual variables have been used in several packing/covering linear programming (LP) algorithms before [S. Plotkin, D. Shmoys, and E. Tardos, Math. Oper. Res., 20 (1995), pp. 257-301; Y. Bartal, J. W. Byers, and D. Raz, Proceedings of the IEEE Symposium on Foundations of Computer Science, 1997; N. Garg and J. K\"{o}nemann, SIAM J. Comput., 37 (2007), pp. 630-652; L. K. Fleischer, SIAM J. Discrete Math., 13 (2000), pp. 505-520; N. E. Young, Proceedings of the IEEE Symposium on Foundations of Computer Science, 2001; C. Koufogiannakis and N. E. Young, Proceedings of the IEEE Symposium on Foundations of Computer Science, 2007], this is the first algorithm which is both stateless and has polylogarithmic convergence. Our algorithms can be thought of as applying distributed gradient descent/ascent on a carefully chosen potential. Our analysis differs from those of previous multiplicative update based algorithms and argues that while the current solution is far away from optimality, the potential function decreases/increases by a significant factor.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2468–2486},
numpages = {19},
keywords = {fast convergence, distributed and stateless algorithms, gradient descent, linear programming}
}

@article{10.1137/070681831,
author = {Czumaj, Artur and Shapira, Asaf and Sohler, Christian},
title = {Testing Hereditary Properties of Nonexpanding Bounded-Degree Graphs},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070681831},
doi = {10.1137/070681831},
abstract = {We study graph properties that are testable for bounded-degree graphs in time independent of the input size. Our goal is to distinguish between graphs having a predetermined graph property and graphs that are far from every graph having that property. It is well known that in the bounded-degree graph model (where two graphs are considered “far” if they differ in $varepsilon n$ edges for a positive constant $varepsilon$), many graph properties cannot be tested even with a constant or even with a polylogarithmic number of queries. Therefore in this paper we focus our attention on testing graph properties for special classes of graphs. Specifically, we show that every hereditary graph property is testable with a constant number of queries provided that every sufficiently large induced subgraph of the input graph has poor expansion. This result implies that, for example, any hereditary property (e.g., $k$-colorability, $H$-freeness, etc.) is testable in the bounded-degree graph model for planar graphs, graphs with bounded genus, interval graphs, etc. No such results have been known before, and prior to our work, very few graph properties have been known to be testable with a constant number of queries for general graph classes in the bounded-degree graph model.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2499–2510},
numpages = {12},
keywords = {hereditary graph properties, approximation algorithms, bounded-degree graphs, randomized algorithms, property testing, planar graphs, nonexpanding graphs}
}

@article{10.1137/070680801,
author = {Kozik, Marcin},
title = {A 2EXPTIME Complete Varietal Membership Problem},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070680801},
doi = {10.1137/070680801},
abstract = {We construct a finite algebra generating a variety with 2EXPTIME complete membership problem. This proves that the universal membership problem for varieties and the varietal equivalence problem are 2EXPTIME complete as well, answering the question of Bergman and Slutzki from 2000.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2443–2467},
numpages = {25},
keywords = {computational complexity, varietal membership problem, hyperexponential time, alternating Turing machine}
}

@article{10.1137/060660126,
author = {Krauthgamer, Robert and Rabani, Yuval},
title = {Improved Lower Bounds for Embeddings into $L_1$},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060660126},
doi = {10.1137/060660126},
abstract = {We improve upon recent lower bounds on the minimum distortion of embedding certain finite metric spaces into $L_1$. In particular, we show that for every $nge1$, there is an $n$-point metric space of negative type that requires a distortion of $Omega(loglog n)$ for such an embedding, implying the same lower bound on the integrality gap of a well-known semidefinite programming relaxation for sparsest cut. This result builds upon and improves the recent lower bound of $(loglog n)^{1/6-o(1)}$ due to Khot and Vishnoi [The unique games conjecture, integrality gap for cut problems and the embeddability of negative type metrics into $l_1$, in Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, IEEE, Piscataway, NJ, 2005, pp. 53-62]. We also show that embedding the edit distance metric on ${0,1}^n$ into $L_1$ requires a distortion of $Omega(log n)$. This result improves a very recent $(log n)^{1/2-o(1)}$ lower bound by Khot and Naor [Nonembeddability theorems via Fourier analysis, in Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, IEEE, Piscataway, NJ, 2005, pp. 101-112].},
journal = {SIAM J. Comput.},
month = apr,
pages = {2487–2498},
numpages = {12},
keywords = {semidefinite programming relaxation, approximation algorithms, integrality gap, edit distance, graph partitioning, negative type metrics, metric embeddings}
}

@article{10.1137/080723971,
author = {Adleman, Leonard and Kari, Jarkko and Kari, Lila and Reishus, Dustin and Sosik, Petr},
title = {The Undecidability of the Infinite Ribbon Problem: Implications for Computing by Self-Assembly},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080723971},
doi = {10.1137/080723971},
abstract = {Self-assembly, the process by which objects autonomously come together to form complex structures, is omnipresent in the physical world. Recent experiments in self-assembly demonstrate its potential for the parallel creation of a large number of nanostructures, including possibly computers. A systematic study of self-assembly as a mathematical process has been initiated by L. Adleman and E. Winfree. The individual components are modeled as square tiles on the infinite two-dimensional plane. Each side of a tile is covered by a specific “glue,” and two adjacent tiles will stick iff they have matching glues on their abutting edges. Tiles that stick to each other may form various two-dimensional “structures” such as squares and rectangles, or may cover the entire plane. In this paper we focus on a special type of structure, called a ribbon: a non-self-crossing rectilinear sequence of tiles on the plane, in which successive tiles are adjacent along an edge and abutting edges of consecutive tiles have matching glues. We prove that it is undecidable whether an arbitrary finite set of tiles with glues (infinite supply of each tile type available) can be used to assemble an infinite ribbon. While the problem can be proved undecidable using existing techniques if the ribbon is required to start with a given “seed” tile, our result settles the “unseeded” case, an open problem formerly known as the “unlimited infinite snake problem.” The proof is based on a construction, due to R. Robinson, of a special set of tiles that allow only aperiodic tilings of the plane. This construction is used to create a special set of directed tiles (tiles with arrows painted on the top) with the “strong plane-filling property”—a variation of the “plane-filling property” previously defined by J. Kari. A construction of “sandwich” tiles is then used in conjunction with this special tile set, to reduce the well-known undecidable tiling problem to the problem of the existence of an infinite directed zipper (a special kind of ribbon). A “motif” construction is then introduced that allows one tile system to simulate another by using geometry to represent glues. Using motifs, the infinite directed zipper problem is reduced to the infinite ribbon problem, proving the latter undecidable. An immediate consequence of our result is the undecidability of the existence of arbitrarily large structures self-assembled using tiles from a given tile set.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2356–2381},
numpages = {26},
keywords = {DNA computing, molecular computing, self-assembly, tiling, undecidability}
}

@article{10.1137/080680990,
author = {Chan, Mee Yee and Chan, Wun-Tat and Chin, Francis Y. L. and Fung, Stanley P. Y. and Kao, Ming-Yang},
title = {Linear-Time Haplotype Inference on Pedigrees without Recombinations and Mating Loops},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/080680990},
doi = {10.1137/080680990},
abstract = {In this paper, an optimal linear-time algorithm is presented to solve the haplotype inference problem for pedigree data when there are no recombinations and the pedigree has no mating loops. The approach is based on the use of graphs to capture SNP, Mendelian, and parity constraints of the given pedigree. This representation allows us to capture the constraints as the edges in a graph, rather than as a system of linear equations as in previous approaches. Graph traversals are then used to resolve the parity of these edges, resulting in an optimal running time.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2179–2197},
numpages = {19},
keywords = {computational biology, recombination, pedigree, haplotype inference}
}

@article{10.1137/070709037,
author = {Aldous, David J. and Bordenave, Charles and Lelarge, Marc},
title = {Dynamic Programming Optimization over Random Data: The Scaling Exponent for Near-Optimal Solutions},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070709037},
doi = {10.1137/070709037},
abstract = {A very simple example of an algorithmic problem solvable by dynamic programming is to maximize, over $Asubseteq{1,2,ldots,n}$, the objective function $|A|-sum_ixi_i{rm1hspace{-0.90ex}1}(iin A,i+1in A)$ for given $xi_i&gt;0$. This problem, with random $(xi_i)$, provides a test example for studying the relationship between optimal and near-optimal solutions of combinatorial optimization problems. We show that, amongst solutions differing from the optimal solution in a small proportion $delta$ of places, we can find near-optimal solutions whose objective function value differs from the optimum by a factor of order $delta^2$ but not of smaller order. We conjecture this relationship holds widely in the context of dynamic programming over random data, and Monte Carlo simulations for the Kauffman-Levin NK model are consistent with the conjecture. This work is a technical contribution to a broad program initiated in [D. J. Aldous and A. G. Percus, Proc. Natl. Acad. Sci. USA, 100 (2003), pp. 11211-11215] of relating such scaling exponents to the algorithmic difficulty of optimization problems.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2382–2410},
numpages = {29},
keywords = {scaling exponent, probabilistic analysis of algorithms, dynamic programming, near-optimal solutions, optimization, Markov chain, local weak convergence}
}

@article{10.1137/07070440X,
author = {Gopalan, Parikshit and Kolaitis, Phokion G. and Maneva, Elitza and Papadimitriou, Christos H.},
title = {The Connectivity of Boolean Satisfiability: Computational and Structural Dichotomies},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/07070440X},
doi = {10.1137/07070440X},
abstract = {Boolean satisfiability problems are an important benchmark for questions about complexity, algorithms, heuristics, and threshold phenomena. Recent work on heuristics and the satisfiability threshold has centered around the structure and connectivity of the solution space. Motivated by this work, we study structural and connectivity-related properties of the space of solutions of Boolean satisfiability problems and establish various dichotomies in Schaefer's framework. On the structural side, we obtain dichotomies for the kinds of subgraphs of the hypercube that can be induced by the solutions of Boolean formulas, as well as for the diameter of the connected components of the solution space. On the computational side, we establish dichotomy theorems for the complexity of the connectivity and $st$-connectivity questions for the graph of solutions of Boolean formulas. Our results assert that the intractable side of the computational dichotomies is PSPACE-complete, while the tractable side—which includes but is not limited to all problems with polynomial-time algorithms for satisfiability—is in P for the $st$-connectivity question, and in coNP for the connectivity question. The diameter of components can be exponential for the PSPACE-complete cases, whereas in all other cases it is linear; thus, diameter and complexity of the connectivity problems are remarkably aligned. The crux of our results is an expressibility theorem showing that in the tractable cases, the subgraphs induced by the solution space possess certain good structural properties, whereas in the intractable cases, the subgraphs can be arbitrary.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2330–2355},
numpages = {26},
keywords = {Boolean satisfiability, PSPACE, PSPACE-completeness, graph connectivity, computational complexity, dichotomy theorems}
}

@article{10.1137/070701376,
author = {Albers, Susanne},
title = {On the Value of Coordination in Network Design},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070701376},
doi = {10.1137/070701376},
abstract = {We study network design games where $n$ self-interested agents have to form a network by purchasing links from a given set of edges. We consider Shapley cost sharing mechanisms that split the cost of an edge in a fair manner among the agents using the edge. It is well known that the price of anarchy of these games is as high as $n$. Another line of research has focused on evaluating the price of stability, i.e., the cost of the best Nash equilibrium relative to the social optimum. In this paper we investigate to which extent coordination among agents can improve the quality of solutions. We resort to the concept of strong Nash equilibria, which were introduced by Aumann and are resilient to deviations by coalitions of agents. We analyze the price of anarchy of strong Nash equilibria and develop lower and upper bounds for unweighted and weighted games in both directed and undirected graphs. These bounds are tight or nearly tight for many scenarios. It shows that, by using coordination, the price of anarchy drops from linear to logarithmic bounds. We complement these results by also proving the first superconstant lower bound on the price of stability of standard equilibria (without coordination) in undirected graphs. More specifically, we show a lower bound of $Omega(log W/loglog W)$ for weighted games, where $W$ is the total weight of all the agents. This almost matches the known upper bound of $O(log W)$. Our results imply that, for most settings, the worst-case performance ratios of strong coordinated equilibria are essentially always as good as the performance ratios of the best equilibria achievable without coordination. These settings include unweighted games in directed graphs as well as weighted games in both directed and undirected graphs.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2273–2302},
numpages = {30},
keywords = {Shapley cost sharing, coalition, price of anarchy, strong Nash equilibrium, price of stability}
}

@article{10.1137/070691954,
author = {Bazzi, Louay M. J.},
title = {Polylogarithmic Independence Can Fool DNF Formulas},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070691954},
doi = {10.1137/070691954},
abstract = {We show that any $k$-wise independent probability distribution on ${0,1}^n$ $O(m^{2.2}$ $2^{-sqrt{k}/10})$-fools any boolean function computable by an $m$-clause disjunctive normal form (DNF) (or conjunctive normal form (CNF)) formula on $n$ variables. Thus, for each constant $e&gt;0$, there is a constant $c&gt;0$ such that any boolean function computable by an $m$-clause DNF (or CNF) formula is $m^{-e}$-fooled by any $clog^2m$-wise probability distribution. This resolves up to an $O(log m)$ factor the depth-2 circuit case of a conjecture due to Linial and Nisan [Combinatorica, 10 (1990), pp. 349-365]. The result is equivalent to a new characterization of DNF (or CNF) formulas by low degree polynomials. It implies a similar statement for probability distributions with the small bias property. Using known explicit constructions of small probability spaces having the limited independence property or the small bias property, we directly obtain a large class of explicit pseudorandom generators of $O(log^2mlog n)$-seed length for $m$-clause DNF (or CNF) formulas on $n$ variables, improving previously known seed lengths.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2220–2272},
numpages = {53},
keywords = {DNF formulas, pseudorandomness, harmonic analysis, limited independence, posets, polynomial approximation}
}

@article{10.1137/070687591,
author = {Xiao, Jing and Liu, Lan and Xia, Lirong and Jiang, Tao},
title = {Efficient Algorithms for Reconstructing Zero-Recombinant Haplotypes on a Pedigree Based on Fast Elimination of Redundant Linear Equations},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070687591},
doi = {10.1137/070687591},
abstract = {Computational inference of haplotypes from genotypes has attracted a great deal of attention in the computational biology community recently, partially driven by the international HapMap project. In this paper, we study the question of how to efficiently infer haplotypes from genotypes of individuals related by a pedigree, assuming that the hereditary process was free of mutations (i.e., the Mendelian law of inheritance) and recombinants. The problem has recently been formulated as a system of linear equations over the finite field of $F(2)$ and solved in $O(m^3n^3)$ time by using standard Gaussian elimination, where $m$ is the number of loci (or markers) in a genotype and $n$ the number of individuals in the pedigree. We give a much faster algorithm with running time $O(mn^2+n^3log^2nloglog n)$. The key ingredients of our construction are (i) a new system of linear equations based on some spanning tree of the pedigree graph and (ii) an efficient method for eliminating redundant equations in a system of $O(mn)$ linear equations over $O(n)$ variables. Although such a fast elimination method is not known for general systems of linear equations, we take advantage of the underlying pedigree graph structure and recent progress on low-stretch spanning trees.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2198–2219},
numpages = {22},
keywords = {low-stretch spanning tree, system of linear equations, pedigree analysis, haplotype inference}
}

@article{10.1137/060678609,
author = {Devroye, Luc and King, James and McDiarmid, Colin},
title = {Random Hyperplane Search Trees},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060678609},
doi = {10.1137/060678609},
abstract = {A hyperplane search tree is a binary tree used to store a set $S$ of $n$ $d$-dimensional data points. In a random hyperplane search tree for $S$, the root represents a hyperplane defined by $d$ data points drawn uniformly at random from $S$. The remaining data points are split by the hyperplane, and the definition is used recursively on each subset. We assume that the data are points in general position in $mathbb{R}^d$. We show that, uniformly over all such data sets $S$, the expected height of the hyperplane tree is not worse than that of the $k$-d tree or the ordinary one-dimensional random binary search tree, and that, for any fixed $dge3$, the expected height improves over that of the standard random binary search tree by an asymptotic factor strictly greater than one.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2411–2425},
numpages = {15},
keywords = {random tree, random sampling, large deviation theory, hyperplane tree, data structures, binary search tree, height of a tree, expected time analysis}
}

@article{10.1137/060670511,
author = {Chan, T.-H. Hubert and Dhamdhere, Kedar and Gupta, Anupam and Kleinberg, Jon and Slivkins, Aleksandrs},
title = {Metric Embeddings with Relaxed Guarantees},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060670511},
doi = {10.1137/060670511},
abstract = {We consider the problem of embedding finite metrics with slack: We seek to produce embeddings with small dimension and distortion while allowing a (small) constant fraction of all distances to be arbitrarily distorted. This definition is motivated by recent research in the networking community, which achieved striking empirical success at embedding Internet latencies with low distortion into low-dimensional Euclidean space, provided that some small slack is allowed. Answering an open question of Kleinberg, Slivkins, and Wexler [in Proceedings of the 45th IEEE Symposium on Foundations of Computer Science, 2004], we show that provable guarantees of this type can in fact be achieved in general: Any finite metric space can be embedded, with constant slack and constant distortion, into constant-dimensional Euclidean space. We then show that there exist stronger embeddings into $ell_1$ which exhibit gracefully degrading distortion: There is a single embedding into $ell_1$ that achieves distortion at most $O(logfrac{1}{epsilon})$ on all but at most-1.5pt an $epsilon$ fraction of distances simultaneously for all $epsilon&gt;0$. We extend this with distortion1pt $O(logfrac{1}{epsilon})^{1/p}$ to maps into general $ell_p$, $pgeq1$, for several classes of metrics, including those with bounded doubling dimension and those arising from the shortest-path metric of a graph with an excluded minor. Finally, we show that many of our constructions are tight and give a general technique to obtain lower bounds for $epsilon$-slack embeddings from lower bounds for low-distortion embeddings.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2303–2329},
numpages = {27},
keywords = {metric embeddings, metric spaces, metric decompositions, low-distortion embeddings, randomized algorithms}
}

@article{10.1137/050643635,
author = {Guha, Sudipto and Meyerson, Adam and Munagala, Kamesh},
title = {A Constant Factor Approximation for the Single Sink Edge Installation Problem},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/050643635},
doi = {10.1137/050643635},
abstract = {We present the first constant approximation to the single sink buy-at-bulk network design problem, where we have to design a network by buying pipes of different costs and capacities per unit length to route demands at a set of sources to a single sink. The distances in the underlying network form a metric. This result improves the previous bound of $O(log|R|)$, where $R$ is the set of sources. We also present a better constant approximation to the related Access Network Design problem. Our algorithms are randomized and combinatorial. As a subroutine in our algorithm, we use an interesting variant of facility location with lower bounds on the amount of demand an open facility needs to serve. We call this variant load balanced facility location and present a constant factor approximation for it, while relaxing the lower bounds by a constant factor.},
journal = {SIAM J. Comput.},
month = mar,
pages = {2426–2442},
numpages = {17},
keywords = {facility location, Steiner trees, network design, approximation algorithms}
}

@article{10.1137/08071421X,
author = {Sherstov, Alexander A.},
title = {Separating ${AC}^0$ from Depth-2 Majority Circuits},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/08071421X},
doi = {10.1137/08071421X},
abstract = {We construct a function in ${AC}^0$ that cannot be computed by a depth-2 majority circuit of size less than $exp(Theta(n^{1/5}))$. This solves an open problem due to Krause and Pudl\'{a}k [Theoret. Comput. Sci., 174 (1997), pp. 137-156] and matches Allender's classic result [A note on the power of threshold circuits, in Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science (FOCS), Research Triangle Park, NC, 1989, pp. 580-584] that ${AC}^0$ can be efficiently simulated by depth-3 majority circuits. To obtain our result, we develop a novel technique for proving lower bounds on communication complexity. This technique, the Degree/Discrepancy Theorem, is of independent interest. It translates lower bounds on the threshold degree of any Boolean function into upper bounds on the discrepancy of a related function. Upper bounds on the discrepancy, in turn, immediately imply lower bounds on communication and circuit size. In particular, we exhibit the first known function in ${AC}^0$ with exponentially small discrepancy, $exp(-Omega(n^{1/5}))$, thereby establishing the separations $Sigma_2^{cc}notsubseteq{PP}^{cc}$ and $Pi_2^{cc}notsubseteq{PP}^{cc}$ in communication complexity.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2113–2129},
numpages = {17},
keywords = {constant-depth and/or/not circuits, majority circuits, communication complexity, threshold degree of Boolean functions, discrepancy, Degree/Discrepancy Theorem}
}

@article{10.1137/070696507,
author = {Dasgupta, Anirban and Drineas, Petros and Harb, Boulos and Kumar, Ravi and Mahoney, Michael W.},
title = {Sampling Algorithms and Coresets for $\ell_p$ Regression},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070696507},
doi = {10.1137/070696507},
abstract = {The $ell_p$ regression problem takes as input a matrix $Ainmathbb{R}^{ntimes d}$, a vector $binmathbb{R}^n$, and a number $pin[1,infty)$, and it returns as output a number ${cal Z}$ and a vector $x_{text{{sc opt}}}inmathbb{R}^d$ such that ${cal Z}=min_{xinmathbb{R}^d}|Ax-b|_p=|Ax_{text{{sc opt}}}-b|_p$. In this paper, we construct coresets and obtain an efficient two-stage sampling-based approximation algorithm for the very overconstrained ($ngg d$) version of this classical problem, for all $pin[1, infty)$. The first stage of our algorithm nonuniformly samples $hat{r}_1=O(36^p d^{max{p/2+1,p}+1})$ rows of $A$ and the corresponding elements of $b$, and then it solves the $ell_p$ regression problem on the sample; we prove this is an 8-approximation. The second stage of our algorithm uses the output of the first stage to resample $hat{r}_1/epsilon^2$ constraints, and then it solves the $ell_p$ regression problem on the new sample; we prove this is a $(1+epsilon)$-approximation. Our algorithm unifies, improves upon, and extends the existing algorithms for special cases of $ell_p$ regression, namely, $p = 1,2$ [K. L. Clarkson, in Proceedings of the 16th Annual ACM-SIAM Symposium on Discrete Algorithms, ACM, New York, SIAM, Philadelphia, 2005, pp. 257-266; P. Drineas, M. W. Mahoney, and S. Muthukrishnan, in Proceedings of the 17th Annual ACM-SIAM Symposium on Discrete Algorithms, ACM, New York, SIAM, Philadelphia, 2006, pp. 1127-1136]. In the course of proving our result, we develop two concepts—well-conditioned bases and subspace-preserving sampling—that are of independent interest.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2060–2078},
numpages = {19},
keywords = {$ell_p$ regression, randomized algorithms, sampling algorithms}
}

@article{10.1137/070694879,
author = {Shpilka, Amir},
title = {Interpolation of Depth-3 Arithmetic Circuits with Two Multiplication Gates},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070694879},
doi = {10.1137/070694879},
abstract = {In this paper we consider the problem of constructing a small arithmetic circuit for a polynomial for which we have oracle access. Our focus is on $n$-variate polynomials, over a finite field $mathbb{F}$, that have depth-3 arithmetic circuits (with an addition gate at the top) with two multiplication gates of degree at most $d$. We obtain the following results: 1. Multilinear case. When the circuit is multilinear (multiplication gates compute multilinear polynomials) we give an algorithm that outputs, with probability $1-o(1)$, all the depth-3 circuits with two multiplication gates computing the polynomial. The running time of the algorithm is $operatorname{poly}(n,|mathbb{F}|)$. 2. General case. When the circuit is not multilinear we give a quasi-polynomial (in $n,d,|mathbb{F}|$) time algorithm that outputs, with probability $1-o(1)$, a succinct representation of the polynomial. In particular, if the depth-3 circuit for the polynomial is not of small depth-3 rank (namely, after removing the g.c.d. (greatest common divisor) of the two multiplication gates, the remaining linear functions span a not too small linear space), then we output the depth-3 circuit itself. In the case that the rank is small we output a depth-3 circuit with a quasi-polynomial number of multiplication gates. $diamond$ Prior to our work there have been several interpolation algorithms for restricted models. However, all the techniques used there completely fail when dealing with depth-3 circuits with even just two multiplication gates. Our proof technique is new and relies on the factorization algorithm for multivariate black-box polynomials, on lower bounds on the length of linear locally decodable codes with two queries, and on a theorem regarding the structure of identically zero depth-3 circuits with four multiplication gates.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2130–2161},
numpages = {32},
keywords = {interpolation, exact learning, arithmetic circuits, reconstruction, depth-3}
}

@article{10.1137/070685373,
author = {Hon, Wing-Kai and Sadakane, Kunihiko and Sung, Wing-Kin},
title = {Breaking a Time-and-Space Barrier in Constructing Full-Text Indices},
year = {2009},
issue_date = {February 2009},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/070685373},
doi = {10.1137/070685373},
abstract = {Suffix trees and suffix arrays are the most prominent full-text indices, and their construction algorithms are well studied. In the literature, the fastest algorithm runs in $O(n)$ time, while it requires $O(n\log n)$-bit working space, where $n$ denotes the length of the text. On the other hand, the most space-efficient algorithm requires $O(n)$-bit working space while it runs in $O(n\log n)$ time. It was open whether these indices can be constructed in both $o(n\log n)$ time and $o(n\log n)$-bit working space. This paper breaks the above time-and-space barrier under the unit-cost word RAM. We give an algorithm for constructing the suffix array, which takes $O(n)$ time and $O(n)$-bit working space, for texts with constant-size alphabets. Note that both the time and the space bounds are optimal. For constructing the suffix tree, our algorithm requires $O(n\log^{\epsilon}n)$ time and $O(n)$-bit working space for any $0<\epsilon<1$. Apart from that, our algorithm can also be adopted to build other existing full-text indices, such as compressed suffix tree, compressed suffix arrays, and FM-index. We also study the general case where the size of the alphabet $\Sigma$ is not constant. Our algorithm can construct a suffix array and a suffix tree using optimal $O(n\log|\Sigma|)$-bit working space while running in $O(n\log\log|\Sigma|)$ time and $O(n(\log^{\epsilon}n+\log|\Sigma|))$ time, respectively. These are the first algorithms that achieve $o(n\log n)$ time with optimal working space. Moreover, for the special case where $\log|\Sigma|=O((\log\log n)^{1-\epsilon})$, we can speed up our suffix array construction algorithm to the optimal $O(n)$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2162–2178},
numpages = {16},
keywords = {suffix trees, suffix arrays, text indexing, preprocessing}
}

@article{10.1137/07068196X,
author = {Spakowski, Holger and Tripathi, Rahul},
title = {Hierarchical Unambiguity},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/07068196X},
doi = {10.1137/07068196X},
abstract = {We develop techniques to investigate relativized hierarchical unambiguous computation. We apply our techniques to generalize known constructs involving relativized unambiguity based complexity classes (UP and Promise-UP) to new constructs involving arbitrary higher levels of the relativized unambiguous polynomial hierarchy (UPH). Our techniques are developed on constraints imposed by hierarchical arrangement of unambiguous nondeterministic polynomial-time Turing machines, and so they differ substantially, in applicability and in nature, from standard methods (such as the switching lemma [J. H\r{a}stad, Computational Limitations of Small-Depth Circuits, MIT Press, Cambridge, 1987]), which play roles in carrying out similar generalizations. Aside from achieving these generalizations, we resolve a question posed by Cai, Hemachandra, and Vysko\v{c} in [Complexity Theory, Cambridge University Press, Cambridge, UK, 1993, pp. 101-146], on an issue related to nonadaptive Turing access to UP and adaptive smart Turing access to Promise-UP.},
journal = {SIAM J. Comput.},
month = feb,
pages = {2079–2112},
numpages = {34},
keywords = {unambiguous computation, relativization, promise problems, computational complexity}
}

@article{10.1137/S009753970443999X,
author = {Schmid, Ulrich and Weiss, Bettina and Keidar, Idit},
title = {Impossibility Results and Lower Bounds for Consensus under Link Failures},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970443999X},
doi = {10.1137/S009753970443999X},
abstract = {We provide a suite of impossibility results and lower bounds for the required number of processes and rounds for synchronous consensus under transient link failures. Our results show that consensus can be solved even in the presence of $O(n^2)$ moving omission and/or arbitrary link failures per round, provided that both the number of affected outgoing and incoming links of every process is bounded. Providing a step further toward the weakest conditions under which consensus is solvable, our findings are applicable to a variety of dynamic phenomena such as transient communication failures and end-to-end delay variations. We also prove that our model surpasses alternative link failure modeling approaches in terms of assumption coverage.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1912–1951},
numpages = {40},
keywords = {fault-tolerant distributed algorithms, transient link failures, impossibility results, assumption coverage analysis, consensus, lower bounds}
}

@article{10.1137/070710913,
author = {Villanger, Yngve and Heggernes, Pinar and Paul, Christophe and Telle, Jan Arne},
title = {Interval Completion Is Fixed Parameter Tractable},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070710913},
doi = {10.1137/070710913},
abstract = {We present an algorithm with runtime $O(k^{2k}n^3m)$ for the following NP-complete problem [M. Garey and D. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness, W. H. Freeman and Co., San Francisco, 1979, problem GT35]: Given an arbitrary graph $G$ on $n$ vertices and $m$ edges, can we obtain an interval graph by adding at most $k$ new edges to $G$? This resolves the long-standing open question [H. Kaplan, R. Shamir, and R. E. Tarjan, SIAM J. Comput., 28 (1999), pp. 1906-1922; R. G. Downey and M. R. Fellows, Parameterized Complexity, Springer-Verlag, New York, 1999; M. Serna and D. Thilikos, Bull. Eur. Assoc. Theory Comput. Sci. EATCS, 86 (2005), pp. 41-65; G. Gutin, S. Szeider, and A. Yeo, in Proceedings IWPEC 2006, Lecture Notes in Comput. Sci. 4169, Springer-Verlag, Berlin, 2006, pp. 60-71], first posed by Kaplan, Shamir, and Tarjan, of whether this problem was fixed parameter tractable. The problem has applications in profile minimization for sparse matrix computations [J. A. George and J. W. H. Liu, Computer Solution of Large Sparse Positive Definite Systems, Prentice-Hall, Englewood Cliffs, NJ, 1981; R. E. Tarjan, in Sparse Matrix Computations, J. R. Bunch and D. J. Rose, eds., Academic Press, 1976, pp. 3-22], and our results show tractability for the case of a small number $k$ of zero elements in the envelope. Our algorithm performs bounded search among possible ways of adding edges to a graph to obtain an interval graph and combines this with a greedy algorithm when graphs of a certain structure are reached by the search.},
journal = {SIAM J. Comput.},
month = jan,
pages = {2007–2020},
numpages = {14},
keywords = {FPT algorithm, interval graphs, branching, edge completion, profile minimization}
}

@article{10.1137/070708093,
author = {Barto, Libor and Kozik, Marcin and Niven, Todd},
title = {The CSP Dichotomy Holds for Digraphs with No Sources and No Sinks (A Positive Answer to a Conjecture of Bang-Jensen and Hell)},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070708093},
doi = {10.1137/070708093},
abstract = {Bang-Jensen and Hell conjectured in 1990 (using the language of graph homomorphisms) a constraint satisfaction problem (CSP) dichotomy for digraphs with no sources or sinks. The conjecture states that the CSP for such a digraph is tractable if each component of its core is a cycle and is $NP$-complete otherwise. In this paper we prove this conjecture and, as a consequence, a conjecture of Bang-Jensen, Hell, and MacGillivray from 1995 classifying hereditarily hard digraphs. Further, we show that the CSP dichotomy for digraphs with no sources or sinks agrees with the algebraic characterization conjectured by Bulatov, Jeavons, and Krokhin in 2005.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1782–1802},
numpages = {21},
keywords = {smooth digraphs, constraint satisfaction problem, graph homomorphism}
}

@article{10.1137/070707130,
author = {Bose, Prosenjit and Carmi, Paz and Couture, Mathieu and Maheshwari, Anil and Morin, Pat and Smid, Michiel},
title = {Spanners of Complete $k$-Partite Geometric Graphs},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070707130},
doi = {10.1137/070707130},
abstract = {We address the following problem: Given a complete $k$-partite geometric graph $K$ whose vertex set is a set of $n$ points in $mathbb{R}^d$, compute a spanner of $K$ that has a “small” stretch factor and “few” edges. We present two algorithms for this problem. The first algorithm computes a $(5+epsilon)$-spanner of $K$ with $O(n)$ edges in $O(nlog n)$ time. The second algorithm computes a $(3+epsilon)$-spanner of $K$ with $O(nlog n)$ edges in $O(n log n)$ time. The latter result is optimal: We show that for any $2leq kleq n-Theta(sqrt{nlog n})$, spanners with $O(nlog n)$ edges and stretch factor less than 3 do not exist for all complete $k$-partite geometric graphs.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1803–1820},
numpages = {18},
keywords = {$k$-partite geometric graphs, computational geometry, spanners}
}

@article{10.1137/070697926,
author = {Allender, Eric and B\"{u}rgisser, Peter and Kjeldgaard-Pedersen, Johan and Miltersen, Peter Bro},
title = {On the Complexity of Numerical Analysis},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070697926},
doi = {10.1137/070697926},
abstract = {We study two quite different approaches to understanding the complexity of fundamental problems in numerical analysis: (a) the Blum-Shub-Smale model of computation over the reals; and (b) a problem we call the “generic task of numerical computation,” which captures an aspect of doing numerical computation in floating point, similar to the “long exponent model” that has been studied in the numerical computing community. We show that both of these approaches hinge on the question of understanding the complexity of the following problem, which we call PosSLP: Given a division-free straight-line program producing an integer $N$, decide whether $N&gt;0$. In the Blum-Shub-Smale model, polynomial-time computation over the reals (on discrete inputs) is polynomial-time equivalent to PosSLP when there are only algebraic constants. We conjecture that using transcendental constants provides no additional power, beyond nonuniform reductions to PosSLP, and we present some preliminary results supporting this conjecture. The generic task of numerical computation is also polynomial-time equivalent to PosSLP. We prove that PosSLP lies in the counting hierarchy. Combining this with work of Tiwari, we obtain that the Euclidean traveling salesman problem lies in the counting hierarchy—the previous best upper bound for this important problem (in terms of classical complexity classes) being PSPACE. In the course of developing the context for our results on arithmetic circuits, we present some new observations on the complexity of the arithmetic circuit identity testing (ACIT) problem. In particular, we show that if $n!$ is not ultimately easy, then ACIT has subexponential complexity.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1987–2006},
numpages = {20},
keywords = {BPP, straight-line programs, Blum-Shub-Smale model, sum of square roots problem, arithmetic circuits, counting hierarchy}
}

@article{10.1137/070697367,
author = {Gelade, Wouter and Martens, Wim and Neven, Frank},
title = {Optimizing Schema Languages for XML: Numerical Constraints and Interleaving},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070697367},
doi = {10.1137/070697367},
abstract = {The presence of a schema offers many advantages in processing, translating, querying, and storage of XML data. Basic decision problems such as equivalence, inclusion, and nonemptiness of intersection of schemas form the basic building blocks for schema optimization and integration, and algorithms for static analysis of transformations. It is thereby paramount to establish the exact complexity of these problems. Most common schema languages for XML can be adequately modeled by some kind of grammar with regular expressions at right-hand sides. In this paper, we observe that, apart from the usual regular operators of union, concatenation, and Kleene-star, schema languages also allow numerical occurrence constraints and interleaving operators. Although the expressiveness of these operators remains within the regular languages, the presence or absence of these operators has a significant impact on the complexity of the basic decision problems. We present a complete overview of the complexity of the basic decision problems for DTDs, XSDs, and Relax NG with regular expressions incorporating numerical occurrence constraints and interleaving. We also discuss chain regular expressions and the complexity of the schema simplification problem incorporating the new operators.},
journal = {SIAM J. Comput.},
month = jan,
pages = {2021–2043},
numpages = {23},
keywords = {XML schema languages, complexity, optimization, regular expressions}
}

@article{10.1137/070696519,
author = {Kedlaya, Kiran S. and Yekhanin, Sergey},
title = {Locally Decodable Codes from Nice Subsets of Finite Fields and Prime Factors of Mersenne Numbers},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070696519},
doi = {10.1137/070696519},
abstract = {A $k$-query locally decodable code (LDC) encodes an $n$-bit message $x$ as an $N$-bit codeword $C(x)$, such that one can probabilistically recover any bit $x_i$ of the message by querying only $k$ bits of the codeword $C(x)$, even after some constant fraction of codeword bits has been corrupted. The major goal of LDC related research is to establish the optimal trade-off between length and query complexity of such codes. Recently vast improvements in upper bounds for the length of LDCs were achieved via constructions that rely on existence of certain special (“nice”) subsets of finite fields. In this work we extend the constructions of LDCs from “nice” subsets. We argue that further progress on upper bounds for LDCs via these methods is tied to progress on an old number theory question regarding the size of the largest prime factors of Mersenne numbers. Specifically, we show that every Mersenne number $m=2^t-1$ that has a prime factor $p&gt;m^gamma$ yields a family of $k(gamma)$-query LDCs of length $exp(n^{1/t})$. Conversely, if for some fixed $k$ and all $epsilon&gt;0$ one can use the “nice” subsets technique to obtain a family of $k$-query LDCs of length $exp(n^epsilon)$, then infinitely many Mersenne numbers have prime factors larger than currently known.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1952–1969},
numpages = {18},
keywords = {locally decodable codes, Mersenne primes}
}

@article{10.1137/070695976,
author = {Straccia, Umberto and Ojeda-Aciego, Manuel and Dam\'{a}sio, Carlos V.},
title = {On Fixed-Points of Multivalued Functions on Complete Lattices and Their Application to Generalized Logic Programs},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070695976},
doi = {10.1137/070695976},
abstract = {Unlike monotone single-valued functions, multivalued mappings may have zero, one, or (possibly infinitely) many minimal fixed-points. The contribution of this work is twofold. First, we overview and investigate the existence and computation of minimal fixed-points of multivalued mappings, whose domain is a complete lattice and whose range is its power set. Second, we show how these results are applied to a general form of logic programs, where the truth space is a complete lattice. We show that a multivalued operator can be defined whose fixed-points are in one-to-one correspondence with the models of the logic program.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1881–1911},
numpages = {31},
keywords = {logic programming, complete lattices, multivalued functions, fixed-points}
}

@article{10.1137/07069328X,
author = {Guha, Sudipto and McGregor, Andrew},
title = {Stream Order and Order Statistics: Quantile Estimation in Random-Order Streams},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/07069328X},
doi = {10.1137/07069328X},
abstract = {When trying to process a data stream in small space, how important is the order in which the data arrive? Are there problems that are unsolvable when the ordering is worst case, but that can be solved (with high probability) when the order is chosen uniformly at random? If we consider the stream as if ordered by an adversary, what happens if we restrict the power of the adversary? We study these questions in the context of quantile estimation, one of the most well studied problems in the data-stream model. Our results include an $O($polylog $n)$-space, $O(loglog n)$-pass algorithm for exact selection in a randomly ordered stream of $n$ elements. This resolves an open question of Munro and Paterson [Theoret. Comput. Sci., 23 (1980), pp. 315-323]. We then demonstrate an exponential separation between the random-order and adversarial-order models: using $O($polylog $n)$ space, exact selection requires $Omega(log n/loglog n)$ passes in the adversarial-order model. This lower bound, in contrast to previous results, applies to fully general randomized algorithms and is established via a new bound on the communication complexity of a natural pointer-chasing style problem. We also prove the first fully general lower bounds in the random-order model: finding an element with rank $n/2pm n^{delta}$ in the single-pass random-order model with probability at least $9/10$ requires $Omega(sqrt{n^{1-3delta}/log n})$ space.},
journal = {SIAM J. Comput.},
month = jan,
pages = {2044–2059},
numpages = {16},
keywords = {communication complexity, stream computation, stochastically generated streams}
}

@article{10.1137/070690201,
author = {Dyer, Martin and Goldberg, Leslie Ann and Jerrum, Mark},
title = {The Complexity of Weighted Boolean CSP},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070690201},
doi = {10.1137/070690201},
abstract = {This paper gives a dichotomy theorem for the complexity of computing the partition function of an instance of a weighted Boolean constraint satisfaction problem. The problem is parameterized by a finite set $mathcal{F}$ of nonnegative functions that may be used to assign weights to the configurations (feasible solutions) of a problem instance. Classical constraint satisfaction problems correspond to the special case of 0,1-valued functions. We show that computing the partition function, i.e., the sum of the weights of all configurations, is $text{{sf FP}}^{text{{sf#P}}}$-complete unless either (1) every function in $mathcal{F}$ is of “product type,” or (2) every function in $mathcal{F}$ is “pure affine.” In the remaining cases, computing the partition function is in P.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1970–1986},
numpages = {17},
keywords = {complexity theory, #P, constraint satisfaction, counting}
}

@article{10.1137/070685531,
author = {Park, Gahyun and Hwang, Hsien-Kuei and Nicod\`{e}me, Pierre and Szpankowski, Wojciech},
title = {Profiles of Tries},
year = {2009},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070685531},
doi = {10.1137/070685531},
abstract = {Tries (from retrieval) are one of the most popular data structures on words. They are pertinent to the (internal) structure of stored words and several splitting procedures used in diverse contexts. The profile of a trie is a parameter that represents the number of nodes (either internal or external) with the same distance from the root. It is a function of the number of strings stored in a trie and the distance from the root. Several, if not all, trie parameters such as height, size, depth, shortest path, and fill-up level can be uniformly analyzed through the (external and internal) profiles. Although profiles represent one of the most fundamental parameters of tries, they have hardly been studied in the past. The analysis of profiles is surprisingly arduous, but once it is carried out it reveals unusually intriguing and interesting behavior. We present a detailed study of the distribution of the profiles in a trie built over random strings generated by a memoryless source. We first derive recurrences satisfied by the expected profiles and solve them asymptotically for all possible ranges of the distance from the root. It appears that profiles of tries exhibit several fascinating phenomena. When moving from the root to the leaves of a trie, the growth of the expected profiles varies. Near the root, the external profiles tend to zero at an exponential rate, and then the rate gradually rises to being logarithmic; the external profiles then abruptly tend to infinity, first logarithmically and then polynomially; they then tend polynomially to zero again. Furthermore, the expected profiles of asymmetric tries are oscillating in a range where profiles grow polynomially, while symmetric tries are nonoscillating, in contrast to most shape parameters of random tries studied previously. Such a periodic behavior for asymmetric tries implies that the depth satisfies a central limit theorem but not a local limit theorem of the usual form. Also the widest levels in symmetric tries contain a linear number of nodes, differing from the order $n/sqrt{log n}$ for asymmetric tries, $n$ being the size of the trees. Finally, it is observed that profiles satisfy central limit theorems when the variance goes unbounded, while near the height they are distributed according to Poisson laws. As a consequence of these results we find typical behaviors of the height, shortest path, fill-up level, and depth. These results are derived here by methods of analytic algorithmics such as generating functions, Mellin transform, Poissonization and de-Poissonization, the saddle-point method, singularity analysis, and uniform asymptotic analysis.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1821–1880},
numpages = {60},
keywords = {singularity analysis, depth, digital trees, tries, fill-up level, height, profile, saddle-point method, Mellin transform, shortest path, analytic Poissonization}
}

@article{10.1137/070709244,
author = {Barak, Boaz and Goldreich, Oded},
title = {Universal Arguments and Their Applications},
year = {2008},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070709244},
doi = {10.1137/070709244},
abstract = {We put forward a new type of computationally sound proof system called universal arguments. Universal arguments are related but different from both CS proofs (as defined by Micali [SIAM J. Comput., 37 (2000), pp. 1253-1298]) and arguments (as defined by Brassard, Chaum, and Cr\'{e}peau [J. Comput. System Sci., 37 (1988), pp. 156-189]. In particular, we adopt the instance-based prover-efficiency paradigm of CS proofs but follow the computational-soundness condition of argument systems (i.e., we consider only cheating strategies that are implementable by polynomial-size circuits). We show that universal arguments can be constructed based on standard intractability assumptions that refer to polynomial-size circuits (rather than based on assumptions that refer to subexponential-size circuits as used in the construction of CS proofs). Furthermore, these protocols have a constant number of rounds and are of the public-coin type. As an application of these universal arguments, we weaken the intractability assumptions used in the non-black-box zero-knowledge arguments of Barak [in Proceedings of the 42nd IEEE Symposiun on Foundations of Computer Science, 2001]. Specifically, we only utilize intractability assumptions that refer to polynomial-size circuits (rather than assumptions that refer to circuits of some “nice” superpolynomial size).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1661–1694},
numpages = {34},
keywords = {collision-resistant hashing, probabilistic proof systems, probabilistic checkable proofs, zero-knowledge proof systems, tree hashing, witness indistinguishable proof systems, error-correcting codes, computationally sound proof systems, proofs of knowledge}
}

@article{10.1137/070707932,
author = {Raz, Ran and Shpilka, Amir and Yehudayoff, Amir},
title = {A Lower Bound for the Size of Syntactically Multilinear Arithmetic Circuits},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070707932},
doi = {10.1137/070707932},
abstract = {We construct an explicit polynomial $f(x_1,dots,x_n)$, with coefficients in ${0,1}$, such that the size of any syntactically multilinear arithmetic circuit computing $f$ is at least $Omega(n^{4/3}/log^2n)$. The lower bound holds over any field.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1624–1647},
numpages = {24},
keywords = {lower bounds, explicit constructions, arithmetic circuits}
}

@article{10.1137/070706550,
author = {Gavinsky, Dmitry and Kempe, Julia and Kerenidis, Iordanis and Raz, Ran and de Wolf, Ronald},
title = {Exponential Separation for One-Way Quantum Communication Complexity, with Applications to Cryptography},
year = {2008},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070706550},
doi = {10.1137/070706550},
abstract = {We give an exponential separation between one-way quantum and classical communication protocols for a partial Boolean function (a variant of the Boolean hidden matching problem of Bar-Yossef et al.). Previously, such an exponential separation was known only for a relational problem. The communication problem corresponds to a strong extractor that fails against a small amount of quantum information about its random source. Our proof uses the Fourier coefficients inequality of Kahn, Kalai, and Linial. We also give a number of applications of this separation. In particular, we show that there are privacy amplification schemes that are secure against classical adversaries but not against quantum adversaries; and we give the first example of a key-expansion scheme in the model of bounded-storage cryptography that is secure against classical memory-bounded adversaries but not against quantum ones.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1695–1708},
numpages = {14},
keywords = {exponential separation, one-way communication, hidden matching problem, quantum communication, streaming model, communication complexity, quantum cryptography, bounded-storage model, extractor}
}

@article{10.1137/070683155,
author = {Feigenbaum, Joan and Kannan, Sampath and McGregor, Andrew and Suri, Siddharth and Zhang, Jian},
title = {Graph Distances in the Data-Stream Model},
year = {2008},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070683155},
doi = {10.1137/070683155},
abstract = {We explore problems related to computing graph distances in the data-stream model. The goal is to design algorithms that can process the edges of a graph in an arbitrary order given only a limited amount of working memory. We are motivated by both the practical challenge of processing massive graphs such as the web graph and the desire for a better theoretical understanding of the data-stream model. In particular, we are interested in the trade-offs between model parameters such as per-data-item processing time, total space, and the number of passes that may be taken over the stream. These trade-offs are more apparent when considering graph problems than they were in previous streaming work that solved problems of a statistical nature. Our results include the following: (1) Spanner construction: There exists a single-pass, $tilde{O}(tn^{1+1/t})$-space, $tilde{O}(t^2n^{1/t})$-time-per-edge algorithm that constructs a $(2t+1)$-spanner. For $t=Omega(log n/{loglog n})$, the algorithm satisfies the semistreaming space restriction of $O(noperatorname{polylog}n)$ and has per-edge processing time $O(operatorname{polylog}n)$. This resolves an open question from [J. Feigenbaum et al., Theoret. Comput. Sci., 348 (2005), pp. 207-216]. (2) Breadth-first-search (BFS) trees: For any even constant $k$, we show that any algorithm that computes the first $k$ layers of a BFS tree from a prescribed node with probability at least $2/3$ requires either greater than $k/2$ passes or $tilde{Omega}(n^{1+1/k})$ space. Since constructing BFS trees is an important subroutine in many traditional graph algorithms, this demonstrates the need for new algorithmic techniques when processing graphs in the data-stream model. (3) Graph-distance lower bounds: Any $t$-approximation of the distance between two nodes requires $Omega(n^{1+1/t})$ space. We also prove lower bounds for determining the length of the shortest cycle and other graph properties. (4) Techniques for decreasing per-edge processing: We discuss two general techniques for speeding up the per-edge computation time of streaming algorithms while increasing the space by only a small factor.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1709–1727},
numpages = {19},
keywords = {stream algorithms, spanners, graph distances}
}

@article{10.1137/060671899,
author = {Beimel, Amos and Carmi, Paz and Nissim, Kobbi and Weinreb, Enav},
title = {Private Approximation of Search Problems},
year = {2008},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060671899},
doi = {10.1137/060671899},
abstract = {Many approximation algorithms have been presented in the last decades for ${cal NP}$-hard search problems. The focus of this paper is on cryptographic applications, where it is desirable to design algorithms which do not leak unnecessary information. Specifically, we are interested in private approximation algorithms—efficient approximation algorithms whose output does not leak information not implied by the optimal solutions to the search problems. Privacy requirements add constraints on the approximation algorithms; in particular, known approximation algorithms usually leak a lot of information. For functions, Feigenbaum et al. [ACM Trans. Algorithms, 2 (2006), pp. 435-472] presented a natural requirement that a private algorithm should not leak information not implied by the original function. Generalizing this requirement to relations is not straightforward as an input may have many different outputs. We present a new definition that captures a minimal privacy requirement from such algorithms; applied to an input instance, it should not leak any information that is not implied by its collection of exact solutions. We argue that our privacy requirement is natural and quite minimal. We show that, even under this minimal definition of privacy, for well-studied problems such as vertex cover and max exact 3SAT, private approximation algorithms are unlikely to exist even for poor approximation ratios. Similarly to Halevi et al. [in Proceedings of the 33rd ACM Symposium on Theory of Computing, ACM, New York, 2001, pp. 550-559], we define a relaxed notion of approximation algorithms that leak (a little) information, and demonstrate the applicability of this notion by showing near optimal approximation algorithms for max exact 3SAT that leak a little information.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1728–1760},
numpages = {33},
keywords = {secure computation, private approximation, vertex cover, solution-list algorithms}
}

@article{10.1137/060666202,
author = {Emek, Yuval and Peleg, David},
title = {Approximating Minimum Max-Stretch Spanning Trees on Unweighted Graphs},
year = {2008},
issue_date = {December 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060666202},
doi = {10.1137/060666202},
abstract = {Given a graph (G) and a spanning tree (T) of (G), we say that (T) is a tree (t)-spanner of (G) if the distance between every pair of vertices in (T) is at most (t) times their distance in (G). The problem of finding a tree (t)-spanner minimizing (t) is referred to as the Minimum Max-Stretch spanning Tree (MMST) problem. This paper concerns the MMST problem on unweighted graphs. The problem is known to be NP-hard, and the paper presents an (O(log n))-approximation algorithm for it. Furthermore, it is established that unless (mathrm{P}=mathrm{NP}), the problem cannot be approximated additively by any (o(n)) term.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1761–1781},
numpages = {21},
keywords = {low stretch, spanning trees, spanners}
}

@article{10.1137/050629665,
author = {Meyerson, Adam and Munagala, Kamesh and Plotkin, Serge},
title = {Cost-Distance: Two Metric Network Design},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/050629665},
doi = {10.1137/050629665},
abstract = {We present the Cost-Distance problem: finding a Steiner tree which optimizes the sum of edge costs along one metric and the sum of source-sink distances along an unrelated second metric. We give the first known $O(log k)$ randomized approximation scheme for Cost-Distance, where $k$ is the number of sources. We reduce several common network design problems to Cost-Distance, obtaining (in some cases) the first known logarithmic approximation for them. These problems include single-sink buy-at-bulk with variable pipe types between different sets of nodes, facility location with buy-at-bulk-type costs on edges (integrated logistics), constructing single-source multicast trees with good cost and delay properties, priority Steiner trees, and multilevel facility location. Our algorithm is also easier to implement and significantly faster than previously known algorithms for buy-at-bulk design problems.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1648–1659},
numpages = {12},
keywords = {approximation algorithms, network design, Steiner trees, facility location}
}

@article{10.1137/070693217,
author = {Buchsbaum, Adam L. and Georgiadis, Loukas and Kaplan, Haim and Rogers, Anne and Tarjan, Robert E. and Westbrook, Jeffery R.},
title = {Linear-Time Algorithms for Dominators and Other Path-Evaluation Problems},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070693217},
doi = {10.1137/070693217},
abstract = {We present linear-time algorithms for the classic problem of finding dominators in a flowgraph, and for several other problems whose solutions require evaluating a function defined on paths in a tree. Although all these problems had linear-time solutions previously, our algorithms are simpler, in some cases substantially. Our improvements come from three new ideas: a refined analysis of path compression that gives a linear bound if the compressions favor certain nodes; replacement of random-access table look-up by a radix sort; and a more careful partitioning of a tree into easily managed parts. In addition to finding dominators, our algorithms find nearest common ancestors off-line, verify and construct minimum spanning trees, do interval analysis of a flowgraph, and build the component tree of a weighted tree. Our algorithms do not require the power of a random-access machine; they run in linear time on a pointer machine. The genesis of our work was the discovery of a subtle error in the analysis of a previous allegedly linear-time algorithm for finding dominators. That algorithm was an attempt to simplify a more complicated algorithm, which itself was intended to correct errors in a yet earlier algorithm. Our work provides a systematic study of the subtleties in the dominators problem, the techniques needed to solve it in linear time, and the range of application of the resulting methods. We have tried to make our techniques as simple and as general as possible and to understand exactly how earlier approaches to the dominators problem were either incorrect or overly complicated.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1533–1573},
numpages = {41},
keywords = {data structures, analysis of algorithms, dominators, random-access machine, path compression, flowgraphs, set union, minimum spanning trees, pointer machine, nearest common ancestors, component tree, interval analysis}
}

@article{10.1137/070686652,
author = {Jurdzi\'{n}ski, Marcin and Paterson, Mike and Zwick, Uri},
title = {A Deterministic Subexponential Algorithm for Solving Parity Games},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070686652},
doi = {10.1137/070686652},
abstract = {The existence of polynomial-time algorithms for the solution of parity games is a major open problem. The fastest known algorithms for the problem are randomized algorithms that run in subexponential time. These algorithms are all ultimately based on the randomized subexponential simplex algorithms of Kalai and of Matou\v{s}ek, Sharir, and Welzl. Randomness seems to play an essential role in these algorithms. We use a completely different, and elementary, approach to obtain a deterministic subexponential algorithm for the solution of parity games. The new algorithm, like the existing randomized subexponential algorithms, uses only polynomial space, and it is almost as fast as the randomized subexponential algorithms mentioned above.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1519–1532},
numpages = {14},
keywords = {discrete-time games, analysis of algorithms and problem complexity, specification and verification, 2-player games, games on graphs}
}

@article{10.1137/070680096,
author = {Anshelevich, Elliot and Dasgupta, Anirban and Kleinberg, Jon and Tardos, \'{E}va and Wexler, Tom and Roughgarden, Tim},
title = {The Price of Stability for Network Design with Fair Cost Allocation},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070680096},
doi = {10.1137/070680096},
abstract = {Network design is a fundamental problem for which it is important to understand the effects of strategic behavior. Given a collection of self-interested agents who want to form a network connecting certain endpoints, the set of stable solutions—the Nash equilibria—may look quite different from the centrally enforced optimum. We study the quality of the best Nash equilibrium, and refer to the ratio of its cost to the optimum network cost as the price of stability. The best Nash equilibrium solution has a natural meaning of stability in this context—it is the optimal solution that can be proposed from which no user will defect. We consider the price of stability for network design with respect to one of the most widely studied protocols for network cost allocation, in which the cost of each edge is divided equally between users whose connections make use of it; this fair-division scheme can be derived from the Shapley value and has a number of basic economic motivations. We show that the price of stability for network design with respect to this fair cost allocation is $O(log k)$, where $k$ is the number of users, and that a good Nash equilibrium can be achieved via best-response dynamics in which users iteratively defect from a starting solution. This establishes that the fair cost allocation protocol is in fact a useful mechanism for inducing strategic behavior to form near-optimal equilibria. We discuss connections to the class of potential games defined by Monderer and Shapley, and extend our results to cases in which users are seeking to balance network design costs with latencies in the constructed network, with stronger results when the network has only delays and no construction costs. We also present bounds on the convergence time of best-response dynamics, and discuss extensions to a weighted game.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1602–1623},
numpages = {22},
keywords = {network design, price of stability, Shapley cost-sharing}
}

@article{10.1137/050645580,
author = {Mostefaoui, Achour and Rajsbaum, Sergio and Raynal, Michel and Travers, Corentin},
title = {The Combined Power of Conditions and Information on Failures to Solve Asynchronous Set Agreement},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/050645580},
doi = {10.1137/050645580},
abstract = {To cope with the impossibility of solving agreement problems in asynchronous systems made up of $n$ processes and prone to $t$ process crashes, system designers tailor their algorithms to run fast in “normal” circumstances. Two orthogonal notions of “normality” have been studied in the past through failure detectors that give processes information about process crashes, and through conditions that restrict the inputs to an agreement problem. This paper investigates how the two approaches can benefit from each other to solve the $k$-set agreement problem, where processes must agree on at most $k$ of their input values (when $k=1$ we have the famous consensus problem). It proposes novel failure detectors for solving $k$-set agreement and a protocol that combines them with conditions, establishing a new bridge among asynchronous, synchronous, and partially synchronous systems with respect to agreement problems. The paper also proves a lower bound when solving the $k$-set agreement problem with a condition.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1574–1601},
numpages = {28},
keywords = {process crash, consensus, failure detection, input vector, asynchronous system, condition, shared memory, set agreement, snapshot, legal condition}
}

@article{10.1137/070691140,
author = {Khot, Subhash and Naor, Assaf},
title = {Linear Equations Modulo 2 and the $L_1$ Diameter of Convex Bodies},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070691140},
doi = {10.1137/070691140},
abstract = {We design a randomized polynomial time algorithm which, given a 3-tensor of real numbers $A={a_{ijk}}_{i,j,k=1}^n$ such that for all $i,j,kin{1,dots,n}$ we have $a_{ijk}=a_{ikj}=a_{kji}=a_{jik}=a_{kij}=a_{jki}$ and $a_{iik}=a_{ijj}=a_{iji}=0$, computes a number $operatorname{Alg}(A)$ which satisfies with probability at least $frac12$, $Omega(sqrt{frac{log n}{n}}t)cdotmax_{xin {-1,1}^n}sum_{i,j,k=1}^n a_{ijk}x_ix_jx_kleoperatorname{Alg}(A)lemax_{xin {-1,1}^n}sum_{i,j,k=1}^n a_{ijk}x_ix_jx_k$. On the other hand, we show via a simple reduction from a result of H\r{a}stad and Venkatesh [Random Structures Algorithms, 25 (2004), pp. 117-149] that under the assumption $NPnotsubseteq DTIME(n^{(log n)^{O(1)}})$, for every $epsilon&gt;0$ there is no algorithm that approximates $max_{xin {-1,1}^n}sum_{i,j,k=1}^n a_{ijk}x_ix_jx_k$ within a factor of $2^{(log n)^{1-epsilon}}$ in time $2^{(log n)^{O(1)}}$. Our algorithm is based on a reduction to the problem of computing the diameter of a convex body in $mathbb{R}^n$ with respect to the $L_1$ norm. We show that it is possible to do so up to a multiplicative error of $O(sqrt{frac{n}{log n}})$, while no randomized polynomial time algorithm can achieve accuracy $o(sqrt{frac{n}{log n}})$. This resolves a question posed by Brieden et al. in [Mathematika, 48 (2001), pp. 63-105]. We apply our new algorithm to improve the algorithm of H\r{a}stad and Venkatesh for the Max-E3-Lin-2 problem. Given an overdetermined system $mathcal{E}$ of $N$ linear equations modulo 2 in $nle N$ Boolean variables such that in each equation only three distinct variables appear, the goal is to approximate in polynomial time the maximum number of satisfiable equations in $mathcal{E}$ minus $frac{N}{2}$ (i.e., we subtract the expected number of satisfied equations in a random assignment). H\r{a}stad and Venkatesh obtained an algorithm which approximates this value up to a factor of $O(sqrt{N})$. We obtain an $O(sqrt{frac{n}{log n}})$ approximation algorithm. By relating this problem to the refutation problem for random $3-CNF$ formulas, we give evidence that obtaining a significant improvement over this approximation factor is likely to be difficult.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1448–1463},
numpages = {16},
keywords = {refutation of random SAT, Grothendieck's inequality, computational convex geometry, Max-E3-Lin-2, semidefinite programming}
}

@article{10.1137/060670730,
author = {Hariharan, Ramesh and Kavitha, Telikepalli and Mehlhorn, Kurt},
title = {Faster Algorithms for Minimum Cycle Basis in Directed Graphs},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060670730},
doi = {10.1137/060670730},
abstract = {We consider the problem of computing a minimum cycle basis in a directed graph. The input to this problem is a directed graph $G$ whose edges have nonnegative weights. A cycle in this graph is actually a cycle in the underlying undirected graph with edges traversable in both directions. A ${-1,0,1}$ edge incidence vector is associated with each cycle: edges traversed by the cycle in the right direction get 1 and edges traversed in the opposite direction get $-1$. The vector space over $mathbb{Q}$ generated by these vectors is the cycle space of $G$. A set of cycles is called a cycle basis of $G$ if it forms a basis for this vector space. We seek a cycle basis where the sum of weights of the cycles is minimum. The current fastest algorithm for computing a minimum cycle basis in a directed graph with $m$ edges and $n$ vertices runs in $tilde{O}(m^{omega+1}n)$ time, where $omega &lt; 2.376$ is the exponent of matrix multiplication. We present an $O(m^3n+m^2n^2log n)$ algorithm. We obtain our algorithm by using fast matrix multiplication over rings and an efficient extension of Dijkstra's algorithm to compute a shortest cycle in $G$ whose dot product with a function on its edge set is nonzero. We also present a simple $O(m^2n+mn^2log n)$ Monte Carlo algorithm. The problem of computing a minimum cycle basis in an undirected graph has been well studied. In this problem a ${0,1}$ edge incidence vector is associated with each cycle and the vector space over $mathbb{Z}_2$ generated by these vectors is the cycle space of the graph. The fastest known algorithm for computing a minimum cycle basis in an undirected graph runs in $O(m^2n + mn^2log n)$ time and our randomized algorithm for directed graphs matches this running time.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1430–1447},
numpages = {18},
keywords = {shortest paths, randomization, fast matrix multiplication, cycle basis}
}

@article{10.1137/060664112,
author = {Wang, Lusheng and Lin, Yu and Liu, Xiaowen},
title = {Approximation Algorithms for Biclustering Problems},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060664112},
doi = {10.1137/060664112},
abstract = {One of the main goals in the analysis of microarray data is to identify groups of genes and groups of experimental conditions (including environments, individuals, and tissues) that exhibit similar expression patterns. This is the so-called biclustering problem. In this paper, we consider two variations of the biclustering problem: the consensus submatrix problem and the bottleneck submatrix problem. The input of the problems contains an $m\times n$ matrix $A$ and integers $l$ and $k$. The consensus submatrix problem is to find an $l\times k$ submatrix with $l<m$ and $k<n$ and a consensus vector such that the sum of distances between the rows in the submatrix and the consensus vector is minimized. The bottleneck submatrix problem is to find an $l\times k$ submatrix with $l<m$ and $k<n$, an integer $d$ and a center vector such that the distance between every row in the submatrix and the vector is at most $d$ and $d$ is minimized. We show that both problems are NP-hard and give randomized approximation algorithms for special cases of the two problems. Using standard techniques, we can derandomize the algorithms to get polynomial time approximation schemes for the two problems. To the best of our knowledge, this is the first time that approximation algorithms with guaranteed ratios are presented for microarray data analysis.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1504–1518},
numpages = {14},
keywords = {microarray data analysis, computational biology, genes, approximation algorithms}
}

@article{10.1137/060656048,
author = {Demaine, Erik D. and Feige, Uriel and Hajiaghayi, MohammadTaghi and Salavatipour, Mohammad R.},
title = {Combination Can Be Hard: Approximability of the Unique Coverage Problem},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060656048},
doi = {10.1137/060656048},
abstract = {We prove semilogarithmic inapproximability for a maximization problem called unique coverage: given a collection of sets, find a subcollection that maximizes the number of elements covered exactly once. Specifically, assuming that $mathrm{NP}notsubseteqoperatorname{BPTIME}(2^{n^varepsilon})$ for an arbitrary $varepsilon&gt;0$, we prove $O(1/log^{sigma}n)$ inapproximability for some constant $sigma=sigma(varepsilon)$. We also prove $O(1/log^{1/3-varepsilon}n)$ inapproximability for any $varepsilon&gt;0$, assuming that refuting random instances of 3SAT is hard on average; and we prove $O(1/log n)$ inapproximability under a plausible hypothesis concerning the hardness of another problem, balanced bipartite independent set. We establish an $Omega(1/log n)$-approximation algorithm, even for a more general (budgeted) setting, and obtain an $Omega(1/log B)$-approximation algorithm when every set has at most $B$ elements. We also show that our inapproximability results extend to envy-free pricing, an important problem in computational economics. We describe how the (budgeted) unique coverage problem, motivated by real-world applications, has close connections to other theoretical problems, including max cut, maximum coverage, and radio broadcasting.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1464–1483},
numpages = {20},
keywords = {wireless networks, hardness of approximation, unique coverage}
}

@article{10.1137/06064980X,
author = {Kijima, S. and Matsui, T.},
title = {Approximation Algorithm and Perfect Sampler for Closed Jackson Networks with Single Servers},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/06064980X},
doi = {10.1137/06064980X},
abstract = {In this paper, we propose the first fully polynomial-time randomized approximation scheme (FPRAS) for closed Jackson networks with single servers. Our algorithm is based on the Markov chain Monte Carlo (MCMC) method, and our scheme returns an approximate solution, for which the size of error satisfies a given error rate. We propose two Markov chains: one is for approximate sampling, and the other is for perfect sampling based on the monotone coupling from the past algorithm.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1484–1503},
numpages = {20},
keywords = {path coupling, Markov chain Monte Carlo, perfect sampling, coupling from the past, Jackson networks, FPRAS, rapidly mixing}
}

@article{10.1137/080715421,
author = {Baev, Ivan and Rajaraman, Rajmohan and Swamy, Chaitanya},
title = {Approximation Algorithms for Data Placement Problems},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/080715421},
doi = {10.1137/080715421},
abstract = {We develop approximation algorithms for the problem of placing replicated data in arbitrary networks, where the nodes may both issue requests for data objects and have capacity for storing data objects so as to minimize the average data-access cost. We introduce the data placement problem to model this problem. We have a set of caches $mathcal{F}$, a set of clients $mathcal{D}$, and a set of data objects $mathcal{O}$. Each cache $i$ can store at most $u_i$ data objects. Each client $jinmathcal{D}$ has demand $d_j$ for a specific data object $o(j)inmathcal{O}$ and has to be assigned to a cache that stores that object. Storing an object $o$ in cache $i$ incurs a storage cost of $f_i^o$, and assigning client $j$ to cache $i$ incurs an access cost of $d_jc_{ij}$. The goal is to find a placement of the data objects to caches respecting the capacity constraints, and an assignment of clients to caches so as to minimize the total storage and client access costs. We present a 10-approximation algorithm for this problem. Our algorithm is based on rounding an optimal solution to a natural linear-programming relaxation of the problem. One of the main technical challenges encountered during rounding is to preserve the cache capacities while incurring only a constant-factor increase in the solution cost. We also introduce the connected data placement problem to capture settings where write-requests are also issued for data objects, so that one requires a mechanism to maintain consistency of data. We model this by requiring that all caches containing a given object be connected by a Steiner tree to a root for that object, which issues a multicast message upon a write to (any copy of) that object. The total cost now includes the cost of these Steiner trees. We devise a 14-approximation algorithm for this problem. We show that our algorithms can be adapted to handle two variants of the problem: (a) a $k$-median variant, where there is a specified bound on the number of caches that may contain a given object, and (b) a generalization where objects have lengths and the total length of the objects stored in any cache must not exceed its capacity.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1411–1429},
numpages = {19},
keywords = {data placement, facility location, linear programming, approximation algorithms}
}

@article{10.1137/070697793,
author = {Kleinberg, Jon and Sandler, Mark and Slivkins, Aleksandrs},
title = {Network Failure Detection and Graph Connectivity},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070697793},
doi = {10.1137/070697793},
abstract = {We consider a model for monitoring the connectivity of a network subject to node or edge failures. In particular, we are concerned with detecting $(epsilon,k)$-failures: events in which an adversary deletes up to $k$ network elements (nodes or edges), after which there are two sets of nodes $A$ and $B$, each at least an $epsilon$ fraction of the network, that are disconnected from one another. We say that a set $D$ of nodes is an $(epsilon,k)$-detection set if, for any $(epsilon,k)$-failure of the network, some two nodes in $D$ are no longer able to communicate; in this way, $D$ “witnesses” any such failure. Recent results show that for any graph $G$, there is an $(epsilon,k)$-detection set of size bounded by a polynomial in $k$ and $epsilon$, independent of the size of $G$. In this paper, we expose some relationships between bounds on detection sets and the edge-connectivity $lambda$ and node-connectivity $kappa$ of the underlying graph. Specifically, we show that detection set bounds can be made considerably stronger when parameterized by these connectivity values. We show that for an adversary that can delete $k lambda$ edges, there is always a detection set of size $O(frac{k}{epsilon}logfrac{1}{epsilon})$ which can be found by random sampling. Moreover, an $(epsilon,lambda)$-detection set of minimum size (which is at most $frac{1}{epsilon}$) can be computed in polynomial time. A crucial point is that these bounds are independent not just of the size of $G$ but also of the value of $lambda$. Extending these bounds to node failures is much more challenging. The most technically difficult result of this paper is that a random sample of $O(frac{1}{epsilon}logfrac{1}{epsilon})$ nodes is a detection set for adversaries that can delete a number of nodes up to $kappa$, the node-connectivity. For the case of edge-failures we use VC-dimension techniques and the cactus representation of all minimum edge-cuts of a graph; for node failures, we develop a novel approach for working with the much more complex set of all minimum node-cuts of a graph.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1330–1346},
numpages = {17},
keywords = {network failures, cactus representation, connectivity, detection sets, minimal cuts, VC-dimension}
}

@article{10.1137/060673898,
author = {Marx, D\'{a}niel},
title = {Closest Substring Problems with Small Distances},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060673898},
doi = {10.1137/060673898},
abstract = {We study two pattern matching problems that are motivated by applications in computational biology. In the Closest Substring problem $k$ strings $s_1,dots, s_k$ are given, and the task is to find a string $s$ of length $L$ such that each string $s_i$ has a consecutive substring of length $L$ whose distance is at most $d$ from $s$. We present two algorithms that aim to be efficient for small fixed values of $d$ and $k$: for some functions $f$ and $g$, the algorithms have running time $f(d)cdot n^{O(log d)}$ and $g(d,k)cdot n^{O(loglog k)}$, respectively. The second algorithm is based on connections with the extremal combinatorics of hypergraphs. The Closest Substring problem is also investigated from the parameterized complexity point of view. Answering an open question from [P. A. Evans, A. D. Smith, and H. T. Wareham, Theoret. Comput. Sci., 306 (2003), pp. 407-430, M. R. Fellows, J. Gramm, and R. Niedermeier, Combinatorica, 26 (2006), pp. 141-167, J. Gramm, J. Guo, and R. Niedermeier, Lecture Notes in Comput. Sci. 2751, Springer, Berlin, 2003, pp. 195-209, J. Gramm, R. Niedermeier, and P. Rossmanith, Algorithmica, 37 (2003), pp. 25-42], we show that the problem is W[1]-hard even if both $d$ and $k$ are parameters. It follows as a consequence of this hardness result that our algorithms are optimal in the sense that the exponent of $n$ in the running time cannot be improved to $o(log d)$ or to $o(log log k)$ (modulo some complexity-theoretic assumptions). Consensus Patterns is the variant of the problem where, instead of the requirement that each $s_i$ has a substring that is of distance at most $d$ from $s$, we have to select the substrings in such a way that the average of these $k$ distances is at most $delta$. By giving an $f(delta)cdot n^9$ time algorithm, we show that the problem is fixed-parameter tractable. This answers an open question from [M. R. Fellows, J. Gramm, and R. Niedermeier, Combinatorica, 26 (2006), pp. 141-167].},
journal = {SIAM J. Comput.},
month = aug,
pages = {1382–1410},
numpages = {29},
keywords = {parameterized complexity, consensus pattern, fixed-parameter tractability, closest substring, computational complexity}
}

@article{10.1137/06066850X,
author = {Alekhnovich, Michael and Razborov, Alexander A.},
title = {Resolution Is Not Automatizable Unless W[P] Is Tractable},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/06066850X},
doi = {10.1137/06066850X},
abstract = {We show that neither resolution nor tree-like resolution is automatizable unless the class W[P] from the hierarchy of parameterized problems is fixed-parameter tractable by randomized algorithms with one-sided error.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1347–1363},
numpages = {17},
keywords = {automatizability, proof complexity, resolution}
}

@article{10.1137/060658709,
author = {Atserias, Albert and Dawar, Anuj and Grohe, Martin},
title = {Preservation under Extensions on Well-Behaved Finite Structures},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060658709},
doi = {10.1137/060658709},
abstract = {A class of relational structures is said to have the extension preservation property if every first-order sentence that is preserved under extensions on the class is equivalent to an existential sentence. The class of all finite structures does not have the extension preservation property. We study the property on classes of finite structures that are better behaved. We show that the property holds for classes of acyclic structures, structures of bounded degree, and more generally structures that are wide in a sense that we will make precise. We also show that the preservation property holds for the class of structures of treewidth at most $k$, for any $k$. In contrast, we show that the property fails for the class of planar graphs.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1364–1381},
numpages = {18},
keywords = {first-order logic, finite model theory, Gaifman locality, bounded treewidth, planar graphs}
}

@article{10.1137/S0097539799359385,
author = {Aharonov, Dorit and Ben-Or, Michael},
title = {Fault-Tolerant Quantum Computation with Constant Error Rate},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799359385},
doi = {10.1137/S0097539799359385},
abstract = {This paper shows that quantum computation can be made fault-tolerant against errors and inaccuracies when $eta$, the probability for an error in a qubit or a gate, is smaller than a constant threshold $eta_c$. This result improves on Shor's result [Proceedings of the 37th Symposium on the Foundations of Computer Science, IEEE, Los Alamitos, CA, 1996, pp. 56-65], which shows how to perform fault-tolerant quantum computation when the error rate $eta$ decays polylogarithmically with the size of the computation, an assumption which is physically unreasonable. The cost of making the quantum circuit fault-tolerant in our construction is polylogarithmic in time and space. Our result holds for a very general local noise model, which includes probabilistic errors, decoherence, amplitude damping, depolarization, and systematic inaccuracies in the gates. Moreover, we allow exponentially decaying correlations between the errors both in space and in time. Fault-tolerant computation can be performed with any universal set of gates. The result also holds for quantum particles with $p&gt;2$ states, namely, $p$-qudits, and is also generalized to one-dimensional quantum computers with only nearest-neighbor interactions. No measurements, or classical operations, are required during the quantum computation. We estimate the threshold of our construction to be $eta_csimeq 10^{-6}$, in the best case. By this we show that local noise is in principle not an obstacle for scalable quantum computation. The main ingredient of our proof is the computation on states encoded by a quantum error correcting code (QECC). To this end we introduce a special class of Calderbank-Shor-Steane (CSS) codes, called polynomial codes (the quantum analogue of Reed-Solomon codes). Their nice algebraic structure allows all of the encoded gates to be transversal. We also provide another version of the proof which uses more general CSS codes, but its encoded gates are slightly less elegant. To achieve fault tolerance, we encode the quantum circuit by another circuit by using one of these QECCs. This step is repeated polyloglog many times, each step slightly improving the effective error rate, to achieve the desired reliability. The resulting circuit exhibits a hierarchical structure, and for the analysis of its robustness we borrow terminology from Khalfin and Tsirelson [Found. Phys., 22 (1992), pp. 879-948] and G\'{a}cs [Advances in Computing Research: A Research Annual: Randomness and Computation, JAI Press, Greenwich, CT, 1989]. The paper is to a large extent self-contained. In particular, we provide simpler proofs for many of the known results we use, such as the fact that it suffices to correct for bit-flips and phase-flips, the correctness of CSS codes, and the fact that two-qubit gates are universal, together with their extensions to higher-dimensional particles. We also provide full proofs of the universality of the sets of gates we use (the proof of universality was missing in Shor's paper). This paper thus provides a self-contained and complete proof of universal fault-tolerant quantum computation in the presence of local noise.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1207–1282},
numpages = {76},
keywords = {quantum fault tolerance, quantum error correction, quantum computation, quantum Reed-Solomon codes, polynomial codes, concatenated codes, noise and decoherence, density matrices, universal set of gates}
}

@article{10.1137/S0097539798346123,
author = {De Santis, Alfredo and Di Crescenzo, Giovanni and Persiano, Giuseppe and Yung, Moti},
title = {On Monotone Formula Composition of Perfect Zero-Knowledge Languages},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798346123},
doi = {10.1137/S0097539798346123},
abstract = {We investigate structural properties of interactive perfect zero-knowledge (PZK) proofs. Specifically, we look into the closure properties of PZK languages under monotone boolean formula composition. This gives rise to new protocol techniques. We show that interactive PZK for random self-reducible (RSR) (and for co-RSR) languages is closed under monotone boolean formula composition. Namely, we present PZK proofs for monotone boolean formulae whose atoms are statements about membership in a PZK language which is RSR (or whose complement is RSR). We also discuss extensions, recent applications, and generalizations of the techniques.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1300–1329},
numpages = {30},
keywords = {random self-reducible languages, zero knowledge, interactive proofs}
}

@article{10.1137/S0097539704445925,
author = {Kannan, Ravindran and Salmasian, Hadi and Vempala, Santosh},
title = {The Spectral Method for General Mixture Models},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445925},
doi = {10.1137/S0097539704445925},
abstract = {We present an algorithm for learning a mixture of distributions based on spectral projection. We prove a general property of spectral projection for arbitrary mixtures and show that the resulting algorithm is efficient when the components of the mixture are logconcave distributions in $Re^n$ whose means are separated. The separation required grows with $k$, the number of components, and $log n$. This is the first result demonstrating the benefit of spectral projection for general Gaussians and widens the scope of this method. It improves substantially on previous results, which focus either on the special case of spherical Gaussians or require a separation that has a considerably larger dependence on $n$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1141–1156},
numpages = {16},
keywords = {logconcave distributions, singular value decomposition, principal component analysis, mixture models}
}

@article{10.1137/080718115,
author = {Mulmuley, Ketan D. and Sohoni, Milind},
title = {Geometric Complexity Theory II: Towards Explicit Obstructions for Embeddings among Class Varieties},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/080718115},
doi = {10.1137/080718115},
abstract = {In [K. D. Mulmuley and M. Sohoni, SIAM J. Comput., 31 (2001), pp. 496-526], henceforth referred to as Part I, we suggested an approach to the $P$ vs. $NP$ and related lower bound problems in complexity theory through geometric invariant theory. In particular, it reduces the arithmetic (characteristic zero) version of the $NP not subseteq P$ conjecture to the problem of showing that a variety associated with the complexity class $NP$ cannot be embedded in a variety associated with the complexity class $P$. We shall call these class varieties associated with the complexity classes $P$ and $NP$. This paper develops this approach further, reducing these lower bound problems—which are all nonexistence problems—to some existence problems: specifically to proving the existence of obstructions to such embeddings among class varieties. It gives two results towards explicit construction of such obstructions. The first result is a generalization of the Borel-Weil theorem to a class of orbit closures, which include class varieties. The second result is a weaker form of a conjectured analogue of the second fundamental theorem of invariant theory for the class variety associated with the complexity class $NC$. These results indicate that the fundamental lower bound problems in complexity theory are, in turn, intimately linked with explicit construction problems in algebraic geometry and representation theory. The results here were announced in [K. D. Mulmuley and M. Sohoni, in Advances in Algebra and Geometry (Hyderabad, $2001$), Hindustan Book Agency, New Delhi, India, 2003, pp. 239-261].},
journal = {SIAM J. Comput.},
month = jul,
pages = {1175–1206},
numpages = {32},
keywords = {algebraic geometry, geometric invariant theory, computational complexity, representation theory}
}

@article{10.1137/070700577,
author = {Jain, Sanjay and Stephan, Frank},
title = {Mitotic Classes in Inductive Inference},
year = {2008},
issue_date = {July 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070700577},
doi = {10.1137/070700577},
abstract = {For the natural notion of splitting classes into two disjoint subclasses via a recursive classifier working on texts, the question of how these splittings can look in the case of learnable classes is addressed. Here the strength of the classes is compared using the strong and weak reducibility from intrinsic complexity. It is shown that, for explanatorily learnable classes, the complete classes are also mitotic with respect to weak and strong reducibility, respectively. But there is a weakly complete class that cannot be split into two classes which are of the same complexity with respect to strong reducibility. It is shown that, for complete classes for behaviorally correct learning, one-half of each splitting is complete for this learning notion as well. Furthermore, it is shown that explanatorily learnable and recursively enumerable classes always have a splitting into two incomparable classes; this gives an inductive inference counterpart of the Sacks splitting theorem from recursion theory.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1283–1299},
numpages = {17},
keywords = {inductive inference, reducibilities, mitotic classes, recursion theory}
}

@article{10.1137/070684689,
author = {Lutz, Jack H. and Mayordomo, Elvira},
title = {Dimensions of Points in Self-Similar Fractals},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070684689},
doi = {10.1137/070684689},
abstract = {Self-similar fractals arise as the unique attractors of iterated function systems (IFSs) consisting of finitely many contracting similarities satisfying an open set condition. Each point $x$ in such a fractal $F$ arising from an IFS $S$ is naturally regarded as the “outcome” of an infinite coding sequence $T$ (which need not be unique) over the alphabet $Sigma_k = {0, ldots, k-1}$, where $k$ is the number of contracting similarities in $S$. A classical theorem of Moran (1946) and Falconer (1989) states that the Hausdorff and packing dimensions of a self-similar fractal coincide with its similarity dimension, which depends only on the contraction ratios of the similarities. The theory of computing has recently been used to provide a meaningful notion of the dimensions of individual points in Euclidean space. In this paper, we use (and extend) this theory to analyze the dimensions of individual points in fractals that are computably self-similar, meaning that they are unique attractors of IFSs that are computable and satisfy the open set condition. Our main theorem states that, if $F subseteq mathbb{R}^n$ is any computably self-similar fractal and $S$ is any IFS testifying to this fact, then the dimension identities $operatorname{dim}(x) = operatorname{sdim}(F) operatorname{dim}^{pi_S}(T)$ and $operatorname{Dim}(x) = operatorname{sdim}(F) operatorname{Dim}^{pi_S}(T)$ hold for all $x in F$ and all coding sequences $T$ for $x$. In these equations, $operatorname{sdim}(F)$ denotes the similarity dimension of the fractal $F$; $operatorname{dim}(x)$ and $operatorname{Dim}(x)$ denote the dimension and strong dimension, respectively, of the point $x$ in Euclidean space; and $operatorname{dim}^{pi_S}(T)$ and $operatorname{Dim}^{pi_S}(T)$ denote the dimension and strong dimension, respectively, of the coding sequence $T$ relative to a probability measure $pi_S$ that the IFS $S$ induces on the alphabet $Sigma_k$. The above-mentioned theorem of Moran and Falconer follows easily from our main theorem by relativization. Along the way to our main theorem, we develop the elements of the theory of constructive dimensions relative to general probability measures. The proof of our main theorem uses Kolmogorov complexity characterizations of these dimensions.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1080–1112},
numpages = {33},
keywords = {packing dimension, iterated function system, self-similar fractal, geometric measure theory, fractal geometry, computability, constructive dimension, Hausdorff dimension, Billingsley dimension}
}

@article{10.1137/060674417,
author = {Bansal, Nikhil and Coppersmith, Don and Sviridenko, Maxim},
title = {Improved Approximation Algorithms for Broadcast Scheduling},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060674417},
doi = {10.1137/060674417},
abstract = {We consider scheduling policies in a client-server system where the server delivers data by broadcasting it to the users. In thesimplest model of the problem, there is a single server that holds $n$ pages of unit size. Multiple requests for these pages arrive over time. At each time slot the server broadcasts exactly one page which satisfies all of the outstanding requests for this page at that time. We consider the problem of minimizing the average response time of requests, where the response time of the request is the duration since the request is placed until the time it is satisfied. For the offline version of this problem we give an algorithm with an approximation ratio of $O(log^2(n) / log log(n))$. More generally, for any $epsilon&gt;0$, the algorithm achieves an average response time of $(2+epsilon) cdot text{OPT} + O(log n cdot log_{(1+epsilon)} n)$, which is useful when the optimum value is large. This substantially improves the previously best known approximation factor of $O(sqrt{n})$ for the problem [N. Bansal, M. Charikar, S. Khanna, and J. Naor, Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms, Vancouver, British Columbia, ACM, New York, SIAM, Philadelphia, 2005, pp. 215-221]. Our result is based on iteratively relaxing and rounding an auxiliary linear program derived from a natural linear programming relaxation of the problem.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1157–1174},
numpages = {18},
keywords = {approximation algorithm, broadcast scheduling, LP rounding}
}

@article{10.1137/050645403,
author = {Levy, Jordi and Schmidt-Schau\ss{}, Manfred and Villaret, Mateu},
title = {The Complexity of Monadic Second-Order Unification},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050645403},
doi = {10.1137/050645403},
abstract = {Monadic second-order unification is second-order unification where all function constants occurring in the equations are unary. Here we prove that the problem of deciding whether a set of monadic equations has a unifier is NP-complete, where we use the technique of compressing solutions using singleton context-free grammars. We prove that monadic second-order matching is also NP-complete.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1113–1140},
numpages = {28},
keywords = {theorem proving, second-order unification, lambda calculus, context-free grammars, rewriting systems}
}

@article{10.1137/050643350,
author = {Fomin, Fedor V. and Kratsch, Dieter and Todinca, Ioan and Villanger, Yngve},
title = {Exact Algorithms for Treewidth and Minimum Fill-In},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050643350},
doi = {10.1137/050643350},
abstract = {We show that the treewidth and the minimum fill-in of an $n$-vertex graph can be computed in time $mathcal{O}(1.8899^n)$. Our results are based on combinatorial proofs that an $n$-vertex graph has $mathcal{O}(1.7087^n)$ minimal separators and $mathcal{O}(1.8135^n)$ potential maximal cliques. We also show that for the class of asteroidal triple-free graphs the running time of our algorithms can be reduced to $mathcal{O}(1.4142^n)$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1058–1079},
numpages = {22},
keywords = {minimal triangulation, fill-in, potential maximal clique, exact exponential algorithm, minimal separators, treewidth}
}

@article{10.1137/070685920,
author = {Hlin\v{e}n\'{y}, Petr and Oum, Sang-il},
title = {Finding Branch-Decompositions and Rank-Decompositions},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070685920},
doi = {10.1137/070685920},
abstract = {We present a new algorithm that can output the rank-decomposition of width at most $k$ of a graph if such exists. For that we use an algorithm that, for an input matroid represented over a fixed finite field, outputs its branch-decomposition of width at most $k$ if such exists. This algorithm works also for partitioned matroids. Both of these algorithms are fixed-parameter tractable, that is, they run in time $O(n^3)$ where $n$ is the number of vertices / elements of the input, for each constant value of $k$ and any fixed finite field. The previous best algorithm for construction of a branch-decomposition or a rank-decomposition of optimal width due to Oum and Seymour [J. Combin. Theory Ser. B, 97 (2007), pp. 385-393] is not fixed-parameter tractable.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1012–1032},
numpages = {21},
keywords = {matroid, branch-width, graph, rank-width, clique-width, fixed-parameter tractable algorithm}
}

@article{10.1137/070684483,
author = {Kaplan, Haim and Rubin, Natan and Sharir, Micha and Verbin, Elad},
title = {Efficient Colored Orthogonal Range Counting},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070684483},
doi = {10.1137/070684483},
abstract = {Let $P$ be a set of $n$ points in $mathbb{R}^d$, so that each point is colored by one of $C$ given colors. We present algorithms for preprocessing $P$ into a data structure that efficiently supports queries of the following form: Given an axis-parallel box $Q$, count the number of distinct colors of the points of $Pcap Q$. We present a general and relatively simple solution that has a polylogarithmic query time and worst-case storage about $O(n^d)$. It is based on several interesting structural properties of the problem, which we establish here. We also show that for random inputs, the data structure requires almost linear expected storage. We then present several techniques for achieving space-time tradeoff. In $mathbb{R}^2$, the most efficient solution uses fast matrix multiplication in the preprocessing stage. In higher dimensions we use simpler tradeoff mechanisms, which behave just as well. We give a reduction from matrix multiplication to the off-line version of problem, which shows that in $mathbb{R}^2$ our time-space tradeoffs are reasonably sharp, in the sense that improving them substantially would improve the best exponent of matrix multiplication. Finally, we present a generalized matrix multiplication problem and show its intimate relation to counting colors in boxes in higher dimension.},
journal = {SIAM J. Comput.},
month = jun,
pages = {982–1011},
numpages = {30},
keywords = {output-sensitive decomposition, matrix multiplication, union of orthants, time-space tradeoff, generalized range searching, colored orthogonal range counting}
}

@article{10.1137/070682150,
author = {Nguyen, C. Thach and Shen, Jian and Hou, Minmei and Sheng, Li and Miller, Webb and Zhang, Louxin},
title = {Approximating the Spanning Star Forest Problem and Its Application to Genomic Sequence Alignment},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/070682150},
doi = {10.1137/070682150},
abstract = {This paper studies the algorithmic issues of the spanning star forest problem. We prove the following results: (1) There is a polynomial-time approximation scheme for planar graphs; (2) there is a polynomial-time $frac{3}{5}$-approximation algorithm for graphs; (3) it is NP-hard to approximate the problem within ratio $frac{259}{260} + epsilon$ for graphs; (4) there is a linear-time algorithm to compute the maximum star forest of a weighted tree; (5) there is a polynomial-time $frac{1}{2}$-approximation algorithm for weighted graphs. We also show how to apply this spanning star forest model to aligning multiple genomic sequences over a tandem duplication region.},
journal = {SIAM J. Comput.},
month = jun,
pages = {946–962},
numpages = {17},
keywords = {approximation algorithm, genomic sequence alignment, spanning star forest, dominating set}
}

@article{10.1137/060669474,
author = {Aronov, Boris and Har-Peled, Sariel},
title = {On Approximating the Depth and Related Problems},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060669474},
doi = {10.1137/060669474},
abstract = {We study the question of finding a deepest point in an arrangement of regions and provide a fast algorithm for this problem using random sampling, showing it sufficient to solve this problem when the deepest point is shallow. This implies, among other results, a fast algorithm for approximately solving linear programming problems with violations. We also use this technique to approximate the disk covering the largest number of red points, while avoiding all the blue points, given two such sets in the plane. Using similar techniques implies that approximate range counting queries have roughly the same time and space complexity as emptiness range queries.},
journal = {SIAM J. Comput.},
month = jun,
pages = {899–921},
numpages = {23},
keywords = {randomized algorithms, computational geometry, approximation}
}

@article{10.1137/060662204,
author = {Fleischer, Rudolf and Kamphans, Tom and Klein, Rolf and Langetepe, Elmar and Trippen, Gerhard},
title = {Competitive Online Approximation of the Optimal Search Ratio},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060662204},
doi = {10.1137/060662204},
abstract = {How efficiently can we search an unknown environment for a goal in an unknown position? How much would it help if the environment were known? We answer these questions for simple polygons and for undirected graphs by providing online search strategies that are as good as the best offline search algorithms, up to a constant factor. For other settings we prove that no such online algorithms exist. We introduce a natural measure which gives reasonable results and is more realistic than pure pessimistic competitive analysis.},
journal = {SIAM J. Comput.},
month = jun,
pages = {881–898},
numpages = {18},
keywords = {searching, online motion planning, natural measure, competitive ratio, exploration}
}

@article{10.1137/060661259,
author = {Gopalan, Parikshit},
title = {Query-Efficient Algorithms for Polynomial Interpolation over Composites},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060661259},
doi = {10.1137/060661259},
abstract = {The problem of polynomial interpolation is to reconstruct a polynomial based on its valuations on a set of inputs $I$. We consider the problem over $mathbb{Z}_m$ when $m$ is composite. We ask the following question: Given $I subseteq mathbb{Z}_m$, how many evaluations of a polynomial at points in $I$ are required to compute its value at every point in $I$? Surprisingly for composite $m$, this number can vary exponentially between $log |I|$ and $|I|$, in contrast to the prime case where $|I|$ evaluations are necessary. While we show this minimization problem to be NP-hard, we give an efficient algorithm of query complexity within a factor $t$ of the optimum, where $t$ is the number of prime factors of $m$. We use our interpolation algorithm to design algorithms for zero testing and distributional learning of polynomials over $mathbb{Z}_m$. In some cases, we get an exponential improvement over known algorithms in query complexity and running time. Our main technical contribution is the notion of an interpolating set for $I$ which is a subset $S$ of $I$ such that a polynomial which is $0$ over $S$ must be $0$ at every point in $I$. Any interpolation algorithm needs to query an interpolating set for $I$. Our query-efficient algorithms are obtained by constructing interpolating sets whose size is close to optimal.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1033–1057},
numpages = {25},
keywords = {interpolation, polynomials, composites}
}

@article{10.1137/050646895,
author = {Arenas, Marcelo and Fan, Wenfei and Libkin, Leonid},
title = {On the Complexity of Verifying Consistency of XML Specifications},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050646895},
doi = {10.1137/050646895},
abstract = {XML specifications often consist of a type definition (typically, a document type definition (DTD)) and a set of integrity constraints. It has been shown previously that such specifications can be inconsistent, and thus it is often desirable to check consistency at compile time. It is known [W. Fan and L. Libkin, J. ACM, 49 (2002), pp. 368-406] that for general keys, foreign keys, and DTDs the consistency problem is undecidable; however, it becomes NP-complete when all keys are one-attribute (unary) and tractable, if no foreign keys are used. In this paper, we consider a variety of previously studied constraints for XML data and investigate the complexity of the consistency problem. Our main conclusion is that, in the presence of foreign key constraints, compile-time verification of consistency is infeasible. We look at absolute constraints that hold in the entire document and relative constraints that hold only in a part of the document. For absolute constraints, we prove decidability and establish complexity bounds for primary multiattribute keys and unary foreign keys and study unary constraints that involve regular expressions. For relative constraints, we prove that even for unary constraints the consistency problem is undecidable. We also show that results continue to hold for extended DTDs, a more expressive typing mechanism for XML.},
journal = {SIAM J. Comput.},
month = jun,
pages = {841–880},
numpages = {40},
keywords = {consistency, XML, document type definition, complexity, keys and foreign keys}
}

@article{10.1137/050644756,
author = {Markov, Igor L. and Shi, Yaoyun},
title = {Simulating Quantum Computation by Contracting Tensor Networks},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050644756},
doi = {10.1137/050644756},
abstract = {The treewidth of a graph is a useful combinatorial measure of how close the graph is to a tree. We prove that a quantum circuit with $T$ gates whose underlying graph has a treewidth $d$ can be simulated deterministically in $T^{O(1)}exp[O(d)]$ time, which, in particular, is polynomial in $T$ if $d=O(log T)$. Among many implications, we show efficient simulations for log-depth circuits whose gates apply to nearby qubits only, a natural constraint satisfied by most physical implementations. We also show that one-way quantum computation of Raussendorf and Briegel (Phys. Rev. Lett., 86 (2001), pp. 5188-5191), a universal quantum computation scheme with promising physical implementations, can be efficiently simulated by a randomized algorithm if its quantum resource is derived from a small-treewidth graph with a constant maximum degree. (The requirement on the maximum degree was removed in [I. L. Markov and Y. Shi, preprint:quant-ph/0511069].)},
journal = {SIAM J. Comput.},
month = jun,
pages = {963–981},
numpages = {19},
keywords = {quantum computation, classical simulation, tensor network, treewidth, computational complexity, one-way quantum computation}
}

@article{10.1137/050635900,
author = {Gil, \'{A}ngel J. and Hermann, Miki and Salzer, Gernot and Zanuttini, Bruno},
title = {Efficient Algorithms for Description Problems over Finite Totally Ordered Domains},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050635900},
doi = {10.1137/050635900},
abstract = {Given a finite set of vectors over a finite totally ordered domain, we study the problem of computing a constraint in conjunctive normal form such that the set of solutions for the produced constraint is identical to the original set. We develop an efficient polynomial-time algorithm for the general case, followed by specific polynomial-time algorithms producing Horn, dual Horn, and bijunctive formulas for sets of vectors closed under the operations of conjunction, disjunction, and median, respectively. Our results generalize the work of Dechter and Pearl on relational data, as well as the papers by H\'{e}brard and Zanuttini. They complement the results of H\"{a}hnle et al. on multivalued logics and Jeavons et al. on the algebraic approach to constraints.},
journal = {SIAM J. Comput.},
month = jun,
pages = {922–945},
numpages = {24},
keywords = {description problems, complexity, finite domain, algorithms}
}

@article{10.5555/1405029.1405039,
author = {Fagin, Ronald and Gupta, Anupam and Kumar, Ravi and O'Donnell, Ryan},
title = {Special Issue Dedicated to the Thirty-Seventh Annual ACM Symposium on Theory of Computing (STOC 2005)},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
abstract = {This volume comprises the polished and fully refereed versions of a selection of papers presented at the Thirty-Seventh Annual ACM Symposium on Theory of Computing (STOC 2005), held in Baltimore, Maryland, May 22-24, 2005. Unrefereed preliminary versions of the papers presented at the symposium appeared in the proceedings of the meeting, published by ACM. The symposium was sponsored by the ACM Special Interest Group on Algorithms and Computation Theory (SIGACT).The STOC 2005 Program Committee consisted of Gerth St\o{}lting Brodal, Harry Buhrman, Jin-Yi Cai, Cynthia Dwork, Ronald Fagin (chair), Martin Farach-Colton, Anupam Gupta, Sariel Har-Peled, Russell Impagliazzo, Kamal Jain, Adam Tauman Kalai, David Karger, Claire Kenyon, Subhash Khot, Ravi Kumar, Moni Naor, Ryan O'Donnell, Toniann Pitassi, Tim Roughgarden, Alistair Sinclair, and Amnon Ta-Shma.Out of 290 “Extended Abstracts” submitted to the STOC 2005 Program Committee, 84 were selected for presentation at the symposium. The present volume includes 9 of these papers that were invited to this volume. All papers were refereed in accordance with the SIAM Journal on Computing's stringent standards, and these papers were substantially updated in the process. We take this opportunity to thank all the referees whose anonymous work has significantly contributed to the value of this volume.Ronald Fagin, the Program Chair of the 2005 STOC Conference, invited three other members of the Program Committee (Anupam Gupta, Ravi Kumar, and Ryan O'Donnell) to assist in editing this special issue of the of the SIAM Journal on Computing, and all agreed. We feel that it was an honor to edit this issue.},
journal = {SIAM J. Comput.},
month = may,
pages = {.7},
numpages = {1}
}

@article{10.5555/1405029.1405033,
author = {Sanghvi, Saurabh and Vadhan, Salil},
title = {The Round Complexity of Two-Party Random Selection},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
abstract = {We study the round complexity of two-party protocols for generating a random $n$-bit string such that the output is guaranteed to have bounded “bias,” even if one of the two parties deviates from the protocol (possibly using unlimited computational resources). Specifically, we require that the output's statistical difference from the uniform distribution on ${0,1}^n$ is bounded by a constant less than 1. We present a protocol for the above problem that has $2 log^* n + O(1)$ rounds, improving a previous $2n$-round protocol of Goldreich, Goldwasser, and Linial (FOCS '91). Like the GGL Protocol, our protocol actually provides a stronger guarantee, ensuring that the output lands in any set $T subseteq {0,1}^n$ of density $mu$ with probability at most $O(sqrt{mu + delta})$, where $delta$ may be an arbitrarily small constant. We then prove a nearly matching lower bound, showing that any protocol guaranteeing bounded statistical difference requires at least $log^* n - log^* log^* n - O(1)$ rounds. We also prove several results for the case when the output's bias is measured by the maximum multiplicative factor by which a party can increase the probability of a set $T subseteq {0,1}^n$.},
journal = {SIAM J. Comput.},
month = may,
pages = {523–550},
numpages = {28},
keywords = {coin flipping, distributed computing, cryptography}
}

@article{10.1137/S0097539705446925,
author = {Maheshwari, Anil and Zeh, Norbert},
title = {I/O-Efficient Planar Separators},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446925},
doi = {10.1137/S0097539705446925},
abstract = {We present I/O-efficient algorithms for computing optimal separator partitions of planar graphs. Our main result shows that, given a planar graph $G$ with $N$ vertices and an integer $r &gt; 0$, a vertex separator of size O$(N / sqrt{r})$ that partitions $G$ into O$(N / r)$ subgraphs of size at most $r$ and boundary size O$(sqrt{r})$ can be computed in O$(operatorname{sort}(N))$ I/Os. This bound holds provided that $M ge 56r log^2 B$. Together with an I/O-efficient planar embedding algorithm presented in [N. Zeh, I/O-Efficient Algorithms for Shortest Path Related Problems, Ph.D. thesis, School of Computer Science, Carleton University, Ottawa, ON, Canada, 2002], this result is the basis for I/O-efficient solutions to many other fundamental problems on planar graphs, including breadth-first search and shortest paths [L. Arge, G. S. Brodal, and L. Toma, J. Algorithms, 53 (2004), pp. 186-206; L. Arge, L. Toma, and N. Zeh, I/O-efficient algorithms for planar digraphs, in Proceedings of the 15th ACM Symposium on Parallelism in Algorithms and Architectures, ACM, New York, 2003, pp. 85-93], depth-first search [L. Arge et al., J. Graph Algorithms Appl., 7 (2003), pp. 105-129; L. Arge and N. Zeh, I/O-efficient strong connectivity and depth-first search for directed planar graphs, in Proceedings of the 44th IEEE Symposium on Foundations of Computer Science, IEEE Press, Piscataway, NJ, 2003, pp. 261-270], strong connectivity [L. Arge and N. Zeh, I/O-efficient strong connectivity and depth-first search for directed planar graphs, in Proceedings of the 44th IEEE Symposium on Foundations of Computer Science, IEEE Press, Piscataway, NJ, 2003, pp. 261-270], and topological sorting [L. Arge and L. Toma, Simplified external memory algorithms for planar DAGs, in Proceedings of the 9th Scandinavian Workshop on Algorithm Theory, Lecture Notes in Comput. Sci. 3111, Springer-Verlag, Berlin, New York, 2004, pp. 493-503; L. Arge, L. Toma, and N. Zeh, I/O-efficient algorithms for planar digraphs, in Proceedings of the 15th ACM Symposium on Parallelism in Algorithms and Architectures, ACM, New York, 2003, pp. 85-93]. Our second result shows that, given I/O-efficient solutions to these problems, a general separator algorithm for graphs with costs and weights on their vertices [L. Aleksandrov et al., Partitioning planar graphs with costs and weights, in Proceedings of the 4th Workshop on Algorithm Engineering and Experiments, Lecture Notes in Comput. Sci. 2409, Springer-Verlag, Berlin, New York, 2002, pp. 98-107] can be made I/O-efficient. Many classical separator theorems are special cases of this result. In particular, our I/O-efficient version allows the computation of a separator as produced by our first separator algorithm, but without placing any constraints on $r$ in relation to the memory size.},
journal = {SIAM J. Comput.},
month = may,
pages = {767–801},
numpages = {35},
keywords = {planar graphs, graph separators, memory hierarchies, I/O-efficient algorithms, graph algorithms}
}

@article{10.1137/06067777X,
author = {Cheng, Siu-Wing and Na, Hyeon-Suk and Vigneron, Antoine and Wang, Yajun},
title = {Approximate Shortest Paths in Anisotropic Regions},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/06067777X},
doi = {10.1137/06067777X},
abstract = {Our goal is to find an approximate shortest path for a point robot moving in a planar subdivision with $n$ vertices. Let $rhogeq 1$ be a real number. Distances in each face of this subdivision are measured by a convex distance function whose unit disk is contained in a concentric unit Euclidean disk and contains a concentric Euclidean disk with radius $1/rho$. Different convex distance functions may be used for different faces, and obstacles are allowed. These convex distance functions may be asymmetric. For any $varepsilonin(0,1)$ and for any two points $v_s$ and $v_d$, we give an algorithm that finds a path from $v_s$ to $v_d$ whose cost is at most $(1+varepsilon)$ times the optimal. Our algorithm runs in $O(frac{rho^2log rho}{varepsilon^2}n^3 log(frac{rho n}varepsilon))$ time. This bound does not depend on any other parameters; in particular it does not depend on the minimum angle in the subdivision. We give applications to two special cases that have been considered before: the weighted region problem and motion planning in the presence of uniform flows. For the weighted region problem with weights in $[1,rho]cup {infty}$, the time bound of our algorithm improves to $O(frac{rholog rho}{varepsilon}n^3 log(frac{rho n}varepsilon))$.},
journal = {SIAM J. Comput.},
month = may,
pages = {802–824},
numpages = {23},
keywords = {shortest path, weighted region, computational geometry, approximation algorithm, convex distance function}
}

@article{10.1137/060671553,
author = {Pass, Rafael and Rosen, Alon},
title = {New and Improved Constructions of Nonmalleable Cryptographic Protocols},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/060671553},
doi = {10.1137/060671553},
abstract = {We present a new constant-round protocol for nonmalleable zero-knowledge. Using this protocol as a subroutine, we obtain a new constant-round protocol for nonmalleable commitments. Our constructions rely on the existence of (standard) collision-resistant hash functions. Previous constructions either relied on the existence of trapdoor permutations and hash functions that are collision resistant against subexponential-sized circuits or required a superconstant number of rounds. Additional results are the first construction of a nonmalleable commitment scheme that is statistically hiding (with respect to opening) and the first nonmalleable commitments that satisfy a strict polynomial-time simulation requirement. Our approach differs from the approaches taken in previous works in that we view nonmalleable zero-knowledge as a building block rather than an end goal. This gives rise to a modular construction of nonmalleable commitments and results in a somewhat simpler analysis.},
journal = {SIAM J. Comput.},
month = may,
pages = {702–752},
numpages = {51},
keywords = {cryptography, zero-knowledge, round-complexity, nonmalleability, nonblack-box simulation, man-in-the-middle}
}

@article{10.1137/06065934X,
author = {T\'{o}th, Csaba D.},
title = {Binary Space Partitions for Axis-Aligned Fat Rectangles},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/06065934X},
doi = {10.1137/06065934X},
abstract = {It is shown that for any $n$ disjoint axis-aligned fat rectangles in three-space there is a binary space partition (BSP) of $O(nlog^8 n)$ size and $O(log^5 n)$ height and it can be constructed in $O(n ,mathrm{polylog}, n)$ time. This improves earlier bounds of Agarwal et al. [SIAM J. Comput., 29 (2000), pp. 1422-1448]. On the other hand, for every $nin mathbb{N}$, there are $n$ disjoint axis-aligned fat rectangles in $mathbb{R}^3$ such that their smallest axis-aligned BSP has $Omega(nlog n)$ size.},
journal = {SIAM J. Comput.},
month = may,
pages = {429–447},
numpages = {19},
keywords = {axis-aligned rectangles, fat objects, binary space partition, convex partition}
}

@article{10.1137/06065310X,
author = {Grandoni, F. and K\"{o}nemann, J. and Panconesi, A. and Sozio, M.},
title = {A Primal-Dual Bicriteria Distributed Algorithm for Capacitated Vertex Cover},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/06065310X},
doi = {10.1137/06065310X},
abstract = {In this paper we consider the capacitated vertex cover problem, which is the variant of vertex cover where each node is allowed to cover a limited number of edges. We present an efficient, deterministic, distributed approximation algorithm for the problem. Our algorithm computes a $(2+epsilon)$-approximate solution which violates the capacity constraints by a factor of $(4+epsilon)$ in a polylogarithmic number of communication rounds. On the other hand, we also show that every efficient distributed approximation algorithm for this problem must violate the capacity constraints. Our result is achieved in two steps. We first develop a $2$-approximate, sequential primal-dual algorithm that violates the capacity constraints by a factor of $2$. Subsequently, we present a distributed version of this algorithm. We demonstrate that the sequential algorithm has an inherent need for synchronization which forces any naive distributed implementation to use a linear number of communication rounds. The challenge in this step is therefore to achieve a reduction of the communication complexity to a polylogarithmic number of rounds without worsening the approximation guarantee.},
journal = {SIAM J. Comput.},
month = may,
pages = {825–840},
numpages = {16},
keywords = {primal-dual algorithms, vertex cover, approximation algorithms, distributed algorithms}
}

@article{10.1137/050646445,
author = {Ben-Sasson, Eli and Sudan, Madhu},
title = {Short PCPs with Polylog Query Complexity},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050646445},
doi = {10.1137/050646445},
abstract = {We give constructions of probabilistically checkable proofs (PCPs) of length $n cdot polylog n$ proving satisfiability of circuits of size $n$ that can be verified by querying $polylog n$ bits of the proof. We also give analogous constructions of locally testable codes (LTCs) mapping $n$ information bits to $ncdot polylog n$ bit long codewords that are testable with $polylog n$ queries. Our constructions rely on new techniques revolving around properties of codes based on relatively high-degree polynomials in one variable, i.e., Reed-Solomon codes. In contrast, previous constructions of short PCPs, beginning with [L. Babai, L. Fortnow, L. Levin, and M. Szegedy, Checking computations in polylogarithmic time, in Proceedings of the 23rd ACM Symposium on Theory of Computing, ACM, New York, 1991, pp. 21-31] and until the recent [E. Ben-Sasson, O. Goldreich, P. Harsha, M. Sudan, and S. Vadhan, Robust PCPs of proximity, shorter PCPs, and applications to coding, in Proceedings of the 36th ACM Symposium on Theory of Computing, ACM, New York, 2004, pp. 13-15], relied extensively on properties of low-degree polynomials in many variables. We show how to convert the problem of verifying the satisfaction of a circuit by a given assignment to the task of verifying that a given function is close to being a Reed-Solomon codeword, i.e., a univariate polynomial of specified degree. This reduction also gives an alternative to using the “sumcheck protocol” [C. Lund, L. Fortnow, H. Karloff, and N. Nisan, J. ACM, 39 (1992), pp. 859-868]. We then give a new PCP for the special task of proving that a function is close to being a Reed-Solomon codeword. The resulting PCPs are not only shorter than previous ones but also arguably simpler. In fact, our constructions are also more natural in that they yield locally testable codes first, which are then converted to PCPs. In contrast, most recent constructions go in the opposite direction of getting locally testable codes from PCPs.},
journal = {SIAM J. Comput.},
month = may,
pages = {551–607},
numpages = {57},
keywords = {probabilistically checkable proofs (PCPs), PCPs of proximity, locally testable codes, Reed-Solomon codes}
}

@article{10.1137/050645427,
author = {Boja\'{n}czyk, Mikoundefinedaj and Colcombet, Thomas},
title = {Tree-Walking Automata Do Not Recognize All Regular Languages},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050645427},
doi = {10.1137/050645427},
abstract = {Tree-walking automata are a natural sequential model for recognizing tree languages. It is well known that every tree language recognized by a tree-walking automaton is regular. We show that the converse does not hold.},
journal = {SIAM J. Comput.},
month = may,
pages = {658–701},
numpages = {44},
keywords = {formal languages, tree-walking automata, tree automata}
}

@article{10.1137/050644768,
author = {Shi, Yaoyun and Zhu, Yufan},
title = {Tensor Norms and the Classical Communication Complexity of Nonlocal Quantum Measurement},
year = {2008},
issue_date = {June 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050644768},
doi = {10.1137/050644768},
abstract = {We initiate the study of quantifying nonlocality of a bipartite measurement by the minimum amount of classical communication required to simulate the measurement. We derive general upper bounds in terms of some tensor norms of the measurement operator. As applications, we show that (a) if the amount of communication is a constant, then quantum and classical communication protocols with an unlimited amount of shared entanglement or shared randomness compute the same class of functions; and (b) it requires only a constant amount of communication to classically generate an approximation of the output distribution resulting from local measurements on an entangled quantum state, as long as the number of measurement outcomes is a constant.},
journal = {SIAM J. Comput.},
month = may,
pages = {753–766},
numpages = {14},
keywords = {classical simulation, communication complexity, quantum entanglement, tensor norms, Bell inequality}
}

@article{10.1137/05064299X,
author = {Feige, Uriel and Hajiaghayi, MohammadTaghi and Lee, James R.},
title = {Improved Approximation Algorithms for Minimum Weight Vertex Separators},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/05064299X},
doi = {10.1137/05064299X},
abstract = {We develop the algorithmic theory of vertex separators and its relation to the embeddings of certain metric spaces. Unlike in the edge case, we show that embeddings into $L_1$ (and even Euclidean embeddings) are insufficient but that the additional structure provided by many embedding theorems does suffice for our purposes. We obtain an $O(sqrt{log n})$ approximation for minimum ratio vertex cuts in general graphs, based on a new semidefinite relaxation of the problem, and a tight analysis of the integrality gap which is shown to be $Theta(sqrt{log n})$. We also prove an optimal $O(log k)$-approximate max-flow/min-vertex-cut theorem for arbitrary vertex-capacitated multicommodity flow instances on $k$ terminals. For uniform instances on any excluded-minor family of graphs, we improve this to $O(1)$, and this yields a constant-factor approximation for minimum ratio vertex cuts in such graphs. Previously, this was known only for planar graphs, and for general excluded-minor families the best known ratio was $O(log n)$. These results have a number of applications. We exhibit an $O(sqrt{log n})$ pseudoapproximation for finding balanced vertex separators in general graphs. In fact, we achieve an approximation ratio of $O(sqrt{log {opt}})$, where ${opt}$ is the size of an optimal separator, improving over the previous best bound of $O(log {opt})$. Likewise, we obtain improved approximation ratios for treewidth: in any graph of treewidth $k$, we show how to find a tree decomposition of width at most $O(k sqrt{log k})$, whereas previous algorithms yielded $O(k log k)$. For graphs excluding a fixed graph as a minor (which includes, e.g., bounded genus graphs), we give a constant-factor approximation for the treewidth. This in turn can be used to obtain polynomial-time approximation schemes for several problems in such graphs.},
journal = {SIAM J. Comput.},
month = may,
pages = {629–657},
numpages = {29},
keywords = {multicommodity flows, sparsest cut, graph separators, embeddings}
}

@article{10.1137/050642381,
author = {Trifonov, Vladimir},
title = {An $O(\logn \log\logn)$ Space Algorithm for Undirected St-Connectivity},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050642381},
doi = {10.1137/050642381},
abstract = {We present a deterministic $O(log n log log n)$ space algorithm for undirected st-connectivity. It is based on a space-efficient simulation of the deterministic EREW algorithm of Chong and Lam [J. Algorithms, 18 (1995), pp. 378-402], an approach suggested by Prof. Vijaya Ramachandran, and uses the universal exploration sequences for trees constructed by Kouck\'{y} in [Proceedings of the 16th Annual IEEE Conference on Computational Complexity, 2001, pp. 21-27]. Our result improves the $O(log^{4/3} n)$ bound of Armoni et al. in [Proceedings of the 20th Annual ACM Symposium on Theory of Computing, 1997, pp. 230-239] and is a big step towards the optimal $O(log n)$. Independently of our result and using a different set of techniques, the optimal bound was achieved by Reingold in [Proceedings of the 37th Annual ACM Symposium on Theory of Computing, 2005, pp. 376-385].},
journal = {SIAM J. Comput.},
month = may,
pages = {449–483},
numpages = {35},
keywords = {undirected st-connectivity, space-bounded computation}
}

@article{10.1137/050641661,
author = {Elkin, Michael and Emek, Yuval and Spielman, Daniel A. and Teng, Shang-Hua},
title = {Lower-Stretch Spanning Trees},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050641661},
doi = {10.1137/050641661},
abstract = {We show that every weighted connected graph $G$ contains as a subgraph a spanning tree into which the edges of $G$ can be embedded with average stretch $O (log^{2} n log log n)$. Moreover, we show that this tree can be constructed in time $O (m log n + n log^2 n)$ in general, and in time $O (m log n)$ if the input graph is unweighted. The main ingredient in our construction is a novel graph decomposition technique. Our new algorithm can be immediately used to improve the running time of the recent solver for symmetric diagonally dominant linear systems of Spielman and Teng from $ m 2^{(O (sqrt{log nloglog n})) }$ to $m log^{O (1)}n$, and to $O ( n log^{2} n log log n)$ when the system is planar. Our result can also be used to improve several earlier approximation algorithms that use low-stretch spanning trees.},
journal = {SIAM J. Comput.},
month = may,
pages = {608–628},
numpages = {21},
keywords = {low-distortion embeddings, low-stretch spanning trees, probabilistic tree metrics}
}

@article{10.1137/050636231,
author = {Morris, Ben},
title = {The Mixing Time of the Thorp Shuffle},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050636231},
doi = {10.1137/050636231},
abstract = {The Thorp shuffle is defined as follows. Cut a deck of cards into two equal piles. Drop the first card from the left pile or the right pile according to the outcome of a fair coin flip, then drop from the other pile. Continue this way until both piles are empty. We show that the mixing time for the Thorp shuffle with $2^d$ cards is polynomial in $d$.},
journal = {SIAM J. Comput.},
month = may,
pages = {484–504},
numpages = {21},
keywords = {mixing time, Markow chain, card shuffling}
}

@article{10.1137/050633445,
author = {Alon, Noga and Shapira, Asaf},
title = {Every Monotone Graph Property Is Testable},
year = {2008},
issue_date = {May 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050633445},
doi = {10.1137/050633445},
abstract = {A graph property is called monotone if it is closed under removal of edges and vertices. Many monotone graph properties are some of the most well-studied properties in graph theory, and the abstract family of all monotone graph properties was also extensively studied. Our main result in this paper is that any monotone graph property can be tested with one-sided error, and with query complexity depending only on $epsilon$. This result unifies several previous results in the area of property testing and also implies the testability of well-studied graph properties that were previously not known to be testable. At the heart of the proof is an application of a variant of Szemer\'{e}di's regularity lemma. The main ideas behind this application may be useful in characterizing all testable graph properties and in generally studying graph property testing. As a byproduct of our techniques we also obtain additional results in graph theory and property testing, which are of independent interest. One of these results is that the query complexity of testing testable graph properties with one-sided error may be arbitrarily large. Another result, which significantly extends previous results in extremal graph theory, is that for any monotone graph property ${cal P}$, any graph that is $epsilon$-far from satisfying ${cal P}$ contains a subgraph of size depending on $epsilon$ only, which does not satisfy ${cal P}$. Finally, we prove the following compactness statement: If a graph $G$ is $epsilon$-far from satisfying a (possibly infinite) set of monotone graph properties ${cal P}$, then it is at least $delta_{{cal P}}(epsilon)$-far from satisfying one of the properties.},
journal = {SIAM J. Comput.},
month = may,
pages = {505–522},
numpages = {18},
keywords = {graphs, monotone properties, property testing, regularity lemma}
}

@article{10.1137/060672261,
author = {de Berg, Mark and Gray, Chris},
title = {Vertical Ray Shooting and Computing Depth Orders for Fat Objects},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060672261},
doi = {10.1137/060672261},
abstract = {We present new results for three problems dealing with a set $mathcal{P}$ of $n$ convex constant-complexity fat polyhedra in 3-space. (i) We describe a data structure for vertical ray shooting in $mathcal{P}$ that has $O(log^2 n)$ query time and uses $O(nlog^2 n)$ storage. (ii) We give an algorithm to compute in $O(nlog^3 n)$ time a depth order on $mathcal{P}$ if it exists. (iii) We give an algorithm to verify in $O(nlog^3 n)$ time whether a given order on $mathcal{P}$ is a valid depth order. All three results improve on previous results.},
journal = {SIAM J. Comput.},
month = apr,
pages = {257–275},
numpages = {19},
keywords = {depth orders, fat objects, ray shooting, computational geometry}
}

@article{10.1137/060670328,
author = {Epstein, Leah and Levin, Asaf},
title = {An APTAS for Generalized Cost Variable-Sized Bin Packing},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060670328},
doi = {10.1137/060670328},
abstract = {Bin packing is a well-known problem which has a large number of applications. Classical bin packing is a simple model in which all bins are identical. In the bin packing problem with variable-sized bins, we are given a supply of a variety of sizes. This latter model assumes, however, that the cost of a bin is always defined to be its exact size. In this paper we study the more general problem where an available bin size is associated with a fixed cost, which may be smaller or larger than its size. The costs of different bin sizes are unrelated. This generalized problem has various applications in storage and scheduling. In order to generalize previous work, we design new rounding and allocation methods. Our main result is an asymptotic polynomial time approximation scheme for the generalized problem.},
journal = {SIAM J. Comput.},
month = apr,
pages = {411–428},
numpages = {18},
keywords = {approximation algorithm, bin packing, worst case analysis}
}

@article{10.1137/060669231,
author = {Jonsson, Peter and Kuivinen, Fredrik and Nordh, Gustav},
title = {MAX ONES Generalized to Larger Domains},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060669231},
doi = {10.1137/060669231},
abstract = {We study a family of problems, called Maximum Solution, where the objective is to maximize a linear goal function over the feasible integer assignments to a set of variables subject to a set of constraints. When the domain is Boolean (i.e., restricted to ${0,1}$), the maximum solution problem is identical to the well-studied Max Ones problem, and the approximability is completely understood for all restrictions on the underlying constraints [S. Khanna, M. Sudan, L. Trevisan, and D. P. Williamson, SIAM J. Comput., 30 (2001), pp. 1863-1920]. We continue this line of research by considering domains containing more than two elements. We present two main results: a complete classification for the approximability of all maximal constraint languages over domains of cardinality at most $4$, and a complete classification of the approximability of the problem when the set of allowed constraints contains all permutation constraints. Under the assumption that a conjecture due to Szczepara [Minimal Clones Generated by Groupoids, Ph.D. thesis, Universit\'{e} de M\'{o}ntreal, Montreal, QC, 1996] holds, we give a complete classification for all maximal constraint languages. These classes of languages are well studied in universal algebra and computer science; they have, for instance, been considered in connection with machine learning and constraint satisfaction. Our results are proved by using algebraic results from clone theory, and the results indicate that this approach is very powerful for classifying the approximability of certain optimization problems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {329–365},
numpages = {37},
keywords = {constraint satisfaction, combinatorial optimization, approximability, universal algebra}
}

@article{10.1137/060667839,
author = {Chen, Ke and Har-Peled, Sariel},
title = {The Euclidean Orienteering Problem Revisited},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060667839},
doi = {10.1137/060667839},
abstract = {We consider the rooted orienteering problem: Given a set $P$ of $n$ points in the plane, a starting point $r in P$, and a length constraint $B$, one needs to find a path starting from $r$ that visits as many points of $P$ as possible and of length not exceeding $B$. We present a $(1-varepsilon)$-approximation algorithm for this problem that runs in $n^{O(1/varepsilon)}$ time; the computed path visits at least $ (1-varepsilon)k_{mathrm{opt}}$ points of $P$, where $k_{mathrm{opt}}$ is the number of points visited by an optimal solution. This is the first polynomial time approximation scheme for this problem. The algorithm also works in higher dimensions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {385–397},
numpages = {13},
keywords = {$k$-TSP, approximation algorithms, orienteering problem, PTAS}
}

@article{10.1137/060665257,
author = {Cohen, Reuven and Peleg, David},
title = {Convergence of Autonomous Mobile Robots with Inaccurate Sensors and Movements},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060665257},
doi = {10.1137/060665257},
abstract = {A number of recent studies concern algorithms for distributed control and coordination in systems of autonomous mobile robots. The common theoretical model adopted in these studies assumes that the positional input of the robots is obtained by perfectly accurate visual sensors, that robot movements are accurate, and that internal calculations performed by the robots on (real) coordinates are perfectly accurate as well. The current paper concentrates on the effect of weakening this rather strong set of assumptions and replacing it with the more realistic assumption that the robot sensors, movement, and internal calculations may have slight inaccuracies. Specifically, the paper concentrates on the ability of robot systems with inaccurate sensors, movements, and calculations to carry out the task of convergence. The paper presents several impossibility theorems, limiting the inaccuracy levels that still allow convergence, and prohibiting a general algorithm for gathering, namely, meeting at a point, in a finite number of steps. The main positive result is an algorithm for convergence under bounded measurement, movement, and calculation errors.},
journal = {SIAM J. Comput.},
month = apr,
pages = {276–302},
numpages = {27},
keywords = {autonomous robots, inaccurate sensors, fault tolerance}
}

@article{10.1137/060658023,
author = {Brattka, Vasco},
title = {Plottable Real Number Functions and the Computable Graph Theorem},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060658023},
doi = {10.1137/060658023},
abstract = {The Graph Theorem of classical recursion theory states that a total function on the natural numbers is computable if and only if its graph is recursive. It is known that this result can be generalized to real number functions where it has an important practical interpretation: the total computable real number functions are precisely those which can be effectively plotted with any given resolution. We generalize the Graph Theorem to appropriate partial real number functions and even further to functions defined on certain computable metric spaces. Besides the nonuniform version of the Graph Theorem which logically relates computability properties of the function and computability properties of its graph, we also discuss the uniform version: given a program of a function, can we algorithmically derive a description of its graph? And, vice versa, given a description of the graph, can we derive a program of the function? While the passage from functions to graphs is always computable, the inverse direction from graphs to functions is problematic, and it turns out that the answers to the uniform and the nonuniform questions do not coincide. We prove that in both cases certain topological and computational properties (such as compactness or effective local connectedness) are sufficient for a positive answer, and we provide counterexamples which show that the corresponding properties are not superfluous. Additionally, we briefly discuss the special situation of the linear case.},
journal = {SIAM J. Comput.},
month = apr,
pages = {303–328},
numpages = {26},
keywords = {computable real number functions, recursive graphs}
}

@article{10.1137/060651835,
author = {Bar-Yossef, Ziv and Jayram, T. S. and Kerenidis, Iordanis},
title = {Exponential Separation of Quantum and Classical One-Way Communication Complexity},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060651835},
doi = {10.1137/060651835},
abstract = {We give the first exponential separation between quantum and bounded-error randomized one-way communication complexity. Specifically, we define the Hidden Matching Problem HM$_n$: Alice gets as input a string ${bf x}in{0, 1}^n$, and Bob gets a perfect matching $M$ on the $n$ coordinates. Bob's goal is to output a tuple $langle i,j,b rangle$ such that the edge $(i,j)$ belongs to the matching $M$ and $b=x_ioplus x_j$. We prove that the quantum one-way communication complexity of HM$_n$ is $O(log n)$, yet any randomized one-way protocol with bounded error must use $Omega({sqrt{n}})$ bits of communication. No asymptotic gap for one-way communication was previously known. Our bounds also hold in the model of Simultaneous Messages (SM), and hence we provide the first exponential separation between quantum SM and randomized SM with public coins. For a Boolean decision version of HM$_n$, we show that the quantum one-way communication complexity remains $O(log n)$ and that the 0-error randomized one-way communication complexity is $Omega(n)$. We prove that any randomized linear one-way protocol with bounded error for this problem requires $Omega(sqrt[3]{n log n})$ bits of communication.},
journal = {SIAM J. Comput.},
month = apr,
pages = {366–384},
numpages = {19},
keywords = {hidden matching, communication complexity, separation, quantum computation}
}

@article{10.1137/050647049,
author = {Balogh, J\'{a}nos and B\'{e}k\'{e}si, J\'{o}zsef and Galambos, G\'{a}bor and Reinelt, Gerhard},
title = {Lower Bound for the Online Bin Packing Problem with Restricted Repacking},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050647049},
doi = {10.1137/050647049},
abstract = {In 1996 Ivkovi\v{c} and Lloyd [A fundamental restriction on
fully dynamic maintenance of bin packing, Inform. Process.
Lett., 59 (1996), pp. 229-232] gave the lower bound $frac{4}{3}$
on the asymptotic worst-case ratio for so-called fully dynamic bin
packing algorithms, where the number of repackable items in each
step is restricted by a constant. In this paper we improve this
result to about $1.3871$. We present our proof for a semionline
case of the classical bin packing, but it works for fully dynamic
bin packing as well. We prove the lower bound by analyzing and
solving a specific optimization problem. The bound can be expressed
exactly using the Lambert $W$ function.},
journal = {SIAM J. Comput.},
month = apr,
pages = {398–410},
numpages = {13},
keywords = {worst-case behavior, semionline algorithm, bin packing, lower bound}
}

@article{10.5555/1404986.1404991,
author = {Farshi, Mohammad and Giannopoulos, Panos and Gudmundsson, Joachim},
title = {Improving the Stretch Factor of a Geometric Network by Edge Augmentation},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
abstract = {Given a Euclidean graph $G$ in $mathbb{R}^d$ with $n$ vertices and $m$ edges, we consider the problem of adding an edge to $G$ such that the stretch factor of the resulting graph is minimized. Currently, the fastest algorithm for computing the stretch factor of a graph with positive edge weights runs in $cal{O}$$(nm+n^2 log n)$ time, resulting in a trivial $cal{O}$$(n^3m+n^4 log n)$-time algorithm for computing the optimal edge. First, we show that a simple modification yields the optimal solution in $cal{O}$$(n^4)$ time using $cal{O}$$(n^2)$ space. To reduce the running time we consider several approximation algorithms.},
journal = {SIAM J. Comput.},
month = mar,
pages = {226–240},
numpages = {15},
keywords = {geometric networks, approximation algorithms, computational geometry}
}

@article{10.5555/1362744.1362753,
author = {Dinur, Irit and Tardos, Eva},
title = {Special Issue on Foundations of Computer Science},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
abstract = {This volume comprises the polished and fully refereed versions of a selection of papers presented at the Forty-Sixth Annual IEEE Symposium on Foundations of Computer Science (FOCS 2005), held in Pittsburgh, Pennsylvania, October 23-25, 2005. Unrefereed preliminary versions of the papers presented at the symposium appeared in the proceedings of the meeting, published by IEEE. The FOCS 2005 Program Committee consisted of Ziv Bar-Yossef, Paul Beame, Ran Canetti, Irit Dinur, Ashish Goel, Venkatesan Guruswami, Sariel Har-Peled, Michael Kearns, Richard Lipton, Frank McSherry, Satish Rao, Omer Reingold, Eva Tardos, Mikkel Thorup, Berthold Voecking, John Watrous, Mihalis Yannakakis, and David Zuckerman. Of 276 extended abstracts submitted to the FOCS 2005 Program Committee, 62 were selected for presentation at the symposium. Eight of those 62 papers are included in this volume. This collection encompasses a wide variety of topics and methods in theoretical computer science, often shedding new light on entire areas with a fresh approach. The topics include algorithms, learning, property testing, combinatorics, cryptography, and distributed and quantum computing. All papers were refereed in accordance with SICOMP's stringent standards, and most were substantially updated in the process. We take this opportunity to thank all the referees whose anonymous work has significantly contributed to the value of this volume. It was an honor to edit this special section in SIAM Journal on Computing.},
journal = {SIAM J. Comput.},
month = mar,
pages = {.7},
numpages = {1}
}

@article{10.1137/070680795,
author = {Fischer, Eldar and Matsliah, Arie},
title = {Testing Graph Isomorphism},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/070680795},
doi = {10.1137/070680795},
abstract = {Two graphs $G$ and $H$ on $n$ vertices are $epsilon$-far from being isomorphic if at least $epsilonbinom{n}{2}$ edges must be added or removed from $E(G)$ in order to make $G$ and $H$ isomorphic. In this paper we deal with the question of how many queries are required to distinguish between the case that two graphs are isomorphic and the case that they are $epsilon$-far from being isomorphic. A query is defined as probing the adjacency matrix of any one of the two graphs, i.e., asking if a pair of vertices forms an edge of the graph or not. We investigate both one-sided and two-sided error testers under two possible settings: The first setting is where both graphs need to be queried, and the second setting is where one of the graphs is fully known to the algorithm in advance. We prove that the query complexity of the best one-sided error testing algorithm is $widetilde{Theta}(n^{3/2})$ if both graphs need to be queried, and that it is $widetilde{Theta}(n)$ if one of the graphs is known in advance (where the $widetilde{Theta}$ notation hides polylogarithmic factors in the upper bounds). For two-sided error testers, we prove that the query complexity of the best tester is $widetilde{Theta}(sqrt{n})$ when one of the graphs is known in advance, and we show that the query complexity lies between $Omega(n)$ and $widetilde{O}(n^{5/4})$ if both $G$ and $H$ need to be queried. All of our algorithms are additionally nonadaptive, while all of our lower bounds apply for adaptive testers as well as nonadaptive ones.},
journal = {SIAM J. Comput.},
month = mar,
pages = {207–225},
numpages = {19},
keywords = {property testing, graph isomorphism, approximation}
}

@article{10.1137/060676003,
author = {Manthey, Bodo},
title = {On Approximating Restricted Cycle Covers},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060676003},
doi = {10.1137/060676003},
abstract = {A cycle cover of a graph is a set of cycles such that every vertex is part of exactly one cycle. An $L$-cycle cover is a cycle cover in which the length of every cycle is in the set $L$. The weight of a cycle cover of an edge-weighted graph is the sum of the weights of its edges. We come close to settling the complexity and approximability of computing $L$-cycle covers. On the one hand, we show that, for almost all $L$, computing $L$-cycle covers of maximum weight in directed and undirected graphs is $mathsf{APX}$-hard. Most of our hardness results hold even if the edge weights are restricted to zero and one. On the other hand, we show that the problem of computing $L$-cycle covers of maximum weight can be approximated within a factor of $2$ for undirected graphs and within a factor of $8/3$ in the case of directed graphs. This holds for arbitrary sets $L$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {181–206},
numpages = {26},
keywords = {inapproximability, two-factors, approximation algorithms, cycle covers}
}

@article{10.1137/060664537,
author = {Allender, Eric and Hellerstein, Lisa and McCabe, Paul and Pitassi, Toniann and Saks, Michael},
title = {Minimizing Disjunctive Normal Form Formulas and $AC^0$ Circuits Given a Truth Table},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060664537},
doi = {10.1137/060664537},
abstract = {For circuit classes $R$, the fundamental computational problem Min-R asks for the minimum $R$-size of a Boolean function presented as a truth table. Prominent examples of this problem include Min-DNF, which asks whether a given Boolean function presented as a truth table has a $k$-term disjunctive normal form (DNF), and Min-Circuit (also called the minimum circuit size problem (MCSP)), which asks whether a Boolean function presented as a truth table has a size $k$ Boolean circuit. We present a new reduction proving that Min-DNF is NP-complete. It is significantly simpler than the known reduction of Masek [Some NP-Complete Set Covering Problems, manuscript, 1979], which is from Circuit-SAT. We then give a more complex reduction, yielding the result that Min-DNF cannot be approximated to within a factor smaller than $(log N)^{gamma}$, for some constant $gamma&gt;0$, assuming that NP is not contained in quasi-polynomial time. The standard greedy algorithm for Set Cover is often used in practice to approximate Min-DNF. The question of whether Min-DNF can be approximated to within a factor of $o(log N)$ remains open, but we construct an instance of Min-DNF on which the solution produced by the greedy algorithm is $Omega(log N)$ larger than optimal. Finally, we turn to the question of approximating circuit size for slightly more general classes of circuits. DNF formulas are depth-two circuits of AND and OR gates. Depth-$d$ circuits are denoted by $AC^0_d$. We show that it is hard to approximate the size of $AC^0_d$ circuits (for large enough $d$) under cryptographic assumptions.},
journal = {SIAM J. Comput.},
month = mar,
pages = {63–84},
numpages = {22},
keywords = {truth table minimization, machine learning theory, complexity theory, approximation algorithms}
}

@article{10.1137/060661880,
author = {Pass, Rafael and Rosen, Alon},
title = {Concurrent Nonmalleable Commitments},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060661880},
doi = {10.1137/060661880},
abstract = {We present a nonmalleable commitment scheme that retains its security properties even when concurrently executed a polynomial number of times. That is, a man-in-the-middle adversary who is simultaneously participating in multiple concurrent commitment phases of our scheme, both as a sender and as a receiver, cannot make the values to which he commits depend on the values to which he receives commitments. Our result is achieved without assuming an a priori bound on the number of executions and without relying on any setup assumptions. Our construction relies on the existence of standard claw-free permutations and requires only a constant number of communication rounds.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1891–1925},
numpages = {35},
keywords = {nonmalleability, cryptography, non-black-box simulation, concurrency, commitments}
}

@article{10.1137/060658448,
author = {Jain, Kamal and Vazirani, Vijay V.},
title = {Equitable Cost Allocations via Primal-Dual-Type Algorithms},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060658448},
doi = {10.1137/060658448},
abstract = {Perhaps the strongest notion of truth-revealing in a cost sharing mechanism is group strategyproofness. However, matters are not so clear-cut on fairness, and many different, sometimes even conflicting, notions of fairness have been proposed which have relevance in different situations. We present a large class of group strategyproof cost sharing methods, for submodular cost functions, satisfying a wide range of fairness criteria, thereby allowing the service provider to choose a method that best satisfies the notion of fairness that is most relevant to its application. Our class includes the Dutta-Ray egalitarian method as a special case. It also includes a new cost sharing method, which we call the opportunity egalitarian method.},
journal = {SIAM J. Comput.},
month = mar,
pages = {241–256},
numpages = {16},
keywords = {submodular cost functions, opportunity egalitarian method, fairness in cost sharing, cost sharing methods, group strategyproof mechanism}
}

@article{10.1137/060658400,
author = {Pagh, Anna and Pagh, Rasmus},
title = {Uniform Hashing in Constant Time and Optimal Space},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060658400},
doi = {10.1137/060658400},
abstract = {Many algorithms and data structures employing hashing have been analyzed under the uniform hashing assumption, i.e., the assumption that hash functions behave like truly random functions. Starting with the discovery of universal hash functions, many researchers have studied to what extent this theoretical ideal can be realized by hash functions that do not take up too much space and can be evaluated quickly. In this paper we present an almost ideal solution to this problem: a hash function $h: Urightarrow V$ that, on any set of $n$ inputs, behaves like a truly random function with high probability, can be evaluated in constant time on a RAM and can be stored in $(1+epsilon)nlog |V| + O(n+loglog |U|)$ bits. Here $epsilon$ can be chosen to be any positive constant, so this essentially matches the entropy lower bound. For many hashing schemes this is the first hash function that makes their uniform hashing analysis come true, with high probability, without incurring overhead in time or space.},
journal = {SIAM J. Comput.},
month = mar,
pages = {85–96},
numpages = {12},
keywords = {randomized algorithms, hash function, uniform hashing}
}

@article{10.1137/060656838,
author = {Moshkovitz, Dana and Raz, Ran},
title = {Sub-Constant Error Low Degree Test of Almost-Linear Size},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060656838},
doi = {10.1137/060656838},
abstract = {Given (the table of) a function $f : mathbb{F}^m rightarrow mathbb{F}$ over a finite field $mathbb{F}$, a low degree tester tests its agreement with an $m$-variate polynomial of total degree at most $d$ over $mathbb{F}$. The tester is usually given access to an oracle $mathcal{A}$ providing the supposed restrictions of $f$ to affine subspaces of constant dimension (e.g., lines, planes, etc.). The tester makes very few (probabilistic) queries to $f$ and to $mathcal{A}$ (say, one query to $f$ and one query to $mathcal{A}$) and decides whether to accept or reject based on the replies. We wish to minimize two parameters of the tester: its error and its size. The error bounds the probability that the tester accepts although the function is far from a low degree polynomial. The size is the number of bits required to write the oracle replies on all possible tester queries. Low degree testing is a central ingredient in most constructions of probabilistically checkable proofs (PCPs). The error of the low degree tester is related to the error of the PCP, and its size is related to the size of the PCP. We design and analyze new low degree testers that have both subconstant error $o(1)$ and almost-linear size $n^{1+o(1)}$ (where $n = left|mathbb{F}right|^{m}$). Previous constructions of subconstant error testers had polynomial size. These testers enabled the construction of PCPs with subconstant error, but polynomial size. Previous constructions of almost-linear size testers obtained only constant error. These testers were used to construct almost-linear size PCPs with constant error. The testers we present in this work enabled the construction of PCPs with both subconstant error and almost-linear size.},
journal = {SIAM J. Comput.},
month = mar,
pages = {140–180},
numpages = {41},
keywords = {probabilistically checkable proofs, plane vs. point test, low degree testing, sampling}
}

@article{10.1137/060656309,
author = {Halman, Nir},
title = {On the Algorithmic Aspects of Discrete and Lexicographic Helly-Type Theorems and the Discrete LP-Type Model},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060656309},
doi = {10.1137/060656309},
abstract = {Helly's theorem says that, if every $d+1$ elements of a given finite set of convex objects in $mathbb{R}^d$ have a common point, there is a point common to all of the objects in the set. In discrete Helly theorems the common point should belong to an a priori given set. In lexicographic Helly theorems the common point should not be lexicographically greater than a given point. Using discrete and lexicographic Helly theorems we get linear time solutions for various optimization problems. For this, we introduce the DLP-type (discrete linear programming-type) model, and provide new algorithms that solve in randomized linear time fixed-dimensional DLP-type problems. For variable-dimensional DLP-type problems, our algorithms run in time subexponential in the combinatorial dimension. Finally, we use our results in order to solve in randomized linear time problems such as the discrete $p$-center on the real line, the discrete weighted 1-center problem in $mathbb{R}^d$ with either $l_1$ or $l_infty$ norm, the standard (continuous) problem of finding a line transversal for a totally separable set of planar convex objects, a discrete version of the problem of finding a line transversal for a set of axis-parallel planar rectangles, and the (planar) lexicographic rectilinear $p$-center problem for $p=1,2,3$. These are the first known linear time algorithms for these problems. Moreover, we use our algorithms to solve in randomized subexponential time various problems in game theory, improving upon the best known algorithms for these problems.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1–45},
numpages = {45},
keywords = {Helly-type theorems, LP-type model, design and analysis of algorithms}
}

@article{10.1137/060654864,
author = {Goyal, Navin and Kindler, Guy and Saks, Michael},
title = {Lower Bounds for the Noisy Broadcast Problem},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060654864},
doi = {10.1137/060654864},
abstract = {We prove the first nontrivial (superlinear) lower bound in the noisy broadcast model, defined by El Gamal in [Open problems presented at the $1984$ workshop on Specific Problems in Communication and Computation sponsored by Bell Communication Research, in Open Problems in Communication and Computation, T. M. Cover and B. Gopinath, eds., Springer-Verlag, New York, 1987, pp. 60-62]. In this model there are $n+1$ processors $P_0,P_1,ldots,P_n$, each of which is initially given a private input bit $x_i$. The goal is for $P_0$ to learn the value of $f(x_1,ldots,x_n)$, for some specified function $f$, using a series of noisy broadcasts. At each step a designated processor broadcasts one bit to all of the other processors, and the bit received by each processor is flipped with fixed probability (independently for each recipient). In 1988, Gallager [IEEE Trans. Inform. Theory, 34 (1988), pp. 176-180] gave a noise-resistant protocol that allows $P_0$ to learn the entire input with constant probability in $O(nloglog n)$ broadcasts. We prove that Gallager's protocol is optimal, up to a constant factor. Our lower bound follows by reduction from a lower bound for generalized noisy decision trees, a new model which may be of independent interest. For this new model we show a lower bound of $Omega(n log n)$ on the depth of a tree that learns the entire input. While the above lower bound is for an $n$-bit function, we also show an $Omega(nloglog n)$ lower bound for the number of broadcasts required to compute certain explicit boolean-valued functions, when the correct output must be attained with probability at least $1-n^{-alpha}$ for a constant parameter $alpha&gt;0$ (this bound applies to all threshold functions as well as any other boolean-valued function with linear sensitivity). This bound also follows by reduction from a lower bound of $Omega(nlog n)$ on the depth of generalized noisy decision trees that compute the same functions with the same error. We also show a (nontrivial) $Omega(n)$ lower bound on the depth of generalized noisy decision trees that compute such functions with small constant error. Finally, we show the first protocol in the noisy broadcast model that computes the Hamming weight of the input using a linear number of broadcasts.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1806–1841},
numpages = {36},
keywords = {distributed computation, computation in presence of noise}
}

@article{10.1137/060652385,
author = {Haxell, P. E. and Nagle, B. and R\"{o}dl, V.},
title = {An Algorithmic Version of the Hypergraph Regularity Method},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060652385},
doi = {10.1137/060652385},
abstract = {Extending the Szemer\'{e}di regularity lemma for graphs, P. Frankl and V. R\"{o}dl [Random Structures Algorithms, 20 (2002), pp. 131-164] established a 3-graph regularity lemma triple systems ${cal G}_n$ admit bounded partitions of their edge sets, most classes of which consist of regularly distributed triples. Many applications of this lemma require a companion counting lemma [B. Nagle and V. R\"{o}dl, Random Structures Algorithms, 23 (2003), pp. 264-332] allowing one to find and enumerate subhypergraphs of a given isomorphism type in a “dense and regular” environment created by the 3-graph regularity lemma. Combined applications of these lemmas are known as the 3-graph regularity method. In this paper, we provide an algorithmic version of the 3-graph regularity lemma which, as we show, is compatible with a counting lemma. We also discuss some applications.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1728–1776},
numpages = {49},
keywords = {algorithmic regularity lemma for hypergraphs, counting lemma for hypergraphs}
}

@article{10.1137/060651380,
author = {Dodis, Yevgeniy and Ostrovsky, Rafail and Reyzin, Leonid and Smith, Adam},
title = {Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/060651380},
doi = {10.1137/060651380},
abstract = {We provide formal definitions and efficient secure techniques for turning noisy information into keys usable for any cryptographic application, and, in particular, reliably and securely authenticating biometric data. Our techniques apply not just to biometric information, but to any keying material that, unlike traditional cryptographic keys, is (1) not reproducible precisely and (2) not distributed uniformly. We propose two primitives: a fuzzy extractor reliably extracts nearly uniform randomness $R$ from its input; the extraction is error-tolerant in the sense that $R$ will be the same even if the input changes, as long as it remains reasonably close to the original. Thus, $R$ can be used as a key in a cryptographic application. A secure sketch produces public information about its input $w$ that does not reveal $w$ and yet allows exact recovery of $w$ given another value that is close to $w$. Thus, it can be used to reliably reproduce error-prone biometric inputs without incurring the security risk inherent in storing them. We define the primitives to be both formally secure and versatile, generalizing much prior work. In addition, we provide nearly optimal constructions of both primitives for various measures of “closeness” of input data, such as Hamming distance, edit distance, and set difference.},
journal = {SIAM J. Comput.},
month = mar,
pages = {97–139},
numpages = {43},
keywords = {biometric authentication, randomness extractors, fuzzy extractors, metric embeddings, password-based systems, error-tolerance, error-correcting codes, fuzzy fingerprints, nonuniformity}
}

@article{10.1137/060651343,
author = {Damg\r{A}rd, Ivan B. and Fehr, Serge and Salvail, Louis and Schaffner, Christian},
title = {Cryptography in the Bounded-Quantum-Storage Model},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060651343},
doi = {10.1137/060651343},
abstract = {We initiate the study of two-party cryptographic primitives with unconditional security, assuming that the adversary's quantum memory is of bounded size. We show that oblivious transfer and bit commitment can be implemented in this model using protocols where honest parties need no quantum memory, whereas an adversarial player needs quantum memory of size at least $n/2$ in order to break the protocol, where $n$ is the number of qubits transmitted. This is in sharp contrast to the classical bounded-memory model, where we can only tolerate adversaries with memory of size quadratic in honest players' memory size. Our protocols are efficient and noninteractive and can be implemented using today's technology. On the technical side, a new entropic uncertainty relation involving min-entropy is established.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1865–1890},
numpages = {26},
keywords = {quantum uncertainty relation, oblivious transfer, bit commitment, quantum-bounded-storage model, quantum cryptography}
}

@article{10.1137/060649562,
author = {Klein, Philip N.},
title = {A Linear-Time Approximation Scheme for TSP in Undirected Planar Graphs with Edge-Weights},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060649562},
doi = {10.1137/060649562},
abstract = {We give an algorithm requiring $O(c^{1/epsilon^2}n)$ time to find an $epsilon$-optimal traveling salesman tour in the shortest-path metric defined by an undirected planar graph with nonnegative edge-lengths. For the case of all lengths equal to 1, the time required is $O(c^{1/epsilon} n)$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1926–1952},
numpages = {27},
keywords = {planar graphs, traveling salesman, approximation algorithm, algorithms, combinatorial optimization, graphs}
}

@article{10.1137/060649057,
author = {Kalai, Adam Tauman and Klivans, Adam R. and Mansour, Yishay and Servedio, Rocco A.},
title = {Agnostically Learning Halfspaces},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/060649057},
doi = {10.1137/060649057},
abstract = {We give a computationally efficient algorithm that learns (under distributional assumptions) a halfspace in the difficult agnostic framework of Kearns, Schapire, and Sellie [Mach. Learn., 17 (1994), pp. 115-141], where a learner is given access to a distribution on labelled examples but where the labelling may be arbitrary (similar to malicious noise). It constructs a hypothesis whose error rate on future examples is within an additive $epsilon$ of the optimal halfspace, in time poly$(n)$ for any constant $epsilon&gt;0$, for the uniform distribution over ${-1,1}^n$ or unit sphere in $mathbb R^n,$ as well as any log-concave distribution in $mathbb R^n$. It also agnostically learns Boolean disjunctions in time $2^{tilde{O}(sqrt{n})}$ with respect to any distribution. Our algorithm, which performs $L_1$ polynomial regression, is a natural noise-tolerant arbitrary-distribution generalization of the well-known “low-degree” Fourier algorithm of Linial, Mansour, and Nisan. We observe that significant improvements on the running time of our algorithm would yield the fastest known algorithm for learning parity with noise, a challenging open problem in computational learning theory.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1777–1805},
numpages = {29},
keywords = {agnostic learning, Fourier, halfspaces}
}

@article{10.1137/06064888X,
author = {Alon, Noga and Shapira, Asaf},
title = {A Characterization of the (Natural) Graph Properties Testable with One-Sided Error},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/06064888X},
doi = {10.1137/06064888X},
abstract = {The problem of characterizing all the testable graph properties is considered by many to be the most important open problem in the area of property testing. Our main result in this paper is a solution of an important special case of this general problem: Call a property tester oblivious if its decisions are independent of the size of the input graph. We show that a graph property ${cal P}$ has an oblivious one-sided error tester if and only if ${cal P}$ is semihereditary. We stress that any “natural” property that can be tested (either with one-sided or with two-sided error) can be tested by an oblivious tester. In particular, all the testers studied thus far in the literature were oblivious. Our main result can thus be considered as a precise characterization of the natural graph properties, which are testable with one-sided error. One of the main technical contributions of this paper is in showing that any hereditary graph property can be tested with one-sided error. This general result contains as a special case all the previous results about testing graph properties with one-sided error. More importantly, as a special case of our main result, we infer that some of the most well-studied graph properties, both in graph theory and computer science, are testable with one-sided error. Some of these properties are the well-known graph properties of being perfect, chordal, interval, comparability, permutation, and more. None of these properties was previously known to be testable.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1703–1727},
numpages = {25},
keywords = {hereditary properties, property testing, regularity lemma, one-sided error}
}

@article{10.1137/050644896,
author = {Moore, Cristopher and Russell, Alexander and Schulman, Leonard J.},
title = {The Symmetric Group Defies Strong Fourier Sampling},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/050644896},
doi = {10.1137/050644896},
abstract = {The dramatic exponential speedups of quantum algorithms over their best existing classical counterparts were ushered in by the technique of Fourier sampling, introduced by Bernstein and Vazirani and developed by Simon and Shor into an approach to the hidden subgroup problem. This approach has proved successful for abelian groups, leading to efficient algorithms for factoring, extracting discrete logarithms, and other number-theoretic problems. We show, however, that this method cannot resolve the hidden subgroup problem in the symmetric groups, even in the weakest, information-theoretic sense. In particular, we show that the Graph Isomorphism problem cannot be solved by this approach. Our work implies that any quantum approach based upon the measurement of coset states must depart from the original framework by using entangled measurements on multiple coset states.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1842–1864},
numpages = {23},
keywords = {graph isomorphism, Fourier sampling, quantum computing, hidden subgroup problem}
}

@article{10.1137/050639090,
author = {Laplante, Sophie and Magniez, Fr\'{e}d\'{e}ric},
title = {Lower Bounds for Randomized and Quantum Query Complexity Using Kolmogorov Arguments},
year = {2008},
issue_date = {March 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {38},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050639090},
doi = {10.1137/050639090},
abstract = {We prove a very general lower bound technique for quantum and randomized query complexity that is easy to prove as well as to apply. To achieve this, we introduce the use of Kolmogorov complexity to query complexity. Our technique generalizes the weighted and unweighted methods of Ambainis and the spectral method of Barnum, Saks, and Szegedy. As an immediate consequence of our main theorem, it can be shown that adversary methods can only prove lower bounds for Boolean functions $f$ in $O(min(sqrt{n C_0(f)},sqrt{n C_1(f)}))$, where $C_0, C_1$ is the certificate complexity and $n$ is the size of the input.},
journal = {SIAM J. Comput.},
month = mar,
pages = {46–62},
numpages = {17},
keywords = {quantum computing, Kolmogorov complexity, lower bounds, query complexity, adversary method}
}

@article{10.1137/070698774,
author = {Goldberg, Andrew V.},
title = {A Practical Shortest Path Algorithm with Linear Expected Time},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070698774},
doi = {10.1137/070698774},
abstract = {We present an improvement of the multilevel bucket shortest path algorithm of Denardo and Fox [Oper. Res., 27 (1979), pp. 161-186] and justify this improvement both theoretically and experimentally. We prove that if the input arc lengths come from a natural probability distribution, the new algorithm runs in linear average time while the original algorithm does not. We also describe an implementation of the new algorithm. Our experimental data suggests that the new algorithm is preferable to the original one in practice. Furthermore, for integral arc lengths that fit into a word of today's computers, the performance is close to that of breadth-first search, suggesting limitations on further practical improvements.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1637–1655},
numpages = {19},
keywords = {data structures, experimental evaluation, algorithms, shortest paths}
}

@article{10.1137/070682575,
author = {Valiant, Leslie G.},
title = {Holographic Algorithms},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/070682575},
doi = {10.1137/070682575},
abstract = {Complexity theory is built fundamentally on the notion of efficient reduction among computational problems. Classical reductions involve gadgets that map solution fragments of one problem to solution fragments of another in one-to-one, or possibly one-to-many, fashion. In this paper we propose a new kind of reduction that allows for gadgets with many-to-many correspondences, in which the individual correspondences among the solution fragments can no longer be identified. Their objective may be viewed as that of generating interference patterns among these solution fragments so as to conserve their sum. We show that such holographic reductions provide a method of translating a combinatorial problem to finite systems of polynomial equations with integer coefficients such that the number of solutions of the combinatorial problem can be counted in polynomial time if one of the systems has a solution over the complex numbers. We derive polynomial time algorithms in this way for a number of problems for which only exponential time algorithms were known before. General questions about complexity classes can also be formulated. If the method is applied to a P-complete problem, then polynomial systems can be obtained, the solvability of which would imply P$^{{tiny{#P}}}$ = NC2.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1565–1594},
numpages = {30},
keywords = {computational complexity, enumeration}
}

@article{10.1137/060673886,
author = {Gla\ss{}er, Christian and Pavan, A. and Selman, Alan L. and Zhang, Liyu},
title = {Splitting NP-Complete Sets},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060673886},
doi = {10.1137/060673886},
abstract = {We show that a set is m-autoreducible if and only if it is m-mitotic. This solves a long-standing open question in a surprising way. As a consequence of this unconditional result and recent work by Gla\ss{}er et al., complete sets for all of the following complexity classes are m-mitotic: $mathrm{NP}$, $mathrm{coNP}$, $oplusmathrm{P}$, $mathrm{PSPACE}$, and $mathrm{NEXP}$, as well as all levels of $mathrm{PH}$, $mathrm{MODPH}$, and the Boolean hierarchy over $mathrm{NP}$. In the cases of $mathrm{NP}$, $mathrm{PSPACE}$, $mathrm{NEXP}$, and $mathrm{PH}$, this at once answers several well-studied open questions. These results tell us that complete sets share a redundancy that was not known before. In particular, every $mathrm{NP}$-complete set $A$ splits into two $mathrm{NP}$-complete sets $A_1$ and $A_2$. We disprove the equivalence between autoreducibility and mitoticity for all polynomial-time-bounded reducibilities between 3-tt-reducibility and Turing-reducibility: There exists a sparse set in $mathrm{EXP}$ that is polynomial-time 3-tt-autoreducible, but not weakly polynomial-time T-mitotic. In particular, polynomial-time T-autoreducibility does not imply polynomial-time weak T-mitoticity, which solves an open question by Buhrman and Torenvliet.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1517–1535},
numpages = {19},
keywords = {mitoticity, computational and structural complexity, autoreducibility, NP-complete sets}
}

@article{10.1137/060670705,
author = {Feldman, Jon and O'Donnell, Ryan and Servedio, Rocco A.},
title = {Learning Mixtures of Product Distributions over Discrete Domains},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060670705},
doi = {10.1137/060670705},
abstract = {We consider the problem of learning mixtures of product distributions over discrete domains in the distribution learning framework introduced by Kearns et al. [Proceedings of the $26$th Annual Symposium on Theory of Computing (STOC), Montr\'{e}al, QC, 1994, ACM, New York, pp. 273-282]. We give a $operatorname{poly}(n/epsilon)$-time algorithm for learning a mixture of $k$ arbitrary product distributions over the $n$-dimensional Boolean cube ${0,1}^n$ to accuracy $epsilon$, for any constant $k$. Previous polynomial-time algorithms could achieve this only for $k = 2$ product distributions; our result answers an open question stated independently in [M. Cryan, Learning and Approximation Algorithms for Problems Motivated by Evolutionary Trees, Ph.D. thesis, University of Warwick, Warwick, UK, 1999] and [Y. Freund and Y. Mansour, Proceedings of the $12$th Annual Conference on Computational Learning Theory, 1999, pp. 183-192]. We further give evidence that no polynomial-time algorithm can succeed when $k$ is superconstant, by reduction from a difficult open problem in PAC (probably approximately correct) learning. Finally, we generalize our $operatorname{poly}(n/epsilon)$-time algorithm to learn any mixture of $k = O(1)$ product distributions over ${0,1, dots, b-1}^n$, for any $b = O(1)$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1536–1564},
numpages = {29},
keywords = {product distributions, computational learning theory, mixture distributions, PAC learning}
}

@article{10.1137/060668572,
author = {Chen, Hubie},
title = {The Complexity of Quantified Constraint Satisfaction: Collapsibility, Sink Algebras, and the Three-Element Case},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060668572},
doi = {10.1137/060668572},
abstract = {The constraint satisfaction probem (CSP) is a well-acknowledged framework in which many combinatorial search problems can be naturally formulated. The CSP may be viewed as the problem of deciding the truth of a logical sentence consisting of a conjunction of constraints, in front of which all variables are existentially quantified. The quantified constraint satisfaction problem (QCSP) is the generalization of the CSP where universal quantification is permitted in addition to existential quantification. The general intractability of these problems has motivated research studying the complexity of these problems under a restricted constraint language, which is a set of relations that can be used to express constraints. This paper introduces collapsibility, a technique for deriving positive complexity results on the QCSP. In particular, this technique allows one to show that, for a particular constraint language, the QCSP reduces to the CSP. We show that collapsibility applies to three known tractable cases of the QCSP that were originally studied using disparate proof techniques in different decades: Quantified 2-SAT (Aspvall, Plass, and Tarjan in 1979), Quantified Horn-SAT (Karpinski, Kleine B\"{u}ning, and Schmitt in 1987), and Quantified Affine-SAT (Creignou, Khanna, and Sudan in 2001). This reconciles and reveals common structure among these cases, which are describable by constraint languages over a two-element domain. In addition to unifying these known tractable cases, we study constraint languages over domains of larger size.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1674–1701},
numpages = {28},
keywords = {quantified satisfiability, computational complexity, constraint satisfaction, universal algebra}
}

@article{10.1137/060653445,
author = {Chan, Ho-Leung and Lam, Tak-Wah and Liu, Kin-Shing},
title = {Extra Unit-Speed Machines Are Almost as Powerful as Speedy Machines for Flow Time Scheduling},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060653445},
doi = {10.1137/060653445},
abstract = {We study online scheduling of jobs to minimize the flow time and stretch on parallel machines. We consider algorithms that are given extra resources so as to compensate for the lack of future information. Recent results show that a modest increase in machine speed can provide very competitive performance; in particular, using $O(1)$ times faster machines, the algorithm SRPT (shortest remaining processing time) is 1-competitive for both flow time [C. A. Phillips et al., in Proceedings of STOC, ACM, New York, 1997, pp. 140-149] and stretch [W. T. Chan et al., in Proceedings of MFCS, Springer-Verlag, Berlin, 2005, pp. 236-247] and HDF (highest density first) is $O(1)$-competitive for weighted flow time [L. Becchetti et al., in Proceedings of RANDOM-APPROX, Springer-Verlag, Berlin, 2001, pp. 36-47]. Using extra unit-speed machines instead of faster machines to achieve competitive performance is more challenging, as a faster machine can speed up a job but extra unit-speed machines cannot. This paper gives a nontrivial relationship between the extra-speed and extra-machine analyses. It shows that competitive results via faster machines can be transformed to similar results via extra machines, hence giving the first algorithms that, using $O(1)$ times unit-speed machines, are 1-competitive for flow time and stretch and $O(1)$-competitive for weighted flow time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1595–1612},
numpages = {18},
keywords = {flow time, extra-resource augmentation, stretch, competitive analysis, online scheduling}
}

@article{10.1137/050648250,
author = {Attiya, Hagit and Hay, David},
title = {Randomization Does Not Reduce the Average Delay in Parallel Packet Switches},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050648250},
doi = {10.1137/050648250},
abstract = {Switching cells in parallel is a common approach to building switches with very high external line rates and a large number of ports. A prime example is the parallel packet switch (PPS) in which a demultiplexing algorithm sends cells, arriving at rate $R$ on $N$ input-ports, through one of $K$ intermediate slower switches, operating at rate $r<R$. In order to utilize the parallelism of the PPS, a key issue is to balance the load among the planes; since randomization is known as a successful paradigm to solve load balancing problems, it is tempting to design randomized demultiplexing algorithms that balance the load on the average. This paper presents lower bounds on the average queuing delay introduced by the PPS relative to an optimal work-conserving first-come first-serve (FCFS) switch for randomized demultiplexing algorithms that do not have full and immediate information about the switch status. These lower bounds are shown to be asymptotically optimal through a methodology for analyzing the maximal relative queuing delay by measuring the imbalance between the middle stage switches; clearly, this also bounds (from above) the average relative queuing delay. The methodology is used to devise new algorithms that rely on slightly outdated global information on the switch status. It is also used to provide, for the first time, a complete proof of the maximum relative queuing delay provided by the fractional traffic dispatch algorithm [S. Iyer and N. McKeown, in Proceedings of IEEE INFOCOM, IEEE Communications Society, New York, NY, 2001, pp. 1680-1687; D. Khotimsky and S. Krishnan, in Proceedings of the IEEE International Conference on Communications, IEEE Communications Society, New York, NY, 2001, pp. 100-106]. These optimal algorithms are deterministic, proving that randomization does not reduce the relative queuing delay of the PPS.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1613–1636},
numpages = {23},
keywords = {inverse multiplexing, queuing delay, load balancing, randomization, packet switching, Clos networks}
}

@article{10.1137/050639272,
author = {Anshelevich, Elliot and Kempe, David and Kleinberg, Jon},
title = {Stability of Load Balancing Algorithms in Dynamic Adversarial Systems},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050639272},
doi = {10.1137/050639272},
abstract = {In the dynamic load balancing problem, we seek to keep the job load roughly evenly distributed among the processors of a given network. The arrival and departure of jobs is modeled by an adversary restricted in its power. Muthukrishnan and Rajaraman [An adversarial model for distributed dynamic load balancing, in Proceedings of the 10th ACM Symposium on Parallel Algorithms and Architectures, ACM, New York, 1998] gave a clean characterization of a restriction on the adversary that can be considered the natural analogue of a cut condition. They proved that a simple local balancing algorithm proposed by Aiello et al. [Approximate load balancing on dynamic and asynchronous networks, in Proceedings of the 25th ACM Symposium on Theory of Computing, ACM, New York, 1993] is stable against such an adversary if the insertion rate is restricted to a $(1-varepsilon)$ fraction of the cut size. They left as an open question whether the algorithm is stable at rate 1. In this paper, we resolve this question positively, by proving stability of the local algorithm at rate 1. Our proof techniques are very different from the ones used by Muthukrishnan and Rajaraman and yield a simpler proof and tighter bounds on the difference in loads. In addition, we introduce a multicommodity version of this load balancing model and show how to extend the result to the case of balancing two different kinds of loads at once (obtaining as a corollary a new proof of the 2-commodity Max-Flow Min-Cut Theorem). We also show how to apply the proof techniques to the problem of routing packets in adversarial systems. Awerbuch et al. [Simple routing strategies for adversarial systems, in Proceedings of the 42nd IEEE Symposium on Foundations of Computer Science, IEEE Computer Society, Los Alamitos, CA, 2001] showed that the same load balancing algorithm is stable against an adversary, inserting packets at rate 1 with a single destination in dynamically changing networks. Our techniques give a much simpler proof for a different model of adversarially changing networks.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1656–1673},
numpages = {18},
keywords = {adversarial load balancing, multicommodity flow, packet routing}
}

@article{10.1137/S0097539705429847,
author = {Demetrescu, Camil and Thorup, Mikkel and Chowdhury, Rezaul Alam and Ramachandran, Vijaya},
title = {Oracles for Distances Avoiding a Failed Node or Link},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705429847},
doi = {10.1137/S0097539705429847},
abstract = {We consider the problem of preprocessing an edge-weighted directed graph $G$ to answer queries that ask for the length and first hop of a shortest path from any given vertex $x$ to any given vertex $y$ avoiding any given vertex or edge. As a natural application, this problem models routing in networks subject to node or link failures. We describe a deterministic oracle with constant query time for this problem that uses $O(n^2log n)$ space, where $n$ is the number of vertices in $G$. The construction time for our oracle is $O(mn^{2} + n^{3}log n)$. However, if one is willing to settle for $Theta (n^{2.5})$ space, we can improve the preprocessing time to $O(mn^{1.5}+n^{2.5}log n)$ while maintaining the constant query time. Our algorithms can find the shortest path avoiding a failed node or link in time proportional to the length of the path.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1299–1318},
numpages = {20},
keywords = {graph algorithms, shortest paths, data structures, network failures}
}

@article{10.1137/S0097539704442416,
author = {Buhrman, Harry and Fortnow, Lance and Newman, Ilan and R\"{o}hrig, Hein},
title = {Quantum Property Testing},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442416},
doi = {10.1137/S0097539704442416},
abstract = {A language $L$ has a property tester if there exists a probabilistic algorithm that given an input $x$ queries only a small number of bits of $x$ and distinguishes the cases as to whether $x$ is in $L$ and $x$ has large Hamming distance from all $y$ in $L$. We define a similar notion of quantum property testing and show that there exist languages with good quantum property testers but no good classical testers. We also show there exist languages which require a large number of queries even for quantumly testing.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1387–1400},
numpages = {14},
keywords = {property testing, quantum computing}
}

@article{10.1137/07068151X,
author = {Archer, Aaron and Levin, Asaf and Williamson, David P.},
title = {A Faster, Better Approximation Algorithm for the Minimum Latency Problem},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/07068151X},
doi = {10.1137/07068151X},
abstract = {We give a 7.18-approximation algorithm for the minimum latency problem that uses only $O(n log n)$ calls to the prize-collecting Steiner tree (PCST) subroutine of Goemans and Williamson. This improves the previous best algorithms in both performance guarantee and running time. A previous algorithm of Goemans and Kleinberg for the minimum latency problem requires an approximation algorithm for the $k$-minimum spanning tree ($k$-MST) problem which is called as a black box for each value of $k$. Their algorithm can achieve an approximation factor of 10.77 while making $O(n (n+log C) log n)$ PCST calls, a factor of 8.98 using $O(n^3(n+log C) log n)$ PCST calls, or a factor of $7.18+epsilon$ using $n^{O(1/epsilon)}log C$ PCST calls, via the $k$-MST algorithms of Garg, Arya and Ramesh, and Arora and Karakostas, respectively. Here $n$ denotes the number of nodes in the instance, and $C$ is the largest edge cost in the input. In all cases, the running time is dominated by the PCST calls. Since the PCST subroutine can be implemented to run in $O(n^2)$ time, the overall running time of our algorithm is $O(n^3 log n)$. We also give a faster randomized version of our algorithm that achieves the same approximation guarantee in expectation, but uses only $O(log^2 n)$ PCST calls, and derandomize it to obtain a deterministic algorithm with factor $7.18+epsilon$, using $O(frac{1}{epsilon} log^2 n)$ PCST calls. The basic idea for our improvement is that we do not treat the $k$-MST algorithm as a black box. This allows us to take advantage of some special situations in which the PCST subroutine delivers a 2-approximate $k$-MST. We are able to obtain the same approximation ratio that would be given by Goemans and Kleinberg if we had access to 2-approximate $k$-MSTs for all values of $k$, even though we have them only for some values of $k$ that we are not able to specify in advance. We also extend our algorithm to a weighted version of the minimum latency problem.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1472–1498},
numpages = {27},
keywords = {traveling repairman, minimum latency problem, approximation algorithm, Lagrangian relaxation, prize-collecting Steiner tree}
}

@article{10.1137/060676155,
author = {Rubin, K. and Silverberg, A.},
title = {Compression in Finite Fields and Torus-Based Cryptography},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060676155},
doi = {10.1137/060676155},
abstract = {We present efficient compression algorithms for subgroups of multiplicative groups of finite fields, we use our compression algorithms to construct efficient public key cryptosystems called $T_2$ and CEILIDH, we disprove some conjectures, and we use the theory of algebraic tori to give a better understanding of our cryptosystems, the Lucas-based, XTR, and Gong-Harn cryptosystems, and conjectured generalizations.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1401–1428},
numpages = {28},
keywords = {torus-based cryptography, CEILIDH, multiplicative groups, compression}
}

@article{10.1137/060666998,
author = {Dekel, Ofer and Shalev-Shwartz, Shai and Singer, Yoram},
title = {The Forgetron: A Kernel-Based Perceptron on a Budget},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060666998},
doi = {10.1137/060666998},
abstract = {The Perceptron algorithm, despite its simplicity, often performs well in online classification tasks. The Perceptron becomes especially effective when it is used in conjunction with kernel functions. However, a common difficulty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly as the algorithm progresses. Moreover, the running time of each online round grows linearly with the amount of memory used to store the hypothesis. In this paper, we present the Forgetron family of kernel-based online classification algorithms, which overcome this problem by restricting themselves to a predefined memory budget. We obtain different members of this family by modifying the kernel-based Perceptron in various ways. We also prove a unified mistake bound for all of the Forgetron algorithms. To our knowledge, this is the first online kernel-based learning paradigm which, on one hand, maintains a strict limit on the amount of memory it uses and, on the other hand, entertains a relative mistake bound. We conclude with experiments using real datasets, which underscore the merits of our approach.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1342–1372},
numpages = {31},
keywords = {learning theory, online classification, kernel methods, the Perceptron algorithm}
}

@article{10.1137/060653780,
author = {Nickerson, Bradford G. and Shi, Qingxiu},
title = {On $k$-d Range Search with Patricia Tries},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060653780},
doi = {10.1137/060653780},
abstract = {Patricia tries are explored for indexing combined text and spatial data. A combined text and spatial data range search algorithm is presented for reporting all data from a set of size $n$ intersecting a query hyperrectangle. We also use Patricia tries to answer $epsilon$-approximate orthogonal range search on a set of $n$ random points and hyperrectangles in $k$-dimensional data space. $epsilon$-approximate orthogonal range counting queries can be answered in $O(k {rm log} n epsilon^{k-1})$ time, and the number of nodes visited for orthogonal range counting queries is shown to be $O({rm log} n + k(1+2n^{1/k}Delta)^{k-1})$ for cubical range of side length $Delta$. Patricia tries are evaluated experimentally for both orthogonal range search and $epsilon$-approximate orthogonal range search (for $2 leq k leq 14$ and $n$ up to 1,000,000) using uniformly distributed random data. The expected range search time is determined theoretically and found to agree with experimental results.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1373–1386},
numpages = {14},
keywords = {Patricia trie, orthogonal range search, approximate range search}
}

@article{10.1137/060650271,
author = {Roditty, Liam and Zwick, Uri},
title = {Improved Dynamic Reachability Algorithms for Directed Graphs},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/060650271},
doi = {10.1137/060650271},
abstract = {We obtain several new dynamic algorithms for maintaining the transitive closure of a directed graph and several other algorithms for answering reachability queries without explicitly maintaining a transitive closure matrix. Among our algorithms are: (i) A decremental algorithm for maintaining the transitive closure of a directed graph, through an arbitrary sequence of edge deletions, in $O(mn)$ total expected time, essentially the time needed for computing the transitive closure of the initial graph. Such a result was previously known only for acyclic graphs. (ii) Two fully dynamic algorithms for answering reachability queries. The first is deterministic and has an amortized insert/delete time of $O(msqrt{n})$, and worst-case query time of $O(sqrt{n})$. The second is randomized and has an amortized insert/delete time of $O(m^{0.58}n)$ and worst-case query time of $O(m^{0.43})$. This significantly improves the query times of algorithms with similar update times. (iii) A fully dynamic algorithm for maintaining the transitive closure of an acyclic graph. The algorithm is deterministic and has a worst-case insert time of $O(m)$, constant amortized delete time of $O(1)$, and a worst-case query time of $O(n/log n)$. Our algorithms are obtained by combining several new ideas, one of which is a simple sampling idea used for detecting decompositions of strongly connected components, with techniques of Even and Shiloach [J. ACM, 28 (1981), pp. 1-4], Italiano [Inform. Process. Lett., 28 (1988), pp. 5-11], Henzinger and King [Proceedings of the $36$th Annual Symposium on Foundations of Computer Science, Milwaukee, WI, 1995, pp. 664-672], and Frigioni et al. [ACM J. Exp. Algorithmics, 6 (2001), (electronic)].},
journal = {SIAM J. Comput.},
month = jan,
pages = {1455–1471},
numpages = {17},
keywords = {transitive closure, strongly connected components, dynamic algorithms}
}

@article{10.1137/050646408,
author = {K\"{o}nemann, Jochen and Leonardi, Stefano and Sch\"{a}fer, Guido and van Zwam, Stefan H. M.},
title = {A Group-Strategyproof Cost Sharing Mechanism for the Steiner Forest Game},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050646408},
doi = {10.1137/050646408},
abstract = {We consider a game-theoretical variant of the Steiner forest problem in which each player $j$, out of a set of $k$ players, strives to connect his terminal pair $(s_j, t_j)$ of vertices in an undirected, edge-weighted graph $G$. In this paper we show that a natural adaptation of the primal-dual Steiner forest algorithm of Agrawal, Klein, and Ravi [SIAM J. Comput., 24 (1995), pp. 445-456] yields a $2$-budget balanced and cross-monotonic cost sharing method for this game. We also present a negative result, arguing that no cross-monotonic cost sharing method can achieve a budget balance factor of less than $2$ for the Steiner tree game. This shows that our result is tight. Our algorithm gives rise to a new linear programming relaxation for the Steiner forest problem which we term the lifted-cut relaxation. We show that this new relaxation is stronger than the standard undirected cut relaxation for the Steiner forest problem.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1319–1341},
numpages = {23},
keywords = {mechanism design, group-strategyproofness, approximation algorithms, Steiner forests, primal-dual algorithms}
}

@article{10.1137/050644033,
author = {Bez\'{a}kov\'{a}, Ivona and \v{S}tefankovi\v{c}, Daniel and Vazirani, Vijay V. and Vigoda, Eric},
title = {Accelerating Simulated Annealing for the Permanent and Combinatorial Counting Problems},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050644033},
doi = {10.1137/050644033},
abstract = {We present an improved “cooling schedule” for simulated annealing algorithms for combinatorial counting problems. Under our new schedule the rate of cooling accelerates as the temperature decreases. Thus, fewer intermediate temperatures are needed as the simulated annealing algorithm moves from the high temperature (easy region) to the low temperature (difficult region). We present applications of our technique to colorings and the permanent (perfect matchings of bipartite graphs). Moreover, for the permanent, we improve the analysis of the Markov chain underlying the simulated annealing algorithm. This improved analysis, combined with the faster cooling schedule, results in an $O(n^7log^4{n})$ time algorithm for approximating the permanent of a $0/1$ matrix.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1429–1454},
numpages = {26},
keywords = {cooling schedule, approximate counting problems, Markov chain Monte Carlo, simulated annealing}
}

@article{10.1137/05063787X,
author = {Augustine, John and Irani, Sandy and Swamy, Chaitanya},
title = {Optimal Power-Down Strategies},
year = {2008},
issue_date = {January 2008},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/05063787X},
doi = {10.1137/05063787X},
abstract = {We consider the problem of selecting threshold times to transition a device to low-power sleep states during an idle period. The two-state case, in which there is a single active and a single sleep state, is a continuous version of the ski-rental problem. We consider a generalized version in which there is more than one sleep state, each with its own power-consumption rate and transition costs. We give an algorithm that, given a system, produces a deterministic strategy whose competitive ratio is arbitrarily close to optimal. We also give an algorithm to produce the optimal online strategy given a system and a probability distribution that generates the length of the idle period. We also give a simple algorithm that achieves a competitive ratio of $3 + 2sqrt{2} approx 5.828$ for any system.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1499–1516},
numpages = {18},
keywords = {power-aware computation, online algorithms, dynamic power management}
}

@article{10.1137/S009753970444661X,
author = {Awerbuch, Baruch and Hajiaghayi, Mohammad T. and Kleinberg, Robert and Leighton, Tom},
title = {Localized Client-Server Load Balancing without Global Information},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444661X},
doi = {10.1137/S009753970444661X},
abstract = {We consider distributed algorithms for maximizing throughput in a network of clients and servers, modeled as a bipartite graph. We seek algorithms and lower bounds for decentralized algorithms in which each participant has only local knowledge about the state of itself and its neighbors. Our problem is analogous to recent work on oblivious routing [M. Bienkowski, M. Korzeniowski, and H. R\"{a}cke, Proceedings of the $15$th Annual ACM Symposium on Parallel Algorithms and Architectures, 2003, pp. 24-33, C. Harrelson, K. Hildrum, and S. Rao, Proceedings of the $15$th Annual ACM Symposium on Parallel Algorithms and Architectures, 2003, pp. 34-43, H. R\"{a}cke, Proceedings of the $43$rd Annual IEEE Symposium on Foundations of Computer Science, 2002, pp. 43-52] but with the objective of maximizing throughput rather than minimizing congestion. In contrast to that work, we prove a strong lower bound (polynomial in $n$, the size of the graph) on the competitive ratio of any oblivious algorithm. This is accompanied by simple algorithms achieving upper bounds which are tight in terms of $OPT$, the maximum throughput achievable by an omniscient algorithm, and are also tight in terms of $m$, the number of servers. Finally, we investigate an online version of the problem, in a restricted model which requires that clients, upon becoming active, must remain so for at least $log(n)$ time steps. In contrast to our primarily negative results in the oblivious case, here we present an algorithm which is constant-competitive. Our lower bounds justify the intuition, implicit in earlier work on the subject [B. Awerbuch and Y. Azar, Proceedings of the $35$th Annual IEEE Symposium on Foundations of Computer Science, 1994, pp. 240-249], that some such restriction (i.e., requiring some stability in the demand pattern over time) is necessary in order to achieve a constant—or even polylogarithmic—competitive ratio.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1259–1279},
numpages = {21},
keywords = {distributed algorithms, maximum matching, oblivious routing, multicommodity flow}
}

@article{10.1137/06065043X,
author = {Chang, Guey-Yun and Chen, Gen-Huey},
title = {($t$,$k$)-Diagnosability of Multiprocessor Systems with Applications to Grids and Tori},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/06065043X},
doi = {10.1137/06065043X},
abstract = {($t$, $k$)-diagnosis, which is a generalization of sequential diagnosis, requires at least $k$ faulty processors identified and replaced (or repaired) in each iteration provided there are at most $t$ faulty processors, where $t ge k$. This paper suggests lower bounds on the degrees of $(t,k)$-diagnosability of multiprocessor systems under both the PMC and the MM* models. As a consequence, grids and tori of $d$ dimensions are shown to be $(Omega(N^frac{d}{d+1})$, $Omega(d))$-diagnosable and $(Omega(N^frac{d}{d+1})$, $Omega(2d))$-diagnosable, respectively, where $N$ is the number of processors.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1280–1298},
numpages = {19},
keywords = {$(t, diagnosability, multiprocessor system, diagnosis, MM* model, sequential diagnosis, k)$-diagnosis, PMC model}
}

@article{10.1137/S0097539704446335,
author = {Davidovitch, Lior and Dolev, Shlomi and Rajsbaum, Sergio},
title = {Stability of Multivalued Continuous Consensus},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446335},
doi = {10.1137/S0097539704446335},
abstract = {Multivalued consensus functions defined from a vector of inputs over the set $V$ of possible input values (and possibly from the previous input and output values) to a single output are investigated. The consensus functions are designed to tolerate $t$ faulty inputs. Two classes of multivalued consensus functions are defined, the exact value and the range value, which require the output to be one of the nonfaulty inputs or in the range of the nonfaulty inputs, respectively. The instability of consensus functions is examined, counting the maximal number of output changes along a geodesic path of input changes, a path in which each input is changed at most once. Lower and upper bounds for the instability of multivalued consensus functions as a function of $n$, the number of sensors, $t$, and $|V|$ are presented. A new technique for obtaining such lower bounds, using edgewise simplex subdivision, is presented.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1057–1076},
numpages = {20},
keywords = {stability, consensus}
}

@article{10.1137/070687153,
author = {Chen, Yijia and Grohe, Martin},
title = {An Isomorphism Between Subexponential and Parameterized Complexity Theory},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/070687153},
doi = {10.1137/070687153},
abstract = {We establish a close connection between (sub)exponential time complexity and parameterized complexity by proving that the so-called miniaturization mapping is a reduction preserving isomorphism between the two theories.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1228–1258},
numpages = {31},
keywords = {exponential time hypothesis, exponential time complexity, subexponential time, parameterized complexity}
}

@article{10.1137/06067095X,
author = {Asano, Tetsuo and Matou\v{s}ek, Ji\v{r}\'{I} and Tokuyama, Takeshi},
title = {Zone Diagrams: Existence, Uniqueness, and Algorithmic Challenge},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/06067095X},
doi = {10.1137/06067095X},
abstract = {A zone diagram is a new variation of the classical notion of the Voronoi diagram. Given points (sites) ${mathbf p}_1,ldots,{mathbf p}_n$ in the plane, each ${mathbf p}_i$ is assigned a region $R_i$, but in contrast to the ordinary Voronoi diagrams, the union of the $R_i$ has a nonempty complement, the neutral zone. The defining property is that each $R_i$ consists of all ${mathbf x}in{mathbb{R}}^2$ that lie closer (nonstrictly) to ${mathbf p}_i$ than to the union of all the other $R_j$, $jne i$. Thus, the zone diagram is defined implicitly, by a “fixed-point property,” and neither its existence nor its uniqueness seem obvious. We establish existence using a general fixed-point result (a consequence of Schauder's theorem or Kakutani's theorem); this proof should generalize easily to related settings, say higher dimensions. Then we prove uniqueness of the zone diagram, as well as convergence of a natural iterative algorithm for computing it, by a geometric argument, which also relies on a result for the case of two sites in an earlier paper. Many challenging questions remain open.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1182–1198},
numpages = {17},
keywords = {distance trisector curve, Voronoi diagram, computational geometry, zone diagram}
}

@article{10.1137/060665889,
author = {Cheng, Siu-Wing and Dey, Tamal K. and Ramos, Edgar A. and Ray, Tathagata},
title = {Sampling and Meshing a Surface with Guaranteed Topology and Geometry},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060665889},
doi = {10.1137/060665889},
abstract = {This paper presents an algorithm for sampling and triangulating a generic $C^2$-smooth surface $Sigmasubset mathbb{R}^3$ that is input with an implicit equation. The output triangulation is guaranteed to be homeomorphic to $Sigma$. We also prove that the triangulation has well-shaped triangles, large dihedral angles, and a small size. The only assumption we make is that the input surface representation is amenable to certain types of computations, namely, computations of the intersection points of a line and $Sigma$, computations of the critical points in a given direction, and computations of certain silhouette points.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1199–1227},
numpages = {29},
keywords = {smooth surface, geometry, Delaunay refinement, Delaunay triangulation, topology, Voronoi diagram}
}

@article{10.1137/060660345,
author = {Berenbrink, Petra and Friedetzky, Tom and Goldberg, Leslie Ann and Goldberg, Paul W. and Hu, Zengjian and Martin, Russell},
title = {Distributed Selfish Load Balancing},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/060660345},
doi = {10.1137/060660345},
abstract = {Suppose that a set of $m$ tasks are to be shared as equally as possible among a set of $n$ resources. A game-theoretic mechanism to find a suitable allocation is to associate each task with a “selfish agent” and require each agent to select a resource, with the cost of a resource being the number of agents that select it. Agents would then be expected to migrate from overloaded to underloaded resources, until the allocation becomes balanced. Recent work has studied the question of how this can take place within a distributed setting in which agents migrate selfishly without any centralized control. In this paper we discuss a natural protocol for the agents which combines the following desirable features: It can be implemented in a strongly distributed setting, uses no central control, and has good convergence properties. For $m gg n$, the system becomes approximately balanced (an $epsilon$-Nash equilibrium) in expected time $O(log log m)$. We show using a martingale technique that the process converges to a perfectly balanced allocation in expected time $O(log log m + n^4)$. We also give a lower bound of $Omega(max{log log m, n})$ for the convergence time.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1163–1181},
numpages = {19},
keywords = {load balancing, reallocation, convergence, equilibrium}
}

@article{10.1137/050646354,
author = {Chen, Jianer and Fernau, Henning and Kanj, Iyad A. and Xia, Ge},
title = {Parametric Duality and Kernelization: Lower Bounds and Upper Bounds on Kernel Size},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/050646354},
doi = {10.1137/050646354},
abstract = {Determining whether a parameterized problem is kernelizable and has a small kernel size has recently become one of the most interesting topics of research in the area of parameterized complexity and algorithms. Theoretically, it has been proved that a parameterized problem is kernelizable if and only if it is fixed-parameter tractable. Practically, applying a data reduction algorithm to reduce an instance of a parameterized problem to an equivalent smaller instance (i.e., a kernel) has led to very efficient algorithms and now goes hand-in-hand with the design of practical algorithms for solving $mathcal{NP}$-hard problems. Well-known examples of such parameterized problems include the vertex cover problem, which is kernelizable to a kernel of size bounded by $2k$, and the planar dominating set problem, which is kernelizable to a kernel of size bounded by $335k$. In this paper we develop new techniques to derive upper and lower bounds on the kernel size for certain parameterized problems. In terms of our lower bound results, we show, for example, that unless $mathcal{P} = mathcal{NP}$, planar vertex cover does not have a problem kernel of size smaller than $4k/3$, and planar independent set and planar dominating set do not have kernels of size smaller than $2k$. In terms of our upper bound results, we further reduce the upper bound on the kernel size for the planar dominating set problem to $67 k$, improving significantly the $335 k$ previous upper bound given by Alber, Fellows, and Niedermeier [J. ACM, 51 (2004), pp. 363-384]. This latter result is obtained by introducing a new set of reduction and coloring rules, which allows the derivation of nice combinatorial properties in the kernelized graph leading to a tighter bound on the size of the kernel. The paper also shows how this improved upper bound yields a simple and competitive algorithm for the planar dominating set problem.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1077–1106},
numpages = {30},
keywords = {vertex cover, dominating set, independent set, kernel, parameterized algorithm, planar graph}
}

@article{10.1137/050645804,
author = {Halevy, Shirley and Kushilevitz, Eyal},
title = {Distribution-Free Property-Testing},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/050645804},
doi = {10.1137/050645804},
abstract = {We consider the problem of distribution-free property-testing of functions. In this setting of property-testing, the distance between functions is measured with respect to a fixed but unknown distribution $D$ on the domain. The testing algorithms are given oracle access to random sampling from the domain according to this distribution $D$. This notion of distribution-free testing was previously defined, but no distribution-free property-testing algorithm was known for any (non-trivial) property. We present the first such distribution-free property-testing algorithms for two of the central problems in this field. The testers are obtained by extending some known results (from “standard,” uniform distribution, property-testing): (1) A distribution-free testing algorithm for low-degree multivariate polynomials with query complexity $O(d^2 + d cdot epsilon^{-1})$, where $d$ is the total degree of the polynomial. The same approach that is taken for the distribution-free testing of low-degree polynomials is shown to apply also to several other problems; (2) a distribution-free monotonicity testing algorithm for functions $f:[n]^d rightarrow A$ for low dimensions (e.g., when $d$ is a constant) with query complexity similar to the one achieved in the uniform setting. On the negative side, we prove an exponential gap between the query complexity required for uniform and distribution-free monotonicity testing in the high-dimensional case.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1107–1138},
numpages = {32},
keywords = {distribution-free testing lower bounds, distribution-free property-testing, monotonicity testing, low-degree testing, property-testing}
}

@article{10.1137/050642095,
author = {Busch, Costas and Magdon-Ismail, Malik and Mavronicolas, Marios},
title = {Universal Bufferless Packet Switching},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/050642095},
doi = {10.1137/050642095},
abstract = {A packet-switching algorithm specifies the actions of the nodes in order to deliver packets in the network. A packet-switching algorithm is universal if it applies to any network topology and for any batch communication problem on the network. A long-standing open problem has concerned the existence of a universal packet-switching algorithm with near-optimal performance guarantees for the class of bufferless networks where the buffer size for packets in transit is zero. We give a positive answer to this question. In particular, we give a universal bufferless algorithm which is within a polylogarithmic factor from optimal for arbitrary batch problems: ${cal T}=Oleft({cal T}^*cdot log^3(n+N)right)$, where ${cal T}$ is the packet delivery time of our algorithm, ${cal T}^*$ is the optimal delivery time, n is the size of the network, and $N$ is the number of packets. At the heart of our result is a new deterministic technique for constructing a universal bufferless algorithm by emulating a store-and-forward algorithm on a transformation of the network. The main idea is to replace packet buffering in the transformed network with packet circulation in regions of the original network. The cost of the emulation on the packet delivery time is proportional to the buffer sizes used by the store-and-forward algorithm. We obtain the advertised result by using a store-and-forward algorithm with logarithmic sized buffers. The resulting bufferless algorithm is constructive and can be implemented in a distributed way.},
journal = {SIAM J. Comput.},
month = nov,
pages = {1139–1162},
numpages = {24},
keywords = {optimal scheduling, deterministic bufferless emulation, routing, graph decomposition}
}

@article{10.1137/06067328X,
author = {Abraham, David J. and Irving, Robert W. and Kavitha, Telikepalli and Mehlhorn, Kurt},
title = {Popular Matchings},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/06067328X},
doi = {10.1137/06067328X},
abstract = {We consider the problem of matching a set of applicants to a set of posts, where each applicant has a preference list, ranking a nonempty subset of posts in order of preference, possibly involving ties. We say that a matching $M$ is popular if there is no matching $M'$ such that the number of applicants preferring $M'$ to $M$ exceeds the number of applicants preferring $M$ to $M'$. In this paper, we give the first polynomial-time algorithms to determine if an instance admits a popular matching and to find a largest such matching, if one exists. For the special case in which every preference list is strictly ordered (i.e., contains no ties), we give an $O(n + m)$ time algorithm, where $n$ is the total number of applicants and posts and $m$ is the total length of all of the preference lists. For the general case in which preference lists may contain ties, we give an $O(sqrt{n}m)$ time algorithm.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1030–1045},
numpages = {16},
keywords = {bipartite graphs, matchings, one-sided preference lists}
}

@article{10.1137/06065773X,
author = {Woodruff, David and Yekhanin, Sergey},
title = {A Geometric Approach to Information-Theoretic Private Information Retrieval},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/06065773X},
doi = {10.1137/06065773X},
abstract = {A $t$-private private information retrieval (PIR) scheme allows a user to retrieve the $i$th bit of an $n$-bit string $x$ replicated among $k$ servers, while any coalition of up to $t$ servers learns no information about $i$. We present a new geometric approach to PIR and obtain the following: (1) A $t$-private $k$-server protocol with communication $O (frac{k^2}{t} log k n^{1/left lfloor (2k-1)/t right rfloor})$, removing the ${k}{t}$ term of previous schemes. This answers an open question of [Y. Ishai and E. Kushilevitz, in Proceedings of the $31$st ACM Symposium on Theory of Computing, 1999, pp. 79-88]. (2) A $2$-server protocol with $O(n^{1/3})$ communication, polynomial preprocessing, and online work $O(n/log^r n)$ for any constant $r$. This improves the $O(n/log^2 n)$ work of [A. Beimel, Y. Ishai, and T. Malkin, J. Cryptology, 17 (2004), pp. 125-151]. (3) Smaller communication for instance hiding [D. Beaver, J. Feigenbaum, J. Kilian, and P. Rogaway, J. Cryptology, 10 (1997), pp. 17-36; Y. Ishai and E. Kushilevitz, in Proceedings of the $31$st ACM Symposium on Theory of Computing, 1999, pp. 79-88], PIR with a polylogarithmic number of servers, and robust PIR [A. Beimel and Y. Stahl, in Proceedings of the $3$rd Conference on Security in Communications Networks (SCN $2002$), Lecture Notes in Comput. Sci. 2576, Springer, Berlin, 2003, pp. 326-341].},
journal = {SIAM J. Comput.},
month = oct,
pages = {1046–1056},
numpages = {11},
keywords = {preprocessing, partial derivatives, private information retrieval}
}

@article{10.5555/1350525.1350539,
author = {Lynch, Nancy and Segala, Roberto and Vaandrager, Frits},
title = {Observing Branching Structure through Probabilistic Contexts},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
abstract = {Probabilistic automata (PAs) constitute a general framework for modeling and analyzing discrete event systems that exhibit both nondeterministic and probabilistic behavior, such as distributed algorithms and network protocols. The behavior of PAs is commonly defined using schedulers (also called adversaries or strategies), which resolve all nondeterministic choices based on past history. From the resulting purely probabilistic structures, trace distributions can be extracted, whose intent is to capture the observable behavior of a PA. However, when PAs are composed via an (asynchronous) parallel composition operator, a global scheduler may establish strong correlations between the behavior of system components and, for example, resolve nondeterministic choices in one PA based on the outcome of probabilistic choices in the other. It is well known that, as a result of this, the (linear-time) trace distribution precongruence is not compositional for PAs. In his 1995 Ph.D. thesis, Segala has shown that the (branching-time) probabilistic simulation preorder is compositional for PAs. In this paper, we establish that the simulation preorder is, in fact, the coarsest refinement of the trace distribution preorder that is compositional. We prove our characterization result by providing (1) a context of a given PA ${cal A}$, called the tester, which may announce the state of ${cal A}$ to the outside world, and (2) a specific global scheduler, called the observer, which ensures that the state information that is announced is actually correct. Now when another PA ${cal B}$ is composed with the tester, it may generate the same external behavior as the observer only when it is able to simulate ${cal A}$ in the sense that whenever ${cal A}$ goes to some state $s$, ${cal B}$ can go to a corresponding state $u$, from which it may generate the same external behavior. Our result shows that probabilistic contexts together with global schedulers are able to exhibit the branching structure of PAs.},
journal = {SIAM J. Comput.},
month = sep,
pages = {977–1013},
numpages = {37},
keywords = {trace distributions, simulation preorder, concurrency theory, compositionality, probabilistic automata}
}

@article{10.1137/S0097539704440727,
author = {Fu, Bin and Wang, Wei},
title = {Geometric Separators and Their Applications to Protein Folding in the HP-Model},
year = {2007},
issue_date = {September 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704440727},
doi = {10.1137/S0097539704440727},
abstract = {We develop a new method for deriving a geometric separator for a set of grid points. Our separator has a linear structure, which can effectively partition a grid graph. For example, we prove that for a grid graph $G$ with a set of $n$ points $P$ in a two-dimensional grid, there is a separator with at most $1.129sqrt{n}$ points in $P$ that partitions $G$ into two disconnected grid graphs each with at most ${2nover 3}$ points. Our separator theorem for grid graphs has a significantly smaller upper bound than that was obtained for the general planar graphs in [H. N. Djidjev and S. M. Venkatesan, Acta Inform., 34 (1997), pp. 231-234]. The protein folding problem in the HP-model is to put a sequence, consisting of two characters H and P, in a $d$-dimensional grid to have maximal number of HH-contacts, where an HH-contact is a pair of non-consecutive H letters that are put at two grid points of distance 1. Our separator is then applied to develop an exact algorithm for the protein-folding problem in the HP-model, which is NP-hard both in both two and three dimensions [B. Berger and T. Leighton, J. Comput. Biol., 5 (1998), pp. 27-40; P. Crescenzi et al., J. Comput. Biol., 5 (1998), pp. 423-465]. We design a $2^{O(n^{1-{1over d}}log n)}$ time algorithm for the $d$-dimensional protein folding problem in the HP-model. In particular, our algorithm has $O(2^{6.145sqrt{n}log n})$ and $O(2^{6.913n^{2over 3}log n})$ computational time in two and three dimensions, respectively.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1014–1029},
numpages = {16},
keywords = {protein folding, algorithm, separator, time complexity}
}

@article{10.5555/1328865.1328876,
author = {Chen, Xujin and Hu, Xiaodong and Zang, Wenan},
title = {A Min-Max Theorem on Tournaments},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
abstract = {We present a structural characterization of all tournaments $T=(V,A)$ such that, for any nonnegative integral weight function defined on $V$, the maximum size of a feedback vertex set packing is equal to the minimum weight of a triangle in $T$. We also answer a question of Frank by showing that it is $NP$-complete to decide whether the vertex set of a given tournament can be partitioned into two feedback vertex sets. In addition, we give exact and approximation algorithms for the feedback vertex set packing problem on tournaments.},
journal = {SIAM J. Comput.},
month = jun,
pages = {923–937},
numpages = {15},
keywords = {min-max relation, feedback vertex set, covering, tournament, packing}
}

@article{10.5555/1328865.1328873,
author = {Beame, Paul and Pitassi, Toniann and Segerlind, Nathan},
title = {Lower Bounds for Lov\'{a}Sz-Schrijver Systems and Beyond Follow from Multiparty Communication Complexity},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
abstract = {We prove that an $omega(log^4 n)$ lower bound for the three-party number-on-the-forehead (NOF) communication complexity of the set-disjointness function implies an $n^{omega(1)}$ size lower bound for treelike Lov\'{a}sz-Schrijver systems that refute unsatisfiable formulas in conjunctive normal form (CNFs). More generally, we prove that an $n^{Omega(1)}$ lower bound for the $(k+1)$-party NOF communication complexity of set disjointness implies a $2^{n^{Omega(1)}}$ size lower bound for all treelike proof systems whose formulas are degree $k$ polynomial inequalities.},
journal = {SIAM J. Comput.},
month = jun,
pages = {845–869},
numpages = {25},
keywords = {zero-one programming, propositional proof complexity, communication complexity, lower bounds}
}

@article{10.5555/1328865.1328872,
author = {O'Donnell, Ryan and Servedio, Rocco A.},
title = {Learning Monotone Decision Trees in Polynomial Time},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
abstract = {We give an algorithm that learns any monotone Boolean function $fisafunc$ to any constant accuracy, under the uniform distribution, in time polynomial in $n$ and in the decision tree size of $f.$ This is the first algorithm that can learn arbitrary monotone Boolean functions to high accuracy, using random examples only, in time polynomial in a reasonable measure of the complexity of $f.$ A key ingredient of the result is a new bound showing that the average sensitivity of any monotone function computed by a decision tree of size $s$ must be at most $sqrt{log s}$. This bound has proved to be of independent utility in the study of decision tree complexity [O. Schramm, R. O'Donnell, M. Saks, and R. Servedio, Every decision tree has an influential variable, in Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, IEEE Computer Society, Los Alamitos, CA, 2005, pp. 31-39]. We generalize the basic inequality and learning result described above in various ways—specifically, to partition size (a stronger complexity measure than decision tree size), $p$-biased measures over the Boolean cube (rather than just the uniform distribution), and real-valued (rather than just Boolean-valued) functions.},
journal = {SIAM J. Comput.},
month = jun,
pages = {827–844},
numpages = {18},
keywords = {monotone, learning, decision trees}
}

@article{10.1137/S0097539798332464,
author = {Aiello, William and Leighton, F. T.},
title = {Hamming Codes, Hypercube Embeddings, and Fault Tolerance},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798332464},
doi = {10.1137/S0097539798332464},
abstract = {In this paper, we devise a special $1$-error-correcting code that enables us to embed the graph product of an $N/log N$-node hypercube and a $log N$-node complete graph into in an $N$-node hypercube with constant load, dilation, and congestion. We apply the result to construct improved embeddings of trees and other structures in a hypercube, and to design more efficient and robust algorithms for reconfiguring a hypercube around random or worst-case faults. The result has also been used subsequently by others to show that the $N$-node hypercube can emulate all $N$-node planar graphs with constant slowdown.},
journal = {SIAM J. Comput.},
month = jun,
pages = {783–803},
numpages = {21},
keywords = {worst-case faults, tree embedding, tree compression, random faults, reconfiguration, hypercube, graph embeddings, fault tolerance, emulation}
}

@article{10.1137/S0097539705447177,
author = {Moore, Cristopher and Rockmore, Daniel and Russell, Alexander and Schulman, Leonard J.},
title = {The Power of Strong Fourier Sampling: Quantum Algorithms for Affine Groups and Hidden Shifts},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447177},
doi = {10.1137/S0097539705447177},
abstract = {Many quantum algorithms, including Shor's celebrated factoring and discrete log algorithms, proceed by reduction to a hidden subgroup problem, in which an unknown subgroup $H$ of a group $G$ must be determined from a quantum state $psi$ over $G$ that is uniformly supported on a left coset of $H$. These hidden subgroup problems are typically solved by Fourier sampling: the quantum Fourier transform of $psi$ is computed and measured. When the underlying group is nonabelian, two important variants of the Fourier sampling paradigm have been identified: the weak standard method, where only representation names are measured, and the strong standard method, where full measurement (i.e., the row and column of the representation, in a suitably chosen basis, as well as its name) occurs. It has remained open whether the strong standard method is indeed stronger, that is, whether there are hidden subgroups that can be reconstructed via the strong method but not by the weak, or any other known, method. In this article, we settle this question in the affirmative. We show that hidden subgroups $H$ of the $q$-hedral groups, i.e., semidirect products ${mathbb Z}_q ltimes {mathbb Z}_p$, where $q mid (p-1)$, and in particular the affine groups $A_p$, can be information-theoretically reconstructed using the strong standard method. Moreover, if $|H| = p/ {rm polylog}(p)$, these subgroups can be fully reconstructed with a polynomial amount of quantum and classical computation. We compare our algorithms to two weaker methods that have been discussed in the literature—the “forgetful” abelian method, and measurement in a random basis—and show that both of these are weaker than the strong standard method. Thus, at least for some families of groups, it is crucial to use the full power of representation theory and nonabelian Fourier analysis, namely, to measure the high-dimensional representations in an adapted basis that respects the group's subgroup structure. We apply our algorithm for the hidden subgroup problem to new families of cryptographically motivated hidden shift problems, generalizing the work of van Dam, Hallgren, and Ip on shifts of multiplicative characters. Finally, we close by proving a simple closure property for the class of groups over which the hidden subgroup problem can be solved efficiently.},
journal = {SIAM J. Comput.},
month = jun,
pages = {938–958},
numpages = {21},
keywords = {Fourier analysis, quantum computation, hidden subgroup problem, group representations}
}

@article{10.1137/S0097539704446220,
author = {Dutta, Partha and Guerraoui, Rachid and Pochon, Bastian},
title = {The Time-Complexity of Local Decision in Distributed Agreement},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446220},
doi = {10.1137/S0097539704446220},
abstract = {Agreement is at the heart of distributed computing. In its simple form, it requires a set of processes to decide on a common value out of the values they propose. The time-complexity of distributed agreement problems is generally measured in terms of the number of communication rounds needed to achieve a global decision, i.e., for all nonfaulty (correct) processes to reach a decision. This paper studies the time-complexity of local decisions in agreement problems, which we define as the number of communication rounds needed for at least one correct process to decide. We explore bounds for early local decision that depend on the number $f$ of actual failures (that occur in a given run of an algorithm), out of the maximum number $t$ of failures tolerated (by the algorithm). We first consider the synchronous message-passing model where we give tight local decision bounds for three variants of agreement: consensus, uniform consensus, and (nonblocking) atomic commit. We use these results to (1) show that, for consensus, local decision bounds are not compatible with global decision bounds (roughly speaking, they cannot be reached by the same algorithm), and (2) draw the first sharp line between the time-complexity of uniform consensus and atomic commit. Then we consider the eventually synchronous model, where we give tight local decision bounds for synchronous runs of uniform consensus. (In this model, consensus and uniform consensus are similar, atomic commit is impossible, and one cannot bound the number of rounds to reach a decision in nonsynchronous runs of consensus algorithms.) We prove a counterintuitive result that the early local decision bound is the same as the early global decision bound. We also give a matching early deciding consensus algorithm that is significantly better than previous eventually synchronous consensus algorithms.},
journal = {SIAM J. Comput.},
month = jun,
pages = {722–756},
numpages = {35},
keywords = {distributed systems, lower bounds, agreement problems}
}

@article{10.1137/S0097539703446912,
author = {Athreya, Krishna B. and Hitchcock, John M. and Lutz, Jack H. and Mayordomo, Elvira},
title = {Effective Strong Dimension in Algorithmic Information and Computational Complexity},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703446912},
doi = {10.1137/S0097539703446912},
abstract = {The two most important notions of fractal dimension are Hausdorff dimension, developed by Hausdorff [Math. Ann., 79 (1919), pp. 157-179], and packing dimension, developed independently by Tricot [Math. Proc. Cambridge Philos. Soc., 91 (1982), pp. 57-74] and Sullivan [Acta Math., 153 (1984), pp. 259-277]. Both dimensions have the mathematical advantage of being defined from measures, and both have yielded extensive applications in fractal geometry and dynamical systems. Lutz [Proceedings of the 15th IEEE Conference on Computational Complexity, Florence, Italy, 2000, IEEE Computer Society Press, Piscataway, NJ, 2000, pp. 158-169] has recently proven a simple characterization of Hausdorff dimension in terms of gales, which are betting strategies that generalize martingales. Imposing various computability and complexity constraints on these gales produces a spectrum of effective versions of Hausdorff dimension, including constructive, computable, polynomial-space, polynomial-time, and finite-state dimensions. Work by several investigators has already used these effective dimensions to shed significant new light on a variety of topics in theoretical computer science. In this paper we show that packing dimension can also be characterized in terms of gales. Moreover, even though the usual definition of packing dimension is considerably more complex than that of Hausdorff dimension, our gale characterization of packing dimension is an exact dual of—and every bit as simple as—the gale characterization of Hausdorff dimension. Effectivizing our gale characterization of packing dimension produces a variety of effective strong dimensions, which are exact duals of the effective dimensions mentioned above. In general (and in analogy with the classical fractal dimensions), the effective strong dimension of a set or sequence is at least as great as its effective dimension, with equality for sets or sequences that are sufficiently regular. We develop the basic properties of effective strong dimensions and prove a number of results relating them to fundamental aspects of randomness, Kolmogorov complexity, prediction, Boolean circuit-size complexity, polynomial-time degrees, and data compression. Aside from the above characterization of packing dimension, our two main theorems are the following. 1. If $vec{beta} = (beta_0,beta_1,ldots)$ is a computable sequence of biases that are bounded away from 0 and $R$ is random with respect to $vec{beta}$, then the dimension and strong dimension of $R$ are the lower and upper average entropies, respectively, of $vec{beta}$. 2. For each pair of $Delta^0_2$-computable real numbers $0 &lt; alpha le beta le 1$, there exists $A in {rm E}$ such that the polynomial-time many-one degree of $A$ has dimension $alpha$ in E and strong dimension $beta$ in E. Our proofs of these theorems use a new large deviation theorem for self-information with respect to a bias sequence $vec{beta}$ that need not be convergent.},
journal = {SIAM J. Comput.},
month = jun,
pages = {671–705},
numpages = {35},
keywords = {packing dimension, effective dimension, Hausdorff dimension, Martin-L\"{o}f randomness, computational complexity, Kolmogorov complexity}
}

@article{10.1137/S0097539703436485,
author = {Molloy, Michael and Salavatipour, Mohammad R.},
title = {The Resolution Complexity of Random Constraint Satisfaction Problems},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436485},
doi = {10.1137/S0097539703436485},
abstract = {We consider random instances of constraint satisfaction problems where each variable has domain size $d$ and each constraint contains $t$ restrictions on $k$ variables. For each $(d,k,t)$ we determine whether the resolution complexity is a.s. constant, polynomial, or exponential in the number of variables. For a particular range of $(d,k,t)$, we determine a sharp threshold for resolution complexity where the resolution complexity drops from a.s. exponential to a.s. polynomial when the clause density passes a specific value.},
journal = {SIAM J. Comput.},
month = jun,
pages = {895–922},
numpages = {28},
keywords = {resolution complexity, phase transition, random $k$-SAT, sharp threshold, random constraint satisfaction problems}
}

@article{10.1137/S0097539702404055,
author = {Kolliopoulos, Stavros G. and Rao, Satish},
title = {A Nearly Linear-Time Approximation Scheme for the Euclidean $k$-Median Problem},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702404055},
doi = {10.1137/S0097539702404055},
abstract = {This paper provides a randomized approximation scheme for the $k$-median problem when the input points lie in the $d$-dimensional Euclidean space. The worst-case running time is $O(2^{O((log(1/epsilon) / varepsilon)^{d-1})} n log^{d+6} n ),$ which is nearly linear for any fixed $varepsilon$ and $d$. Moreover, our method provides the first polynomial-time approximation scheme for and uncapacitated facility location instances in $d$-dimensional Euclidean space for any fixed $d &gt; 2.$ Our work extends techniques introduced originally by Arora for the Euclidean traveling salesman problem (TSP). To obtain the improvement we develop a structure theorem to describe hierarchical decomposition of solutions. The theorem is based on an adaptive decomposition scheme, which guesses at every level of the hierarchy the structure of the optimal solution and accordingly modifies the parameters of the decomposition. We believe that our methodology is of independent interest and may find applications to further geometric problems.},
journal = {SIAM J. Comput.},
month = jun,
pages = {757–782},
numpages = {26},
keywords = {approximation algorithms, Euclidean space, linear time, $k$-median, facility location, approximation schemes}
}

@article{10.1137/060656413,
author = {Correa, Jos\'{e} R. and Goemans, Michel X.},
title = {Improved Bounds on Nonblocking 3-Stage Clos Networks},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060656413},
doi = {10.1137/060656413},
abstract = {We consider a generalization of edge coloring bipartite graphs in which every edge has a weight in $[0,1]$ and the coloring of the edges must satisfy that the sum of the weights of the edges incident to a vertex $v$ of any color must be at most 1. For unit weights, K\"{o}nig's theorem says that the number of colors needed is exactly the maximum degree. For this generalization, we show that $2.557 n + o(n)$ colors are sufficient, where $n$ is the maximum total weight adjacent to any vertex, improving the previously best bound of $2.833n+O(1)$ due to Du et al. Our analysis is interesting on its own and involves a novel decomposition result for bipartite graphs and the introduction of an associated continuous one-dimensional bin packing instance which we can prove allows perfect packing. This question is motivated by the question of the rearrangeability of 3-stage Clos networks. In that context, the corresponding parameter $n$ of interest in the edge coloring problem is the maximum over all vertices of the number of unit-sized bins needed to pack the weights of the incident edges. In that setting, we are able to improve the bound to $2.5480 n + o(n)$, also improving a bound of $2.5625n+O(1)$ of Du et al. We also consider the online version of this problem in which edges have to be colored as soon as they are revealed. In this context, we can show that $5n$ colors are enough. This contrasts with the best known lower bound of $3n-2$ by Tsai, Wang, and Hwang but improves upon the previous best upper bound of $5.75n$ obtained by Gao and Hwang. Additionally, we show several improved bounds for more restricted versions of the problem. These online bounds are achieved by simple and easy-to-implement algorithms, inspired by the first fit heuristic for bin packing.},
journal = {SIAM J. Comput.},
month = jun,
pages = {870–894},
numpages = {25},
keywords = {rearrangeability of 3-stage Clos networks, bipartite edge coloring, bin packing}
}

@article{10.1137/060654827,
author = {Eisenbrand, Friedrich and Grandoni, Fabrizio and Oriolo, Gianpaolo and Skutella, Martin},
title = {New Approaches for Virtual Private Network Design},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/060654827},
doi = {10.1137/060654827},
abstract = {Virtual private network design is the following NP-hard problem. We are given a communication network represented as a weighted graph with thresholds on the nodes which represent the amount of flow that a node can send to and receive from the network. The task is to reserve capacities at minimum cost and to specify paths between every ordered pair of nodes such that all valid traffic-matrices can be routed along the corresponding paths. Recently, this network design problem has received considerable attention in the literature. It is motivated by the fact that the exact amount of flow which is exchanged between terminals is not known in advance and prediction is often elusive. The main contributions of this paper are as follows: (1) Using Hu's 2-commodity flow theorem, we provide a new and considerably stronger lower bound on the cost of an optimum solution. With this lower bound we reanalyze a simple routing scheme which has been described in the literature many times, and provide an improved upper bound on its approximation ratio. (2) We present a new randomized approximation algorithm. In contrast to earlier approaches from the literature, the resulting solution does not have tree structure. A combination of our new algorithm with the simple routing scheme yields an expected performance ratio of $3.79$ for virtual private network design. This is a considerable improvement of the previously best known $5.55$-approximation result [A. Gupta, A. Kumar, and T. Roughgarden, Simpler and better approximation algorithms for network design, in Proceedings of the ACM Symposium on Theory of Computing, ACM, New York, 2003, pp. 365-372]. (3) Our VPND algorithm uses a Steiner tree approximation algorithm as a subroutine. It is known that an optimum Steiner tree can be computed in polynomial time if the number of terminals is logarithmic. Replacing the approximate Steiner tree computation with an exact one whenever the number of terminals is sufficiently small, we finally reduce the approximation ratio to $3.55$. To the best of our knowledge, this is the first time that a nontrivial result from exact (exponential) algorithms leads to an improved polynomial-time approximation algorithm.},
journal = {SIAM J. Comput.},
month = jun,
pages = {706–721},
numpages = {16},
keywords = {randomized algorithms, approximation algorithms, network design}
}

@article{10.1137/05064206X,
author = {Naor, Assaf and Schechtman, Gideon},
title = {Planar Earthmover Is Not in $L_1$},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/05064206X},
doi = {10.1137/05064206X},
abstract = {We show that any $L_1$ embedding of the transportation cost (a.k.a. Earthmover) metric on probability measures supported on the grid ${0,1,ldots,n}^2 subseteq mathbb{R}^2$ incurs distortion $Omega left(sqrt{log n}right)$. We also use Fourier analytic techniques to construct a simple $L_1$ embedding of this space which has distortion $O(log n)$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {804–826},
numpages = {23},
keywords = {nearest neighbor search, metric embeddings, Earthmover metric}
}

@article{10.1137/050627915,
author = {Alon, Noga and Fischer, Eldar and Newman, Ilan},
title = {Efficient Testing of Bipartite Graphs for Forbidden Induced Subgraphs},
year = {2007},
issue_date = {June 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050627915},
doi = {10.1137/050627915},
abstract = {Alon et. al. [N. Alon, E. Fischer, M. Krivelevich, and M. Szegedy, Combinatorica, 20 (2000), pp. 451-476] showed that every property that is characterized by a finite collection of forbidden induced subgraphs is $epsilon$-testable. However, the complexity of the test is double-tower with respect to $1/epsilon$, as the only tool known to construct such tests uses a variant of Szemer\'{e}di's regularity lemma. Here we show that any property of bipartite graphs that is characterized by a finite collection of forbidden induced subgraphs is $epsilon$-testable, with a number of queries that is polynomial in $1/epsilon$. Our main tool is a new “conditional” version of the regularity lemma for binary matrices, which may be interesting on its own.},
journal = {SIAM J. Comput.},
month = jun,
pages = {959–976},
numpages = {18},
keywords = {property testing, regularity lemma, approximation, graph algorithms}
}

@article{10.5555/1328738.1328748,
author = {Klauck, Hartmut},
title = {One-Way Communication Complexity and the Ne\v{c}Iporuk Lower Bound on Formula Size},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
abstract = {In this paper the Ne\v{c}iporuk method for proving lower bounds on the size of Boolean formulas is reformulated in terms of one-way communication complexity. We investigate the settings of probabilistic formulas, nondeterministic formulas, and quantum formulas. In all cases we can use results about one-way communication complexity to prove lower bounds on formula size. The main results regarding formula size are as follows: We show a polynomial size gap between probabilistic/quantum and deterministic formulas, a near-quadratic gap between the sizes of nondeterministic formulas with limited access to nondeterministic bits and nondeterministic formulas with access to slightly more such bits, and a near-quadratic lower bound on quantum formula size. Furthermore we give a polynomial separation between the sizes of quantum formulas with and without multiple read random inputs. The lower bound methods for quantum and probabilistic formulas employ a variant of the Ne\v{c}iporuk bound in terms of the Vapnik-Chervonenkis dimension. To establish our lower bounds we show optimal separations between one-way and two-way protocols for limited nondeterministic and quantum communication complexity, and we show that zero-error quantum one-way communication complexity asymptotically equals deterministic one-way communication complexity for total functions.},
journal = {SIAM J. Comput.},
month = may,
pages = {552–583},
numpages = {32},
keywords = {communication complexity, limited nondeterminism, lower bounds, quantum computing, computational complexity, formula size}
}

@article{10.5555/1328738.1328740,
author = {Barak, Boaz and Ong, Shien Jin and Vadhan, Salil},
title = {Derandomization in Cryptography},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
abstract = {We give two applications of Nisan-Wigderson-type (NW-type) (“noncryptographic”) pseudorandom generators in cryptography. Specifically, assuming the existence of an appropriate NW-type generator, we construct the following two protocols: (1) a one-message witness-indistinguishable proof system for every language in NP, based on any trapdoor permutation. This proof system does not assume a shared random string or any setup assumption, so it is actually an “NP proof system.” (2) a noninteractive bit-commitment scheme based on any one-way function. The specific NW-type generator we need is a hitting set generator fooling nondeterministic circuits. It is known how to construct such a generator if $E = DTIME(2^{O(n)})$ has a function of nondeterministic circuit complexity $2^{Omega(n)}$. Our witness-indistinguishable proofs are obtained by using the NW-type generator to derandomize the ZAPs of Dwork and Naor [Proceedings of the 41st Annual ACM Symposium on Foundations of Computer Science, 2000, pp. 283-293]. To our knowledge, this is the first construction of an NP proof system achieving a secrecy property. Our commitment scheme is obtained by derandomizing the interactive commitment scheme of Naor [J. Cryptology, 4 (1991), pp. 151-158]. Previous constructions of noninteractive commitment schemes were known only under incomparable assumptions.},
journal = {SIAM J. Comput.},
month = may,
pages = {380–400},
numpages = {21},
keywords = {complexity theory, interactive proofs, commitment schemes, pseudorandom generators, witness-indistinguishable proofs}
}

@article{10.1137/S0097539705447116,
author = {Br\"{o}nnimann, Herv\'{e} and Devillers, Olivier and Dujmovi\'{c}, Vida and Everett, Hazel and Glisse, Marc and Goaoc, Xavier and Lazard, Sylvain and Na, Hyeon-Suk and Whitesides, Sue},
title = {Lines and Free Line Segments Tangent to Arbitrary Three-Dimensional Convex Polyhedra},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447116},
doi = {10.1137/S0097539705447116},
abstract = {Motivated by visibility problems in three dimensions, we investigate the complexity and construction of the set of tangent lines in a scene of three-dimensional polyhedra. We prove that the set of lines tangent to four possibly intersecting convex polyhedra in $mathbb{R}^3$ with a total of $n$ edges consists of $Theta(n^2)$ connected components in the worst case. In the generic case, each connected component is a single line, but our result still holds for arbitrarily degenerate scenes. More generally, we show that a set of $k$ possibly intersecting convex polyhedra with a total of $n$ edges admits, in the worst case, $Theta(n^2k^2)$ connected components of maximal free line segments tangent to at least four polytopes. Furthermore, these bounds also hold for possibly occluded lines rather than maximal free line segments. Finally, we present an $O(n^2 k^2 log n)$ time and $O(nk^2)$ space algorithm that, given a scene of $k$ possibly intersecting convex polyhedra, computes all the minimal free line segments that are tangent to any four of the polytopes and are isolated transversals to the set of edges they intersect; in particular, we compute at least one line segment per connected component of tangent lines.},
journal = {SIAM J. Comput.},
month = may,
pages = {522–551},
numpages = {30},
keywords = {visual events, visibility complex, computational geometry, 3D visibility}
}

@article{10.1137/S0097539704446724,
author = {Arya, Sunil and Malamatos, Theocharis and Mount, David M. and Wong, Ka Chun},
title = {Optimal Expected-Case Planar Point Location},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446724},
doi = {10.1137/S0097539704446724},
abstract = {Point location is the problem of preprocessing a planar polygonal subdivision $S$ of size $n$ into a data structure in order to determine efficiently the cell of the subdivision that contains a given query point. We consider this problem from the perspective of expected query time. We are given the probabilities $p_z$ that the query point lies within each cell $z in S$. The entropy $H$ of the resulting discrete probability distribution is the dominant term in the lower bound on the expected-case query time. We show that it is possible to achieve query time $H + O(sqrt{H}+1)$ with space $O(n)$, which is optimal up to lower order terms in the query time. We extend this result to subdivisions with convex cells, assuming a uniform query distribution within each cell. In order to achieve space efficiency, we introduce the concept of entropy-preserving cuttings.},
journal = {SIAM J. Comput.},
month = may,
pages = {584–610},
numpages = {27},
keywords = {trapezoidal maps, entropy, polygonal subdivision, expected-case complexity, point location, entropy-preserving cuttings}
}

@article{10.1137/S0097539704446232,
author = {Garg, Naveen and K\"{o}nemann, Jochen},
title = {Faster and Simpler Algorithms for Multicommodity Flow and Other Fractional Packing Problems},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446232},
doi = {10.1137/S0097539704446232},
abstract = {This paper considers the problem of designing fast, approximate, combinatorial algorithms for multicommodity flows and other fractional packing problems. We present new, faster, and much simpler algorithms for these problems.},
journal = {SIAM J. Comput.},
month = may,
pages = {630–652},
numpages = {23},
keywords = {approximation algorithms, multicommodity flow, fractional packing, concurrent flow}
}

@article{10.1137/S0097539702420474,
author = {Moss, A. and Rabani, Y.},
title = {Approximation Algorithms for Constrained Node Weighted Steiner Tree Problems},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702420474},
doi = {10.1137/S0097539702420474},
abstract = {We consider a class of optimization problems where the input is an undirected graph with two weight functions defined for each node, namely the node's profit and its cost. The goal is to find a connected set of nodes of low cost and high profit. We present approximation algorithms for three natural optimization criteria that arise in this context, all of which are NP-hard. The budget problem asks for maximizing the profit of the set subject to a budget constraint on its cost. The quota problem requires minimizing the cost of the set subject to a quota constraint on its profit. Finally, the prize collecting problem calls for minimizing the cost of the set plus the profit (here interpreted as a penalty) of the complement set. For all three problems, our algorithms give an approximation guarantee of $O(log n)$, where $n$ is the number of nodes. To the best of our knowledge, these are the first approximation results for the quota problem and for the prize collecting problem, both of which are at least as hard to approximate as the set cover. For the budget problem, our results improve on a previous $O(log^2 n)$ result of Guha et al. Our methods involve new theorems relating tree packings to (node) cut conditions. We also show similar theorems (with better bounds) using edge cut conditions. These imply bounds for the analogous budget and quota problems with edge costs which are comparable to known (constant factor) bounds.},
journal = {SIAM J. Comput.},
month = may,
pages = {460–481},
numpages = {22},
keywords = {network design, node-weighted problems, combinatorial approximation algorithms}
}

@article{10.1137/S0097539702404377,
author = {van Dam, Wim and Magniez, Fr\'{e}d\'{e}ric and Mosca, Michele and Santha, Miklos},
title = {Self-Testing of Universal and Fault-Tolerant Sets of Quantum Gates},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702404377},
doi = {10.1137/S0097539702404377},
abstract = {We consider the design of self-testers for quantum gates. A self-tester for the gates $boldsymbol{F}_1,ldots, boldsymbol{F}_m$ is a procedure that, given any gates $boldsymbol{G}_1, ldots, boldsymbol{G}_m$, decides with high probability if each $boldsymbol{G}_i$ is close to $boldsymbol{F}_i$. This decision has to rely only on measuring in the computational basis the effect of iterating the gates on the classical states. It turns out that, instead of individual gates, we can design only procedures for families of gates. To achieve our goal we borrow some elegant ideas of the theory of program testing: We characterize the gate families by specific properties, develop a theory of robustness for them, and show that they lead to self-testers. In particular we prove that the universal and fault-tolerant set of gates consisting of a Hadamard gate, a $mathrm{ctext{-}NOT}$ gate, and a phase rotation gate of angle $pi/4$ is self-testable.},
journal = {SIAM J. Comput.},
month = may,
pages = {611–629},
numpages = {19},
keywords = {quantum circuit, fault-tolerance, self-testing, robustness}
}

@article{10.1137/S0097539701385995,
author = {Mounie, Gregory and Rapine, Christophe and Trystram, Denis},
title = {A $\frac32$-Approximation Algorithm for Scheduling Independent Monotonic Malleable Tasks},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701385995},
doi = {10.1137/S0097539701385995},
abstract = {A malleable task is a computational unit that may be executed on any arbitrary number of processors, whose execution time depends on the amount of resources allotted to it. This paper presents a new approach for scheduling a set of independent malleable tasks which leads to a worst case guarantee of $frac{3}{2}+varepsilon$ for the minimization of the parallel execution time for any fixed $varepsilon &gt; 0$. The main idea of this approach is to focus on the determination of a good allotment and then to solve the resulting problem with a fixed number of processors by a simple scheduling algorithm. The first phase is based on a dual approximation technique where the allotment problem is expressed as a knapsack problem for partitioning the set of tasks into two shelves of respective heights $1$ and $frac{1}{2}$.},
journal = {SIAM J. Comput.},
month = may,
pages = {401–412},
numpages = {12},
keywords = {polynomial approximation, malleable tasks, scheduling, performance guarantee}
}

@article{10.1137/060658035,
author = {Roy, Amitabha and Straubing, Howard},
title = {Definability of Languages by Generalized First-Order Formulas over $(\mathbb{N},+)$},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/060658035},
doi = {10.1137/060658035},
abstract = {We consider an extension of first-order logic by modular quantifiers of a fixed modulus $q$. Drawing on collapse results from finite model theory and techniques of finite semigroup theory, we show that if the only available numerical predicate is addition, then sentences in this logic cannot define the set of bit strings in which the number of 1's is divisible by a prime $p$ that does not divide $q$. More generally, we completely characterize the regular languages definable in this logic. The corresponding statement, with addition replaced by arbitrary numerical predicates, is equivalent to the conjectured separation of the circuit complexity class $ACC$ from $NC^1$. Thus our theorem can be viewed as proving a highly uniform version of the conjecture.},
journal = {SIAM J. Comput.},
month = may,
pages = {502–521},
numpages = {20},
keywords = {circuit complexity, finite model theory, semigroup theory}
}

@article{10.1137/060652324,
author = {Fischer, Eldar and Newman, Ilan},
title = {Testing versus Estimation of Graph Properties},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/060652324},
doi = {10.1137/060652324},
abstract = {Tolerant testing is an emerging topic in the field of property testing, which was defined in [M. Parnas, D. Ron, and R. Rubinfeld, J. Comput. System Sci., 72 (2006), pp. 1012-1042] and has recently become a very active topic of research. In the general setting, there exist properties that are testable but are not tolerantly testable [E. Fischer and L. Fortnow, Proceedings of the $20$th IEEE Conference on Computational Complexity, 2005, pp. 135-140]. On the other hand, we show here that in the setting of the dense graph model, all testable properties are not only tolerantly testable (which was already implicitly proved in [N. Alon, E. Fischer, M. Krivelevich, and M. Szegedy, Combinatorica, 20 (2000), pp. 451-476] and [O. Goldreich and L. Trevisan, Random Structures Algorithms, 23 (2003), pp. 23-57]), but also admit a constant query size algorithm that estimates the distance from the property up to any fixed additive constant. In the course of the proof we develop a framework for extending Szemer\'{e}di's regularity lemma, both as a prerequisite for formulating what kind of information about the input graph will provide us with the correct estimation, and as the means for efficiently gathering this information. In particular, we construct a probabilistic algorithm that finds the parameters of a regular partition of an input graph using a constant number of queries, and an algorithm to find a regular partition of a graph using a $mathrm{TC}_0$ circuit. This, in some ways, strengthens the results of [N. Alon, R. A. Duke, H. Lefmann, V. R\"{o}dl, and R. Yuster, J. Algorithms, 16 (1994), pp. 80-109].},
journal = {SIAM J. Comput.},
month = may,
pages = {482–501},
numpages = {20},
keywords = {property testing, approximation, graph algorithms, regularity lemma}
}

@article{10.1137/050645464,
author = {Blum, Avrim and Chawla, Shuchi and Karger, David R. and Lane, Terran and Meyerson, Adam and Minkoff, Maria},
title = {Approximation Algorithms for Orienteering and Discounted-Reward TSP},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050645464},
doi = {10.1137/050645464},
abstract = {In this paper, we give the first constant-factor approximation algorithm for the rooted Orienteering problem, as well as a new problem that we call the Discounted-Reward traveling salesman problem (TSP), motivated by robot navigation. In both problems, we are given a graph with lengths on edges and rewards on nodes, and a start node $s$. In the Orienteering problem, the goal is to find a path starting at $s$ that maximizes the reward collected, subject to a hard limit on the total length of the path. In the Discounted-Reward TSP, instead of a length limit we are given a discount factor $gamma$, and the goal is to maximize the total discounted reward collected, where the reward for a node reached at time $t$ is discounted by $gamma^t$. This problem is motivated by an approximation to a planning problem in the Markov decision process (MDP) framework under the commonly employed infinite horizon discounted reward optimality criterion. The approximation arises from a need to deal with exponentially large state spaces that emerge when trying to model one-time events and nonrepeatable rewards (such as for package deliveries). We also consider tree and multiple-path variants of these problems and provide approximations for those as well. Although the unrooted Orienteering problem, where there is no fixed start node $s$, has been known to be approximable using algorithms for related problems such as $k$-TSP (in which the amount of reward to be collected is fixed and the total length is approximately minimized), ours is the first to approximate the rooted question, solving an open problem in [E. M. Arkin, J. S. B. Mitchell, and G. Narasimhan, Proceedings of the $14$th ACM Symposium on Computational Geometry, 1998, pp. 307-316] and [B. Awerbuch, Y. Azar, A. Blum, and S. Vempala, SIAM J. Comput., 28 (1998), pp. 254-262]. We complement our approximation result for Orienteering by showing that the problem is APX-hard.},
journal = {SIAM J. Comput.},
month = may,
pages = {653–670},
numpages = {18},
keywords = {approximation algorithms, robot navigation, Markov decision processes, traveling salesman problem, prize-collecting traveling salesman problem, orienteering}
}

@article{10.1137/050643684,
author = {Magniez, Fre´de´ric and Santha, Miklos and Szegedy, Mario},
title = {Quantum Algorithms for the Triangle Problem},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050643684},
doi = {10.1137/050643684},
abstract = {We present two new quantum algorithms that either find a triangle (a copy of $K_{3}$) in an undirected graph $G$ on $n$ nodes, or reject if $G$ is triangle free. The first algorithm uses combinatorial ideas with Grover Search and makes $tilde{O}(n^{10/7})$ queries. The second algorithm uses $tilde{O}(n^{13/10})$ queries and is based on a design concept of Ambainis [in Proceedings of the $45$th IEEE Symposium on Foundations of Computer Science, 2004, pp. 22-31] that incorporates the benefits of quantum walks into Grover Search [L. Grover, in Proceedings of the Twenty-Eighth ACM Symposium on Theory of Computing, 1996, pp. 212-219]. The first algorithm uses only $O(log n)$ qubits in its quantum subroutines, whereas the second one uses $O(n)$ qubits. The Triangle Problem was first treated in [H. Buhrman et al., SIAM J. Comput., 34 (2005), pp. 1324-1330], where an algorithm with $O(n+sqrt{nm})$ query complexity was presented, where $m$ is the number of edges of $G$.},
journal = {SIAM J. Comput.},
month = may,
pages = {413–424},
numpages = {12},
keywords = {68R10, 68W99, 05C85}
}

@article{10.1137/050643672,
author = {Pavan, A. and Tirthapura, Srikanta},
title = {Range-Efficient Counting of Distinct Elements in a Massive Data Stream},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050643672},
doi = {10.1137/050643672},
abstract = {Efficient one-pass estimation of $F_0$, the number of distinct elements in a data stream, is a fundamental problem arising in various contexts in databases and networking. We consider range-efficient estimation of $F_0$: estimation of the number of distinct elements in a data stream where each element of the stream is not just a single integer but an interval of integers. We present a randomized algorithm which yields an (ε, δ)-approximation of $F_0$, with the following time and space complexities ($n$ is the size of the universe of the items): (1) The amortized processing time per interval is $O(log{frac{1}{delta}}log frac{n}{epsilon})$. (2) The workspace used is $O(frac{1}{epsilon^2}log{frac{1}{delta}}log n)$ bits. Our algorithm improves upon a previous algorithm by Bar-Yossef, Kumar and Sivakumar [Proceedings of the $13$th ACM-SIAM Symposium on Discrete Algorithms (SODA), 2002, pp. 623-632], which requires $O(frac{1}{epsilon^5} log{frac{1}{delta}}log^5 n)$ processing time per item. This algorithm can also be used to compute the max-dominance norm of a stream of multiple signals and significantly improves upon the previous best time and space bounds by Cormode and Muthukrishnan [Proceedings of the $11$th European Symposium on Algorithms (ESA), Lecture Notes in Comput. Sci. 2938, Springer, Berlin, 2003, pp. 148-160]. This algorithm also provides an efficient solution to the distinct summation problem, which arises during data aggregation in sensor networks [Proceedings of the $2$nd International Conference on Embedded Networked Sensor Systems, ACM Press, New York, 2004, pp. 250-262, Proceedings of the $20$th International Conference on Data Engineering (ICDE), 2004, pp. 449-460].},
journal = {SIAM J. Comput.},
month = may,
pages = {359–379},
numpages = {21},
keywords = {reductions, sensor networks, data streams, range efficiency, distinct elements}
}

@article{10.1137/050643295,
author = {Gurevich, Yuri and Schupp, Paul},
title = {Membership Problem for the Modular Group},
year = {2007},
issue_date = {May 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/050643295},
doi = {10.1137/050643295},
abstract = {The modular group plays an important role in many branches of mathematics. We show that the membership problem for the modular group is decidable in polynomial time. To this end, we develop a new syllable-based version of the known subgroup-graph approach. The new approach can be used to prove additional results. We demonstrate this by using it to prove that the membership problem for a free group remains decidable in polynomial time when elements are written in a normal form with exponents.},
journal = {SIAM J. Comput.},
month = may,
pages = {425–459},
numpages = {35},
keywords = {membership problem, unimodular matrices, folding, $PSL_2(mathbb{Z})$, modular group, free group, combinatorial group theory, geometric group theory, polynomial time, syllabic presentation}
}

@article{10.5555/1328722.1328736,
author = {Aharonov, Dorit and Ta-Shma, Amnon},
title = {Adiabatic Quantum State Generation},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
abstract = {The design of new quantum algorithms has proven to be an extremely difficult task. This paper considers a different approach to this task by studying the problem of quantum state generation. We motivate this problem by showing that the entire class of statistical zero knowledge, which contains natural candidates for efficient quantum algorithms such as graph isomorphism and lattice problems, can be reduced to the problem of quantum state generation. To study quantum state generation, we define a paradigm which we call adiabatic state generation (ASG) and which is based on adiabatic quantum computation. The ASG paradigm is not meant to replace the standard quantum circuit model or to improve on it in terms of computational complexity. Rather, our goal is to provide a natural theoretical framework, in which quantum state generation algorithms could be designed. The new paradigm seems interesting due to its intriguing links to a variety of different areas: the analysis of spectral gaps and ground-states of Hamiltonians in physics, rapidly mixing Markov chains, adiabatic computation, and approximate counting. To initiate the study of ASG, we prove several general lemmas that can serve as tools when using this paradigm. We demonstrate the application of the paradigm by using it to turn a variety of (classical) approximate counting algorithms into efficient quantum state generators of nontrivial quantum states, including, for example, the uniform superposition over all perfect matchings in a bipartite graph.},
journal = {SIAM J. Comput.},
month = apr,
pages = {47–82},
numpages = {36},
keywords = {state generation, quantum algorithm, quantum sampling, Zeno effect, statistical zero knowledge, quantum computation, Hamiltonians, spectral gap, adiabatic theorem, Markov chains}
}

@article{10.5555/1328722.1328729,
author = {Klauck, Hartmut},
title = {Lower Bounds for Quantum Communication Complexity},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
abstract = {We prove lower bounds on the bounded error quantum communication complexity. Our methods are based on the Fourier transform of the considered functions. First we generalize a method for proving classical communication complexity lower bounds developed by Raz [Comput. Complexity, 5 (1995), pp. 205-221] to the quantum case. Applying this method, we give an exponential separation between bounded error quantum communication complexity and nondeterministic quantum communication complexity. We develop several other lower bound methods based on the Fourier transform, notably showing that $sqrt{bar{s}(f)/log n}$, for the average sensitivity $bar{s}(f)$ of a function $f$, yields a lower bound on the bounded error quantum communication complexity of $f((x wedge y)oplus z)$, where $x$ is a Boolean word held by Alice and $y,z$ are Boolean words held by Bob. We then prove the first large lower bounds on the bounded error quantum communication complexity of functions, for which a polynomial quantum speedup is possible. For all the functions we investigate, the only previously applied general lower bound method based on discrepancy yields bounds that are $O(log n)$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {20–46},
numpages = {27},
keywords = {lower bounds, quantum computing, communication complexity, computational complexity}
}

@article{10.5555/1328722.1328723,
author = {Andrews, Matthew and Zhang, Lisa},
title = {Hardness of the Undirected Congestion Minimization Problem},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
abstract = {We show that there is no $gammaloglog M/logloglog M$-approximation for the undirected congestion minimization problem unless $NP subseteq ZPTIME(n^{{rm polylog} n})$, where $M$ is the size of the graph and γ is some positive constant.},
journal = {SIAM J. Comput.},
month = apr,
pages = {112–131},
numpages = {20},
keywords = {congestion minimization, hardness of approximation, undirected graphs}
}

@article{10.1137/SMJCAT000037000001000165000001,
author = {Achlioptas, Dimitris and Koltun, Vladlen},
title = {Special Section on Foundations of Computer Science},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000037000001000165000001},
doi = {10.1137/SMJCAT000037000001000165000001},
abstract = {This volume comprises the polished and fully refereed versions of a selection of papers presented at the Forty-Fifth Annual IEEE Symposium on Foundations of Computer Science (FOCS 2004), held in Rome, Italy, October 17-19, 2004. Unrefereed preliminary versions of the papers presented at the symposium appeared in the proceedings of the meeting, published by IEEE.The FOCS 2004 Program Committee consisted of Dimitris Achlioptas, Micah Adler, Eli Ben-Sasson, Faith Fich, Oded Goldreich, Martin Grohe, Sean Hallgren, Johan Ha˚stad, Giuseppe F. Italiano, Vladlen Koltun, Yuval Rabani, Miklos Santha, Leonard Schulman, Rocco Servedio, D. Sivakumar, Eli Upfal, and David Williamson.Out of 272 “Extended Abstracts” submitted to the FOCS 2004 Program Committee, 64 were selected for presentation at the symposium. Eight of those 64 papers are included in this volume. This collection encompasses a wide variety of questions and methods in theoretical computer science, often shedding new light on entire areas with a fresh approach. The topics include fundamental questions of complexity theory and algorithms as well as foundational mathematical problems. All papers were refereed in accordance with SICOMP’s stringent standards, and most were substantially updated in the process.We take this opportunity to thank all the referees whose anonymous work has significantly contributed to the value of this volume. It was an honor to edit this special section in SIAM Journal on Computing.},
journal = {SIAM J. Comput.},
month = apr,
pages = {165},
numpages = {1}
}

@article{10.1137/S0097539705447384,
author = {Jain, Kamal},
title = {A Polynomial Time Algorithm for Computing an Arrow-Debreu Market Equilibrium for Linear Utilities},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447384},
doi = {10.1137/S0097539705447384},
abstract = {We provide the first polynomial time exact algorithm for computing an Arrow-Debreu market equilibrium for the case of linear utilities. Our algorithm is based on solving a convex program using the ellipsoid algorithm and simultaneous diophantine approximation. As a side result, we prove that the set of assignments at equilibrium is convex and the equilibrium prices themselves are log-convex. Our convex program is explicit and intuitive, which allows maximizing a concave function over the set of equilibria. On the practical side, Ye developed an interior point algorithm [Lecture Notes in Comput. Sci. 3521, Springer, New York, 2005, pp. 3-5] to find an equilibrium based on our convex program. We also derive separate combinatorial characterizations of equilibrium for Arrow-Debreu and Fisher cases. Our convex program can be extended for many nonlinear utilities and production models. Our paper also makes a powerful theorem (Theorem 6.4.1 in [M. Grotschel, L. Lovasz, and A. Schrijver, Geometric Algorithms and Combinatorial Optimization, 2nd ed., Springer-Verlag, Berlin, Heidelberg, 1993]) even more powerful (in Theorems 12 and 13) in the area of geometric algorithms and combinatorial optimization. The main idea in this generalization is to allow ellipsoids to contain not the whole convex region but a part of it. This theorem is of independent interest.},
journal = {SIAM J. Comput.},
month = apr,
pages = {303–318},
numpages = {16},
keywords = {convex set, polynomial time algorithms, economics, market equilibrium}
}

@article{10.1137/S0097539705447372,
author = {Khot, Subhash and Kindler, Guy and Mossel, Elchanan and O’Donnell, Ryan},
title = {Optimal Inapproximability Results for MAX-CUT and Other 2-Variable CSPs?},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447372},
doi = {10.1137/S0097539705447372},
abstract = {In this paper we show a reduction from the Unique Games problem to the problem of approximating MAX-CUT to within a factor of $alpha_{text{tiny{GW}}} + epsilon$ for all $epsilon &gt; 0$; here $alpha_{text{tiny{GW}}} approx .878567$ denotes the approximation ratio achieved by the algorithm of Goemans and Williamson in [J. Assoc. Comput. Mach., 42 (1995), pp. 1115-1145]. This implies that if the Unique Games Conjecture of Khot in [Proceedings of the 34th Annual ACM Symposium on Theory of Computing, 2002, pp. 767-775] holds, then the Goemans-Williamson approximation algorithm is optimal. Our result indicates that the geometric nature of the Goemans-Williamson algorithm might be intrinsic to the MAX-CUT problem. Our reduction relies on a theorem we call Majority Is Stablest. This was introduced as a conjecture in the original version of this paper, and was subsequently confirmed in [E. Mossel, R. O’Donnell, and K. Oleszkiewicz, Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, 2005, pp. 21-30]. A stronger version of this conjecture called Plurality Is Stablest is still open, although [E. Mossel, R. O’Donnell, and K. Oleszkiewicz, Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, 2005, pp. 21-30] contains a proof of an asymptotic version of it. Our techniques extend to several other two-variable constraint satisfaction problems. In particular, subject to the Unique Games Conjecture, we show tight or nearly tight hardness results for MAX-2SAT, MAX-$q$-CUT, and MAX-2LIN($q$). For MAX-2SAT we show approximation hardness up to a factor of roughly $.943$. This nearly matches the $.940$ approximation algorithm of Lewin, Livnat, and Zwick in [Proceedings of the 9th Annual Conference on Integer Programming and Combinatorial Optimization, Springer-Verlag, Berlin, 2002, pp. 67-82]. Furthermore, we show that our .943... factor is actually tight for a slightly restricted version of MAX-2SAT. For MAX-$q$-CUT we show a hardness factor which asymptotically (for large $q$) matches the approximation factor achieved by Frieze and Jerrum [Improved approximation algorithms for MAX k-CUT and MAX BISECTION, in Integer Programming and Combinatorial Optimization, Springer-Verlag, Berlin, pp. 1-13], namely $1 - 1/q + 2({rm ln},q)/q^2$. For MAX-2LIN($q$) we show hardness of distinguishing between instances which are $(1-epsilon)$-satisfiable and those which are not even, roughly, $(q^{-epsilon/2})$-satisfiable. These parameters almost match those achieved by the recent algorithm of Charikar, Makarychev, and Makarychev [Proceedings of the 38th Annual ACM Symposium on Theory of Computing, 2006, pp. 205-214]. The hardness result holds even for instances in which all equations are of the form $x_i - x_j = c$. At a more qualitative level, this result also implies that $1-epsilon$ vs. ε hardness for MAX-2LIN($q$) is equivalent to the Unique Games Conjecture.},
journal = {SIAM J. Comput.},
month = apr,
pages = {319–357},
numpages = {39},
keywords = {Unique Games, constraint satisfaction, hardness of approximation, MAX-CUT}
}

@article{10.1137/S0097539705447360,
author = {Micciancio, Daniele and Regev, Oded},
title = {Worst-Case to Average-Case Reductions Based on Gaussian Measures},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447360},
doi = {10.1137/S0097539705447360},
abstract = {We show that finding small solutions to random modular linear equations is at least as hard as approximating several lattice problems in the worst case within a factor almost linear in the dimension of the lattice. The lattice problems we consider are the shortest vector problem, the shortest independent vectors problem, the covering radius problem, and the guaranteed distance decoding problem (a variant of the well-known closest vector problem). The approximation factor we obtain is $n log^{O(1)} n$ for all four problems. This greatly improves on all previous work on the subject starting from Ajtai’s seminal paper [Generating hard instances of lattice problems, in Complexity of Computations and Proofs, Quad. Mat. 13, Dept. Math., Seconda Univ. Napoli, Caserta, Italy, 2004, pp. 1-32] up to the strongest previously known results by Micciancio [SIAM J. Comput., 34 (2004), pp. 118-169]. Our results also bring us closer to the limit where the problems are no longer known to be in NP intersect coNP. Our main tools are Gaussian measures on lattices and the high-dimensional Fourier transform. We start by defining a new lattice parameter which determines the amount of Gaussian noise that one has to add to a lattice in order to get close to a uniform distribution. In addition to yielding quantitatively much stronger results, the use of this parameter allows us to simplify many of the complications in previous work. Our technical contributions are twofold. First, we show tight connections between this new parameter and existing lattice parameters. One such important connection is between this parameter and the length of the shortest set of linearly independent vectors. Second, we prove that the distribution that one obtains after adding Gaussian noise to the lattice has the following interesting property: the distribution of the noise vector when conditioning on the final value behaves in many respects like the original Gaussian noise vector. In particular, its moments remain essentially unchanged.},
journal = {SIAM J. Comput.},
month = apr,
pages = {267–302},
numpages = {36},
keywords = {lattices, Gaussian measures, worst-case to average-case reductions}
}

@article{10.1137/S0097539705447359,
author = {Chien, Steve and Sinclair, Alistair},
title = {Algebras with Polynomial Identities and Computing the Determinant},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447359},
doi = {10.1137/S0097539705447359},
abstract = {In 1991, Nisan proved an exponential lower bound on the size of an algebraic branching program (ABP) that computes the determinant of a matrix in the noncommutative “free algebra” setting, in which there are no nontrivial relationships between the matrix entries. By contrast, when the matrix entries commute there are polynomial size ABPs for the determinant. This paper extends Nisan’s result to a much wider class of noncommutative algebras, including all nontrivial matrix algebras over any field of characteristic 0, group algebras of all nonabelian finite groups over algebraically closed fields of characteristic 0, the quaternion algebra, and the Clifford algebras. As a result, we obtain more compelling evidence for the essential role played by commutativity in the efficient computation of the determinant. The key to our approach is a characterization of noncommutative algebras by means of the polynomial identities that they satisfy. Extending Nisan’s lower bound framework, we find that any reduction in complexity compared to the free algebra must arise from the ability of the identities to reduce the rank of certain naturally associated matrices. Using results from the theory of algebras with polynomial identities, we are able to show that none of the identities of the above classes of algebras is able to achieve such a rank reduction.},
journal = {SIAM J. Comput.},
month = apr,
pages = {252–266},
numpages = {15},
keywords = {permanents, algebraic branching programs, algebraic computation, determinants, polynomial identities, complexity lower bounds}
}

@article{10.1137/S0097539705447347,
author = {Demaine, Erik D. and Harmon, Dion and Iacono, John and Paˇtras¸cu, Mihai},
title = {Dynamic Optimality—Almost},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447347},
doi = {10.1137/S0097539705447347},
abstract = {We present an $O(lg lg n)$-competitive online binary search tree, improving upon the best previous (trivial) competitive ratio of $O(lg n)$. This is the first major progress on Sleator and Tarjan’s dynamic optimality conjecture of 1985 that $O(1)$-competitive binary search trees exist.},
journal = {SIAM J. Comput.},
month = apr,
pages = {240–251},
numpages = {12},
keywords = {binary search trees, splay trees, competitiveness}
}

@article{10.1137/S0097539705447335,
author = {Cheng, Qi and Wan, Daqing},
title = {On the List and Bounded Distance Decodability of Reed-Solomon Codes},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447335},
doi = {10.1137/S0097539705447335},
abstract = {For an error-correcting code and a distance bound, the list decoding problem is to compute all the codewords within a given distance to a received message. The bounded distance decoding problem is to find one codeword if there is at least one codeword within the given distance, or to output the empty set if there is not. Obviously the bounded distance decoding problem is not as hard as the list decoding problem. For a Reed-Solomon code $[n,k]_q$, a simple counting argument shows that for any integer $0<g < n $, there exists at least one Hamming ball of radius $n-g$, which contains at least ${n \choose g}/q^{g-k} $ many codewords. Let $\hat{g}(n,k,q) $ be the smallest positive integer $g$ such that ${{n \choose g}/ q^{g-k}} \leq 1 $. One knows that $$k-1\leq \hat{g}(n,k,q) \leq \sqrt{n(k-1)}\leq n.$$ For the distance bound up to $n-\sqrt{n(k-1)}$, it is known that both the list and bounded distance decoding can be solved efficiently. For the distance bound between $n - \sqrt{n(k-1)}$ and $n- \hat{g}(n,k,q) $, we do not know whether the Reed-Solomon code is list or bounded distance decodable; nor do we know whether there are polynomially many codewords in all balls of the radius. It is generally believed that the answer to both questions is no. In this paper, we prove the following: (1) List decoding cannot be done for radius $n - \hat{g}(n,k,q) $ or larger, unless the discrete logarithm over ${\bf F}_{q^{\hat{g}(n,k,q) -k}}$ is easy. (2) Let $h$ and $g$ be positive integers satisfying $ q\geq \max(g^2, (h-1)^{2+\epsilon})$ and $g \geq ({4 \over \epsilon } + 2) (h+1)$ for a constant $\epsilon > 0 $. We show that the discrete logarithm problem over ${\bf F}_{q^{h}}$ can be efficiently reduced by a randomized algorithm to the bounded distance decoding problem of the Reed-Solomon code $[q, g-h]_q$ with radius $q - g$. These results show that the decoding problems for the Reed-Solomon code are at least as hard as the discrete logarithm problem over certain finite fields. For the list decoding problem of Reed-Solomon codes, although the infeasible radius that we obtain is much larger than the radius, which is known to be feasible, it is the first nontrivial bound. Our result on the bounded distance decodability of Reed-Solomon codes is also the first of its kind. The main tools for obtaining these results are an interesting connection between the problem of list decoding of Reed-Solomon code, the problem of a discrete logarithm over finite fields, and a generalization of Katz’s theorem on representations of elements in an extension finite field by products of distinct linear factors.},
journal = {SIAM J. Comput.},
month = apr,
pages = {195–209},
numpages = {15},
keywords = {Reed-Solomon codes, bounded distance decoding algorithm, discrete logarithm problem, list decoding algorithm}
}</g>

@article{10.1137/S0097539705447323,
author = {Aharonov, Dorit and van Dam, Wim and Kempe, Julia and Landau, Zeph and Lloyd, Seth and Regev, Oded},
title = {Adiabatic Quantum Computation is Equivalent to Standard Quantum Computation},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447323},
doi = {10.1137/S0097539705447323},
abstract = {Adiabatic quantum computation has recently attracted attention in the physics and computer science communities, but its computational power was unknown. We describe an efficient adiabatic simulation of any given quantum algorithm, which implies that the adiabatic computation model and the conventional quantum computation model are polynomially equivalent. Our result can be extended to the physically realistic setting of particles arranged on a two-dimensional grid with nearest neighbor interactions. The equivalence between the models allows stating the main open problems in quantum computation using well-studied mathematical objects such as eigenvectors and spectral gaps of sparse matrices.},
journal = {SIAM J. Comput.},
month = apr,
pages = {166–194},
numpages = {29},
keywords = {quantum computation, nearest neighbor interactions, adiabatic computation}
}

@article{10.1137/S0097539705447311,
author = {Ambainis, Andris},
title = {Quantum Walk Algorithm for Element Distinctness},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447311},
doi = {10.1137/S0097539705447311},
abstract = {We use quantum walks to construct a new quantum algorithm for element distinctness and its generalization. For element distinctness (the problem of finding two equal items among $N$ given items), we get an $O(N^{2/3})$ query quantum algorithm. This improves the previous $O(N^{3/4})$ quantum algorithm of Buhrman et al. [SIAM J. Comput., 34 (2005), pp. 1324-1330] and matches the lower bound of Aaronson and Shi [J. ACM, 51 (2004), pp. 595-605]. We also give an $O(N^{k/(k+1)})$ query quantum algorithm for the generalization of element distinctness in which we have to find $k$ equal items among $N$ items.},
journal = {SIAM J. Comput.},
month = apr,
pages = {210–239},
numpages = {30},
keywords = {element distinctness, quantum query algorithms, quantum computing}
}

@article{10.1137/S009753970444630X,
author = {Bradford, Phillip G. and Katehakis, Michael N.},
title = {A Probabilistic Study on Combinatorial Expanders and Hashing},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444630X},
doi = {10.1137/S009753970444630X},
abstract = {This paper gives a new way of showing that certain constant degree graphs are graph expanders. This is done by giving new proofs of expansion for three permutations of the Gabber-Galil expander. Our results give an expansion factor of $frac{3}{16}$ for subgraphs of these three-regular graphs with $(p-1)^2$ inputs for $p$ prime. The proofs are not based on eigenvalue methods or higher algebra. The same methods show the expected number of probes for unsuccessful search in double hashing is bounded by $frac{1}{1-alpha}$, where α is the load factor. This assumes a double hashing scheme in which two hash functions are randomly and independently chosen from a specified uniform distribution. The result is valid regardless of the distribution of the inputs. This is analogous to Carter and Wegman’s result for hashing with chaining. This paper concludes by elaborating on how any sufficiently sized subset of inputs in any distribution expands in the subgraph of the Gabber-Galil graph expander of focus. This is related to any key distribution having expected $frac{1}{1 - alpha}$ probes for unsuccessful search for double hashing given the initial random, independent, and uniform choice of two universal hash functions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {83–111},
numpages = {29},
keywords = {combinatorial expanders, Gabber-Galil expander, pairwise independence, double hashing, hash collisions, expansion factor, expander graphs}
}

@article{10.1137/050641594,
author = {Harary, Frank and Slany, Wolfgang and Verbitsky, Oleg},
title = {On the Computational Complexity of the Forcing Chromatic Number},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050641594},
doi = {10.1137/050641594},
abstract = {We consider vertex colorings of graphs in which adjacent vertices have distinct colors. A graph is $s$-chromatic if it is colorable in $s$ colors and any coloring of it uses at least $s$ colors. The forcing chromatic number $F_{chi}(G)$ of an $s$-chromatic graph $G$ is the smallest number of vertices which must be colored so that, with the restriction that $s$ colors are used, every remaining vertex has its color determined uniquely. We estimate the computational complexity of $force G$ relating it to the complexity class US introduced by Blass and Gurevich [Inform. Control, 55 (1982), pp. 80-88]. We prove that recognizing whether $F_{chi}(G)le2$ is US-hard with respect to polynomial-time many-one reductions. Moreover, this problem is coNP-hard even under the promises that $F_{chi}(G)le3$ and $G$ is 3-chromatic. On the other hand, recognizing whether $F_{chi}(G)le k$, for each constant $k$, is reducible to a problem in US via a disjunctive truth-table reduction. Similar results are obtained also for forcing variants of the clique and the domination numbers of a graph.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1–19},
numpages = {19},
keywords = {chromatic number of a graph, combinatorial forcing, unique satisfiability, complexity classes, computational complexity}
}

@article{10.1137/050634840,
author = {Madelaine, Florent and Stewart, Iain A.},
title = {Constraint Satisfaction, Logic and Forbidden Patterns},
year = {2007},
issue_date = {April 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {37},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050634840},
doi = {10.1137/050634840},
abstract = {In the 1990s, Feder and Vardi attempted to find a large subclass of NP which exhibits a dichotomy, that is, where every problem in the subclass is either solvable in polynomial-time or NP-complete. Their studies resulted in a candidate class of problems, namely, those definable in the logic MMSNP. While it remains open as to whether MMSNP exhibits a dichotomy, for various reasons it remains a strong candidate. Feder and Vardi added to the significance of MMSNP by proving that, although MMSNP strictly contains CSP, the class of constraint satisfaction problems, MMSNP and CSP are computationally equivalent. We introduce here a new class of combinatorial problems, the class of forbidden patterns problems FPP, and characterize MMSNP as the finite unions of problems from FPP. We use our characterization to detail exactly those problems that are in MMSNP but not in CSP. Furthermore, given a problem in MMSNP, we are able to decide whether the problem is in CSP or not (this whole process is effective). If the problem is in CSP, then we can construct a template for this problem; otherwise, for any given candidate for the role of template, we can build a counterexample (again, this process is effective).},
journal = {SIAM J. Comput.},
month = apr,
pages = {132–163},
numpages = {32},
keywords = {existential monadic second-order logic, constraint satisfaction, finite model theory}
}

@article{10.5555/1328675.1328684,
author = {Chrobak, Marek and Jawor, Wojciech and Sgall, Jirˇi´ and Tichy´, Toma´sˇ},
title = {Online Scheduling of Equal-Length Jobs: Randomization and Restarts Help},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
abstract = {We consider the following scheduling problem. The input is a set of jobs with equal processing times, where each job is specified by its release time and deadline. The goal is to determine a single-processor nonpreemptive schedule that maximizes the number of completed jobs. In the online version, each job arrives at its release time. We give two online algorithms with competitive ratios below $2$ and show several lower bounds on the competitive ratios. First, we give a barely random $5/3$-competitive algorithm that uses only one random bit. We also show a lower bound of $3/2$ on the competitive ratio of barely random algorithms that randomly choose one of two deterministic algorithms. If the two algorithms are selected with equal probability, we can further improve the bound to $8/5$. Second, we give a deterministic $3/2$-competitive algorithm in the model that allows restarts, and we show that in this model the ratio $3/2$ is optimal. For randomized algorithms with restarts we show a lower bound of $6/5$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1709–1728},
numpages = {20},
keywords = {randomization, online algorithms, competitive analysis, job scheduling}
}

@article{10.5555/1328675.1328683,
author = {Hitchcock, John M.},
title = {Online Learning and Resource-Bounded Dimension: Winnow Yields New Lower Bounds for Hard Sets},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
abstract = {We establish a relationship between the online mistake-bound model of learning and resource-bounded dimension. This connection is combined with the Winnow algorithm to obtain new results about the density of hard sets under adaptive reductions. This improves previous work of Fu [SIAM J. Comput., 24 (1995), pp. 1082-1090] and Lutz and Zhao [SIAM J. Comput., 30 (2000), pp. 1197-1210], and solves one of Lutz and Mayordomo’s “twelve problems in resource-bounded measure” [Bull. Eur. Assoc. Theor. Comput. Sci. EATSC, 68 (1999), pp. 64-80].},
journal = {SIAM J. Comput.},
month = feb,
pages = {1696–1708},
numpages = {13},
keywords = {resource-bounded measure, sparse sets, resource-bounded dimension, computational complexity, polynomial-time reductions}
}

@article{10.5555/1328675.1328678,
author = {Kuijpers, Bart and Kuper, Gabriel and Paredaens, Jan and Vandeurzen, Luc},
title = {First-Order Languages Expressing Constructible Spatial Database Queries},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
abstract = {The research presented in this paper is situated in the framework of constraint databases introduced by Kanellakis, Kuper, and Revesz in their seminal paper of 1990, specifically, the language with real polynomial constraints (FO+poly). For reasons of efficiency, this model is implemented with onlylinear polynomial constraints, but this limitation to linear polynomial constraints has severe implications on the expressive power of the query language. In particular, when used for modeling spatial data, important queries that involve Euclidean distance are not expressible. The aim of this paper is to identify a class of two-dimensional constraint databases and a query language within the constraint model that go beyond the linear model and allow the expression of queries concerning distance. We seek inspiration in the Euclidean constructions, i.e., constructions by ruler and compass. We first present a programming language that captures exactly the first-order ruler-and-compass constructions that are expressible in a first-order language with real polynomial constraints. If this language is extended with a while operator, we obtain a language that is complete for all ruler-and-compass constructions in the plane. We then transform this language in a natural way into a query language on finite point databases, but this language turns out to have the same expressive power as FO+poly and is therefore too powerful for our purposes. We then consider a safe fragment of this language and use this to construct a query language that allows the expression of Euclidean distance without having the full power of FO+poly.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1570–1599},
numpages = {30},
keywords = {real algebraic geometry, query languages, ruler-and-compass constructions, first-order logic, constraint databases}
}

@article{10.1137/S0097539704446712,
author = {Soloveichik, David and Winfree, Erik},
title = {Complexity of Self-Assembled Shapes},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446712},
doi = {10.1137/S0097539704446712},
abstract = {The connection between self-assembly and computation suggests that a shape can be considered the output of a self-assembly “program,” a set of tiles that fit together to create a shape. It seems plausible that the size of the smallest self-assembly program that builds a shape and the shape’s descriptional (Kolmogorov) complexity should be related. We show that when using a notion of a shape that is independent of scale, this is indeed so: in the tile assembly model, the minimal number of distinct tile types necessary to self-assemble a shape, at some scale, can be bounded both above and below in terms of the shape’s Kolmogorov complexity. As part of the proof, we develop a universal constructor for this model of self-assembly that can execute an arbitrary Turing machine program specifying how to grow a shape. Our result implies, somewhat counterintuitively, that self-assembly of a scaled-up version of a shape often requires fewer tile types. Furthermore, the independence of scale in self-assembly theory appears to play the same crucial role as the independence of running time in the theory of computability. This leads to an elegant formulation of languages of shapes generated by self-assembly. Considering functions from bit strings to shapes, we show that the running-time complexity, with respect to Turing machines, is polynomially equivalent to the scale complexity of the same function implemented via self-assembly by a finite set of tile types. Our results also hold for shapes defined by Wang tiling—where there is no sense of a self-assembly process—except that here time complexity must be measured with respect to nondeterministic Turing machines.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1544–1569},
numpages = {26},
keywords = {self-assembly, scaled shapes, universal constructor, Kolmogorov complexity, Wang tiles}
}

@article{10.1137/S0097539704446384,
author = {Ben-Moshe, Boaz and Katz, Matthew J. and Mitchell, Joseph S. B.},
title = {A Constant-Factor Approximation Algorithm for Optimal 1.5D Terrain Guarding},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446384},
doi = {10.1137/S0097539704446384},
abstract = {We present the first constant-factor approximation algorithm for a nontrivial instance of the optimal guarding (coverage) problem in polygons. In particular, we give an $O(1)$-approximation algorithm for placing the fewest point guards on a 1.5D terrain, so that every point of the terrain is seen by at least one guard. While polylogarithmic-factor approximations follow from set cover results, our new results exploit the geometric structure of terrains to obtain a substantially improved approximation algorithm.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1631–1647},
numpages = {17},
keywords = {approximation algorithms, geometric optimization, guarding}
}

@article{10.1137/S0097539704445366,
author = {Gabow, Harold N.},
title = {Finding Paths and Cycles of Superpolylogarithmic Length},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445366},
doi = {10.1137/S0097539704445366},
abstract = {Let ℓ be the number of edges in a longest cycle containing a given vertex 𝓋 in an undirected graph. We show how to find a cycle through 𝓋 of length exp(Ω(√ log ℓ/log log ℓ)) in polynomial time. This implies the same bound for the longest cycle, longest 𝓋𝓌-path, and longest path. The previous best bound for longest path is length Ω( (log ℓ )2 / log log ℓ) due to Bj\"{o}rklund and Husfeldt. Our approach, which builds on Bj\"{o}rklund and Husfeldt's, uses cycles to enlarge cycles. This self-reducibility allows the approximation method to be iterated.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1648–1671},
numpages = {24},
keywords = {approximation algorithms, graph algorithms, long cycles, long paths}
}

@article{10.1137/S0097539704443793,
author = {Bostan, Alin and Gaudry, Pierrick and Schost, E´ric},
title = {Linear Recurrences with Polynomial Coefficients and Application to Integer Factorization and Cartier-Manin Operator},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704443793},
doi = {10.1137/S0097539704443793},
abstract = {We study the complexity of computing one or several terms (not necessarily consecutive) in a recurrence with polynomial coefficients. As applications, we improve the best currently known upper bounds for factoring integers deterministically and for computing the Cartier-Manin operator of hyperelliptic curves.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1777–1806},
numpages = {30},
keywords = {Cartier-Manin operator, linear recurrences, factorization}
}

@article{10.1137/S0097539703428324,
author = {Arge, Lars and Bender, Michael A. and Demaine, Erik D. and Holland-Minkley, Bryan and Ian Munro, J.},
title = {An Optimal Cache-Oblivious Priority Queue and Its Application to Graph Algorithms},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703428324},
doi = {10.1137/S0097539703428324},
abstract = {We develop an optimal cache-oblivious priority queue data structure, supporting insertion, deletion, and delete-min operations in $O(frac{1}{B}log_{M/B}frac{N}{B})$ amortized memory transfers, where $M$ and $B$ are the memory and block transfer sizes of any two consecutive levels of a multilevel memory hierarchy. In a cache-oblivious data structure, $M$ and $B$ are not used in the description of the structure. Our structure is as efficient as several previously developed external memory (cache-aware) priority queue data structures, which all rely crucially on knowledge about $M$ and $B$. Priority queues are a critical component in many of the best known external memory graph algorithms, and using our cache-oblivious priority queue we develop several cache-oblivious graph algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1672–1695},
numpages = {24},
keywords = {cache-oblivious algorithms, priority queue}
}

@article{10.1137/S0097539703427215,
author = {Fleischer, Lisa and Skutella, Martin},
title = {Quickest Flows Over Time},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703427215},
doi = {10.1137/S0097539703427215},
abstract = {Flows over time (also called dynamic flows) generalize standard network flows by introducing an element of time. They naturally model problems where travel and transmission are not instantaneous. Traditionally, flows over time are solved in time-expanded networks that contain one copy of the original network for each discrete time step. While this method makes available the whole algorithmic toolbox developed for static flows, its main and often fatal drawback is the enormous size of the time-expanded network. We present several approaches for coping with this difficulty. First, inspired by the work of Ford and Fulkerson on maximal $s$-$t$-flows over time (or “maximal dynamic $s$-$t$-flows”), we show that static length-bounded flows lead to provably good multicommodity flows over time. Second, we investigate “condensed” time-expanded networks which rely on a rougher discretization of time. We prove that a solution of arbitrary precision can be computed in polynomial time through an appropriate discretization leading to a condensed time-expanded network of polynomial size. In particular, our approach yields fully polynomial-time approximation schemes for the NP-hard quickest min-cost and multicommodity flow problems. For single commodity problems, we show that storage of flow at intermediate nodes is unnecessary, and our approximation schemes do not use any.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1600–1630},
numpages = {31},
keywords = {approximation algorithms, flows over time, quickest flows, earliest arrival flows, network flows, dynamic flows}
}

@article{10.1137/S0097539703426817,
author = {Dwork, Cynthia and Naor, Moni},
title = {Zaps and Their Applications},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703426817},
doi = {10.1137/S0097539703426817},
abstract = {A zap is a 2-round, public coin witness-indistinguishable protocol in which the first round, consisting of a message from the verifier to the prover, can be fixed “once and for all” and applied to any instance. We present a zap for every language in NP, based on the existence of noninteractive zero-knowledge proofs in the shared random string model. The zap is in the standard model and hence requires no common guaranteed random string. We present several applications for zaps, including 3-round concurrent zero-knowledge and 2-round concurrent deniable authentication, in the timing model of Dwork, Naor, and Sahai [J. ACM, 51 (2004), pp. 851-898], using moderately hard functions. We also characterize the existence of zaps in terms of a primitive called verifiable pseudorandom bit generators.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1513–1543},
numpages = {31},
keywords = {nonmalleable cryptosystems, zero-knowledge}
}

@article{10.1137/050666023,
author = {Schulman, Leonard J. and Mor, Tal and Weinstein, Yossi},
title = {Physical Limits of Heat-Bath Algorithmic Cooling},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/050666023},
doi = {10.1137/050666023},
abstract = {Simultaneous near-certain preparation of qubits (quantum bits) in their ground states is a key hurdle in quantum computing proposals as varied as liquid-state NMR and ion traps. “Closed-system” cooling mechanisms are of limited applicability due to the need for a continual supply of ancillas for fault tolerance and to the high initial temperatures of some systems. “Open-system” mechanisms are therefore required. We describe a new, efficient initialization procedure for such open systems. With this procedure, an $n$-qubit device that is originally maximally mixed, but is in contact with a heat bath of bias $varepsilon gg 2^{-n}$, can be almost perfectly initialized. This performance is optimal due to a newly discovered threshold effect: For bias $varepsilon ll 2^{-n}$ no cooling procedure can, even in principle (running indefinitely without any decoherence), significantly initialize even a single qubit.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1729–1747},
numpages = {19},
keywords = {state preparation, thermodynamics, quantum computation}
}

@article{10.1137/05064727X,
author = {Alekseyev, Max A. and Pevzner, Pavel A.},
title = {Whole Genome Duplications and Contracted Breakpoint Graphs},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/05064727X},
doi = {10.1137/05064727X},
abstract = {The genome halving problem, motivated by the whole genome duplication events in molecular evolution, was solved by El-Mabrouk and Sankoff in the pioneering paper [SIAM J. Comput., 32 (2003), pp. 754-792]. The El-Mabrouk-Sankoff algorithm is rather complex, inspiring a quest for a simpler solution. An alternative approach to the genome halving problem based on the notion of the contracted breakpoint graph was recently proposed in [M. A. Alekseyev and P. A. Pevzner, IEEE/ACM Trans. Comput. Biol. Bioinformatics, 4 (2007), pp. 98-107]. This new technique reveals that while the El-Mabrouk-Sankoff result is correct in most cases, it does not hold in the case of unichromosomal genomes. This raises a problem of correcting a flaw in the El-Mabrouk-Sankoff analysis and devising an algorithm that deals adequately with all genomes. In this paper we efficiently classify all genomes into two classes and show that while the El-Mabrouk-Sankoff theorem holds for the first class, it is incorrect for the second class. The crux of our analysis is a new combinatorial invariant defined on duplicated permutations. Using this invariant we were able to come up with a full proof of the genome halving theorem and a polynomial algorithm for the genome halving problem.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1748–1763},
numpages = {16},
keywords = {breakpoint graph, genome duplication, genome rearrangement, de Bruijn graph, genome halving}
}

@article{10.1137/050627472,
author = {Varadarajan, Kasturi and Venkatesh, S. and Ye, Yinyu and Zhang, Jiawei},
title = {Approximating the Radii of Point Sets},
year = {2007},
issue_date = {February 2007},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/050627472},
doi = {10.1137/050627472},
abstract = {We consider the problem of computing the outer-radii of point sets. In this problem, we are given integers $n, d$, and $k$, where $k le d$, and a set $P$ of $n$ points in $Re^d$. The goal is to compute the outer $k$-radius of $P$, denoted by ${cal R}_k(P)$, which is the minimum over all $(d-k)$-dimensional flats $F$ of $max_{p in P} d(p,F)$, where $d(p,F)$ is the Euclidean distance between the point $p$ and flat $F$. Computing the radii of point sets is a fundamental problem in computational convexity with many significant applications. The problem admits a polynomial time algorithm when the dimension $d$ is constant [U. Faigle, W. Kern, and M. Streng, Math. Program., 73 (1996), pp. 1-5]. Here we are interested in the general case in which the dimension $d$ is not fixed and can be as large as $n$, where the problem becomes NP-hard even for $k=1$. It is known that $R_k(P)$ can be approximated in polynomial time by a factor of $(1 + varepsilon)$ for any $varepsilon &gt; 0$ when $d - k$ is a fixed constant [M. Ba˘doiu, S. Har-Peled, and P. Indyk, in Proceedings of the ACM Symposium on the Theory of Computing, 2002; S. Har-Peled and K. Varadarajan, in Proceedings of the ACM Symposium on Computing Geometry, 2002]. A polynomial time algorithm that guarantees a factor of $O(sqrt{log n})$ approximation for $R_1(P)$, the width of the point set $P$, is implied by the results of Nemirovski, Roos, and Terlaky [Math. Program., 86 (1999), pp. 463-473] and Nesterov [Handbook of Semidefinite Programming Theory, Algorithms, Kluwer Academic Publishers, Norwell, MA, 2000]. In this paper, we show that $R_k(P)$ can be approximated by a ratio of $O(sqrt{log n})$ for any $1 leq k leq d$, thus matching the previously best known ratio for approximating the special case $R_1 (P)$, the width of point set $P$. Our algorithm is based on semidefinite programming relaxation with a new mixed deterministic and randomized rounding procedure. We also prove an inapproximability result that gives evidence that our approximation algorithm is doing well for a large range of $k$. We show that there exists a constant $delta &gt; 0$ such that the following holds for any $0 &lt; eps &lt; 1$: there is no polynomial time algorithm that approximates $R_k(P)$ within $(log n)^{delta}$ for all $k$ such that $k leq d - d^{varepsilon}$ unless NP $subseteq$ DTIME $[2^{(log m)^{O(1)}}]$. Our inapproximability result for $R_k(P)$ extends a previously known hardness result of Brieden [Discrete Comput. Geom., 28 (2002), pp. 201-209] and is proved by modifying Brieden’s construction using basic ideas from probabilistically checkable proofs (PCP) theory.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1764–1776},
numpages = {13},
keywords = {computational convexity, approximation algorithms, semidefinite programming}
}

@article{10.5555/1328008.1328018,
author = {Goldreich, Oded},
title = {Special Issue on Randomness and Complexity},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
abstract = {The idea of a SICOMP special issue on randomness and complexity occurred to us when we were in residence at the Radcliffe Institute for Advanced Study at Harvard University during the academic year 2003-2004. We were part of a science cluster in theoretical computer science at the Radcliffe Institute whose other members were Eli Ben-Sasson, Dana Ron, Ronitt Rubinfeld, and Salil Vadhan. The focus of this cluster was randomness and computation. The extensive interaction within the cluster members as well as with frequent visitors (most notably Irit Dinur, Shafi Goldwasser, and Tali Kaufman) made us more aware than ever of the richness of the area, and the idea of editing a special issue on randomness and complexity emerged naturally.The interplay of randomness and complexity is at the heart of modern cryptography and plays a fundamental role in the design of algorithms and in complexity theory at large. Specifically, this interplay is pivotal to several intriguing notions of probabilistic proof systems (e.g., interactive proofs, zero-knowledge proofs, and probabilistically checkable proofs), is the focus of the computational approach to randomness, and is essential for various types of sub-linear time algorithms. All these areas were at the focus of extensive research in the last two decades, but each research generation brings its own new perspective (and/or focus) to them. This special issue reports some of the recent progress achieved in these related areas, where recent relates to spring 2004, when papers were invited for this issue. Following are some of the issue’s main themes.Cryptography. The paper of Applebaum, Ishai, and Kushilevitz provides strong evidence that many cryptographic primitives and tasks can be implemented at very low complexity. For example, they show that the existence of one-way functions that can be evaluated in ${ cal NC}1$ implies the existence of one-way functions that can be evaluated in ${cal NC}0$. Whereas the former are widely believed to exist (e.g., based on the standard factoring assumption), most researchers have previously believed that the latter do not exist. We stress that evaluation in ${cal NC}0$ means that each output bit only depends on a constant number of input bits. The new work further shows that dependence on four input bits suffices (whereas dependence on at least three input bits is definitely necessary).Probabilistically checkable proofs (PCPs). Current research in the area is marked by a renewed attention to aspects such as the following:1. Achieving constructs of almost-linear length that can be tested by very few (say constant number of) queries.2. Obtaining a combinatorial proof of the PCP theorem.3. Exploration of the relationship between PCP and coding theory (e.g., locally testable codes).4. Applications of PCPs to obtaining new inapproximability results regarding long-standing problems such as min-bisection.Specifically, the paper of Ben-Sasson et al. presents significant improvements to the trade-off between proof-length and the number of queries. The paper of Dinur and Reingold makes a major step in the project of obtaining combinatorial proofs of the PCP theorem. Both papers share a reformulation of the proof-composition paradigm, where “proximity testing” and “robustness” play a central role. Finally, Khot’s paper puts forward new PCP parameters and introduces new PCP constructions that are used to provide evidence that min-bisection is not approximable up to some constant.Randomness extraction. The construction of randomness extractors has received much attention in the last two decades. Much of the past work (especially in the 1990s) has focused on extracting randomness from a single weak source while using an auxiliary short (uniformly distributed) seed. The focus was on using the weakest possible form of a source (i.e., a min-entropy source). In contrast, the current era is marked by a focus on stronger sources while disallowing the use of an auxiliary (uniformly distributed) seed. The paper of Gabizon, Raz, and Shaltiel studies bit-fixing sources, whereas the paper of Barak, Impagliazzo, and Wigderson studies extraction from a constant number of independent sources of linear min-entropy (which may be viewed as a single source consisting of a constant number of independent blocks). Indeed, each of these papers revisits problems raised in the mid 1980s, which were neglected in the 1990s (due to the focus of that era on obtaining the best results for seed-assisted extraction from a single min-entropy source). Needless to say, we believe that the renewed interest in these problems (especially the second one) is highly justified.We wish to seize the opportunity to say a few words regarding seed-assisted versus seedless randomness extraction. Seed-assisted randomness extraction found many applications (via direct and indirect connections to other important problems), but still one may ask what they mean for the original problem of implementing a randomized procedure using a weak source of randomness. One answer is that the seed can be obtained from an expensive high-quality auxiliary source and that one wishes to minimize the use of this source (and thus uses a cheaper low-quality random source for the bulk of the randomness required). Another answer is that if the seed is short enough, then one may afford to try all possible seeds, invoke the procedure with the corresponding randomness extracted (from the same source output and varying seeds), and rule by majority. This suggestion is adequate for the implementation of standard randomized algorithms, but not in “adversarial” settings (e.g., cryptography) in which a randomized procedure is invoked in order to protect against some (adversarial) party. Thus, seedless randomness extraction is essential in many applications.Worst-case to average-case reductions. The question of whether worst-case to average-case reductions or even merely “hardness amplification” exist for $cal{NP}$ has received much interest recently. The first part of the question is studied in the paper of Bogdanov and Trevisan which provides a negative indication, restricted to nonadaptive reductions. The second part of the question is unfortunately not represented in this special issue (and the interested reader is directed to [1]).Zero-knowledge. Vadhan’s paper presents an unconditional study of computational zero-knowledge, yielding valuable transformations between various forms of zero-knowledge (e.g., from a weak form of zero-knowledge to the standard form). This work builds on studies of statistical zero-knowledge that were conducted in the late 1990s, thus fulfilling a prophecy made at the time.Low-degree tests. The celebrated low-degree tests have been revisited recently with a focus on derandomization and on low-degree tests over small finite fields. The first direction is represented by the work of Shpilka and Wigderson that seems to provide a “proof from The Book” for (a derandomized version of) the linearity test. The second direction is unfortunately not represented in this special issue (and the interested reader is directed to [2, 3]).},
journal = {SIAM J. Comput.},
month = dec,
pages = {.9–.11},
numpages = {1}
}

@article{10.1137/S0097539705447207,
author = {Vadhan, Salil P.},
title = {An Unconditional Study of Computational Zero Knowledge},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447207},
doi = {10.1137/S0097539705447207},
abstract = {We prove a number of general theorems about ZK, the class of problems possessing (computational) zero-knowledge proofs. Our results are unconditional, in contrast to most previous works on ZK, which rely on the assumption that one-way functions exist. We establish several new characterizations of ZK and use these characterizations to prove results such as the following:1. Honest-verifier ZK equals general ZK.2. Public-coin ZK equals private-coin ZK.3. ZK is closed under union.4. ZK with imperfect completeness equals ZK with perfect completeness.5. Any problem in ${bf ZK} cap {bf NP}$ can be proven in computational zero knowledge by a ${bf BPP}^{{bf NP}}$ prover.6. ZK with black-box simulators equals ZK with general, non-black-box simulators.The above equalities refer to the resulting class of problems (and do not necessarily preserve other efficiency measures such as round complexity). Our approach is to combine the conditional techniques previously used in the study of ZK with the unconditional techniques developed in the study of SZK, the class of problems possessing statistical zero-knowledge proofs. To enable this combination, we prove that every problem in ZK can be decomposed into a problem in SZK together with a set of instances from which a one-way function can be constructed.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1160–1214},
numpages = {55},
keywords = {cryptography, zero-knowledge proofs, language-dependent commitment schemes, pseudoentropy, auxiliary-input one-way functions, computational complexity}
}

@article{10.1137/S0097539705447141,
author = {Barak, Boaz and Impagliazzo, Russell and Wigderson, Avi},
title = {Extracting Randomness Using Few Independent Sources},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447141},
doi = {10.1137/S0097539705447141},
abstract = {In this work we give the first deterministic extractors from a constant number of weak sources whose entropy rate is less than 1/2. Specifically, for every $delta &gt;0$ we give an explicit construction for extracting randomness from a constant (depending polynomially on $1/delta$) number of distributions over $bits^n$, each having min-entropy $delta n$. These extractors output $n$ bits that are $2^{-n}$ close to uniform. This construction uses several results from additive number theory, and in particular a recent result of Bourgain et al. We also consider the related problem of constructing randomness dispersers. For any constant output length $m$, our dispersers use a constant number of identical distributions, each with requires min-entropy $Omega(log n)$, and outputs every possible $m$-bit string with positive probability. The main tool we use is a variant of the “stepping-up lemma” of Erdo˝s and Hajnal used in establishing a lower bound on the Ramsey number for hypergraphs.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1095–1118},
numpages = {24},
keywords = {Ramsey graphs, randomness extractors, sum-product theorem}
}

@article{10.1137/S009753970544713X,
author = {Boneh, Dan and Canetti, Ran and Halevi, Shai and Katz, Jonathan},
title = {Chosen-Ciphertext Security from Identity-Based Encryption},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970544713X},
doi = {10.1137/S009753970544713X},
abstract = {We propose simple and efficient CCA-secure public-key encryption schemes (i.e., schemes secure against adaptive chosen-ciphertext attacks) based on any identity-based encryption (IBE) scheme. Our constructions have ramifications of both theoretical and practical interest. First, our schemes give a new paradigm for achieving CCA-security; this paradigm avoids “proofs of well-formedness” that have been shown to underlie previous constructions. Second, instantiating our construction using known IBE constructions we obtain CCA-secure encryption schemes whose performance is competitive with the most efficient CCA-secure schemes to date. Our techniques extend naturally to give an efficient method for securing IBE schemes (even hierarchical ones) against adaptive chosen-ciphertext attacks. Coupled with previous work, this gives the first efficient constructions of CCA-secure IBE schemes.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1301–1328},
numpages = {28},
keywords = {public-key encryption, chosen-ciphertext security, identity-based encryption}
}

@article{10.1137/S0097539705447049,
author = {Gabizon, Ariel and Raz, Ran and Shaltiel, Ronen},
title = {Deterministic Extractors for Bit-Fixing Sources by Obtaining an Independent Seed},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447049},
doi = {10.1137/S0097539705447049},
abstract = {An $(n,k)$-bit-fixing source is a distribution $X$ over ${0,1}^n$ such that there is a subset of $k$ variables in $X_1,ldots,X_n$ which are uniformly distributed and independent of each other, and the remaining $n-k$ variables are fixed. A deterministic bit-fixing source extractor is a function $E:{0,1}^n rightarrow {0,1}^m$ which on an arbitrary $(n,k)$-bit-fixing source outputs $m$ bits that are statistically close to uniform. Recently, Kamp and Zuckerman [Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, 2003, pp. 92-101] gave a construction of a deterministic bit-fixing source extractor that extracts $Omega(k^2/n)$ bits and requires $k&gt;sqrt{n}$.In this paper we give constructions of deterministic bit-fixing source extractors that extract $(1-o(1))k$ bits whenever $k&gt;(log n)^c$ for some universal constant $c&gt;0$. Thus, our constructions extract almost all the randomness from bit-fixing sources and work even when $k$ is small. For $k gg sqrt{n}$ the extracted bits have statistical distance $2^{-n^{Omega(1)}}$ from uniform, and for $k le sqrt{n}$ the extracted bits have statistical distance $k^{-Omega(1)}$ from uniform.Our technique gives a general method to transform deterministic bit-fixing source extractors that extract few bits into extractors which extract almost all the bits.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1072–1094},
numpages = {23},
keywords = {seed obtainers, bit-fixing sources, deterministic extractors, seeded extractors, derandomization}
}

@article{10.1137/S0097539705447037,
author = {Khot, Subhash},
title = {Ruling Out PTAS for Graph Min-Bisection, Dense k-Subgraph, and Bipartite Clique},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447037},
doi = {10.1137/S0097539705447037},
abstract = {Assuming that NP $notsubseteq$ $cap_{epsilon &gt; 0}$ BPTIME($2^{n^epsilon}$), we show that graph min-bisection, dense $k$-subgraph, and bipartite clique have no polynomial time approximation scheme (PTAS). We give a reduction from the minimum distance of code (MDC) problem. Starting with an instance of MDC, we build a quasi-random probabilistically checkable proof (PCP) that suffices to prove the desired inapproximability results. In a quasi-random PCP, the query pattern of the verifier looks random in a certain precise sense. Among the several new techniques we introduce, the most interesting one gives a way of certifying that a given polynomial belongs to a given linear subspace of polynomials. As is important for our purpose, the certificate itself happens to be another polynomial, and it can be checked probabilistically by reading a constant number of its values.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1025–1071},
numpages = {47},
keywords = {hardness of approximation, approximation algorithms, probabilistically checkable proofs (PCPs)}
}

@article{10.1137/S0097539705447013,
author = {Hemaspaandra, Lane A. and Homan, Christopher M. and Kosub, Sven and Wagner, Klaus W.},
title = {The Complexity of Computing the Size of an Interval},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447013},
doi = {10.1137/S0097539705447013},
abstract = {Given a p-order $A$ over a universe of strings (i.e., a transitive, reflexive, antisymmetric relation such that if $(x, y) in A$, then $|x|$ is polynomially bounded by $|y|$), an interval size function of $A$ returns, for each string $x$ in the universe, the number of strings in the interval between strings $b(x)$ and $t(x)$ (with respect to $A$), where $b(x)$ and $t(x)$ are functions that are polynomial-time computable in the length of $x$. By choosing sets of interval size functions based on feasibility requirements for their underlying p-orders, we obtain new characterizations of complexity classes. We prove that the set of all interval size functions whose underlying p-orders are polynomial-time decidable is exactly &amp;mesh;P. We show that the interval size functions for orders with polynomial-time adjacency checks are closely related to the class FPSPACE(poly). Indeed, FPSPACE(poly) is exactly the class of all nonnegative functions that are an interval size function minus a polynomial-time computable function. We study two important functions in relation to interval size functions. The function &amp;mesh;DIV maps each natural number $n$ to the number of nontrivial divisors of $n$. We show that &amp;mesh;DIV is an interval size function of a polynomial-time decidable partial p-order with polynomial-time adjacency checks. The function &amp;mesh;MONSAT maps each monotone boolean formula $F$ to the number of satisfying assignments of $F$. We show that &amp;mesh;MONSAT is an interval size function of a polynomial-time decidable total p-order with polynomial-time adjacency checks. Finally, we explore the related notion of cluster computation.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1264–1300},
numpages = {37},
keywords = {counting functions, interval size functions, computational complexity, cluster computing}
}

@article{10.1137/S0097539705446974,
author = {Bogdanov, Andrej and Trevisan, Luca},
title = {On Worst-Case to Average-Case Reductions for NP Problems},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446974},
doi = {10.1137/S0097539705446974},
abstract = {We show that if an NP-complete problem has a nonadaptive self-corrector with respect to any samplable distribution, then coNP is contained in NP/poly and the polynomial hierarchy collapses to the third level. Feigenbaum and Fortnow [SIAM J. Comput., 22 (1993), pp. 994-1005] show the same conclusion under the stronger assumption that an NP-complete problem has a nonadaptive random self-reduction. A self-corrector for a language L with respect to a distribution $cal D$ is a worst-case to average-case reduction that transforms any given algorithm that correctly decides $L$ on most inputs (with respect to $cal D$) into an algorithm of comparable efficiency that decides L correctly on every input. A random self-reduction is a special case of a self-corrector, where the reduction, given an input $x$, is restricted to only making oracle queries that are distributed according to $cal D$. The result of Feigenbaum and Fortnow depends essentially on the property that the distribution of each query in a random self-reduction is independent of the input of the reduction. Our result implies that the average-case hardness of a problem in NP or the security of a one-way function cannot be based on the worst-case complexity of an NP-complete problem via nonadaptive reductions (unless the polynomial hierarchy collapses).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1119–1159},
numpages = {41},
keywords = {one-way function, average-case complexity, worst-case to average-case reduction}
}

@article{10.1137/S0097539705446962,
author = {Dinur, Irit and Reingold, Omer},
title = {Assignment Testers: Towards a Combinatorial Proof of the PCP Theorem},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446962},
doi = {10.1137/S0097539705446962},
abstract = {In this work we look back into the proof of the PCP (probabilistically checkable proofs) theorem, with the goal of finding new proofs that are “more combinatorial” and arguably simpler. For that we introduce the notion of an assignment tester, which is a strengthening of the standard PCP verifier, in the following sense. Given a statement and an alleged proof for it, while the PCP verifier checks correctness of the statement, the assignment tester checks correctness of the statement and the proof. This notion enables composition that is truly modular; i.e., one can compose two assignment testers without any assumptions on how they are constructed. A related notion called PCPs of proximity was independently introduced in [E. Ben-Sasson et al., Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, 2004, ACM, New York, 2004, pp. 1-10]. We provide a toolkit of (nontrivial) generic transformations on assignment testers. These transformations may be interesting in their own right, and allow us to present the following two main results: 1. A new proof of the PCP theorem. This proof relies on a rather weak assignment tester given as a “black box.” From this, we construct combinatorially the full PCP. An important component of this proof is a new combinatorial aggregation technique (i.e., a new transformation that allows the verifier to read fewer, though possibly longer, “pieces” of the proof). An implementation of the black-box tester can be obtained from the algebraic proof techniques that already appear in [L. Babai et al., Proceedings of the 23rd ACM Symposium on Theory of Computing, New Orleans, LA, 1991, ACM, New York, 1991, pp. 21-31; U. Feige et al., J. ACM, 43 (1996), pp. 268-292]. 2. Our second construction is a “standalone” combinatorial construction showing $NP subseteq PCP[polylog, 1]$. This implies, for example, that approximating max-SAT is quasi-NP-hard. This construction relies on a transformation that makes an assignment tester “oblivious,” so that the proof locations read are independent of the statement that is being proven. This eliminates, in a rather surprising manner, the need for aggregation in a crucial point in the proof.},
journal = {SIAM J. Comput.},
month = dec,
pages = {975–1024},
numpages = {50},
keywords = {assignment tester, combinatorial proof, PCP theorem}
}

@article{10.1137/S0097539705446950,
author = {Applebaum, Benny and Ishai, Yuval and Kushilevitz, Eyal},
title = {Cryptography in $NC^0$},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446950},
doi = {10.1137/S0097539705446950},
abstract = {We study the parallel time-complexity of basic cryptographic primitives such as one-way functions (OWFs) and pseudorandom generators (PRGs). Specifically, we study the possibility of implementing instances of these primitives by $NC^0$ functions, namely, by functions in which each output bit depends on a constant number of input bits. Despite previous efforts in this direction, there has been no convincing theoretical evidence supporting this possibility, which was posed as an open question in several previous works.We essentially settle this question by providing strong positive evidence for the possibility of cryptography in $NC^0$. Our main result is that every “moderately easy” OWF (resp., PRG), say computable in $NC^1$, can be compiled into a corresponding OWF (resp., “low-stretch” PRG) in which each output bit depends on at most 4 input bits. The existence of OWFs and PRGs in $NC^1$ is a relatively mild assumption, implied by most number-theoretic or algebraic intractability assumptions commonly used in cryptography. A similar compiler can also be obtained for other cryptographic primitives such as one-way permutations, encryption, signatures, commitment, and collision-resistant hashing.Our techniques can also be applied to obtain (unconditional) constructions of “noncryptographic” PRGs. In particular, we obtain ε-biased generators and a PRG for space-bounded computation in which each output bit depends on only 3 input bits.Our results make use of the machinery of randomizing polynomials [Y. Ishai and E. Kushilevitz, Proceedings of the 41st Annual IEEE Symposium on Foundations of Computer Science (FOCS), 2000, pp. 294-304], which was originally motivated by questions in the domain of information-theoretic secure multiparty computation.},
journal = {SIAM J. Comput.},
month = dec,
pages = {845–888},
numpages = {44},
keywords = {$NC^0$, one-way function, randomizing polynomials, constant depth circuits, cryptography, pseudo-random generator, cryptographic primitives}
}

@article{10.1137/S0097539705446846,
author = {Kamp, Jesse and Zuckerman, David},
title = {Deterministic Extractors for Bit-Fixing Sources and Exposure-Resilient Cryptography},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446846},
doi = {10.1137/S0097539705446846},
abstract = {We give an efficient deterministic algorithm that extracts $Omega(n^{2gamma})$ almost-random bits from sources where $n^{frac{1}{2}+gamma}$ of the $n$ bits are uniformly random and the rest are fixed in advance. This improves upon previous constructions, which required that at least $n/2$ of the bits be random in order to extract many bits. Our construction also has applications in exposure-resilient cryptography, giving explicit adaptive exposure-resilient functions and, in turn, adaptive all-or-nothing transforms. For sources where instead of bits the values are chosen from $[d]$, for $d&gt;2$, we give an algorithm that extracts a constant fraction of the randomness. We also give bounds on extracting randomness for sources where the fixed bits can depend on the random bits.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1231–1247},
numpages = {17},
keywords = {bit-fixing sources, cryptography, exposure-resilient, extractors, deterministic, random walks, resilient function, randomness}
}

@article{10.1137/S0097539705446810,
author = {Ben-Sasson, Eli and Goldreich, Oded and Harsha, Prahladh and Sudan, Madhu and Vadhan, Salil},
title = {Robust PCPs of Proximity, Shorter PCPs, and Applications to Coding},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446810},
doi = {10.1137/S0097539705446810},
abstract = {We continue the study of the trade-off between the length of probabilistically checkable proofs (PCPs) and their query complexity, establishing the following main results (which refer to proofs of satisfiability of circuits of size $n$):1. We present PCPs of length $exp(o(loglog n)^2)cdot n$ that can be verified by making $o(loglog n)$ Boolean queries.2. For every epsilon&gt;0, we present PCPs of length $exp(log^epsilon n)cdot n$ that can be verified by making a constant number of Boolean queries.In both cases, false assertions are rejected with constant probability (which may be set to be arbitrarily close to 1). The multiplicative overhead on the length of the proof, introduced by transforming a proof into a probabilistically checkable one, is just quasi polylogarithmic in the first case (of query complexity $o(loglog n)$), and is $2^{(log n)^epsilon}$, for any $epsilon &gt; 0$, in the second case (of constant query complexity). Our techniques include the introduction of a new variant of PCPs that we call “robust PCPs of proximity.” These new PCPs facilitate proof composition, which is a central ingredient in the construction of PCP systems. (A related notion and its composition properties were discovered independently by Dinur and Reingold.) Our main technical contribution is a construction of a “length-efficient” robust PCP of proximity. While the new construction uses many of the standard techniques used in PCP constructions, it does differ from previous constructions in fundamental ways, and in particular does not use the “parallelization” step of Arora et al. [J. ACM, 45 (1998), pp. 501-555]. The alternative approach may be of independent interest. We also obtain analogous quantitative results for locally testable codes. In addition, we introduce a relaxed notion of locally decodable codes and present such codes mapping $k$ information bits to codewords of length $k^{1+epsilon}$ for any $epsilon&gt;0$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {889–974},
numpages = {86},
keywords = {property testing, locally decodable codes, probabilistically checkable proofs, locally testable codes, PCP}
}

@article{10.1137/S0097539704446682,
author = {Chen, Ke and Fiat, Amos and Kaplan, Haim and Levy, Meital and Matousˇek, Jirˇi´ and Mossel, Elchanan and Pach, Ja´nos and Sharir, Micha and Smorodinsky, Shakhar and Wagner, Uli and Welzl, Emo},
title = {Online Conflict-Free Coloring for Intervals},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446682},
doi = {10.1137/S0097539704446682},
abstract = {We consider an online version of the conflict-free coloring of a set of points on the line, where each newly inserted point must be assigned a color upon insertion, and at all times the coloring has to be conflict-free, in the sense that in every interval $I$ there is a color that appears exactly once in $I$. We present deterministic and randomized algorithms for achieving this goal, and analyze their performance, that is, the maximum number of colors that they need to use, as a function of the number $n$ of inserted points. We first show that a natural and simple (deterministic) approach may perform rather poorly, requiring $Omega(sqrt{n})$ colors in the worst case. We then derive two efficient variants of this simple algorithm. The first is deterministic and uses $O(log^2 n)$ colors, and the second is randomized and uses $O(log n)$ colors with high probability. We also show that the $O(log^2 n)$ bound on the number of colors used by our deterministic algorithm is tight on the worst case. We also analyze the performance of the simplest proposed algorithm when the points are inserted in a random order and present an incomplete analysis that indicates that, with high probability, it uses only $O(log n)$ colors. Finally, we show that in the extension of this problem to two dimensions, where the relevant ranges are disks, $n$ colors may be required in the worst case.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1342–1359},
numpages = {18},
keywords = {randomized algorithms, branching processes, online algorithms, conflict-free coloring}
}

@article{10.1137/S009753970444658X,
author = {Shpilka, Amir and Wigderson, Avi},
title = {Derandomizing Homomorphism Testing in General Groups},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444658X},
doi = {10.1137/S009753970444658X},
abstract = {The main result of this paper is a near-optimal derandomization of the affine homomorphism test of Blum, Luby, and Rubinfeld [J. Comput. System Sci., 47 (1993), pp. 549-595].We show that for any groups G and Γ, and any expanding generating set S of G, the natural deramdomized version of the BLR test in which we pick an element x randomly from G and y randomly from S and test whether $f(x)cdot f(y)=f(xcdot y)$, performs nearly as well (depending of course on the expansion) as the original test. Moreover, we show that the underlying homomorphism can be found by the natural local “belief propagation decoding.”We note that the original BLR test uses $2log_2 |G|$ random bits, whereas the derandomized test uses only $(1+o(1))log_2 |G|$ random bits. This factor of 2 savings in the randomness complexity translates to a near quadratic savings in the length of the tables in the related locally testable codes (and possibly probabilistically checkable proofs which may use them).Our result is a significant generalization of recent results that either refer to the special case of the groups $G=Z_p^m$ and $Γ =Z_p$ or are nonconstructive. We use simple combinatorial arguments and the transitivity of Cayley graphs (and this analysis gives optimal results up to constant factors). Previous techniques used the Fourier transform, a method which seems unextendable to general groups (and furthermore gives suboptimal bounds).Finally, we provide a polynomial time (in $|G|$) construction of a (somewhat) small ($|G|^{epsilon}$) set of expanding generators for every group $G$, which yield efficient testers of randomness $(1+epsilon) log |G|$ for $G$. This result follows from a simple derandomization of a known probabilistic construction.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1215–1230},
numpages = {16},
keywords = {homomorphism testing, derandomization, linearity testing}
}

@article{10.1137/S0097539704445718,
author = {Halperin, Eran and Kortsarz, Guy and Krauthgamer, Robert and Srinivasan, Aravind and Wang, Nan},
title = {Integrality Ratio for Group Steiner Trees and Directed Steiner Trees},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445718},
doi = {10.1137/S0097539704445718},
abstract = {The natural relaxation for the group Steiner tree problem, as well as for its generalization, the directed Steiner tree problem, is a flow-based linear programming relaxation. We prove new lower bounds on the integrality ratio of this relaxation. For the group Steiner tree problem, we show that the integrality ratio is $Omega(log^2 k)$, where $k$ denotes the number of groups; this holds even for input graphs that are hierarchically well-separated trees, introduced by Bartal [in Proceedings of the 37th Annual IEEE Symposium on Foundations of Computer Science, 1996, pp. 184-193], in which case this lower bound is tight. This also applies for the directed Steiner tree problem. In terms of the number $n$ of vertices, our results for the directed Steiner problem imply an $Omega(frac{log^2 n}{(log log n)^2})$ integrality ratio. For both problems, these are the first lower bounds on the integrality ratio that are superlogarithmic in the input size. This exhibits, for the first time, a relaxation of a natural optimization problem whose integrality ratio is known to be superlogarithmic but subpolynomial. Our results and techniques have been used by Halperin and Krauthgamer [in Proceedings of the 35th Annual ACM Symposium on Theory of Computing, 2003, pp. 585-594] to show comparable inapproximability results, assuming that NP has no quasi-polynomial Las Vegas algorithms. We also show algorithmically that the integrality ratio for the group Steiner tree problem is much better for certain families of instances, which helps pinpoint the types of instances (parametrized by optimal solutions to their flow-based relaxations) that appear to be most difficult to approximate.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1494–1511},
numpages = {18},
keywords = {linear programming relaxation, integrality ratio, group Steiner tree, flow-based relaxation, directed Steiner tree, approximation algorithms}
}

@article{10.1137/S0097539704442726,
author = {Chrobak, Marek and Ga¸sieniec, Leszek and Kowalski, Dariusz R.},
title = {The Wake-Up Problem in MultiHop Radio Networks},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442726},
doi = {10.1137/S0097539704442726},
abstract = {We study the problem of waking up a collection of $n$ processors connected by a multihop ad hoc ratio network with unknown topology, no access to a global clock, and no collision detection mechanism available. Each node in the network either wakes up spontaneously or gets activated by receiving a wake-up signal from another node. All active nodes transmit the wake-up signals according to a given protocol $calW$. The running time of $calW$ is the number of steps counted from the first spontaneous wake-up until all nodes become activated. We provide two protocols for this problem. The first one is a deterministic protocol with running time $O(n^{5/3}log n)$. Our protocol is based on a novel concept of a shift-tolerant selector to which we refer as a (radio) synchronizer. The second protocol is randomized, and its expected running time is $O(D log^2 n)$, where $D$ is the diameter of the network. Subsequently we show how to employ our wake-up protocols to solve two other communication primitives: leader election and clock synchronization.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1453–1471},
numpages = {19},
keywords = {wake-up, radio network, gossiping, probabilistic method, broadcasting}
}

@article{10.1137/S0097539704440107,
author = {Alekhnovich, Mikhail and Ben-Sasson, Eli},
title = {Linear Upper Bounds for Random Walk on Small Density Random $3$-CNFs},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704440107},
doi = {10.1137/S0097539704440107},
abstract = {We analyze the efficiency of the random walk algorithm on random $3$-CNF instances and prove linear upper bounds on the running time of this algorithm for small clause density, less than $1.63$. This is the first subexponential upper bound on the running time of a local improvement algorithm on random instances. Our proof introduces a simple, yet powerful tool for analyzing such algorithms, which may be of further use. This object, called a terminator, is a weighted satisfying assignment. We show that any CNF having a good (small weight) terminator is assured to be solved quickly by the random walk algorithm. This raises the natural question of the terminator threshold which is the maximal clause density for which such assignments exist (with high probability). We use the analysis of the pure literal heuristic presented by Broder, Frieze, and Upfal [Proceedings of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms, 1993, pp. 322-330] and Luby, Mitzenmacher, and Shokrollahi [Proceedings of the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, 1998, pp. 364-373] and show that for small clause densities good terminators exist. Thus we show that the pure literal threshold ($approx$1.63) is a lower bound on the terminator threshold. (We conjecture the terminator threshold to be in fact higher.) One nice property of terminators is that they can be found efficiently via linear programming. This makes tractable the future investigation of the terminator threshold and also provides an efficiently computable certificate for short running time of the simple random walk heuristic.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1248–1263},
numpages = {16},
keywords = {SAT solving, random CNF, SAT heuristics, random walk algorithm}
}

@article{10.1137/S0097539701391518,
author = {Frieze, Alan and Sorkin, Gregory B.},
title = {The Probabilistic Relationship Between the Assignment and Asymmetric Traveling Salesman Problems},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701391518},
doi = {10.1137/S0097539701391518},
abstract = {We consider the gap between the cost of an optimal assignment in a complete bipartite graph with random edge weights, and the cost of an optimal traveling salesman tour in a complete directed graph with the same edge weights. Using an improved “patching” heuristic, we show that with high probability the gap is $O((ln n)^2/n)$, and that its expectation is $Omega(1/n)$. One of the underpinnings of this result is that the largest edge weight in an optimal assignment has expectation $Theta(ln n / n)$. A consequence of the small assignment-TSP gap is an $e^{tilde{O}(sqrt{n})}$-time algorithm which, with high probability, exactly solves a random asymmetric traveling salesman instance. In addition to the assignment-TSP gap, we also consider the expected gap between the optimal and second-best assignments; it is at least $Omega(1/n^2)$ and at most $O(ln n/n^2)$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1435–1452},
numpages = {18},
keywords = {cycle cover, patching heuristic, matching, permutation digraph, asymmetric traveling salesman problem, near-permutation digraph, average-case analysis of algorithms, alternating path, random assignment problem, assignment problem}
}

@article{10.1137/06065430X,
author = {Chuzhoy, Julia and Naor, Joseph (Seffi)},
title = {The Hardness of Metric Labeling},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/06065430X},
doi = {10.1137/06065430X},
abstract = {The metric labeling problem is an elegant and powerful mathematical model capturing a wide range of classification problems. The input to the problem consists of a set $L$ of labels and a weighted graph $G=(V,E)$. Additionally, a metric distance function on the labels is defined, and for each label and each vertex, an assignment cost is given. The goal is to find a minimum-cost assignment of the vertices to the labels. The cost of the solution consists of two parts: the assignment costs of the vertices and the separation costs of the edges (where each edge pays its weight times the distance between the two labels to which its endpoints are assigned). Due to the simple structure and the variety of applications, the problem and its special cases (with various distance functions on the labels) have recently received much attention. Metric labeling is known to have a logarithmic approximation, and it has been an open question for some time whether a constant approximation exists. We refute this possibility and prove that no constant factor approximation algorithm exists for metric labeling unless P=NP. Moreover, we prove that the problem is $\Omega((\log |V|)^{1/2-\delta})$-hard to approximate for any constant $\delta: 0<\delta<1/2$, unless NP has quasi-polynomial time algorithms.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1376–1386},
numpages = {11},
keywords = {metric labeling, hardness of approximation, classification}
}

@article{10.1137/050640941,
author = {Viola, Emanuele},
title = {Pseudorandom Bits for Constant-Depth Circuits with Few Arbitrary Symmetric Gates},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050640941},
doi = {10.1137/050640941},
abstract = {We exhibit an explicitly computable pseudorandom generator stretching $l$ bits into $m(l) = l^{Omega(log l)}$ bits that look random to constant-depth circuits of size $m(l)$ with $log m(l)$ arbitrary symmetric gates (e.g., PARITY, MAJORITY). This improves on a generator by Luby, Velickovic, and Wigderson [Proceedings of the Second Israel Symposium on Theory of Computing Systems, 1993, pp. 18-24] that achieves the same stretch but fools only circuits of depth 2 with one arbitrary symmetric gate at the top. Our generator fools a strictly richer class of circuits than Nisan’s generator for constant-depth circuits (but Nisan’s generator has a much bigger stretch) [Combinatorica, 11 (1991), pp. 63-70]. In particular, we conclude that every function computable by uniform $poly(n)$-size probabilistic constant-depth circuits with $O(log n)$ arbitrary symmetric gates is in $mathit{TIME}(2^{n^{o(1)}})$. This seems to be the richest probabilistic circuit class known to admit a subexponential derandomization. Our generator is obtained by constructing an explicit function $f : zo^n to zo$ that is very hard on average for constant-depth circuits of size $s(n) = n^{Omega(log n)}$ with $log s(n)$ arbitrary symmetric gates, and plugging it into the Nisan-Wigderson pseudorandom generator construction [J. Comput. System Sci., 49 (1994), pp. 149-167]. The proof of the average-case hardness of this function is a modification of arguments by Razborov and Wigderson [Inform. Process. Lett., 45 (1993), pp. 303-307] and Hansen and Miltersen [Proceedings of the 29th International Symposium on Mathematical Foundations of Computer Science, Lecture Notes in Comput. Sci. 3153, Springer-Verlag, Berlin, 2004, pp. 334-345] and combines Ha˚stad’s switching lemma [Computational Limitations of Small-Depth Circuits, MIT Press, Cambridge, MA, 1987] with a multiparty communication complexity lower bound by Babai, Nisan, and Szegedy [J. Comput. System Sci., 45 (1992), pp. 204-232].},
journal = {SIAM J. Comput.},
month = dec,
pages = {1387–1403},
numpages = {17},
keywords = {constant-depth circuit, average-case hardness, symmetric gate, derandomization, lower bound, pseudorandom generator, communication complexity, switching lemma}
}

@article{10.1137/05063605X,
author = {Dvir, Zeev and Shpilka, Amir},
title = {Locally Decodable Codes with Two Queries and Polynomial Identity Testing for Depth 3 Circuits},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/05063605X},
doi = {10.1137/05063605X},
abstract = {In this work we study two, seemingly unrelated, notions.  Locally decodable codes  (LDCs) are codes that allow the recovery of each message bit from a constant number of entries of the codeword.  Polynomial identity testing  (PIT) is one of the fundamental problems of algebraic complexity: we are given a circuit computing a multivariate polynomial and we have to determine whether the polynomial is identically zero. We improve known results on LDCs and on polynomial identity testing and show a relation between the two notions. In particular we obtain the following results: (1) We show that if $E: mathbb{F}^n mapsto mathbb{F}^m$ is a linear LDC with two queries, then $m = exp(Omega(n))$. Previously this was known only for fields of size $ll 2^n$ [O. Goldreich &amp;etal;,  Comput. Complexity , 15 (2006), pp. 263-296]. (2) We show that from every depth 3 arithmetic circuit ($SigmaPiSigma$ circuit), ${cal C}$, with a bounded (constant) top fan-in that computes the zero polynomial, one can construct an LDC. More formally, assume that ${cal C}$ is minimal (no subset of the multiplication gates sums to zero) and simple (no linear function appears in all the multiplication gates). Denote by $d$ the degree of the polynomial computed by ${cal C}$ and by $r$ the rank of the linear functions appearing in ${cal C}$. Then we can construct a linear LDC with two queries that encodes messages of length $r/{operatorname{polylog}(d)}$ by codewords of length $O(d)$. (3) We prove a structural theorem for $SigmaPiSigma$ circuits, with a bounded top fan-in, that compute the zero polynomial. In particular we show that if such a circuit is simple, minimal, and of polynomial size, then its rank, $r$, is only polylogarithmic in the number of variables (a priori it could have been linear). (4) We give new PIT algorithms for $SigmaPiSigma$ circuits with a bounded top fan-in: (a) a deterministic algorithm that runs in quasipolynomial time, and (b) a randomized algorithm that runs in polynomial time and uses only a polylogarithmic number of random bits. Moreover, when the circuit is multilinear, our deterministic algorithm runs in polynomial time. Previously deterministic subexponential time algorithms for PIT in bounded depth circuits were known only for depth 2 circuits (in the black box model) [D. Grigoriev, M. Karpinski, and M. F. Singer,  SIAM J. Comput. , 19 (1990), pp. 1059-1063; M. Ben-Or and P. Tiwari,  Proceedings of the  20 th Annual ACM Symposium on Theory of Computing , ACM Press, New York, 1988, pp. 301-309; A. R. Klivans and D. Spielman,  Proceedings of the  33 rd Annual ACM Symposium on Theory of Computing , ACM Press, New York, 2001, pp. 216-223]. In particular, for the special case of depth 3 circuits with three multiplication gates our result resolves an open question asked by Klivans and Spielman.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1404–1434},
numpages = {31},
keywords = {polynomial identity test, locally decodable codes, depth 3, arithmetic circuits, derandomization}
}

@article{10.1137/05063235X,
author = {Klauck, Hartmut and Sˇpalek, Robert and de Wolf, Ronald},
title = {Quantum and Classical Strong Direct Product Theorems and Optimal Time-Space Tradeoffs},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/05063235X},
doi = {10.1137/05063235X},
abstract = {A strong direct product theorem says that if we want to compute $k$ independent instances of a function, using less than $k$ times the resources needed for one instance, then our overall success probability will be exponentially small in $k$. We establish such theorems for the classical as well as quantum query complexity of the OR-function. This implies slightly weaker direct product results for all total functions. We prove a similar result for quantum communication protocols computing $k$ instances of the disjointness function. Our direct product theorems imply a time-space tradeoff $T^2S=Om{N^3}$ for sorting $N$ items on a quantum computer, which is optimal up to polylog factors. They also give several tight time-space and communication-space tradeoffs for the problems of Boolean matrix-vector multiplication and matrix multiplication.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1472–1493},
numpages = {22},
keywords = {decision trees, complexity theory, lower bounds, quantum computing, communication complexity}
}

@article{10.1137/050631847,
author = {Eppstein, David and Goodrich, Michael T. and Hirschberg, Daniel S.},
title = {Improved Combinatorial Group Testing Algorithms for Real-World Problem Sizes},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050631847},
doi = {10.1137/050631847},
abstract = {We study practically efficient methods for performing combinatorial group testing. We present efficient nonadaptive and two-stage combinatorial group testing algorithms, which identify the at most $d$ items out of a given set of $n$ items that are defective, using fewer tests for all practical set sizes. For example, our two-stage algorithm matches the information-theoretic lower bound for the number of tests in a combinatorial group testing regimen.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1360–1375},
numpages = {16},
keywords = {combinatorial group testing, Chinese remaindering, Bloom filters}
}

@article{10.1137/050631616,
author = {Kamidoi, Yoko and Yoshida, Noriyoshi and Nagamochi, Hiroshi},
title = {A Deterministic Algorithm for Finding All Minimum $k$-Way Cuts},
year = {2006},
issue_date = {December 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/050631616},
doi = {10.1137/050631616},
abstract = {Let $G=(V,E)$ be an edge-weighted undirected graph with $n$ vertices and $m$ edges. We present a deterministic algorithm to compute a minimum $k$-way cut of $G$ for a given $k$. Our algorithm is a divide-and-conquer method based on a procedure that reduces an instance of the minimum $k$-way cut problem to $O(n^{2k-5})$ instances of the minimum $(lfloor (k+sqrt{k})/2rfloor+1)$-way cut problem, and can be implemented to run in $O(n^{4k/(1-1.71/sqrt{k}) -31} )$ time. With a slight modification, the algorithm can find all minimum $k$-way cuts in $O(n^{4k/(1-1.71/sqrt{k}) -16} )$ time.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1329–1341},
numpages = {13},
keywords = {minimum cut, multiway cut, divide-and-conquer}
}

@article{10.1137/S0097539798332518,
author = {Safra, Shmuel},
title = {Exponential Determinization for Ω-Automata with a Strong Fairness Acceptance Condition},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798332518},
doi = {10.1137/S0097539798332518},
abstract = {In [S. Safra, Proceedings of the 29th IEEE Symposium on Foundations of Computer Science, 1988, pp. 319-327] an exponential determinization procedure for Buchi automata was shown, yielding tight bounds for decision procedures of some logics (see [A. E. Emerson and C. Jutla, Proceedings of the 29th IEEE Symposium on Foundations of Computer Science, 1988, pp. 328-337; Safra (1988); S. Safra and M. Y. Vardi, Proceedings of the 21st ACM Symposium on Theory of Computing, 1989, pp. 127-137; and D. Kozen and J. Tiuryn, Logics of program, in Handbook of Theoretical Computer Science, Elsevier, Amsterdam, 1990, pp. 789-840]). In Safra and Vardi (1989) the complexity of determinization and complementation of ω-automata was further investigated, leaving as an open question the complexity of the determinization of a single class of ω-automata. For this class of ω-automata with strong fairness as an acceptance condition (Streett automata), Safra and Vardi (1989) managed to show an exponential complementation procedure; however, the blow-up of translating these automata—to any of the classes known to admit exponential determinization—is inherently exponential. This might suggest that the blow-up of the determinization of Streett automata is inherently doubly exponential. This paper shows an exponential determinization construction for Streett automata. In fact, the complexity of our construction is roughly the same as the complexity achieved in Safra (1988) for Buchi automata. Moreover, a simple observation extends this upper bound to the complementation problem. Since any ω-automaton that admits exponential determinization can be easily converted into a Streett automaton, we have obtained a single procedure that can be used for all of these conversions. Furthermore, this construction is optimal (up to a constant factor in the exponent) for all of these conversions. Our results imply that Streett automata (with strong fairness as an acceptance condition) can be used instead of Buchi automata (with the weaker acceptance condition) without any loss of efficiency.},
journal = {SIAM J. Comput.},
month = sep,
pages = {803–814},
numpages = {12},
keywords = {ω-automata, verification, reactive systems}
}

@article{10.1137/S0097539704446591,
author = {Agarwal, Pankaj K. and Overmars, Mark and Sharir, Micha},
title = {Computing Maximally Separated Sets in the Plane},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446591},
doi = {10.1137/S0097539704446591},
abstract = {Let $S$ be a set of $n$ points in $reals^2$. Given an integer $1 le k le n$, we wish to find a maximally separated subset $I subseteq S$ of size $k$; this is a subset for which the minimum among the ${kchoose 2}$ pairwise distances between its points is as large as possible. The decision problem associated with this problem is to determine whether there exists $Isubseteq S$, $|I|=k$, so that all ${kchoose 2}$ pairwise distances in $I$ are at least 2. This problem can also be formulated in terms of disk-intersection graphs: Let $D$ be the set of unit disks centered at the points of $S$. The disk-intersection graph $G$ of $D$ has as edges all pairs of disks with nonempty intersection. Any set $I$ with the above properties is then the set of centers of disks that form an independent set in the graph $G$. This problem is known to be NP-complete if $k$ is part of the input. In this paper we first present a linear-time $eps$-approximation algorithm for any constant $k$. Next we give exact algorithms for the cases $k=3$ and $k=4$ that run in time $O(n^{4/3}polylog(n))$. We also present a simpler $n^{O(sqrt{k})}$-time exact algorithm (as compared with the recent algorithm in [J. Alber and J. Fiala, J. Algorithms, 52 (2004), pp. 134-151]) for arbitrary values of $k$.},
journal = {SIAM J. Comput.},
month = sep,
pages = {815–834},
numpages = {20},
keywords = {disk-intersection graphs, geometric optimization, independent set}
}

@article{10.1137/S0097539704445615,
author = {Kaufman, Tali and Ron, Dana},
title = {Testing Polynomials over General Fields},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445615},
doi = {10.1137/S0097539704445615},
abstract = {In this work we fill the knowledge gap concerning testing polynomials over finite fields. As previous works show, when the cardinality of the field, $q$, is sufficiently larger than the degree bound, $d$, then the number of queries sufficient for testing is polynomial or even linear in $d$. On the other hand, when $q=2$ then the number of queries, both sufficient and necessary, grows exponentially with $d$. Here we study the intermediate case where $2 &lt; q = O(d)$ and show a smooth transition between the two extremes. Specifically, let $p$ be the characteristic of the field (so that $p$ is prime and $q = p^s$ for some integer $s geq 1$). Then the number of queries performed by the test grows like $ellcdot q^{2ell+1}$, where $ell = biglceil frac{d+1}{q-q/p}bigrceil $. Furthermore, $q^{Omega(ell)}$ queries are necessary when $q = O(d)$. The test itself provides a unifying view of the tests for these two extremes: it considers random affine subspaces of dimension $ell$ and verifies that the function restricted to the selected subspaces is a polynomial of degree at most $d$. Viewed in the context of coding theory, our result shows that Reed-Muller codes over general fields (usually referred to as generalized Reed-Muller (GRM) codes) are locally testable. In the course of our analysis we provide a characterization of small-weight words that span the code. Such a characterization was previously known only when the field size is a prime or is sufficiently large, in which case the minimum-weight words span the code.},
journal = {SIAM J. Comput.},
month = sep,
pages = {779–802},
numpages = {24},
keywords = {polynomials, testing, Reed-Muller codes}
}

@article{10.1137/S0097539704441630,
author = {Beigel, Richard and Fortnow, Lance and Stephan, Frank},
title = {Infinitely-Often Autoreducible Sets},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441630},
doi = {10.1137/S0097539704441630},
abstract = {A set $A$ is autoreducible if one can compute, for all $x$, the value $A(x)$ by querying $A$ only at places $y neq x$. Furthermore, $A$ is infinitely-often autoreducible if, for infinitely many $x$, the value $A(x)$ can be computed by querying $A$ only at places $y neq x$. For all other $x$, the computation outputs a special symbol to signal that the reduction is undefined. It is shown that for polynomial time Turing and truth-table autoreducibility there are $A$, $B$, $C$ in the class EXP of all exponential-time computable sets such that $A$ is not infinitely-often Turing autoreducible, $B$ is Turing autoreducible but not infinitely-often truth-table autoreducible and $C$ is truth-table autoreducible with $g(n)+1$ queries but not infinitely-often Turing autoreducible with $g(n)$ queries. Here $n$ is the length of the input, $g$ is nondecreasing, and there exists a polynomial $p$ such that $p(n)$ bounds both the computation time and the value of $g$ at input of length $n$. Furthermore, connections between notions of infinitely-often autoreducibility and notions of approximability are investigated. The Hausdorff-dimension of the class of sets which are not infinitely-often autoreducible is shown to be $1$.},
journal = {SIAM J. Comput.},
month = sep,
pages = {595–608},
numpages = {14},
keywords = {infinitely-often autoreducible sets, autoreducible sets, computational complexity, algorithmic randomness, Hausdorff-dimension, exponential-time computable sets}
}

@article{10.1137/S009753970343912X,
author = {Chan, Timothy M.},
title = {Dynamic Subgraph Connectivity with Geometric Applications},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970343912X},
doi = {10.1137/S009753970343912X},
abstract = {Inspired by dynamic connectivity applications in computational geometry, we consider a problem we call dynamic subgraph connectivity: design a data structure for an undirected graph $G=(V,E)$ and a subset of vertices $S subseteq V$ to support insertions/deletions in $S$ and connectivity queries (are two vertices connected?) in the subgraph induced by $S$. We develop the first sublinear, fully dynamic method for this problem for general sparse graphs, using a combination of several simple ideas. Our method requires $widetilde O(|E|^{4omega/(3omega+3)})=O(|E|^{0.94})$ amortized update time, and $widetilde O(|E|^{1/3})$ query time, after $widetilde O(|E|^{(5omega+1)/(3omega+3)})$ preprocessing time, where ω is the matrix multiplication exponent and $widetilde O$ hides polylogarithmic factors.},
journal = {SIAM J. Comput.},
month = sep,
pages = {681–694},
numpages = {14},
keywords = {computational geometry, data structures, connectivity, dynamic graph algorithms}
}

@article{10.1137/S0097539703435492,
author = {undefineduczak, Tomasz and Nesˇetrˇil, Jaroslav},
title = {A Probabilistic Approach to the Dichotomy Problem},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435492},
doi = {10.1137/S0097539703435492},
abstract = {Let ${mathcal R}(n,k)$ denote the random $k$-ary relation defined on the set $[n]={1,2,dots,n}$. We show that the probability that $([n], {mathcal R}(n,k))$ is projective tends to one, as either $n$ or $k$ tends to infinity. This result implies that for most relational systems $(B,{{underline{R}}})$ the ${{textrm{CSP}}}(B,{{underline{R}}})$ problem is NP-complete (and thus that the dichotomy conjecture holds with probability 1), and confirms a conjecture of Rosenberg [I. G. Rosenberg, Rocky Mountain J. Math., 3 (1973), pp. 631-639].},
journal = {SIAM J. Comput.},
month = sep,
pages = {835–843},
numpages = {9},
keywords = {projectivity, random relation, CSP}
}

@article{10.1137/S0097539703434966,
author = {Kumar, Amit and Kleinberg, Jon},
title = {Fairness Measures for Resource Allocation},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434966},
doi = {10.1137/S0097539703434966},
abstract = {In many optimization problems, one seeks to allocate a limited set of resources to a set of individuals with demands. Thus, such allocations can naturally be viewed as vectors, with one coordinate representing each individual. Motivated by work in network routing and bandwidth assignment, we consider the problem of producing solutions that simultaneously approximate all feasible allocations in a coordinate-wise sense. This is a very strong type of “global” approximation guarantee, and we explore its consequences in a wide range of discrete optimization problems, including facility location, scheduling, and bandwidth assignment in networks. A fundamental issue—one not encountered in the traditional design of approximation algorithms—is that good approximations in this global sense need not exist for every problem instance; there is no a priori reason why there should be an allocation that simultaneously approximates all others. As a result, the existential questions concerning such good allocations lead to a new perspective on a number of fundamental problems in resource allocation, and on the structure of their feasible solutions.},
journal = {SIAM J. Comput.},
month = sep,
pages = {657–680},
numpages = {24},
keywords = {fairness, scheduling, bandwidth allocation, approximation algorithms, facility location}
}

@article{10.1137/S0097539703434620,
author = {Srinivasan, Aravind},
title = {An Extension of the Lova´Sz Local Lemma, and Its Applications to Integer Programming},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434620},
doi = {10.1137/S0097539703434620},
abstract = {The Lova´sz local lemma due to Erdo˝s and Lova´sz (Infinite and Finite Sets, Colloq. Math. Soc. J. Bolyai 11, 1975, pp. 609-627) is a powerful tool in proving the existence of rare events. We present an extension of this lemma, which works well when the event to be shown to exist is a conjunction of individual events, each of which asserts that a random variable does not deviate much from its mean. As applications, we consider two classes of NP-hard integer programs: minimax and covering integer programs. A key technique, randomized rounding of linear relaxations, was developed by Raghavan and Thompson (Combinatorica, 7 (1987), pp. 365-374) to derive good approximation algorithms for such problems. We use our extension of the local lemma to prove that randomized rounding produces, with nonzero probability, much better feasible solutions than known before, if the constraint matrices of these integer programs are column-sparse (e.g., routing using short paths, problems on hypergraphs with small dimension/degree). This complements certain well-known results from discrepancy theory. We also generalize the method of pessimistic estimators due to Raghavan (J. Comput. System Sci., 37 (1988), pp. 130-143), to obtain constructive (algorithmic) versions of our results for covering integer programs.},
journal = {SIAM J. Comput.},
month = sep,
pages = {609–634},
numpages = {26},
keywords = {randomized rounding, column-sparse integer programs, discrepancy, Lova´sz local lemma, approximation algorithms}
}

@article{10.1137/S0097539703434231,
author = {Achlioptas, Dimitris and Moore, Cristopher},
title = {Random $k$-SAT: Two Moments Suffice to Cross a Sharp Threshold},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434231},
doi = {10.1137/S0097539703434231},
abstract = {Many NP-complete constraint satisfaction problems appear to undergo a “phase transition” from solubility to insolubility when the constraint density passes through a critical threshold. In all such cases it is easy to derive upper bounds on the location of the threshold by showing that above a certain density the first moment (expectation) of the number of solutions tends to zero. We show that in the case of certain symmetric constraints, considering the second moment of the number of solutions yields nearly matching lower bounds for the location of the threshold. Specifically, we prove that the threshold for both random hypergraph 2-colorability (Property B) and random Not-All-Equal $k$-SAT is $2^{k-1}ln 2 -O(1)$. As a corollary, we establish that the threshold for random $k$-SAT is of order $Theta(2^k)$, resolving a long-standing open problem.},
journal = {SIAM J. Comput.},
month = sep,
pages = {740–762},
numpages = {23},
keywords = {random formulas, phase transitions, satisfiability}
}

@article{10.1137/S009753970343141X,
author = {van Dam, Wim and Hallgren, Sean and Ip, Lawrence},
title = {Quantum Algorithms for Some Hidden Shift Problems},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970343141X},
doi = {10.1137/S009753970343141X},
abstract = {Almost all of the most successful quantum algorithms discovered to date exploit the ability of the Fourier transform to recover subgroup structures of functions, especially periodicity. The fact that Fourier transforms can also be used to capture shift structure has received far less attention in the context of quantum computation. In this paper, we present three examples of “unknown shift” problems that can be solved efficiently on a quantum computer using the quantum Fourier transform. For one of these problems, the shifted Legendre symbol problem, we give evidence that the problem is hard to solve classically, by showing a reduction from breaking algebraically homomorphic cryptosystems. We also define the hidden coset problem, which generalizes the hidden shift problem and the hidden subgroup problem. This framework provides a unified way of viewing the ability of the Fourier transform to capture subgroup and shift structure.},
journal = {SIAM J. Comput.},
month = sep,
pages = {763–778},
numpages = {16},
keywords = {quantum computing, efficient algorithms, Legendre symbol}
}

@article{10.1137/050642228,
author = {Diehl, Scott and van Melkebeek, Dieter},
title = {Time-Space Lower Bounds for the Polynomial-Time Hierarchy on Randomized Machines},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050642228},
doi = {10.1137/050642228},
abstract = {We establish the first polynomial-strength time-space lower bounds for problems in the linear-time hierarchy on randomized machines with two-sided error. We show that for any integer $ell &gt; 1$ and constant $c &lt; ell$, there exists a positive constant $d$ such that QSAT$_{ell}$ cannot be computed by such machines in time $n^c$ and space $n^d$, where QSAT$_{ell}$ denotes the problem of deciding the validity of a quantified Boolean formula with at most $ell - 1$ quantifier alternations. Moreover, $d$ approaches 1/2 from below as $c$ approaches 1 from above for $ell = 2$, and $d$ approaches 1 from below as $c$ approaches 1 from above for $ell ge 3$. In fact, we establish the stronger result that for any constants $a le 1$ and $c &lt; 1 + (ell - 1)a$, there exists a positive constant $d$ such that linear-time alternating machines using space $n^a$ and $ell - 1$ alternations cannot be simulated by randomized machines with two-sided error running in time $n^c$ and space $n^d$, where $d$ approaches $a/2$ from below as $c$ approaches 1 from above for $ell = 2$, and $d$ approaches $a$ from below as $c$ approaches 1 from above for $ell ge 3$. Corresponding to $ell = 1$, we prove that there exists a positive constant $d$ such that the set of Boolean tautologies cannot be decided by a randomized machine with one-sided error in time $n^{1.759}$ and space $n^d$. As a corollary, this gives the same lower bound for satisfiability on deterministic machines, improving on the previously best known such result.},
journal = {SIAM J. Comput.},
month = sep,
pages = {563–594},
numpages = {32},
keywords = {time-space lower bounds, satisfiability, randomized algorithms, polynomial-time hierarchy}
}

@article{10.1137/050636036,
author = {Sharir, Micha and Welzl, Emo},
title = {On the Number of Crossing-Free Matchings, Cycles, and Partitions},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050636036},
doi = {10.1137/050636036},
abstract = {We show that a set of $n$ points in the plane has at most $O(10.05^n)$ perfect matchings with crossing-free straight-line embedding. The expected number of perfect crossing-free matchings of a set of $n$ points drawn independently and identically distributed from an arbitrary distribution in the plane is at most $O(9.24^n)$. Several related bounds are derived: (a) The number of all (not necessarily perfect) crossing-free matchings is at most $O(10.43^n)$. (b) The number of red-blue perfect crossing-free matchings (where the points are colored red or blue and each edge of the matching must connect a red point with a blue point) is at most $O(7.61^n)$. (c) The number of left-right perfect crossing-free matchings (where the points are designated as left or right endpoints of the matching edges) is at most $O(5.38^n)$. (d) The number of perfect crossing-free matchings across a line (where all the matching edges must cross a fixed halving line of the set) is at most $4^n$. These bounds are employed to infer that a set of $n$ points in the plane has at most $O(86.81^n)$ crossing-free spanning cycles (simple polygonizations) and at most $O(12.24^n)$ crossing-free partitions (these are partitions of the point set so that the convex hulls of the individual parts are pairwise disjoint). We also derive lower bounds for some of these quantities.},
journal = {SIAM J. Comput.},
month = sep,
pages = {695–720},
numpages = {26},
keywords = {crossing-free matchings, simple polygonizations, crossing-free partitions, counting, crossing-free geometric graphs}
}

@article{10.1137/050633263,
author = {Chen, Guantao and Gao, Zhicheng and Yu, Xingxing and Zang, Wenan},
title = {Approximating Longest Cycles in Graphs with Bounded Degrees},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050633263},
doi = {10.1137/050633263},
abstract = {Jackson and Wormald conjecture that if $G$ is a 3-connected $n$-vertex graph with maximum degree $dge 4$, then $G$ has a cycle of length $Omega(n^{log_{d-1}2})$. We show that this conjecture holds when $d-1$ is replaced by $max{64,4d+1}$. Our proof implies a cubic algorithm for finding such a cycle.},
journal = {SIAM J. Comput.},
month = sep,
pages = {635–656},
numpages = {22},
keywords = {algorithm, long cycles, 3-connected components, bounded degree}
}

@article{10.1137/050631008,
author = {Bro¨nnimann, Herve´ and Kettner, Lutz and Pocchiola, Michel and Snoeyink, Jack},
title = {Counting and Enumerating Pointed Pseudotriangulations with the Greedy Flip Algorithm},
year = {2006},
issue_date = {August 2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050631008},
doi = {10.1137/050631008},
abstract = {We present an algorithm to enumerate the pointed pseudotriangulations of a given point set, based on the greedy flip algorithm of Pocchiola and Vegter [Discrete Comput. Geom. 16 (1996), pp. 419-453]. Our two independent implementations agree and allow us to experimentally verify or disprove conjectures on the numbers of pointed pseudotriangulations and triangulations of a given point set. (For example, we establish that the number of triangulations is bounded by the number of pointed pseudotriangulations for all sets of up to 10 points.)},
journal = {SIAM J. Comput.},
month = sep,
pages = {721–739},
numpages = {19},
keywords = {enumeration, algorithm, triangulation, pseudotriangulation, combinatorics}
}

@article{10.1137/S009753979833965X,
author = {Bartal, Yair and Fiat, Amos and Leonardi, Stefano},
title = {Lower Bounds for On-Line Graph Problems with Application to On-Line Circuit and Optical Routing},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979833965X},
doi = {10.1137/S009753979833965X},
abstract = {We present lower bounds on the competitive ratio of randomized algorithms for a wide class of on-line graph optimization problems, and we apply such results to on-line virtual circuit and optical routing problems. Lund and Yannakakis [The approximation of maximum subgraph problems, in Proceedings of the 20th International Colloquium on Automata, Languages and Programming, 1993, pp. 40-51] give inapproximability results for the problem of finding the largest vertex induced subgraph satisfying any nontrivial, hereditary property pi--e.g., independent set, planar, acyclic, bipartite. We consider the on-line version of this family of problems, where some graph G is fixed and some subgraph H of G is presented on-line, vertex by vertex. The on-line algorithm must choose a subset of the vertices of H, choosing or rejecting a vertex when it is presented, whose vertex induced subgraph satisfies property pi. Furthermore, we study the on-line version of graph coloring whose off-line version has also been shown to be inapproximable [C. Lund and M. Yannakakis, On the hardness of approximating minimization problems, in Proceedings of the 25th ACM Symposium on Theory of Computing, 1993], on-line max edge-disjoint paths, and on-line path coloring problems. Irrespective of the time complexity, we show an Omega(nepsilon) lower bound on the competitive ratio of randomized on-line algorithms for any of these problems. As a consequence, we obtain an Omega(nepsilon) lower bound on the competitive ratio of randomized on-line algorithms for virtual circuit routing on general networks, in contrast to the known results for some specific networks. Similar lower bounds are obtained for on-line optical routing as well.},
journal = {SIAM J. Comput.},
month = aug,
pages = {354–393},
numpages = {40},
keywords = {lower bounds, network optimization, on-line computation, competitive analysis, graph problems, randomized algorithms}
}

@article{10.1137/S0097539704446554,
author = {Matias, Yossi and Segal, Eran and Vitter, Jeffrey Scott},
title = {Efficient Bundle Sorting},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446554},
doi = {10.1137/S0097539704446554},
abstract = {Many data sets to be sorted consist of a limited number of distinct keys. Sorting such data sets can be thought of as bundling together identical keys and having the bundles placed in order; we therefore denote this as bundle sorting. We describe an efficient algorithm for bundle sorting in external memory, which requires at most c(N/B) logM/Bk disk accesses, where N is the number of keys, M is the size of internal memory, k is the number of distinct keys, B is the transfer block size, and 2 &lt; c &lt; 4. For moderately sized k, this bound circumvents the Theta((N/B) logM/B (N/B)) I/O lower bound known for general sorting. We show that our algorithm is optimal by proving a matching lower bound for bundle sorting. The improved running time of bundle sorting over general sorting can be significant in practice, as demonstrated by experimentation. An important feature of the new algorithm is that it is executed "in-place," requiring no additional disk space.},
journal = {SIAM J. Comput.},
month = aug,
pages = {394–410},
numpages = {17},
keywords = {external memory, algorithms, sorting, bundle sorting}
}

@article{10.1137/S009753970444421X,
author = {Glasser, Christian and Pavan, A. and Selman, Alan L. and Sengupta, Samik},
title = {Properties of NP-Complete Sets},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444421X},
doi = {10.1137/S009753970444421X},
abstract = {We study several properties of sets that are complete for NP. We prove that if L is an NP-complete set and S notsupseteq L is a p-selective sparse set, then L - S is leq pm-hard for NP. We demonstrate the existence of a sparse set S in DTIME(22n) such that for every L in NP - P, L - S is not leq pm-hard for NP. Moreover, we prove for every L in NP - P that there exists a sparse S in EXP such that L - S is not leq pm-hard for NP. Hence, removing sparse information in P from a complete set leaves the set complete, while removing sparse information in EXP from a complete set may destroy its completeness. Previously, these properties were known only for exponential time complexity classes. We use hypotheses about pseudorandom generators and secure one-way permutations to derive consequences for longstanding open questions about whether NP-complete sets are immune. For example, assuming that pseudorandom generators and secure one-way permutations exist, it follows easily that NP-complete sets are not p-immune. Assuming only that secure one-way permutations exist, we prove that no NP-complete set is DTIME(2nepsilon)-immune. Also, using these hypotheses we show that no NP-complete set is quasi-polynomial-close to P. We introduce a strong but reasonable hypothesis and infer from it that disjoint Turing-complete sets for NP are not closed under union. Our hypothesis asserts the existence of a UP-machine M that accepts 0* such that for some 0 &lt; epsilon &lt; 1, no 2nepsilon time-bounded machine can correctly compute infinitely many accepting computations of M. We show that if UP cap coUP contains DTIME(2nepsilon)-bi-immune sets, then this hypothesis is true.},
journal = {SIAM J. Comput.},
month = aug,
pages = {516–542},
numpages = {27},
keywords = {disjoint unions, robustness, immunity, NP-completeness, one-way permutations}
}

@article{10.1137/S0097539704441435,
author = {Kratsch, Dieter and Spinrad, Jeremy},
title = {Between <i>O</i>(<i>Nm</i>) and <i>O</i>(<i>n<sup>alpha</sup></i>)},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441435},
doi = {10.1137/S0097539704441435},
abstract = {This paper uses periodic matrix multiplication to improve the time complexities for a number of graph problems. The time for finding an asteroidal triple is reduced from O(nm) to O(n2.82), and the time for finding a star cutset, a two-pair, and a dominating pair is reduced from O(nm) to O(n2.79). It is also shown that each of these problems is at least as hard as one of three basic graph problems for which the best known algorithms run in times O(nm) and O(nalpha). We note that the fast matrix multiplication algorithms do not seem to be practical because of the enormous constants needed to achieve the asymptotic time bounds. These results are important theoretically for breaking the n3 barrier rather than giving efficient algorithms for a user.},
journal = {SIAM J. Comput.},
month = aug,
pages = {310–325},
numpages = {16},
keywords = {dominating pair, AT-free graphs, star cutset, graphs, two-pair, algorithms, reductions}
}

@article{10.1137/S0097539704441241,
author = {Feldman, Jon and Ruhl, Matthias},
title = {The Directed Steiner Network Problem Is Tractable for a Constant Number of Terminals},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441241},
doi = {10.1137/S0097539704441241},
abstract = {We consider the Directed Steiner Network problem, also called the Point-to-Point Connection problem. Given a directed graph G and p pairs {(s1,t1),...,(sp,tp)} of nodes in the graph, one has to find the smallest subgraph H of G that contains paths from si to ti for all i. The problem is NP-hard for general p, since the Directed Steiner Tree problem is a special case. Until now, the complexity was unknown for constant p geq 3. We prove that the problem is polynomially solvable if p is any constant number, even if nodes and edges in G are weighted and the goal is to minimize the total weight of the subgraph H. In addition, we give an efficient algorithm for the Strongly Connected Steiner Subgraph problem for any constant p, where given a directed graph and p nodes in the graph, one has to compute the smallest strongly connected subgraph containing the p nodes.},
journal = {SIAM J. Comput.},
month = aug,
pages = {543–561},
numpages = {19},
keywords = {Steiner tree, network design, Steiner network, polynomial-time algorithms, directed graphs}
}

@article{10.1137/S0097539704441058,
author = {Elkin, Michael},
title = {An Unconditional Lower Bound on the Time-Approximation Trade-off for the Distributed Minimum Spanning Tree Problem},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441058},
doi = {10.1137/S0097539704441058},
abstract = {The design of distributed approximation protocols is a relatively new and rapidly developing area of research. However, so far, little progress has been made in the study of the hardness of distributed approximation. In this paper we initiate the systematic study of this subject and show strong unconditional lower bounds on the time-approximation trade-off of the distributed minimum spanning tree problem, and show some of its variants.},
journal = {SIAM J. Comput.},
month = aug,
pages = {433–456},
numpages = {24},
keywords = {hardness of approximation, distributed algorithms, minimum spanning tree}
}

@article{10.1137/S0097539703437855,
author = {Kratsch, Dieter and McConnell, Ross M. and Mehlhorn, Kurt and Spinrad, Jeremy P.},
title = {Certifying Algorithms for Recognizing Interval Graphs and Permutation Graphs},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703437855},
doi = {10.1137/S0097539703437855},
abstract = {A certifying algorithm for a problem is an algorithm that provides a certificate with each answer that it produces. The certificate is a piece of evidence that proves that the answer has not been compromised by a bug in the implementation. We give linear-time certifying algorithms for recognition of interval graphs and permutation graphs, and for a few other related problems. Previous algorithms fail to provide supporting evidence when they claim that the input graph is not a member of the class. We show that our certificates of nonmembership can be authenticated in O(|V|) time.},
journal = {SIAM J. Comput.},
month = aug,
pages = {326–353},
numpages = {28},
keywords = {certificates, certifying algorithms, interval graphs, permutation graphs}
}

@article{10.1137/S0097539703435716,
author = {Mahdian, Mohammad and Ye, Yinyu and Zhang, Jiawei},
title = {Approximation Algorithms for Metric Facility Location Problems},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435716},
doi = {10.1137/S0097539703435716},
abstract = {In this paper we present a 1.52-approximation algorithm for the metric uncapacitated facility location problem, and a 2-approximation algorithm for the metric capacitated facility location problem with soft capacities. Both these algorithms improve the best previously known approximation factor for the corresponding problem, and our soft-capacitated facility location algorithm achieves the integrality gap of the standard linear programming relaxation of the problem. Furthermore, we will show, using a result of Thorup, that our algorithms can be implemented in quasi-linear time.},
journal = {SIAM J. Comput.},
month = aug,
pages = {411–432},
numpages = {22},
keywords = {linear programming, greedy method, approximation algorithms, facility location problem}
}

@article{10.1137/S0097539703422479,
author = {Chuzhoy, Julia},
title = {Covering Problems with Hard Capacities},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703422479},
doi = {10.1137/S0097539703422479},
abstract = {We consider the classical vertex cover and set cover problems with hard capacity constraints. This means that a set (vertex) can cover only a limited number of its elements (adjacent edges), and the number of available copies of each set (vertex) is bounded. This is a natural generalization of the classical problems which also captures resource limitations in practical scenarios.We obtain the following results. For the unweighted vertex cover problem with hard capacities we give a 3-approximation algorithm that is based on randomized rounding with alterations. We prove that the weighted version is at least as hard as the set cover problem, yielding an interesting separation between the approximability of weighted and unweighted versions of a "natural" graph problem. A logarithmic approximation factor for both the set cover and the weighted vertex cover problem with hard capacities follows from the work of Wolsey [Combinatorica, 2 (1982), pp. 385-393] on submodular set cover. We provide here a simple and intuitive proof for this bound.},
journal = {SIAM J. Comput.},
month = aug,
pages = {498–515},
numpages = {18},
keywords = {set cover, hard capacities, submodular set cover, vertex cover}
}

@article{10.1137/S0097539702419649,
author = {Fomin, Fedor V. and Thilikos, Dimitrios M.},
title = {Dominating Sets in Planar Graphs: Branch-Width and Exponential Speed-Up},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702419649},
doi = {10.1137/S0097539702419649},
abstract = {We introduce a new approach to design parameterized algorithms on planar graphs which builds on the seminal results of Robertson and Seymour on graph minors. Graph minors provide a list of powerful theoretical results and tools. However, the widespread opinion in the graph algorithms community about this theory is that it is of mainly theoretical importance. In this paper we show how deep min-max and duality theorems from graph minors can be used to obtain exponential speed-up to many known practical algorithms for different domination problems. Our use of branch-width instead of the usual tree-width allows us to obtain much faster algorithms. By using this approach, we show that the k-dominating set problem on planar graphs can be solved in time O(215.13 sqrt k + n3).},
journal = {SIAM J. Comput.},
month = aug,
pages = {281–309},
numpages = {29},
keywords = {dominating set, tree-width, fixed-parameter algorithm, branch-width, planar graph}
}

@article{10.1137/S0097539701397412,
author = {Hoest, Gunnar and Shavit, Nir},
title = {Toward a Topological Characterization of Asynchronous Complexity},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701397412},
doi = {10.1137/S0097539701397412},
abstract = {This paper introduces the use of topological models and methods, formerly used to analyze computability, as tools for the quantification and classification of asynchronous complexity. We present the first asynchronous complexity theorem, applied to decision tasks in the iterated immediate snapshot (IIS) model of Borowsky and Gafni. We do so by introducing a novel form of topological tool called the nonuniform chromatic subdivision. Building on the framework of Herlihy and Shavit's topological computability model, our theorem states that the time complexity of any asynchronous algorithm is directly proportional to the level of nonuniform chromatic subdivisions necessary to allow a simplicial map from a task's input complex to its output complex. To show the power of our theorem, we use it to derive a new tight bound on the time to achieve n process approximate agreement in the IIS model: $bigllceil log_d frac{max_input - min_input}{epsilon} bigrrceil$, where d = 3 for two processes and d = 2 for three or more. This closes an intriguing gap between the known upper and lower bounds implied by the work of Aspnes and Herlihy. More than the new bounds themselves, the importance of our asynchronous complexity theorem is that the algorithms and lower bounds it allows us to derive are intuitive and simple, with topological proofs that require no mention of concurrency at all.},
journal = {SIAM J. Comput.},
month = aug,
pages = {457–497},
numpages = {41},
keywords = {simplicial complexes, subdivisions, immediate snapshots, approximate agreement, shared memory, asynchronous systems, topology}
}

@article{10.1137/S0097539705447001,
author = {Jukna, Stasys},
title = {Disproving the Single Level Conjecture},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447001},
doi = {10.1137/S0097539705447001},
abstract = {We consider the size of monotone circuits for quadratic Boolean functions, that is, disjunctions of length-2 monomials. Our motivation is that a good (linear in the number of variables) lower bound on the monotone circuit size for a certain type of quadratic function would imply a good (even exponential) lower bound on the general nonmonotone circuit size.To get more insight into the structure of monotone circuits for quadratic functions, we consider the so-called single level conjecture posed explicitly in the early 1990s. The conjecture claims that monotone single level circuits, that is, circuits which have only one level of AND gates, for quadratic functions are not much larger than arbitrary monotone circuits. In this paper we disprove the conjecture as follows: there exist quadratic functions whose monotone circuits have linear size but whose monotone single level circuits require almost quadratic size.},
journal = {SIAM J. Comput.},
month = jul,
pages = {83–98},
numpages = {16},
keywords = {clique covering number, Sylvester graph, quadratic functions, Boolean sums, Kneser graph, graph complexity, monotone circuits}
}

@article{10.1137/S0097539704446311,
author = {Creignou, Nadia and Zanuttini, Bruno},
title = {A Complete Classification of the Complexity of Propositional Abduction},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446311},
doi = {10.1137/S0097539704446311},
abstract = {Abduction is the process of explaining a given query with respect to some background knowledge. For instance, $p$ is an explanation for the query $q$ given the knowledge $prightarrow q$. This problem is well known to have many applications, particularly in artificial intelligence (AI), and has been widely studied from both an AI and a complexity-theoretic point of view. In this paper we completely classify the complexity of propositional abduction in Schaefer's famous framework. We consider the case where knowledge bases are taken from a class of formulas in generalized conjunctive normal form. This means that the propositional formulas considered are conjunctions of constraints taken from a fixed finite language. We show that according to the properties of this language, deciding whether at least one explanation exists is either polynomial, NP-complete, or $Sigma_2 {mathrm{P}}$-complete. Our results are stated for a query consisting of a single, positive literal and for assumption-based solutions, i.e., the solutions must be formed upon a distinguished subset of the variables that is part of the input. We show, however, that our results can be interpreted "dually" for negative queries, and thus also for unrestricted (positive or negative) queries.},
journal = {SIAM J. Comput.},
month = jul,
pages = {207–229},
numpages = {23},
keywords = {complexity, abduction, Boolean constraints, propositional logic}
}

@article{10.1137/S0097539704442702,
author = {Drineas, Petros and Kannan, Ravi and Mahoney, Michael W.},
title = {Fast Monte Carlo Algorithms for Matrices III: Computing a Compressed Approximate  Matrix Decomposition},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442702},
doi = {10.1137/S0097539704442702},
abstract = {In many applications, the data consist of (or may be naturally formulated as) an $m times n$ matrix $A$ which may be stored on disk but which is too large to be read into random access memory (RAM) or to practically perform superlinear polynomial time computations on it. Two algorithms are presented which, when given an $m times n$ matrix $A$, compute approximations to $A$ which are the product of three smaller matrices, $C$, $U$, and $R$, each of which may be computed rapidly. Let $A' = CUR$ be the computed approximate decomposition; both algorithms have provable bounds for the error matrix $A-A'$. In the first algorithm, $c$ columns of $A$ and $r$ rows of $A$ are randomly chosen. If the $m times c$ matrix $C$ consists of those $c$ columns of $A$ (after appropriate rescaling) and the $r times n$ matrix $R$ consists of those $r$ rows of $A$ (also after appropriate rescaling), then the $c times r$ matrix $U$ may be calculated from $C$ and $R$. For any matrix $X$, let $|X|_F$ and $|X|_2$ denote its Frobenius norm and its spectral norm, respectively. It is proven that $$ left|A-A'right|_xi le min_{D:mathrm{rank}(D)le k} left|A-Dright|_xi + poly(k,1/c) left|Aright|_F $$ holds in expectation and with high probability for both $xi = 2,F$ and for all $k=1,ldots,mbox{rank}(A)$; thus by appropriate choice of $k$ $$ left|A-A'right|_2 le epsilon left|Aright|_F $$ also holds in expectation and with high probability. This algorithm may be implemented without storing the matrix $A$ in RAM, provided it can make two passes over the matrix stored in external memory and use $O(m+n)$ additional RAM (assuming that $c$ and $r$ are constants, independent of the size of the input). The second algorithm is similar except that it approximates the matrix $C$ by randomly sampling a constant number of rows of $C$. Thus, it has additional error but it can be implemented in three passes over the matrix using only constant additional RAM. To achieve an additional error (beyond the best rank-$k$ approximation) that is at most $epsilon |A|_F$, both algorithms take time which is a low-degree polynomial in $k$, $1/epsilon$, and $1/delta$, where $delta&gt;0$ is a failure probability; the first takes time linear in $mbox{max}(m,n)$ and the second takes time independent of $m$ and $n$. The proofs for the error bounds make important use of matrix perturbation theory and previous work on approximating matrix multiplication and computing low-rank approximations to a matrix. The probability distribution over columns and rows and the rescaling are crucial features of the algorithms and must be chosen judiciously.},
journal = {SIAM J. Comput.},
month = jul,
pages = {184–206},
numpages = {23},
keywords = {randomized algorithms, CUR matrix decomposition, massive data sets, Monte Carlo methods}
}

@article{10.1137/S0097539704442696,
author = {Drineas, Petros and Kannan, Ravi and Mahoney, Michael W.},
title = {Fast Monte Carlo Algorithms for Matrices II: Computing a Low-Rank Approximation to a Matrix},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442696},
doi = {10.1137/S0097539704442696},
abstract = {In many applications, the data consist of (or may be naturally formulated as) an $m times n$ matrix $A$. It is often of interest to find a low-rank approximation to $A$, i.e., an approximation $D$ to the matrix $A$ of rank not greater than a specified rank $k$, where $k$ is much smaller than $m$ and $n$. Methods such as the singular value decomposition (SVD) may be used to find an approximation to $A$ which is the best in a well-defined sense. These methods require memory and time which are superlinear in $m$ and $n$; for many applications in which the data sets are very large this is prohibitive. Two simple and intuitive algorithms are presented which, when given an $m times n$ matrix $A$, compute a description of a low-rank approximation $D^{*}$ to $A$, and which are qualitatively faster than the SVD. Both algorithms have provable bounds for the error matrix $A-D^{*}$. For any matrix $X$, let $|{X}|_F$ and $|{X}|_2$ denote its Frobenius norm and its spectral norm, respectively. In the first algorithm, $c$ columns of $A$ are randomly chosen. If the $m times c$ matrix $C$ consists of those $c$ columns of $A$ (after appropriate rescaling), then it is shown that from $C^TC$ approximations to the top singular values and corresponding singular vectors may be computed. From the computed singular vectors a description $D^{*}$ of the matrix $A$ may be computed such that $mathrm{rank}(D^{*}) le k$ and such that $$ left|A-D^{*}right|_{xi}^{2} le min_{D:mathrm{rank}(D)le k} left|A-Dright|_{xi}^{2} + poly(k,1/c) left|{A}right|^2_F $$ holds with high probability for both $xi = 2,F$. This algorithm may be implemented without storing the matrix $A$ in random access memory (RAM), provided it can make two passes over the matrix stored in external memory and use $O(cm+c^2)$ additional RAM. The second algorithm is similar except that it further approximates the matrix $C$ by randomly sampling $r$ rows of $C$ to form a $r times c$ matrix $W$. Thus, it has additional error, but it can be implemented in three passes over the matrix using only constant additional RAM. To achieve an additional error (beyond the best rank $k$ approximation) that is at most $epsilon|{A}|^2_F$, both algorithms take time which is polynomial in $k$, $1/epsilon$, and $log(1/delta)$, where $delta&gt;0$ is a failure probability; the first takes time linear in $mbox{max}(m,n)$ and the second takes time independent of $m$ and $n$. Our bounds improve previously published results with respect to the rank parameter $k$ for both the Frobenius and spectral norms. In addition, the proofs for the error bounds use a novel method that makes important use of matrix perturbation theory. The probability distribution over columns of $A$ and the rescaling are crucial features of the algorithms which must be chosen judiciously.},
journal = {SIAM J. Comput.},
month = jul,
pages = {158–183},
numpages = {26},
keywords = {randomized algorithms, Monte Carlo methods, singular value decomposition, massive data sets}
}

@article{10.1137/S0097539704442684,
author = {Drineas, Petros and Kannan, Ravi and Mahoney, Michael W.},
title = {Fast Monte Carlo Algorithms for Matrices I: Approximating Matrix Multiplication},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442684},
doi = {10.1137/S0097539704442684},
abstract = {Motivated by applications in which the data may be formulated as a matrix, we consider algorithms for several common linear algebra problems. These algorithms make more efficient use of computational resources, such as the computation time, random access memory (RAM), and the number of passes over the data, than do previously known algorithms for these problems. In this paper, we devise two algorithms for the matrix multiplication problem. Suppose $A$ and $B$ (which are $mtimes n$ and $ntimes p$, respectively) are the two input matrices. In our main algorithm, we perform $c$ independent trials, where in each trial we randomly sample an element of ${ 1,2,ldots, n}$ with an appropriate probability distribution ${cal P}$ on ${ 1,2,ldots, n}$. We form an $mtimes c$ matrix $C$ consisting of the sampled columns of $A$, each scaled appropriately, and we form a $ctimes n$ matrix $R$ using the corresponding rows of $B$, again scaled appropriately. The choice of ${cal P}$ and the column and row scaling are crucial features of the algorithm. When these are chosen judiciously, we show that $CR$ is a good approximation to $AB$. More precisely, we show that $$ left|AB-CRright|_F = O(left|Aright|_F left|Bright|_F /sqrt c) , $$ where $|cdot|_F$ denotes the Frobenius norm, i.e., $|A|^2_F=sum_{i,j}A_{ij}^2$. This algorithm can be implemented without storing the matrices $A$ and $B$ in RAM, provided it can make two passes over the matrices stored in external memory and use $O(c(m+n+p))$ additional RAM to construct $C$ and $R$. We then present a second matrix multiplication algorithm which is similar in spirit to our main algorithm. In addition, we present a model (the pass-efficient model) in which the efficiency of these and other approximate matrix algorithms may be studied and which we argue is well suited to many applications involving massive data sets. In this model, the scarce computational resources are the number of passes over the data and the additional space and time required by the algorithm. The input matrices may be presented in any order of the entries (and not just row or column order), as is the case in many applications where, e.g., the data has been written in by multiple agents. In addition, the input matrices may be presented in a sparse representation, where only the nonzero entries are written.},
journal = {SIAM J. Comput.},
month = jul,
pages = {132–157},
numpages = {26},
keywords = {massive data sets, matrix multiplication, Monte Carlo methods, randomized algorithms, streaming models}
}

@article{10.1137/S0097539703437843,
author = {Bar-Yehuda, R. and Halld\'{o}rsson, M. M.},
title = {Scheduling Split Intervals},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703437843},
doi = {10.1137/S0097539703437843},
abstract = {We consider the problem of scheduling jobs that are given as groups of nonintersecting segments on the real line. Each job $J_j$ is associated with an interval, $I_j$, which consists of up to $t$ segments, for some $t geq 1$, and a weight (profit), $w_j$; two jobs are in conflict if their intervals intersect. Such jobs show up in a wide range of applications, including the transmission of continuous-media data, allocation of linear resources (e.g., bandwidth in linear processor arrays), and computational biology/geometry. The objective is to schedule a subset of nonconflicting jobs of maximum total weight.Our problem can be formulated as the problem of finding a maximum weight independent set in a t-interval graph (the special case of $t=1$ is an ordinary interval graph). We show that, for $t geq 2$, this problem is APX-hard, even for highly restricted instances. Our main result is a $2t$-approximation algorithm for general instances. This is based on a novel fractional version of the Local Ratio technique. One implication of this result is the first constant factor approximation for nonoverlapping alignment of genomic sequences. We also derive a bicriteria polynomial time approximation scheme for a restricted subclass of $t$-interval graphs.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1–15},
numpages = {15},
keywords = {independent set, interval graph, approximation algorithm, scheduling}
}

@article{10.1137/S0097539703434243,
author = {Cryan, Mary and Dyer, Martin and Goldberg, Leslie Ann and Jerrum, Mark and Martin, Russell},
title = {Rapidly Mixing Markov Chains for Sampling Contingency Tables with a Constant Number of Rows},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434243},
doi = {10.1137/S0097539703434243},
abstract = {We consider the problem of sampling almost uniformly from the set of contingency tables with given row and column sums, when the number of rows is a constant. Cryan and Dyer [J. Comput. System Sci., 67 (2003), pp. 291-310] have recently given a fully polynomial randomized approximation scheme (fpras) for the related counting problem, which employs Markov chain methods indirectly. They leave open the question as to whether a natural Markov chain on such tables mixes rapidly. Here we show that the "2 x 2 heat-bath" Markov chain is rapidly mixing. We prove this by considering first a heat-bath chain operating on a larger window. Using techniques developed by Morris [Random Walks in Convex Sets, Ph. D. thesis, Department of Statistics, University of California, Berkeley, CA, 2000] and Morris and Sinclair [SIAM J. Comput., 34 (2004), pp. 195-226] for the multidimensional knapsack problem, we show that this chain mixes rapidly. We then apply the comparison method of Diaconis and Saloff-Coste [Ann. Appl. Probab., 3 (1993), pp. 696-730] to show that the 2 x 2 chain is also rapidly mixing.},
journal = {SIAM J. Comput.},
month = jul,
pages = {247–278},
numpages = {32},
keywords = {contingency table, strongly balanced permutation, balanced almost-uniform permutation}
}

@article{10.1137/S0097539703427197,
author = {Feder, Tom\'{a}s and Hell, Pavol},
title = {Full Constraint Satisfaction Problems},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703427197},
doi = {10.1137/S0097539703427197},
abstract = {Feder and Vardi have conjectured that all constraint satisfaction problems to a fixed structure (constraint language) are polynomial or NP-complete. This so-called dichotomy conjecture remains open, although it has been proved in a number of special cases. Most recently, Bulatov has verified the conjecture for conservative structures, i.e., structures which contain all possible unary relations. We explore three different implications of Bulatov's result. First, the above dichotomy can be extended to so-called inclusive structures, corresponding to conservative constraint satisfaction problems in which each variable comes with its own domain. (This has also been independently observed by Bulatov.) We prove a more general version, extending the dichotomy to so-called three-inclusive structures, i.e., structures which contain, with any unary relation $R$, all unary relations $R'$ for subsets $R' subseteq R$ with at most three elements. For the constraint satisfaction problems in this generalization we must restrict the instances to so-called $1$-full structures, in which each variable is involved in a unary constraint. This leads to our second focus, which is on restrictions to more general kinds of "full" input structures. For any set $W$ of positive integers, we consider a restriction to $W$-full input structures, i.e., structures in which, for each $w in W$, any $w$ variables are involved in a $w$-ary constraint. We identify a class of structures (the so-called $W$-set-full structures) for which the restriction to $W$-full input structures does not change the complexity of the constraint satisfaction problem, and hence the family of these restricted problems also exhibits dichotomy. The general family of three-inclusive constraint satisfaction problems restricted to $W$-full input structures contains examples which we cannot seem to prove either polynomial or NP-complete. Nevertheless, we are able to use our result on the dichotomy for three-inclusive constraint satisfaction problems, to deduce the fact that all three-inclusive constraint satisfaction problems restricted to $W$-full input structures are NP-complete or "quasi-polynomial" (of order $n^{O(log n)}$). Our third focus deals with bounding the number of occurrences of a variable, which we call the degree. We conjecture that the complexity classification of three-inclusive constraint satisfaction problems extends to the case where all degrees are bounded by three. Using previous results, we are able to verify this conjecture in a number of special cases. Conservative, inclusive, and three-inclusive constraint satisfaction problems can be viewed as problems in which each variable is restricted to a "list" of allowed values. This point of view of lists is frequently encountered in the study of graph colorings, graph homomorphisms, and graph partitions. Our results presented here, in all three areas, were strongly motivated by these results on graphs.},
journal = {SIAM J. Comput.},
month = jul,
pages = {230–246},
numpages = {17},
keywords = {matrix partitions, graph homomorphisms, list homomorphisms, full constraint satisfaction problems, quasi-polynomial algorithms, dichotomy conjecture, constraint satisfaction problems, conservative constraint satisfaction problems, bounded degrees, NP-complete problems}
}

@article{10.1137/S0097539701397229,
author = {Wang, Li-San and Warnow, Tandy},
title = {Reconstructing Chromosomal Evolution},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701397229},
doi = {10.1137/S0097539701397229},
abstract = {Chromosomes evolve through genome rearrangement events, including inversions, transpositions, and inverted transpositions, that change the order and strandedness of genes within chromosomes. In this paper we present a method for estimating evolutionary histories for chromosomes based upon such events. The fundamental mathematical challenge of our approach is to estimate the true evolutionary distance between every pair of chromosomes, where the true evolutionary distance is the number of rearrangement events that took place in the evolutionary history between the chromosomes. We present two techniques, Exact- and Approx-IEBP, for estimating true evolutionary distances and prove guarantees about the accuracy of these techniques under a very general stochastic model of chromosomal evolution. We then show how we can use these estimated distances to obtain highly accurate estimates of chromosomal evolutionary history, significantly improving upon the previous best techniques.},
journal = {SIAM J. Comput.},
month = jul,
pages = {99–131},
numpages = {33},
keywords = {distance correction, phylogeny reconstruction, Markov chain, genome rearrangements, transpositions, inversions, Nadeau--Taylor model, neighbor joining}
}

@article{10.1137/050645221,
author = {Agmon, Noa and Peleg, David},
title = {Fault-Tolerant Gathering Algorithms for Autonomous Mobile Robots},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050645221},
doi = {10.1137/050645221},
abstract = {This paper studies fault-tolerant algorithms for the problem of gathering $N$ autonomous mobile robots. A gathering algorithm, executed independently by each robot, must ensure that all robots are gathered at one point within finite time. In a failure-prone system, a gathering algorithm is required to successfully gather the nonfaulty robots, independently of the behavior of the faulty ones. Both crash and Byzantine faults are considered. It is first observed that most existing algorithms fail to operate correctly in a setting allowing crash failures. Subsequently, an algorithm tolerant against one crash-faulty robot in a system of three or more robots is presented.It is then observed that all known algorithms fail to operate correctly in a system prone to Byzantine faults, even in the presence of a single fault. Moreover, it is shown that in an asynchronous environment it is impossible to perform a successful gathering in a $3$-robot system, even if at most one of them might fail in a Byzantine manner. Thus, the problem is studied in a fully synchronous system. An algorithm is provided in this model for gathering $N geq 3$ robots with at most a single faulty robot, and a more general gathering algorithm is given in an $N$-robot system with up to $f$ faults, where $N geq 3f+1$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {56–82},
numpages = {27},
keywords = {autonomous mobile robots, convergence, robot swarms}
}

@article{10.1137/050631562,
author = {Suzuki, Ichiro and Yamashita, Masafumi},
title = {Distributed Anonymous Mobile Robots: Formation of Geometric Patterns},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050631562},
doi = {10.1137/050631562},
abstract = {In this note we make a minor correction to a scheme for robots to broadcast their private information. All major results of the paper [I. Suzuki and M. Yamashita, SIAM J. Comput., 28 (1999), pp. 1347-1363] hold with this correction.},
journal = {SIAM J. Comput.},
month = jul,
pages = {279–280},
numpages = {2},
keywords = {anonymous robots, broadcast}
}

@article{10.1137/050629112,
author = {Case, John and Jain, Sanjay and Martin, Eric and Sharma, Arun and Stephan, Frank},
title = {Identifying Clusters from Positive Data},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050629112},
doi = {10.1137/050629112},
abstract = {The present work studies clustering from an abstract point of view and investigates its properties in the framework of inductive inference. Any class $S$ considered is given by a hypothesis space, i.e., numbering, $A_0,A_1,ldots$ of nonempty recursively enumerable (r.e.) subsets of ${mathbb{N}}$ or ${mathbb{Q}^k}$. A clustering task is a finite and nonempty set of r. e. indices of pairwise disjoint such sets. The class $S$ is said to be clusterable if there is an algorithm which, for every clustering task $I$, converges in the limit on any text for $bigcup_{i in I} A_i$ to a finite set $J$ of indices of pairwise disjoint clusters such that $bigcup_{j in J} A_j = bigcup_{i in I} A_i$. A class is called semiclusterable if there is such an algorithm which finds a $J$ with the last condition relaxed to $bigcup_{j in J} A_j supseteq bigcup_{i in I} A_i$.The relationship between natural topological properties and clusterability is investigated. Topological properties can provide sufficient or necessary conditions for clusterability, but they cannot characterize it. On the one hand, many interesting conditions make use of both the topological structure of the class and a well-chosen numbering. On the other hand, the clusterability of a class does not depend on which numbering of the class is used as a hypothesis space for thebreak clusterer.These ideas are demonstrated in the context of naturally geometrically defined classes. Besides the text for the clustering task, clustering of many of these classes requires the following additional information: the class of convex hulls of finitely many points in a rational vector space can be clustered with the number of clusters as additional information. Interestingly, the class of polygons (together with their interiors) is clusterable if the number of clusters and the overall number of vertices of these clusters is given to the clusterer as additional information. Intriguingly, this additional information is not sufficient for classes including figures with holes.While some classes are unclusterable due to their topological structure, others are only computationally intractable. An oracle might permit clustering all computationally intractable clustering tasks but fail on some classes which are topologically difficult. It is shown that an oracle $E$ permits clustering all computationally difficult classes iff $E geq_T K wedge E' geq_T K"$. Furthermore, no 1-generic oracle below $K$ and no 2-generic oracle permits clustering any class which is not clusterable without an oracle.},
journal = {SIAM J. Comput.},
month = jul,
pages = {28–55},
numpages = {28},
keywords = {Turing degree, numbering, clustering, topological and geometric properties of clusterable classes, hypothesis space, inductive inference}
}

@article{10.1137/050628957,
author = {Bulatov, Andrei and Dalmau, V\'{\i}ctor},
title = {A Simple Algorithm for Mal'tsev Constraints},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {36},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/050628957},
doi = {10.1137/050628957},
abstract = {A Mal'tsev operation is a ternary operation $varphi$ that satisfies the identities $varphi(x,y,y) = varphi(y,y,x) = x$. Constraint satisfaction problems involving constraints invariant under a Mal'tsev operation constitute an important class of constraint satisfaction problems, which includes the affine satisfiability problem, subgroup and near subgroup constraints, and many others. It is also known that any tractable case of the counting constraint satisfaction problem involves only Mal'tsev constraints.The first algorithm solving the arbitrary constraint satisfaction problem with Mal'tsev constraints has been given by Bulatov. However, this algorithm is very sophisticated and relies heavily on advanced algebraic machinery. In this paper, we give a different and much simpler algorithm for this type of constraint.},
journal = {SIAM J. Comput.},
month = jul,
pages = {16–27},
numpages = {12},
keywords = {constraint satisfaction, Mal'tsev}
}

@article{10.1137/S009753970444644X,
author = {Jonsson, Peter and Klasson, Mikael and Krokhin, Andrei},
title = {The Approximability of Three-Valued MAX CSP},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444644X},
doi = {10.1137/S009753970444644X},
abstract = {In the maximum constraint satisfaction problem (MAX CSP), one is given a finite collection of (possibly weighted) constraints on overlapping sets of variables, and the goal is to assign values from a given domain to the variables so as to maximize the number (or the total weight, for the weighted case) of satisfied constraints. This problem is NP-hard in general, and, therefore, it is natural to study how restricting the allowed types of constraints affects the approximability of the problem. It is known that every Boolean (that is, two-valued) MAX CSP with a finite set of allowed constraint types is either solvable exactly in polynomial time or else APX-complete (and hence can have no polynomial-time approximation scheme unless P=NP). It has been an open problem for several years whether this result can be extended to non-Boolean MAX CSP, which is much more difficult to analyze than the Boolean case. In this paper, we make the first step in this direction by establishing this result for MAX CSP over a three-element domain. Moreover, we present a simple description of all polynomial-time solvable cases of our problem. This description uses the well-known algebraic combinatorial property of supermodularity. We also show that every hard three-valued MAX CSP contains, in a certain specified sense, one of the two basic hard MAX CSPs which are the Maximum k-Colorable Subgraph problems for k=2,3.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1329–1349},
numpages = {21},
keywords = {supermodularity, approximability, dichotomy, maximum constraint satisfaction}
}

@article{10.1137/S0097539704446360,
author = {Weihrauch, Klaus and Zhong, Ning},
title = {An Algorithm for Computing Fundamental Solutions},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446360},
doi = {10.1137/S0097539704446360},
abstract = {For a partial differential operator $P=sum _{|alpha |leq m}c_{alpha }D^{alpha }$ with constant coefficients, a generalized function $u$ is a fundamental solution if $Pu=delta$, where $delta$ is the Dirac distribution. In this article, we provide an algorithm which computes a fundamental solution for every such differential operator $P$ on a Turing machine if the input- and output-data are represented canonically.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1283–1294},
numpages = {12},
keywords = {computable analysis, fundamental solution, partial differential equations}
}

@article{10.1137/S009753970444435X,
author = {Berenbrink, Petra and Czumaj, Artur and Steger, Angelika and V\"{o}cking, Berthold},
title = {Balanced Allocations: The Heavily Loaded Case},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444435X},
doi = {10.1137/S009753970444435X},
abstract = {We investigate balls-into-bins processes allocating $m$ balls into $n$ bins based on the multiple-choice paradigm. In the classical  single-choice  variant each ball is placed into a bin selected uniformly at random. In a  multiple-choice  process each ball can be placed into one out of $d ge 2$ randomly selected bins. It is known that in many scenarios having more than one choice for each ball can improve the load balance significantly. Formal analyses of this phenomenon prior to this work considered mostly the lightly loaded case, that is, when $m approx n$. In this paper we present the first  tight  analysis in the  heavily loaded  case, that is, when $m gg n$ rather than $m approx n$. The best previously known results for the multiple-choice processes in the heavily loaded case were obtained using majorization by the single-choice process. This yields an upper bound of the maximum load of bins of $m/n + {mbox{$cal O$}}(sqrt{m ln n ,/, n})$ with high probability. We show, however, that the multiple-choice processes are fundamentally different from the single-choice variant in that they have "  short memory ." The great consequence of this property is that the deviation of the multiple-choice processes from the optimal allocation (that is, the allocation in which each bin has either $lfloor m/n rfloor$ or $lceil m/n rceil$ balls) does not increase with the number of balls as in the case of the single-choice process. In particular, we investigate the allocation obtained by two different multiple-choice allocation schemes, the greedy scheme due to Azar et al. and the always-go-left scheme due to V\"{o}cking. We show that these schemes result in a maximum load of only $m/n + {mbox{$cal O$}}(ln ln n)$ with high probability. All our detailed bounds on the maximum load are tight up to an additive constant.Furthermore, we investigate the two multiple-choice algorithms in a comparative study. We present a majorization result showing that the always-go-left scheme obtains a better load balancing than the greedy scheme for any choice of $n$, $m$, and $d$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1350–1385},
numpages = {36},
keywords = {occupancy problems, balls-into-bins processes, randomized resource allocation}
}

@article{10.1137/S0097539703437491,
author = {Chern, Hua-Huai and Hwang, Hsien-Kuei},
title = {Partial Match Queries in Random <i>k</i>-d Trees},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703437491},
doi = {10.1137/S0097539703437491},
abstract = {We solve the open problem of characterizing the leading constant in the asymptotic approximation to the expected cost used for random partial match queries in random k-d trees. Our approach is new and of some generality; in particular, it is applicable to many problems involving differential equations (or difference equations) with polynomial coefficients.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1440–1466},
numpages = {27},
keywords = {$k$-d trees, differential equations, method of linear operators, asymptotic analysis, partial match queries, average-case analysis of algorithms}
}

@article{10.1137/S0097539703437211,
author = {Abiteboul, Serge and Alstrup, Stephen and Kaplan, Haim and Milo, Tova and Rauhe, Theis},
title = {Compact Labeling Scheme for Ancestor Queries},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703437211},
doi = {10.1137/S0097539703437211},
abstract = {We consider the following problem. Given a rooted tree $T$, label the nodes of $T$ in the most compact way such that, given the labels of two nodes $u$ and $v$, one can determine in constant time, by looking only at the labels, whether $u$ is ancestor of $v$. The best known labeling scheme is rather straightforward and uses labels of length at most $2log_2 n$ bits each, where $n$ is the number of nodes in the tree. Our main result in this paper is a labeling scheme with maximum label length $log_2 n + Oh(sqrt{log n})$. Our motivation for studying this problem is enhancing the performance of web search engines. In the context of this application each indexed document is a tree, and the labels of all trees are maintained in main memory. Therefore even small improvements in the maximum label length are important.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1295–1309},
numpages = {15},
keywords = {ancestor queries, labeling algorithm, rooted tree, alphabetic codes}
}

@article{10.1137/S0097539703436722,
author = {Mortensen, Christian Worm},
title = {Fully Dynamic Orthogonal Range Reporting on RAM},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436722},
doi = {10.1137/S0097539703436722},
abstract = {We show that there exists a constant $omega &lt; 1$ such that the fully dynamic $d$-dimensional orthogonal range reporting problem for any constant $d ge 2$ can be solved in time $O(log^{omega+d-2} n)$ for updates and time $O((log n / loglog n)^{d-1} + r)$ for queries. Here $n$ is the number of points stored and $r$ is the number of points reported. The space usage is $O(n log^{omega+d-2} n)$. For $d=2$ our results are optimal in terms of time per operation, and this is the main contribution of this paper. Also for $d=2$, we give a new improved fully dynamic structure supporting 3-sided queries. The model of computation is a unit cost RAM@. We order the coordinates of points using list order as defined in the paper.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1494–1525},
numpages = {32},
keywords = {orthogonal, data structures, range searching}
}

@article{10.1137/S0097539702410065,
author = {Geerts, Floris and Kuijpers, Bart and Bussche, Jan Vanden},
title = {Linearization and Completeness Results  for Terminating Transitive Closure Queries  on Spatial Databases},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702410065},
doi = {10.1137/S0097539702410065},
abstract = {We study queries to spatial databases, where spatial data are modeled as semi-algebraic sets, using the relational calculus with polynomial inequalities as a basic query language. We work with the extension of the relational calculus with terminating transitive closures. The main result is that this language can express the linearization of semialgebraic databases. We also show that the sublanguage with linear inequalities only can express all computable queries on semilinear databases. As a consequence of these results, we obtain a completeness result for topological queries on semialgebraic databases.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1386–1439},
numpages = {54},
keywords = {query languages, real algebraic geometry, transitive closure logics, constraint databases}
}

@article{10.1137/050644719,
author = {D\"{u}rr, Christoph and Heiligman, Mark and HOyer, Peter and Mhalla, Mehdi},
title = {Quantum Query Complexity of Some Graph Problems},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/050644719},
doi = {10.1137/050644719},
abstract = {Quantum algorithms for graph problems are considered, both in the adjacency matrix model and in an adjacency list-like array model.  We give almost tight lower and upper bounds for the bounded error quantum query complexity of Connectivity, Strong Connectivity, Minimum Spanning Tree, and Single Source Shortest Paths.  For example, we show that the query complexity of Minimum Spanning Tree is in $Theta(n^{3/2})$ in the matrix model and in $Theta(sqrt{nm})$ in the array model, while the complexity of Connectivity is also in $Theta(n^{3/2})$ in the matrix model but in $Theta(n)$ in the array model.  The upper bounds utilize search procedures for finding minima of functions under various conditions.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1310–1328},
numpages = {19},
keywords = {connectivity, minimum spanning tree, lower bound, single source shortest paths, quantum algorithm, graph theory}
}

@article{10.1137/050628994,
author = {Allender, Eric and Buhrman, Harry and Kouck\'{y}, Michal and Melkebeek, Dieter van and Ronneburger, Detlef},
title = {Power from Random Strings},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/050628994},
doi = {10.1137/050628994},
abstract = {We show that sets consisting of strings of high Kolmogorov complexity provide examples of sets that are complete for several complexity classes under probabilistic and nonuniform reductions. These sets are provably not complete under the usual many-one reductions.Let ${{R_{rm C}}}, {{R_{rm Kt}}}, {{R_{rm KS}}}, {{R_{rm KT}}}$ be the sets of strings $x$ having complexity at least $|x|/2$, according to the usual Kolmogorov complexity measure ${mbox{rm C}}$, Levin's time-bounded Kolmogorov complexity ${mbox{rm Kt}}$ [L. Levin, Inform. and Control, 61 (1984), pp. 15-37], a space-bounded Kolmogorov measure ${mbox{rm KS}}$, and a new time-bounded Kolmogorov complexity measure ${mbox{rm KT}}$, respectively.Our main results are as follows:begin{remunerate} item ${{R_{rm KS}}}$ and ${{R_{rm Kt}}}$ are complete for ${{rm{PSPACE}}}$ and {mbox{rm EXP}}, respectively, under ${mbox{rm P/poly}}$-truth-table reductions. Similar results hold for other classes with ${{rm{PSPACE}}}$-robust Turing complete sets.item ${mbox{rm EXP}} = {mbox{rm NP}}^{{{R_{rm Kt}}}}.$item ${{rm{PSPACE}}} = {mbox{rm ZPP}}^{{{R_{rm KS}}}} subseteq {mbox{rm P}}^{{{R_{rm C}}}}$.item The Discrete Log, Factoring, and several lattice problems are solvable in ${mbox{rm BPP}}^{{{R_{rm KT}}}}$. end{remunerate}Our hardness result for ${{rm{PSPACE}}}$ gives rise to fairly natural problems that are complete for ${{rm{PSPACE}}}$ under ${mbox{$leq^{rm p}_{rm T}$}}$ reductions, but not under ${mbox{$leq^{rm log}_{rm m}$}}$ reductions.Our techniques also allow us to show that all computably enumerable sets are reducible to ${{R_{rm C}}}$ via ${mbox{rm P/poly}}$-truth-table reductions. This provides the first "efficient" reduction of the halting problem to ${{R_{rm C}}}$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1467–1493},
numpages = {27},
keywords = {randomness, Kolmogorov complexity, reductions, completeness, derandomization}
}

@article{10.1137/S0097539799358094,
author = {Queyranne, Maurice and Schulz, Andreas S.},
title = {Approximation Bounds for a General Class of Precedence Constrained Parallel Machine Scheduling Problems},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799358094},
doi = {10.1137/S0097539799358094},
abstract = {An important class of scheduling problems concerns parallel machines and precedence constraints. We consider precedence delays, which associate with each precedence constraint a certain amount of time that must elapse between the completion and start times of the corresponding jobs. Together with ordinary precedence constraints, release dates and delivery times can be modeled in this manner. We present a 4-approximation algorithm for the total weighted completion time objective for this general class of problems. The algorithm is a rather simple form of list scheduling. The list is in order of job midpoints derived from a linear programming relaxation. Our analysis unifies and simplifies that of a number of special cases heretofore separately studied, while actually improving many of the former approximation results.},
journal = {SIAM J. Comput.},
month = may,
pages = {1241–1253},
numpages = {13},
keywords = {performance guarantee, precedence constraints, scheduling, linear programming relaxation, approximation algorithm}
}

@article{10.1137/S0097539799350608,
author = {Petersen, Holger and Robson, John Michael},
title = {Efficient Simulations by Queue Machines},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799350608},
doi = {10.1137/S0097539799350608},
abstract = {The following simulations by machines equipped with a one-way input tape and additional queue storage are shown: Every nondeterministic single-tape Turing machine (no separate input-tape) with time bound $t(n)$ can be simulated by one queue in $O(t(n))$ time. Every deterministic machine with a one-turn pushdown store can be simulated deterministically by one queue in $O(nsqrt{n})$ time. Every Turing machine with several multidimensional tapes accepting with time bound $t(n)$ can be simulated by two queues in $O(t(n) log^2 t(n))$ time. Every deterministic Turing machine with several linear tapes accepting with time bound $t(n)$ can be simulated deterministically in time $O(t(n) log t(n))$ by a queue and a pushdown store. The first two results appear to be the first subquadratic simulations of other storage devices by one queue.},
journal = {SIAM J. Comput.},
month = may,
pages = {1059–1069},
numpages = {11},
keywords = {grammars, multiqueue machines, simulation, upper bounds, multitape machines, pushdown automata}
}

@article{10.1137/S0097539704446529,
author = {Jansson, Jesper and Nguyen, Nguyen Bao and Sung, Wing-Kin},
title = {Algorithms for Combining Rooted Triplets into a Galled Phylogenetic Network},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446529},
doi = {10.1137/S0097539704446529},
abstract = {This paper considers the problem of determining whether a given set $T$ of rooted triplets can be merged without conflicts into a galled phylogenetic network and, if so, constructing such a network. When the input $T$ is dense, we solve the problem in $O(|T|)$ time, which is optimal since the size of the input is $Theta(|T|)$. In comparison, the previously fastest algorithm for this problem runs in $O(|T|^2)$ time. We also develop an optimal $O(|T|)$-time algorithm for enumerating all simple phylogenetic networks leaf-labeled by $L$ that are consistent with $T$, where $L$ is the set of leaf labels in $T$, which is used by our main algorithm. Next, we prove that the problem becomes NP-hard if extended to nondense inputs, even for the special case of simple phylogenetic networks. We also show that for every positive integer $n$, there exists some set $T$ of rooted triplets on $n$ leaves such that any galled network can be consistent with at most $0.4883 cdot |T|$ of the rooted triplets in $T$. On the other hand, we provide a polynomial-time approximation algorithm that always outputs a galled network consistent with at least a factor of $frac{5}{12}$ ($&gt; 0.4166$) of the rooted triplets in $T$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1098–1121},
numpages = {24},
keywords = {algorithm, rooted triplet, phylogenetic network, galled network, $SN$-tree, NP-hardness}
}

@article{10.1137/S0097539704446281,
author = {Har-Peled, Sariel and Mendel, Manor},
title = {Fast Construction of Nets in Low-Dimensional Metrics and Their Applications},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446281},
doi = {10.1137/S0097539704446281},
abstract = {We present a near linear time algorithm for constructing hierarchical nets in finite metric spaces with constant doubling dimension.  This data-structure is then applied to obtain improved algorithms for the following problems: approximate nearest neighbor search, well-separated pair decomposition, spanner construction, compact representation scheme, doubling measure, and computation of the (approximate) Lipschitz constant of a function.  In all cases, the running (preprocessing) time is near linear and the space being used is linear.},
journal = {SIAM J. Comput.},
month = may,
pages = {1148–1184},
numpages = {37},
keywords = {distance labeling, doubling dimension, approximate distance oracle, quadtree, metric nets, doubling measure, nearest neighbor search}
}

@article{10.1137/S0097539704445950,
author = {Lohrey, Markus},
title = {Word Problems and Membership Problems on Compressed Words},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445950},
doi = {10.1137/S0097539704445950},
abstract = {We consider a compressed form of the word problem for finitely presented monoids, where the input consists of two compressed representations of words over the generators of a monoid M, and we ask whether these two words represent the same monoid element of M. Words are compressed using straight-line programs, i.e., context-free grammars that generate exactly one word. For several classes of finitely presented monoids we obtain completeness results for complexity classes in the range from P to EXPSPACE. As a by-product of our results on compressed word problems we obtain a fixed deterministic context-free language with a PSPACE-complete compressed membership problem. The existence of such a language was open so far. Finally, we will investigate the complexity of the compressed membership problem for various circuit complexity classes.},
journal = {SIAM J. Comput.},
month = may,
pages = {1210–1240},
numpages = {31},
keywords = {complexity, word problems for monoids, grammar-based compression, context-free languages}
}

@article{10.1137/S0097539704445597,
author = {Niggl, Karl-Heinz and Wunderlich, Henning},
title = {Certifying Polynomial Time and Linear/Polynomial Space for Imperative Programs},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445597},
doi = {10.1137/S0097539704445597},
abstract = {In earlier work of Kristiansen and Niggl the polynomial-time computable functions were characterized by stack programs of $mu$-measure $0$, and the linear-space computable functions by loop programs of $mu$-measure $0$. Until recently, an open problem was how to extend these characterizations to programs with user-friendly basic instructions, such as assignment statements, and with mixed data structures. It is shown how to strengthen the above characterizations to imperative programs built from arbitrary basic instructions by sequencing and by if-then-else and for-do statements. These programs operate on variables, each of which may represent any data structure such as stacks, registers, trees, or graphs.The paper presents a new method of certifying "polynomial size boundedness" of such imperative programs under the natural assumption that the basic instructions used are polynomially size bounded, too. The certificate for a program ${tt P}$ with variables among ${tt X}_{1}, ldots, {tt X}_{n}$ will be an $(n+1)times (n+1)$ matrix $M({tt P})$ over the finite set ${ 0, 1, infty}$.It is shown that certified string programs (i.e., stack programs, but with any polynomial-time computable basic instructions) exactly compute the functions in {sc fptime}. Accordingly, certified general loop programs (using any linear-space computable basic instructions) exactly compute the functions in {sc flinspace}.Furthermore, it is shown that certified power string programs (i.e., string programs, but built from polynomial-space computable basic instructions and extended by power loop statements) exactly compute the polynomial-space computable functions in {sc fpspace}.In addition, examples of certified "natural" (implementations of) algorithms, such as insertion-sort or binary addition and multiplication, are given.},
journal = {SIAM J. Comput.},
month = may,
pages = {1122–1147},
numpages = {26},
keywords = {static program analysis, polynomial space, linear space, property testing, polynomial time, imperative programming languages, implicit computational complexity}
}

@article{10.1137/S0097539704445226,
author = {Kempe, Julia and Kitaev, Alexei and Regev, Oded},
title = {The Complexity of the Local Hamiltonian Problem},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445226},
doi = {10.1137/S0097539704445226},
abstract = {The $k$-{locHam} problem is a natural complete problem for the complexity class $QMA$, the quantum analogue of $NP$.  It is similar in spirit to {sc MAX-$k$-SAT}, which is $NP$-complete for $kgeq 2$. It was known that the problem is $QMA$-complete for any $k geq 3$. On the other hand, 1-{locHam} is in {P} and hence not believed to be $QMA$-complete. The complexity of the 2-{locHam} problem has long been outstanding. Here we settle the question and show that it is $QMA$-complete. We provide two independent proofs; our first proof uses only elementary linear algebra. Our second proof uses a powerful technique for analyzing the sum of two Hamiltonians; this technique is based on perturbation theory and we believe that it might prove useful elsewhere. Using our techniques we also show that adiabatic computation with 2-local interactions on qubits is equivalent to standard quantum computation.},
journal = {SIAM J. Comput.},
month = may,
pages = {1070–1097},
numpages = {28},
keywords = {adiabatic computation, complete problems, quantum computation, local Hamiltonian problem}
}

@article{10.1137/S0097539704383633,
author = {Naor, Moni and Pinkas, Benny},
title = {Oblivious Polynomial Evaluation},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704383633},
doi = {10.1137/S0097539704383633},
abstract = {Oblivious polynomial evaluation is a protocol involving two parties, a sender whose input is a polynomial P, and a receiver whose input is a value $alpha$. At the end of the protocol the receiver learns $P(alpha)$ and the sender learns nothing. We describe efficient constructions for this protocol, which are based on new intractability assumptions that are closely related to noisy polynomial reconstruction. Oblivious polynomial evaluation can be used as a primitive in many applications. We describe several such applications, including protocols for private comparison of data, for mutually authenticated key exchange based on (possibly weak) passwords, and for anonymous coupons.},
journal = {SIAM J. Comput.},
month = may,
pages = {1254–1281},
numpages = {28},
keywords = {cryptography, noisy polynomial reconstruction, secure computation}
}

@article{10.1137/S0097539703436734,
author = {Curran, Sean and Lee, Orlando and Yu, Xingxing},
title = {Finding Four Independent Trees},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436734},
doi = {10.1137/S0097539703436734},
abstract = {Motivated by a multitree approach to the design of reliable communication protocols, Itai and Rodeh gave a linear time algorithm for finding two independent spanning trees in a 2-connected graph. Cheriyan and Maheshwari gave an $O(|V|^2)$ algorithm for finding three independent spanning trees in a 3-connected graph.  In this paper we present an $O(|V|^3)$ algorithm for finding four independent spanning trees in a 4-connected graph. We make use of chain decompositions of 4-connected graphs.},
journal = {SIAM J. Comput.},
month = may,
pages = {1023–1058},
numpages = {36},
keywords = {independent trees, numbering, Connectivity, chain decomposition, algorithm}
}

@article{10.1137/S0097539703431032,
author = {Reingold, Omer and Shaltiel, Ronen and Wigderson, Avi},
title = {Extracting Randomness via Repeated Condensing},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703431032},
doi = {10.1137/S0097539703431032},
abstract = {Extractors (as defined by Nisan and Zuckerman) are procedures that use a  small  number of truly random bits (called the seed) to extract  many  (almost) truly random bits from arbitrary distributions as long as distributions have sufficient (min)-entropy. A natural weakening of an extractor is a  condenser , whose output distribution has a higher entropy rate than the input distribution (without losing much of the initial entropy). An extractor can be viewed as an ultimate condenser because it outputs a distribution with the maximal entropy rate. In this paper we construct explicit condensers with short seed length. The condenser constructions combine (variants of or more efficient versions of) ideas from several works, including the block extraction scheme of [N. Nisan and D. Zuckerman,  J. Comput. System Sci. , 52 (1996), pp. 43-52], the observation made in [A. Srinivasan and D. Zuckerman,  SIAM J. Comput. , 28 (1999), pp. 1433-1459; N. Nisan and A. Ta-Shma,  J. Comput. System Sci. , 58 (1999), pp. 148-173] that a failure of the block extraction scheme is also useful, the recursive "win-win" case analysis of [R. Impagliazzo, R. Shaltiel, and A. Wigderson,  Near-optimal conversion of hardness into pseudo-randomness , in Proceedings of the 40th Annual IEEE Symposium on Foundations of Computer Science, IEEE, Los Alamitos, CA, 1999, pp. 181-190; R. Impagliazzo, R. Shaltiel, and A. Wigderson,  Extractors and pseudo-random generators with optimal seed length , in Proceedings of the 32nd Annual ACM Symposium on Theory of Computing, ACM, New York, 2000, pp. 1-10], and the error correction of random sources used in [L. Trevisan,  J. ACM , 48 (2001), pp. 860-879]. As a by-product (via repeated iterating of condensers), we obtain new extractor constructions. The new extractors give significant qualitative improvements over previous ones for sources of arbitrary min-entropy; they are nearly optimal  simultaneously  in the two main parameters of seed length and output length. Specifically, our extractors can make any one of these two parameters optimal (up to a constant factor) only at a  polylogarithmic  loss in the other. Previous constructions require  polynomial  loss in both cases for general sources.We also give a simple reduction converting "standard" extractors (which are good for an average seed) into "strong" ones (which are good for most seeds), with essentially the same parameters. With this reduction, all the above improvements apply to strong extractors as well.},
journal = {SIAM J. Comput.},
month = may,
pages = {1185–1209},
numpages = {25},
keywords = {derandomization, randomness condensers, randomness extractors}
}

@article{10.1137/S0097539702424496,
author = {Amir, Amihood and Aumann, Yonatan and Lewenstein, Moshe and Porat, Ely},
title = {Function Matching},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702424496},
doi = {10.1137/S0097539702424496},
abstract = {We present problems in the following three application areas: identifying similar codes in which global register reallocation and spill code minimization were done (programming languages); protein threading (computational biology); and searching for color icons under different color maps (image processing). We introduce a new search model called  function matching  that enables us to solve the above problems. The  function matching problem  has as its input a text $T$ of length $n$ over alphabet $Sigma_T$ and a pattern $P = P[1] P[2] cdots P[m]$ of length $m$ over alphabet $Sigma_P$. We seek all text locations $i$, where the $m$-length substring that starts at $i$ is equal to $f(P[1]) f(P[2]) cdots f(P[m])$, for some function $f: Sigma_P rightarrow Sigma_T$.We give a randomized algorithm that solves the function matching problem in time $O(nlog n)$ with probability ${1over n}$ of declaring a false positive. We give a deterministic algorithm whose time is $O(n |Sigma_P| log m)$ and show that it is optimal in the convolutions model. We use function matching to efficiently solve the problem of two-dimensional parameterized matching.},
journal = {SIAM J. Comput.},
month = may,
pages = {1007–1022},
numpages = {16},
keywords = {function matching, parameterized matching, color maps, pattern matching}
}

@article{10.1137/S0097539705447293,
author = {Bienstock, D. and Iyengar, G.},
title = {Approximating Fractional Packings and Coverings in <i>O</i>(1/Epsilon) Iterations},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447293},
doi = {10.1137/S0097539705447293},
abstract = {We adapt a method proposed by Nesterov [Math. Program. Ser. A, 103 (2005), pp. 127-152] to design an algorithm that computes $epsilon$-optimal solutions to fractional packing problems by solving $O(epsilon^{-1}sqrt{Knln(m)})$ separable convex quadratic programs, where $n$ is the number of variables, $m$ is the number of constraints, and $K$ is the maximum number of nonzero elements in any constraint.  We show that the quadratic program can be approximated to any degree of accuracy   by  an appropriately defined piecewise-linear  program. For the special case of the maximum concurrent flow problem on a graph $G = (V,E)$ with rational capacities and demands,  we obtain an algorithm that computes an   $epsilon$-optimal flow by solving  shortest path problems, i.e., problems in which the number of shortest paths computed  grows as $O(epsilon^{-1} log(epsilon^{-1}))$ in $epsilon$ and polynomially in   the size of the problem. In contrast, previous   algorithms required   $Omega(epsilon^{-2})$ iterations. We also describe   extensions to the maximum multicommodity flow problem, the pure covering problem, and mixed packing-covering problem.},
journal = {SIAM J. Comput.},
month = apr,
pages = {825–854},
numpages = {30},
keywords = {multicommodity flows, approximation algorithms, packing problems}
}

@article{10.1137/S0097539705447281,
author = {Healy, Alexander and Vadhan, Salil and Viola, Emanuele},
title = {Using Nondeterminism to Amplify Hardness},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447281},
doi = {10.1137/S0097539705447281},
abstract = {We revisit the problem of hardness amplification in $mathcal{NP}$, as recently studied by O'Donnell [  J. Comput. System Sci. , 69 (2004), pp. 68-94]. We prove that if $mathcal{NP}$ has a balanced function $f$ such that any circuit of size $s(n)$ fails to compute $f$ on a $1/poly(n)$ fraction of inputs, then $mathcal{NP}$ has a function $f'$ such that any circuit of size $s'(n)=s(sqrt{n})^{Omega(1)}$ fails to compute $f'$ on a $1/2 - 1/s'(n)$ fraction of inputs. In particular, begin{enumerate} item if $s(n)=n^{omega(1)}$, we amplify to hardness $1/2-1/n^{omega(1)}$; item if $s(n)=2^{n^{Omega(1)}}$, we amplify to hardness $1/2-1/2^{n^{Omega(1)}}$; item if $s(n)=2^{Omega(n)}$, we amplify to hardness $1/2-1/2^{Omega(sqrt{n})}$. end{enumerate} Our results improve those of of O'Donnell, which amplify to $1/2-1/sqrt{n}$. O'Donnell also proved that no construction of a certain general form could amplify beyond $1/2-1/n$. We bypass this barrier by using both  derandomization  and  nondeterminism  in the construction of $f'$.We also prove impossibility results demonstrating that both our use of nondeterminism and the hypothesis that $f$ is balanced are necessary for "black-box" hardness amplification procedures (such as ours).},
journal = {SIAM J. Comput.},
month = apr,
pages = {903–931},
numpages = {29},
keywords = {hardness amplification, pseudorandom generators for space-bounded computation, noise stability, average-case complexity}
}

@article{10.1137/S009753970544727X,
author = {Lov\'{a}sz, L\'{a}szl\'{o} and Vempala, Santosh},
title = {Hit-and-Run from a Corner},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970544727X},
doi = {10.1137/S009753970544727X},
abstract = {We show that the hit-and-run random walk mixes rapidly starting from any interior point of a convex body. This is the first random walk known to have this property. In contrast, the ball walk can take exponentially many steps from some starting points. The proof extends to sampling an exponential density over a convex body.},
journal = {SIAM J. Comput.},
month = apr,
pages = {985–1005},
numpages = {21},
keywords = {sampling, random walks, isoperimetric inequalities}
}

@article{10.1137/S0097539705447268,
author = {Beier, Rene and V\"{o}cking, Berthold},
title = {Typical Properties of Winners and Losers [0.2ex] in Discrete Optimization},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447268},
doi = {10.1137/S0097539705447268},
abstract = {We present a probabilistic analysis of a large class of combinatorial optimization problems containing all binary optimization problems defined by linear constraints and a linear objective function over ${0,1}^n$. Our analysis is based on a semirandom input model that preserves the combinatorial structure of the underlying optimization problem by parameterizing which input numbers are of a stochastic and which are of an adversarial nature.  This input model covers various probability distributions for the choice of the stochastic numbers and includes smoothed analysis with Gaussian and other kinds of perturbation models as a special case.  In fact, we can exactly characterize the smoothed complexity of binary optimization problems in terms of their worst-case complexity: A binary optimization problem has polynomial smoothed complexity if and only if it admits a (possibly randomized) algorithm with pseudo-polynomial worst-case complexity.Our analysis is centered around structural properties of binary optimization problems, called winner, loser, and feasibility gap. We show that if the coefficients of the objective function are stochastic, then the gap between the best and second best solution is likely to be of order $Omega(1/n)$.  Furthermore, we show that if the coefficients of the constraints are stochastic, then the slack of the optimal solution with respect to this constraint is typically of order $Omega(1/n^2)$. We exploit these properties in an adaptive rounding scheme that increases the accuracy of calculation until the optimal solution is found. The strength of our techniques is illustrated by applications to various npc-hard optimization problems from mathematical programming, network design, and scheduling for which we obtain the first algorithms with polynomial smoothed/average-case complexity.},
journal = {SIAM J. Comput.},
month = apr,
pages = {855–881},
numpages = {27},
keywords = {average-case analysis, optimization problems, smoothed analysis}
}

@article{10.1137/S0097539705447256,
author = {Patrascu, Mihai and Demaine, Erik D.},
title = {Logarithmic Lower Bounds in the Cell-Probe Model},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447256},
doi = {10.1137/S0097539705447256},
abstract = {We develop a new technique for proving cell-probe lower bounds on dynamic data structures.  This technique enables us to prove an amortized randomized $Omega(lg n)$ lower bound per operation for several data structural problems on $n$ elements, including partial sums, dynamic connectivity among disjoint paths (or a forest or a graph), and several other dynamic graph problems (by simple reductions).  Such a lower bound breaks a long-standing barrier of $Omega(lg n,/lglg n)$ for any dynamic language membership problem.  It also establishes the optimality of several existing data structures, such as Sleator and Tarjan's dynamic trees.  We also prove the first $Omega(log_B n)$ lower bound in the external-memory model without assumptions on the data structure (such as the comparison model).  Our lower bounds also give a query-update trade-off curve matched, e.g., by several data structures for dynamic connectivity in graphs.  We also prove matching upper and lower bounds for partial sums when parameterized by the word size and the maximum additive change in an update.},
journal = {SIAM J. Comput.},
month = apr,
pages = {932–963},
numpages = {32},
keywords = {dynamic graph problems, partial-sums problem, data structures, cell-probe complexity, lower bounds}
}

@article{10.1137/S0097539705447244,
author = {Kelner, Jonathan A.},
title = {Spectral Partitioning, Eigenvalue Bounds, and Circle Packings for Graphs of Bounded Genus},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447244},
doi = {10.1137/S0097539705447244},
abstract = {In this paper, we address two long-standing questions about finding good separators in graphs of bounded genus and degree: 1. It is a classical result of Gilbert, Hutchinson, and Tarjan [ J. Algorithms, 5 (1984), pp. 391-407] that one can find asymptotically optimal separators on these graphs if given both the graph and an embedding of it onto a low genus surface. Does there exist a simple, efficient algorithm to find these separators, given only the graph and not the embedding 2. In practice, spectral partitioning heuristics work extremely well on these graphs. Is there a theoretical reason why this should be the case We resolve these two questions by showing that a simple spectral algorithm finds separators of cut ratio $O(sqrt{smash[b]{g/n}})$ and vertex bisectors of size $O(sqrt{gn})$ in these graphs, both of which are optimal. As our main technical lemma, we prove an $O(g/n)$ bound on the second smallest eigenvalue of the Laplacian of such graphs and show that this is tight, thereby resolving a conjecture of Spielman and Teng. While this lemma is essentially combinatorial in nature, its proof comes from continuous mathematics, drawing on the theory of circle packings and the geometry of compact Riemann surfaces.},
journal = {SIAM J. Comput.},
month = apr,
pages = {882–902},
numpages = {21},
keywords = {graph separators, partitioning, circle packing, bounded genus, Laplacian, spectral partitioning}
}

@article{10.1137/S0097539704447304,
author = {Feige, Uriel},
title = {On Sums of Independent Random Variables with Unbounded Variance and Estimating the Average Degree in a Graph},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704447304},
doi = {10.1137/S0097539704447304},
abstract = {We prove the following inequality: for every positive integer $n$ and every collection $X_1, ldots, X_n$ of nonnegative independent random variables, each with expectation 1, the probability that their sum remains below $n+1$ is at least $alpha &gt; 0$. Our proof produces a value of $alpha = 1/13 simeq 0.077$, but we conjecture that the inequality also holds with $alpha = 1/e simeq 0.368$.As an example for the use of the new inequality, we consider the problem of estimating the average degree of a graph by querying the degrees of some of its vertices. We show the following threshold behavior: approximation factors above 2 require far fewer queries than approximation factors below 2. The new inequality is used in order to get tight (up to multiplicative constant factors) relations between the number of queries and the quality of the approximation.  We show how the degree approximation algorithm can be used in order to quickly find those edges in a network that belong to many shortest paths.},
journal = {SIAM J. Comput.},
month = apr,
pages = {964–984},
numpages = {21},
keywords = {shortest paths, Markov inequality}
}

@article{10.1137/S0097539704447237,
author = {Aaronson, Scott},
title = {Lower Bounds for Local Search by Quantum Arguments},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704447237},
doi = {10.1137/S0097539704447237},
abstract = {The problem of finding a local minimum of a black-box function is central for understanding local search as well as quantum adiabatic algorithms.  For functions on the Boolean hypercube $left{0,1right}^n$, we show a lower bound of $Omegaleft(2^{n/4}/nright)$ on the number of queries needed by a quantum computer to solve this problem.  More surprisingly, our approach, based on Ambainis's quantum adversary method, also yields a lower bound of $Omegaleft(2^{n/2}/n^2right)$ on the problem's classical randomized query complexity.  This improves and simplifies a 1983 result of Aldous.  Finally, in both the randomized and quantum cases, we give the first nontrivial lower bounds for finding local minima on grids of constant dimension $dgeq3$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {804–824},
numpages = {21},
keywords = {quantum computing, random walks, local optima, query complexity, decision trees, local search, polynomial local search}
}

@article{10.1137/S0097539704441629,
author = {Alon, Noga and Naor, Assaf},
title = {Approximating the Cut-Norm via Grothendieck's Inequality},
year = {2006},
issue_date = {2006},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441629},
doi = {10.1137/S0097539704441629},
abstract = {The cut-norm $||A||_C$ of a real matrix $A=(a_{ij})_{iin R,jin S}$ is the maximum, over all $I subset R$, $J subset S$, of the quantity $|sum_{i in I, jin J} a_{ij}|$. This concept plays a major role in the design of efficient approximation algorithms for dense graph and matrix problems. Here we show that the problem of approximating the cut-norm  of a given real matrix is MAX SNP hard, and we provide an efficient approximation algorithm. This algorithm finds, for a given matrix $A=(a_{ij})_{iin R,jin S}$, two subsets $I subset R$ and $J subset S$, such that $|sum_{i in I, jin J} a_{ij}| geq rho ||A||_C$, where $rho&gt;0$ is an absolute constant satisfying $rho &gt;0.56$. The algorithm combines semidefinite programming with a rounding technique based on Grothendieck's inequality. We present three known proofs of Grothendieck's inequality, with the necessary modifications which emphasize their algorithmic aspects. These proofs contain rounding techniques which go beyond the random hyperplane rounding of Goemans and Williamson [J. ACM, 42 (1995), pp. 1115-1145], allowing us to transfer various algorithms for dense graph and matrix problems to the sparse case.},
journal = {SIAM J. Comput.},
month = apr,
pages = {787–803},
numpages = {17},
keywords = {semidefinite programming, Szemer\'{e}di partitions, approximation algorithms, Grothendieck's inequality, cut-norm}
}

@article{10.1137/S0097539799365462,
author = {Wagh, Meghanad D. and Guzide, Osman},
title = {Mapping Cycles and Trees on Wrap-Around Butterfly Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799365462},
doi = {10.1137/S0097539799365462},
abstract = {We give a new algebraic representation for the wrap-around butterfly interconnection network.  This new representation is based on the direct product of groups and finite fields and allows an algebraic expression of the network connectivity.  The abstract algebraic tools may then be employed to explore the structural properties of the butterfly.  In this paper we exploit this model to map guest graphs on the butterfly.  In particular, we provide designs of unit dilation mappings of all possible length cycles on butterflies.  We also map the largest possible binary trees on butterfly networks with a dilation 2 if the network degree is less than 16, 3 if it is less than 32, and 4 if it is less than 64.  This is a great improvement over previous results.},
journal = {SIAM J. Comput.},
month = sep,
pages = {741–765},
numpages = {25},
keywords = {mathematical model, butterfly graphs, finite field, trees, mapping, cycles}
}

@article{10.1137/S0097539799361737,
author = {Jansen, Klaus and Porkolab, Lorant},
title = {General Multiprocessor Task Scheduling: Approximate Solutions in Linear Time},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799361737},
doi = {10.1137/S0097539799361737},
abstract = {We study the problem of scheduling $n$ independent tasks on a set of $m$ parallel processors, where the execution time of a task is a function of the subset of processors assigned to the task. For any fixed $m$, we propose a fully polynomial approximation scheme that for any fixed $epsilon &gt; 0$ finds a preemptive schedule of length at most $(1+epsilon)$ times the optimum in $O(n)$ time. We also discuss the nonpreemptive variant of the problem, and present for any fixed $m$ a polynomial approximation scheme that computes an approximate solution of any fixed accuracy in linear time. In terms of the running time, this linear complexity bound gives a substantial improvement of the best previously known polynomial bound [J. Chen and A. Miranda, SIAM J. Comput., 31 (2001), pp. 1--17].},
journal = {SIAM J. Comput.},
month = sep,
pages = {519–530},
numpages = {12},
keywords = {approximation algorithms, linear programming, scheduling problem}
}

@article{10.1137/S0097539705447086,
author = {Goldstein, Darin and Kobayashi, Kojiro},
title = {On the Complexity of Network Synchronization},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705447086},
doi = {10.1137/S0097539705447086},
abstract = {We show that if a minimal-time solution to a fundamental distributed computation primitive, synchronizing a network path of finite-state processors, exists on the three-dimensional, undirected grid, then we can conclude the purely complexity-theoretic result $P = NP$. Every previous result on network synchronization for various network topologies either demonstrates the existence of fast synchronization solutions or proves that a synchronization solution cannot exist at all. To date, it is unknown whether there is a network topology for which there exists a synchronization solution but for which no minimal-time synchronization solution exists. Under the assumption that $P neq NP$, this paper solves this longstanding open problem in the affirmative.},
journal = {SIAM J. Comput.},
month = sep,
pages = {567–589},
numpages = {23},
keywords = {firing squad synchronization problem, network synchronization, distributed computation}
}

@article{10.1137/S0097539704446797,
author = {Vertigan, Dirk},
title = {The Computational Complexity of Tutte Invariants for Planar Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446797},
doi = {10.1137/S0097539704446797},
abstract = {For each pair of algebraic numbers $(x,y)$, the complexity of computing the Tutte polynomial $T(G;x,y)$ of a planar graph $G$ is determined. This computation is found to be $overline{rm#P}$-complete except when $(x-1)(y-1)=1,2$ or when $(x,y)$ is one of $(1,1)$, $(-1,-1)$, $(j,j^2)$, or $(j^2,j)$, where $j=e^{2pi i/3}$, in which case it is polynomial time computable. A corollary gives the computational complexity of various enumeration problems for planar graphs.},
journal = {SIAM J. Comput.},
month = sep,
pages = {690–712},
numpages = {23},
keywords = {enumeration, knot polynomials, reliability, polynomial time, computational complexity, Tutte polynomial, percolation, planar graphs, Potts model, $ZP$-complete}
}

@article{10.1137/S0097539704446323,
author = {Kjos-Hanssen, Bjorn and Nies, Andr\'{e} and Stephan, Frank},
title = {Lowness for the Class of Schnorr Random Reals},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446323},
doi = {10.1137/S0097539704446323},
abstract = {We answer a question of Ambos-Spies and Kucera in the affirmative. They asked whether, when a real is low for Schnorr randomness, it is already low for Schnorr tests.},
journal = {SIAM J. Comput.},
month = sep,
pages = {647–657},
numpages = {11},
keywords = {Schnorr randomness, lowness, recursion theory, Turing degrees, computability theory, randomness}
}

@article{10.1137/S009753970444572X,
author = {Chazelle, Bernard and Liu, Ding and Magen, Avner},
title = {Sublinear Geometric Algorithms},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444572X},
doi = {10.1137/S009753970444572X},
abstract = {We initiate an investigation of sublinear algorithms for geometric problems in two and three dimensions. We give optimal algorithms for intersection detection of convex polygons and polyhedra, point location in two-dimensional triangulations and Voronoi diagrams, and ray shooting in convex polyhedra, all of which run in expected time $O(sqrt{n},)$, where $n$ is the size of the input. We also provide sublinear solutions for the approximate evaluation of the volume of a convex polytope and the length of the shortest path between two points on the boundary.},
journal = {SIAM J. Comput.},
month = sep,
pages = {627–646},
numpages = {20},
keywords = {approximate shortest paths, polyhedral intersection, sublinear algorithms}
}

@article{10.1137/S009753970444346X,
author = {Doberkat, Ernst-Erich},
title = {Stochastic Relations: Congruences, Bisimulations and the Hennessy--Milner Theorem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444346X},
doi = {10.1137/S009753970444346X},
abstract = {The relationship between congruences and bisimulations is investigated for stochastic relations. It is shown that stochastic relations are bisimilar provided they have congruences that generate each other; from this is derived that relations that have isomorphic factor spaces are bisimilar. Stochastic Kripke models are introduced for a modal logic and illustrated for some popular logics.  The criterion developed here permits proving for the general case that Kripke models are bisimilar iff they accept exactly the same formulas.},
journal = {SIAM J. Comput.},
month = sep,
pages = {590–626},
numpages = {37},
keywords = {stochastic Kripke models, congruences, stochastic relations, Hennessy--Milner theorem, modal logic, bisimulations}
}

@article{10.1137/S0097539704442714,
author = {Ngo, Hung Q.},
title = {WDM Switching Networks, Rearrangeable and Nonblocking [w,f]-Connectors},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442714},
doi = {10.1137/S0097539704442714},
abstract = {We propose a framework to analyze and compare wavelength division multiplexed (WDM) switching networks qualitatively and quantitatively. The framework not only helps analyze and compare the complexity of WDM switching networks but also explains interesting properties of different designs. Then several important problems arising from this idea are addressed, and complexity bounds are derived. We also give several applications of the proposed model, including explicit constructions of nonblocking WDM switching fabrics.},
journal = {SIAM J. Comput.},
month = sep,
pages = {766–785},
numpages = {20},
keywords = {f]$-connectors, wavelength division multiplexing, $[w, switching networks}
}

@article{10.1137/S0097539704440740,
author = {Elkin, Michael and Kortsarz, Guy},
title = {A Combinatorial Logarithmic Approximation Algorithm for the Directed Telephone Broadcast Problem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704440740},
doi = {10.1137/S0097539704440740},
abstract = {Consider a synchronous network of processors, modeled by directed or undirected graph $G = (V,E)$, in which in each round every processor is allowed to choose one of its neighbors and to send a message to this neighbor. Given a processor $s in V$ and a subset $T subseteq V$ of processors, the  telephone multicast  problem requires computing the shortest schedule (in terms of the number of rounds) that delivers a message from $s$ to all the processors of $T$. The particular case $T = V$ is called the  telephone broadcast  problem. These problems have multiple applications in distributed computing. Several approximation algorithms with polylogarithmic ratio, including one with logarithmic ratio, for the  undirected  variants of these problems are known. However, all these algorithms involve solving large linear programs. Devising a polylogarithmic approximation algorithm for the directed variants of these problems is an open problem, posed by Ravi in [  Proceedings of the 35th Annual IEEE Symposium on Foundations of Computer Science , (FOCS '94), 1994, pp. 202-213].We devise a  combinatorial logarithmic  approximation algorithm for these problems that applies also for the  directed broadcast  problem. Our algorithm has significantly smaller running time and seems to reveal more information about the combinatorial structure of the solution than the previous algorithms that are based on linear programming.We also improve the lower bounds on the approximation threshold of these problems. Both problems are known to be 3/2-inapproximable. For the undirected (resp., directed) broadcast problem we show that it is NP-hard (resp., impossible unless $NP subseteq DTIME(n^{O(log n)})$) to approximate it within a ratio of $3 - epsilon$ for any $epsilon &gt; 0$ (resp., $Omega(sqrt{log n})$).},
journal = {SIAM J. Comput.},
month = sep,
pages = {672–689},
numpages = {18},
keywords = {directed, graph, multicast, approximation}
}

@article{10.1137/S0097539704371353,
author = {Shi, Weiping and Su, Chen},
title = {The Rectilinear Steiner Arborescence Problem Is NP-Complete},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704371353},
doi = {10.1137/S0097539704371353},
abstract = {Given a set of points in the first quadrant, a rectilinear Steiner arborescence (RSA) is a directed tree rooted at the origin, containing all points, and composed solely of horizontal and vertical edges oriented from left to right, or from bottom to top. The complexity of finding an RSA with the minimum total edge length for general planar point sets has been a well-known open problem in algorithm design and VLSI routing. In this paper, we prove the problem is NP-complete in the strong sense.},
journal = {SIAM J. Comput.},
month = sep,
pages = {729–740},
numpages = {12},
keywords = {NP-complete, computational complexity, Steiner tree}
}

@article{10.1137/S0097539703434267,
author = {Arkin, Esther M. and Bender, Michael A. and Demaine, Erik D. and Fekete, S\'{a}ndor P. and Mitchell, Joseph S. B. and Sethia, Saurabh},
title = {Optimal Covering Tours with Turn Costs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434267},
doi = {10.1137/S0097539703434267},
abstract = {We give the first algorithmic study of a class of "covering tour" problems related to the geometric traveling salesman problem: Find a polygonal tour for a cutter so that it sweeps out a specified region ("pocket") in order to minimize a cost that depends mainly on the number of turns.  These problems arise naturally in manufacturing applications of computational geometry to automatic tool path generation and automatic inspection systems, as well as arc routing ("postman") problems with turn penalties.  We prove the NP-completeness of minimum-turn milling and give efficient approximation algorithms for several natural versions of the problem, including a polynomial-time approximation scheme based on a novel adaptation of the $m$-guillotine method.},
journal = {SIAM J. Comput.},
month = sep,
pages = {531–566},
numpages = {36},
keywords = {traveling salesman problem, $m$-guillotine subdivisions, NP-completeness, lawn mowing, manufacturing, polynomial-time approximation scheme, NC machining, covering, turn costs, milling, approximation algorithms}
}

@article{10.1137/S0097539700382820,
author = {Chekuri, Chandra and Khanna, Sanjeev},
title = {A Polynomial Time Approximation Scheme for the Multiple Knapsack Problem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700382820},
doi = {10.1137/S0097539700382820},
abstract = {The multiple knapsack problem (MKP) is a natural and well-known generalization of the single knapsack problem and is defined as follows. We are given a set of $n$ items and $m$ bins (knapsacks) such that each item $i$ has a profit $p(i)$ and a size $s(i)$, and each bin $j$ has a capacity $c(j)$.  The goal is to find a subset of items of maximum profit such that they have a feasible packing in the bins. MKP is a special case of the generalized assignment problem (GAP) where the profit and the size of an item can vary based on the specific bin that it is assigned to. GAP is APX-hard and a 2-approximation, for it is implicit in the work of Shmoys and Tardos [Math. Program. A, 62 (1993), pp. 461-474], and thus far, this was also the best known approximation for MKP@. The main result of this paper is a polynomial time approximation scheme (PTAS) for MKP@.  Apart from its inherent theoretical interest as a common generalization of the well-studied knapsack and bin packing problems, it appears to be the strongest special case of GAP that is not APX-hard. We substantiate this by showing that slight generalizations of MKP are APX-hard. Thus our results help demarcate the boundary at which instances of GAP become APX-hard. An interesting aspect of our approach is a PTAS-preserving reduction from an arbitrary instance of MKP to an instance with $O(log n)$ distinct sizes and profits.},
journal = {SIAM J. Comput.},
month = sep,
pages = {713–728},
numpages = {16},
keywords = {generalized assignment problem, polynomial time approximation scheme, approximation algorithm, multiple knapsack problem}
}

@article{10.1137/050629434,
author = {Li, Minming and Yao, Frances F.},
title = {An Efficient Algorithm for Computing Optimal Discrete Voltage Schedules},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/050629434},
doi = {10.1137/050629434},
abstract = {We consider the problem of job scheduling on a variable voltage processor with $d$ discrete voltage/speed levels. We give an algorithm which constructs a minimum energy schedule for $n$ jobs in  $O(d nlog n)$ time. Previous approaches solve this problem by first computing the optimal continuous solution in $O(n^3)$ time and then adjusting the speed to discrete levels. In our approach, the optimal discrete solution is characterized and computed directly from the inputs. We also show that $O(nlog n)$ time is required; hence the algorithm is optimal for fixed $d$.},
journal = {SIAM J. Comput.},
month = sep,
pages = {658–671},
numpages = {14},
keywords = {discrete optimization, scheduling, energy efficiency, variable voltage processor}
}

@article{10.1137/S0097539705446895,
author = {Epstein, Leah and Stee, Rob van},
title = {Optimal Online Algorithms for  Multidimensional Packing Problems},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539705446895},
doi = {10.1137/S0097539705446895},
abstract = {We solve an open problem in the literature by providing an online algorithm for multidimensional bin packing that uses only bounded space. To achieve this, we introduce a new technique for classifying the items to be packed. We show that our algorithm is optimal among bounded space algorithms for any dimension $d&gt;1$. Its asymptotic performance ratio is $(Pi_{infty})^d$, where $Pi_{infty}approx1.691$ is the asymptotic performance ratio of the one-dimensional algorithm harm. A modified version of this algorithm for the case where all items are hypercubes is also shown to be optimal. Its asymptotic performance ratio is sublinear in $d$.Furthermore, we extend the techniques used in these algorithms to give optimal algorithms for online bounded space variable-sized packing and resource augmented packing.},
journal = {SIAM J. Comput.},
month = aug,
pages = {431–448},
numpages = {18},
keywords = {online algorithms, multidimensional bin packing, optimal algorithms}
}

@article{10.1137/S0097539704446268,
author = {Albers, Susanne and Schmidt, Markus},
title = {On the Performance of Greedy Algorithms in Packet Buffering},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446268},
doi = {10.1137/S0097539704446268},
abstract = {We study a basic buffer management problem that arises in network switches. Consider $m$ input ports, each of which is equipped with a buffer (queue) of limited capacity. Data packets arrive online and can be stored in the buffers if space permits; otherwise packet loss occurs. In each time step the switch can transmit one packet from one of the buffers to the output port. The goal is to maximize the number of transmitted packets. Simple arguments show that any work-conserving algorithm, which serves any nonempty buffer, is 2-competitive. Azar and Richter recently presented a randomized online algorithm and gave lower bounds for deterministic and randomized strategies. In practice, greedy algorithms are very important because they are fast, use little extra memory, and reduce packet loss by always serving a longest queue. In this paper we first settle the competitive performance of the entire family of greedy strategies. We prove that greedy algorithms are not better than 2-competitive no matter how ties are broken. Our lower bound proof uses a new recursive construction for building adversarial buffer configurations that may be of independent interest. We also give improved lower bounds for deterministic and randomized online algorithms.In this paper we present the first deterministic online algorithm that is better than 2-competitive. We develop a modified greedy algorithm, called  semigreedy , and prove that it achieves a competitive ratio of $17/9 approx 1.89$. The new algorithm is simple, fast, and uses little extra memory. Only when the risk of packet loss is low does it not serve the longest queue. Additionally we study scenarios when an online algorithm is granted additional resources. We consider resource augmentation with respect to memory and speed; i.e., an online algorithm may be given larger buffers or higher transmission rates. We analyze greedy and other online strategies.},
journal = {SIAM J. Comput.},
month = aug,
pages = {278–304},
numpages = {27},
keywords = {packet, competitive, online, buffer, network switch, throughput, greedy}
}

@article{10.1137/S0097539704445470,
author = {Goldberg, Leslie Ann and Martin, Russell and Paterson, Mike},
title = {Strong Spatial Mixing with Fewer Colors for Lattice Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445470},
doi = {10.1137/S0097539704445470},
abstract = {Recursively-constructed couplings have been used in the past for mixing on trees. We show how to extend this technique to nontree-like graphs such as lattices. Using this method, we obtain the following general result. Suppose that $G$ is a triangle-free graph and that for some $degree geq 3$, the maximum degree of $G$ is at most $degree$.  We show that the spin system consisting of $q$-colorings of $G$ has strong spatial mixing, provided $q &gt; alpha degree-gamma$, where $alphaapprox 1.76322$ is the solution to $alpha^alpha=e$, and $gamma = frac{4alpha^3-6alpha^2-3alpha+4}{2(alpha^2-1)}approx 0.47031$. Note that we have no additional lower bound on $q$ or $degree$. This is important for us because our main objective is to have results which are applicable to the lattices studied in statistical physics, such as the integer lattice $zset^d$ and the triangular lattice. For these graphs (in fact, for any graph in which the distance-$k$ neighborhood of a vertex grows subexponentially in $k$), strong spatial mixing implies that there is a unique infinite-volume Gibbs measure. That is, there is one macroscopic equilibrium rather than many. Our general result gives, for example, a ``hand proof'' of strong spatial mixing for $7$-colorings of triangle-free $4$-regular graphs. (Computer-assisted proofs of this result were provided by Salas and Sokal [textit{J. Stat. Phys}., 86 (1997), pp. 551--579] (for the rectangular lattice) and by Bubley, Dyer, Greenhill, and Jerrum [textit{SIAM J. Comput.}, 29 (1999), pp. 387--400].) It also gives a hand proof of strong spatial mixing for $5$-colorings of triangle-free $3$-regular graphs. (A computer-assisted proof for the special case of the hexagonal lattice was provided earlier by Salas and Sokal [textit{J. Stat. Phys}., 86 (1997), pp. 551--579].) Toward the end of the paper we show how to improve our general technique by considering the geometry of the lattice. The idea is to construct the recursive coupling from a system of recurrences rather than from a single recurrence. We use the geometry of the lattice to derive the system of recurrences. This gives us an analysis with a horizon of more than one level of induction, which leads to improved results. We illustrate this idea by proving strong spatial mixing for $q=10$ on the lattice $zset^3$. Finally, we apply the idea to the triangular lattice, adding computational assistance. This gives us a (machine-assisted) proof of strong spatial mixing for $10$-colorings of the triangular lattice. (Such a proof for $11$ colors was given by Salas and Sokal [textit{J. Stat. Phys}., 86 (1997), pp. 551--579].) For completeness, we also show that our strong spatial mixing proof implies rapid mixing of Glauber dynamics for sampling proper colorings of neighborhood-amenable graphs. (It is known that strong spatial mixing often implies rapid mixing, but existing proofs seem to be written for  $zset^d$.) Thus our strong spatial mixing results give rapid},
journal = {SIAM J. Comput.},
month = aug,
pages = {486–517},
numpages = {32},
keywords = {proper graph coloring, strong spatial mixing, antiferromagnetic Potts model}
}

@article{10.1137/S0097539704443598,
author = {Busch, Costas and Tirthapura, Srikanta},
title = {Analysis of Link Reversal Routing Algorithms},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704443598},
doi = {10.1137/S0097539704443598},
abstract = {Link reversal algorithms provide a simple mechanism for routing in communication networks whose topology is frequently changing, such as in mobile ad hoc networks. A link reversal algorithm routes by imposing a direction on each network link such that the resulting graph is a destination oriented DAG. Whenever a node loses routes to the destination, it reacts by reversing some (or all) of its incident links. Link reversal algorithms have been studied experimentally and have been used in practical routing algorithms, including TORA [V. D. Park and M. S. Corson, A highly adaptive distributed routing algorithm for mobile wireless networks, in Proc. INFOCOM, IEEE, Los Alamitos, CA, 1997, pp. 1405--1413]. This paper presents the first formal performance analysis of link reversal algorithms. We study these algorithms in terms of work (number of node reversals) and the time needed until the network stabilizes to a state in which all the routes are reestablished. We focus on the full reversal algorithm and the partial reversal algorithm, both due to Gafni and Bertsekas [IEEE Trans. Comm., 29 (1981), pp. 11--18]; the first algorithm is simpler, while the latter has been found to be more efficient for typical cases. Our results are as follows: The full reversal algorithm requires O ( n 2 ) work and time, where n is the number of nodes that have lost routes to the destination. This bound is tight in the worst case. The partial reversal algorithm requires O ( n $cdot$ a * + n 2 ) work and time, where a * is a nonnegative integral function of the initial state of the network. Further, for every nonnegative integer $alpha$, there exists a network and an initial state with a *=$alpha$, and with n nodes that have lost their paths to the destination, such that the partial reversal algorithm requires $Omega(ncdot {a^*} + n^2)$ work and time. There is an inherent lower bound on the worst-case performance of link reversal algorithms. There exist networks such that for every deterministic link reversal algorithm, there are initial states that require $Omega(n^2)$ work and time to stabilize. Therefore, surprisingly, the full reversal algorithm is asymptotically optimal in the worst case, while the partial reversal algorithm is not, since a * can be arbitrarily larger than n .},
journal = {SIAM J. Comput.},
month = aug,
pages = {305–326},
numpages = {22},
keywords = {ad hoc networks, link reversal routing, self stabilization, fault tolerance, wireless networks}
}

@article{10.1137/S0097539704443240,
author = {Dalal, Ketan and Devroye, Luc and Malalla, Ebrahim and McLeish, Erin},
title = {Two-Way Chaining with Reassignment},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704443240},
doi = {10.1137/S0097539704443240},
abstract = {We present an algorithm for hashing $lfloor alpha n rfloor$ elements into a table with n separate chains that requires O(1) deterministic worst-case insert time and O(1) expected worst-case search time for constant $alpha$. We exploit the connection between two-way chaining and random graph theory in our techniques.},
journal = {SIAM J. Comput.},
month = aug,
pages = {327–340},
numpages = {14},
keywords = {two-way chaining, worst-case search time, hashing, random graphs, probabilistic analysis of algorithms}
}

@article{10.1137/S009753970444096X,
author = {Friedman, Joel and Goerdt, Andreas and Krivelevich, Michael},
title = {Recognizing More Unsatisfiable Random <i>k</i>-SAT Instances Efficiently},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444096X},
doi = {10.1137/S009753970444096X},
abstract = {It is known that random $k$-SAT instances with at least $cn$ clauses, where $c =nobreak c_k$ is a suitable constant, are unsatisfiable (with high probability). We consider the problem to certify efficiently the unsatisfiability of such formulas. A backtracking-based algorithm of Beame et al. [SIAM J. Comput., 31 (2002), pp. 1048--1075] shows that $k$-SAT instances with at least $n^{k-1}/(log n)^{k-2}$ clauses can be certified unsatisfiable in polynomial time. We employ spectral methods to improve on this bound. For even $kge 4$ we present a polynomial time algorithm which certifies random $k$-SAT instances with at least  $n^{(k/2)+o(1)}$ clauses as unsatisfiable (with high probability). For odd $k$ we focus on 3-SAT instances and obtain an efficient algorithm  for formulas with at least $n^{3/2+varepsilon}$ clauses, where $varepsilon &gt;0$ is an arbitrary constant.},
journal = {SIAM J. Comput.},
month = aug,
pages = {408–430},
numpages = {23},
keywords = {random structures, random satisfiability, spectral methods}
}

@article{10.1137/S0097539703434255,
author = {Rasala, April and Wilfong, Gordon},
title = {Strictly Nonblocking WDM Cross-Connects},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434255},
doi = {10.1137/S0097539703434255},
abstract = {Using (WDM) technology, an optical network can route multiple signals simultaneously along a single optical fiber by encoding each signal on its own wavelength. If the network contains places where multiple fibers connect together and signals are allowed to be moved from any of the incoming fibers to any of the outgoing fibers, then the network is said to contain cross-connects. More precisely, a $k_1,times,k_2$ WDM cross-connect has k1 input fibers and k2 output fibers.  Each of the k1 input fibers supports the same n1 input wavelengths and each of the k2 output fibers supports the same n2 output wavelengths.  Since a signal on input wavelength $lambda$ can be routed from its input fiber to an output fiber such that it arrives on the output fiber using wavelength $gamma$, where $lambda neq gamma$, the cross-connect must be capable of performing wavelength conversion.  Along any fiber in the cross-connect a device called a wavelength interchanger can be inserted to perform wavelength conversion.  In other words if the path of a signal from an input fiber to an output fiber passes through a wins, then the wavelength of the signal can be changed to any wavelength that is not already in use along the fiber leaving the wavelength interchanger.  Given the high cost of wisns, the overall cost of a CC{k_1}{k_2} is minimized by reducing the number of wis in the cross-connect. However, a desirable property for a cross-connect C is for C to always be able to provide a route (and wavelength conversion) for any valid demand from any pair of input and output fibers regardless of the routes of other demands currently routed in C.  If C has this capability then it is said to be strictly nonblocking. For most of this paper we consider a demand to be a request for a connection from an input fiber to an output fiber such that the connection starts on a specified input wavelength and leaves the \c{c} on a second specified wavelength.  Using this demand model, we consider cross-connects for which $k_1$ is not necessarily equal to $k_2$ and the number $n_1$ of supported input wavelengths can differ from the number $n_2$ of supported output wavelengths. Without loss of generality we assume that $k_1 leq k_2$ and present a family of snob CCns{k_1}{k_2}s that use Opt wisns.  For the case when $k_1 = k_2=k$ and $n_1 = n_2$, we prove that this is optimal.  For \c{c}s where $n_1$ is not necessarily equal to $n_2$, we show that if there is at most one wavelength interchanger on any path from an input fiber to an output fiber, Opt wis are optimal.  Finally, we consider a more flexible demand model where $k_1 = k_2$ but the input and output wavelengths are not specified as part of the demand.  We show that $2k-1$ wis are still necessary for any snob CC{k}{k}.},
journal = {SIAM J. Comput.},
month = aug,
pages = {449–485},
numpages = {37},
keywords = {strictly nonblocking, cross-connect, optical networking, wavelength division multiplexing}
}

@article{10.1137/S0097539702418589,
author = {Hlinen\'{y}, Petr},
title = {A Parametrized Algorithm for Matroid Branch-Width},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702418589},
doi = {10.1137/S0097539702418589},
abstract = {Branch-width is a structural parameter very closely related to tree-width, but branch-width has an immediate generalization from graphs to matroids. We present an algorithm that, for a given matroid M of bounded branch-width t which is represented over a finite field, finds a branch decomposition of M of width at most 3t in cubic time. Then we show that the branch-width of M is a uniformly fixed-parameter tractable problem. Other applications include recognition of matroid properties definable in the monadic second-order logic for bounded branch-width, and [S.-I. Oum, Approximating rank-width and clique-width quickly, in Proceedings of the 31st International Workshop on Graph-Theoretic Concepts in Computer Science, Springer-Verlag, Heidelberg, to appear] a cubic time approximation algorithm for graph rank-width and clique-width.},
journal = {SIAM J. Comput.},
month = aug,
pages = {259–277},
numpages = {19},
keywords = {representable matroid, branch-width, rank-width, parametrized algorithm}
}

@article{10.1137/S0097539702402354,
author = {Grossi, Roberto and Vitter, Jeffrey Scott},
title = {Compressed Suffix Arrays and Suffix Trees with Applications to Text Indexing and String Matching},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702402354},
doi = {10.1137/S0097539702402354},
abstract = {The proliferation of online text, such as found on the World Wide Web and in online databases, motivates the need for space-efficient text indexing methods that support fast string searching.  We model this scenario as follows: Consider a text $T$ consisting of $n$ symbols drawn from a fixed alphabet $Sigma$.  The text $T$ can be represented in $n lg |Sigma|$ bits by encoding each symbol with $lg |Sigma|$ bits.  The goal is to support fast online queries for searching any string pattern $P$ of $m$ symbols, with $T$ being fully scanned only once, namely, when the index is created at preprocessing time.  The text indexing schemes published in the literature are greedy in terms of space usage: they require $Omega(n lg n)$ additional bits of space in the worst case. For example, in the standard unit cost RAM, suffix trees and suffix arrays need $Omega(n)$ memory words, each of $Omega(lg n)$ bits.  These indexes are larger than the text itself by a multiplicative factor of $Omega(smash{lg_{|Sigma|} n})$, which is significant when $Sigma$ is of constant size, such as in textsc{ascii} or textsc{unicode}. On the other hand, these indexes support fast searching, either in $O(m lg |Sigma|)$ time or in $O(m + lg n)$ time, plus an output-sensitive cost $O(mathit{occ})$ for listing the $mathit{occ}$ pattern occurrences.  We present a new text index that is based upon compressed representations of suffix arrays and suffix trees.  It achieves a fast $smash{O(m /lg_{|Sigma|} n + lg_{|Sigma|}^epsilon n)}$ search time in the worst case, for any constant $0 &lt; epsilon leq 1$, using at most $smash{bigl(epsilon^{-1} + O(1)bigr) , n lg |Sigma|}$ bits of storage. Our result thus presents for the first time an efficient index whose size is provably linear in the size of the text in the worst case, and for many scenarios, the space is actually sublinear in practice.  As a concrete example, the compressed suffix array for a typical 100 MB textsc{ascii} file can require 30--40 MB or less, while the raw suffix array requires 500 MB.  Our theoretical bounds improve emph{both} time and space of previous indexing schemes.  Listing the pattern occurrences introduces a sublogarithmic slowdown factor in the output-sensitive cost, giving $O(mathit{occ} , smash{lg_{|Sigma|}^epsilon n})$ time as a result.  When the patterns are sufficiently long, we can use auxiliary data structures in $O(n lg |Sigma|)$ bits to obtain a total search bound of $O(m /lg_{|Sigma|} n + mathit{occ})$ time, which is optimal.},
journal = {SIAM J. Comput.},
month = aug,
pages = {378–407},
numpages = {30},
keywords = {pattern matching, compression, text retrieval, compressed data structures, suffix arrays, string searching, suffix trees, text indexing}
}

@article{10.1137/S0097539701400154,
author = {Lee, Gyung-Ok and Choe, Kwang-Moo},
title = {A Powerful LL(<i>k</i>) Covering Transformation},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701400154},
doi = {10.1137/S0097539701400154},
abstract = {$k$-transformable grammars have been conjectured to be the uppermost class of LL($k$) covering transformable grammars. PLR($k$) grammars have been known as a well characterized subclass of $k$-transformable grammars. Being contrary to those claims, this paper shows that some PLR($k$) grammars are not $k$-transformable, and so $k$-transformable grammars are not the true uppermost. A powerful LL($k$) covering transformation is suggested in this paper. It is a generalization of the transformations of $k$-transformable grammars and PLR($k$) grammars. A remarkable aspect of the new transforming process is the deterministic property, where "deterministic" means that the transformation is obtained in a single process without requiring any heuristic, unlike $k$-transformable grammars' transformation for which a heuristic is required. The transformable grammar class is shown to be larger than $k$-transformable grammars and PLR($k$) grammars.},
journal = {SIAM J. Comput.},
month = aug,
pages = {359–377},
numpages = {19},
keywords = {LL grammars, LR grammars, left-to-right cover, compilers}
}

@article{10.1137/S0097539701389956,
author = {Bender, Michael A. and Demaine, Erik D. and Farach-Colton, Martin},
title = {Cache-Oblivious B-Trees},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701389956},
doi = {10.1137/S0097539701389956},
abstract = {This paper presents two dynamic search trees attaining near-optimal performance on any hierarchical memory. The data structures are independent of the parameters of the memory hierarchy, e.g., the number of memory levels, the block-transfer size at each level, and the relative speeds of memory levels. The performance is analyzed in terms of the number of memory transfers between two memory levels with an arbitrary block-transfer size of B; this analysis can then be applied to every adjacent pair of levels in a multilevel memory hierarchy. Both search trees match the optimal search bound of $Theta(1+log_{B+1}N)$ memory transfers. This bound is also achieved by the classic B-tree data structure on a two-level memory hierarchy with a known block-transfer size B. The first search tree supports insertions and deletions in $Theta(1+log_{B+1}N)$ amortized memory transfers, which matches the B-tree's worst-case bounds. The second search tree supports scanning S consecutive elements optimally in $Theta(1+S/B)$ memory transfers and supports insertions and deletions in $Theta(1+log_{B+1}N + frac{log^2N}{B})$ amortized memory transfers, matching the performance of the B-tree for $B = Omega(log N loglog N)$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {341–358},
numpages = {18},
keywords = {cache efficiency, memory hierarchy, data structures, search trees}
}

@article{10.1137/S0097539704445445,
author = {Ben-Sasson, Eli and Harsha, Prahladh and Raskhodnikova, Sofya},
title = {Some 3CNF Properties Are Hard to Test},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445445},
doi = {10.1137/S0097539704445445},
abstract = {For a Boolean formula $phi$ on n variables, the associated property $P_phi$ is the collection of n-bit strings that satisfy $phi$. We study the query complexity of tests that distinguish (with high probability) between strings in $P_phi$ and strings that are far from $P_phi$ in Hamming distance. We prove that there are 3CNF formulae (with O( n) clauses) such that testing for the associated property requires $Omega(n)$ queries, even with adaptive tests. This contrasts with 2CNF formulae, whose associated properties are always testable with $O(sqrt{n})$ queries [E. Fischer et al., Monotonicity testing over general poset domains, in Proceedings of the 34th Annual ACM Symposium on Theory of Computing, ACM, New York, 2002, pp. 474--483]. Notice that for every negative instance (i.e., an assignment that does not satisfy $phi$) there are three bit queries that witness this fact. Nevertheless, finding such a short witness requires reading a constant fraction of the input, even when the input is very far from satisfying the formula that is associated with the property. A property is linear if its elements form a linear space. We provide sufficient conditions for linear properties to be hard to test, and in the course of the proof include the following observations which are of independent interest: In the context of testing for linear properties, adaptive two-sided error tests have no more power than nonadaptive one-sided error tests. Moreover, without loss of generality, any test for a linear property is a linear test. A linear test verifies that a portion of the input satisfies a set of linear constraints, which define the property, and rejects if and only if it finds a falsified constraint. A linear test is by definition nonadaptive and, when applied to linear properties, has a one-sided error. Random low density parity check codes (which are known to have linear distance and constant rate) are not locally testable. In fact, testing such a code of length n requires $Omega(n)$ queries.},
journal = {SIAM J. Comput.},
month = jul,
pages = {1–21},
numpages = {21},
keywords = {sublinear algorithms, property testing, lower bounds, locally testable codes, CNF formulae}
}

@article{10.1137/S0097539704444750,
author = {Hassin, Refael and Levin, Asaf},
title = {A Better-Than-Greedy Approximation Algorithm for the Minimum Set Cover Problem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704444750},
doi = {10.1137/S0097539704444750},
abstract = {In the weighted set-cover problem we are given a set of elements $E={ e_1,e_2, ldots ,e_n }$ and a collection $cal F$ of subsets of $E$, where each $S in cal F$ has a positive cost $c_{S}$. The problem is to compute a subcollection $SOL$ such that $bigcup_{Sin SOL}S_j=E$ and its cost $sum_{Sin SOL}c_S$ is minimized.  When $|S|le k forall Sincal F$ we obtain the weighted $k$-set cover problem.  It is well known that the greedy algorithm is an $H_k$-approximation algorithm for the weighted $k$ set cover, where $H_k=sum_{i=1}^k {1 over i}$ is the $k$th harmonic number, and that this bound is exact for the greedy algorithm for all constant values of $k$. In this paper we give the first improvement on this approximation ratio for all constant values of $k$. This result shows that the greedy algorithm is not the best possible for approximating the weighted set cover problem. Our method is a modification of the greedy algorithm that allows the algorithm to regret.},
journal = {SIAM J. Comput.},
month = jul,
pages = {189–200},
numpages = {12},
keywords = {approximation algorithms, greedy algorithm, set cover problem}
}

@article{10.1137/S0097539704443276,
author = {Gennaro, Rosario and Gertner, Yael and Katz, Jonathan and Trevisan, Luca},
title = {Bounds on the Efficiency of Generic Cryptographic Constructions},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704443276},
doi = {10.1137/S0097539704443276},
abstract = {A central focus of modern cryptography is the construction of efficient, high-level cryptographic tools (e.g., encryption schemes) from weaker, low-level cryptographic primitives (e.g., one-way functions). Of interest are both the existence of such constructions and their efficiency.Here, we show essentially tight lower bounds on the best possible efficiency of any black-box construction of some fundamental cryptographic tools from the most basic and widely used cryptographic primitives. Our results hold in an extension of the model introduced by Impagliazzo and Rudich and improve and extend earlier results of Kim, Simon, and Tetali. We focus on constructions of pseudorandom generators, universal one-way hash functions, and digital signatures based on one-way permutations, as well as constructions of public- and private-key encryption schemes based on trapdoor permutations. In each case, we show that any black-box construction beating our efficiency bound would yield the unconditional existence of a one-way function and thus, in particular, prove $P neq NP$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {217–246},
numpages = {30},
keywords = {pseudorandom generators, lower bounds, hash functions, encryption, digital signatures}
}

@article{10.1137/S0097539704441848,
author = {Lotker, Zvi and Patt-Shamir, Boaz and Pavlov, Elan and Peleg, David},
title = {Minimum-Weight Spanning Tree Construction in <i>O</i>(Log Log <i>n</i>) Communication Rounds},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441848},
doi = {10.1137/S0097539704441848},
abstract = {We consider a simple model for overlay networks, where all n processes are connected to all other processes, and each message contains at most O(log n) bits. For this model, we present a distributed algorithm which constructs a minimum-weight spanning tree in O(log log n) communication rounds, where in each round any process can send a message to every other process.  If message size is $Theta(n^epsilon)$ for some $epsilon&gt;0$, then the number of communication rounds is $O(log{1overepsilon})$.},
journal = {SIAM J. Comput.},
month = jul,
pages = {120–131},
numpages = {12},
keywords = {distributed algorithms, minimum-weight spanning tree}
}

@article{10.1137/S0097539703438629,
author = {Melkebeek, Dieter van and Santhanam, Rahul},
title = {Holographic Proofs and Derandomization},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703438629},
doi = {10.1137/S0097539703438629},
abstract = {We derive a stronger consequence of $mathsf{EXP}$ (deterministic exponential time) having polynomial-size circuits than was known previously, namely that for each language $L in mathsf{P}$ (polynomial time), and for each efficiently decidable error-correcting code E having nontrivial relative distance, there is a simulation of L in Merlin-Arthur polylogarithmic time that fools all deterministic polynomial-time adversaries for inputs that are codewords of E. Using the connection between circuit lower bounds and derandomization, we obtain uniform assumptions for derandomizing $mathsf{BPP}$ (probabilistic polynomial time). Our results strengthen the space-randomness tradeoffs of Sipser [ J. Comput. System Sci., 36 (1988), pp. 379--383], Nisan and Wigderson [ J. Comput. System Sci., 49 (1994), pp. 149--167], and Lu [ Comput. Complexity, 10 (2001), pp. 247--259]. We also consider a more quantitative notion of simulation, where the measure of success of the simulation is the fraction of inputs of a given length on which the simulation works. Among other results, we show that if there is no polynomial-time bound t such that $mathsf{P}$ can be simulated well by Merlin-Arthur machines operating in time t, then for any $epsilon &gt; 0$ there is a simulation of $mathsf{BPP}$ in $mathsf{P}$ that works for all but $2^{n^{epsilon}}$ inputs of length n. This is a uniform strengthening of a recent result of Goldreich and Wigderson [ Proceedings of the 6th International Workshop on Randomization and Approximation Techniques in Computer Science, 2002, pp. 209--223]. Finally, we give an unconditional simulation of multitape Turing machines operating in probabilistic time t by Turing machines operating in deterministic time o(2t). We show similar results for randomized $mathsf{NC}^{1}$ circuits. Our proofs are based on a combination of techniques in the theory of derandomization with results on holographic proofs.},
journal = {SIAM J. Comput.},
month = jul,
pages = {59–90},
numpages = {32},
keywords = {Arthur-Merlin games, holographic proofs, derandomization}
}

@article{10.1137/S0097539703436357,
author = {Gao, Jie and Zhang, Li},
title = {Well-Separated Pair Decomposition for the Unit-Disk Graph Metric and Its Applications},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436357},
doi = {10.1137/S0097539703436357},
abstract = {We extend the classic notion of well-separated pair decomposition [P. B. Callahan and S. R. Kosaraju, J. ACM, 42 (1975), pp. 67--90] to the unit-disk graph metric: the shortest path distance metric induced by the intersection graph of unit disks. We show that for the unit-disk graph metric of n points in the plane and for any constant $cgeq 1$, there exists a c-well-separated pair decomposition with O( n log n) pairs, and the decomposition can be computed in O( n log n) time. We also show that for the unit-ball graph metric in k dimensions where $kgeq 3$, there exists a c-well-separated pair decomposition with O( n 2-2/k) pairs, and the bound is tight in the worst case. We present the application of the well-separated pair decomposition in obtaining efficient algorithms for approximating the diameter, closest pair, nearest neighbor, center, median, and stretch factor, all under the unit-disk graph metric.},
journal = {SIAM J. Comput.},
month = jul,
pages = {151–169},
numpages = {19},
keywords = {approximation algorithm, unit-disk graph, well-separated pair decomposition}
}

@article{10.1137/S0097539703436345,
author = {Kuperberg, Greg},
title = {A Subexponential-Time Quantum Algorithm for the Dihedral Hidden Subgroup Problem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436345},
doi = {10.1137/S0097539703436345},
abstract = {We present a quantum algorithm for the dihedral hidden subgroup problem (DHSP) with time and query complexity $2^{O(sqrt{log N})}$. In this problem an oracle computes a function $f$ on the dihedral group $D_N$ which is invariant under a hidden reflection in $D_N$. By contrast, the classical query complexity of DHSP is $O(sqrt{N})$.  The algorithm also applies to the hidden shift problem for an arbitrary finitely generated abelian group.The algorithm begins as usual with a quantum character transform, which in the case of $D_N$ is essentially the abelian quantum Fourier transform. This yields the name of a group representation of $D_N$, which is not by itself useful, and a state in the representation, which is a valuable but indecipherable qubit. The algorithm proceeds by repeatedly pairing two unfavorable qubits to make a new qubit in a more favorable representation of $D_N$. Once the algorithm obtains certain target representations, direct measurements reveal the hidden subgroup.},
journal = {SIAM J. Comput.},
month = jul,
pages = {170–188},
numpages = {19},
keywords = {dihedral hidden subgroup, quantum algorithm}
}

@article{10.1137/S0097539703435753,
author = {Kortsarz, Guy and Nutov, Zeev},
title = {Approximating <i>k</i>-Node Connected Subgraphs via Critical Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435753},
doi = {10.1137/S0097539703435753},
abstract = {We present two new approximation algorithms for the problem of finding a k-node connected spanning subgraph (directed or undirected) of minimum cost. The best known approximation guarantees for this problem were $O(min {k,frac{n}{sqrt{n-k}}})$ for both directed and undirected graphs, and $O(ln k)$ for undirected graphs with $n geq 6k^2$, where $n$ is the number of nodes in the input graph. Our first algorithm has approximation ratio $O(frac{n}{n-k}ln^2 k)$, which is $O(ln^2 k)$ except for very large values of $k$, namely, $k=n-o(n)$. This algorithm is based on a new result on $ell$-connected $p$-critical graphs, which is of independent interest in the context of graph theory. Our second algorithm uses the primal-dual method and has approximation ratio $O(sqrt{n} ln k)$ for all values of $n,k$. Combining these two gives an algorithm with approximation ratio $O(ln k cdot min {sqrt{k},frac{n}{n-k} ln k})$, which asymptotically improves the best known approximation guarantee for directed graphs for all values of $n,k$, and for undirected graphs for $k&gt;sqrt{n/6}$. Moreover, this is the first algorithm that has an approximation guarantee better than $Theta(k)$ for all values of $n,k$. Our approximation ratio also provides an upper bound on the integrality gap of the standard LP-relaxation.},
journal = {SIAM J. Comput.},
month = jul,
pages = {247–257},
numpages = {11},
keywords = {approximation, graphs, network design, connectivity}
}

@article{10.1137/S0097539703435297,
author = {Czumaj, Artur and Erg\"{u}n, Funda and Fortnow, Lance and Magen, Avner and Newman, Ilan and Rubinfeld, Ronitt and Sohler, Christian},
title = {Approximating the Weight of the  Euclidean Minimum Spanning Tree in Sublinear Time},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435297},
doi = {10.1137/S0097539703435297},
abstract = {We consider the problem of computing the weight of a Euclidean minimum spanning tree for a set of n points in $mathbb R^d$. We focus on the setting where the input point set is supported by certain basic (and commonly used) geometric data structures that can provide efficient access to the input in a structured way. We present an algorithm that estimates with high probability the weight of a Euclidean minimum spanning tree of a set of points to within $1 + eps$ using only $widetilde{O}(sqrt{n} , text{poly} (1/eps))$ queries for constant d. The algorithm assumes that the input is supported by a minimal bounding cube enclosing it, by orthogonal range queries, and by cone approximate nearest neighbor queries.},
journal = {SIAM J. Comput.},
month = jul,
pages = {91–109},
numpages = {19},
keywords = {minimum spanning tree, sublinear algorithms}
}

@article{10.1137/S0097539702403645,
author = {Batu, Tuugkan and Dasgupta, Sanjoy and Kumar, Ravi and Rubinfeld, Ronitt},
title = {The Complexity of Approximating the Entropy},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403645},
doi = {10.1137/S0097539702403645},
abstract = {We consider the problem of approximating the entropy of a discrete distribution under several different models of oracle access to the distribution. In the evaluation oracle model, the algorithm is given access to the explicit array of probabilities specifying the distribution. In this model, linear time in the size of the domain is both necessary and sufficient for approximating the entropy. In the generation oracle model, the algorithm has access only to independent samples from the distribution. In this case, we show that a $gamma$-multiplicative approximation to the entropy can be obtained in $O(n^{(1+eta)/gamma^2} log n)$ time for distributions with entropy $Omega(gamma/eta)$, where $n$ is the size of the domain of the distribution and $eta$ is an arbitrarily small positive constant. We show that this model does not permit a multiplicative approximation to the entropy in general. For the class of distributions to which our upper bound applies, we obtain a lower bound of $Omega(n^{1/(2gamma^2)})$.We next consider a combined oracle model in which the algorithm has access to both the generation and the evaluation oracles of the distribution. In this model, significantly greater efficiency can be achieved: we present an algorithm for $gamma$-multiplicative approximation to the entropy that runs in $O((gamma^2 log^2{n})/(h^2 (gamma-1)^2))$ time for distributions with entropy $Omega(h)$; for such distributions, we also show a lower bound of $Omega((log n)/(h(gamma^2-1)+gamma^2))$. Finally, we consider two special families of distributions: those in which the probabilities of the elements decrease monotonically with respect to a known ordering of the domain, and those that are uniform over a subset of the domain. In each case, we give more efficient algorithms for approximating the entropy.},
journal = {SIAM J. Comput.},
month = jul,
pages = {132–150},
numpages = {19},
keywords = {sublinear algorithms, properties of distributions, property testing, entropy estimation}
}

@article{10.1137/S0097539701396959,
author = {Amano, Kazuyuki and Maruoka, Akira},
title = {A Superpolynomial Lower Bound for a Circuit Computing the Clique Function with at Most (1/6)Log Log <i>n</i> Negation Gates},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701396959},
doi = {10.1137/S0097539701396959},
abstract = {In this paper, we investigate the lower bound on the number of gates in a Boolean circuit that computes the clique function with a limited number of negation gates. To derive strong lower bounds on the size of such a circuit we develop a new approach by combining three approaches: the restriction applied to constant depth circuits due to H\r{a}stad, the approximation method applied to monotone circuits due to Razborov, and the boundary covering developed in the present paper. We prove that if a circuit $C$ with at most $floor{(1/6) log log m}$ negation gates detects cliques of size $(log m)^{3(log m)^{1/2}}$ in a graph with $m$ vertices, then $C$ contains at least $2^{(1/5)(log m)^{(log m)^{1/2}}}$ gates. No nontrivial lower bounds on the size of such circuits were previously known, even if we restrict the number of negation gates to be a constant. Moreover, it follows from a result of Fischer [{it Lect. Notes Comput. Sci.,} 33 (1974), pp. 71--82] that if one can improve the number of negation gates from $floor{(1/6)loglog m}$ to $floor{2log m}$ in the statement, then we have P $neq$ NP. We also show that the problem of lower bounding the negation-limited circuit complexity can be reduced to the one of lower bounding the maximum of the monotone circuit complexity of the functions in a certain class of monotone functions.},
journal = {SIAM J. Comput.},
month = jul,
pages = {201–216},
numpages = {16},
keywords = {approximation method, lower bound, circuit complexity, monotone circuit, negation-limited circuit, clique function}
}

@article{10.1137/S009753970139567X,
author = {Jansen, Klaus and Karpinski, Marek and Lingas, Andrzej and Seidel, Eike},
title = {Polynomial Time Approximation Schemes for MAX-BISECTION on Planar and Geometric Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970139567X},
doi = {10.1137/S009753970139567X},
abstract = {The max-bisection and min-bisection problems are to find a partition of the vertices of a graph into two equal size subsets that, respectively, maximizes or minimizes the number of edges with endpoints in both subsets. We design the first polynomial time approximation scheme for the max-bisection problem on arbitrary planar graphs solving a long-standing open problem. The method of solution involves designing exact polynomial time algorithms for computing optimal partitions of bounded treewidth graphs, in particular max- and min-bisection, which could be of independent interest.Using a similar method we design also the first polynomial time approximation scheme for max-bisection on unit disk graphs (which could also be easily extended to other geometrically defined graphs).},
journal = {SIAM J. Comput.},
month = jul,
pages = {110–119},
numpages = {10},
keywords = {approximation algorithms, combinatorial optimization, planar graphs, graph bisection, NP-hardness, polynomial time approximation schemes}
}

@article{10.1137/S0097539700368527,
author = {Lindenbaum, Michael and Samet, Hanan and Hjaltason, Gisli R.},
title = {A Probabilistic Analysis of Trie-Based Sorting  of Large Collections of Line Segments  in Spatial Databases},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {35},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700368527},
doi = {10.1137/S0097539700368527},
abstract = {The size of five trie-based methods of sorting large collections of line segments in a spatial database is investigated analytically using a random lines image model and geometric probability techniques. The methods are based on sorting the line segments with respect to the space that they occupy. Since the space is two-dimensional, the trie is formed by interleaving the bits corresponding to the binary representation of the x and y coordinates of the underlying space and then testing two bits at each iteration. The result of this formulation yields a class of representations that are referred to as quadtrie variants, although they have been traditionally referred to as quadtree variants. The analysis differs from prior work in that it uses a detailed explicit model of the image instead of relying on modeling the branching process represented by the tree and leaving the underlying image unspecified. The analysis provides analytic expressions and bounds on the expected size of these quadtree variants. This enables the prediction of storage required by the representations and of the associated performance of algorithms that rely on them. The results are useful in the following two ways:  They reveal the properties of the various representations and permit their comparison using analytic, nonexperimental criteria. Some of the results confirm previous analyses (e.g., that the storage requirement of the MX quadtree is proportional to the total lengths of the line segments). An important new result is that for a PMR and Bucket PMR quadtree with sufficiently high values of the splitting threshold (i.e., $geq 4$) the number of nodes is proportional to the number of line segments and is independent of the maximum depth of the tree. This provides a theoretical justification for the good behavior and use of the PMR quadtree, which so far has been only of an empirical nature.The random lines model was found to be general enough to approximate real data in the sense that the properties of the trie representations, when used to store real data (e.g., maps), are similar to their properties when storing random lines data. Therefore, by specifying an equivalent random lines model for a real map, the proposed analytical expressions can be applied to predict the storage required for real data.  Specifying the equivalent random lines model requires only an estimate of the effective number of random lines in it.  Several such estimates are derived for real images, and the accuracy of the implied predictions is demonstrated on a real collection of maps. The agreement between the predictions and real data suggests that they could serve as the basis of a cost model that can be used by a query optimizer to generate an appropriate query evaluation plan.},
journal = {SIAM J. Comput.},
month = jul,
pages = {22–58},
numpages = {37},
keywords = {geometric probability, spatial data structures, quadtrees, large spatial databases, quadtries, analysis of algorithms, sorting line segments, tries, query evaluation, cost model}
}

@article{10.1137/S0097539704446475,
author = {Cohen, Reuven and Peleg, David},
title = {Convergence Properties of the Gravitational Algorithm in Asynchronous Robot Systems},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446475},
doi = {10.1137/S0097539704446475},
abstract = {This paper considers the convergence problem in autonomous mobile robot systems. A natural algorithm for the problem requires the robots to move towards their center of gravity. This paper proves the correctness of the gravitational algorithm in the fully asynchronous model. It also analyzes its convergence rate and establishes its convergence in the presence of crash faults.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1516–1528},
numpages = {13},
keywords = {convergence, autonomous mobile robots, robot swarms}
}

@article{10.1137/S0097539704446037,
author = {Cheng, Qi},
title = {On the Bounded Sum-of-Digits Discrete Logarithm Problem in Finite Fields},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704446037},
doi = {10.1137/S0097539704446037},
abstract = {In this paper, we study the bounded sum-of-digits discrete logarithm problem in finite fields. Our results are concerned primarily with fields F qn, where n| q - 1. The fields are called Kummer extensions of F q. It is known that we can efficiently construct an element g with order exponential in n. Let $S_q(bullet)$ be the function from integers to the sum of digits in their q-ary expansions. We first present an algorithm that, given ge (0 $leq$ e &lt; qn), finds e in random polynomial time, provided that S q ( e) &lt; n. We then show that the problem is solvable in random polynomial time for most of the exponent e with Sq ( e) &lt; 1.32 n by exploring an interesting connection between the discrete logarithm problem and the problem of list decoding of Reed--Solomon codes and applying the Guruswami--Sudan algorithm. As far as we are aware, our algorithm is the first one which can solve discrete logarithms of $2{log{1-epsilon}{qn}}$ many instances in polynomial time for infinite many constant characteristic fields F qn. Furthermore, since every finite field has an extension of reasonable degree, which is a Kummer extension, our result reveals an unexpected property of the discrete logarithm problem, namely, the bounded sum-of-digits discrete logarithm problem in any given finite field becomes polynomial-time solvable in certain low degree extensions. As a side result, we obtain a sharper lower bound on the number of congruent polynomials generated by linear factors than the one based on the Stothers--Mason ABC-theorem. We also prove that, in the field Fqq-1, the bounded sum-of-digits discrete logarithm with respect to g can be computed in random time O(f(w)log4 (qq-1)), where f is a subexponential function and w is the bound on the q-ary sum-of-digits of the exponent; hence the problem is fixed parameter tractable. These results are shown to be generalized to Artin--Schreier extension Fpp, where p is a prime.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1432–1442},
numpages = {11},
keywords = {parameterized complexity, sum-of-digits, discrete logarithm problem, finite fields}
}

@article{10.1137/S0097539704445706,
author = {Hershberger, John and Suri, Subhash and T\'{o}th, Csaba D.},
title = {Binary Space Partitions of Orthogonal Subdivisions},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445706},
doi = {10.1137/S0097539704445706},
abstract = {We consider the problem of constructing binary space partitions (BSPs) for orthogonal subdivisions (space-filling packings of boxes) in $d$-space.  We show that a subdivision with $n$ boxes can be refined into a BSP of size $O(n^{(d+1)/{3}})$ for all $d geq 3$ and that such a partition can be computed in time ${O(Klog n)}$, where $K$ is the size of the BSP produced.  Our upper bound on the BSP size is tight for $3$-dimensional subdivisions; in higher dimensions, this is the first nontrivial result for general full-dimensional boxes.  We also present a lower bound construction for a subdivision of $n$ boxes in $d$-space for which every axis-aligned BSP has $Omega(n^{beta(d)})$ size, where $beta(d)$ converges to $(1+sqrt{5})/2$ as $d rightarrow infty$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1380–1397},
numpages = {18},
keywords = {tilings, binary space partitions}
}

@article{10.1137/S0097539704445202,
author = {Aggarwal, Gagan and Cheng, Qi and Goldwasser, Michael H. and Kao, Ming-Yang and Espanes, Pablo Moissetde and Schweller, Robert T.},
title = {Complexities for Generalized Models of Self-Assembly},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704445202},
doi = {10.1137/S0097539704445202},
abstract = {In this paper, we study the complexity of self-assembly under models that are natural generalizations of the tile self-assembly model. In particular, we extend Rothemund and Winfree's study of the tile complexity of tile self-assembly [Proceedings of the 32nd Annual ACM Symposium on Theory of Computing, Portland, OR, 2000, pp. 459--468]. They provided a lower bound of $Omega(frac{log N}{loglog N})$ on the tile complexity of assembling an $Ntimes N$ square for almost all N. Adleman et al. [Proceedings of the 33rd Annual ACM Symposium on Theory of Computing, Heraklion, Greece, 2001, pp. 740--748] gave a construction which achieves this bound.  We consider whether the tile complexity for self-assembly can be reduced through several natural generalizations of the model.  One of our results is a tile set of size $O(sqrt{log N})$ which assembles an $Ntimes N$ square in a model which allows flexible glue strength between nonequal glues. This result is matched for almost all N by a lower bound dictated by Kolmogorov complexity. For three other generalizations, we show that the $Omega(frac{log N}{loglog N})$ lower bound applies to $Ntimes N$ squares.  At the same time, we demonstrate that there are some other shapes for which these generalizations allow reduced tile sets. Specifically, for thin rectangles with length N and width k, we provide a tighter lower bound of $Omega(frac{N^{1/k}}{k})$ for the standard model, yet we also give a construction which achieves $O(frac{log N}{loglog N})$ complexity in a model in which the temperature of the tile system is adjusted during assembly. We also investigate the problem of verifying whether a given tile system uniquely assembles into a given shape; we show that this problem is NP-hard for three of the generalized models.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1493–1515},
numpages = {23},
keywords = {tile complexity, Kolmogorov complexity, tilings, Wang tiles, self-assembly, polyominoes}
}

@article{10.1137/S0097539704444245,
author = {Ezra, Esther and Sharir, Micha},
title = {Output-Sensitive Construction of the Union of Triangles},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704444245},
doi = {10.1137/S0097539704444245},
abstract = {We present an efficient algorithm for the following problem: Given a collection $T ={Delta_1, ldots, Delta_n}$ of $n$ triangles in the plane, such that there exists a subset $S subset T$ (unknown to us) of $xi ll n$ triangles, such that $bigcup_{Delta in S} Delta = bigcup_{Delta in T} Delta$, construct efficiently the union of the triangles in $T$. We show that this problem can be solved in randomized expected time $O(n^{4/3}log{n} + nxilog^2{n})$, which is subquadratic for $xi=o(n/log^2{n})$. In our solution, we use a variant of the method of Br\"{o}nnimann and Goodrich [{it Discrete Comput. Geom.}, 14 (1995), pp. 463--479] for finding a set cover in a set system of finite VC-dimension. We present a detailed implementation of this variant, which makes it run within the asserted time bound. Our approach is fairly general, and we show that it can be extended to compute efficiently the union of simply shaped bodies of constant description complexity in ${reals}^d$, when the union is determined by a small subset of the bodies.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1331–1351},
numpages = {21},
keywords = {set cover, random sampling, union of geometric objects, finite VC-dimension, $eps$-net, hitting set, output sensitivity}
}

@article{10.1137/S009753970444106X,
author = {McCann, Mark and Pippenger, Nicholas},
title = {SRT Division Algorithms as Dynamical Systems},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444106X},
doi = {10.1137/S009753970444106X},
abstract = {Sweeney--Robertson--Tocher (SRT) division, as it was discovered in the late 1950s, represented an important improvement in the speed of division algorithms for computers at the time. A variant of SRT division is still commonly implemented in computers today. Although some bounds on the performance of the original SRT division method were obtained, a great many questions remained unanswered.  In this paper, the original version of SRT division is described as a dynamical system. This enables us to bring modern dynamical systems theory, a relatively new development in mathematics, to bear on an older problem. In doing so, we are able to show that SRT division is ergodic, and is even Bernoulli, for all real divisors and dividends. With the Bernoulli property, we are able to use entropy to prove that the natural extensions of SRT division are isomorphic by way of the Kolmogorov--Ornstein theorem. We demonstrate how our methods and results can be applied to a much larger class of division algorithms.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1279–1301},
numpages = {23},
keywords = {ergodic, dynamical systems, entropy, Bernoulli, SRT division}
}

@article{10.1137/S0097539703435728,
author = {Shi, Qingmin and JaJa, Joseph},
title = {Novel Transformation Techniques Using Q-Heaps with Applications to Computational Geometry},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435728},
doi = {10.1137/S0097539703435728},
abstract = {Using the notions of Q-heaps and fusion trees developed by Fredman and Willard, we develop general transformation techniques to reduce a number of computational geometry problems to their special versions in partially ranked spaces. In particular, we develop a fast fractional cascading technique, which uses linear space and enables sublogarithmic iterative search on catalog trees in the case when the degree of each node is bounded by $O(log^{epsilon}n)$ for some constant $epsilon &gt;0$, where $n$ is the total size of all the lists stored in the tree. We apply the fast fractional cascading technique in combination with the other techniques to derive the first linear-space sublogarithmic time algorithms for two fundamental geometric retrieval problems: orthogonal segment intersection and rectangular point enclosure.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1474–1492},
numpages = {19},
keywords = {searching, geometric retrieval, computational geometry, orthogonal segment intersection, fractional cascading, rectangular point enclosure}
}

@article{10.1137/S0097539703431573,
author = {Hutchinson, David A. and Sanders, Peter and Vitter, Jeffrey Scott},
title = {Duality Between Prefetching and Queued Writing with Parallel Disks},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703431573},
doi = {10.1137/S0097539703431573},
abstract = {Parallel disks promise to be a cost effective means for achieving high bandwidth in applications involving massive data sets, but algorithms for parallel disks can be difficult to devise. To combat this problem, we define a useful and natural duality between writing to parallel disks and the seemingly more difficult problem of prefetching. We first explore this duality for applications involving read-once accesses using parallel disks.  We get a simple linear time algorithm for computing optimal prefetch schedules and analyze the efficiency of the resulting schedules for randomly placed data and for arbitrary interleaved accesses to striped sequences.  Duality also provides an optimal schedule for prefetching plus caching, where blocks can be accessed multiple times. Another application of this duality gives us the first parallel disk sorting algorithms that are provably optimal up to lower-order terms. One of these algorithms is a simple and practical variant of multiway mergesort, addressing a question that had been open for some time.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1443–1463},
numpages = {21},
keywords = {lower bound, external memory sorting, prefetching, randomized algorithm, load balancing, caching}
}

@article{10.1137/S0097539703425861,
author = {Blondel, Vincent D. and Jeandel, Emmanuel and Koiran, Pascal and Portier, Natacha},
title = {Decidable and Undecidable Problems  about Quantum Automata},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703425861},
doi = {10.1137/S0097539703425861},
abstract = {We study the following decision problem: is the language recognized by a quantum finite automaton empty or nonempty? We prove that this problem is decidable or undecidable depending on whether recognition is defined by strict or nonstrict thresholds. This result is in contrast with the corresponding situation for probabilistic finite automata, for which it is known that strict and nonstrict thresholds both lead to undecidable problems.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1464–1473},
numpages = {10},
keywords = {quantum automata, undecidable problems, probabilistic automata, algebraic groups}
}

@article{10.1137/S0097539702419650,
author = {Pettie, Seth and Ramachandran, Vijaya},
title = {A Shortest Path Algorithm for  Real-Weighted Undirected Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702419650},
doi = {10.1137/S0097539702419650},
abstract = {We present a new scheme for computing shortest paths on real-weighted undirected graphs in the fundamental comparison-addition model. In an efficient preprocessing phase our algorithm creates a linear-size structure that facilitates single-source shortest path computations in O( m log $alpha$) time, where $alpha$ = $alpha$( m, n) is the very slowly growing inverse-Ackermann function, m the number of edges, and n the number of vertices. As special cases our algorithm implies new bounds on both the all-pairs and single-source shortest paths problems. We solve the all-pairs problem in O( mn log $alpha$( m, n)) time and, if the ratio between the maximum and minimum edge lengths is bounded by n (log n)O(1), we can solve the single-source problem in O( m + n log log n) time. Both these results are theoretical improvements over Dijkstra's algorithm, which was the previous best for real weighted undirected graphs. Our algorithm takes the hierarchy-based approach invented by Thorup.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1398–1431},
numpages = {34},
keywords = {single-source shortest paths, all-pairs shortest paths, Dijkstra's algorithm, undirected graphs}
}

@article{10.1137/S0097539702403244,
author = {Chazelle, Bernard and Rubinfeld, Ronitt and Trevisan, Luca},
title = {Approximating the Minimum Spanning Tree Weight in Sublinear Time},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403244},
doi = {10.1137/S0097539702403244},
abstract = {We present a probabilistic algorithm that, given a connected graph G (represented by adjacency lists) of average degree d , with edge weights in the set{1,..., w }, and given a parameter $0<\eps<1/2$, estimates in time $O( dw \varepsilon^{-2} \log{\frac{dw}\varepsilon})$ the weight of the minimum spanning tree (MST) of G with a relative error of at most $\eps$. Note that the running time does not depend on the number of vertices in G . We also prove a nearly matching lower bound of $\Omega( dw \varepsilon^{-2} )$ on the probe and time complexity of any approximation algorithm for MST weight. The essential component of our algorithm is a procedure for estimating in time $O(d\eps^{-2}\log \frac{d}\varepsilon)$ the number of connected components of an unweighted graph to within an additive error of $\varepsilon n$. (This becomes $O(\eps^{-2}\log \frac{1}\varepsilon)$ for $d=O(1)$.) The time bound is shown to be tight up to within the $\log \frac{d}\varepsilon$ factor. Our connected-components algorithm picks $O(1/\varepsilon^2)$ vertices in the graph and then grows "local spanning trees" whose sizes are specified by a stochastic process. From the local information collected in this way, the algorithm is able to infer, with high confidence, an estimate of the number of connected components. We then show how estimates on the number of components in various subgraphs of G can be used to estimate the weight of its MST.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1370–1379},
numpages = {10},
keywords = {sublinear time algorithms, approximation algorithms, randomized algorithms, minimum spanning tree}
}

@article{10.1137/S0097539702402780,
author = {Buhrman, Harry and D\"{u}rr, Christoph},
title = {Quantum Algorithms for Element Distinctness},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702402780},
doi = {10.1137/S0097539702402780},
abstract = {We present several applications of quantum amplitude amplification for deciding whether all elements in the image of a given function are distinct, for finding an intersection of two sorted tables, and for finding a triangle in a graph.  Our techniques generalize and improve those of Brassard, Hoyer, and Tapp [ACM SIGACT News, 28 (1997), pp. 14--19].  This shows that in the quantum world element distinctness is significantly easier than sorting, in contrast to the classical world.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1324–1330},
numpages = {7},
keywords = {collision problem, element distinctness, quantum query complexity}
}

@article{10.1137/S0097539702402676,
author = {Erlebach, Thomas and Jansen, Klaus and Seidel, Eike},
title = {Polynomial-Time Approximation Schemes for Geometric Intersection Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702402676},
doi = {10.1137/S0097539702402676},
abstract = {A disk graph is the intersection graph of a set of disks with arbitrary diameters in the plane.  For the case that the disk representation is given, we present polynomial-time approximation schemes (PTASs) for the maximum weight independent set problem (selecting disjoint disks of maximum total weight) and for the minimum weight vertex cover problem in disk graphs.  These are the first known PTASs for $mathcal{NP}$-hard optimization problems on disk graphs. They are based on a novel recursive subdivision of the plane that allows applying a shifting strategy on different levels simultaneously, so that a dynamic programming approach becomes feasible.  The PTASs for disk graphs represent a common generalization of previous results for planar graphs and unit disk graphs. They can be extended to intersection graphs of other "disk-like" geometric objects (such as squares or regular polygons), also in higher dimensions.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1302–1323},
numpages = {22},
keywords = {disk graph, independent set, shifting strategy, vertex cover}
}

@article{10.1137/S0097539701391002,
author = {Hemaspaandra, Edith and Hemaspaandra, Lane A. and Hempel, Harald},
title = {Extending Downward Collapse from 1-versus-2 Queries to <i>m</i>-versus-<i>m</i> + 1 Queries},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701391002},
doi = {10.1137/S0097539701391002},
abstract = {The top part of Figure 1.1 shows some classes from the (truth-table) bounded-query and boolean hierarchies. It is well known that if either of these hierarchies collapses at a given level, then all higher levels of that hierarchy collapse to that same level. This is a standard "upward translation of equality" that has been known for over a decade. The issue of whether these hierarchies can translate equality downwards has proven vastly more challenging. In particular, with regard to Figure 1.1, consider the following claim: [ psigkmtt = psigkmponett implies diffmsigk = codiffmsigk = bh(sigmak). (*) ] This claim, if true, says that equality translates downwards between levels of the bounded-query hierarchy and the boolean hierarchy levels that (before the fact) are immediately below them. Until recently, it was not known whether (*) ever held, except for the degenerate cases m = 0 and k = 0. Then Hemaspaandra, Hemaspaandra, and Hempel [SIAM J. Comput., 28 (1999), pp. 383--393] proved that (*) holds for all m, for k &gt; 2. Buhrman and Fortnow [J. Comput. System Sci., 59 (1999), pp. 182--199] then showed that, when k = 2, (*) holds for the case m = 1. In this paper, we prove that for the case k = 2, (*) holds for all values of m. Since there is an oracle relative to which "for k = 1, (*) holds for all m" fails (see Buhrman and Fortnow), our achievement of the k = 2 case cannot be strengthened to k = 1 by any relativizable proof technique. The new downward translation we obtain also tightens the collapse in the polynomial hierarchy implied by a collapse in the bounded-query hierarchy of the second level of the polynomial hierarchy.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1352–1369},
numpages = {18},
keywords = {upward separation, boolean hierarchy, polynomial hierarchy, no-search easy-hard technique, downward translation of equality, downward collapse, computational complexity theory}
}

@article{10.1137/S009753970445603,
author = {Fischer, Eldar},
title = {The Difficulty of Testing for Isomorphism against a Graph That Is Given in Advance},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970445603},
doi = {10.1137/S009753970445603},
abstract = {Motivated by a question from [E. Fischer, G. Kindler, D. Ron, S. Safra, and A. Samorodnitsky, J. Comput. System Sci., 68 (2004), pp. 753--787], we investigate the number of queries required for testing that an input graph G is isomorphic to a fixed graph H that is given in advance. We correlate this number with a measure of the "complexity" of H that we define here, by proving both an upper bound and a lower bound on the number of queries that depends on this new measure. As far as we know this is the first characterization of this type for graphs.},
journal = {SIAM J. Comput.},
month = may,
pages = {1147–1158},
numpages = {12},
keywords = {graph isomorphism, regularity lemma, property testing}
}

@article{10.1137/S0097539704444555,
author = {Jackson, Jeffrey C. and Servedio, Rocco A.},
title = {Learning Random Log-Depth Decision Trees under Uniform Distribution},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704444555},
doi = {10.1137/S0097539704444555},
abstract = {We consider three natural models of random logarithmic depth decision trees over Boolean variables. We give an efficient algorithm that for each of these models learns all but an inverse polynomial fraction of such trees using only uniformly distributed random examples from {0,1} n. The learning algorithm constructs a decision tree as its hypothesis.},
journal = {SIAM J. Comput.},
month = may,
pages = {1107–1128},
numpages = {22},
keywords = {decision trees, computational learning theory, PAC learning}
}

@article{10.1137/S0097539704444038,
author = {Beimel, Amos and Weinreb, Enav},
title = {Separating the Power of Monotone Span Programs  over Different Fields},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704444038},
doi = {10.1137/S0097539704444038},
abstract = {Monotone span programs represent a linear-algebraic model of computation. They are equivalent to linear secret sharing schemes and have various applications in cryptography and complexity. A fundamental question regarding them is how the choice of the field in which the algebraic operations are performed affects the power of the span program. In this paper we prove that the power of monotone span programs over finite fields of different characteristics is incomparable; we show a superpolynomial separation between any two fields with different characteristics, solving an open problem of Pudl\'{a}k and Sgall [Algebraic models of computation and interpolation for algebraic proof systems, in Proof Complexity and Feasible Arithmetic, DIMACS Ser. Discrete Math. Theoret. Comput. Sci. 39, P. W. Beame and S. Buss, eds., AMS, Providence, RI, 1998, pp. 279--296]. Using this result we prove a superpolynomial lower bound for monotone span programs for a function in uniform-${cal N}C^2$ (and therefore in ${cal P}$), solving an open problem of Babai, G\'{a}l, and Wigderson [Combinatorica, 19 (1999), pp. 301--319]. (All previous superpolynomial lower bounds for monotone span programs were for functions not known to be in ${cal P}$.) Finally, we show that quasi-linear secret sharing schemes, a generalization of linear secret sharing schemes introduced in Beimel and Ishai [On the power of nonlinear secret-sharing, in Proceedings of the 16th Annual IEEE Conference on Computational Complexity, 2001, pp. 188--202], are stronger than linear secret sharing schemes. In particular, this proves, without any assumptions, that nonlinear secret sharing schemes are more efficient than linear secret sharing  schemes.},
journal = {SIAM J. Comput.},
month = may,
pages = {1196–1215},
numpages = {20},
keywords = {lower bounds, algebraic models of computation, monotone span programs, secret sharing}
}

@article{10.1137/S0097539704443057,
author = {Dinur, Irit and Guruswami, Venkatesan and Khot, Subhash and Regev, Oded},
title = {A New Multilayered PCP and the Hardness of Hypergraph Vertex Cover},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704443057},
doi = {10.1137/S0097539704443057},
abstract = {Given a k-uniform hypergraph, the E k-Vertex-Cover problem is to find the smallest subset of vertices that intersects every hyperedge. We present a new multilayered probabilistically checkable proof (PCP) construction that extends the Raz verifier. This enables us to prove that E k-Vertex-Cover is NP-hard to approximate within a factor of $(k-1-epsilon)$ for arbitrary constants $epsilon&gt;0$ and $kge 3$. The result is nearly tight as this problem can be easily approximated within factor k. Our construction makes use of the biased long-code and is analyzed using combinatorial properties of s-wise t-intersecting families of subsets. We also give a different proof that shows an inapproximability factor of $lfloor frac{k}{2} rfloor -eps$. In addition to being simpler, this proof also works for superconstant values of k up to (log N)1/c, where c &gt; 1 is a fixed constant and N is the number of hyperedges.},
journal = {SIAM J. Comput.},
month = may,
pages = {1129–1146},
numpages = {18},
keywords = {hardness of approximation, hypergraph vertex cover, long-code, multilayered outer verifier, probabilistically checkable proof}
}

@article{10.1137/S0097539704441642,
author = {Nickelsen, Arfst and Tantau, Till},
title = {The Complexity of Finding Paths in  Graphs with Bounded Independence Number},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704441642},
doi = {10.1137/S0097539704441642},
abstract = {We study the problem of finding a path between two vertices in finite directed graphs whose independence number is bounded by some constant k. The independence number of a graph is the largest number of vertices that can be picked such that there is no edge between any two of them. The complexity of this problem depends on the exact question we ask: Do we wish only to tell whether a path exists? Do we also wish to construct such a path? Are we required to construct the shortest one? Concerning the first question, we show that the reachability problem is first-order definable for all k  and that its succinct version is $Pi_2^{mathrm{P}}$-complete for all k. In contrast, the reachability problems for many other types of finite graphs, including dags and trees, are not first-order definable, and their succinct versions are PSPACE-complete. Concerning the second question, we show not only that we can construct paths in logarithmic space, but that there even exists a logspace approximation scheme for this problem. The scheme gets a ratio r &gt; 1 as additional input and outputs a path that is at most r times as long as the shortest path. Concerning the third question, we show that even telling whether the shortest path has a certain length is NL-complete and thus is as difficult as for arbitrary directed graphs.},
journal = {SIAM J. Comput.},
month = may,
pages = {1176–1195},
numpages = {20},
keywords = {reachability, shortest paths, first-order definability, connectivity, distance in graphs, approximation algorithms, succinct representations, logarithmic space, completeness, tournaments, polynomial hierarchy}
}

@article{10.1137/S0097539703433158,
author = {Hwang, Frank K. and He, Yong and Wang, Yang},
title = {Strictly Nonblocking Multirate Log<i><sub>d</sub></i>(<i>N</i>,<i>m</i>,<i>p</i>) Networks},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433158},
doi = {10.1137/S0097539703433158},
abstract = {We give necessary and sufficient conditions for the d-nary multilog network to be strictly nonblocking under the discrete multirate model, and we give sufficient conditions for the same under the continuous multirate model.},
journal = {SIAM J. Comput.},
month = may,
pages = {1271–1278},
numpages = {8},
keywords = {multilog network, Cantor network, strictly nonblocking network, multirate model}
}

@article{10.1137/S009753970343275X,
author = {Fatourou, Panagiota and Mavronicolas, Marios and Spirakis, Paul},
title = {Efficiency of Oblivious versus Nonoblivious Schedulers for Optimistic, Rate-Based Flow Control},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970343275X},
doi = {10.1137/S009753970343275X},
abstract = {Two important performance parameters of distributed,  rate-based flow control algorithms  are their  locality  and  convergence complexity . The former is characterized by the amount of global knowledge that is available to their scheduling mechanisms, while the latter is defined as the number of  update operations  performed on rates of individual  sessions  until  max-min fairness  is reached.  Optimistic  algorithms allow any  session  to intermediately receive a rate larger than its max-min fair rate;  bottleneck  algorithms finalize the rate of a session only if it is restricted by a certain, highly congested link of the network. In this work, we present a comprehensive collection of lower and upper bounds on convergence complexity, under varying degrees of locality, for optimistic, bottleneck, rate-based flow control algorithms. Say that an algorithm is  oblivious  if its scheduling mechanism uses no information of either the session rates or the network topology. We present a novel, combinatorial construction of a capacitated network, which we use to establish a fundamental lower bound of $frac{dn}{4} + frac{n}{2}$ on the convergence complexity of  any  oblivious algorithm, where  n  is the number of sessions laid out on a network, and  d , the  session dependency , is a measure of topological dependencies among sessions. Moreover, we devise a novel  simulation proof  to establish that, perhaps surprisingly, the lower bound of $frac{dn}{4} + frac{n}{2}$ on convergence complexity still holds for any  partially oblivious  algorithm, in which the scheduling mechanism is allowed to use information about session rates, but is otherwise unaware of network topology.On the positive side, we prove that the lower bounds for oblivious and partially oblivious algorithms are both  tight . We do so by presenting  optimal  oblivious algorithms, which converge after $frac{dn}{2} + frac{n}{2}$ update operations are performed in the  worst  case. To complete the picture, we show that  linear  convergence complexity can indeed be achieved if information about both session rates and network topology is available to schedulers. We present a counterexample,  nonoblivious  algorithm, which converges within an  optimal  number of  n  update operations.Our results imply a surprising convergence complexity collapse of oblivious and partially oblivious algorithms, and a convergence complexity separation between (partially) oblivious and nonoblivious algorithms for optimistic, bottleneck rate-based flow control.},
journal = {SIAM J. Comput.},
month = may,
pages = {1216–1252},
numpages = {37},
keywords = {partially oblivious, and nonoblivious algorithms; bottleneck algorithms, distributed algorithms; lower bounds; rate-based flow control; max-min fairness; convergence complexity; oblivious}
}

@article{10.1137/S0097539703428002,
author = {Bonis, Annalisa De and Gasieniec, Leszek and Vaccaro, Ugo},
title = {Optimal Two-Stage Algorithms for Group Testing Problems},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703428002},
doi = {10.1137/S0097539703428002},
abstract = {Group testing refers to the situation in which one is given a set of objects ${cal O}$, an unknown subset ${cal P}subseteq {cal  O}$, and the task of determining ${cal P}$ by asking queries of the type "does  ${cal P}$ intersect $cal Q$?," where  $cal Q$ is a subset of ${cal  O}$. Group testing is a basic search paradigm that occurs in a variety of situations such as quality control testing, searching in storage systems, multiple access communications, and data compression, among others. Group testing procedures have been recently applied in computational molecular biology, where they are used for screening libraries of clones with hybridization probes  and sequencing by hybridization.Motivated by  particular features of group testing algorithms used in biological screening, we study the efficiency of two-stage group testing procedures. Our main result is the first optimal two-stage algorithm that uses a number of tests of the same order as the information-theoretic lower bound on the problem. We also provide efficient algorithms for the case in which there is a Bernoulli probability distribution on the possible sets  ${cal P}$, and an optimal algorithm for the case in which the outcome of tests may be unreliable because of the presence of "inhibitory" items in  ${cal  O}$. Our results depend on a combinatorial structure introduced in this paper.  We believe that  it will prove useful in other contexts, too.},
journal = {SIAM J. Comput.},
month = may,
pages = {1253–1270},
numpages = {18},
keywords = {group testing, cover-free families}
}

@article{10.1137/S0097539703420675,
author = {Etessami, Kousha and Wilke, Thomas and Schuller, Rebecca A.},
title = {Fair Simulation Relations, Parity Games, and State Space Reduction for B\"{u}Chi Automata},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703420675},
doi = {10.1137/S0097539703420675},
abstract = {We give efficient algorithms, improving optimal known bounds, for computing a variety of simulation relations on the state space of a Büchi automaton. Our algorithms are derived via a unified and simple parity-game framework. This framework incorporates previously studied notions like fair and direct simulation, but also a new natural notion of simulation called delayed simulation, which we introduce for the purpose of state space reduction. We show that delayed simulation---unlike fair simulation---preserves the automaton language upon quotienting and allows substantially better state space reduction than direct simulation. Using our parity-game approach, which relies on an algorithm by Jurdzi\'{y}ski, we give efficient algorithms for computing all of the above simulations. In particular, we obtain an O( mn 3)-time and O( mn)-space algorithm for computing both the delayed and the fair simulation relations. The best prior algorithm for fair simulation requires time and space O( n 6). Our framework also allows one to compute bisimulations: we compute the fair bisimulation relation in O( mn 3) time and O( mn) space, whereas the best prior algorithm for fair bisimulation requires time and space O( n 10).},
journal = {SIAM J. Comput.},
month = may,
pages = {1159–1175},
numpages = {17},
keywords = {fair simulation relations, state space reduction, B\"{u}chi automata, parity games}
}

@article{10.1137/S0097539700377256,
author = {S\'{e}nizergues, G\'{e}raud},
title = {The Bisimulation Problem for Equational Graphs of Finite Out-Degree},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377256},
doi = {10.1137/S0097539700377256},
abstract = {The bisimulation problem for equational graphs of finite out-degree is shown to be decidable. We reduce this problem to the $eta$-bisimulation problem for deterministic  rational (vectors of) boolean series on the alphabet of a deterministic pushdown automaton ${cal M}$. We then exhibit a complete formal system for deducing equivalent pairs of such vectors.},
journal = {SIAM J. Comput.},
month = may,
pages = {1025–1106},
numpages = {82},
keywords = {complete formal systems, rational languages, equational graphs, deterministic pushdown automata, bisimulation, finite dimensional vector spaces, matrix semigroups}
}

@article{10.1137/S0097539704442118,
author = {Kaminski, Michael},
title = {A Lower Bound on the Complexity of   Polynomial Multiplication over Finite Fields},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704442118},
doi = {10.1137/S0097539704442118},
abstract = {It is shown that computing the coefficients of the product of two degree-$n$ polynomials over a q-element field by means of a quadratic algorithm requires at least $(3 + frac{scriptstyle (q - 1)^2}{scriptstyle q^5 + (q - 1)^3})n - o(n)$ multiplications.},
journal = {SIAM J. Comput.},
month = apr,
pages = {960–992},
numpages = {33},
keywords = {polynomial multiplication, linear recurring sequences, quadratic algorithms, Hankel matrices, error-correcting codes}
}

@article{10.1137/S0097539704440442,
author = {Georgiou, Chryssis and Russell, Alexander and Shvartsman, Alexander A.},
title = {Work-Competitive Scheduling for Cooperative Computing with Dynamic Groups},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704440442},
doi = {10.1137/S0097539704440442},
abstract = {The problem of cooperatively performing a set of t tasks in a decentralized computing environment subject to failures is one of the fundamental problems in distributed computing.  The setting with partitionable networks is especially challenging, as algorithmic solutions must accommodate the possibility that groups of processors become disconnected (and, perhaps, reconnected) during the computation. The efficiency of task-performing algorithms is often assessed in terms of work: the total number of tasks, counting multiplicities, performed by all of the processors during the computation. In general, the scenario where the processors are partitioned into g disconnected components causes any task-performing algorithm to have work $Omega(tcdot g)$ even if each group of processors performs no more than the optimal number of $Theta(t)$ tasks.  Given that such pessimistic lower bounds apply to any scheduling algorithm, we pursue a competitive analysis. Specifically, this paper studies a simple randomized scheduling algorithm for p asynchronous processors, connected by a dynamically changing communication medium, to complete t known tasks. The performance of this algorithm is compared against that of an omniscient off-line algorithm with full knowledge of the future changes in the communication medium. The paper describes a notion of computation width, which associates a natural number with a history of changes in the communication medium, and shows both upper and lower bounds on work-competitiveness in terms of this quantity. Specifically, it is shown that the simple randomized algorithm obtains the competitive ratio $(1+mathbf{cw}/e)$, where $mathbf{cw}$ is the computation width and $e$ is the base of the natural logarithm ($e=2.7182ldots$); this competitive ratio is then shown to be tight.},
journal = {SIAM J. Comput.},
month = apr,
pages = {848–862},
numpages = {15},
keywords = {competitive analysis, work complexity, on-line algorithms, independent tasks, distributed computation, partitionable networks, randomized algorithms}
}

@article{10.1137/S0097539703439404,
author = {Chan, Timothy M.},
title = {Low-Dimensional Linear Programming with Violations},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703439404},
doi = {10.1137/S0097539703439404},
abstract = {Two decades ago, Megiddo and Dyer showed that linear programming (LP) in two and three dimensions (and subsequently any constant number of dimensions) can be solved in linear time. In this paper, we consider the LP problem with at most k violations, i.e., finding a point inside all but at most k halfspaces, given a set of n halfspaces. We present a simple algorithm in two dimensions that runs in O(( n+ k 2)log n) expected time; this is faster than earlier algorithms by Everett, Robert, and van Kreveld (1993) and Matousek (1994) for many values of k and is probably near-optimal. An extension of our algorithm in three dimensions runs in near O( n+ k 11/4 n 1/4) expected time. Interestingly, the idea is based on concave-chain decompositions (or covers) of the $(le k)$-level, previously used in proving combinatorial k-level bounds. Applications in the plane include improved algorithms for finding a line that misclassifies the fewest among a set of bichromatic points, and finding the smallest circle enclosing all but k points. We also discuss related problems of finding local minima in levels.},
journal = {SIAM J. Comput.},
month = apr,
pages = {879–893},
numpages = {15},
keywords = {LP, computational geometry, algorithms}
}

@article{10.1137/S0097539703435686,
author = {Koltun, Vladlen and Sharir, Micha},
title = {Curve-Sensitive Cuttings},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435686},
doi = {10.1137/S0097539703435686},
abstract = {We introduce $(1/r)$-cuttings for collections of surfaces in 3-space, such that the cuttings are sensitive to an additional collection of curves. Specifically, let $S$ be a set of $n$ surfaces and let $C$ be a set of $m$ curves in $mathbb{R}^3$, all of constant description complexity. Let $1le rle min{m,n}$ be a given parameter. We show the existence of a $(1/r)$-cutting $Xi$ of $S$ of size $O(r^{3+varepsilon})$, for any $varepsilon&gt;0$, such that the number of crossings between the curves of $C$ and the cells of $Xi$ is $O(mr^{1+varepsilon})$. The latter bound improves, by roughly a factor of $r$, the bound that can be obtained for cuttings based on vertical decompositions. We view curve-sensitive cuttings as a powerful tool for various scenarios that involve curves and surfaces in three dimensions. As a preliminary application, we use the construction to obtain a bound of $O(m^{1/2}n^{2+varepsilon})$, for any $varepsilon&gt;0$, on the complexity of the multiple zone of $m$ curves in the arrangement of $n$ surfaces in 3-space. After the conference publication of this paper [V. Koltun and M. Sharir, Proceedings of the 19th ACM Symposium on Computational Geometry, 2003, pp. 136--143], curve-sensitive cuttings were applied to derive an algorithm for efficiently counting triple intersections among planar convex objects in three dimensions [E. Ezra and M. Sharir, Proceedings of the 20th ACM Symposium on Computational Geometry, 2004, pp. 210--219], and we expect additional applications to arise in the future.},
journal = {SIAM J. Comput.},
month = apr,
pages = {863–878},
numpages = {16},
keywords = {computational geometry, random sampling, curves in space, zone, cuttings}
}

@article{10.1137/S0097539703432785,
author = {G\'{a}l, Anna and Ros\'{e}n, Adi},
title = {$\Omega(\log n)$ Lower Bounds on the Amount of Randomness in 2-Private Computation},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703432785},
doi = {10.1137/S0097539703432785},
abstract = {We consider the amount of randomness necessary in information-theoretic private protocols. We prove that at least $Omega(log n)$ random bits are necessary for the t-private computation of the function {tt xor} by n players for any $t geq 2$. In view of the upper bound of O( t 2 log( n/ t)) [E. Kushilevitz and Y. Mansour, SIAM J. Discrete Math., 10 (1997), pp. 647--661], this bound is tight, up to constant factors, for any fixed t. For a class of protocols obeying certain restrictions, we give a stronger lower bound of $Omega(t log(n/t))$. We note that all known randomness efficient private protocols designed specifically for {tt xor} belong to this class. In fact we prove slightly stronger statements: we prove that on every input there is a run where the number of random bits used is large, rather than proving only that on some input there is a run where the number of random bits used is large. All our lower bounds hold for the "trusted dealer" model as well, and the $Omega(t log(n/t))$ lower bound for restricted protocols is tight, up to constant factors, for any $t geq 2$ in this model. In comparison, the previous lower bounds on the amount of randomness required by t-private computation of explicit functions did not grow with n for constant values of t, and our results improve the previous lower bounds for {tt xor} for any $2 leq t = o(log n)$. Our results also show that already for t=2$, $Omega(log n)$ random bits are necessary, while it is known that for the case of t=1$ a single random bit is sufficient for privately computing {tt xor} for any number of players. Our proofs use novel techniques by which we extract random variables from a t-private protocol, and then use the t-privacy property of the protocol to prove properties of these random variables. These properties in turn imply that the number of random bits used by the players is large.},
journal = {SIAM J. Comput.},
month = apr,
pages = {946–959},
numpages = {14},
keywords = {lower bounds, randomness, private computation}
}

@article{10.1137/S0097539703428014,
author = {Malewicz, Grzegorz},
title = {A Work-Optimal Deterministic Algorithm for the Certified Write-All Problem with a Nontrivial Number of Asynchronous Processors},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703428014},
doi = {10.1137/S0097539703428014},
abstract = {Martel [C. Martel, A. Park, and R. Subramonian, SIAM J. Comput., 21 (1992), pp. 1070--1099] posed a question for developing a work-optimal deterministic asynchronous algorithm for the fundamental load-balancing and synchronization problem called Certified Write-All (CWA). In this problem, introduced in a slightly different form by Kanellakis and Shvartsman in a PODC'89 paper [P. C. Kanellakis and A. A. Shvartsman, Distributed Computing, 5 (1992), pp. 201--247], p processors must update n memory cells and only then signal the completion of the updates. It is known that solutions to this problem can be used to simulate synchronous parallel programs on asynchronous systems with worst-case guarantees for the overhead of a simulation. Such simulations are interesting because they may increase productivity in parallel computing since synchronous parallel programs are easier to reason about than are asynchronous ones. This paper presents the first solution to the question of Martel, Park, and Subramonian. Specifically, we show a deterministic asynchronous algorithm for the CWA problem. Our algorithm has the work complexity of O( n+ p 4log n). This work complexity is asymptotically optimal for a nontrivial number of processors $p leq left(n/log nright)^{1/4}$. In contrast, all known deterministic algorithms require superlinear in n work when p = n 1/r for any fixed $r geq 1$. Our algorithm generalizes the collision principle introduced by Buss et al. [J. Buss, P. C. Kanellakis, P. L. Ragde, and A. A. Shvartsman, J. Algorithms, 20 (1996), pp. 45--86] in 1996, which has not been previously generalized despite various attempts. Each processor maintains a collection of intervals of {1,2,...,n}. Any processor iteratively selects an interval and works from its tip toward the other tip until it finishes the work or collides with another processor. Collisions are detected effectively using a special Read-Modify-Write operation. In any case, the processor transforms its collection appropriately. Our analysis shows that the transformations preserve some structural properties of collections of intervals. This guarantees that work is assigned to processors in an efficient manner.},
journal = {SIAM J. Comput.},
month = apr,
pages = {993–1024},
numpages = {32},
keywords = {certified write-all, design and analysis of parallel algorithms, asynchrony, deterministic algorithms}
}

@article{10.1137/S0097539702415007,
author = {Skutella, Martin and Uetz, Marc},
title = {Stochastic Machine Scheduling with Precedence Constraints},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702415007},
doi = {10.1137/S0097539702415007},
abstract = {We consider parallel, identical machine scheduling problems, where the jobs are subject to precedence constraints and release dates, and where the processing times of jobs are governed by independent probability distributions. Our objective is to minimize the expected value of the total  weighted completion time. Building upon a linear programming relaxation by M\"{o}hring, Schulz, and Uetz [J. ACM, 46 (1999), pp. 924--942] and a delayed list scheduling algorithm by Chekuri et al. [SIAM J. Comput., 31 (2001), pp. 146--166], we derive the first constant-factor approximation algorithms for this model.},
journal = {SIAM J. Comput.},
month = apr,
pages = {788–802},
numpages = {15},
keywords = {precedence constraints, release dates, stochastic scheduling, approximation algorithms, list scheduling algorithms, LP-relaxation, parallel machines}
}

@article{10.1137/S0097539702411381,
author = {Chiang, Yi-Ting and Lin, Ching-Chi and Lu, Hsueh-I},
title = {Orderly Spanning Trees with Applications},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702411381},
doi = {10.1137/S0097539702411381},
abstract = {We introduce and study orderly spanning trees of plane graphs.  This algorithmic tool generalizes canonical orderings, which exist only for triconnected plane graphs.  Although not every plane graph admits an orderly spanning tree, we provide an algorithm to compute an orderly pair for any connected planar graph G, consisting of an embedded planar graph H isomorphic to G, and an orderly spanning tree of H.  We also present several applications of orderly spanning trees: (1) a new constructive proof for Schnyder's realizer theorem, (2) the first algorithm for computing an area-optimal 2-visibility drawing of a planar graph, and (3) the most compact known encoding of a planar graph with O(1)-time query support. All algorithms in this paper run in linear time.},
journal = {SIAM J. Comput.},
month = apr,
pages = {924–945},
numpages = {22},
keywords = {unit-cost RAM model, orderly spanning tree, data compression, triangulation, graph encoding, realizer, visibility representation, canonical ordering, planar graph algorithm, graph drawing, succinct data structure}
}

@article{10.1137/S0097539702407515,
author = {Efrat, Alon},
title = {The Complexity of the Union of $(\alpha,\beta)$-Covered Objects},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702407515},
doi = {10.1137/S0097539702407515},
abstract = {An $(alpha,beta)$-covered object is a simply connected planar region $c$ with the property that for each point $pinpartial c$ there exists a triangle contained in $c$ and having $p$ as a vertex, such that all its angles are at least $alpha&gt;0$ and all its edges are at least $betacdot{rm diam}(c)$-long. This notion extends that of fat convex objects. We show that the combinatorial complexity of the union of $n$ $(alpha,beta)$-covered objects of "constant description complexity" is $O(lambda_{s+2}(n) log^2nloglog n)$, where $s$ is the maximum number of intersections between the boundaries of any pair of given objects, and  $lambda_s(n)$ denotes the maximum length of an $(n,s)$-Davenport--Schinzel sequence. Our result  extends  and improves previous results concerning convex $alpha$-fat objects.},
journal = {SIAM J. Comput.},
month = apr,
pages = {775–787},
numpages = {13},
keywords = {realistic input models, fat objects, motion planning}
}

@article{10.1137/S0097539701398594,
author = {Charikar, Moses and Guha, Sudipto},
title = {Improved Combinatorial Algorithms for Facility Location Problems},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701398594},
doi = {10.1137/S0097539701398594},
abstract = {We present improved combinatorial approximation algorithms for the uncapacitated facility location problem.  Two central ideas in most of our results are cost scaling and greedy improvement.  We present a simple greedy local search algorithm which achieves an approximation ratio of $2.414+epsilon$ in $tilde{O}(n^2/epsilon)$ time.  This also yields a bicriteria approximation tradeoff of $(1+gamma,1+2/gamma)$ for facility cost versus service cost which is better than previously known tradeoffs and close to the best possible.  Combining greedy improvement and cost scaling with a recent primal-dual algorithm for facility location due to Jain and Vazirani, we get an approximation ratio of $1.853$ in $tilde{O}(n^3)$ time. This is very close to the approximation guarantee of the best known algorithm which is linear programming (LP)-based.  Further, combined with the best known LP-based algorithm for facility location, we get a very slight improvement in the approximation factor for facility location, achieving $1.728$.  We also consider a variant of the capacitated facility location problem and present improved approximation algorithms for this.},
journal = {SIAM J. Comput.},
month = apr,
pages = {803–824},
numpages = {22},
keywords = {local search, combinatorial optimization, facility location, approximation algorithms}
}

@article{10.1137/S0097539701385351,
author = {Corneil, Derek G. and Rotics, Udi},
title = {On the Relationship Between Clique-Width and Treewidth},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701385351},
doi = {10.1137/S0097539701385351},
abstract = {Treewidth is generally regarded as one of the most useful parameterizations of a graph's construction. Clique-width is a similar parameterization that shares one of the powerful properties of treewidth, namely: if a graph is of bounded treewidth (or clique-width), then there is a polynomial time algorithm for any graph problem expressible in monadic second order logic, using quantifiers on vertices (in the case of clique-width you must assume a clique-width parse expression is given). In studying the relationship between treewidth and clique-width, Courcelle and Olariu [ Discrete Appl. Math., 101 (2000), pp. 77--114] showed that any graph of bounded treewidth is also of bounded clique-width; in particular, for any graph G with treewidth k, the clique-width of G is at most 4 * 2 k - 1 + 1. In this paper, we improve this result by showing that the clique-width of G is at most 3 * 2k - 1 and, more importantly, that there is an exponential lower bound on this relationship. In particular, for any k, there is a graph G with treewidth equal to k, where the clique-width of G is at least $2^{lfloor k/2rfloor - 1}$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {825–847},
numpages = {23},
keywords = {treewidth, clique-width}
}

@article{10.1137/S0097539700370539,
author = {Cole, Richard and Hariharan, Ramesh},
title = {Dynamic LCA Queries on Trees},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700370539},
doi = {10.1137/S0097539700370539},
abstract = {We show how to maintain a data structure on trees which allows for the following operations, all in worst-case constant time: insertion of leaves and internal nodes, deletion of leaves, deletion of internal nodes with only one child, determining the least common ancestor of any two nodes. We also generalize the Dietz--Sleator "cup-filling" scheduling methodology, which may be of independent interest.},
journal = {SIAM J. Comput.},
month = apr,
pages = {894–923},
numpages = {30},
keywords = {LCA, "cup-filling" scheduling, dynamic LCA}
}

@article{10.1137/S0097539794261799,
author = {Kalyanasundaram, Bala and Pruhs, Kirk R.},
title = {Fault-Tolerant Scheduling},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794261799},
doi = {10.1137/S0097539794261799},
abstract = {We study fault-tolerant multiprocessor scheduling under the realistic assumption that the occurrence of faults cannot be predicted. The goal in these problems is to minimize the delay incurred by the jobs. Since this is an online problem we use competitive analysis to evaluate possible algorithms. For the problems of minimizing the makespan and minimizing the average completion time (for static release times), we give nonclairvoyant algorithms (both deterministic and randomized) that have provably asymptotically optimal competitive ratios. The main tool used by these algorithms to combat faults is redundancy. We also show that randomization has the same effect as redundancy.},
journal = {SIAM J. Comput.},
month = mar,
pages = {697–719},
numpages = {23},
keywords = {fault-tolerant, multiprocessor scheduling, competitive analysis, makespan, transient faults, permanent faults}
}

@article{10.1137/S0097539704444440,
author = {Huo, Yumei and Y, Joseph and Leung, .-T.},
title = {Online Scheduling of Precedence Constrained Tasks},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704444440},
doi = {10.1137/S0097539704444440},
abstract = {A fundamental problem in scheduling theory is that of scheduling a set of n tasks, with precedence constraints, on $m ge 1$ identical and parallel processors so as to minimize the makespan (schedule length). In the past, research has focused on the setting whereby all tasks are available for processing at the beginning (i.e., at time t = 0). In this article we consider the situation where tasks, along with their precedence constraints, are released at different times, and the scheduler has to make scheduling decisions without knowledge of future releases. In other words, the scheduler has to schedule tasks in an online fashion. We consider both preemptive and nonpreemptive schedules. We show that optimal online algorithms exist for some cases, while for others it is impossible to have one. Our results give a sharp boundary delineating the possible and the impossible cases.},
journal = {SIAM J. Comput.},
month = mar,
pages = {743–762},
numpages = {20},
keywords = {intrees, schedule length, precedence constraints, online and offline scheduling, preemptive and nonpreemptive scheduling, outtrees, parallel and identical processors}
}

@article{10.1137/S009753970444199X,
author = {Czumaj, Artur and Sohler, Christian},
title = {Abstract Combinatorial Programs and Efficient Property Testers},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970444199X},
doi = {10.1137/S009753970444199X},
abstract = {Property testing is a relaxation of classical decision problems which aims at distinguishing between functions having a predetermined property and functions being far from any function having the property. In this paper we present a novel framework for analyzing property testing algorithms. Our framework is based on a connection of property testing and a new class of problems which we call  abstract combinatorial programs . We show that if the problem of testing a property can be reduced to an  abstract combinatorial program  of  small dimension , then the property has an efficient tester. We apply our framework to a variety of problems. We present efficient property testing algorithms for  geometric clustering  problems, for the  reversal distance  problem, and for  graph  and  hypergraph coloring  problems. We also prove that, informally, any  hereditary graph property  can be efficiently tested if and only if it can be reduced to an abstract combinatorial program of small size.Our framework allows us to analyze all our testers in a unified way, and the obtained complexity bounds either match or improve the previously known bounds. Furthermore, even if the asymptotic complexity of the testers is not improved, the obtained proofs are significantly simpler than the previous ones. We believe that our framework will help to understand the structure of efficiently testable properties.},
journal = {SIAM J. Comput.},
month = mar,
pages = {580–615},
numpages = {36},
keywords = {approximation algorithms, randomized algorithms, coloring, hereditary graph properties, clustering problems, property testing}
}

@article{10.1137/S0097539703439088,
author = {Seidel, Raimund and Sharir, Micha},
title = {Top-Down Analysis of Path Compression},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703439088},
doi = {10.1137/S0097539703439088},
abstract = {We present a new analysis of the worst-case cost of path compression, which is an operation that is used in various well-known "union-find" algorithms.  In contrast to previous analyses which are essentially based on bottom-up approaches, our method proceeds top-down, yielding recurrence relations from which the various bounds arise naturally.  In particular the famous quasi-linear bound involving the inverse Ackermann function can be derived without having to introduce the Ackermann function itself.},
journal = {SIAM J. Comput.},
month = mar,
pages = {515–525},
numpages = {11},
keywords = {union-find problem, disjoint sets data structure, inverse Ackermann function, path compression}
}

@article{10.1137/S0097539703437831,
author = {Anagnostopoulos, Aris and Kirsch, Adam and Upfal, Eli},
title = {Load Balancing in Arbitrary Network Topologies with Stochastic Adversarial Input},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703437831},
doi = {10.1137/S0097539703437831},
abstract = {We study the long-term (steady state) performance of a simple, randomized, local load balancing technique under a broad range of input conditions. We assume a system of  n  processors connected by an arbitrary network topology. Jobs are placed in the processors by a deterministic or randomized adversary. The adversary knows the current and past load distribution in the network and can use this information to place the new tasks in the processors. A node can execute one job per step, and can also participate in one load balancing operation in which it can move tasks to a direct neighbor in the network. In the protocol we analyze here, a node equalizes its load with a random neighbor in the graph. Our analysis of the protocol does not assume any particular input distribution. The input is generated by an arbitrary deterministic or probabilistic adversary subject only to some weak statistical properties. For stability and expected performance of the system we adopt the stochastic adversary model of [Borodin et al.,  J. ACM , 48 (2001), pp. 13--38]. For high-probability bounds we introduce a more restricted input model, the  strongly bounded  adversary.Assuming the stochastic adversarial input model, we show that if the adversary does not trivially overload the network (i.e., there is an integer $wgeq 1$ such that the expected number of new jobs in any interval of length $w$ is bounded by $lambda nw$ for some $lambda&lt;1$), then the system is stable for any connected network topology, regardless of how the adversary allocates the new jobs between the processors.When the system is stable, the next performance parameter of interest is the waiting time of jobs. We develop expected and high probability bounds on the total load in the system and the waiting time of jobs in terms of the network topology. In particular, in the above stochastic adversary model, if the network is an expander graph, the expected wait of a task is  O (  w  + log  n ), and in the strongly bounded adversary model the waiting time of a task is  O (  w  + log  n ) with high probability.We contrast these results with the work stealing load balancing protocol, where we show that in sparse networks, the load in the system and the waiting time can be exponential in the network size.},
journal = {SIAM J. Comput.},
month = mar,
pages = {616–639},
numpages = {24},
keywords = {stability, stochastic adversary, dynamic load balancing, steady state analysis, efficiency}
}

@article{10.1137/S0097539703435765,
author = {Chan, Ho-Leung and Lam, Tak-Wah and To, Kar-Keung},
title = {Nonmigratory Online Deadline Scheduling on Multiprocessors},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435765},
doi = {10.1137/S0097539703435765},
abstract = {In this paper we consider multiprocessor scheduling with hard deadlines and investigate the cost of eliminating migration in the online setting. Let I be any set of jobs that can be completed by some migratory offline schedule on m processors. We show that I can also be completed by a nonmigratory online schedule using m speed-5.828 processors (i.e., processors 5.828 times faster).  This result supplements the previous results that I can also be completed by a nonmigratory offline schedule using 6m unit-speed processors [B. Kalyanasundaram and K. R. Pruhs, J. Algorithms, 38 (2001), pp. 2--24] or a migratory online schedule using m speed-2 processors [C. A. Phillips et al., Algorithmica, 32 (2002), pp. 163--200]. Our result is based on a simple conservative scheduling algorithm called PARK, which commits a processor to a job only when the processor has zero commitment before its deadline. A careful analysis of PARK further shows that the processor speed can be reduced arbitrarily close to 1 by exploiting more processors (say, using 16m speed-1.8 processors). PARK also finds application in overloaded systems; it gives the first online nonmigratory algorithm that can exploit moderately faster processors to match the performance of any migratory offline algorithm.},
journal = {SIAM J. Comput.},
month = mar,
pages = {669–682},
numpages = {14},
keywords = {online algorithms, resource augmentation, multiprocessor scheduling, competitive analysis, job migration}
}

@article{10.1137/S0097539703433900,
author = {Agarwal, Pankaj K. and Sharir, Micha},
title = {Pseudo-Line Arrangements: Duality, Algorithms, and Applications},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433900},
doi = {10.1137/S0097539703433900},
abstract = {A finite collection of  x -monotone unbounded Jordan curves in the plane is called a family of  pseudo-lines  if every pair of curves intersect in at most one point, and the two curves cross each other there. Let  L  be such a collection of  n  pseudo-lines, and let  P  be a set of  m  points in $reals^2$. Extending a result of Goodman [  Discrete Math ., 32 (1980), pp. 27--35], we define a  duality  transform that maps  L  to a set  L * of points in $reals^2$ and  P  to a set  P * of (  x -monotone) pseudo-lines in $reals^2$, so that the incidence and the "above-below" relations between the points and the pseudo-lines are preserved. We present an efficient algorithm for computing the dual arrangement {eus A}$(P^*)$ under an appropriate model of computation. We also present a dynamic data structure for reporting, in $O(m^eps + k)$ time, all  k  points of  P  that lie below a query arc, which is either a circular arc or a portion of the graph of a polynomial of fixed degree. This result is needed for computing the dual arrangement for certain classes of pseudo-lines arising in several applications, but is also interesting in its own right. We present a few applications of our dual arrangement algorithm, such as computing incidences between points and pseudo-lines and computing a subset of faces in a pseudo-line arrangement.Next, we present an efficient algorithm for cutting a set of circles into arcs so that every pair of arcs intersect in at most one point, i.e., the resulting arcs constitute a collection of  pseudo-segments . By combining this algorithm with our algorithm for computing the dual arrangement of pseudo-lines, we obtain efficient algorithms for several problems involving arrangements of circles or circular arcs, such as reporting or counting incidences between points and circles and computing a set of marked faces in arrangements of circles.},
journal = {SIAM J. Comput.},
month = mar,
pages = {526–552},
numpages = {27},
keywords = {arrangements, pseudo-lines, duality}
}

@article{10.1137/S0097539703432542,
author = {Cesa-Bianchi, Nicol\`{o} and Conconi, Alex and Gentile, Claudio},
title = {A Second-Order Perceptron Algorithm},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703432542},
doi = {10.1137/S0097539703432542},
abstract = {Kernel-based linear-threshold algorithms, such as support vector machines and Perceptron-like algorithms, are among the best available techniques for solving pattern classification problems. In this paper, we describe an extension of the classical Perceptron algorithm, called second-order Perceptron, and analyze its performance within the mistake bound model of on-line learning. The bound achieved by our algorithm depends on the sensitivity to second-order data information and is the best known mistake bound for (efficient) kernel-based linear-threshold classifiers to date. This mistake bound, which strictly generalizes the well-known Perceptron bound, is expressed in terms of the eigenvalues of the empirical data correlation matrix and depends on a parameter controlling the sensitivity of the algorithm to the distribution of these eigenvalues. Since the optimal setting of this parameter is not known a priori, we also analyze two variants of the second-order Perceptron algorithm: one that adaptively sets the value of the parameter in terms of the number of mistakes made so far, and one that is parameterless, based on pseudoinverses.},
journal = {SIAM J. Comput.},
month = mar,
pages = {640–668},
numpages = {29},
keywords = {Perceptron algorithm, pattern classification, mistake bounds}
}

@article{10.1137/S0097539702418048,
author = {K\"{o}nemann, J. and Ravi, R.},
title = {Primal-Dual Meets Local Search: Approximating MSTs With Nonuniform Degree Bounds},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702418048},
doi = {10.1137/S0097539702418048},
abstract = {We present a new bicriteria approximation algorithm for the degree-bounded minimum-cost spanning tree (MST) problem: Given an undirected graph with nonnegative edge weights and a degree bound B, find a spanning tree of maximum node-degree B and minimum total edge-cost. Our algorithm outputs a tree of maximum degree at most a constant times B and total edge-cost at most a constant times that of a minimum-cost degree- B-bounded spanning tree. While our new algorithm is based on ideas from Lagrangian relaxation, as is our previous work [SIAM J. Comput., 31 (2002), pp. 1783--1793], it does not rely on computing a solution to a linear program. Instead, it uses a repeated application of Kruskal's MST algorithm interleaved with a combinatorial update of approximate Lagrangian node-multipliers maintained by the algorithm. These updates cause subsequent repetitions of the spanning tree algorithm to run for longer and longer times, leading to overall progress and a proof of the performance guarantee. A second useful feature of our algorithm is that it can handle nonuniform degree bounds on the nodes: Given distinct bounds Bv for every node $v in V$, the output tree has degree at most O(Bv + log|V|) for every $v in V$. As before, the cost of the tree is at most a constant times that of a minimum-cost tree obeying all degree bounds.},
journal = {SIAM J. Comput.},
month = mar,
pages = {763–773},
numpages = {11},
keywords = {network algorithms, bicriteria approximation, Lagrangian relaxation, spanning trees, approximation algorithms, degree-bounded spanning trees}
}

@article{10.1137/S0097539702416141,
author = {Dujmovic, Vida and Morin, Pat and Wood, David R.},
title = {Layout of Graphs with Bounded Tree-Width},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702416141},
doi = {10.1137/S0097539702416141},
abstract = {A  queue layout  of a graph consists of a total order of the vertices, and a partition of the edges into  queues , such that no two edges in the same queue are nested. The minimum number of queues in a queue layout of a graph is its  queue-number . A  three-dimensional  (  straight-line grid ) drawing of a graph represents the vertices by points in $mathbb{Z}^3$ and the edges by noncrossing line-segments. This paper contributes three main results: (1) It is proved that the minimum volume of a certain type of three-dimensional drawing of a graph  G  is closely related to the queue-number of  G . In particular, if  G  is an  n -vertex member of a proper minor-closed family of graphs (such as a planar graph), then  G  has a $mathcal{O}(1) times mathcal{O}(1) times mathcal{O}(n)$ drawing if and only if  G  has a $mathcal{O}(1)$ queue-number.(2) It is proved that the queue-number is bounded by the tree-width, thus resolving an open problem due to Ganley and Heath [  Discrete Appl. Math ., 109 (2001), pp. 215--221] and disproving a conjecture of Pemmaraju [  Exploring the Powers of Stacks and Queues via Graph Layouts , Ph. D. thesis, Virginia Polytechnic Institute and State University, Blacksburg, VA, 1992]. This result provides renewed hope for the positive resolution of a number of open problems in the theory of queue layouts.(3) It is proved that graphs of bounded tree-width have three-dimensional drawings with $mathcal{O}(n)$ volume. This is the most general family of graphs known to admit three-dimensional drawings with $mathcal{O}(n)$ volume.The proofs depend upon our results regarding  track layouts  and  tree-partitions  of graphs, which may be of independent interest.},
journal = {SIAM J. Comput.},
month = mar,
pages = {553–579},
numpages = {27},
keywords = {track-number, three-dimensional graph drawing, tree-partition, acyclic coloring, tree-width, k-tree, queue layout, acyclic chromatic number, track layout, queue-number, tree-partition-width}
}

@article{10.1137/S0097539702408247,
author = {Zhang, Huaming and He, Xin},
title = {On Even Triangulations of 2-Connected Embedded Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702408247},
doi = {10.1137/S0097539702408247},
abstract = {Recently, Hoffmann and Kriegel proved an important combinatorial theorem [ SIAM J. Discrete Math., 9 (1996), pp. 210--224]: Every 2-connected bipartite plane multigraph G without 2-cycle faces has a triangulation in which all vertices have even degree (this is called an even triangulation). Combined with the classical Whitney's theorem, this result implies that every such graph has a 3-colorable plane triangulation. Using this theorem, Hoffmann and Kriegel significantly improved the upper bounds of several art gallery and prison guard problems. A complicated O( n 2) time algorithm was obtained in [ SIAM J. Discrete Math., 9 (1996), pp. 210--224] for constructing an even triangulation of G. Hoffmann and Kriegel conjectured that there is an O( n 3/2) time algorithm for solving this problem. In this paper, we develop a simple proof of the above theorem. Our proof reveals and relies on a natural correspondence between even triangulations of G and certain orientations of G. Based on this new proof, we obtain a very simple O(n) time algorithm for finding an even triangulation of G. We also extend our proof to show the existence of even triangulations for similar graphs on high genus surface.},
journal = {SIAM J. Comput.},
month = mar,
pages = {683–696},
numpages = {14},
keywords = {high genus graph, even triangulations, graph coloring, plane graph}
}

@article{10.1137/S0097539700376676,
author = {Bulatov, Andrei and Jeavons, Peter and Krokhin, Andrei},
title = {Classifying the Complexity of Constraints Using Finite Algebras},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700376676},
doi = {10.1137/S0097539700376676},
abstract = {Many natural combinatorial problems can be expressed as constraint satisfaction problems. This class of problems is known to be NP-complete in general, but certain restrictions on the form of the constraints can ensure tractability. Here we show that any set of relations used to specify the allowed forms of constraints can be associated with a finite universal algebra and we explore how the computational complexity of the corresponding constraint satisfaction problem is connected to the properties of this algebra. Hence, we completely translate the problem of classifying the complexity of restricted constraint satisfaction problems into the language of universal algebra.We introduce a notion of "tractable algebra," and investigate how the tractability of an algebra relates to the tractability of the smaller algebras which may be derived from it, including its subalgebras and homomorphic images. This allows us to reduce significantly the types of algebras which need to be classified. Using our results we also show that if the decision problem associated with a given collection of constraint types can be solved efficiently, then so can the corresponding search problem. We then classify all finite strictly simple surjective algebras with respect to tractability, obtaining a dichotomy theorem which generalizes Schaefer's dichotomy for the generalized satisfiability problem. Finally, we suggest a possible general algebraic criterion for distinguishing the tractable and intractable cases of the constraint satisfaction problem.},
journal = {SIAM J. Comput.},
month = mar,
pages = {720–742},
numpages = {23},
keywords = {constraint satisfaction problem, dichotomy theorem, universal algebra}
}

@article{10.1137/S0097539799362172,
author = {Ishihara, Yasunori and Ishii, Shin and Seki, Hiroyuki and Ito, Minoru},
title = {Temporal Reasoning about Two Concurrent Sequences of Events},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799362172},
doi = {10.1137/S0097539799362172},
abstract = {This paper discusses temporal reasoning with respect to constraints on two concurrent sequences of events. If two given sequences of events can be mapped into one sequence that satisfies a given constraint, then the constraint is said to be consistent. First, we mention that the consistency of such constraints is NP-complete. Then we introduce the notion of graph representations of constraints. If a graph representation of a given constraint c can be constructed in polynomial time, then the consistency of c is decidable in polynomial time. However, it is shown that the graph representability of a given c is coNP-complete. Next, we propose a subclass CDC$^{neq} of constraints such that for each constraint c in CDC$^{neq}$, a graph representation of c can be constructed in polynomial time. The expressive power of CDC$^{neq}$ is incomparable to any other subclasses of constraints for which the consistency problem is known to be tractable.},
journal = {SIAM J. Comput.},
month = feb,
pages = {498–513},
numpages = {16},
keywords = {consistency, complexity, temporal constraint, temporal reasoning}
}

@article{10.1137/S0097539798344367,
author = {Chandra, Tushar and Hadzilacos, Vassos and Jayanti, Prasad and Toueg, Sam},
title = {Generalized Irreducibility of Consensus and the Equivalence of <i>t</i>-Resilient and Wait-Free Implementations of Consensus},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798344367},
doi = {10.1137/S0097539798344367},
abstract = {We study the consensus problem, which requires multiple processes with different input values to agree on one of these values, in the context of asynchronous shared memory systems. Prior research focussed either on t-resilient solutions of this problem (which must be correct even if up to t processes crash) or on wait-free solutions (which must be correct despite the crash of any number of processes). In this paper, we show that these two forms of solvability are closely related. Specifically, for all $n &gt; t ge 2$ and all sets ${mathcal{S}}$ of shared object types (that include simple read/write registers), there is a t-resilient solution to n-process consensus using objects of types in ${mathcal{S}}$ if and only if there is a wait-free solution to (t + 1)-process consensus using objects of types in ${mathcal{S}}$.Our proof of this equivalence uses another result derived in this paper, which is of independent interest. Roughly speaking, this result states that a wait-free solution to (n - 1)-process consensus is never necessary in designing a wait-free solution to n-process consensus, regardless of the types of objects available. More precisely, for all $n ge 2$ and all sets ${mathcal{S}}$ of shared object types (that include simple read/write registers), if there is a wait-free solution to n-process consensus that uses a wait-free solution to (n - 1)-process consensus and objects of types in ${mathcal{S}}$, then there is a wait-free solution to n-process consensus that uses only objects of types in ${mathcal{S}}$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {333–357},
numpages = {25},
keywords = {wait-free algorithms, consensus, impossibility results, asynchronous distributed computation, fault tolerant algorithms}
}

@article{10.1137/S0097539704440430,
author = {Chung, Kai-min and Lu, Hsueh-I},
title = {An Optimal Algorithm for the Maximum-Density Segment Problem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704440430},
doi = {10.1137/S0097539704440430},
abstract = {We address a fundamental problem arising from analysis of biomolecular sequences. The input consists of two numbers w min and w max and a sequence S of n number pairs ( ai, wi) with wi &gt; 0. Let segment S( i, j) of S be the consecutive subsequence of S between indices i and j. The density of S( i, j) is d( i, j) = ( ai + ai + 1 + cdots + aj)/( wi + wi + 1 + cdots + wj)$. The maximum-density segment problem is to find a maximum-density segment over all segments S( i, j) with w min leq w i + wi + 1 + cdots + wj leq w max. The best previously known algorithm for the problem, due to Goldwasser, Kao, and Lu [ Proceedings of the Second International Workshop on Algorithms in Bioinformatics, R. Guigó and D. Gusfield, eds., Lecture Notes in Comput. Sci. 2452, Springer-Verlag, New York, 2002, pp. 157--171], runs in O( n log( w max- w min+1)) time. In the present paper, we solve the problem in O( n) time. Our approach bypasses the complicated right-skew decomposition, introduced by Lin, Jiang, and Chao [ J. Comput. System Sci., 65 (2002), pp. 570--586]. As a result, our algorithm has the capability to process the input sequence in an online manner, which is an important feature for dealing with genome-scale sequences. Moreover, for a type of input sequences S representable in O( m) space, we show how to exploit the sparsity of S and solve the maximum-density segment problem for S in O( m) time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {373–387},
numpages = {15},
keywords = {maximum-density segment, bioinformatics, computational geometry, data structure, sequence algorithm, slope selection, biological sequence analysis}
}

@article{10.1137/S0097539703438277,
author = {Bl\"{a}ser, Markus},
title = {A Complete Characterization of the Algebras of Minimal Bilinear Complexity},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703438277},
doi = {10.1137/S0097539703438277},
abstract = {Let R(A) denote the rank (also called bilinear complexity) of a finite dimensional associative algebra A. A fundamental lower bound for R(A) is the so-called Alder--Strassen bound R(A) ge 2 dim A - t, where t is the number of maximal twosided ideals of A. An algebra is called an algebra of minimal rank if the Alder--Strassen bound is tight, i.e., $R(A) = 2 dim A - t.As the main contribution of this work, we characterize all algebras of minimal rank over arbitrary fields. This finally solves an open problem in algebraic complexity theory; see, for instance, [V. Strassen, Handbook of Theoretical Computer Science, J. van Leeuwen, ed., Elsevier Science, New York, 1990, Vol. A, pp. 634--672, section 12, Problem 4] or [P. B\"{u}rgisser, M. Clausen, and M. A. Shokrollahi, Algebraic Complexity Theory, Springer, New York, 1997, Problem 17.5].},
journal = {SIAM J. Comput.},
month = feb,
pages = {277–298},
numpages = {22},
keywords = {associative algebras, bilinear complexity, Alder--Strassen bound, rank}
}

@article{10.1137/S0097539703434978,
author = {Kaibel, Volker and Mechtel, Rafael and Sharir, Micha and Ziegler, G\"{u}nter M.},
title = {The Simplex Algorithm in Dimension Three},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703434978},
doi = {10.1137/S0097539703434978},
abstract = {We investigate the worst-case behavior of the simplex algorithm on linear programs with three variables, that is, on 3-dimensional simple polytopes. Among the pivot rules that we consider, the "random edge" rule yields the best asymptotic behavior as well as the most complicated analysis. All other rules turn out to be much easier to study, but also produce worse results: Most of them show essentially worst-possible behavior; this includes both Kalai's "random-facet" rule, which without dimension restriction is known to be subexponential, and Zadeh's deterministic history-dependent rule, for which no nonpolynomial instances in  general dimensions have been found so far.},
journal = {SIAM J. Comput.},
month = feb,
pages = {475–497},
numpages = {23},
keywords = {linear programming, pivot rule, linearity coefficient, random edge}
}

@article{10.1137/S0097539703433146,
author = {Buresh-Oppenheim, Joshua and Beame, Paul and Pitassi, Toniann and Raz, Ran and Sabharwal, Ashish},
title = {Bounded-Depth Frege Lower Bounds for Weaker Pigeonhole Principles},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433146},
doi = {10.1137/S0097539703433146},
abstract = {We prove a quasi-polynomial lower bound on the size of bounded-depth Frege proofs of the pigeonhole principle $PHP^{m}_n$ where $m= (1+1/{polylog n})n$. This lower bound qualitatively matches the known quasi-polynomial-size bounded-depth Frege proofs for these principles. Our technique, which uses a switching lemma argument like other lower bounds for bounded-depth Frege proofs, is novel in that the tautology to which this switching lemma is applied remains random throughout the argument.},
journal = {SIAM J. Comput.},
month = feb,
pages = {261–276},
numpages = {16},
keywords = {propositional proof complexity, pigeonhole principle}
}

@article{10.1137/S0097539703430154,
author = {Doerr, Benjamin},
title = {Nonindependent Randomized Rounding and an Application to Digital Halftoning},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703430154},
doi = {10.1137/S0097539703430154},
abstract = {We investigate the problem of rounding a given [0,1]-valued matrix to a 0,1 matrix such that the rounding error with respect to $2 times 2$ boxes is small. Such roundings yield good solutions for the digital halftoning problem, as shown by Asano et al. [Proceedings of the 13th Annual ACM-SIAM Symposium on Discrete Algorithms, San Francisco, 2002, SIAM, Philadelphia, 2002, pp. 896--904]. We present a randomized algorithm computing roundings with expected error at most 0.5463 per box, improving the 0.75 nonconstructive bound of Asano et al. Our algorithm is the first to solve this problem fast enough for practical application, namely, in linear time.  Of broader interest might be our rounding scheme, which is a modification  of randomized rounding. Instead of independently rounding the variables, we impose a number of suitable dependencies. Thus, by equipping the rounding process with some of the problem information, we reduce the rounding error significantly compared to independent randomized rounding, which leads to an expected error of 0.82944 per box. Finally, we give a characterization of realizable dependencies.},
journal = {SIAM J. Comput.},
month = feb,
pages = {299–317},
numpages = {19},
keywords = {digital halftoning, discrepancy, randomized rounding}
}

@article{10.1137/S0097539703426805,
author = {Bhattacharjee, Rajat and Goel, Ashish and Lotker, Zvi},
title = {Instability of FIFO at Arbitrarily Low Rates in the Adversarial Queueing Model},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703426805},
doi = {10.1137/S0097539703426805},
abstract = {We study the stability of the commonly used packet forwarding protocol, FIFO (first in first out), in the adversarial queueing model. We prove that FIFO can become unstable, i.e., lead to unbounded buffer-occupancies and queueing delays, at arbitrarily low injection rates. In order to demonstrate instability at rate $r$, we use a network of size $tilde{O}(1/r)$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {318–332},
numpages = {15},
keywords = {stability, FIFO, adversarial queueing model}
}

@article{10.1137/S0097539702413197,
author = {Rao, Satish and Richa, Andr\'{e}a W.},
title = {New Approximation Techniques for Some Linear Ordering Problems},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702413197},
doi = {10.1137/S0097539702413197},
abstract = {We describe logarithmic approximation algorithms for the NP-hard graph optimization problems of minimum linear arrangement, minimum containing interval graph, and minimum storage--time product. This improves upon the best previous approximation bounds of Even, Naor, Rao, and Schieber [  J. ACM , 47 (2000), pp. 585--616] for these problems by a factor of $Omega$(log log  n ).  We use the lower bound provided by the volume  W  of a spreading metric for each of the ordering problems above (as defined by Even et al.) in order to find a solution with cost at most a  logarithmic factor times W  for these problems. We develop a divide-and-conquer strategy where the cost of a solution to a problem at a recursive level is $C$ plus the cost of a solution to the subproblems at this level,  and  where the spreading metric volume on the subproblems is less than the original volume by $Omega$(  C  log  n ), ensuring that the resulting solution has cost  O (log  n ) times the original spreading metric volume. We note that this is an existentially tight bound on the relationship between the spreading metric volume and the true optimal values for these problems. For planar graphs, we combine a structural theorem of Klein, Plotkin, and Rao [  Proceedings of the  25  th ACM Symposium on Theory of Computing , 1993, pp. 682--690] with our new recursion technique to show that the spreading metric cost volumes are within an  O (log log  n ) factor of the cost of an optimal solution for the minimum linear arrangement, and the minimum containing interval graph problems.},
journal = {SIAM J. Comput.},
month = feb,
pages = {388–404},
numpages = {17},
keywords = {storage--time product, interval graph completion, minimum linear arrangement, spreading metrics, approximation algorithms}
}

@article{10.1137/S0097539702409927,
author = {Gupta, Anupam and Kumar, Amit and Rastogi, Rajeev},
title = {Traveling with a Pez Dispenser (or, Routing Issues in MPLS)},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702409927},
doi = {10.1137/S0097539702409927},
abstract = {A new packet routing model proposed by the Internet Engineering Task Force is MultiProtocol Label Switching, or MPLS [B. Davie and Y. Rekhter, MPLS: Technology and Applications, Morgan Kaufmann (Elsevier), New York, 2000]. Instead of each router's parsing the packet network layer header and doing its lookups based on that analysis (as in much of conventional packet routing), MPLS ensures that the analysis of the header is performed just once. The packet is then assigned a stack of labels, where the labels are usually much smaller than the packet headers themselves. When a router receives a packet, it examines the label at the top of the label stack and makes the decision of where the packet is forwarded based solely on that label. It can pop the top label off the stack if it so desires, and can also push some new labels onto the stack, before forwarding the packet. This scheme has several advantages over conventional routing protocols, the two primary ones being (a) reduced amount of header analysis at intermediate routers, which allows for faster switching times, and (b) better traffic engineering capabilities and hence easier handling of quality of service issues. However, essentially nothing is known at a theoretical level about the performance one can achieve with this protocol, or about the intrinsic trade-offs in its use of resources.This paper initiates a theoretical study of MPLS protocols, and routing algorithms and lower bounds are given for a variety of situations. We first study the routing problem on the line, a case which is already nontrivial, and give routing protocols whose trade-offs are close to optimality. We then extend our results for paths to trees, and thence onto more general graphs. These routing algorithms on general graphs are obtained by finding a tree cover of a graph, i.e., a small family of subtrees of the graph such that, for each pair of vertices, one of the trees in the family contains an (almost-)shortest path between them. Our results show tree covers of logarithmic size for planar graphs and graphs with bounded separators, which may be of independent interest.},
journal = {SIAM J. Comput.},
month = feb,
pages = {453–474},
numpages = {22},
keywords = {tree covers, graph separators, network routing, analysis of algorithms, MPLS routing, distance labeling}
}

@article{10.1137/S0097539701395978,
author = {Calinescu, Gruia and Karloff, Howard and Rabani, Yuval},
title = {Approximation Algorithms for the 0-Extension Problem},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701395978},
doi = {10.1137/S0097539701395978},
abstract = {In the 0-extension problem, we are given a weighted graph with some nodes marked as terminals and a semimetric on the set of terminals. Our goal is to assign the rest of the nodes to terminals so as to minimize the sum, over all edges, of the product of the edge's weight and the distance between the terminals to which its endpoints are assigned. This problem generalizes the multiway cut problem of Dahlhaus et al. [SIAM J. Comput., 23 (1994), pp. 864--894] and is closely related to the metric labeling problem introduced by Kleinberg and Tardos [Proceedings of the 40th IEEE Annual Symposium on Foundations of Computer Science, New York, 1999, pp. 14--23].We present approximation algorithms for {sc 0-Extension}. In arbitrary graphs, we present a O(log k)-approximation algorithm, k being the number of terminals. We also give O(1)-approximation guarantees for weighted planar graphs. Our results are based on a natural metric relaxation of the problem previously considered by Karzanov [European J. Combin., 19 (1998), pp. 71--101]. It is similar in flavor to the linear programming relaxation of Garg, Vazirani, and Yannakakis [SIAM J. Comput., 25 (1996), pp. 235--251] for the multicut problem, and similar to relaxations for other graph partitioning problems. We prove that the integrality ratio of the metric relaxation is at least $c sqrt{lg k}$ for a positive c for infinitely many k. Our results improve some of the results of Kleinberg and Tardos, and they further our understanding on how to use metric relaxations.},
journal = {SIAM J. Comput.},
month = feb,
pages = {358–372},
numpages = {15},
keywords = {graph partitioning, metric space, approximation algorithm, linear programming relaxation}
}

@article{10.1137/S0097539701388884,
author = {Thorup, Mikkel},
title = {Quick <i>k</i>-Median, <i>k</i>-Center, and Facility Location for Sparse Graphs},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701388884},
doi = {10.1137/S0097539701388884},
abstract = {We present $tilde{O}(m)$ time and space constant factor approximation algorithms for the k-median, k-center, and facility location problems with assignment costs being shortest path distances in a weighted undirected graph with n vertices and m edges.  For all of these location problems, $tilde{O}(n^2)$ time and space algorithms were already known, but here we are addressing large sparse graphs. An application could be placement of content distributing servers on the Internet. The Internet is large and changes so frequently that an $tilde{O}(n^2)$ time solution would likely be outdated long before completion.},
journal = {SIAM J. Comput.},
month = feb,
pages = {405–432},
numpages = {28},
keywords = {efficient approximation algorithms, k-median, k-center, location problems, facility location, shortest paths}
}

@article{10.1137/S0097539701387544,
author = {Muthukrishnan, S. and Rajaraman, Rajmohan and Shaheen, Anthony and Gehrke, Johannes E.},
title = {Online Scheduling to Minimize Average Stretch},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701387544},
doi = {10.1137/S0097539701387544},
abstract = {We consider the classical problem of online job scheduling on uniprocessor and multiprocessor machines.  For a given job, we measure the quality of service provided by an algorithm by the stretch of the job, which is defined as the ratio of the amount of time that the job spends in the system to the processing time of the job.  For a given sequence of jobs, we measure the performance of an algorithm by the average stretch achieved by the algorithm over all the jobs in the sequence. The average stretch metric has been used to evaluate the performance of scheduling algorithms in many applications arising in databases, networks, and systems. The main contribution of this paper is to show that the shortest remaining processing time (SRPT) algorithm  is O(1)-competitive with respect to average stretch for both uniprocessors and multiprocessors.  For uniprocessors, we prove that SRPT is 2-competitive; we also establish an essentially matching lower bound on the competitive ratio of SRPT.  For multiprocessors, we show that the competitive ratio of SRPT is at most $9 + 2sqrt{6} le 14$. Furthermore, we establish constant-factor lower bounds on the competitive ratio of any online algorithm for both uniprocessors and multiprocessors.},
journal = {SIAM J. Comput.},
month = feb,
pages = {433–452},
numpages = {20},
keywords = {shortest remaining processing time (SRPT), slowdown, stretch, online algorithms, competitive ratio, scheduling}
}

@article{10.1137/S0097539703435522,
author = {\`{A}lvarez, Carme and Blesa, Maria and Serna, Maria},
title = {A Characterization of Universal Stability in the Adversarial Queuing Model},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703435522},
doi = {10.1137/S0097539703435522},
abstract = {We study universal stability of directed and undirected graphs in the adversarial queuing model for static packet routing. In this setting, packets are injected in some edge and have to traverse a predefined path before leaving the system.  Restrictions on the allowed packet trajectory provide a way to analyze stability under different packet trajectories. We consider five packet trajectories, two for directed graphs and three for undirected graphs, and provide polynomial time algorithms for testing universal stability  when considering each of them. In each case we obtain a different characterization of the universal stability property in terms of a set of forbidden subgraphs. Thus we show that variations of the allowed packet trajectory lead to nonequivalent characterizations. Using those characterizations we are also able to provide polynomial time algorithms for testing stability under the NTGLIS (Nearest To Go-Longest In System) protocol.},
journal = {SIAM J. Comput.},
month = jan,
pages = {41–66},
numpages = {26},
keywords = {network stability, interconnection networks, greedy scheduling protocols, graph algorithms, adversarial queueing theory}
}

@article{10.1137/S0097539703433912,
author = {Katz, Michal and Katz, Nir A. and Korman, Amos and Peleg, David},
title = {Labeling Schemes for Flow and Connectivity},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433912},
doi = {10.1137/S0097539703433912},
abstract = {This paper studies labeling schemes for flow and connectivity functions. A flow labeling scheme using $O(log ncdotlog {hat{omega}}+log^2 n)$-bit labels is presented for general n-vertex graphs with maximum (integral) capacity ${hat{omega}}$. This is shown to be asymptotically optimal. For edge-connectivity, this yields a tight bound of $Theta(log^2 n)$ bits. A k-vertex connectivity labeling scheme is then given for general n-vertex graphs using at most 3 log n bits for k = 2, 5 log n bits for k = 3, and 2 k log n bits for k &gt; 3. Finally, a lower bound of $Omega (klog n)$ is established for k -vertex connectivity on n-vertex graphs, where k is polylogarithmic in n.},
journal = {SIAM J. Comput.},
month = jan,
pages = {23–40},
numpages = {18},
keywords = {graphs, edge-connectivity, distributed data structures, vertex-connectivity, labeling schemes, flow}
}

@article{10.1137/S0097539703433511,
author = {Micciancio, Daniele},
title = {Almost Perfect Lattices, the Covering Radius Problem, and Applications to Ajtai's Connection Factor},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433511},
doi = {10.1137/S0097539703433511},
abstract = {Lattices have received considerable attention as a potential source of computational hardness to be used in cryptography, after a breakthrough result of Ajtai [in Proceedings of the 28th Annual ACM Symposium on Theory of Computing, Philadelphia, PA, 1996, pp. 99--108] connecting the average-case and worst-case complexity of various lattice problems. The purpose of this paper is twofold. On the expository side, we present a rigorous self-contained proof of results along the lines of Ajtai's seminal work. At the same time, we explore to what extent Ajtai's original results can be quantitatively improved. As a by-product, we define a random class of lattices such that computing short nonzero vectors in the class with nonnegligible probability is at least as hard as approximating the length of the shortest nonzero vector in any n-dimensional lattice within worst-case approximation factors $gamma(n) = n^{3} omega(sqrt{log nloglog n})$. This improves previously known best connection factor $gamma(n) = n^{4+epsilon}$ [J.-Y. Cai and A. P. Nerurkar, in Proceedings of the 38th Annual IEEE Symposium on Foundations of Computer Science, Miami Beach, FL, 1997, pp. 468--477]. We also show how our reduction implies the existence of collision resistant cryptographic hash functions based on the worst-case inapproximability of the shortest vector problem within the same factors $gamma(n) = n^{3} omega(sqrt{log nloglog n})$.In the process we distill various new lattice problems that might be of independent interest, related to the covering radius, the bounded distance decoding problem, approximate counting of lattice points inside convex bodies, and the efficient construction of lattices with good geometric and algorithmic decoding properties. We also show how further investigation of these new lattice problems might lead to even stronger connections between the average-case and worst-case complexity of the shortest vector problem, possibly leading to connection factors as low as $gamma(n) = n^{1.5} omega(log n)$.},
journal = {SIAM J. Comput.},
month = jan,
pages = {118–169},
numpages = {52},
keywords = {hash functions, point lattices, covering radius, average-case complexity, cryptography, shortest vector problem, closest vector problem with preprocessing, almost perfect lattices}
}

@article{10.1137/S0097539703433122,
author = {Bartal, Yair and Mendel, Manor},
title = {Multiembedding of Metric Spaces},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433122},
doi = {10.1137/S0097539703433122},
abstract = {Metric embedding has become a common technique in the design of algorithms. Its applicability is often dependent on how large the embedding's distortion is. For example, embedding finite metric space into trees may require linear distortion as a function of the size of the metric. Using probabilistic metric embeddings, the bound on the distortion reduces to logarithmic in the size of the metric. We make a step in the direction of bypassing the lower bound on the distortion in terms of the size of the metric. We define "multiembeddings" of metric spaces, in which a point is mapped onto a set of points, while keeping the target metric of polynomial size and preserving the distortion of paths. The distortion obtained with such multiembeddings into ultrametrics is at most $O(log Deltaloglog Delta)$, where $Delta$ is the  aspect ratio  of the metric. In particular, for expander graphs, we are able to obtain  constant  distortion embeddings into trees, in contrast with the $Omega(log n)$ lower bound for all previous notions of embeddings.We demonstrate the algorithmic application of the new embeddings for two optimization problems:  group Steiner tree  and  metrical task systems .},
journal = {SIAM J. Comput.},
month = jan,
pages = {248–259},
numpages = {12},
keywords = {metric embeddings, metrical task systems, group Steiner tree}
}

@article{10.1137/S0097539703426799,
author = {Hougardy, Stefan and Wagler, Annegret},
title = {Perfectness is an Elusive Graph Property},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703426799},
doi = {10.1137/S0097539703426799},
abstract = {A graph property is called elusive (or evasive) if every algorithm for testing this property has to read in the worst case $nchoose 2$ entries of the adjacency matrix of the given graph. Several graph properties have been shown to be elusive, e.g., planarity or k-colorability. A famous conjecture of Karp says that every nontrivial monotone graph property is elusive. We prove that a nonmonotone but hereditary graph property is elusive: perfectness.},
journal = {SIAM J. Comput.},
month = jan,
pages = {109–117},
numpages = {9},
keywords = {elusiveness, perfect graph, graph property testing, evasiveness}
}

@article{10.1137/S0097539703426416,
author = {Hitchcock, John M.},
title = {Small Spans in Scaled Dimension},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703426416},
doi = {10.1137/S0097539703426416},
abstract = {Juedes and Lutz [  SIAM J. Comput. , 24 (1995), pp. 279--295] proved a  small span theorem  for polynomial-time many-one reductions in exponential time. This result says that for language  A  decidable in exponential time, either the class of languages reducible to  A  (the lower span) or the class of problems to which  A  can be reduced (the upper span) is small in the sense of resource-bounded measure and, in particular, that the degree of  A  is small. Small span theorems have been proved for increasingly stronger polynomial-time reductions, and a small span theorem for polynomial-time Turing reductions would imply $BPP not= EXP$. In contrast to the progress in resource-bounded measure, Ambos-Spies et al. [{  Proceedings of the  16  th IEEE Conference on Computational Complexity , Philadelphia, PA, IEEE Computer Society, Los Alamitos, CA, 2001, pp. 210--217] showed that there is no small span theorem for the resource-bounded dimension of Lutz [  SIAM J. Comput .}, 32 (2003), pp. 1236--1259], even for polynomial-time many-one reductions. Resource-bounded scaled dimension, recently introduced by Hitchcock, Lutz, and Mayordomo [  J. Comput. System Sci. , 69 (2004), pp. 97--122], provides rescalings of resource-bounded dimension. We use scaled dimension to further understand the contrast between measure and dimension regarding polynomial-time spans and degrees. We strengthen prior results by showing that the small span theorem holds for polynomial-time many-one reductions in the -3rd-order scaled dimension, but fails to hold in the -2nd-order scaled dimension. Our results also hold in exponential space.As an application, we show that determining the -2nd- or -1st-order scaled dimension in $ESPACE$ of the many-one complete languages for $E$ would yield a proof of $mathrm{P} = BPP$ or $mathrm{P} not= PSPACE$. On the other hand, it is shown unconditionally that the complete languages for $E$ have $-$3rd-order scaled dimension 0 in $ESPACE$ and $-$2nd- and $-$1st-order scaled dimension 1 in $E$.},
journal = {SIAM J. Comput.},
month = jan,
pages = {170–194},
numpages = {25},
keywords = {resource-bounded dimension, polynomial-time degrees, small span theorems}
}

@article{10.1137/S0097539702412143,
author = {Cohen, Edith and Kaplan, Haim},
title = {Balanced-Replication Algorithms for Distribution Trees},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702412143},
doi = {10.1137/S0097539702412143},
abstract = {In many Internet applications, requests for a certain object are routed bottom-up  over a tree where the root of the tree is the node containing the object. When an object becomes popular, the root node of the tree may become a hot-spot. Therefore, many applications allow intermediate nodes to acquire the ability to serve the requests, for example, by caching the object. We call such distinguished nodes primed. We propose and analyze different algorithms where nodes decide when to become primed; these algorithms balance the maximum load on a node and the number of primed nodes. Many applications require both fully distributed decisions and smooth convergence to a stable set of primed nodes. We first present optimal algorithms which require communication across the tree.   We then consider the natural previously proposed {sc threshold} algorithm, where a node becomes primed when the incoming flow of requests exceeds a threshold.  We show examples where {sc threshold} exhibits undesirable behavior during convergence.  Finally, we  propose another fully distributed algorithm, {sc gap}, which converges gracefully.},
journal = {SIAM J. Comput.},
month = jan,
pages = {227–247},
numpages = {21},
keywords = {distributed algorithms, cache, replication, networks, algorithms, peer-to-peer}
}

@article{10.1137/S0097539702411915,
author = {Morris, Ben and Sinclair, Alistair},
title = {Random Walks on Truncated Cubes and Sampling 0-1 Knapsack Solutions},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702411915},
doi = {10.1137/S0097539702411915},
abstract = {We solve an open problem concerning the mixing time of symmetric random walk on the n-dimensional cube truncated by a hyperplane, showing that it is polynomial in n.  As a consequence, we obtain a fully polynomial randomized approximation scheme for counting the feasible solutions of a 0-1 knapsack problem. The results extend to the case of any fixed number of hyperplanes. The key ingredient in our analysis is a combinatorial construction we call a "balanced almost uniform permutation," which is of independent interest.},
journal = {SIAM J. Comput.},
month = jan,
pages = {195–226},
numpages = {32},
keywords = {knapsack problem, balanced permutations, random sampling, random permutations, random walks, hypercubes, Markov chains}
}

@article{10.1137/S0097539702405619,
author = {Akcoglu, Karhan and Drineas, Petros and Kao, Ming-Yang},
title = {Fast Universalization of Investment Strategies},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702405619},
doi = {10.1137/S0097539702405619},
abstract = {A universalization of a parameterized investment strategy is an online algorithm whose average daily performance approaches that of the strategy operating with the optimal parameters determined offline in hindsight. We present a general framework for universalizing investment strategies and discuss conditions under which investment strategies are universalizable. We present examples of common investment strategies that fit into our framework. The examples include both trading strategies that decide positions in individual stocks, and portfolio strategies that allocate wealth among multiple stocks. This work extends in a natural way Cover's universal portfolio work. We also discuss the runtime efficiency of universalization algorithms. While a straightforward implementation of our algorithms runs in time exponential in the number of parameters, we show that the efficient universal portfolio computation technique of Kalai and Vempala [Proceedings of the 41st Annual IEEE Symposium on Foundations of Computer Science, Redondo Beach, CA, 2000, pp. 486--491] involving the sampling of log-concave functions can be generalized to other classes of investment strategies, thus yielding provably good approximation algorithms in our framework.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1–22},
numpages = {22},
keywords = {constantly rebalanced portfolios, portfolio strategies, portfolio optimization, trading strategies, computational finance, universal portfolios, investment strategies}
}

@article{10.1137/S0097539701389944,
author = {Alekhnovich, Michael and Ben-Sasson, Eli and Razborov, Alexander A. and Wigderson, Avi},
title = {Pseudorandom Generators in  Propositional Proof Complexity},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701389944},
doi = {10.1137/S0097539701389944},
abstract = {We call a pseudorandom generator $G_n:{0,1}^nto {0,1}^m$ hard for a propositional proof system P if P cannot efficiently prove the (properly encoded) statement $G_n(x_1,ldots,x_n)neq b$ for any string $bin{0,1}^m$. We consider a variety of "combinatorial" pseudorandom generators inspired by the Nisan--Wigderson generator on the one hand, and by the construction of Tseitin tautologies on the other. We prove that under certain circumstances these generators are hard for such proof systems as resolution, polynomial calculus, and polynomial calculus with resolution (PCR).},
journal = {SIAM J. Comput.},
month = jan,
pages = {67–88},
numpages = {22},
keywords = {resolution, polynomial calculus, propositional proof complexity, generator}
}

@article{10.1137/S0097539701388355,
author = {Ivansson, Lars and Lagergren, Jens},
title = {Algorithms for RH Mapping: New Ideas and Improved Analysis},
year = {2005},
issue_date = {2005},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {34},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701388355},
doi = {10.1137/S0097539701388355},
abstract = {Radiation hybrid (RH) mapping is a technique for constructing a physical map describing the locations of n markers on a chromosome of an organism. In [J. Comput. Biol., 4 (1997), pp. 517--533], Ben-Dor and Chor presented new algorithms for the RH problem and gave the first performance guarantees for such algorithms. We improve the lower bounds on the number of experiments in a way that is sufficient for two of these algorithms to give a correct ordering of the markers with high probability. Not only are the new bounds tighter, but our analysis also captures to a much higher extent how the bounds depend on the actual arrangement of the markers. Furthermore, we modify the two algorithms to utilize RH mapping data produced with several radiation intensities. We show that the new algorithms are almost insensitive to the problem of using the correct intensity.},
journal = {SIAM J. Comput.},
month = jan,
pages = {89–108},
numpages = {20},
keywords = {algorithms, multiple intensities, RH mapping, performance bounds}
}

@article{10.1137/S0097539799354308,
author = {Piotr\'{o}w, Marek},
title = {Depth Optimal Sorting Networks Resistant to <i>k</i> Passive Faults},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799354308},
doi = {10.1137/S0097539799354308},
abstract = {We study the problem of constructing a sorting network that is tolerant to faults and whose running time (i.e., depth) is as small as possible. We consider the scenario of worst-case comparator faults and follow the model of  passive  comparator failure proposed by Yao and Yao  SIAM J. Comput ., 14 (1985), pp. 120--128], in which a faulty comparator outputs its inputs directly without comparison. Our main result is the first construction of an  N -input  k -fault-tolerant sorting network with an asymptotically optimal depth $theta$(log  N  +  k ). That improves over the result of Leighton and Ma [  Proceedings of the  5th Annual ACM Symposium on Parallel Algorithms and Architectures, Velen, Germany, 1993, ACM, New York, pp. 30--41], whose network is of depth  O (log  N  +  k logfrac{log  N }{log  k })$. Actually, we present a fault-tolerant correction network that can be added after any  N -input sorting network to correct its output in the presence of at most  k  faulty comparators. Since the depth of the network is  O (log  N  +  k ) and the constants hidden behind the "  O " notation are small, the construction can be of practical use.Developing the techniques necessary to show the main result, we construct a fault-tolerant network for the insertion problem. As a by-product, we get an  N -input  O (log  N )-depth INSERT-network that is tolerant to random faults, thereby answering a question posed by Ma in his Ph. D. thesis [  Fault-Tolerant Sorting Network , Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA, 1994].The results are based on a new notion of constant delay comparator networks, that is, networks in which each register is used (compared) only in a period of time of a constant length. Copies of such networks can be pipelined with only a constant increase in the total depth per copy.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1484–1512},
numpages = {29},
keywords = {sorting networks, fault-tolerant sorting, comparators}
}

@article{10.1137/S009753979731501X,
author = {Schwiegelshohn, Uwe},
title = {Preemptive Weighted Completion Time Scheduling of Parallel Jobs},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979731501X},
doi = {10.1137/S009753979731501X},
abstract = {We present a new algorithm for the preemptive offline scheduling of independent jobs on a system consisting of m identical machines. The jobs can be parallel; that is, they may need the concurrent availability of several machines for their execution. To this end, we introduce a machine model which is based on existing multiprocessors and accounts for the penalty of preemption.  After examining the relation between makespan and total weighted completion time costs for the scheduling of parallel jobs, we show that our new algorithm achieves an approximation factor of 2.37 for total weighted completion time scheduling if no preemption penalty is considered. This compares favorably to the thus far best approximation factor of 8.53 for the nonpreemptive case. To fine-tune the algorithm with respect to different preemption penalties, we use a fairly simple numerical optimization problem. Further, we present an algorithm to transform the preemptive schedule into a nonpreemptive one. This leads to an improved approximation factor of 7.11 for the nonpreemptive weighted completion time scheduling.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1280–1308},
numpages = {29},
keywords = {approximation algorithms, scheduling}
}

@article{10.1137/S0097539703436424,
author = {Kaufman, Tali and Krivelevich, Michael and Ron, Dana},
title = {Tight Bounds for Testing Bipartiteness in General Graphs},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436424},
doi = {10.1137/S0097539703436424},
abstract = {In this paper we consider the problem of testing bipartiteness of general graphs.  The problem has previously been studied in two models, one most suitable for dense graphs and one most suitable for bounded-degree graphs. Roughly speaking, dense graphs can be tested for bipartiteness with constant complexity, while the complexity of testing bounded-degree graphs is $tilde{Theta}(sqrt{n})$, where $n$ is the number of vertices in the graph (and $tilde{Theta}(f(n))$ means $Theta(f(n)cdot{rm polylog}(f(n)))$). Thus there is a large gap between the complexity of testing in the two cases.In this work we bridge the gap described above. In particular, we study the problem of testing bipartiteness in a model that is suitable for all densities. We present an algorithm whose complexity is $tilde{O}(min(sqrt{n},n^2/m))$, where $m$ is the number of edges in the graph, and we match it with an almost tight lower bound.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1441–1483},
numpages = {43},
keywords = {randomized algorithms, property testing, bipartiteness}
}

@article{10.1137/S0097539703431391,
author = {Feige, Uriel and Langberg, Michael and Schechtman, Gideon},
title = {Graphs with Tiny Vector Chromatic Numbers   and Huge Chromatic Numbers},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703431391},
doi = {10.1137/S0097539703431391},
abstract = {Karger, Motwani, and Sudan [ J. ACM, 45 (1998), pp. 246--265] introduced the notion of a vector coloring of a graph. In particular, they showed that every $k$-colorable graph is also vector k-colorable, and that for constant k, graphs that are vector k-colorable can be colored by roughly $Delta{1 - 2k}$ colors. Here $Delta$ is the maximum degree in the graph and is assumed to be of the order of $n{delta}$ for some $0 &lt; delta &lt; 1$. Their results play a major role in the best approximation algorithms used for coloring and for maximum independent sets. We show that for every positive integer k there are graphs that are vector k-colorable but do not have independent sets significantly larger than $nDelta{1 - 2k}$ (and hence cannot be colored with significantly fewer than $Delta{1 - 2k}$ colors). For $k = O(log nloglog n)$ we show vector k-colorable graphs that do not have independent sets of size (log n)c, for some constant c. This shows that the vector chromatic number does not approximate the chromatic number within factors better than npolylog n. As part of our proof, we analyze property testing algorithms that distinguish between graphs that have an independent set of size nk, and graphs that are far from having such an independent set. Our bounds on the sample size improve previous bounds of Goldreich, Goldwasser, and Ron [J. ACM, 45 (1998), pp. 653--750] for this problem.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1338–1368},
numpages = {31},
keywords = {semidefinite programming, chromatic number, approximation algorithms, independent set, property testing}
}

@article{10.1137/S0097539703427550,
author = {Hemaspaandra, Lane A. and Hempel, Harald and Nickelsen, Arfst},
title = {Algebraic Properties for Selector Functions},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703427550},
doi = {10.1137/S0097539703427550},
abstract = {The  nondeterministic  advice complexity of the P-selective sets is known to be exactly linear. Regarding the  deterministic  advice complexity of the P-selective sets---i.e., the amount of Karp--Lipton advice needed for polynomial-time machines to recognize them in general---the best current upper bound is quadratic [K. Ko,  J. Comput. System Sci. , 26 (1983), pp. 209--221] and the best current lower bound is linear [L. Hemaspaandra and L. Torenvliet,  Theoret. Comput. Sci. , 154 (1996), pp. 367--377]. We prove that every associatively P-selective set is commutatively, associatively P-selective. Using this, we establish an algebraic sufficient condition for the P-selective sets to have a linear upper bound (which thus would match the existing lower bound) on their deterministic advice complexity: If all P-selective sets are associatively P-selective, then the deterministic advice complexity of the P-selective sets is linear. The weakest previously known sufficient condition was P = NP.We also establish related results for algebraic properties of, and advice complexity of, the nondeterministically selective sets.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1309–1337},
numpages = {29},
keywords = {digraphs, printability, tournaments, selector functions, associativity, NP-selectivity, computational complexity theory, semifeasible computation, immunity, algebraic properties, advice complexity, nonuniform complexity, commutativity, P-selectivity, nondeterministic selectivity}
}

@article{10.1137/S0097539703425848,
author = {Glasser, Christian and Selman, Alan L. and Sengupta, Samik and Zhang, Liyu},
title = {Disjoint NP-Pairs},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703425848},
doi = {10.1137/S0097539703425848},
abstract = {We study the question of whether the class DisjNP of disjoint pairs (A, B) of NP-sets contains a complete pair. The question relates to the question of whether optimal proof systems exist, and we relate it to the previously studied question of whether there exists a disjoint pair of NP-sets that is NP-hard. We show under reasonable hypotheses that nonsymmetric disjoint NP-pairs exist, which provides additional evidence for the existence of P-inseparable disjoint NP-pairs.    We construct an oracle relative to which  the class of disjoint NP-pairs does not have a complete pair; an oracle relative to which optimal proof systems exist, and hence complete pairs exist, but no pair is NP-hard; and an oracle relative to which complete pairs exist, but optimal proof systems do not exist.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1369–1416},
numpages = {48},
keywords = {propositional proof systems, symmetry, oracles, promise problems, disjoint NP-pairs}
}

@article{10.1137/S0097539702418498,
author = {Charikar, Moses and Chekuri, Chandra and Feder, Tomas and Motwani, Rajeev},
title = {Incremental Clustering and  Dynamic Information Retrieval},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702418498},
doi = {10.1137/S0097539702418498},
abstract = {Motivated by applications such as document and image classification in information retrieval, we consider the problem of clustering dynamic point sets in a metric space.  We propose a model called incremental clustering which is based on a careful analysis of the requirements of the information retrieval application, and which should also be useful in other applications.  The goal is to efficiently maintain clusters of small diameter as new points are inserted.  We analyze several natural greedy algorithms and demonstrate that they perform poorly.  We propose new deterministic and randomized incremental clustering algorithms which have a provably good performance, and which we believe should also perform well in practice. We complement our positive results with lower bounds on the performance of incremental algorithms. Finally, we consider the dual clustering problem where the clusters are of fixed diameter, and the goal is to minimize the number of clusters.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1417–1440},
numpages = {24},
keywords = {k-center, dynamic information retrieval, performance guarantee, agglomerative clustering, minimum diameter clustering, incremental clustering}
}

@article{10.1137/S009753970139207X,
author = {McKenzie, Pierre},
title = {Arithmetic Circuits and Polynomial Replacement Systems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970139207X},
doi = {10.1137/S009753970139207X},
abstract = {This paper addresses the problems of counting proof-trees (as introduced by Venkateswaran and Tompa) and counting proof-circuits, a related but seemingly more natural question.  These problems lead to a common generalization of straight-line programs which we call polynomial replacement systems {PRSs}.  We contribute a classification of these systems and we investigate their complexity.  Diverse problems falling within the scope of this study include, for example, counting proof-circuits and evaluating ${cup,+}$-circuits over the natural numbers.  A number of complexity results are obtained, including a proof that counting proof-circuits is $numP$-complete.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1513–1531},
numpages = {19},
keywords = {computational complexity, arithmetic circuit, counting classes}
}

@article{10.1137/S0097539700379383,
author = {Bartal, Yair and Byers, John W. and Raz, Danny},
title = {Fast, Distributed Approximation Algorithms for Positive Linear Programming with Applications to Flow Control},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700379383},
doi = {10.1137/S0097539700379383},
abstract = {We study combinatorial optimization problems in which a set of distributed agents must achieve a global objective using only local information. Papadimitriou and Yannakakis [Proceedings of the 25th ACM Symposium on Theory of Computing, 1993, pp. 121--129] initiated the study of such problems in a framework where distributed decision-makers must generate feasible solutions to positive linear programs with information only about local constraints. We extend their model by allowing these distributed decision-makers to perform local communication to acquire information over time and then explore the tradeoff between the amount of communication and the quality of the solution to the linear program that the decision-makers can obtain.Our main result is a distributed algorithm that obtains a $(1 + epsilon)$ approximation to the optimal linear programming solution while using only a polylogarithmic number of rounds of local communication. This algorithm offers a significant improvement over the logarithmic approximation ratio previously obtained by Awerbuch and Azar [Proceedings of the 35th Annual IEEE Symposium on  Foundations of Computer Science, 1994, pp. 240--249] for this problem while providing a comparable running time. Our results apply directly to the application of network flow control, an application in which distributed routers must quickly choose how to allocate bandwidth to connections using only local information to achieve global objectives. The sequential version of our algorithm is faster and considerably simpler than the best known approximation algorithms capable of achieving a $(1 + epsilon)$ approximation ratio for positive linear programming.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1261–1279},
numpages = {19},
keywords = {primal-dual, linear programming, flow control, approximation algorithm}
}

@article{10.1137/S0097539798337224,
author = {Havlicek, John},
title = {A Note on the Homotopy Type of Wait-Free  Atomic Snapshot Protocol Complexes},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798337224},
doi = {10.1137/S0097539798337224},
abstract = {In the atomic snapshot system model, the processes of an asynchronous distributed system communicate by atomic write and atomic snapshot read operations on a shared memory consisting of single-writer multiple-reader registers.  The processes may fail by crashing. It is shown that in this model, a wait-free full-information protocol complex is homotopy equivalent to the underlying input complex. A span in the sense of Herlihy and Shavit provides the homotopy equivalence.  It follows that the protocol and input complexes are indistinguishable by ordinary homology or homotopy groups.},
journal = {SIAM J. Comput.},
month = may,
pages = {1215–1222},
numpages = {8},
keywords = {simplicial complex, topology, homotopy, wait-free protocol, distributed computing, atomic snapshot}
}

@article{10.1137/S0097539704412910,
author = {Servedio, Rocco A. and Gortler, Steven J.},
title = {Equivalences and Separations Between Quantum and Classical Learnability},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539704412910},
doi = {10.1137/S0097539704412910},
abstract = {We consider quantum versions of two well-studied models of learning Boolean functions: Angluin's model of exact learning from membership queries and Valiant's probably approximately correct (PAC) model of learning from random examples. For each of these two learning models we establish a polynomial relationship between the number of quantum or classical queries required for learning. These results contrast known results that show that testing black-box functions for various properties, as opposed to learning, can require exponentially more classical queries than quantum queries. We also show that, under a widely held computational hardness assumption (the intractability of factoring Blum integers), there is a class of Boolean functions which is polynomial-time learnable in the quantum version but not the classical version of each learning model.  For the model of exact learning from membership queries, we establish a stronger separation by showing that if any one-way function exists, then there is a class of functions which is polynomial-time learnable in the quantum setting but not in the classical setting. Thus, while quantum and classical learning are equally powerful from an information theory perspective, the models are different when viewed from a computational complexity perspective.},
journal = {SIAM J. Comput.},
month = may,
pages = {1067–1092},
numpages = {26},
keywords = {quantum computation, PAC learning, query complexity, computational learning theory}
}

@article{10.1137/S0097539703436473,
author = {Chen, Guantao and Xu, Jun and Yu, Xingxing},
title = {Circumference of Graphs with Bounded Degree},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703436473},
doi = {10.1137/S0097539703436473},
abstract = {Karger, Motwani, and Ramkumar Algorithmica, 18 (1997), pp. 82--98] have shown that there is no constant approximation algorithm to find a longest cycle in a Hamiltonian graph, and they conjectured that this is the case even for graphs with bounded degree. On the other hand, Feder, Motwani, and Subi [ SIAM J. Comput., 31 (2002), pp. 1596--1607] have shown that there is a polynomial time algorithm for finding a cycle of length $n^{log_32}$ in a 3-connected cubic n-vertex graph. In this paper, we show that if G is a 3-connected n-vertex graph with maximum degree at most d, then one can find, in O( n 3) time, a cycle in G of length at least $Omega(n^{log_b2})$, where $b=2(d-1)^2+1$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1136–1170},
numpages = {35},
keywords = {circumference, 3-connected components, long cycles and paths, bounded degree}
}

@article{10.1137/S009753970343395X,
author = {D\'{o}sa, Gy\"{o}rgy and He, Yong},
title = {Better Online Algorithms for Scheduling with Machine Cost},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970343395X},
doi = {10.1137/S009753970343395X},
abstract = {For most scheduling problems the set of machines is fixed initially and remains unchanged for the duration of the problem. Recently Imreh and Noga proposed adding the concept of machine cost to scheduling problems and considered the so-called list model problem. For this problem, we are given a sequence of independent jobs with positive sizes, which must be processed nonpreemptively on a machine. No machines are initially provided, and when a job is revealed the algorithm has the option to purchase new machines. The objective is to minimize the sum of the makespan and cost of machines. In this paper, we first present an online algorithm with a competitive ratio at most 1.5798, which improves the known upper bound 1.618. Then for a special case where every job size is no greater than the machine cost, we present an optimal online algorithm with a competitive ratio 4/3. Last, we present an algorithm with a competitive ratio at most 3/2 for the semionline problem with known largest size, which improves the known upper bound 1.5309.},
journal = {SIAM J. Comput.},
month = may,
pages = {1035–1051},
numpages = {17},
keywords = {machine cost, competitive analysis, parallel machine scheduling, online algorithm}
}

@article{10.1137/S0097539703432165,
author = {Tonder, Andr\'{e} van},
title = {A Lambda Calculus for Quantum Computation},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703432165},
doi = {10.1137/S0097539703432165},
abstract = {The classical lambda calculus may be regarded both as a programming language and as a formal algebraic system for reasoning about computation. It provides a computational model equivalent to the Turing machine and continues to be  of enormous benefit in the classical theory of computation. We propose that quantum computation, like its classical counterpart, may benefit from a version of the lambda calculus suitable for expressing and reasoning about quantum algorithms. In this paper we develop a quantum lambda calculus as an alternative model of quantum computation, which combines some of the benefits of both the quantum Turing machine and the quantum circuit models. The calculus turns out to be closely related to the linear lambda calculi used in the study of linear logic.  We set up a computational model and an equational proof system for this calculus, and we argue that it is equivalent to the quantum Turing machine.},
journal = {SIAM J. Comput.},
month = may,
pages = {1109–1135},
numpages = {27},
keywords = {models of computation, lambda calculus, quantum computation, linear logic}
}

@article{10.1137/S0097539703431007,
author = {Orlin, James B. and Punnen, Abraham P. and Schulz, Andreas S.},
title = {Approximate Local Search in Combinatorial Optimization},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703431007},
doi = {10.1137/S0097539703431007},
abstract = {Local search algorithms for combinatorial optimization problems are generally of pseudopolynomial running time, and polynomial-time algorithms are  not often known for finding locally optimal solutions for NP-hard optimization problems. We introduce the concept of $varepsilon$-local optimality and show that, for every $varepsilon &gt; 0$, an $varepsilon$-local optimum can be identified in time polynomial in the problem size and $1/varepsilon$ whenever the corresponding neighborhood can be searched in polynomial time.  If the neighborhood can be searched in polynomial time for a $delta$-local optimum, a variation of our main algorithm produces a $(delta + varepsilon)$-local optimum in time polynomial in the problem size and $1/varepsilon$. As a consequence, a combinatorial optimization problem has a fully polynomial-time approximation scheme if and only if the problem of determining a better neighbor in an exact neighborhood has a fully polynomial-time approximation scheme.},
journal = {SIAM J. Comput.},
month = may,
pages = {1201–1214},
numpages = {14},
keywords = {approximation algorithms, 0/1-integer programming, computational complexity, combinatorial optimization, neighborhood search, local search}
}

@article{10.1137/S0097539703428555,
author = {Segerlind, Nathan and Buss, Sam and Impagliazzo, Russell},
title = {A Switching Lemma for Small Restrictions and Lower Bounds for <i>k</i>-DNF Resolution},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703428555},
doi = {10.1137/S0097539703428555},
abstract = {We prove a new switching lemma that works for restrictions that set only a small fraction of the variables and is applicable to formulas in disjunctive normal form (DNFs) with small terms. We use this to prove lower bounds for the Res( k) propositional proof system, an extension of resolution which works with k-DNFs instead of clauses. We also obtain an exponential separation between depth d circuits of bottom fan-in k and depth d circuits of bottom fan-in k + 1. Our results for Res(k) are as follows: The 2 n to n weak pigeonhole principle requires exponential size to refute in Res( k ) for $k leq sqrt{log n / log log n } $. For each constant k , there exists a constant w &gt; k so that random w -CNFs require exponential size to refute in Res( k ). For each constant k , there are sets of clauses which have polynomial size Res( k + 1) refutations but which require exponential size Res( k ) refutations.},
journal = {SIAM J. Comput.},
month = may,
pages = {1171–1200},
numpages = {30},
keywords = {Res(k), k-DNFs, switching lemmas, resolution, random restriction, Sipser functions, weak pigeonhole principles, Boolean circuit complexity, propositional proof complexity, random CNFs, circuit bottom fan-in, lower bounds}
}

@article{10.1137/S009753970241096X,
author = {Tor\'{a}n, Jacobo},
title = {On the Hardness of Graph Isomorphism},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970241096X},
doi = {10.1137/S009753970241096X},
abstract = {We show that the graph isomorphism problem is hard under DLOGTIME uniform AC{$^0$} many-one reductions for the complexity classes NL, PL (probabilistic logarithmic space) for every logarithmic space modular class {Mod}$_k$L and for the class DET of problems NC{$^1$} reducible to the determinant. These are the strongest known hardness results for the graph isomorphism problem and imply a randomized logarithmic space reduction from the perfect matching problem to graph isomorphism. We also investigate hardness results for the graph automorphism problem.},
journal = {SIAM J. Comput.},
month = may,
pages = {1093–1108},
numpages = {16},
keywords = {reducibility, complexity, graph isomorphism}
}

@article{10.1137/S0097539701390859,
author = {Biskup, Joachim and Paredaens, Jan and Schwentick, Thomas and Van den Bussche, Jan},
title = {Solving Equations in the Relational Algebra},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701390859},
doi = {10.1137/S0097539701390859},
abstract = {Enumerating all solutions of a relational algebra equation is a natural and powerful operation which, when added as a query language primitive to the nested relational algebra, yields a query language for nested relational databases, equivalent to the well-known powerset algebra.  We study sparse equations, which are equations with at most polynomially many solutions.  We look at their complexity and compare their expressive power with that of similar notions in the powerset algebra.},
journal = {SIAM J. Comput.},
month = may,
pages = {1052–1066},
numpages = {15},
keywords = {relational algebra, equation, parity, sparse expression, Fagin's theorem, nested relation}
}

@article{10.1137/S0097539701389245,
author = {Bar-Noy, Amotz and Ladner, Richard E.},
title = {Efficient Algorithms for Optimal Stream Merging for Media-on-Demand},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701389245},
doi = {10.1137/S0097539701389245},
abstract = {We address the problem of designing optimal off-line algorithms that minimize the required bandwidth for media-on-demand systems that use stream merging. We concentrate on the case where clients can receive two media streams simultaneously and can buffer up to half of a full stream. We construct an O(nm) optimal algorithm for n arbitrary time arrivals of clients, where m is the average number of arrivals in an interval of a stream length. We then show how to adopt our algorithm to be optimal even if clients have a limited size buffer. The complexity remains the same.We also prove that using stream merging may reduce the required bandwidth by a factor of order $rho L/log(rho L)$ compared to the simple batching solution where L is the length of a stream and $rhole 1$ is the density in time of all the n arrivals. On the other hand, we show that the bandwidth required when clients can receive an unbounded number of streams simultaneously is always at least 1/2 the bandwidth required when clients are limited to receiving at most two streams.},
journal = {SIAM J. Comput.},
month = may,
pages = {1011–1034},
numpages = {24},
keywords = {stream merging, monotonicity property, media-on-demand, dynamic programming}
}

@article{10.1137/S0097539799356265,
author = {Chekuri, Chandra and Khanna, Sanjeev},
title = {On Multidimensional Packing Problems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799356265},
doi = {10.1137/S0097539799356265},
abstract = {We study the approximability of multidimensional generalizations of three classical packing problems: multiprocessor scheduling, bin packing, and the knapsack problem.  Specifically, we study the  vector scheduling problem, its dual problem, namely, the  vector bin packing problem, and a class of packing integer programs.  The vector scheduling problem is to schedule n d-dimensional tasks on m machines such that the maximum load over all dimensions and all machines is minimized. The vector bin packing problem, on the other hand, seeks to minimize the number of bins needed to schedule all n tasks such that the maximum load on any dimension across all bins is bounded by a fixed quantity, say, 1.  Such problems naturally arise when scheduling tasks that have multiple resource requirements. Finally, packing integer programs capture a core problem that directly relates to both vector scheduling and vector bin packing, namely, the problem of packing a maximum number of vectors in a single bin of unit height.  We obtain a variety of new algorithmic as well as inapproximability results for these three problems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {837–851},
numpages = {15},
keywords = {multiprocessor scheduling, vector bin packing, knapsack, hardness of approximation, approximation algorithms, vector scheduling, multidimensional packing, packing integer programs, bin packing, combinatorial optimization}
}

@article{10.1137/S0097539703427975,
author = {Barak, Boaz and Lindell, Yehuda},
title = {Strict Polynomial-Time in Simulation and Extraction},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703427975},
doi = {10.1137/S0097539703427975},
abstract = {The notion of efficient computation is usually identified in cryptography and complexity with (strict) probabilistic polynomial-time. However, until recently, in order to obtain emph{constant-round} zero-knowledge proofs and proofs of knowledge, one had to allow simulators and knowledge extractors to run in time that is only polynomial on the average (i.e., expected polynomial-time). Recently Barak gave the first constant-round zero-knowledge argument with a strict (in contrast to expected) polynomial-time simulator. The simulator in his protocol is a nonblack-box simulator (i.e., it makes inherent use of the description of the code of the verifier).In this paper, we further address the question of strict polynomial-time in constant-round zero-knowledge proofs and arguments of knowledge. First, we show that there exists a constant-round zero-knowledge argument of knowledge with a strict polynomial-time knowledge extractor. As in the simulator of Barak's zero-knowledge protocol, the extractor for our argument of knowledge is not black-box and makes inherent use of the code of the prover. On the negative side, we show that nonblack-box techniques are essential for both strict polynomial-time simulation and extraction. That is, we show that no (nontrivial) constant-round zero-knowledge proof or argument can have a strict polynomial-time black-box simulator. Similarly, we show that no (nontrivial) constant-round zero-knowledge proof or argument of knowledge can have a strict polynomial-time black-box knowledge extractor.},
journal = {SIAM J. Comput.},
month = apr,
pages = {783–818},
numpages = {36},
keywords = {expected vs. strict polynomial-time, zero-knowledge proof systems, black-box vs. nonblack-box algorithms, proofs of knowledge}
}

@article{10.1137/S0097539703427203,
author = {Flum, J\"{o}rg and Grohe, Martin},
title = {The Parameterized Complexity of Counting Problems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703427203},
doi = {10.1137/S0097539703427203},
abstract = {We develop a parameterized complexity theory for counting problems. As the basis of this theory, we introduce a hierarchy of parameterized counting complexity classes #W$[t]$, for $tge 1$, that corresponds to Downey and Fellows's W-hierarchy [R. G. Downey and M. R. Fellows, Parameterized Complexity, Springer-Verlag, New York, 1999] and we show that a few central W-completeness results for decision problems translate to #W-completeness results for the corresponding counting problems.  Counting complexity gets interesting with problems whose decision version is tractable, but whose counting version is hard. Our main result states that counting cycles and paths of length k in both directed and undirected graphs, parameterized by k, is #W$[1]-complete. This makes it highly unlikely that these problems are fixed-parameter tractable, even though their decision versions are fixed-parameter tractable. More explicitly, our result shows that most likely there is no $f(k) cdot n^c$-algorithm for counting cycles or paths of length k in a graph of size n for any computable function $f: mathbb{N} to mathbb{N}$ and constant c, even though there is a $2^{O(k)} cdot n^{2.376}$ algorithm for finding a cycle or path of length k [N. Alon, R. Yuster, and U. Zwick, J. ACM, 42 (1995), pp. 844--856].},
journal = {SIAM J. Comput.},
month = apr,
pages = {892–922},
numpages = {31},
keywords = {descriptive complexity, parameterized complexity, paths and cycles, counting complexity}
}

@article{10.1137/S0097539703420651,
author = {Vinodchandran, N. V.},
title = {Counting Complexity of Solvable Black-Box Group Problems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703420651},
doi = {10.1137/S0097539703420651},
abstract = {We place many computational problems over solvable black-box groups in the counting complexity classes SPP or LWPP@. The classes SPP and LWPP are considered classes of low counting complexity. In particular, SPP is low (powerless when used as oracles) for all gap-definable counting classes (PP@, C$_=$P@, Mod$_k$P@, etc.) and LWPP is low for PP and C$_=$P@.  The results improve the upper bounds for these problems proved in [Arvind and Vinodchandran, Theoret. Comput. Sci., 180 (1997), pp. 17--45], where the authors place these problems in randomized versions of SPP and LWPP.  Because of the randomization, upper bounds in that paper implied lowness only for the class PP. The results in this paper favor the belief that these problems are unlikely to be complete for NP.},
journal = {SIAM J. Comput.},
month = apr,
pages = {852–869},
numpages = {18},
keywords = {computational complexity theory, complexity classes, computational group theory}
}

@article{10.1137/S0097539702419339,
author = {Kowalski, Dariusz R. and Pelc, Andrzej},
title = {Time of Deterministic Broadcasting in Radio Networks with Local Knowledge},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702419339},
doi = {10.1137/S0097539702419339},
abstract = {We consider broadcasting in radio networks, modeled as undirected graphs, whose nodes know only their own label and labels of their neighbors. In every step every node acts either as a  transmitter or as a receiver. A node acting as a transmitter sends a message which can potentially reach all of its neighbors. A node acting as a receiver  in a given step gets a message if and only if exactly one of its neighbors transmits in this step.Bar-Yehuda, Goldreich, and Itai [J. Comput. System Sci., 45 (1992), pp. 104--126] considered broadcasting in this model. They claimed a linear lower bound on the time of deterministic broadcasting in such radio networks of diameter 3. This claim turns out to be incorrect in this model (although it is valid in a more pessimistic model [R. Bar-Yehuda, O. Goldreich, and A. Itai, Errata Regarding "On the time complexity of broadcast in radio networks: An exponential gap between determinism and randomization," http://www.wisdom.weizmann.ac.il/mathusers/oded/p_bgi.html, 2002]). We construct an algorithm that broadcasts in logarithmic time on all graphs from the Bar-Yehuda, Goldreich, and Itai paper (BGI). Moreover, we show how to broadcast in sublinear time on all n-node graphs of diameter $o(log log n)$. On the other hand, we construct a class of graphs of diameter 4, such that every broadcasting algorithm requires time $Omega(sqrt[4]{n})$ on these graphs. In view of the randomized algorithm from BGI, running in expected time ${cal O}(D log n + log ^2 n)$ on all $n$-node graphs of diameter D (cf. also a recent ${cal O}(D log (n/D) + log ^2 n)$-time algorithm from [D. Kowalski and A. Pelc, Proceedings of the 22nd Annual ACM Symposium on Principles of Distributed Computing, Boston, 2003, pp. 73--82; A. Czumaj and W. Rytter, Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, Cambridge, MA, 2003, pp. 492--501]), our lower bound gives the first correct proof of an exponential gap between determinism and randomization in the time of radio broadcasting, under the considered model of radio communication.},
journal = {SIAM J. Comput.},
month = apr,
pages = {870–891},
numpages = {22},
keywords = {broadcasting, deterministic, distributed, radio network}
}

@article{10.1137/S0097539702403803,
author = {Loera, Jesus De and Onn, Shmuel},
title = {The Complexity of Three-Way Statistical Tables},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403803},
doi = {10.1137/S0097539702403803},
abstract = {Multiway tables with specified marginals arise in a variety of applications in statistics and operations research. We provide a comprehensive complexity classification of three fundamental computational problems on tables: existence, counting, and entry-security. One outcome of our work is that each of the following problems is intractable already for "slim" 3-tables, with constant number 3 of rows: (1) deciding existence of 3-tables with specified 2-marginals; (2) counting all 3-tables with specified 2-marginals; (3) deciding whether a specified value is attained in a specified entry by at least one of the 3-tables having the same 2-marginals as a given table. This implies that a characterization of feasible marginals for such slim tables, sought by much recent research, is unlikely to exist.Another consequence of our study is a systematic efficient way of embedding the set of 3-tables satisfying any given 1-marginals and entry upper bounds in a set of slim 3-tables satisfying suitable 2-marginals with no entry bounds. This provides a valuable tool for studying multi-index transportation problems and multi-index transportation polytopes. Remarkably, it enables us to automatically recover a famous example due to Vlach of a "real-feasible integer-infeasible" collection of 2-marginals for 3-tables of smallest possible size (3,4,6).},
journal = {SIAM J. Comput.},
month = apr,
pages = {819–836},
numpages = {18},
keywords = {marginal statistics, transportation polytope, contingency table, statistical disclosure control, computational complexity, data quality, transportation problems, confidentiality, Fr\'{e}chet bound, statistical table, data security}
}

@article{10.1137/S0097539701397801,
author = {Vikas, Narayan},
title = {Compaction, Retraction, and Constraint Satisfaction},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701397801},
doi = {10.1137/S0097539701397801},
abstract = {In this paper, we show a very close relationship among the compaction, retraction, and constraint satisfaction problems in the context of reflexive and bipartite graphs. The compaction and retraction problems are special graph coloring problems, and the constraint satisfaction problem is well known to have an important role in artificial intelligence. The relationships we present provide evidence that, similar to %as for the retraction problem, it is likely to be difficult to determine whether for every fixed reflexive or bipartite graph, the compaction problem is polynomial time solvable or NP-complete. In particular, the relationships that we present relate to a long-standing open problem concerning the equivalence of the compaction and retraction problems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {761–782},
numpages = {22},
keywords = {homomorphism, constraint satisfaction, compaction, computational complexity, retraction, coloring, graph}
}

@article{10.1137/S0097539797320906,
author = {Halpern, Joseph Y. and Meyden, Ron vander and Vardi, Moshe Y.},
title = {Complete Axiomatizations for Reasoning about Knowledge and Time},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797320906},
doi = {10.1137/S0097539797320906},
abstract = {Sound and complete axiomatizations are provided for a number of different logics involving modalities for knowledge and time.  These logics arise from different choices for various parameters regarding the interaction of knowledge with time and regarding the language used. All the logics considered involve the discrete time linear temporal logic operators "next" and "until" and an operator for the knowledge of each of a number of agents. Both the single-agent and multiple-agent cases are studied: in some instances of the latter there is also an operator for the common knowledge of the group of all agents.  Four different semantic properties of agents are considered: whether they (i) have a unique initial state, (ii) operate synchronously, (iii) have perfect recall, and (iv) learn. The property of no learning is essentially dual to perfect recall. Not all settings of these parameters lead to recursively axiomatizable logics, but sound and complete axiomatizations are presented for all the ones that do.},
journal = {SIAM J. Comput.},
month = mar,
pages = {674–703},
numpages = {30},
keywords = {complete axiomatizations, epistemic logic, knowledge, temporal logic, common knowledge}
}

@article{10.1137/S0097539703440678,
author = {Regev, Oded},
title = {Quantum Computation and Lattice Problems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703440678},
doi = {10.1137/S0097539703440678},
abstract = {We present the first explicit connection between quantum computation and lattice problems. Namely, our main result is a solution to the unique shortest vector problem (SVP) under the assumption that there exists an algorithm that solves the hidden subgroup problem on the dihedral group by coset sampling. Additionally, we present an approach to solving the hidden sub-group problem on the dihedral group by using an average case subset sum routine.},
journal = {SIAM J. Comput.},
month = mar,
pages = {738–760},
numpages = {23},
keywords = {shortest vector problem, hidden subgroup problem, lattices, quantum computation}
}

@article{10.1137/S0097539703431019,
author = {Chen, Xiao and Shen, Jian},
title = {On the Frame--Stewart Conjecture about the Towers of Hanoi},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703431019},
doi = {10.1137/S0097539703431019},
abstract = {The multipeg Towers of Hanoi problem consists of  k  pegs mounted on a board together with  n  disks of different sizes. Initially these disks are placed on one peg in the order of their size, with the largest at the bottom. The rules of the problem allow disks to be moved one at a time from one peg to another as long as a disk is never placed on top of a smaller disk. The goal of the problem is to transfer all the disks to another peg with the minimum number of moves, denoted by  H (  n ,  k ). An easy recursive argument shows that  H (  n ,3)= 2   n  -1. However, the problem of computing the exact value of  H (  n ,  k ) for $k ge 4$ has been open since 1939, and in particular, the special case of  H (  n ,4) has been open since 1907. In 1941, Frame and Stewart each gave an algorithm to solve the Towers of Hanoi problem based on an unproved assumption. The Frame--Stewart number, denoted by  FS (  n ,  k ), is the number of moves needed to solve the Towers of Hanoi problem using the "presumed optimal" Frame--Stewart algorithm. Since then, proving the Frame--Stewart conjecture  FS (  n ,  k ) =  H (  n ,  k ) has become a notorious open problem. In this paper, we prove that  FS (  n ,  k ) and  H (  n ,  k ) both have the same order of magnitude of $2^{(1pm o(1))(n(k-2)!)^{1/(k-2)}}$. This provides the strongest evidence so far to support the Frame--Stewart conjecture.},
journal = {SIAM J. Comput.},
month = mar,
pages = {584–589},
numpages = {6},
keywords = {Frame--Stewart algorithm, Towers of Hanoi problem, Frame--Stewart conjecture, optimal algorithm}
}

@article{10.1137/S0097539703424521,
author = {Devroye, Luc and Neininger, Ralph},
title = {Distances and Finger Search in Random Binary Search Trees},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703424521},
doi = {10.1137/S0097539703424521},
abstract = {For the random binary search tree with n nodes  inserted the number of ancestors of the elements with ranks k and $ell$,  $1 le k &lt; ell le n$, as well as the path distance between these elements in the tree are considered. For both quantities, central limit theorems for appropriately rescaled versions are derived. For the path distance, the condition $ell-k to infty$ as $nto infty$ is required. We obtain tail bounds and the order of higher moments for the path distance. The path distance measures the complexity of finger search in the tree.},
journal = {SIAM J. Comput.},
month = mar,
pages = {647–658},
numpages = {12},
keywords = {analysis of algorithms, random binary search tree, path distance, finger search, limit law}
}

@article{10.1137/S0097539703423941,
author = {Buchsbaum, Adam L. and Karloff, Howard and Kenyon, Claire and Reingold, Nick and Thorup, Mikkel},
title = {<i>OPT</i> Versus <i>LOAD</i> in Dynamic Storage Allocation},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703423941},
doi = {10.1137/S0097539703423941},
abstract = {Dynamic storage allocation is the problem of packing given axis-aligned rectangles into a horizontal strip of minimum height by sliding the rectangles vertically but not horizontally. Where  L = is the maximum sum of heights of rectangles that intersect any vertical line and  OPT  is the minimum height of the enclosing strip, it is obvious that $ensuremath{text{it OPT}}ge ensuremath{text{it LOAD}}$; previous work showed that $ensuremath{text{it OPT}}le 3cdot  LOAD . We continue the study of the relationship between  OPT  and  LOAD , proving that  OPT =  L +  O ((  h max /  L ) 1/7)  L , where  h max  is the maximum job height. Conversely, we prove that for any $epsilon&gt;0$, there exists a  c &gt;0 such that for all sufficiently large integers $h_{max}$, there is a dynamic storage allocation instance with maximum job height $h_{max}$, maximum load at most  L , and $ensuremath{text{it OPT}}geq L+c(h_{max}/L)^{1/2+epsilon}L$, for infinitely many integers  L . En route, we construct several new polynomial-time approximation algorithms for dynamic storage allocation, including a $(2+epsilon)$-approximation algorithm for the general case and polynomial-time approximation schemes for several natural special cases. },
journal = {SIAM J. Comput.},
month = mar,
pages = {632–646},
numpages = {15},
keywords = {approximation algorithms, polynomial-time approximation schemes, dynamic storage allocation}
}

@article{10.1137/S0097539702417225,
author = {Andrews, Matthew and Zhang, Lisa},
title = {The Effects of Temporary Sessions on Network Performance},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702417225},
doi = {10.1137/S0097539702417225},
abstract = {We consider a packet network, in which packets are injected in  sessions  along fixed paths. Packet movement is restricted by link bandwidth. In case of contention, a  contention resolution protocol  determines which packets proceed. In the  permanent session model , a fixed set of connections is present in the network at all times. In the  temporary session model , connections come and go over time. In this paper we compare network performance in these two models in terms of stability and end-to-end delay. We provide the first separation of the two models in terms of stability. In particular, we show that generalized processor sharing (GPS) can be unstable with temporary sessions, whereas GPS is known to be stable and have polynomial delay bounds with permanent sessions.We also observe that the relative performance of protocols can differ in the two models. For example, in the temporary session model the protocol farthest-to-go (FTG) is known to be stable and therefore outperforms GPS. However, in the permanent session model we show that FTG can suffer exponential delays and is therefore outperformed by GPS.Although polynomial delay bounds are easy to obtain for permanent sessions, this is not the case when sessions can be temporary. We show that a common framework for bounding delays can only lead to superpolynomial bounds in the temporary session model. We also construct superpolynomial lower bounds on delay for a large class of deterministic, distributed protocols that includes the longest-in-system protocol.},
journal = {SIAM J. Comput.},
month = mar,
pages = {659–673},
numpages = {15},
keywords = {permanent sessions, delay bounds, scheduling, stability, packet networks, temporary sessions}
}

@article{10.1137/S0097539702416736,
author = {Kortsarz, Guy and Krauthgamer, Robert and Lee, James R.},
title = {Hardness of Approximation for Vertex-Connectivity Network Design Problems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702416736},
doi = {10.1137/S0097539702416736},
abstract = {In the survivable network design problem (SNDP), the goal is to find a minimum-cost spanning subgraph satisfying certain connectivity requirements. We study the vertex-connectivity variant of SNDP in which the input specifies, for each pair of vertices, a required number of vertex-disjoint paths connecting them.We give the first strong lower bound on the approximability of SNDP, showing that the problem admits no efficient $2^{log^{1-epsilon} n}$ ratio approximation for any fixed $epsilon! &gt;! 0$, unless $NPsubseteq DTIME(n^{polylog(n)})$. We show hardness of approximation results for some important special cases of SNDP, and we exhibit the first lower bound on the approximability of the related classical NP-hard problem of augmenting the connectivity of a graph using edges from a given set.},
journal = {SIAM J. Comput.},
month = mar,
pages = {704–720},
numpages = {17},
keywords = {hardness of approximation, approximation algorithms, survivable network design, vertex connectivity, connectivity augmentation}
}

@article{10.1137/S0097539702416402,
author = {Arya, Vijay and Garg, Naveen and Khandekar, Rohit and Meyerson, Adam and Munagala, Kamesh and Pandit, Vinayaka},
title = {Local Search Heuristics for <i>k</i>-Median and  Facility Location Problems},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702416402},
doi = {10.1137/S0097539702416402},
abstract = {We analyze local search heuristics for the metric k-median and facility location problems. We define the locality gap of a local search procedure for a minimization problem as the maximum ratio of a locally optimum solution (obtained using this procedure) to the global optimum. For k-median, we show that local search with swaps has a locality gap of 5. Furthermore, if we permit up to p facilities to be swapped simultaneously, then the locality gap is 3+2/p. This is the first analysis of a local search for k-median that provides a bounded performance guarantee with only k medians. This also improves the previous known 4 approximation for this problem. For uncapacitated facility location, we show that local search, which permits adding, dropping, and swapping a facility, has a locality gap of 3. This improves the bound of 5 given by M. Korupolu, C. Plaxton, and R. Rajaraman [Analysis of a Local Search Heuristic for Facility Location Problems, Technical Report 98-30, DIMACS, 1998].  We also consider a capacitated facility location problem where each facility has a capacity and we are allowed to open multiple copies of a facility. For this problem we introduce a new local search operation which opens one or more copies of a facility and drops zero or more facilities. We prove that this local search has a locality gap between 3 and 4.},
journal = {SIAM J. Comput.},
month = mar,
pages = {544–562},
numpages = {19},
keywords = {local search, approximation algorithm, facility location}
}

@article{10.1137/S0097539702406510,
author = {Pe'er, Itsik and Pupko, Tal and Shamir, Ron and Sharan, Roded},
title = {Incomplete Directed Perfect Phylogeny},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702406510},
doi = {10.1137/S0097539702406510},
abstract = {Perfect phylogeny is one of the fundamental models for studying evolution. We investigate the following variant of the model: The input is a species-characters matrix. The characters are binary and directed; i.e., a species can only gain characters. The difference from standard perfect phylogeny is that for some species the states of some characters are unknown. The question is whether one can complete the missing states in a way that admits a perfect phylogeny. The problem arises in classical phylogenetic studies, when some states are missing or undetermined. Quite recently, studies that infer phylogenies using inserted repeat elements in DNA gave rise to the same problem. Extant solutions for it take time O(n2m) for n species and m characters. We provide a graph theoretic formulation of the problem as a graph sandwich problem, and give near-optimal $tilde{O}(nm)$-time algorithms for the problem. We also study the problem of finding a single, general solution tree, from which any other solution can be obtained by node splitting. We provide an algorithm to construct such a tree, or determine that none exists.},
journal = {SIAM J. Comput.},
month = mar,
pages = {590–607},
numpages = {18},
keywords = {perfect phylogeny, incomplete data, evolution, graph sandwich}
}

@article{10.1137/S0097539702401786,
author = {Molloy, Michael},
title = {The Glauber Dynamics on Colorings of a Graph with High Girth and Maximum Degree},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702401786},
doi = {10.1137/S0097539702401786},
abstract = {We prove that the Glauber dynamics on the C-colorings of a graph G on n vertices with girth g and maximum degree $Delta$ mixes rapidly if (i) $C=qDelta$ and $q&gt;q^*$, where $q^*=1.4890ldots$ is the root of $(1-{rm e}^{-1/q})^2+q{rm e}^{-1/q}=1$; and (ii) $Deltageq Dlog n$ and $ggeq DlogDelta$ for some constant D=D(q).  This improves the bound of roughly $1.763Delta$ obtained by Dyer and Frieze [ Proceedings of the 32nd Annual Symposium on Foundations of Computer Science, 2001] for the same class of graphs. Our bound on this class of graphs is lower than the bound of $11Delta/6approx1.833Delta$ obtained by Vigoda [J. Math. Phys., 41 (2000), pp. 1555--1569] for general graphs.},
journal = {SIAM J. Comput.},
month = mar,
pages = {721–737},
numpages = {17},
keywords = {colorings, Glauber dynamics, rapidly mixing Markov chains}
}

@article{10.1137/S0097539701399666,
author = {Kesselman, Alexander and Lotker, Zvi and Mansour, Yishay and Patt-Shamir, Boaz and Schieber, Baruch and Sviridenko, Maxim},
title = {Buffer Overflow Management in QoS Switches},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701399666},
doi = {10.1137/S0097539701399666},
abstract = {We consider two types of buffering policies that are used in network switches supporting Quality of Service (QoS). In the  FIFO  type, packets must be transmitted in the order in which they arrive; the constraint in this case is the limited buffer space. In the  bounded-delay  type, each packet has a maximum delay time by which it must be transmitted, or otherwise it is lost. We study the case of overloads resulting in packet loss. In our model, each packet has an intrinsic value, and the goal is to maximize the total value of transmitted packets. Our main contribution is a thorough investigation of some natural greedy algorithms in various models. For the FIFO model we prove tight bounds on the competitive ratio of the greedy algorithm that discards packets with the lowest value when an overflow occurs. We also prove that the greedy algorithm that drops the earliest packets among all low-value packets is the best greedy algorithm. This algorithm can be as much as 1.5 times better than the tail-drop greedy policy, which drops the latest lowest-value packets.In the bounded-delay model we show that the competitive ratio of any on-line algorithm for a uniform bounded-delay buffer is bounded away from 1, independent of the delay size. We analyze the greedy algorithm in the general case and in three special cases: delay bound 2, link bandwidth 1, and only two possible packet values.Finally, we consider the off-line scenario. We give efficient optimal algorithms and study the relation between the bounded-delay and FIFO models in this case.},
journal = {SIAM J. Comput.},
month = mar,
pages = {563–583},
numpages = {21},
keywords = {buffer overflows, FIFO scheduling, deadline scheduling, competitive analysis, Quality of Service}
}

@article{10.1137/S0097539701393384,
author = {Elkin, Michael and Peleg, David},
title = {$(1 + \epsilon,\beta)$-Spanner Constructions for General Graphs},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701393384},
doi = {10.1137/S0097539701393384},
abstract = {An {em $(alpha,beta)$-spanner} of a graph G is a subgraph H such that $mathit{dist}_H(u,w)le alphacdot mathit{dist}t_G(u,w)+beta$ for every pair of vertices u,w, where distG'(u,w) denotes the distance between two vertices u and v in G'. It is known that every graph G has a polynomially constructible $(2kappa-1,0)$-spanner (also known as  multiplicative $(2kappa-1)$-spanner) of size $O(n^{1+1/kappa})$ for every integer $kappage 1$, and a polynomially constructible (1,2)-spanner (also known as additive 2-spanner) of size ${tilde O}(n^{3/2})$. This paper explores hybrid spanner constructions (involving both multiplicative and additive factors) for general graphs and shows that the multiplicative factor can be made arbitrarily close to 1 while keeping  the spanner size arbitrarily close to O(n), at the cost of allowing the additive term to be a sufficiently large constant. More formally, we show that for any constant $epsilon, lambda &gt; 0$ there exists a constant $beta = beta(epsilon, lambda)$ such that for every $n$-vertex graph G there is an efficiently constructible $(1+ epsilon, beta)$-spanner of size $O(n^{1 + lambda})$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {608–631},
numpages = {24},
keywords = {spanners, graph partitions, graph algorithms}
}

@article{10.1137/S0097539701386216,
author = {Siegel, Alan},
title = {On Universal Classes of Extremely Random Constant-Time Hash Functions},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701386216},
doi = {10.1137/S0097539701386216},
abstract = {A family of functions  F  that map [0,  m -1] into [0,  n -1] is said to be $h$-wise independent if any tuple of $h$ distinct points in $[0,m-1]$ have a corresponding image, for a randomly selected $fin F$, that is uniformly distributed in $[0,n-1]^{h}$. This paper shows that for suitably fixed $epsilon&lt;1$ and any $h},
journal = {SIAM J. Comput.},
month = mar,
pages = {505–543},
numpages = {39},
keywords = {PRAM emulation, limited independence, storage-time tradeoff, hashing, hash functions, optimal speedup, universal hash functions}
}

@article{10.1137/S0097539703437181,
author = {Pan, Victor Y. and Wang, Xinmao},
title = {On Rational Number Reconstruction and Approximation},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703437181},
doi = {10.1137/S0097539703437181},
abstract = {The celebrated LKS algorithm by Lehmer, Knuth, and Sch\"{o}nhage, combined with the product tree technique, enables an equivalently rapid alternative to our recent modification of the extended Euclidean algorithm for the reconstruction of a rational number from its modular as well as numerical approximations.},
journal = {SIAM J. Comput.},
month = feb,
pages = {502–503},
numpages = {2},
keywords = {product tree technique, extended Euclidean algorithm, rational number reconstruction, rational number approximation, LKS algorithm}
}

@article{10.1137/S0097539703433110,
author = {Honkala, Iiro and Laihonen, Tero},
title = {On Identifying Codes in the Triangular and Square Grids},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703433110},
doi = {10.1137/S0097539703433110},
abstract = {It is shown that in the infinite square grid the density of every $(r, leq 2)$-identifying code is at least 1/8 and that there exists a sequence $C_r$ of $(r, leq 2)$-identifying codes such that the density of Cr tends to 1/8 when $r rightarrow infty$. In the infinite triangular grid a sequence $C'_r$ of $(r, leq 2)$-identifying codes is given such that the density of $C'_r$ tends to 0 when $r rightarrow infty$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {304–312},
numpages = {9},
keywords = {density, identifying code, multiprocessor system, square lattice, triangular lattice}
}

@article{10.1137/S0097539703427963,
author = {Har-Peled, Sariel and Wang, Yusu},
title = {Shape Fitting with Outliers},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703427963},
doi = {10.1137/S0097539703427963},
abstract = {Given a set $mathcal{H}$ of n hyperplanes in ${Bbb R}^d$, we present an algorithm that $eps$-approximates the extent between the top and bottom k levels of the arrangement of $mathcal{H}$ in time $O(n + (k/eps)^c)$, where c is a constant depending on d.  The algorithm relies on computing a subset of $mathcal{H}$ of size $O(k/eps^{d-1})$, in near linear time, such that the k-level of the arrangement of the subset approximates that of the original arrangement.  Using this algorithm, we propose efficient approximation algorithms for shape fitting with outliers for various shapes. These are the first algorithms to handle outliers efficiently for the shape fitting problems considered.},
journal = {SIAM J. Comput.},
month = feb,
pages = {269–285},
numpages = {17},
keywords = {outliers, approximation, shape fitting}
}

@article{10.1137/S0097539703426775,
author = {Hassin, Refael and Levin, Asaf},
title = {An Efficient Polynomial Time Approximation Scheme for the Constrained Minimum Spanning Tree Problem Using Matroid Intersection},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703426775},
doi = {10.1137/S0097539703426775},
abstract = {Given an undirected graph G=(V,E) with |V|=n and |E|=m, nonnegative integers ce and de for each edge $e in E$, and a bound D, the constrained minimum spanning tree problem (CST) is to find a spanning tree T=(V,ET) such that $sum_{e in E_T} d_e leq D$ and $sum_{e in E_T} c_e$ is minimized.  We present an efficient polynomial time approximation scheme (EPTAS) for this problem.  Specifically, for every $epsilon&gt;0$ we present a $(1+epsilon)$-approximation algorithm with time complexity $O((frac{1}{epsilon})^{O(frac{1}{epsilon})}n^4)$. Our method is based on Lagrangian relaxation and matroid intersection.},
journal = {SIAM J. Comput.},
month = feb,
pages = {261–268},
numpages = {8},
keywords = {matroid intersection, spanning tree, approximation algorithm, bicriteria optimization}
}

@article{10.1137/S009753970342585X,
author = {Khuller, Samir and Kim, Yoo-Ah},
title = {Algorithms for Data Migration with Cloning},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970342585X},
doi = {10.1137/S009753970342585X},
abstract = {Our work is motivated by the problem of managing data on storage devices, typically a set of disks. Such high-demand storage servers are used as Web servers or as multimedia servers for handling high demand for data. As the system is running, it needs to dynamically respond to changes in demand for different data items. In this work we study the  data migration problem, which arises when we need to quickly change one storage configuration into another. We show that this problem is NP-hard. In addition, we develop polynomial-time approximation algorithms for this problem and prove a worst-case bound of 9.5 on the approximation factor achieved by our algorithm.},
journal = {SIAM J. Comput.},
month = feb,
pages = {448–461},
numpages = {14},
keywords = {gossip, broadcast, approximation algorithms, multicast}
}

@article{10.1137/S0097539703421620,
author = {Chen, William Y. C. and Li, Xueliang and Wang, Chao and Zhang, Xiaoyan},
title = {The Minimum All-Ones Problem for Trees},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703421620},
doi = {10.1137/S0097539703421620},
abstract = {The minimum all-ones problem was shown to be NP-complete for general graphs. Therefore, it becomes an interesting problem to identify special classes of graphs for which one can find polynomial time algorithms. In this paper we consider this problem for trees. First, for any solution to the all-ones problem for a tree, we give a characterization of the elements in the solution by introducing the concept of the quasi all-ones problem. Then we give the enumeration for the number of solutions in a tree. By using the minimum odd (even) sum problem as subprocess, we obtain a linear time algorithm for the minimum all-ones problem for trees. We also get a linear time algorithm for finding solutions to the all-ones problem in a unicyclic graph.},
journal = {SIAM J. Comput.},
month = feb,
pages = {379–392},
numpages = {14},
keywords = {all-ones problem, lamp lighting problem, graph algorithm, time complexity}
}

@article{10.1137/S0097539702420139,
author = {Alon, Noga and Beigel, Richard and Kasif, Simon and Rudich, Steven and Sudakov, Benny},
title = {Learning a Hidden Matching},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702420139},
doi = {10.1137/S0097539702420139},
abstract = {We consider the problem of learning a matching (i.e., a graph in which all vertices have degree 0 or 1) in a model where the only allowed operation is to query whether a set of vertices induces an edge. This is motivated by a problem that arises in molecular biology.  In the deterministic nonadaptive setting, we prove a $(frac{1}{2}+o(1)){n choose 2} $ upper bound and a nearly matching $0.32{n choose 2}$ lower bound for the minimum possible number of queries.  In contrast, if we allow randomness, then we obtain (by a randomized, nonadaptive algorithm) a much lower O(n log n) upper bound, which is best possible (even for randomized fully adaptive algorithms).},
journal = {SIAM J. Comput.},
month = feb,
pages = {487–501},
numpages = {15},
keywords = {matchings in graphs, genome sequencing, finite projective planes, combinatorial search problems}
}

@article{10.1137/S0097539702419352,
author = {Icking, Christian and Klein, Rolf and Langetepe, Elmar and Schuierer, Sven and Semrau, Ines},
title = {An Optimal Competitive Strategy for Walking in Streets},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702419352},
doi = {10.1137/S0097539702419352},
abstract = {A simple polygon P with two distinguished vertices, s and t, is called a street if the two boundary chains from s to t are mutually weakly visible. We present an on-line strategy that walks from s to t, in any unknown street, on a path at most $sqrt{2}$ times longer than the shortest path. This matches the best lower bound previously known and settles an open problem in the area of competitive path planning. (The result was simultaneously and independently obtained by the first three authors and by the last two authors. Both papers, [C. Icking, R. Klein, and E. Langetepe, Proceedings of the 16th Symposium on Theoretical Aspects in Computer Science, Lecture Notes in Comput. Sci. 1563, Springer-Verlag, Berlin, 1999, pp. 110--120] and [S. Schuierer and I. Semrau, Proceedings of the 16th Symposium on Theoretical Aspects of Computer Science, pp. 121--131], were presented at STACS'99. The present paper contains a joint full version.)},
journal = {SIAM J. Comput.},
month = feb,
pages = {462–486},
numpages = {25},
keywords = {competitive strategy, autonomous robot, street, on-line navigation, computational geometry, polygon, LR-visibility, path planning}
}

@article{10.1137/S0097539702413306,
author = {Lotker, Zvi and Patt-Shamir, Boaz and Ros\'{e}n, Adi},
title = {New Stability Results for Adversarial Queuing},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702413306},
doi = {10.1137/S0097539702413306},
abstract = {We consider the model of "adversarial queuing theory" for packet networks introduced by Borodin et al. [J. ACM, 48 (2001), pp. 13--38]. We show that the scheduling protocol first-in-first-out (FIFO) can be unstable at any injection rate larger than 1/2 and that it is always stable if the injection rate is less than 1/d, where d is the length of the longest route used by any packet. We further show that every work-conserving (i.e., greedy) scheduling policy is stable if the injection rate is less than 1/(d+1).},
journal = {SIAM J. Comput.},
month = feb,
pages = {286–303},
numpages = {18},
keywords = {stability, network protocols, lower bounds, adversarial queuing theory}
}

@article{10.1137/S0097539702408363,
author = {Goldberg, Leslie Ann and Kelk, Steven and Paterson, Mike},
title = {The Complexity of Choosing an $H$-Coloring (Nearly) Uniformly at Random},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702408363},
doi = {10.1137/S0097539702408363},
abstract = {Cooper, Dyer, and Frieze [J. Algorithms, 39 (2001), pp. 117--134] studied the problem of sampling H-colorings (nearly) uniformly at random. Special cases of this problem include sampling colorings and independent sets and sampling from statistical physics models such as the Widom--Rowlinson model, the Beach model, the Potts model and the hard-core lattice gas model. Cooper et al. considered the family of "cautious" ergodic Markov chains with uniform stationary distribution and showed that, for every fixed connected "nontrivial " graph H, every such chain mixes slowly.  In this paper, we give a complexity result for the problem. Namely, we show that for any fixed graph H with no trivial components, there is unlikely to be any polynomial almost uniform sampler (PAUS) for H-colorings.  We show that if there were a PAUS for the H-coloring problem, there would also be a PAUS for sampling independent sets in bipartite graphs, and, by the self-reducibility of the latter problem, there would be a fully polynomial randomized approximation scheme (FPRAS) for #BIS---the problem of counting independent sets in bipartite graphs. Dyer, Goldberg, Greenhill, and Jerrum have shown that #BIS is complete in a certain logically defined complexity class. Thus, a PAUS for sampling H-colorings would give an FPRAS for the entire complexity class. In order to achieve our result we introduce the new notion of sampling-preserving reduction which seems to be more useful in certain settings than approximation-preserving reduction.},
journal = {SIAM J. Comput.},
month = feb,
pages = {416–432},
numpages = {17},
keywords = {random sampling, graph homomorphism, computational complexity, graph coloring}
}

@article{10.1137/S0097539701397059,
author = {Roughgarden, Tim},
title = {Stackelberg Scheduling Strategies},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701397059},
doi = {10.1137/S0097539701397059},
abstract = {We study the problem of optimizing the performance of a system shared by selfish, noncooperative users. We consider the concrete setting of scheduling small jobs on a set of shared machines possessing latency functions that specify the amount of time needed to complete a job, given the machine load. We measure system performance by the  total latency  of the system. Assigning jobs according to the selfish interests of individual users, who wish to minimize only the latency that their own jobs experience, typically results in suboptimal system performance. However, in many systems of this type there is a mixture of "selfishly controlled" and "centrally controlled" jobs. The congestion due to centrally controlled jobs will influence the actions of selfish users, and we thus aspire to contain the degradation in system performance due to selfish behavior by scheduling the centrally controlled jobs in the best possible way.We formulate this goal as an optimization problem via  Stackelberg games , games in which one player acts a  leader  (here, the centralized authority interested in optimizing system performance) and the rest as  followers  (the selfish users). The problem is then to compute a strategy for the leader (a  Stackelberg strategy ) that induces the followers to react in a way that (approximately) minimizes the total latency in the system.In this paper, we prove that it is NP-hard to compute an optimal Stackelberg strategy and present simple strategies with provably good performance guarantees. More precisely, we give a simple algorithm that computes a strategy inducing a job assignment with total latency no more than a constant times that of the optimal assignment of all of the jobs; in the absence of centrally controlled jobs and a Stackelberg strategy, no result of this type is possible. We also prove stronger performance guarantees in the special case where every machine latency function is linear in the machine load.},
journal = {SIAM J. Comput.},
month = feb,
pages = {332–350},
numpages = {19},
keywords = {scheduling, Stackelberg equilibria, selfish routing}
}

@article{10.1137/S0097539701396807,
author = {Gottlob, Georg and Pichler, Reinhard},
title = {Hypergraphs in Model Checking: Acyclicity and Hypertree-Width versus Clique-Width},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701396807},
doi = {10.1137/S0097539701396807},
abstract = {The principal aim of model checking is to provide efficient decision procedures for the evaluation of certain logical formulae over finite relational structures. Graphs and hypergraphs are important examples of such structures. If no restrictions are imposed on the logical formulae and on the structures under consideration, then this problem of model checking has a very high computational complexity. Hence, several restrictions have been proposed in the literature on the logical formulae and/or on the structures under consideration in order to guarantee the tractability of this decision problem, e.g., acyclicity, bounded tree-width, query-width and hypertree-width in the case of queries, as well as bounded tree-width and clique-width in the case of structures. The aim of this paper is a  detailed comparison of the expressive power of these restrictions.},
journal = {SIAM J. Comput.},
month = feb,
pages = {351–378},
numpages = {28},
keywords = {model checking, database queries, acyclicity, hypertree-width, clique-width, tractability, hypergraphs}
}

@article{10.1137/S009753970138445X,
author = {Amano, Kazuyuki and Maruoka, Akira},
title = {The Potential of the Approximation Method},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970138445X},
doi = {10.1137/S009753970138445X},
abstract = {Developing certain techniques for the approximation method, we establish precise versions of the following statements concerning lower bounds for circuits that detect cliques of size s in a graph with m vertices: For $5 leq s leq m/4$, a monotone circuit computing CLIQUE$(m,s)$ contains at least $(1/2)1.8^{min(sqrt{s-1}/2, m/(4s))}$ gates: If a nonmonotone circuit computes CLIQUE using a "small" amount of negation, then the circuit contains an exponential number of gates. The former is proved by using so-called bottleneck counting argument within the framework of approximation, and the latter is verified by introducing a notion of restricting negation in circuits and generalizing these arguments to nonmonotone cases.},
journal = {SIAM J. Comput.},
month = feb,
pages = {433–447},
numpages = {15},
keywords = {monotone circuit, negation-limited circuit, approximation method, clique function, circuit complexity, lower bounds}
}

@article{10.1137/S0097539700381851,
author = {Goldberg, Leslie Ann and Jerrum, Mark and Kannan, Sampath and Paterson, Mike},
title = {A Bound on the Capacity of Backoff and Acknowledgment-Based Protocols},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700381851},
doi = {10.1137/S0097539700381851},
abstract = {We study contention-resolution protocols for multiple-access channels. We show that every backoff protocol is transient if the arrival rate, $lambda$, is at least 0.42 and that the capacity of every backoff protocol is at most 0.42. Thus, we show that backoff protocols have (provably) smaller capacity than full-sensing protocols. Finally, we show that the corresponding results, with the larger arrival bound of 0.531, also hold for every acknowledgment-based protocol.},
journal = {SIAM J. Comput.},
month = feb,
pages = {313–331},
numpages = {19},
keywords = {backoff, contention-resolution, multiple-access channel, protocol, stability}
}

@article{10.1137/S009753970037727X,
author = {M\"{o}hring, Rolf H. and Skutella, Martin and Stork, Frederik},
title = {Scheduling with AND/OR Precedence Constraints},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970037727X},
doi = {10.1137/S009753970037727X},
abstract = {In many scheduling applications it is required that the processing of some job be postponed until some other job, which can be chosen from a pregiven set of alternatives, has been completed. The traditional concept of precedence constraints fails to model such restrictions.  Therefore, the concept has been generalized to so-called AND/OR  precedence constraints which can cope with this kind of requirement. In the context of traditional precedence constraints, feasibility, transitivity, and the computation of earliest start times for jobs are fundamental, well-studied problems.  The purpose of this paper is to provide efficient algorithms for these tasks for the more general model of AND/OR precedence constraints.  We show that feasibility as well as many questions related to transitivity can be solved by applying essentially the same linear-time algorithm.  In order to compute earliest start times we propose two polynomial-time algorithms to cope with different classes of time distances between jobs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {393–415},
numpages = {23},
keywords = {mean payoff games, project scheduling, andor precedence constraints, earliest start schedule}
}

@article{10.1137/S0097539703418808,
author = {Cheng, Siu-Wing and Dey, Tamal K.},
title = {Quality Meshing with Weighted Delaunay Refinement},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703418808},
doi = {10.1137/S0097539703418808},
abstract = {Delaunay meshes with bounded circumradius to shortest edge length ratio have been proposed in the past for quality meshing.  The only poor quality tetrahedra, called slivers, that can occur in such a mesh can be eliminated by the sliver exudation method. This method has been shown to work for periodic point sets, but not with boundaries. Recently a randomized point-placement strategy has been proposed to remove slivers while conforming to a given boundary.  In this paper we present a deterministic algorithm for generating a weighted Delaunay mesh  which respects the input boundary and has no poor quality tetrahedron including slivers. As in previous work, we assume that no input angle is acute.  Our result is achieved by combining the weight pumping method for sliver exudation and the Delaunay refinement method for boundary conformation.},
journal = {SIAM J. Comput.},
month = jan,
pages = {69–93},
numpages = {25},
keywords = {Delaunay triangulation, mesh quality, weighted Delaunay refinement, computational geometry, tetrahedral mesh generation, algorithms, sliver}
}

@article{10.1137/S0097539703405754,
author = {Chudak, Fabi\'{a}n A. and Shmoys, David B.},
title = {Improved Approximation Algorithms for the Uncapacitated Facility Location Problem},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539703405754},
doi = {10.1137/S0097539703405754},
abstract = {We consider the uncapacitated facility location problem.  In this problem, there is a set of locations at which facilities can be built; a fixed cost fi is incurred if a facility is opened at location i.  Furthermore, there is a set of demand locations to be serviced by the opened facilities; if the demand location j is assigned to a facility at location i, then there is an associated service cost proportional to the distance between i and j, cij. The objective is to determine which facilities to open and an assignment of demand points to the opened facilities, so as to minimize the total cost.  We assume that the distance function c is symmetric and satisfies the triangle inequality.  For this problem we obtain a (1+2/e)-approximation algorithm, where $1+2/e approx 1.736$, which is a significant improvement on the previously known approximation guarantees.The algorithm works by rounding an optimal fractional solution to a linear programming relaxation.  Our techniques use properties of optimal solutions to the linear program, randomized rounding, as well as a generalization of the decomposition techniques of Shmoys, Tardos, and Aardal [Proceedings of the 29th ACM Symposium on Theory of Computing, El Paso, TX, 1997, pp. 265--274].},
journal = {SIAM J. Comput.},
month = jan,
pages = {1–25},
numpages = {25},
keywords = {randomized rounding, facility location, approximation algorithms}
}

@article{10.1137/S0097539702431840,
author = {Even, Guy and Lotker, Zvi and Ron, Dana and Smorodinsky, Shakhar},
title = {Conflict-Free Colorings of Simple Geometric Regions with Applications to Frequency Assignment   in Cellular Networks},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702431840},
doi = {10.1137/S0097539702431840},
abstract = {Motivated by a frequency assignment problem in cellular networks, we introduce and study a new coloring problem that we call minimum conflict-free coloring (min-CF-coloring).  In its general form, the input of the min-CF-coloring problem is a set system $(X,{cal S})$, where each $S in {cal S}$ is a subset of X. The output is a coloring $chi$ of the sets in ${cal S}$ that satisfies the following constraint: for every $x in X$ there exists a color $i$ and a unique set $S in {cal S}$ such that $x in S$ and $chi(S) = i$.  The goal is to minimize the number of colors used by the coloring $chi$.  Min-CF-coloring of general set systems is not easier than the classic graph coloring problem.  However, in view of our motivation, we consider set systems induced by simple geometric regions in the plane.  In particular, we study disks (both congruent and noncongruent), axis-parallel rectangles (with a constant ratio between the smallest and largest rectangle), regular hexagons (with a constant ratio between the smallest and largest hexagon), and general congruent centrally symmetric convex regions in the plane. In all cases we have coloring algorithms that use O(log n) colors (where n is the number of regions).  Tightness is demonstrated by showing that even in the case of unit disks, $Theta(log n)$ colors may be necessary.  For rectangles and hexagons we also obtain a constant-ratio approximation algorithm when the ratio between the largest and smallest rectangle (hexagon) is a constant.  We also consider a dual problem of CF-coloring points with respect to sets. Given a set system $(X,{cal S})$, the goal in the dual problem is to color the elements in X with a minimum number of colors so that every set $S in {cal S}$ contains a point whose color appears only once in S. We show that O(log |X|) colors suffice for set systems in which X is a set of points in the plane and the sets are intersections of X with scaled translations of a convex region. This result is used in proving that O(log n) colors suffice in the primal version.},
journal = {SIAM J. Comput.},
month = jan,
pages = {94–136},
numpages = {43},
keywords = {frequency assignment, conflict-free coloring, computational geometry, approximation algorithms}
}

@article{10.1137/S0097539702415950,
author = {B\"{u}rgisser, Peter and Cucker, Felipe},
title = {Counting Complexity Classes for Numeric Computations I: Semilinear Sets},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702415950},
doi = {10.1137/S0097539702415950},
abstract = {We define a counting class ${rm #P}_add$ in the Blum--Shub--Smale setting of additive computations over the reals. Structural properties of this class are studied, including a characterization in terms of the classical counting class $#{sf P}$ introduced by Valiant. We also establish transfer theorems for both directions between the real additive and the discrete setting. Then we characterize in terms of completeness results the complexity of computing basic topological invariants of semilinear sets given by additive circuits. It turns out that the computation of the Euler characteristic is ${rm FP}_{rm add}^{{rm #P}_{rm add}}$-complete, while for fixed $k$ the computation of the $k$th Betti number is ${rm FPAR}_{rm add}$-complete. Thus the latter is more difficult under standard complexity theoretic assumptions. We use all of the above to prove some analogous completeness results in the classical setting.},
journal = {SIAM J. Comput.},
month = jan,
pages = {227–260},
numpages = {34},
keywords = {counting complexity, Betti numbers, Euler characteristic, real complexity classes}
}

@article{10.1137/S0097539702414622,
author = {Hromkovic, Juraj and Schnitger, Georg},
title = {Nondeterministic Communication with   a Limited Number of Advice Bits},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702414622},
doi = {10.1137/S0097539702414622},
abstract = {We present a new technique for differentiating deterministic from nondeterministic communication complexity. As a consequence we give almost tight lower bounds for the nondeterministic communication complexity with a restricted number of advice bits. In particular, for any function $t : mathbb{N} rightarrow mathbb{N}$ with $t(n) leq n2$ we construct a family $(L_{n,t(n)} : n in mathbb{N})$ of languages such that $L_{n,t(n)} subseteq {0,1}{2n}$, ${rm nc}(L_{n,t(n)}) = O(t(n) cdot log_2 frac{n}{t(n)})$ and ${rm nc}(overline{L_{n,t(n)}}) = Obigl(frac{n}{t(n) cdot log_2 frac{n}{t(n)}} + log_2 t(n)bigr)$, but ${rm nc}_{o(t(n))}(L_{n,t(n)}) = Omegabigl(frac{n}{log_2 frac{n}{t(n)}}bigr)$. Here ${rm nc}_r(L)$ is the nondeterministic communication complexity of L, assuming that at most r advice bits are utilized. Thus, in contrast to probabilistic communication complexity, a small reduction in the number of advice bits results in almost maximal communication. As a special case we obtain a family $L_n subseteq {0,1}{2n}$ of languages with {rm nc}_{o(sqrt{n}log_2 n)}(L_n) &amp;=&amp; Omegabiggl(frac{n}{log_2 n}biggr), {rm nc}(L_n) + {rm nc}(overline{L_n}) &amp;=&amp; O(sqrt{n}), and hence nondeterministic communication with slightly restricted access to advice bits is almost quadratically weaker than nondeterminism that always gives correct answers (from the set {yes, no, }). As a consequence we obtain an almost optimal separation between Monte-Carlo communication and correct nondeterminism and answer a question of Beame and Lawry.},
journal = {SIAM J. Comput.},
month = jan,
pages = {43–68},
numpages = {26},
keywords = {communication complexity, nondeterminism}
}

@article{10.1137/S0097539702403773,
author = {Cramer, Ronald and Shoup, Victor},
title = {Design and Analysis of Practical Public-Key Encryption Schemes Secure against Adaptive Chosen Ciphertext Attack},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403773},
doi = {10.1137/S0097539702403773},
abstract = {A new public-key encryption scheme, along with several variants, is proposed and analyzed. The scheme and its variants are quite practical and are proved secure against adaptive chosen ciphertext attack under standard intractability assumptions. These appear to be the first public-key encryption schemes in the literature that are simultaneously practical and provably secure.},
journal = {SIAM J. Comput.},
month = jan,
pages = {167–226},
numpages = {60},
keywords = {public-key encryption, chosen ciphertext security, cryptography, decisional Diffie--Hellman assumption}
}

@article{10.1137/S0097539701424465,
author = {Cole, Richard and Hariharan, Ramesh},
title = {Faster Suffix Tree Construction with Missing Suffix Links},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701424465},
doi = {10.1137/S0097539701424465},
abstract = {We consider suffix tree construction for situations with missing suffix links. Two examples of such situations are suffix trees for parameterized strings and suffix trees for two-dimensional arrays. These trees also have the property that the node degrees may be large. We add a new back-propagation component to McCreight's algorithm and also give a high probability hashing scheme for large degrees. We show that these two features enable construction of suffix trees for general situations with missing suffix links in O(n) time, with high probability. This gives the first randomized linear time algorithm for constructing suffix trees for parameterized strings.},
journal = {SIAM J. Comput.},
month = jan,
pages = {26–42},
numpages = {17},
keywords = {dynamic perfect hashing, suffix tree, parameterized strings, two-dimensional suffix trees}
}

@article{10.1137/S0097539700375944,
author = {Babai, L\'{a}szl\'{o} and G\'{a}l, Anna and Kimmel, Peter G. and Lokam, Satyanarayana V.},
title = {Communication Complexity of Simultaneous Messages},
year = {2004},
issue_date = {2004},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {33},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700375944},
doi = {10.1137/S0097539700375944},
abstract = {In the multiparty communication game (CFL game) of Chandra, Furst, and Lipton [  Proceedings of the  15  th Annual ACM Symposium on Theory of Computing , Boston, MA, 1983, pp. 94--99]  k  players collaboratively evaluate a function  f (  x  0, . . . ,  x k -1) in which player  i  knows all inputs except  xi . The players have unlimited computational power. The objective is to minimize communication. In this paper, we study the SIMULTANEOUS MESSAGES (SM) model of multiparty communication complexity. The SM model is a restricted version of the CFL game in which the players are not allowed to communicate with each other. Instead, each of the  k  players simultaneously sends a message to a  referee , who sees none of the inputs. The referee then announces the function value.We prove lower and upper bounds on the SM complexity of several classes of explicit functions. Our lower bounds extend to randomized SM complexity via an entropy argument. A lemma establishing a tradeoff between average Hamming distance and range size for transformations of the Boolean cube might be of independent interest.Our lower bounds on SM complexity imply an exponential gap between the SM model and the CFL model for up to $(log n)^{1-epsilon}$ players for any $epsilon &gt; 0$. This separation is obtained by comparing the respective complexities of the Generalized Addressing Function, GAF  G ,  k , where  G  is a group of order  n . We also combine our lower bounds on SM complexity with the ideas of H\r{a}stad and Goldmann [  Comput. Complexity , 1 (1991), pp. 113--129] to derive superpolynomial lower bounds for certain depth-2 circuits computing a function related to the GAF function.We prove some counterintuitive upper bounds on SM complexity. We show that {sf GAF}$_{mathbb{Z}_2^t,3}$ has SM complexity $O(n^{0.92})$. When the number of players is at least $clog n$, for some constant  c &gt;0, our SM protocol for {sf GAF}$_{mathbb{Z}_2^t,k}$ has polylog(  n ) complexity. We also examine a class of functions defined by certain depth-2 circuits. This class includes the Generalized Inner Product function and Majority of Majorities. When the number of players is at least 2+log  n , we obtain polylog(  n ) upper bounds for this class of functions.},
journal = {SIAM J. Comput.},
month = jan,
pages = {137–166},
numpages = {30},
keywords = {group theory, communication complexity, lower bounds, circuit complexity}
}

@article{10.1137/S0097539799358835,
author = {Kumar, V. S. Anil and Ramesh, H.},
title = {Covering Rectilinear Polygons with Axis-Parallel Rectangles},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799358835},
doi = {10.1137/S0097539799358835},
abstract = {We give an $O(sqrt{log n})$ factor approximation algorithm for covering a rectilinear polygon with holes using axis-parallel rectangles. This is the first polynomial time approximation algorithm for this problem with an $o(log n)$ approximation factor.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1509–1541},
numpages = {33},
keywords = {covering polygons, approximation algorithms}
}

@article{10.1137/S009753979935476,
author = {Ambainis, Andris and Schulman, Leonard J. and Ta-Shma, Amnon and Vazirani, Umesh and Wigderson, Avi},
title = {The Quantum Communication Complexity of Sampling},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979935476},
doi = {10.1137/S009753979935476},
abstract = {Sampling is an important primitive in probabilistic and quantum algorithms.  In the spirit of communication complexity, given a function $f: X times Y rightarrow {0,1}$ and a probability distribution ${cal D}$ over $X times Y$, we define the sampling complexity of $(f, {cal D})$ as the minimum number of bits that Alice and Bob must communicate for Alice to pick $x in X$ and Bob to pick $y in Y$ as well as a value $z$ such that the resulting distribution of $(x,y,z)$ is close to the distribution $({cal D}, f({cal D}))$.In this paper we initiate the study of sampling complexity, in both the classical and quantum models. We give several variants of a definition. We completely characterize some of these variants and give upper and lower bounds on others. In particular, this allows us to establish an exponential gap between quantum and classical sampling complexity for the set-disjointness function.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1570–1585},
numpages = {16},
keywords = {quantum information theory, quantum communication complexity, communication complexity, the log-rank conjecture in communication complexity, set-disjointness}
}

@article{10.1137/S0097539799351018,
author = {Gathen, Joachim vonzur and Shparlinski, Igor and Sinclair, Alistair},
title = {Finding Points on Curves over Finite Fields},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799351018},
doi = {10.1137/S0097539799351018},
abstract = {We solve two computational problems concerning plane algebraic curves over finite fields: generating a uniformly random point, and finding all points deterministically in amortized polynomial time (over a prime field, for nonexceptional curves).},
journal = {SIAM J. Comput.},
month = jun,
pages = {1436–1448},
numpages = {13},
keywords = {finite fields, random sampling, probabilistic algorithms, algebraic curves, computer algebra, algebraic geometry}
}

@article{10.1137/S0097539798346652,
author = {Reif, John H. and Sun, Zheng},
title = {On Frictional Mechanical Systems and Their Computational Power},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798346652},
doi = {10.1137/S0097539798346652},
abstract = {In this paper we define a class of mechanical systems consisting of rigid objects (defined by linear or quadratic surface patches) connected by frictional contact linkages between surfaces. (This class of mechanisms is similar to the analytical engine developed by Babbage in the 1800s, except that we assume frictional surfaces instead of toothed gears.) We prove that a universal Turing Machine (TM) can be simulated by a (universal) frictional mechanical system in this class consisting of a constant number of parts. Our universal frictional mechanical system has the property that it can reach a distinguished final configuration through a sequence of legal movements if and only if the universal TM accepts the input string encoded by its initial configuration. There are two implications from this result. First, the robotic mover's problem is undecidable when there are frictional linkages. Second, a mechanical computer can be constructed that has the computational power of any conventional electronic computer and yet has only a constant number of mechanical parts. Previous constructions for mechanical computing devices (such as Babbage's analytical engine) either provided no general construction for finite state control or the control was provided by electronic devices (as was common in electromechanical computers such as Mark I subsequent to Turing's result). Our result seems to be the first to provide a general proof of the simulation of a universal TM via a purely mechanical mechanism.In addition, we discuss the universal frictional mechanical system in the context of an error model that allows an error up to $epsilon$ in each mechanical operation. We first show that, for a universal TM  M , a frictional mechanical system in this $epsilon$-error model can be constructed such that, given any space bound  S , the system can simulate the computation of  M  on any input string $omega$ if  M  decides $omega$ in space bound  S , provided that $epsilon &lt; 2^{-cS}$ for some constant  c . We also show that, for any universal TM  M  and space bound  S , there exists a frictional mechanical system in the $epsilon$-error model with $epsilon = Omega(1)$; it has  O (  S ) parts and can simulate  M  on any input $omega$ that  M  decides in space bound  S .},
journal = {SIAM J. Comput.},
month = jun,
pages = {1449–1474},
numpages = {26},
keywords = {complexity, motion planning, robotics, mechanical computing device}
}

@article{10.1137/S009753970342465X,
author = {Grolmusz, Vince},
title = {Computing Elementary Symmetric Polynomials with a Subpolynomial Number of Multiplications},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970342465X},
doi = {10.1137/S009753970342465X},
abstract = {Elementary symmetric polynomials $S_n^k$ are the building blocks of symmetric polynomials. In this work we prove that for constant $k$'s, $S_n^k$ modulo composite numbers m = p 1 p 2 can be computed using only n o(1) multiplications if the coefficients of monomials x i 1 x i 2. . . x ik are allowed to be 1 either mod p 1 or mod p 2 but not necessarily both. To the best of our knowledge, no previous result yielded even a sublinear (i.e., $n^{\varepsilon}$, $0<\varepsilon<1$) number of multiplications for similar tasks. Moreover, our algorithm fits in the model of the most restrictive depth-3 arithmetic circuits (homogeneous, multilinear, or the graph model). In contrast, by a lower bound of Nisan and Wigderson [ Comput. Complexity , 6 (1997), pp. 217--234], any homogeneous depth-3 circuit needs size $\Omega((n/2k)^{k/2})$ for computing $S_n^k$ modulo primes. Moreover, the number of multiplications in our algorithm remains sublinear while k = O (log log n ). Our results generalize for other nonprime-power composite moduli as well. The proof uses perfect hashing functions and the famous BBR polynomial of Barrington, Beigel, and Rudich.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1475–1487},
numpages = {13},
keywords = {arithmetic circuits, composite modulus, symmetric polynomials, algebraic algorithms}
}

@article{10.1137/S0097539702419662,
author = {Devillers, Olivier and Dujmovic, Vida and Everett, Hazel and Goaoc, Xavier and Lazard, Sylvain and Na, Hyeon-Suk and Petitjean, Sylvain},
title = {The Expected Number of 3D Visibility Events Is Linear},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702419662},
doi = {10.1137/S0097539702419662},
abstract = {In this paper, we show that, amongst $n$ uniformly distributed unit balls in $mathbb{R}^3$, the expected number of maximal nonoccluded line segments tangent to four balls is linear. Using our techniques we show a linear bound on the expected size of the visibility complex, a data structure encoding the visibility information of a scene, providing evidence that the storage requirement for this data structure is not necessarily prohibitive.  These results significantly improve the best previously known bounds of $O(n^{8/3})$ [F. Durand, G. Drettakis, and C. Puech, {ACM Transactions on Graphics}, 21 (2002), pp. 176--206].  Our results generalize in various directions. We show that the linear bound on the expected number of maximal nonoccluded line segments that are not too close to the boundary of the scene and tangent to four unit balls extends to balls of various but bounded radii, to polyhedra of bounded aspect ratio, and even to nonfat three-dimensional objects such as polygons of bounded aspect ratio. We also prove that our results extend to other distributions such as the Poisson distribution.  Finally, we indicate how our probabilistic analysis provides new insight on the expected size of other global visibility data structures, notably the aspect graph.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1586–1620},
numpages = {35},
keywords = {expected complexity, visual events, probabilistic analysis, computational geometry, three-dimensional visibility, visibility complex}
}

@article{10.1137/S0097539702417511,
author = {Asano, Tetsuo and Katoh, Naoki and Obokata, Koji and Tokuyama, Takeshi},
title = {Matrix Rounding under the <i>L<sub>p</sub></i>-Discrepancy Measure and Its Application to Digital Halftoning},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702417511},
doi = {10.1137/S0097539702417511},
abstract = {We study the problem of rounding a real-valued matrix into an integer-valued matrix to minimize an Lp-discrepancy measure between them. To define the Lp-discrepancy measure, we introduce a family ${cal F}$ of regions (rigid submatrices) of the matrix and consider a hypergraph defined by the family. The difficulty of the problem depends on the choice of the region family ${cal F}$. We first investigate the rounding problem by using integer programming problems with convex piecewise-linear objective functions and give some nontrivial upper bounds for the Lp discrepancy. We propose "laminar family" for constructing a practical and well-solvable class of ${cal F}$. Indeed, we show that the problem is solvable in polynomial time if ${cal F}$ is the union of two laminar families. Finally, we show that the matrix rounding using L1 discrepancy for the union of two laminar families is suitable for developing a high-quality digital-halftoning software.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1423–1435},
numpages = {13},
keywords = {approximation algorithm, network flow, discrepancy, matrix rounding, digital halftoning, linear programming, totally unimodular}
}

@article{10.1137/S0097539702416761,
author = {Bj\"{o}rklund, Andreas and Husfeldt, Thore},
title = {Finding a Path of Superlogarithmic Length},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702416761},
doi = {10.1137/S0097539702416761},
abstract = {We consider the problem of finding a long, simple path in an undirected graph.  We present a polynomial-time algorithm that finds a path of length $Omegabigl((log L/loglog L)^2bigr)$, where L denotes the length of the longest simple path in the graph. This establishes the performance ratio O(n(log log n/log n)2) for the longest path problem, where n denotes the number of vertices in the graph.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1395–1402},
numpages = {8},
keywords = {longest path, approximation algorithms, graph algorithms}
}

@article{10.1137/S0097539702415317,
author = {Ebert, Todd and Merkle, Wolfgang and Vollmer, Heribert},
title = {On the Autoreducibility of Random Sequences},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702415317},
doi = {10.1137/S0097539702415317},
abstract = {A binary sequence $A=A(0)A(1)ldots$ is called infinitely often (i.o.)~Turing-au-to-re-duc-ible if $A$~is reducible to itself via an oracle   Turing machine that never queries   its oracle at the current input, outputs either $A(x)$ or a   don't-know symbol on any given input~$x$, and outputs $A(x)$ for   infinitely many~$x$.  If in addition the oracle Turing machine terminates on all inputs and   oracles, $A$~is called i.o.~truth-table-autoreducible.     We obtain the somewhat counterintuitive result that every Martin-L"of random  sequence, in fact even every rec-random or p-random sequence, is i.o.~truth-table-autoreducible.   Furthermore, we investigate the question of how dense the set of guessed bits can be when i.o.~autoreducing a random sequence.  We show that rec-random sequences are never   i.o.~truth-table-autoreducible such that the set of guessed bits has   positive constant density in the limit and that a similar   assertion holds for Martin-L"of random sequences and   i.o.~Turing autoreducibility. On the other hand, we show that for any rational-valued computable function~$r$ that goes   nonascendingly to zero, any rec-random sequence is i.o.~truth-table-autoreducible such that on any prefix of length~$m$ at least   a fraction of~$r(m)$ of the $m$~bits in the prefix are guessed.     We include a self-contained account of the hat problem, a puzzle that has received some attention outside of theoretical computer science.   The hat problem asks for guessing bits of a finite sequence, thus illustrating the notion of i.o.~autoreducibility in a finite setting.   The solution to the hat problem is then used as a module in the proofs of the positive results on i.o.~autoreducibility.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1542–1569},
numpages = {28},
keywords = {Turing autoreducibility, truth-table autoreducibility, error-correcting codes, infinitely often autoreducibility, rec-random sequences, hypercube topology, Martin-L"of random sequences, density of guessed bits, p-random sequences, random sequences, hat problem, autoreducibility}
}

@article{10.1137/S0097539702411368,
author = {Aichholzer, Oswin and Aurenhammer, Franz and Krasser, Hannes and Brass, Peter},
title = {Pseudotriangulations from Surfaces  and a Novel Type of Edge Flip},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702411368},
doi = {10.1137/S0097539702411368},
abstract = {We prove that planar pseudotriangulations have realizations as polyhedral surfaces in three-space. Two main implications are presented.  The spatial embedding leads to a novel flip operation that allows for a drastic reduction of flip distances, especially between (full) triangulations. Moreover, several key results for triangulations, like flipping to optimality, (constrained) Delaunayhood, and a convex polytope representation, are extended to pseudotriangulations in a natural way.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1621–1653},
numpages = {33},
keywords = {surface realization, polytope representation, pseudotriangulation, locally convex function, flip distance, constrained regular complex}
}

@article{10.1137/S009753970240481X,
author = {Arge, Lars and Vitter, Jeffrey Scott},
title = {Optimal External Memory Interval Management},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970240481X},
doi = {10.1137/S009753970240481X},
abstract = {In this paper we present the external interval tree, an optimal external memory data structure for answering stabbing queries on a set of dynamically maintained intervals. The external interval tree can be used in an optimal solution to the dynamic interval management problem, which is a central problem for object-oriented and temporal databases and for constraint logic programming. Part of the structure uses a weight-balancing technique for efficient worst-case manipulation of balanced trees, which is of independent interest. The external interval tree, as well as our new balancing technique, have recently been used to develop several efficient external data structures.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1488–1508},
numpages = {21},
keywords = {data structures, stabbing queries, I/O efficient, interval management}
}

@article{10.1137/S0097539702402007,
author = {Crochemore, Maxime and Landau, Gad M. and Ziv-Ukelson, Michal},
title = {A Subquadratic Sequence Alignment Algorithm for Unrestricted Scoring Matrices},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702402007},
doi = {10.1137/S0097539702402007},
abstract = {Given two strings of size $n$ over a constant alphabet, the classical algorithm for computing the similarity between two sequences [D. Sankoff and J. B. Kruskal, eds., { Time Warps, String Edits, and Macromolecules}; Addison--Wesley, Reading, MA, 1983; T. F. Smith and M. S. Waterman,  J. Molec. Biol., 147 (1981), pp. 195--197] uses a dynamic programming matrix and compares the two strings in O( n 2) time. We address the challenge of computing the similarity of two strings in subquadratic time for metrics which use a scoring matrix of unrestricted weights. Our algorithm applies to both { local} and { global} similarity computations. The speed-up is achieved by dividing the dynamic programming matrix into variable sized blocks, as induced by Lempel--Ziv parsing of both strings, and utilizing the inherent periodic nature of both strings. This leads to an $O(n^2 / log n)$, algorithm for an input of constant alphabet size. For most texts, the time complexity is actually $O(h n^2 / log n)$, where $h le 1$ is the entropy of the text. We also present an algorithm for comparing two { run-length} encoded strings of length m and n, compressed into m' and n' runs, respectively, in O( m' n + n' m) complexity. This result extends to all distance or similarity scoring schemes that use an additive gap penalty.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1654–1673},
numpages = {20},
keywords = {dynamic programming, alignment, text compression, run length}
}

@article{10.1137/S0097539700376159,
author = {Fiat, Amos and Mendel, Manor},
title = {Better Algorithms for Unfair Metrical Task Systems and Applications},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700376159},
doi = {10.1137/S0097539700376159},
abstract = {Unfair metrical task systems are a generalization of online metrical task systems. In this paper we introduce new techniques to combine algorithms for unfair metrical task systems and apply these techniques to obtain improved randomized online algorithms for metrical task systems on arbitrary metric spaces.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1403–1422},
numpages = {20},
keywords = {randomized algorithms, online algorithms}
}

@article{10.1137/S0097539799350839,
author = {Fern\'{a}ndez-Baca, David and Lagergren, Jens},
title = {A Polynomial-Time Algorithm for Near-Perfect Phylogeny},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799350839},
doi = {10.1137/S0097539799350839},
abstract = {A parameterized version of the Steiner tree problem in phylogeny is defined, where the parameter measures the amount by which a phylogeny differs from "perfection."  This problem is shown to be solvable in polynomial time for any fixed value of the parameter.},
journal = {SIAM J. Comput.},
month = may,
pages = {1115–1127},
numpages = {13},
keywords = {phylogeny, parsimony, character-based methods, computational biology, Steiner tree, perfect phylogeny, algorithms, evolutionary trees}
}

@article{10.1137/S0097539702418759,
author = {Kochol, Martin and Lozin, Vadim and Randerath, Bert},
title = {The 3-Colorability Problem on Graphs with Maximum Degree Four},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702418759},
doi = {10.1137/S0097539702418759},
abstract = {The 3-colorability problem is known to be NP-complete in the class of graphs with maximum degree four. On the other hand, due to the celebrated theorem of Brooks, the problem has a polynomial-time solution for graphs with maximum degree three. To make the complexity gap more precise, we study a family of intermediate graph classes between these two extremes and classify all of them according to the computational complexity of the problem. In particular, we generalize Brooks's theorem in the case of 3-colorability to a larger class by showing that every connected graph in that class is 3-colorable, unless it is a complete graph on four vertices.},
journal = {SIAM J. Comput.},
month = may,
pages = {1128–1139},
numpages = {12},
keywords = {dichotomy, 3-colorability, polynomial algorithms, NP-completeness}
}

@article{10.1137/S0097539702417754,
author = {Glier, Oliver},
title = {Kolmogorov Complexity and Deterministic Context-Free Languages},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702417754},
doi = {10.1137/S0097539702417754},
abstract = {We deal with a criterion for deterministic context-free languages that was originally formulated by Li and Vit\'{a}nyi [SIAM J. Comput., 24 (1995), pp. 398--410]. Their result---called the KC-DCF lemma---relates Kolmogorov complexity to pushdown automata and works on a superset of examples compared to traditional iteration and pumping lemmas. Sadly, their KC-DCF lemma has a flaw. In this paper, we give a counterexample to the original KC-DCF lemma and also provide a corrected version.},
journal = {SIAM J. Comput.},
month = may,
pages = {1389–1394},
numpages = {6},
keywords = {deterministic context-free languages, Kolmogorov complexity, formal language theory}
}

@article{10.1137/S0097539702414026,
author = {Parnas, Michal and Ron, Dana and Rubinfeld, Ronitt},
title = {On Testing Convexity and Submodularity},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702414026},
doi = {10.1137/S0097539702414026},
abstract = {Convex and submodular functions play an important role in many applications, and in particular in combinatorial optimization. Here we study two special cases: convexity in one dimension and submodularity in two dimensions. The latter type of functions are equivalent to the well-known Monge matrices. A matrix $V = {v_{i,j}}_{i,j=0}^{i=n_1,j=n_2}$ is called a Monge matrix if for every $0 leq i &lt; i' leq n_1$ and $0 leq j &lt; j' leq n_2$ we have $v_{i,j}+v_{i',j'} le v_{i,j'}+v_{i',j}$. If inequality holds in the opposite direction, then V is an inverse Monge matrix (supermodular function). Many problems, such as the traveling salesperson problem and various transportation problems, can be solved more efficiently if the input is a Monge matrix.In this work we present testing algorithms for the above properties. A testing algorithm for a predetermined property $cal P$ is  given query access to an unknown function f and a distance parameter $epsilon$. The algorithm should accept f with high probability if it has the property $cal P$ and reject it with high probability if more than an $epsilon$-fraction of the function values should be modified so that f obtains the property. Our algorithm for testing whether a 1-dimensional function $f:[n] rightarrow mathbb{R}$ is convex (concave) has query complexity and running time of $Oleft((log n) /epsilonright)$. Our algorithm for testing whether an n1 \texttimes{} n2 matrix V is a Monge (inverse Monge) matrix has query complexity and running time of $Oleft((log n_1cdotlog n_2) /epsilonright)$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1158–1184},
numpages = {27},
keywords = {approximation algorithms, convex functions, randomized algorithms, Monge matrices, property testing}
}

@article{10.1137/S0097539702410053,
author = {Shen, Jian and Sheng, Li and Wu, Jie},
title = {Searching for Sorted Sequences of Kings in Tournaments},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702410053},
doi = {10.1137/S0097539702410053},
abstract = {A tournament Tn is an orientation of a complete graph on n vertices. A king in a tournament is a vertex from which every other vertex is reachable by a path of length at most 2. A sorted sequence of kings in a tournament Tn is an ordered list of its vertices u1, u2, . . ., un such that ui dominates $u_{i+1}$ ($u_i rightarrow u_{i+1}$) and $u_i$ is a king in the subtournament induced by ${u_j: i le j le n}$ for each i=1,2, . . .,n-1. In particular, if Tn is transitive, searching for a sorted sequence of kings in Tn is equivalent to sorting a set of n numbers. In this paper, we try to find a sorted sequence of kings in a general tournament by asking the following type of binary question: "What is the orientation of the edge between two specified vertices u, v?" The cost for finding a sorted sequence of kings is the minimum number of binary questions asked in order to guarantee the finding of a sorted sequence of kings. Using an adversary argument proposed in this paper, we show that the cost for finding a sorted sequence of kings in Tn is $Theta(n^{3/2})$ in the worst case, thus settling the order of magnitude of this question. We also show that the cost for finding a king in Tn is $Omega(n^{4/3})$ and O(n3/2) in the worst case. Finally, we show a connection between a sorted sequence of kings and a median order in a tournament.},
journal = {SIAM J. Comput.},
month = may,
pages = {1201–1209},
numpages = {9},
keywords = {king, divide-and-conquer algorithm, sorted sequence of kings, tournament, recursive relation, adversary argument}
}

@article{10.1137/S0097539702408223,
author = {Kohayakawa, Y. and R\"{o}dl, V. and Thoma, L.},
title = {An Optimal Algorithm for Checking Regularity},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702408223},
doi = {10.1137/S0097539702408223},
abstract = {We present a deterministic algorithm ${cal A}$ that, in O(m2) time, verifies whether a given m by m bipartite graph G is regular, in the sense of Szemer\'{e}di [Regular partitions of graphs, in Probl\`{e}mes Combinatoires et Th\'{e}orie des Graphes (Orsay, 1976), Colloques Internationaux CNRS 260, CNRS, Paris, 1978, pp. 399--401]. In the case in which G is not regular enough, our algorithm outputs a witness to this irregularity.  Algorithm ${cal A}$ may be used as a subroutine in an algorithm that finds an $varepsilon$-regular partition of a given n-vertex graph $Gamma$ in time O(n2). This time complexity is optimal, up to a constant factor, and improves upon the bound O(M(n)), proved by Alon et al. [The algorithmic aspects of the regularity lemma, J. Algorithms, 16 (1994),  pp. 80--109], where M(n)=O(n2.376) is the time required to square a 0--1 matrix over the integers.  Our approach is elementary, except that it makes use of linear-sized expanders to accomplish a suitable form of deterministic sampling.},
journal = {SIAM J. Comput.},
month = may,
pages = {1210–1235},
numpages = {26},
keywords = {quasi-randomness, deterministic sampling, regular pairs, expander graphs, Szemer\'{e}di's regularity lemma}
}

@article{10.1137/S0097539702406388,
author = {Y, Joseph and Leung, .-T. and Pinedo, Michael},
title = {Minimizing Total Completion Time on Parallel Machines with Deadline Constraints},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702406388},
doi = {10.1137/S0097539702406388},
abstract = {Consider n independent jobs and m identical machines in parallel. Job j has a processing time pj and a deadline $bar{d}_j$. It must complete its processing before or at its deadline. All jobs are available for processing at time t=0 and preemptions are allowed. A set of jobs is said to be feasible if there exists a schedule that meets all the deadlines; such a schedule is called a feasible schedule. Given a feasible set of jobs, our goal is to find a schedule that minimizes the  total completion time $sum C_j$. In the classical $alpha mid beta mid gamma$ scheduling notation this problem is referred to as $P mid prmt, bar{d}_j mid sum C_j$. Lawler (Recent Results in the Theory of Machine Scheduling, in Mathematical Programming: The State of the Art, A. Bachem, M. Gr\"{o}tschel, and B. Korte, eds., Springer, Berlin, 1982, pp. 202--234) raised the question of whether or not the problem is NP-hard. In this paper we present a polynomial-time algorithm for every $m ge 2$, and we show that the more general problem with m unrelated machines, i.e., $R mid prmt, bar{d}_j mid sum C_j$, is strongly NP-hard.},
journal = {SIAM J. Comput.},
month = may,
pages = {1370–1388},
numpages = {19},
keywords = {preemptive scheduling, maximum lateness, unrelated machines, deadline constraints, polynomial-time algorithm, total completion time, parallel and identical machines}
}

@article{10.1137/S0097539702405954,
author = {Shpilka, Amir},
title = {Lower Bounds for Matrix Product},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702405954},
doi = {10.1137/S0097539702405954},
abstract = {We prove lower bounds on the number of product gates in bilinear and quadratic circuits that compute the product of two n × n matrices over finite fields. In particular we obtain the following results: We show that the number of product gates in any bilinear (or quadratic ) circuit that computes the product of two n × n matrices over ${rm GF}(2)$ is at least 3 n 2 - o ( n 2). We show that the number of product gates in any bilinear circuit that computes the product of two n × n matrices over ${rm GF}(q)$ is at least $(2.5 + frac{1.5}{q3 -1})n2 -o(n2)$. These results improve the former results of [N. H. Bshouty, SIAM J. Comput., 18 (1989), pp. 759--765; M. Bl\"{a}ser, Proceedings of the 40 th Annual IEEE Symposium on Foundations of Computer Science, IEEE Computer Society, Los Alamitos, CA, 1999, pp. 45--50], who proved lower bounds of 2.5 n 2 - o( n 2).},
journal = {SIAM J. Comput.},
month = may,
pages = {1185–1200},
numpages = {16},
keywords = {linear codes, matrix product, lower bounds}
}

@article{10.1137/S0097539702403098,
author = {Cohen, Edith and Halperin, Eran and Kaplan, Haim and Zwick, Uri},
title = {Reachability and Distance Queries via 2-Hop Labels},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403098},
doi = {10.1137/S0097539702403098},
abstract = {Reachability and distance queries in graphs are fundamental to numerous applications, ranging from geographic navigation systems to Internet routing. Some of these applications involve huge graphs and yet require fast query answering. We propose a new data structure for representing all distances in a graph. The data structure is  distributed  in the sense that it may be viewed as assigning  labels  to the vertices, such that a query involving vertices  u  and  v  may be answered using only the labels of  u  and  v . Our labels are based on 2-  hop covers  of the shortest paths, or of all paths, in a graph. For shortest paths, such a cover is a collection  S  of shortest paths such that, for every two vertices  u  and  v , there is a shortest path from  u  to  v  that is a concatenation of  two  paths from  S . We describe an efficient algorithm for finding an  almost optimal  2-hop cover of a given collection of paths. Our approach is general and can be applied to directed or undirected graphs, exact or approximate shortest paths, or to reachability queries.We study the proposed data structure using a combination of theoretical and experimental means. We implemented our algorithm and checked the size of the resulting data structure on several real-life networks from different application areas. Our experiments show that the total size of the labels is typically not much larger than the network itself, and is usually considerably smaller than an explicit representation of the transitive closure of the network.},
journal = {SIAM J. Comput.},
month = may,
pages = {1338–1355},
numpages = {18},
keywords = {shortest-path queries, reachability queries, 2-hop labels, distance labels}
}

@article{10.1137/S0097539702402147,
author = {Raz, Ran},
title = {On the Complexity of Matrix Product},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702402147},
doi = {10.1137/S0097539702402147},
abstract = {Our main result is a lower bound of $Omega(m^2 log m)$ for the size of any arithmetic circuit for the product of two matrices, over the real or complex numbers, as long as the circuit does not use products with field elements of absolute value larger than 1 (where m \texttimes{} m is the size of each matrix). That is, our lower bound is superlinear in the number of inputs and is applied for circuits that use addition gates, product gates, and products with field elements of absolute value up to 1. We also prove size-depth tradeoffs for such circuits: We show that if a circuit, as above, is of depth d, then its size is  $Omega(m^{2+ 1/O(d)})$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1356–1369},
numpages = {14},
keywords = {arithmetic circuits, circuit complexity, algebraic complexity, singular values, bounded coefficients model, lower bounds}
}

@article{10.1137/S0097539701417723,
author = {Lutz, Jack H.},
title = {Dimension in Complexity Classes},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701417723},
doi = {10.1137/S0097539701417723},
abstract = {A theory of resource-bounded dimension is developed using gales, which are natural generalizations of martingales. When the resource bound $Delta$ (a parameter of the theory) is unrestricted, the resulting dimension is precisely the classical Hausdorff dimension (sometimes called fractal dimension). Other choices of the parameter $Delta$ yield internal dimension theories in E, E 2, ESPACE, and other complexity classes, and in the class of all decidable problems. In general, if $mathcal{C}$ is such a class, then every set X of languages has a dimension in $mathcal{C}$, which is a real number $dim (X mid mathcal{C}) in [0, 1]$. Along with the elements of this theory, two preliminary applications are presented: For every real number $0 le alpha le frac 1 2$, the set ${rm FREQ}(le alpha)$, consisting of all languages that asymptotically contain at most $alpha$ of all strings, has dimension $mathcal{H}(alpha)$---the binary entropy of $alpha$---in E and in E 2. For every real number $0 le alpha le 1$, the set ${rm SIZE}(alpha frac {2n} n)$, consisting of all languages decidable by Boolean circuits of at most $alpha frac {2n} n$ gates, has dimension $alpha$ in ESPACE.},
journal = {SIAM J. Comput.},
month = may,
pages = {1236–1259},
numpages = {24},
keywords = {Hausdorff dimension, complexity classes, martingales, circuit-size complexity, gales, resource-bounded dimension, computational complexity}
}

@article{10.1137/S0097539701399654,
author = {Arora, Sanjeev and Karakostas, George},
title = {Approximation Schemes for Minimum Latency Problems},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701399654},
doi = {10.1137/S0097539701399654},
abstract = {The minimum latency problem, also known as the traveling repairman problem, is a variant of the traveling salesman problem in which the starting node of the tour is given and the goal is to minimize the sum of the arrival times at the other nodes. We present a quasi-polynomial time approximation scheme (QPTAS) for this problem when the instance is a weighted tree, when the nodes lie in $mathbb{R}^d$ for some fixed d, and for planar graphs. We also present a polynomial time constant factor approximation algorithm for the general metric case. The currently best polynomial time approximation algorithm for general metrics, due to Goemans and Kleinberg, computes a 3.59-approximation.},
journal = {SIAM J. Comput.},
month = may,
pages = {1317–1337},
numpages = {21},
keywords = {minimum latency tour, traveling repairman, search ratio, randomized search ratio, quasi-polynomial approximation schemes, approximation algorithms, vehicle routing}
}

@article{10.1137/S0097539701399551,
author = {Berenbrink, Petra and Friedetzky, Tom and Goldberg, Leslie Ann},
title = {The Natural Work-Stealing Algorithm is Stable},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701399551},
doi = {10.1137/S0097539701399551},
abstract = {In this paper we analyze a very simple dynamic work-stealing algorithm. In the work-generation model, there are  n  (work)  generators . A  generator-allocation function  is simply a function from the  n  generators to the  n  processors. We consider a fixed, but arbitrary, distribution $cal D$ over generator-allocation functions. During each time step of our process, a generator-allocation function  h  is chosen from $cal D$, and the generators are allocated to the processors according to  h . Each generator may then generate a unit-time task, which it inserts into the queue of its host processor. It generates such a task independently with probability $lambda$. After the new tasks are generated, each processor removes one task from its queue and services it. For many choices of $cal D$, the work-generation model allows the load to become arbitrarily imbalanced, even when $lambda&lt;1$. For example, $cal D$ could be the point distribution containing a single function  h  which allocates all of the generators to just one processor. For this choice of $cal D$, the chosen processor receives around $lambda n$ units of work at each step and services one. The natural work-stealing algorithm that we analyze is widely used in practical applications and works as follows. During each time step, each  empty  processor (with no work to do) sends a request to a randomly selected other processor. Any  nonempty  processor having received at least one such request in turn decides (again randomly) in favor of one of the requests. The number of tasks which are transferred from the nonempty processor to the empty one is determined by the so-called  work-stealing function   f . In particular, if a processor that accepts a request has $ell$ tasks stored in its queue, then $f(ell)$ tasks are transferred to the currently empty one. A popular work-stealing function is $f(ell)=lfloor ell/2rfloor$, which transfers (roughly) half of the tasks. We analyze the  long-term behavior  of the system as a function of $lambda$ and  f . We show that the system is  stable  for any constant generation rate $lambda&lt;1$ and for a wide class of functions  f . Most intuitively sensible functions are included in this class (for example, every monotonically nondecreasing function  f  which satisfies $0 leq f(ell)leq ell/2$ and $f(ell)=omega(1)$ as a function of $ell$ is included). Furthermore, we give  upper bounds  on the average system load (as a function of  f  and  n ). Our proof techniques combine Lyapunov function arguments with domination arguments, which are needed to cope with dependency.},
journal = {SIAM J. Comput.},
month = may,
pages = {1260–1279},
numpages = {20},
keywords = {work-stealing, dynamic, stability}
}

@article{10.1137/S009753970139272X,
author = {P\"{u}schel, Markus and Moura, Jos\'{e} M. F.},
title = {The Algebraic Approach to the Discrete Cosine and Sine Transforms and Their Fast Algorithms},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970139272X},
doi = {10.1137/S009753970139272X},
abstract = {It is known that the discrete Fourier transform (DFT) used in digital signal processing can be characterized in the framework of the representation theory of algebras, namely, as the decomposition matrix for the regular module ${mathbb{C}}[Z_n] = {mathbb{C}}[x]/(x^n - 1)$. This characterization provides deep insight into the DFT and can be used to derive and understand the structure of its fast algorithms.  In this paper we present an algebraic characterization of the important class of discrete cosine and sine transforms as decomposition matrices of certain regular modules associated with four series of Chebyshev polynomials. Then we derive most of their known algorithms by pure algebraic means. We identify the mathematical principle behind each algorithm and give insight into its structure. Our results show that the connection between algebra and digital signal processing is stronger than previously understood.},
journal = {SIAM J. Comput.},
month = may,
pages = {1280–1316},
numpages = {37},
keywords = {group representation, discrete Fourier transform (DFT), discrete sine transform (DST), algebra representation, discrete trigonometric transform (DTT), Chebyshev polynomial, polynomial transform, discrete cosine transform (DCT), FFT, symmetry, fast algorithm}
}

@article{10.1137/S0097539700379644,
author = {Aaronson, Scott},
title = {Algorithms for Boolean Function Query Properties},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700379644},
doi = {10.1137/S0097539700379644},
abstract = {We investigate efficient algorithms for computing Boolean function properties relevant to query complexity. Such properties include, for example, deterministic, randomized, and quantum query complexities; block sensitivity; certificate complexity; and degree as a real polynomial. The algorithms compute the properties, given an n-variable functions truth table (of size N=2 n) as input. Our main results are the following: O ( N log2 3 log N ) algorithms for many common properties, an O ( N log2 5 log N ) algorithm for block sensitivity, an O ( N ) algorithm for testing quasi symmetry, a notion of a tree decomposition of a Boolean function, proof that the decomposition is unique, and an O ( N log2 3 log N ) algorithm for finding it, a subexponential-time approximation algorithm for space-bounded quantum query complexity. To develop this algorithm, we give a new way to search systematically through unitary matrices using finite-precision arithmetic. The algorithms discussed have been implemented in a linkable library.},
journal = {SIAM J. Comput.},
month = may,
pages = {1140–1157},
numpages = {18},
keywords = {query complexity, Boolean function, truth table, algorithm, quantum computation}
}

@article{10.1137/S009753970240447X,
author = {Bar-Noy, Amotz and Ladner, Richard E.},
title = {Windows Scheduling Problems for Broadcast Systems},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970240447X},
doi = {10.1137/S009753970240447X},
abstract = {The windows scheduling problem is defined by the positive integers n, h, and w1, ...,wn. There are n pages where the window wi is associated with page i, and h is the number of  slotted channels available for broadcasting the pages. A schedule that solves the problem assigns pages to slots such that the gap between any two consecutive appearances of page i is at most wi slots. We investigate two optimization problems. (i) The optimal windows scheduling problem: given w1, ..., wn find a schedule in which h is minimized. (ii) The optimal harmonic windows scheduling problem: given h find a schedule for the windows wi = i in which n is maximized. The former is a formulation of the problem of minimizing the bandwidth in push systems that support guaranteed delay, and the latter is a formulation of the problem of minimizing the startup delay in media-on-demand systems. For the optimal windows scheduling problem we present an algorithm that constructs asymptotically close to optimal schedules, and for the optimal harmonic windows scheduling problem we show how to achieve the largest known n's for all values of h.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1091–1113},
numpages = {23},
keywords = {broadcast systems, push systems, windows scheduling, scheduling algorithms, media-on-demand systems}
}

@article{10.5555/639069.773507,
author = {Mettu, Ramgopal R. and Plaxton, C. Greg},
title = {The Online Median Problem},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
abstract = {We introduce a natural variant of the (metric uncapacitated) k-median problem that we call the online median problem.  Whereas the k-median problem involves optimizing the simultaneous placement of k facilities, the online median problem imposes the following additional constraints: the facilities are placed one at a time, a facility cannot be moved once it is placed, and the total number of facilities to be placed, k, is not known in advance.  The objective of an online median algorithm is to minimize the competitive ratio, that is, the worst-case ratio of the cost of an online placement to that of an optimal offline placement.  Our main result is a constant-competitive algorithm for the online median problem running in time that is linear in the input size.  In addition, we present a related, though substantially simpler, constant-factor approximation algorithm for the (metric uncapacitated) facility location problem that runs in time linear in the input size.  The latter algorithm is similar in spirit to the recent primal-dual-based facility location algorithm of Jain and Vazirani, but our approach is more elementary and yields an improved running time. While our primary focus is on problems which ask us to minimize the weighted average service distance to facilities, we also show that our results can be generalized to hold, to within constant factors, for more general objective functions. For example, we show that all of our approximation results hold, to within constant factors, for the k-means objective function.},
journal = {SIAM J. Comput.},
month = mar,
pages = {816–832},
numpages = {17},
keywords = {$k$-means, $k$-median, approximation algorithms, clustering, discrete location theory, facility location}
}

@article{10.5555/639069.639088,
author = {Koltun, Vladlen and Sharir, Micha},
title = {3-Dimensional Euclidean Voronoi Diagrams of  Lines with a Fixed Number of Orientations},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
abstract = {We show that the combinatorial complexity of the Euclidean Voronoi diagram of $n$ lines in $mathbb{R}^3$ that have at most c distinct orientations is $O(c^3n^{2+varepsilon})$ for any $varepsilon&gt;0$. This result is a step toward proving the long-standing conjecture that the Euclidean Voronoi diagram of lines in three dimensions has near-quadratic complexity. It provides the first natural instance in which this conjecture is shown to hold. In a broader context, our result adds a natural instance to the (rather small) pool of instances of general 3-dimensional Voronoi diagrams for which near-quadratic complexity bounds are known.},
journal = {SIAM J. Comput.},
month = mar,
pages = {616–642},
numpages = {27},
keywords = {Voronoi diagrams, arrangements, computational geometry, lines in space}
}

@article{10.1137/S0097539799366340,
author = {Arya, Sunil and Fu, Ho-Yam Addy},
title = {Expected-Case Complexity of Approximate Nearest Neighbor Searching},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799366340},
doi = {10.1137/S0097539799366340},
abstract = {Most research in algorithms for geometric query problems has focused on their worst-case performance. However, when information on the query distribution is available, the alternative paradigm of designing and analyzing algorithms from the perspective of expected-case performance appears more attractive. We study the approximate nearest neighbor problem from this perspective.As a first step in this direction, we assume that the query points are sampled uniformly from a hypercube that encloses all the data points; however, we make no assumption on the distribution of the data points.  We show that with a simple partition tree, called the sliding-midpoint tree, it is possible to achieve linear space and logarithmic query time in the expected case; in contrast, the data structures known to achieve linear space and logarithmic query time in the worst case are complex, and algorithms on them run more slowly in practice. Moreover, we prove that the sliding-midpoint tree achieves optimal expected query time in a certain class of algorithms.},
journal = {SIAM J. Comput.},
month = mar,
pages = {793–815},
numpages = {23},
keywords = {priority search, approximation, expected-case analysis, sliding-midpoint tree, nearest neighbor searching}
}

@article{10.1137/S0097539798344847,
author = {\c{C}am, Hasan},
title = {Rearrangeability of $(2\protectn-1)$-Stage Shuffle-Exchange Networks},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798344847},
doi = {10.1137/S0097539798344847},
abstract = {Rearrangeable networks can realize each and every permutation in one pass through the network. Shuffle-exchange networks  provide an efficient interconnection scheme for implementing various types of parallel processes. Whether (2n)-stage  shuffle-exchange networks with N= 2n  inputs/outputs are rearrangeable  has remained an open question for approximately three  decades. This question has been answered affirmatively in this paper. An important corollary of the main result is the proof that two passes through an Omega network are sufficient and necessary to implement any permutation. In obtaining the main results of this paper, frames that look like grids with horizontal links of different lengths are shown to be remarkable tools for identifying and characterizing the binary matrix representations of permutations.},
journal = {SIAM J. Comput.},
month = mar,
pages = {557–585},
numpages = {29},
keywords = {rearrangeable network, frames, shuffle-exchange network, permutations, balanced matrices}
}

@article{10.1137/S0097539702410697,
author = {Braun, Oliver and Schmidt, G\"{u}nter},
title = {Parallel Processor Scheduling with Limited Number of Preemptions},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702410697},
doi = {10.1137/S0097539702410697},
abstract = {In this paper, we compare the makespan of preemptive and i-preemptive schedules where only a limited number i of preemptions is allowed. The problem is to schedule n independent jobs on m identical processors that operate in parallel. The objective is to minimize the makespan, i.e., the completion time of the last job that finishes. We show that the ratio of the optimal i-preemptive schedule length ${C_{max}^{ip^*}}$ versus the optimal preemptive schedule length ${C_{max}^{p^*}}$ is bounded from above by ${C_{max}^{ip^*}} le {( 2 - 2 / (m/(i+1) + 1) )} {C_{max}^{p^*}}$. Furthermore, we show that the ratio of the length ${C_{max}^{LPT}}$ of a nonpreemptive schedule following the {it longest processing time (LPT)} rule versus the optimal preemptive schedule length ${C_{max}^{p^*}}$ is bounded from above by exactly the same bound when i=0.},
journal = {SIAM J. Comput.},
month = mar,
pages = {671–680},
numpages = {10},
keywords = {parallel processor scheduling, longest processing time rule, preemptive scheduling, nonpreemptive scheduling, schedule length, worst-case analysis, $i$-preemptive scheduling}
}

@article{10.1137/S0097539702407345,
author = {Wolf, Ronald de},
title = {Nondeterministic Quantum Query and Communication Complexities},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702407345},
doi = {10.1137/S0097539702407345},
abstract = {We study nondeterministic quantum algorithms for Boolean functions f. Such algorithms have positive acceptance probability on input x iff f(x)=1. In the setting of query complexity, we show that the nondeterministic quantum complexity of a Boolean function is equal to its "nondeterministic polynomial" degree. We also prove a quantum-vs.-classical gap of 1 vs. n for nondeterministic query complexity for a total function. In the setting of communication complexity, we show that the nondeterministic quantum complexity of a two-party function is equal to the logarithm of the rank of a nondeterministic version of the communication matrix. This implies that the quantum communication complexities of the equality and disjointness functions are n+1 if we do not allow any error probability. We also exhibit a total function in which the nondeterministic quantum communication complexity is exponentially smaller than its classical counterpart.},
journal = {SIAM J. Comput.},
month = mar,
pages = {681–699},
numpages = {19},
keywords = {query complexity, communication complexity, nondeterminism, quantum computing}
}

@article{10.1137/S0097539702405139,
author = {Eidenbenz, Stephan J. and Widmayer, Peter},
title = {An Approximation Algorithm for Minimum Convex Cover with Logarithmic Performance Guarantee},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702405139},
doi = {10.1137/S0097539702405139},
abstract = {The problem MINIMUM CONVEX COVER of covering a given polygon with a minimum number of (possibly overlapping) convex polygons is known to be NP-hard, even for polygons without holes [J. C. Culberson and R. A. Reckhow, J. Algorithms, 17 (1994), pp. 2--44]. We propose a polynomial-time approximation algorithm for this problem for polygons with or without holes that achieves an approximation ratio of O(log n), where n is the number of vertices in the input polygon. To obtain this result, we first show that an optimum solution of a restricted version of this problem, where the vertices of the convex polygons may lie only on a certain grid, contains at most three times as many convex polygons as the optimum solution of the unrestricted problem. As a second step, we use dynamic programming to obtain a convex polygon which is maximum with respect to the number of "basic triangles" that are not yet covered by another convex polygon. We obtain a solution that is at most a logarithmic factor off the optimum by iteratively applying our dynamic programming algorithm. Furthermore, we show that MINIMUM CONVEX COVER is APX-hard; i.e., there exists a constant $delta &gt;0$ such that no polynomial-time algorithm can achieve an approximation ratio of $1+delta$. We obtain this result by analyzing and slightly modifying an already existing reduction [J. C. Culberson and R. A. Reckhow, J. Algorithms, 17 (1994), pp. 2--44].},
journal = {SIAM J. Comput.},
month = mar,
pages = {654–670},
numpages = {17},
keywords = {convex cover, dynamic programming, approximation algorithms, inapproximability, art gallery}
}

@article{10.1137/S0097539702404389,
author = {Chan, Timothy M.},
title = {Semi-Online Maintenance of Geometric Optima and Measures},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702404389},
doi = {10.1137/S0097539702404389},
abstract = {We give the first nontrivial worst-case results for dynamic versions of various basic geometric optimization and measure problems under the semi-online model, where during the insertion of an object we are told when the object is to be deleted.  Problems that we can solve with sublinear update time include the Hausdorff distance of two point sets, discrete 1-center, largest empty circle, convex hull volume in three dimensions, volume of the union of axis-parallel cubes, and minimum enclosing rectangle.  The decision versions of the Hausdorff distance and discrete 1-center problems can be solved fully dynamically.  Some applications are mentioned.},
journal = {SIAM J. Comput.},
month = mar,
pages = {700–716},
numpages = {17},
keywords = {dynamic data structures, computational geometry}
}

@article{10.1137/S0097539702403438,
author = {Rudin, John F. and Chandrasekaran, R.},
title = {Improved Bounds for the Online Scheduling Problem},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403438},
doi = {10.1137/S0097539702403438},
abstract = {The problem considered here is the same as the one discussed in [G. Galambos and G. J. Woeginger, eds., SIAM J. Comput., 22 (1993), pp. 349--355]. It is an m-machine online scheduling problem in which we wish to minimize the competitive ratio for the makespan objective. In this paper, we show that $sqrt{3}$ is a lower bound on this competitive ratio for m=4. In particular, we show how to force a lower bound of $sqrt{3,}-epsilon $ for any positive $epsilon $. This reduces the gap between the performance of known algorithms [S. Albers, in Proceedings of the 29th Annual ACM Symposium on Theory of Computing, ACM, New York, 1997, pp. 130--139] and the lower bound. The method used introduces an approach to building the task master's strategy.},
journal = {SIAM J. Comput.},
month = mar,
pages = {717–735},
numpages = {19},
keywords = {scheduling, lower bound, online, competitive ratio}
}

@article{10.1137/S0097539701398521,
author = {Boneh, Dan and Franklin, Matthew},
title = {Identity-Based Encryption from the Weil Pairing},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701398521},
doi = {10.1137/S0097539701398521},
abstract = {We propose a fully functional identity-based encryption (IBE) scheme. The scheme has chosen ciphertext security in the random oracle model assuming a variant of the computational Diffie--Hellman problem.  Our system is based on bilinear maps between groups.  The Weil pairing on elliptic curves is an example of such a map.  We give precise definitions for secure IBE schemes and give several applications for such systems.},
journal = {SIAM J. Comput.},
month = mar,
pages = {586–615},
numpages = {30},
keywords = {escrow ElGamal, bilinear maps, elliptic curve cryptography, identity-based encryption, Tate pairing, Weil pairing}
}

@article{10.1137/S0097539701391592,
author = {Husfeldt, Thore and Rauhe, Theis},
title = {New Lower Bound Techniques for Dynamic Partial Sums and Related Problems},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701391592},
doi = {10.1137/S0097539701391592},
abstract = {We study the complexity of the dynamic partial sum problem in the cell-probe model.  We give the model access to nondeterministic queries and prove that the problem remains hard. We give the model access to the right answer $pm 1$ as an oracle and prove that the problem remains hard. This suggests which kind of information is hard to maintain.  From these results, we derive a number of lower bounds for dynamic algorithms and data structures: We prove lower bounds for dynamic algorithms for existential range queries, reachability in directed graphs, planarity testing, planar point location, incremental parsing, and fundamental data structure problems like maintaining the majority of the prefixes of a string of bits.  We prove a lower bound for reachability in grid graphs in terms of the graph's width. We characterize the complexity of maintaining the value of any symmetric function on the prefixes of a bit string.},
journal = {SIAM J. Comput.},
month = mar,
pages = {736–753},
numpages = {18},
keywords = {cell-probe model, data structure, partial sum, dynamic algorithm}
}

@article{10.1137/S0097539700377177,
author = {El-Mabrouk, Nadia and Sankoff, David},
title = {The Reconstruction of Doubled Genomes},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377177},
doi = {10.1137/S0097539700377177},
abstract = {The genome can be modeled as a set of strings (chromosomes) of distinguished elements called genes.  Genome duplication is an important source of new gene functions and novel physiological pathways. Originally (ancestrally), a duplicated genome contains two identical copies of each chromosome, but through the genomic rearrangement mutational processes of reciprocal translocation (prefix and/or suffix exchanges between chromosomes) and substring reversals, this simple doubled structure is disrupted.  At the time of observation, each of the chromosomes resulting from the accumulation of rearrangements can be decomposed into a succession of conserved segments, such that each segment appears exactly twice in the genome.  We present exact algorithms for reconstructing the ancestral doubled genome in linear time, minimizing the number of rearrangement mutations required to derive the observed order of genes along the present-day chromosomes.  Somewhat different techniques are required for a translocations-only model, a translocations/reversals model, both of these in the multichromosomal context (eukaryotic nuclear genomes), and a reversals-only model for single chromosome prokaryotic and organellar genomes.  We apply these methods to the yeast genome, which is thought to have doubled, and to the liverwort mitochondrial genome, whose duplicate genes are unlikely to have arisen by genome doubling.},
journal = {SIAM J. Comput.},
month = mar,
pages = {754–792},
numpages = {39},
keywords = {translocation, signed genes, reversal, exact polynomial algorithms, genome rearrangement, Hannenhalli--Pevzner graph, genome duplication}
}

@article{10.1137/S0097539700370084,
author = {Eppstein, David},
title = {Setting Parameters by Example},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700370084},
doi = {10.1137/S0097539700370084},
abstract = {We introduce a class of "inverse parametric optimization" problems, in which one is given both a parametric optimization problem and a desired optimal solution; the task is to determine parameter values that lead to the given solution.  We describe algorithms for solving such problems for minimum spanning trees, shortest paths, and other "optimal subgraph" problems and discuss applications in multicast routing, vehicle path planning, resource allocation, and board game programming.},
journal = {SIAM J. Comput.},
month = mar,
pages = {643–653},
numpages = {11},
keywords = {alpha-beta search, parametric search, randomized algorithms, inverse optimization, minimum spanning tree, shortest paths, ellipsoid method, vehicle routing, evaluation function, adaptive user interfaces}
}

@article{10.1137/S0097539799363359,
author = {Khuller, Samir and Bhatia, Randeep and Pless, Robert},
title = {On Local Search and Placement of Meters in Networks},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799363359},
doi = {10.1137/S0097539799363359},
abstract = {This work is motivated by the problem of placing pressure-meters in fluid networks. The problem is formally defined in graph-theoretic terms as follows. Given a graph, find a cotree (complement of a tree) incident upon the minimum number of vertices. We show that this problem is NP-hard and MAX SNP-hard. We design an algorithm with an approximation factor of $2 + epsilon$ for this problem for any fixed $epsilon &gt;0$. This approximation bound comes from the analysis of a local search heuristic, a common practical optimization technique that does not often allow formal worst-case analysis.  The algorithm is made very efficient by finding restrictive definitions of the local neighborhoods to be searched. We also exhibit a polynomial time approximation scheme for this problem when the input is restricted to planar graphs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {470–487},
numpages = {18},
keywords = {feedback sets, approximation algorithms, pressure-meters, local search}
}

@article{10.1137/S0097539702412908,
author = {Seiden, Steven S. and Stee, Rob van and Epstein, Leah},
title = {New Bounds for Variable-Sized Online Bin Packing},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702412908},
doi = {10.1137/S0097539702412908},
abstract = {In the variable-sized online bin packing problem, one has to assign items to bins one by one. The bins are drawn from some fixed set of sizes, and the goal is to minimize the sum of the sizes of the bins used. We present new algorithms for this problem and show upper bounds for them which improve on the best previous upper bounds. We also show the first general lower bounds for this problem. The case in which bins of two sizes, 1 and $alpha in (0,1)$, are used is studied in detail. This investigation leads us to the discovery of several interesting fractal-like curves.},
journal = {SIAM J. Comput.},
month = feb,
pages = {455–469},
numpages = {15},
keywords = {bin packing, online algorithms}
}

@article{10.1137/S0097539702408636,
author = {Wang, Xinmao and Pan, Victor Y.},
title = {Acceleration of Euclidean Algorithm and Rational Number Reconstruction},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702408636},
doi = {10.1137/S0097539702408636},
abstract = {We accelerate the known algorithms for computing a selected entry of the extended Euclidean algorithm for integers and, consequently, for the modular and numerical rational number reconstruction problems. The acceleration is from quadratic to nearly linear time, matching the known complexity bound for the integer gcd, which our algorithm computes as a special case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {548–556},
numpages = {9},
keywords = {extended Euclidean algorithm, rational number reconstruction}
}

@article{10.1137/S009753970240639X,
author = {Eiter, Thomas and Gottlob, Georg and Makino, Kazuhisa},
title = {New Results on Monotone Dualization and Generating Hypergraph Transversals},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970240639X},
doi = {10.1137/S009753970240639X},
abstract = {We consider the problem of dualizing a monotone CNF (equivalently, computing all minimal transversals of a hypergraph) whose associated decision problem is a prominent open problem in NP-completeness. We present a number of new polynomial time, respectively, output-polynomial time results for significant cases, which largely advance the tractability frontier and improve on previous results. Furthermore, we show that duality of two monotone CNFs can be disproved with limited nondeterminism. More precisely, this is feasible in polynomial time with O(log2 n/log log n) suitably guessed bits. This result sheds new light on the complexity of this important problem.},
journal = {SIAM J. Comput.},
month = feb,
pages = {514–537},
numpages = {24},
keywords = {limited nondeterminism, dualization, combinatorial enumeration, treewidth, hypergraphs, transversal computation, output-polynomial algorithms, hypergraph acyclicity}
}

@article{10.1137/S0097539702403785,
author = {T\'{o}th, Csaba D.},
title = {Binary Space Partitions for Line Segments with a Limited Number of Directions},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702403785},
doi = {10.1137/S0097539702403785},
abstract = {We show that there is always a binary space partition (BSP) of size O(n log k) and an autopartition of size O(nk) for n disjoint line segments in the plane, assuming that the segments have k distinct orientations. In particular, if k is a constant, these bounds imply that there is a linear-size BSP and autopartition. Our proof is constructive and can be turned into algorithms computing such a BSP or autopartition in O(n2) and O(n2k) times.},
journal = {SIAM J. Comput.},
month = feb,
pages = {307–325},
numpages = {19},
keywords = {binary space partition, line segments, computational geometry}
}

@article{10.1137/S009753970240118X,
author = {Feige, Uriel and Krauthgamer, Robert},
title = {The Probable Value of the Lov\'{a}Sz-Schrijver Relaxations for Maximum Independent Set},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970240118X},
doi = {10.1137/S009753970240118X},
abstract = {Lov\'{a}sz and Schrijver [SIAM J. Optim., 1 (1991), pp. 166--190] devised a lift-and-project method that produces a sequence of convex relaxations for the problem of finding in a graph an independent set (or a clique) of maximum size. Each relaxation in the sequence is tighter than the one before it, while the first relaxation is already at least as strong as the Lov\'{a}sz theta function [IEEE Trans. Inform. Theory, 25 (1979), pp. 1--7]. We show that on a random graph Gn,1/2, the value of the rth relaxation in the sequence is roughly rule{0pt}{7pt}$smash{sqrt{rule{0pt}{7pt}smash{n/2^r}}}$, almost surely. It follows that for those relaxations known to be efficiently computable, namely, for r=O(1), the value of the relaxation is comparable to the theta function. Furthermore, a perfectly tight relaxation is almost surely obtained only at the $r=Theta(log n)$ relaxation in the sequence.},
journal = {SIAM J. Comput.},
month = feb,
pages = {345–370},
numpages = {26},
keywords = {random graph, lift-and-project, semidefinite relaxation, stable set polytope, clique}
}

@article{10.1137/S0097539701398582,
author = {Bohman, Tom and Frieze, Alan},
title = {Arc-Disjoint Paths in Expander Digraphs},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701398582},
doi = {10.1137/S0097539701398582},
abstract = {Given a digraph D=(V,A) and a set of $kappa$ pairs of vertices in V, we are interested in finding, for each pair (xi, yi), a directed path connecting xi to yi such that the set of $kappa$ paths so found is arc-disjoint.  For arbitrary graphs the problem is ${cal NP}$-complete, even for $kappa=2$. We present a polynomial time randomized algorithm for finding arc-disjoint paths in an r-regular expander digraph D. We show that if D has sufficiently strong  expansion properties and the degree r is sufficiently large, then all sets of $kappa=Omega(n/log n)$ pairs of vertices can be joined. This is within a constant factor of best possible.},
journal = {SIAM J. Comput.},
month = feb,
pages = {326–344},
numpages = {19},
keywords = {expander digraphs, randomized algorithm, edge disjoint paths}
}

@article{10.1137/S0097539701395668,
author = {Feder, Tom\'{a}s and Motwani, Rajeev and Panigrahy, Rina and Olston, Chris and Widom, Jennifer},
title = {Computing the Median with Uncertainty},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701395668},
doi = {10.1137/S0097539701395668},
abstract = {We consider a new model for computing with uncertainty. It is desired to compute a function f(X1,. . .,Xn), where X1, . . ., Xn are unknown but guaranteed to lie in specified intervals I1, . . ., In. It is possible to query the precise value of any Xj at a cost cj. The goal is to pin down the value of f to within a precision $delta$ at a minimum possible cost. We focus on the selection function f which returns the value of the kth smallest argument. We present optimal offline and online algorithms for this problem.},
journal = {SIAM J. Comput.},
month = feb,
pages = {538–547},
numpages = {10},
keywords = {median, uncertainty, selection, online algorithms, query processing}
}

@article{10.1137/S0097539701385168,
author = {Mourrain, B. and Pan, V. Y. and Ruatta, O.},
title = {Accelerated Solution of Multivariate Polynomial Systems of Equations},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701385168},
doi = {10.1137/S0097539701385168},
abstract = {We propose new Las Vegas randomized algorithms for the solution of a square nondegenerate system of equations, with well-separated roots.  The algorithms use $Oc (delta, csttn D^{2} log(D) log(b))$ arithmetic operations (in addition to the operations required to compute the normal form of the boundary monomials modulo the ideal) to approximate all real roots of the system as well as all roots lying in a fixed n-dimensional box or disc.  Here D is an upper bound on the number of all complex roots of the system (e.g., Bezout or Bernshtein bound), $delta$ is the number of real roots or the roots lying in the box or disc, and $epsilon=2^{-b}$ is the required upper bound on the output errors.  For computing the normal form modulo the ideal, the efficient practical algorithms of [B. Mourrain and P. Tr\'{e}buchet, in Proceedings of the International Symposium on Symbolic and Algebraic Computation, ACM, New York, 2000, pp. 231--238] or [J. C. Faug\`{e}re, J. Pure Appl. Algebra, 139 (1999), pp. 61--88] can be applied.  We also yield the bound $Oc( csttn D^{2} log(D) )$ on the complexity of counting the numbers of all roots in a fixed box (disc) and all real roots. For a large class of inputs and typically in practical computations, the factor $delta$ is much smaller than $D,  delta=o(D)$. This improves by the order of magnitude the known complexity estimates of the order of at least 3n D4 + D3 log(b) or D4, which so far are the record estimates even for the approximation of a single root of a system and for each of the cited counting problems, respectively.  Our progress relies on proposing several novel techniques. In particular, we exploit the structure of matrices associated to a given polynomial system and relate it to the associated linear operators, dual space of linear forms, and normal forms of polynomials in the quotient algebra; furthermore, our techniques support the new nontrivial extension of the matrix sign and quadratic inverse power iterations to the case of multivariate polynomial systems, where we emulate the recursive splitting of a univariate polynomial into factors of smaller degree.},
journal = {SIAM J. Comput.},
month = feb,
pages = {435–454},
numpages = {20},
keywords = {multivariate polynomials, quotient algebras, quasi-Toeplitz matrices, matrix sign iteration, systems of equations, quasi-Hankel matrices, quadratic power iteration, dual spaces}
}

@article{10.1137/S009753970138462X,
author = {Raz, Ran and Shpilka, Amir},
title = {Lower Bounds for Matrix Product in Bounded Depth Circuits with Arbitrary Gates},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970138462X},
doi = {10.1137/S009753970138462X},
abstract = {We prove superlinear lower bounds for the number of edges in constant depth circuits with n inputs and up to n outputs. Our lower bounds are proved for all types of constant depth circuits, e.g., constant depth arithmetic circuits and constant depth Boolean circuits with arbitrary gates. The bounds apply for several explicit functions and, most importantly, for matrix product. In particular, we obtain the following results: We show that the number of edges in any constant depth arithmetic circuit for matrix product (over any field) is superlinear in m 2 (where m × m is the size of each matrix). That is, the lower bound is superlinear in the number of input variables. Moreover, if the circuit is bilinear, the result applies also for the case in which the circuit gets any product of two linear functions for free. We show that the number of edges in any constant depth arithmetic circuit for the trace of the product of three matrices (over fields with characteristic 0) is superlinear in m 2. (Note that the trace is a single-output function.) We give explicit examples for n Boolean functions f 1,. . ., f n , such that any constant depth Boolean circuit with arbitrary gates for f 1,. . ., f n has a superlinear number of edges. The lower bound is also proved for circuits with arbitrary gates over any finite field . The bound applies for matrix product over finite fields as well as for several other explicit functions.},
journal = {SIAM J. Comput.},
month = feb,
pages = {488–513},
numpages = {26},
keywords = {superconcentrators, lower bounds, matrix products, bounded depth circuits}
}

@article{10.1137/S009753970037775X,
author = {Chen, Zhi-Zhong and He, Xin and Kao, Ming-Yang},
title = {Common-Face Embeddings of Planar Graphs},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970037775X},
doi = {10.1137/S009753970037775X},
abstract = {Given a planar graph $Ggg$ and a sequence ${CC}_1,ldots,{CC}_q$, where each ${CC}_i$ is a family of vertex subsets of $Ggg$, we wish to find a plane embedding of $Ggg$, if any exists, such that, for each $iin{1,ldots,q}$, there is a face Fi in the embedding whose boundary contains at least one vertex from each set in CCi.  This problem has applications in the recovery of topological information from geographical data and the design of constrained layouts in VLSI. Let $inputsize$ be the input size, i.e., the total number of vertices and edges in $Ggg$ and the families CCi, counting multiplicity. We show that this problem is NP-complete in general. We also show that it is solvable in $O(inputsizelog inputsize)$ time for the special case in which, for each input family CCi, each set in CCi induces a connected subgraph of the input graph $Ggg$. Note that the classical problem of simply finding a planar embedding is a further special case of this case with q=0. Therefore, the processing of the additional constraints CC1, . . .,CCq incurs only a logarithmic factor of overhead.},
journal = {SIAM J. Comput.},
month = feb,
pages = {408–434},
numpages = {27},
keywords = {topological inference, planar graph, planar embedding}
}

@article{10.1137/S0097539700377657,
author = {Ellis, John and Chow, Stirling and Manke, Dennis},
title = {Many to One Embeddings from Grids into Cylinders, Tori, and Hypercubes},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377657},
doi = {10.1137/S0097539700377657},
abstract = {We describe novel methods for embedding 2-dimensional grid graphs into cylinders (one way wrap-around grids), tori, and hypercubes, where the guest grid  G  is larger than the host graph  H , implying a many to one embedding. We call $lceilmid Gmid / mid Hmidrceil$ the optimal load, denoted  l . We consider optimal embeddings with respect to dilation (the stretching of guest edges) and load; i.e., edges are mapped to edges or onto one node, and the number of grid nodes mapped onto any hypercube node is not greater than  l .We show, by construction, that, for loads of at least 4, optimal embeddings into the hypercube always exist subject only to modest restrictions on the relative dimensions of guest and host. If the problem instances are grouped by grid height, the restrictions imply that only some finite number of instances in each group may not be solvable by the given methods.The essence of the method is a mapping from grids into cylinders of height at least one half of but not greater than the grid height, and so it can also be used to construct embeddings into cylinders and tori.Previous work has gone so far as to show that if the optimal load  l  is a power of 2, then dilation  1 , load  l +1 embeddings into the hypercube can be constructed. Optimal results for loads 2 and 3 are not known.},
journal = {SIAM J. Comput.},
month = feb,
pages = {386–407},
numpages = {22},
keywords = {grid, graph embedding, cylinder, torus, many to one, hypercube}
}

@article{10.1137/S0097539700377293,
author = {Flocchini, P. and Roncato, A. and Santoro, N.},
title = {Backward Consistency and Sense of Direction in Advanced Distributed Systems},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377293},
doi = {10.1137/S0097539700377293},
abstract = {Studies on the relationship between label consistency, computability, and complexity assume the existence of  local orientation ; this assumption is in fact at the basis of the  point-to-point  model and is realistic for systems where a communication link can connect only two entities. However, in systems which use more advanced communication and interconnection technology, such as  buses ,  optical  networks, and  wireless  communication media, and more importantly, in heterogeneous systems (such as the  Internet ) which include any combination of the above, local orientation  cannot  be assumed. This implies that the entire established body of results on the relationship between label consistency (e.g.,  sense  of direction) and computability and complexity does not hold for systems with advanced communication technology. In this paper we consider a new type of consistency which we shall call  backward consistency  and which, unlike sense of direction, can exist even without local orientation. Thus, unlike all previous forms of consistency, it can be found (or designed) in advanced distributed systems.We study backward consistency both in terms of its relationship with the traditional properties of local orientation and (weak) sense of direction, and with respect to symmetries of the edge labelings and of the naming functions. We show that backward consistency is computationally equivalent to sense of direction; in other words, it is possible to take advantage of the computational power of sense of direction even in the absence of local orientation.},
journal = {SIAM J. Comput.},
month = feb,
pages = {281–306},
numpages = {26},
keywords = {sense of direction, distributed computing, global consistency}
}

@article{10.1137/S0097539700369168,
author = {Gamarnik, David},
title = {Stability of Adaptive and Nonadaptive Packet Routing Policies in Adversarial Queueing Networks},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700369168},
doi = {10.1137/S0097539700369168},
abstract = {We investigate the stability of packet routing policies in adversarial queueing networks. We provide a simple classification of networks which are stable under any greedy scheduling policy. We show that a network is stable if and only if the underlying undirected connected graph contains at most two edges. We also propose a simple and distributed policy  which is stable in an arbitrary adversarial queueing network even for the critical value of the arrival rate r=1. Finally, a simple and checkable network flow-type load condition is formulated for adaptive adversarial queueing networks, and a policy is proposed which achieves stability under this new load condition. This load condition is a relaxation of the integral network flow-type condition considered previously in the literature.},
journal = {SIAM J. Comput.},
month = feb,
pages = {371–385},
numpages = {15},
keywords = {congestion, scheduling, multicommodity flow}
}

@article{10.1137/S0097539799361701,
author = {Feigenbaum, Joan and Kannan, Sampath and Strauss, Martin J. and Viswanathan, Mahesh},
title = {An Approximate <i>L</i><sup>1</sup>-Difference Algorithm for  Massive Data Streams},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799361701},
doi = {10.1137/S0097539799361701},
abstract = {Massive data sets are increasingly important in a wide range of applications, including observational sciences, product marketing, and the monitoring and operations of large systems.  In network operations, raw data typically arrive in streams, and decisions must be made by algorithms that make one pass over each stream, throw much of the raw data away, and produce "synopses" or "sketches" for further processing.  Moreover, network-generated massive data sets are often distributed: Several different, physically separated network elements may receive or generate data streams that, together, comprise one logical data set; to be of use in operations, the streams must be analyzed locally and their synopses sent to a central operations facility.  The enormous scale, distributed nature, and one-pass processing requirement on the data sets of interest must be addressed with new algorithmic techniques.We present one fundamental new technique here: a space-efficient, one-pass algorithm for approximating the L1-difference $sum_i|a_i-b_i|$ between two functions, when the function values ai and bi are given as data streams, and their order is chosen by an adversary.  Our main technical innovation, which may be of interest outside the realm of massive data stream algorithmics, is a method of constructing families ${V_j(s)}$ of limited-independence random variables that are range-summable, by which we mean that $sum_{j=0}^{c-1} V_j(s)$ is computable in time polylog(c) for all seeds s.  Our L1-difference algorithm can be viewed as a "sketching" algorithm, in the sense of [Broder et al., J. Comput. System Sci., 60 (2000), pp. 630--659], and our technique performs better than that of Broder et al. when used to approximate the symmetric difference of two sets with small symmetric difference.},
journal = {SIAM J. Comput.},
month = jan,
pages = {131–151},
numpages = {21},
keywords = {distance approximation, streaming algorithms}
}

@article{10.1137/S0097539799360240,
author = {Grandjean, Etienne and Schwentick, Thomas},
title = {Machine-Independent Characterizations and Complete Problems for Deterministic Linear Time},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799360240},
doi = {10.1137/S0097539799360240},
abstract = {This article presents two algebraic characterizations and two related complete problems for the complexity class DLIN that was introduced in [E. Grandjean, Ann. Math. Artif. Intell., 16 (1996), pp. 183--236]. DLIN is essentially the class of all functions that can be computed in linear time on a Random Access Machine which uses only numbers of linear value during its computations.The algebraic characterizations are in terms of recursion schemes that define unary functions. One of these schemes defines several functions simultaneously, while the other one defines only one function. From the algebraic characterizations, we derive two complete problems for DLIN under new, very strict, and machine-independent affine reductions.},
journal = {SIAM J. Comput.},
month = jan,
pages = {196–230},
numpages = {35},
keywords = {completeness, model of computation, affine reductions, Random Access Machine, recursion schemes, linear time}
}

@article{10.1137/S0097539701398375,
author = {Auer, Peter and Cesa-Bianchi, Nicol\`{o} and Freund, Yoav and Schapire, Robert E.},
title = {The Nonstochastic Multiarmed Bandit Problem},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701398375},
doi = {10.1137/S0097539701398375},
abstract = {In the multiarmed bandit problem, a gambler must decide which arm of  K  nonidentical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of  T  plays, we prove that the per-round payoff of our algorithm approaches that of the best arm at the rate  O (  T -1/2). We show by a matching lower bound that this is the best possible.We also prove that our algorithm approaches the per-round payoff of  any  set of strategies at a similar rate: if the best strategy is chosen from a pool of  N  strategies, then our algorithm approaches the per-round payoff of the strategy at the rate  O ((log  N 1/2  T -1/2). Finally, we apply our results to the problem of playing an unknown repeated matrix game. We show that our algorithm approaches the minimax payoff of the unknown game at the rate  O (  T -1/2).},
journal = {SIAM J. Comput.},
month = jan,
pages = {48–77},
numpages = {30},
keywords = {unknown matrix games, adversarial bandit problem}
}

@article{10.1137/S0097539701392949,
author = {Canetti, Ran and Kilian, Joe and Petrank, Erez and Rosen, Alon},
title = {Black-Box Concurrent Zero-Knowledge Requires   (Almost) Logarithmically Many Rounds},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701392949},
doi = {10.1137/S0097539701392949},
abstract = {We show that any concurrent zero-knowledge protocol for a nontrivial language (i.e., for a language outside ${cal BPP}$), whose security is proven via black-box simulation, must use at least $tildeOmega(log n)$ rounds of interaction. This result achieves a substantial improvement over previous lower bounds and is the first bound to rule out the possibility of constant-round concurrent zero-knowledge when proven via black-box simulation. Furthermore, the bound is polynomially related to the number of rounds in the best known concurrent zero-knowledge protocol for languages in ${cal NP}$ (which is established via black-box simulation).},
journal = {SIAM J. Comput.},
month = jan,
pages = {1–47},
numpages = {47},
keywords = {interactive protocols, lower bounds, concurrent zero knowledge, round complexity, zero knowledge, cryptography}
}

@article{10.1137/S0097539701383923,
author = {Devroye, Luc},
title = {Limit Laws for Sums of Functions of Subtrees of Random Binary Search Trees},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701383923},
doi = {10.1137/S0097539701383923},
abstract = {We consider sums of functions of subtrees of a random binary search tree and obtain general laws of large numbers and central limit theorems. These sums correspond to random recurrences of the quicksort type, $X_n {stackrel{cal L}{=}} X_{I_n} + X'_{n-1-I_n} + Y_n$, $n ge 1$, where In is uniformly distributed on {0,1,. . ., n-1 }, Yn is a given random variable, $X_k {stackrel{cal L}{=}} X'_k$ for all k, and, given In, XIn and X'n-1-In are independent. Conditions are derived such that $(X_n - mu n )/sigma sqrt{n} {stackrel{cal L}{rightarrow}} {cal N}(0,1)$, the normal distribution, for some finite constants $mu$ and $sigma$.},
journal = {SIAM J. Comput.},
month = jan,
pages = {152–171},
numpages = {20},
keywords = {convergence, binary search tree, random trees, limit law, probabilistic analysis, data structures, toll functions, Stein's method}
}

@article{10.1137/S0097539701383522,
author = {Vikas, Narayan},
title = {Computational Complexity of Compaction to Reflexive Cycles},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701383522},
doi = {10.1137/S0097539701383522},
abstract = {In this paper, we solve a widely publicized open problem posed by Peter Winkler in 1988. The problem is to decide whether or not it is possible to partition the vertices of a graph into four distinct nonempty sets A, B, C, and D, such that there is no edge between the sets A and C, and between the sets B and D, and that there is at least one edge between any other pair of distinct sets. Winkler asked whether this problem is NP-complete. We show in this paper that it is NP-complete. We study the problem as the compaction problem for a reflexive 4-cycle. We also show in this paper that the compaction problem for a reflexive k-cycle is NP-complete for all $k geq 4$.},
journal = {SIAM J. Comput.},
month = jan,
pages = {253–280},
numpages = {28},
keywords = {computational complexity, compaction, retraction, homomorphism, graph, coloring}
}

@article{10.1137/S0097539700380754,
author = {Feige, Uriel and Halld\'{o}rsson, Magn\'{u}s M. and Kortsarz, Guy and Srinivasan, Aravind},
title = {Approximating the Domatic Number},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700380754},
doi = {10.1137/S0097539700380754},
abstract = {A set of vertices in a graph is a dominating set if every vertex outside the set has a neighbor in the set. The domatic number problem is that of partitioning the vertices of a graph into the maximum number of disjoint dominating sets. Let  n  denote the number of vertices, $delta$ the minimum degree, and $Delta$ the maximum degree. We show that every graph has a domatic partition with $(1 - o(1))(delta + 1)/ln n$ dominating sets and, moreover, that such a domatic partition can be found in polynomial-time. This implies a $(1 + o(1))ln n$-approximation algorithm for domatic number, since the domatic number is always at most $delta + 1$. We also show this to be essentially best possible. Namely, extending the approximation hardness of set cover by combining multiprover protocols with zero-knowledge techniques, we show that for every $epsilon &gt; 0$, a $(1 - epsilon)ln n$-approximation implies that $NP subseteq DTIME(n^{O(loglog n)})$. This makes domatic number the first natural maximization problem (known to the authors) that is provably approximable to within polylogarithmic factors but no better.We also show that every graph has a domatic partition with $(1 - o(1))(delta + 1)/ln Delta$ dominating sets, where the "  o (1)" term goes to zero as $Delta$ increases. This can be turned into an efficient algorithm that produces a domatic partition of $Omega(delta/ln Delta)$ sets.},
journal = {SIAM J. Comput.},
month = jan,
pages = {172–195},
numpages = {24},
keywords = {approximation algorithms, domination, probabilistic analysis, domatic number}
}

@article{10.1137/S0097539700378754,
author = {Keidar, Idit and Khazan, Roger I.},
title = {A Virtually Synchronous Group Multicast Algorithm for WANs: Formal Approach},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700378754},
doi = {10.1137/S0097539700378754},
abstract = {This paper presents a formal design for a novel group communication service targeted for wide-area networks (WANs). The service provides virtual synchrony semantics. Such semantics facilitate the design of fault tolerant distributed applications.  The presented design is more suitable for WANs than previously suggested ones. In particular, it features the first algorithm to achieve virtual synchrony semantics in a single communication round. The design also employs a scalable WAN-oriented architecture: it effectively decouples the main two components of virtually synchronous group communication---group membership and reliable group multicast. The design is carried out formally and rigorously.  This paper includes formal specifications of both safety and liveness properties.  The algorithm is formally modeled and assertionally verified.},
journal = {SIAM J. Comput.},
month = jan,
pages = {78–130},
numpages = {53},
keywords = {group communication, formal modeling, virtual synchrony, reliable multicast}
}

@article{10.1137/S0097539700373520,
author = {Even, Guy and Guha, Sudipto and Schieber, Baruch},
title = {Improved Approximations of Crossings in Graph Drawings and VLSI Layout Areas},
year = {2003},
issue_date = {2003},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {32},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700373520},
doi = {10.1137/S0097539700373520},
abstract = {We give improved approximations for two classical embedding problems: (i) minimizing the number of crossings in a drawing on the plane of a bounded degree graph; and (ii) minimizing the VLSI layout area of a graph of maximum degree four. These improved algorithms can be applied to improve a variety of VLSI layout problems. Our results are as follows. (i) We compute a drawing on the plane of a bounded degree graph in which the sum of the numbers of vertices and crossings is O(log 3 n)$ times the optimal minimum sum. This is a logarithmic factor improvement relative to the best known result. (ii) We compute a VLSI layout of a graph of maximum degree four in a square grid whose area is O(log 4 n)$ times the minimum layout area. This is an O(log 2 n) improvement over the best known long-standing result.},
journal = {SIAM J. Comput.},
month = jan,
pages = {231–252},
numpages = {22},
keywords = {VLSI layout, graph drawing, approximation algorithm, crossing number}
}

@article{10.5555/586845.586958,
author = {Kutz, Martin},
title = {Lower Bounds for Lucas Chains},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
abstract = {Lucas chains are a special type of addition chains satisfying an extra condition: for the representation  a k  =  a j  +  a i  of each element  a k  in the chain, the difference  a j  -  a i  must also be contained in the chain. In analogy to the relation between addition chains and exponentiation, Lucas chains yield computation sequences for Lucas functions, a special kind of linear recurrences. We show that the great majority of natural numbers  n  does not have Lucas chains shorter than $(1-epsilon)log_phi n$ for any $epsilon &gt; 0$, where $phi$ is the golden ratio.Peter L. Montgomery was the first to consider Lucas chains, in the early eighties. He discovered a decomposition theorem for Lucas chains and a lower bound on their length in terms of Fibonacci numbers. His work was not published. Therefore several of Montgomery's original ideas are represented in this paper.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1896–1908},
numpages = {13},
keywords = {addition chain, Fibonacci number, lower bound, smooth number, Lucas function, golden ratio, Lucas chain}
}

@article{10.5555/586845.586953,
author = {Cole, Richard and Hariharan, Ramesh},
title = {Approximate String Matching: A Simpler Faster Algorithm},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
abstract = {We give two algorithms for finding all approximate matches of a pattern in a text, where the edit distance between the pattern and the matching text substring is at most  k . The first algorithm, which is quite simple, runs in time $O(frac{nk^3}{m}+n+m)$ on all patterns except  k -break periodic strings (defined later). The second algorithm runs in time $O(frac{nk^4}{m}+n+m)$ on  k -break periodic patterns. The two classes of patterns are easily distinguished in  O (  m )time.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1761–1782},
numpages = {22},
keywords = {edit distance, algorithms, string matching}
}

@article{10.1137/S0097539799362639,
author = {Hemaspaandra, Edith and Wechsung, Gerd},
title = {The Minimization Problem for Boolean Formulas},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799362639},
doi = {10.1137/S0097539799362639},
abstract = {More than a quarter of a century ago, the question of the complexity of determining whether a given Boolean formula is minimal motivated Meyer and Stockmeyer to define the polynomial hierarchy. This problem (in the standard formalized version---that of Garey and Johnson) has been known for decades to be coNP-hard and in NPNP, and yet no one had even been able to establish (many-one) NP-hardness. In this paper, we show that and more: The problem in fact is (many-one) hard for parallel access to NP.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1948–1958},
numpages = {11},
keywords = {reductions, Boolean formula minimization, computational complexity, polynomial hierarchy, parallel access}
}

@article{10.1137/S0097539799352449,
author = {Han, Yijie and Shen, Xiaojun},
title = {Parallel Integer Sorting Is More Efficient Than Parallel Comparison Sorting on Exclusive Write PRAMs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799352449},
doi = {10.1137/S0097539799352449},
abstract = {We present a significant improvement for parallel integer sorting. On the EREW (exclusive read exclusive write) PRAM our algorithm sorts n integers in the range {0,1, . . . , m-1 } in time O(log n) with $O(n sqrt{frac{log n}{k}})$ operations using word length $k log (m+n)$, where $1 leq k leq log n$. In this paper we present the following four variants of our algorithm. noindent (1) The first variant sorts integers in ${ 0, 1, ldots, m-1}$ in time O(log n) and in linear space with O(n) operations using word length log m log n. (2) The second variant sorts integers in {0, 1, . . , n-1} in time O(log n) and in linear space with $O(nsqrt{log n})$ operations using word length log n. (3) The third variant sorts integers in {0, 1, . . . , m-1} in time O(log3/2 n) and in linear space with $O(nsqrt{log n})$ operations using word length log (m+n). (4) The fourth variant sorts integers in {0, 1, . . . ,m-1} in time O(log n) and space $O(nm^epsilon )$ with $O(nsqrt{log n})$ operations using word length log (m+n). Our algorithms can then be generalized to the situation where the word length is k log (m+n), $1 leq k leq log n$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1852–1878},
numpages = {27},
keywords = {parallel algorithms, bucket sorting, design of algorithms, conservative algorithms, integer sorting, analysis of algorithms, algorithms}
}

@article{10.1137/S009753979732058X,
author = {Bshouty, Nader H. and Mansour, Yishay},
title = {Simple Learning Algorithms for Decision Trees and Multivariate Polynomials},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732058X},
doi = {10.1137/S009753979732058X},
abstract = {In this paper we develop a new approach for learning decision trees and multivariate polynomials via interpolation of multivariate polynomials. This new approach yields simple learning algorithms for multivariate polynomials and decision trees over finite fields under  any  constant bounded product distribution. The output hypothesis is a (single) multivariate polynomial that is an $epsilon$-approximation of the target under  any  constant bounded product distribution. The new approach demonstrates the learnability of many classes under any constant bounded product distribution and using membership queries, such as  j -disjoint disjunctive normal forms (DNFs) and multivariate polynomials with bounded degree over any field.The technique shows how to interpolate multivariate polynomials with bounded term size from membership queries only. This, in particular, gives a learning algorithm for an  O (log  n )-depth decision tree from membership queries only and a new learning algorithm of  any  multivariate polynomial over sufficiently large fields from membership queries only. We show that our results for learning from membership queries only are the best possible.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1909–1925},
numpages = {17},
keywords = {decision tree learning, multivariate polynomial, learning interpolation}
}

@article{10.1137/S0097539702405292,
author = {Buhrman, H. and Miltersen, P. B. and Radhakrishnan, J. and Venkatesh, S.},
title = {Are Bitvectors Optimal?},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539702405292},
doi = {10.1137/S0097539702405292},
abstract = {We study the  it static membership problem : Given a set  S  of at most  n  keys drawn from a universe  U  of size  m , store it so that queries of the form "Is  u  in  S __ __" can be answered by making few accesses to the memory. We study schemes for this problem that use space close to the information theoretic lower bound of $Omega(nlog(frac{m}{n}))$ bits and yet answer queries by reading a small number of bits of the memory. We show that, for $epsilon &gt; 0$, there is a scheme that stores $O(frac{n}{epsilon^2}log m)$ bits and answers membership queries using a randomized algorithm that reads just one bit of memory and errs with probability at most $epsilon$. We consider schemes that make no error for queries in  S  but are allowed to err with probability at most $epsilon$ for queries not in  S . We show that there exist such schemes that store $O((frac{n}{epsilon})^2 log m)$ bits and answer queries using just one bitprobe. If multiple probes are allowed, then the number of bits stored can be reduced to $O(n^{1+delta}log m)$ for any $delta &gt; 0$. The schemes mentioned above are based on probabilistic constructions of set systems with small intersections.We show lower bounds that come close to our upper bounds (for a large range of  n  and $epsilon$): Schemes that answer queries with just one bitprobe and error probability $epsilon$ must use $Omega(frac{n}{epsilonlog(1/epsilon)} log m)$ bits of storage; if the error is restricted to queries not in  S , then the scheme must use $Omega(frac{n^2}{epsilon^2 log (n/epsilon)}log m)$ bits of storage. We also consider deterministic schemes for the static membership problem and show tradeoffs between space and the number of probes.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1723–1744},
numpages = {22},
keywords = {bit probe model, set membership problem, set systems, data structures}
}

@article{10.1137/S0097539701398363,
author = {Datar, Mayur and Gionis, Aristides and Indyk, Piotr and Motwani, Rajeev},
title = {Maintaining Stream Statistics over Sliding Windows},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701398363},
doi = {10.1137/S0097539701398363},
abstract = {We consider the problem of maintaining aggregates and statistics over data streams, with respect to the last N data elements seen so far. We refer to this model as the sliding window model. We consider the following basic problem: Given a stream of bits, maintain a count of the number of 1's in the last N elements seen from the stream. We show that, using $O(frac{1}{epsilon} log^2 N)$ bits of memory, we can estimate the number of 1's to within a factor of $1 + epsilon$. We also give a matching lower bound of $Omega(frac{1}{epsilon}log^2 N)$ memory bits for any deterministic or randomized algorithms. We extend our scheme to maintain the sum of the last N positive integers and provide matching upper and lower bounds for this more general problem as well. We also show how to efficiently compute the Lp norms ($p in [1,2]$) of vectors in the sliding window model using our techniques.  Using our algorithm, one can adapt many other techniques to work for the sliding window model with a multiplicative overhead of $O(frac{1}{epsilon}log N)$ in memory and a $1 +epsilon$ factor loss in accuracy. These include maintaining approximate histograms, hash tables, and statistics or aggregates such as sum and averages.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1794–1813},
numpages = {20},
keywords = {sliding windows, statistics, approximation algorithms, data streams}
}

@article{10.1137/S0097539701395115,
author = {Lefmann, Hanno and Schmitt, Niels},
title = {A Deterministic Polynomial-Time Algorithm for Heilbronn's Problem in Three Dimensions},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701395115},
doi = {10.1137/S0097539701395115},
abstract = {Heilbronn conjectured that among arbitrary n points in the two-dimensional unit square [0,1]2, there must be three points which form a triangle of area O(1/n2). This conjecture was disproved by a nonconstructive argument of Koml\'{o}s, Pintz, and Szemer\'{e}di [J. London Math. Soc., 25 (1982), pp. 13--24], who showed that for every n there exists a configuration of n points in the unit square [0,1]2 where all triangles have area $Omega({log n}/{n^2})$. Here we will consider a three-dimensional analogue of this problem and show how to find deterministically in polynomial time n points in the unit cube [0,1]3 such that the volume of every tetrahedron among these n points is $Omega(log n/n^3)$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1926–1947},
numpages = {22},
keywords = {independent sets in hypergraphs, Heilbronn's triangle problem, arrangements of simplices}
}

@article{10.1137/S009753970138390X,
author = {Hwang, Hsien-Kuei and Neininger, Ralph},
title = {Phase Change of Limit Laws in the Quicksort Recurrence under Varying Toll Functions},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970138390X},
doi = {10.1137/S009753970138390X},
abstract = {We characterize all limit laws of the quicksort-type random variables defined recursively by ${cal L}(X_n)= {cal L}(X_{I_n}+X^*_{n-1-I_n}+T_n)$ when the "toll function" Tn varies and satisfies general conditions, where (Xn), (Xn*), (In, Tn) are independent, In is uniformly distributed over {0, . . .,n-1}, and ${cal L}(X_n)={cal L}(X_n^ast)$. When the "toll function" Tn (cost needed to partition the original problem into smaller subproblems) is small (roughly $limsup_{nrightarrowinfty}log E(T_n)/log nle 1/2$), Xn is asymptotically normally distributed; nonnormal limit laws emerge when Tn becomes larger. We give many new examples ranging from the number of exchanges in quicksort to sorting on a broadcast communication model, from an in-situ permutation algorithm to tree traversal algorithms, etc.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1687–1722},
numpages = {36},
keywords = {analysis of algorithms, binary search trees, limit distribution, contraction method, method of moments, quicksort}
}

@article{10.1137/S0097539700382169,
author = {Pach, J\'{a}nos and Tardos, G\'{a}bor},
title = {On the Boundary Complexity of the Union of   Fat Triangles},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700382169},
doi = {10.1137/S0097539700382169},
abstract = {A triangle is said to be {it $delta$-fat/} if its smallest angle is at least $delta&gt;0$. A connected component of the complement of the union of a family of triangles is called a {it hole}. It is shown that any family of n $delta$-fat triangles in the plane determines at most $Oleft(frac{n}{delta}logfrac{2}{delta}right)$ holes. This improves on some earlier bounds of Efrat, Rote, Sharir, and Matousek, et al. Solving a problem of Agarwal and Bern, we also give a general upper bound for the number of holes determined by n triangles in the plane with given angles. As a corollary, we obtain improved upper bounds for the boundary complexity of the union of fat polygons in the plane, which, in turn, leads to better upper bounds for the running times of some known algorithms for motion planning, for finding a separator line for a set of segments, etc.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1745–1760},
numpages = {16},
keywords = {fat objects, boundary complexity, holes}
}

@article{10.1137/S0097539700377165,
author = {Guruswami, Venkatesan and Hastad, Johan and Sudan, Madhu},
title = {Hardness of Approximate Hypergraph Coloring},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377165},
doi = {10.1137/S0097539700377165},
abstract = {We introduce the notion of covering complexity of a verifier for probabilistically checkable proofs (PCPs). Such a verifier is given an input, a claimed theorem, and an oracle, representing a purported proof of the theorem. The verifier is also given a random string and decides whether to accept the proof or not, based on the given random string. We define the covering complexity of such a verifier, on a given input, to be the minimum number of proofs needed to "satisfy" the verifier on every random string; i.e., on every random string, at least one of the given proofs must be accepted by the verifier.  The covering complexity of PCP verifiers offers a promising route to getting stronger inapproximability results for some minimization problems and, in particular, (hyper)graph coloring problems.  We present a PCP verifier for NP statements that queries only four bits and yet has a covering complexity of one for true statements and a superconstant covering complexity for statements not in the language. Moreover, the acceptance predicate of this verifier is a simple not-all-equal check on the four bits it reads. This enables us to prove that, for any constant c, it is NP-hard to color a 2-colorable 4-uniform hypergraph using just c colors and also yields a superconstant inapproximability result under a stronger hardness assumption.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1663–1686},
numpages = {24},
keywords = {hardness of approximations, graph coloring, set splitting, hypergraph coloring, PCP, covering PCP}
}

@article{10.1137/S0097539700376007,
author = {Russell, Alexander and Saks, Michael and Zuckerman, David},
title = {Lower Bounds for Leader Election and Collective Coin-Flipping in the Perfect Information Model},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700376007},
doi = {10.1137/S0097539700376007},
abstract = {Collective coin-flipping is the problem of producing common random bits in a distributed computing environment with adversarial faults. We consider the perfect information model: all communication is by broadcast and corrupt players are computationally unbounded. Protocols in this model may involve many asynchronous rounds.  We assume that honest players communicate only uniformly random bits. We demonstrate that any n-player coin-flipping protocol that is resilient against corrupt coalitions of linear size must use either at least [1/2 - o(1)]log* n communication rounds or at least [log(2k-1) n]1-o(1) communication bits in the kth round, where log(j) denotes the logarithm iterated j times.  In particular, protocols using one bit per round require [1/2 - o(1)]log* n rounds.  These bounds also apply to the leader election problem.  The primary component of this result is a new bound on the influence of random sets of variables on Boolean functions.  Finally, in the one-round case, using other methods we prove a new bound on the influence of sets of variables of size $beta n$ for $beta &gt; 1/3$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1645–1662},
numpages = {18},
keywords = {collective coin-flipping, perfect information model, leader election}
}

@article{10.1137/S0097539700374550,
author = {Agarwal, Pankaj K. and Biedl, Therese and Lazard, Sylvain and Robbins, Steve and Suri, Subhash and Whitesides, Sue},
title = {Curvature-Constrained Shortest Paths in a Convex Polygon},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700374550},
doi = {10.1137/S0097539700374550},
abstract = {Let B be a point robot moving in the plane, whose path is constrained to have curvature at most 1, and let $poly$ be a convex polygon with n vertices. We study the collision-free, optimal path-planning problem for B moving between two configurations inside $poly$. (A configuration specifies both a location and a direction of travel.) We present an O(n2 log n) time algorithm for determining whether a collision-free path exists for B between two given configurations. If such a path exists, the algorithm returns a shortest one. We provide a detailed classification of curvature-constrained shortest paths inside a convex polygon and prove several properties of them, which are interesting in their own right. For example, we prove that any such shortest path is comprised of at most eight segments, each of which is a circular arc of unit radius or a straight-line segment. Some of the properties are quite general and shed some light on curvature-constrained shortest paths amid obstacles.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1814–1851},
numpages = {38},
keywords = {nonholonomic motion planning, Dubins path, mobile robot, curvature constraint, shortest paths, bounded radius of curvature, computational geometry}
}

@article{10.1137/S0097539700371065,
author = {Pettie, Seth and Ramachandran, Vijaya},
title = {A Randomized Time-Work Optimal Parallel Algorithm for Finding a Minimum Spanning Forest},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700371065},
doi = {10.1137/S0097539700371065},
abstract = {We present a randomized algorithm to find a minimum spanning forest (MSF) in an undirected graph. With high probability, the algorithm runs in logarithmic time and linear work on an exclusive read exclusive write (EREW) PRAM. This result is optimal w.r. t. both work and parallel time, and is the first provably optimal parallel algorithm for this problem under both measures. We also give a simple, general processor allocation scheme for tree-like computations.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1879–1895},
numpages = {17},
keywords = {parallel algorithm, EREW PRAM, minimum spanning tree, optimal algorithm}
}

@article{10.1137/S009753970036917X,
author = {K\"{o}nemann, J. and Ravi, R.},
title = {A Matter of Degree: Improved Approximation Algorithms for Degree-Bounded Minimum Spanning Trees},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970036917X},
doi = {10.1137/S009753970036917X},
abstract = {In this paper, we present a new bicriteria approximation algorithm for the degree-bounded minimum spanning tree problem.  In this problem, we are given an undirected graph, a nonnegative cost function on the edges, and a positive integer B*, and the goal is to find a minimum-cost spanning tree T with maximum degree at most B*. In an n-node graph, our algorithm finds a spanning tree with maximum degree O(B*+logn) and cost O(optB*), where optB* is the minimum cost of any spanning tree whose maximum degree is at most B*. Our algorithm uses ideas from Lagrangean duality.  We show how a set of optimum Lagrangean multipliers yields bounds on both the degree and the cost of the computed solution.},
journal = {SIAM J. Comput.},
month = jun,
pages = {1783–1793},
numpages = {11},
keywords = {Lagrangean relaxation, approximation algorithms, degree-bounded spanning trees, bicriteria approximation, spanning trees, network algorithms}
}

@article{10.1137/S0097539799363992,
author = {Zhou, Yunhong and Suri, Subhash},
title = {Algorithms for a Minimum Volume Enclosing Simplex in Three Dimensions},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799363992},
doi = {10.1137/S0097539799363992},
abstract = {We develop a combinatorial algorithm for determining a minimum volume simplex enclosing a set of points in ${cal R}^3$.  If the convex hull of the points has $n$ vertices, then our algorithm takes $Theta(n^4)$ time. Combining our exact but slow algorithm with a simple but crude approximation technique, we also develop an $varepsilon$-approximation algorithm. The algorithm computes in $O(n + 1/varepsilon^6)$ time a simplex whose volume is within $(1 + varepsilon)$ factor of the optimal for any $varepsilon &gt; 0$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1339–1357},
numpages = {19},
keywords = {shape approximation, centroid, bounding volumes}
}

@article{10.1137/S0097539799354771,
author = {Chv\'{a}tal, V. and Fonlupt, J. and Sun, L. and Zemirline, A.},
title = {Recognizing Dart-Free Perfect Graphs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799354771},
doi = {10.1137/S0097539799354771},
abstract = {A graph G is called a Berge graph if neither G nor its complement contains a chordless cycle whose length is odd and at least five; what we call a dart is the graph with vertices u,v,w,x,y and edges uv,vw,uy,vy,wy,xy; a graph is called dart-free if it has no induced subgraph isomorphic to the dart.  We present a polynomial-time algorithm to recognize dart-free Berge graphs; this algorithm uses as a subroutine the polynomial-time algorithm for recognizing claw-free Berge graphs designed previously by Chv\'{a}tal and Sbihi [J. Combin. Theory Ser. B, 44 (1988), pp. 154--176].},
journal = {SIAM J. Comput.},
month = may,
pages = {1315–1338},
numpages = {24},
keywords = {perfect graphs}
}

@article{10.1137/S0097539799353443,
author = {Brodsky, Alex and Pippenger, Nicholas},
title = {Characterizations of  1-Way Quantum Finite Automata},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799353443},
doi = {10.1137/S0097539799353443},
abstract = {The 2-way quantum finite automaton introduced by Kondacs and Watrous [  Proceedings of the 38  th Annual Symposium on Foundations of Computer Science , 1997, IEEE Computer Society, pp. 66--75] can accept nonregular languages with bounded error in polynomial time. If we restrict the head of the automaton to moving classically and to moving only in one direction, the acceptance power of this 1-way quantum finite automaton is reduced to a proper subset of the regular languages. In this paper we study two different models of 1-way quantum finite automata. The first model, termed measure-once quantum finite automata, was introduced by Moore and Crutchfield [  Theoret. Comput. Sci. , 237 (2000), pp. 275--306], and the second model, termed measure-many quantum finite automata, was introduced by Kondacs and Watrous [  Proceedings of the 38  th Annual Symposium on Foundations of Computer Science , 1997, IEEE Computer Society, pp. 66--75].We characterize the measure-once model when it is restricted to accepting with bounded error and show that, without that restriction, it can solve the word problem over the free group. We also show that it can be simulated by a probabilistic finite automaton and describe an algorithm that determines if two measure-once automata are equivalent.We prove several closure properties of the classes of languages accepted by measure-many automata, including inverse homomorphisms, and provide a new necessary condition for a language to be accepted by the measure-many model with bounded error. Finally, we show that piecewise testable sets can be accepted with bounded error by a measure-many quantum finite automaton, introducing new construction techniques for quantum automata in the process.},
journal = {SIAM J. Comput.},
month = may,
pages = {1456–1478},
numpages = {23},
keywords = {quantum finite automata, quantum computation, automata theory}
}

@article{10.1137/S0097539798340928,
author = {Servedio, Rocco A.},
title = {Perceptron, Winnow, and PAC Learning},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798340928},
doi = {10.1137/S0097539798340928},
abstract = {We analyze the performance of the widely studied Perceptron and Winnow algorithms for learning linear threshold functions under Valiant's probably approximately correct (PAC) model of concept learning. We show that under the uniform distribution on boolean examples, the Perceptron algorithm can efficiently PAC learn nested functions (a class of linear threshold functions known to be hard for Perceptron under arbitrary distributions) but cannot efficiently PAC learn arbitrary linear threshold functions. We also prove that Littlestone's Winnow algorithm is not an efficient PAC learning algorithm for the class of positive linear threshold functions, thus answering an open question posed by Schmitt [ Neural Comput., 10 (1998), pp. 235--250]. Based on our results we conjecture that no "local" algorithm can learn linear threshold functions efficiently.},
journal = {SIAM J. Comput.},
month = may,
pages = {1358–1369},
numpages = {12},
keywords = {Perceptron, PAC learning, linear threshold function, Winnow}
}

@article{10.1137/S0097539798285997,
author = {Mayer, Alain and Ostrovsky, Rafail and Ofek, Yoram and Yung, Moti},
title = {Self-Stabilizing Symmetry Breaking in Constant Space},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798285997},
doi = {10.1137/S0097539798285997},
abstract = {We investigate the problem of self-stabilizing round-robin token management on a bidirectional ring of identical processors. Each processor is an asynchronous probabilistic finite state (i.e., constant space) machine which sends and receives constant-size messages and whose state transition is triggered by the receipt of a message.  We also show that this problem is equivalent to symmetry breaking (i.e., leader election).We justify and suggest a two-layer (hardware and software) solution to the token management problem: The subproblem of reducing an arbitrary but nonzero number of tokens (in an otherwise arbitrary initial system state) to exactly one token (and a legal system state) is solved in hardware and takes only small polynomial time. The detection of a complete lack of tokens (communication deadlock) is done by a software clock. In high-speed networks the hardware layer can be implemented using fast universal switches (i.e., finite state machines) independent of the size of the network.  We note that randomization is essential, since Dijkstra showed that for arbitrary rings the subproblem does not have a deterministic solution (regardless of the computational power of the identical processors).  The use of the software layer (deadlock detection)  in our solution is minimized.},
journal = {SIAM J. Comput.},
month = may,
pages = {1571–1595},
numpages = {25},
keywords = {distributed algorithms, media access protocols, self-stabilizing protocols, self-stabilization, token ring protocols}
}

@article{10.1137/S0097539701395486,
author = {Feder, Tom\'{a}s and Motwani, Rajeev and Subi, Carlos},
title = {Approximating the Longest Cycle Problem   in Sparse Graphs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701395486},
doi = {10.1137/S0097539701395486},
abstract = {We consider the problem of finding long paths and cycles in Hamiltonian graphs. The focus of our work is on sparse graphs, e.g., cubic graphs, that satisfy some property known to hold for Hamiltonian graphs, e.g.,  k -cyclability. We first consider the problem of finding long cycles in 3-connected cubic graphs whose edges have weights $w_igeq 0$. We find cycles of weight at least ${(sum w_i^a)}^{frac{1}{a}}$ for $a=log_2 3$. Based on this result, we develop an algorithm for finding a cycle of length at least $m^{(log_3 2)/2}approx m^{0.315}$ in 3-cyclable graphs with vertices of degree at most 3 and with  m  edges. As a corollary of this result, for arbitrary graphs with vertices of degree at most 3 that have a cycle of length l (or, more generally, a 3-cyclable minor with degrees at most 3 and with l edges), we find a cycle of length at least $l^{(log_3 2)/2}$.We consider the graph property of 1-  toughness  that is common to Hamiltonian graphs and 3-connected cubic graphs, and we try to determine if 1-toughness implies the existence of long cycles. We show that 2-connectivity and 1-toughness, for constant degree graphs, may give cycles that are only of logarithmic length. However, we exhibit a class of 3-connected 1-tough graphs with degrees up to 6, where we can find cycles of length at least ${m}^{log_3 2}/2$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1596–1607},
numpages = {12},
keywords = {long paths and cycles, approximation algorithms, Hamiltonian graphs}
}

@article{10.1137/S0097539701389257,
author = {Naor, Moni and Reingold, Omer and Rosen, Alon},
title = {Pseudorandom Functions and Factoring},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701389257},
doi = {10.1137/S0097539701389257},
abstract = {The computational hardness of factoring integers is the most established assumption on which cryptographic primitives are based. This work presents an efficient construction of pseudorandom functions whose security is based on the intractability of factoring. In particular, we are able to construct efficient length-preserving pseudorandom functions, where each evaluation requires only a (small) constant number of modular multiplications per output bit. This is substantially more efficient than any previous construction of pseudorandom functions based on factoring and matches (up to a constant factor) the efficiency of the best-known factoring-based pseudorandom bit generators.},
journal = {SIAM J. Comput.},
month = may,
pages = {1383–1404},
numpages = {22},
keywords = {pseudorandom functions, pseudorandomness, integer factorization, cryptography, computational number theory}
}

@article{10.1137/S0097539701388768,
author = {Boros, E. and Elbassioni, K. and Gurvich, V. and Khachiyan, L. and Makino, K.},
title = {Dual-Bounded Generating Problems: All Minimal Integer Solutions for  a Monotone System of Linear Inequalities},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701388768},
doi = {10.1137/S0097539701388768},
abstract = {We consider the problem of enumerating all minimal integer solutions of a monotone system of linear inequalities.  We first show that, for any monotone system of r linear inequalities in n variables, the number of maximal infeasible integer vectors is at most rn times the number of minimal integer solutions to the system.  This bound is accurate up to a polylog(r) factor and leads to a polynomial-time reduction of the enumeration problem to a natural generalization of the well-known dualization problem for hypergraphs, in which dual pairs of hypergraphs are replaced by dual collections of integer vectors in a box.  We provide a quasi-polynomial algorithm for the latter dualization problem. These results imply, in particular, that the problem of incrementally generating all minimal integer solutions to a monotone system  of linear inequalities can be done in quasi-polynomial time.},
journal = {SIAM J. Comput.},
month = may,
pages = {1624–1643},
numpages = {20},
keywords = {monotone discrete binary functions, integer programming, dualization, regular discrete functions, monotone inequalities, complexity of incremental algorithms, quasi-polynomial time}
}

@article{10.1137/S0097539701387854,
author = {Spreen, Dieter},
title = {Safe Weak Minimization Revisited},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701387854},
doi = {10.1137/S0097539701387854},
abstract = {Minimization operators of different strengths have been studied in the framework of "predicative (safe) recursion." In this paper, a modification of these operators is presented. By adding the new operator to those used by Bellantoni--Cook and Leivant to characterize the polynomial-time computable functions, one obtains a characterization of the nondeterministic polynomial-time computable multifunctions. Thus the generation of the nondeterministic polytime multifunctions from the deterministic polytime functions parallels the generation of the computable functions from the primitive recursive ones.},
journal = {SIAM J. Comput.},
month = may,
pages = {1542–1556},
numpages = {15},
keywords = {recursion on notation, multifunction, nondeterministic polynomial time, implicit computational complexity, safe (predicative) recursion, minimization, normal form theorem}
}

@article{10.1137/S0097539701386526,
author = {Hiptmair, R. and Ostrowski, J.},
title = {Generators of $H_1(\Gamma_{h},\mathbbZ)$ for Triangulated Surfaces: Construction and Classification},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701386526},
doi = {10.1137/S0097539701386526},
abstract = {We consider a bounded Lipschitz-polyhedron $Omegasubsetmathbb{R}^3$ of general topology equipped with a tetrahedral triangulation that induces a mesh $Gamma_h$ of the surface $partialOmega$. We seek a maximal set of surface edge cycles that are independent in $H_1(Gamma_h,mathbb{Z})$ and bounding with respect to the exterior of $Omega$. We present an algorithm for constructing suitable 1-cycles in $Gamma_h$: First, representatives of a basis of the homology group $H_1(Gamma_h,mathbb{Z})$ are constructed, merely using the combinatorial description of the surface mesh $Gamma_h$. Then, a duality pairing based on linking numbers is used to determine those combinations that are bounding with respect to $mathbb{R}^3setminusOmega$. This is the key to circumventing a triangulation of the exterior region $mathbb{R}^3setminusOmega$ in the computations. For shape-regular, quasi-uniform families of meshes, the asymptotic complexity of the algorithm is shown to be  O (  N 2), where  N  is the number of edges of $Gamma_h$.The scheme provides an essential preprocessing step for all boundary element methods for eddy current simulation, which rely on discrete divergence-free vectorfields and their description through stream functions.},
journal = {SIAM J. Comput.},
month = may,
pages = {1405–1423},
numpages = {19},
keywords = {computational electromagnetism, nonbounding cycles, cellular homology, linking numbers, surface stream functions}
}

@article{10.1137/S0097539701385296,
author = {G\'{a}l, Anna and Ros\'{e}n, Adi},
title = {A Theorem on Sensitivity and  Applications in Private Computation},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701385296},
doi = {10.1137/S0097539701385296},
abstract = {In this paper we prove a theorem that gives an (almost) tight upper bound on the sensitivity of a multiple-output Boolean function in terms of the sensitivity of its coordinates and the size of the range of the function. We apply this theorem to get improved lower bounds on the time (number of rounds) to compute Boolean functions by private protocols. These bounds are given in terms of the sensitivity of the function being computed and the amount of randomness used by the private protocol. These lower bounds are tight (up to constant factors) for the case of the xor function and together with the results in [E. Kushilevitz and A. Ros\'{e}n, SIAM J. Discrete Math., 11 (1998), pp. 61--80.] establish a tight (up to constant factors) tradeoff between randomness and time in private computation.},
journal = {SIAM J. Comput.},
month = may,
pages = {1424–1437},
numpages = {14},
keywords = {lower bounds, randomness, sensitivity, private computation}
}

@article{10.1137/S0097539701383844,
author = {Dyer, Martin and Frieze, Alan and Jerrum, Mark},
title = {On Counting Independent Sets in Sparse Graphs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701383844},
doi = {10.1137/S0097539701383844},
abstract = {We prove two results concerning approximate counting of independent sets in graphs with constant maximum degree $Delta$. The first implies that the Markov chain Monte Carlo technique is likely to fail if $Delta geq 6$. The second shows that no fully polynomial randomized approximation scheme can exist for $Delta geq 25$, unless $mathrm{RP}=mathrm{NP}$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1527–1541},
numpages = {15},
keywords = {05C69, 68Q17; Secondary, 60J10, Primary, 68E10, 68Q25, 68W40}
}

@article{10.1137/S0097539700389652,
author = {Klivans, Adam R. and van Melkebeek, Dieter},
title = {Graph Nonisomorphism Has Subexponential Size Proofs Unless the Polynomial-Time Hierarchy Collapses},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700389652},
doi = {10.1137/S0097539700389652},
abstract = {Traditional hardness versus randomness results focus on time-efficient randomized decision procedures. We generalize these trade-offs to a much wider class of randomized processes. We work out various applications, most notably to derandomizing Arthur-Merlin games. We show that every language with a bounded round Arthur-Merlin game has subexponential size membership proofs for infinitely many input lengths unless exponential time coincides with the third level of the polynomial-time hierarchy (and hence the polynomial-time hierarchy collapses). Since the graph nonisomorphism problem has a bounded round Arthur-Merlin game, this provides the first strong evidence that graph nonisomorphism has subexponential size proofs. We also establish hardness versus randomness trade-offs for space bounded computation.},
journal = {SIAM J. Comput.},
month = may,
pages = {1501–1526},
numpages = {26},
keywords = {universal traversal sequences, unique satisfiability, learning theory, hardness versus randomness, rigid matrices, interactive proofs, pseudorandomness, graph isomorphism, derandomization, linebreak Arthur-Merlin games}
}

@article{10.1137/S0097539700382947,
author = {Gudmundsson, Joachim and Levcopoulos, Christos and Narasimhan, Giri},
title = {Fast Greedy Algorithms for Constructing Sparse Geometric Spanners},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700382947},
doi = {10.1137/S0097539700382947},
abstract = {Given a set V of n points in $IR^d$ and a real constant t&gt;1, we present the first O(nlog n)-time algorithm to compute a geometric t-spanner on V. A geometric t-spanner on V is a connected graph G = (V,E) with edge weights equal to the Euclidean distances between the endpoints, and with the property that, for all $u,vin V$, the distance between u and v in G is at most t times the Euclidean distance between u and v. The spanner output by the algorithm has O(n) edges and weight $O(1)cdot wt(MST)$, and its degree is bounded by a constant.},
journal = {SIAM J. Comput.},
month = may,
pages = {1479–1500},
numpages = {22},
keywords = {cluster graph, computational geometry, sparse geometric spanners}
}

@article{10.1137/S009753970038211X,
author = {Newman, Ilan},
title = {Testing Membership in Languages That Have Small Width Branching Programs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970038211X},
doi = {10.1137/S009753970038211X},
abstract = {Combinatorial property testing, initiated formally by Goldreich, Goldwasser, and Ron in [  J. ACM , 45 (1998), pp. 653--750] and inspired by Rubinfeld and Sudan [  SIAM J. Comput. , 25 (1996), pp. 252--271], deals with the following relaxation of decision problems: Given a fixed property and an input  x , one wants to decide whether  x  has the property or is "far" from having the property. The main result here is that, if ${cal G}= { g_n:{0,1}^n rightarrow {0,1} }$ is a family of Boolean functions which have oblivious read-once branching programs of width  w , then, for every  n  and $epsilon &gt; 0$, there is a randomized algorithm that always accepts every $x in {0,1}^n$ if $g_n(x)=1$ and rejects it with high probability if at least $epsilon n$ bits of $x$ should be modified in order for it to be in  g n -1(1). The algorithm makes $(frac{2^{w}}{epsilon})^{O(w)}$ queries. In particular, for constant $epsilon$ and  w , the query complexity is O(1). This generalizes the results of Alon et al. [  Proceedings of the 40  th IEEE Symposium on Foundations of Computer Science , IEEE Computer Society, 1999, pp. 645--655] asserting that regular languages are $epsilon$-testable for every $epsilon &gt; 0$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1557–1570},
numpages = {14},
keywords = {branching programs, randomized algorithms, property testing}
}

@article{10.1137/S0097539700381097,
author = {Halperin, Eran},
title = {Improved Approximation Algorithms for the Vertex Cover Problem in Graphs and Hypergraphs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700381097},
doi = {10.1137/S0097539700381097},
abstract = {We obtain improved algorithms for finding small vertex covers in bounded degree graphs and hypergraphs. We use semidefinite programming to relax the problems and introduce new rounding techniques for these relaxations. On graphs with maximum degree at most $Delta$, the algorithm achieves a performance ratio of $2-(1-o(1))frac{2 ln ln Delta}{ln Delta}$ for large $Delta$, which improves the previously known ratio of $2-frac{log Delta + O(1)}{Delta}$ obtained by Halld\'{o}rsson and Radhakrishnan. Using similar techniques, we also present improved approximations for the vertex cover problem in hypergraphs. For k-uniform hypergraphs with n vertices, we achieve a ratio of $k-(1-o(1))frac{kln ln n}{ln n}$ for large n, and for k-uniform hypergraphs with maximum degree at most $Delta$ the  algorithm achieves a ratio of $k-(1-o(1))frac{k(k-1)ln ln Delta}{ln Delta}$ for large $Delta$. These results considerably improve the previous best ratio of $k(1-c/Delta^frac{1}{k-1})$ for bounded degree k-uniform hypergraphs, and $k(1-c/n^frac{k-1}{k})$ for general k-uniform hypergraphs, both obtained by Krivelevich. Using similar techniques, we also obtain an approximation algorithm for the weighted independent set problem, matching a recent result of Halldorsson.},
journal = {SIAM J. Comput.},
month = may,
pages = {1608–1623},
numpages = {16},
keywords = {vertex cover, approximation algorithms, semidefinite programming}
}

@article{10.1137/S0097539700376068,
author = {Malvestuto, F. M. and Mezzini, M.},
title = {A Linear Algorithm for Finding the Invariant Edges of an Edge-Weighted Graph},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700376068},
doi = {10.1137/S0097539700376068},
abstract = {Given an edge-weighted graph where all weights are nonnegative reals, an edge reweighting is an assignment of nonnegative reals to edges such that, for each vertex, the sums of given and new weights assigned to the edges incident on the vertex do coincide. An edge is then said to be invariant if its weight is the same for any edge reweighting. We show that the set of invariant edges of an arbitrary edge-weighted graph can be determined in time linear in the size of the underlying graph. Moreover, an application to the security of statistical data is discussed.},
journal = {SIAM J. Comput.},
month = may,
pages = {1438–1455},
numpages = {18},
keywords = {graph algorithms, linear algebra, matroid theory}
}

@article{10.1137/S009753970037446X,
author = {Awerbuch, Baruch and Azar, Yossi and Leonardi, Stefano and Regev, Oded},
title = {Minimizing the Flow Time Without Migration},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970037446X},
doi = {10.1137/S009753970037446X},
abstract = {We consider the classical problem of scheduling jobs in a multiprocessor setting in order to minimize the flow time (total time in the system). The performance of the algorithm, both in offline and online settings, can be significantly improved if we allow preemption, i.e., interrupt a job and later continue its execution, perhaps migrating it to a different machine. Preemption is inherent to make a scheduling algorithm efficient. While in the case of a single processor most operating systems can easily handle preemptions, migrating a job to a different machine results in a huge overhead. Thus, it is not commonly used in most multiprocessor operating systems. The natural question is whether migration is an inherent component for an efficient scheduling algorithm in either the online or offline setting. Leonardi and Raz [  Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing , El Paso, TX, 1997, pp. 110--119] showed that the well-known algorithm,  shortest remaining processing time  (SRPT), performs within a logarithmic factor of the optimal offline algorithm. Note that SRPT must use  both  preemption and migration to schedule the jobs. It is not known if better approximation factors can be reached and thus SRPT, although it is an online algorithm, becomes the best known algorithm in the offline setting. In fact, in the online setting, Leonardi and Raz showed that no algorithm can achieve a better bound.Without migration, no (offline or online) approximations are known. This paper introduces a new algorithm that does not use migration, works online, and is just as effective (in terms of approximation ratio) as the best known offline algorithm that uses migration.},
journal = {SIAM J. Comput.},
month = may,
pages = {1370–1382},
numpages = {13},
keywords = {scheduling, flow time, online, approximation, migration}
}

@article{10.1137/S0097539799364006,
author = {Moses, Yoram and Rajsbaum, Sergio},
title = {A Layered Analysis of Consensus},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799364006},
doi = {10.1137/S0097539799364006},
abstract = {This paper introduces a simple notion of layering as a tool for analyzing well-behaved runs of a given model of distributed computation.  Using layering, a model-independent analysis of the consensus problem is performed and then applied to proving lower bounds and impossibility results for consensus in a number of familiar and less familiar models. The proofs are simpler and more direct than existing ones, and they expose a unified structure to the difficulty of reaching consensus. In particular, the proofs for the classical synchronous and asynchronous models now follow the same outline. A new notion of connectivity among states in runs of a consensus protocol, called potence connectivity, is introduced. This notion is more general than previous notions of connectivity used for this purpose and plays a key role in the uniform analysis of consensus.},
journal = {SIAM J. Comput.},
month = apr,
pages = {989–1021},
numpages = {33},
keywords = {consensus, lower bounds, distributed systems, shaved-memory systems, topology, impossibility results}
}

@article{10.1137/S0097539799354321,
author = {Chen, Zhi-Zhong and He, Xin and Huang, Chun-Hsi},
title = {Finding Double Euler Trails of Planar Graphs in Linear Time},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799354321},
doi = {10.1137/S0097539799354321},
abstract = {This paper answers an open question in the design of complimentary metal-oxide semiconductor VLSI circuits. The question asks whether a polynomial-time algorithm can decide if a given planar graph has a plane embedding ${cal E}$ such that ${cal E}$ has an Euler trail P = e1 e2 ... em and its dual graph has an Euler trail $P^*=e^*_1 e^*_2 ldots e^*_m$, where $e^*_i$ is the dual edge of ei for i=1,2,...,m. This paper answers this question in the affirmative by presenting a linear-time algorithm.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1255–1285},
numpages = {31},
keywords = {planar graph, dual graph, Euler trail}
}

@article{10.1137/S009753979833297X,
author = {Geser, Alfons},
title = {Decidability of Termination of Grid String Rewriting Rules},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979833297X},
doi = {10.1137/S009753979833297X},
abstract = {Termination of string rewriting is known undecidable. Termination of string rewriting with only one rule is neither known decidable nor known undecidable. This paper presents a decision procedure for rules $urightarrow v$ such that some letter b from u occurs as often or less often in v. We call such rules "grid" rules. By far most rules are grid rules. Grid rules cover all rules which terminate by a total division order. Thus total division orders are shown to be irrelevant for the termination problem of one-rule string rewriting.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1156–1168},
numpages = {13},
keywords = {termination, semi-Thue system, grid rule, total division order, string rewriting system, one-rule}
}

@article{10.1137/S0097539797330689,
author = {Attiya, Hagit and Rajsbaum, Sergio},
title = {The Combinatorial Structure of Wait-Free Solvable Tasks},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797330689},
doi = {10.1137/S0097539797330689},
abstract = {This paper presents a self-contained study of wait-free solvable tasks. A new necessary condition for wait-free solvability, based on a restricted set of executions, is proved. This set of executions induces a very simple-to-understand structure, which is used to prove tight bounds for k-set consensus and renaming. The framework is based on topology, but uses only elementary combinatorics, and, in contrast to previous works, does not rely on algebraic or geometric arguments.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1286–1313},
numpages = {28},
keywords = {shared memory systems, distributed systems, atomic read/write registers, renaming, combinatorial topology, wait-free solvable tasks, set consensus, consensus}
}

@article{10.1137/S0097539797327702,
author = {D\"{u}rr, Christoph and Santha, Miklos},
title = {A Decision Procedure for Unitary Linear  Quantum Cellular Automata},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797327702},
doi = {10.1137/S0097539797327702},
abstract = {Linear quantum cellular automata were introduced recently as one of the models of quantum computing.  A basic postulate of quantum mechanics imposes a strong constraint on any quantum machine: it has to be unitary; that is, its time evolution operator has to be a unitary transformation.  In this paper we give an efficient algorithm to decide if a linear quantum cellular automaton is unitary.  The complexity of the algorithm is O(n(3r-1)/(r+1)) = O(n3) in the algebraic computational model if the automaton has a continuous neighborhood of size r, where n is the size of the input.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1076–1089},
numpages = {14},
keywords = {reversible cellular automata, quantum computation}
}

@article{10.1137/S0097539701387660,
author = {Feige, Uriel and Krauthgamer, Robert},
title = {A Polylogarithmic Approximation of the Minimum Bisection},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701387660},
doi = {10.1137/S0097539701387660},
abstract = {A bisection of a graph with n vertices is a partition of its vertices into two sets, each of size n/2. The bisection cost is the number of edges connecting the two sets. It is known that finding a bisection of minimum cost is NP-hard. We present an algorithm that finds a bisection whose cost is within ratio of O(log2 n) from the minimum. For graphs excluding any fixed graph as a minor (e.g., planar graphs) we obtain an improved approximation ratio of O(log n). The previously known approximation ratio for bisection was roughly $sqrt{n}$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1090–1118},
numpages = {29},
keywords = {dynamic programming, approximation algorithms, divide and conquer, graph partitioning, graph separators}
}

@article{10.1137/S0097539701385958,
author = {Merkle, Wolfgang},
title = {Lattice Embeddings for Abstract Bounded Reducibilities},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701385958},
doi = {10.1137/S0097539701385958},
abstract = {We give an abstract account of resource-bounded reducibilities as exemplified by the polynomially time- or logarithmically space-bounded reducibilities of Turing, truth-table, and many-one type. We introduce a small set of axioms that are satisfied for most of the specific resource-bounded reducibilities appearing in the literature. Some of the axioms are of a more algebraic nature, such as the requirement that the reducibility under consideration is a reflexive relation, while others are formulated in terms of recursion theory and, for example, are related to delayed computations of arbitrary recursive sets.The main technical result shown is that for any reducibility that satisfies these axioms, every countable distributive lattice can be embedded into any proper interval of the structure induced on the recursive sets. This extends a corresponding result for polynomially time-bounded reducibilities due to Ambos-Spies [Inform. and Control, 65 (1985), pp. 63--84], as well as a result on embeddings of partial orderings for axiomatically described reducibilities due to Mehlhorn [J. Comput. System Sci., 12 (1976), pp. 147--178].},
journal = {SIAM J. Comput.},
month = apr,
pages = {1119–1155},
numpages = {37},
keywords = {resource-bounded reducibilities, axiomatization of reducibilities, embeddings of partial orderings, abstract reducibilities, embeddings of distributive lattices}
}

@article{10.1137/S0097539700381991,
author = {Laber, Eduardo S. and Milidi\'{u}, Ruy L. and Pessoa, Artur A.},
title = {On Binary Searching with Nonuniform Costs},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700381991},
doi = {10.1137/S0097539700381991},
abstract = {Let us consider an ordered vector A[1:n]. If the cost of testing  each position is similar, then the standard binary search is the  best strategy to search the vector. This is true in both the average  and  worst case. However, if the costs are nonuniform, then the best strategy is not  necessarily the standard binary search. The best  algorithm to construct a strategy that minimizes the expected search cost runs in O(n3) time and requires O(n2) space. The same complexities hold for  the best algorithm to construct a strategy that minimizes the worst case search cost.Here, we show how to efficiently construct search strategies that are at most at a constant factor from the optimal one. These constructions take linear time and use only linear space. For both the problem of minimizing the expected search cost, under uniform access probabilities, and the problem of minimizing the worst case search cost, we present algorithms that require O(n) space and give a $(2+epsilon+o(1))$-approximated solution in O(n) time for any fixed value of $epsilon &gt; 0$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1022–1047},
numpages = {26},
keywords = {search trees, scaling, approximation algorithms}
}

@article{10.1137/S009753970038050X,
author = {Theobald, Thorsten},
title = {An Enumerative Geometry Framework for Algorithmic Line Problems in $\mathbb R^3$},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970038050X},
doi = {10.1137/S009753970038050X},
abstract = {We investigate the enumerative geometry aspects of algorithmic line problems when the admissible bodies are balls or polytopes. For this purpose, we study the common tangent lines/transversals to k balls of arbitrary radii and 4-k lines in ${mathbb R}^3$. In particular, we compute tight upper bounds for the maximum number of real common tangents/transversals in these cases. Our results extend the results of Macdonald, Pach, and Theobald who investigated common tangents to four unit balls in ${mathbb R}^3$ [Discrete Comput. Geom., 26 (2001), pp. 1--17].},
journal = {SIAM J. Comput.},
month = apr,
pages = {1212–1228},
numpages = {17},
keywords = {computational geometry, balls, transversals, tangents, real solutions, lines, enumerative geometry}
}

@article{10.1137/S0097539700377025,
author = {Valiant, Leslie G.},
title = {Quantum Circuits That Can Be Simulated Classically in Polynomial Time},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377025},
doi = {10.1137/S0097539700377025},
abstract = {A model of quantum computation based on unitary matrix operations was introduced by Feynman and Deutsch. It has been asked whether the power of this model exceeds that of classical Turing machines. We show here that a significant class of these quantum computations can be simulated classically in polynomial time. In particular we show that two-bit operations characterized by 4 \texttimes{} 4 matrices in which the sixteen entries obey a set of five polynomial relations can be composed according to certain rules to yield a class of circuits that  can be simulated classically in polynomial time.  This contrasts with the known universality of two-bit operations and  demonstrates that efficient quantum computation of restricted classes is reconcilable with the Polynomial Time Turing Hypothesis. Therefore, it is possible that, The techniques introduced bring the quantum computational model within the realm of algebraic complexity theory. In a manner consistent with one view of quantum physics, the wave function is simulated deterministically, and randomization arises only in the course of making measurements.  The results generalize the quantum model in that they do not require the matrices to be unitary. In a different direction these techniques also yield deterministic polynomial time algorithms for the decision and parity problems for certain classes of read-twice Boolean formulae. All our results are based on the use of gates that are defined in terms of their graph matching properties.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1229–1254},
numpages = {26},
keywords = {quantum computation, matchgates, polynomial time simulation, Turing Hypothesis}
}

@article{10.1137/S0097539700376937,
author = {Downey, Rod G. and Hirschfeldt, Denis R. and Nies, Andr\'{e}},
title = {Randomness, Computability, and Density},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700376937},
doi = {10.1137/S0097539700376937},
abstract = {We study effectively given positive reals (more specifically, computably enumerable reals) under a measure of relative randomness introduced by Solovay [manuscript, IBM Thomas J. Watson Research Center, Yorktown Heights, NY, 1975] and studied by Calude, Hertling, Khoussainov, and Wang [ Theoret. Comput. Sci. , 255 (2001), pp. 125--149], Calude [ Theoret. Comput. Sci. , 271 (2002), pp. 3--14], Kucera and Slaman [ SIAM J. Comput. , 31 (2002), pp. 199--211], and Downey, Hirschfeldt, and LaForte [ Mathematical Foundations of Computer Science 2001, Springer-Verlag, Berlin, 2001, pp. 316--327], among others. This measure is called domination or Solovay reducibility and is defined by saying that $\alpha$ dominates $\beta$ if there are a constant c and a partial computable function $\varphi$ such that for all positive rationals $q<\alpha$ we have $\varphi(q)\!\downarrow<\beta$ and $\beta- \varphi(q) \leqslant c(\alpha- q)$. The intuition is that an approximating sequence for $\alpha$ generates one for $\beta$ whose rate of convergence is not much slower than that of the original sequence. It is not hard to show that if $\alpha$ dominates $\beta$, then the initial segment complexity of $\alpha$ is at least that of $\beta$. In this paper we are concerned with structural properties of the degree structure generated by Solovay reducibility. We answer a natural question in this area of investigation by proving the density of the Solovay degrees. We also provide a new characterization of the random computably enumerable reals in terms of splittings in the Solovay degrees. Specifically, we show that the Solovay degrees of computably enumerable reals are dense, that any incomplete Solovay degree splits over any lesser degree, and that the join of any two incomplete Solovay degrees is incomplete, so that the complete Solovay degree does not split at all. The methodology is of some technical interest, since it includes a priority argument in which the injuries are themselves controlled by randomness considerations.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1169–1183},
numpages = {15},
keywords = {computably enumerable reals, Kolmogorov complexity, algorithmic information theory, randomness, Solovay reducibility}
}

@article{10.1137/S0097539700369156,
author = {Beame, Paul and Karp, Richard and Pitassi, Toniann and Saks, Michael},
title = {The Efficiency of Resolution and Davis--Putnam Procedures},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700369156},
doi = {10.1137/S0097539700369156},
abstract = {We consider several problems related to the use of resolution-based methods for determining whether a given boolean formula in conjunctive normal form is satisfiable.  First, building on the work of Clegg, Edmonds, and Impagliazzo in [Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing, Philadelphia, PA, 1996, ACM, New York, 1996, pp. 174--183], we give an algorithm for unsatisfiability that when given an unsatisfiable formula of F finds a resolution proof of F. The runtime of our algorithm is subexponential in the size of the shortest resolution proof of F. Next, we investigate a class of backtrack search algorithms for producing resolution refutations of unsatisfiability, commonly known as Davis--Putnam procedures, and provide the first asymptotically tight average-case complexity analysis for their behavior on random formulas.  In particular,  for a simple algorithm in this class, called ordered DLL, we prove that the running time of the algorithm on a randomly generated k-CNF formula with n variables and m clauses is $2^{Theta(n(n/m)^{1/(k-2)})}$ with probability $1-o(1)$. Finally, we give new lower bounds on $mbox{res}(F)$, the size of the smallest resolution refutation of F, for a class of formulas representing the pigeonhole principle and for randomly generated formulas. For random formulas, Chvatal and Szemeredi [J. ACM, 35 (1988), pp. 759--768] had shown that random 3-CNF formulas with a linear number of clauses require exponential size resolution proofs, and Fu [On the Complexity of Proof Systems, Ph. D. thesis, University of Toronto, Toronto, ON, Canada, 1995] extended their results to k-CNF formulas.  These proofs apply only when the number of clauses is $Omega(n log n)$.  We show that a lower bound of the form $2^{n^{gamma}}$ holds with high probability even when the number of clauses is $n^{(k+2)/4-epsilon}$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1048–1075},
numpages = {28},
keywords = {satisfiability, proof complexity, search algorithms, random formulas, Davis--Putnam procedure, resolution, lower bounds}
}

@article{10.1137/S0097539700366735,
author = {Alekhnovich, Michael and Ben-Sasson, Eli and Razborov, Alexander A. and Wigderson, Avi},
title = {Space Complexity in Propositional Calculus},
year = {2002},
issue_date = {2002},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700366735},
doi = {10.1137/S0097539700366735},
abstract = {We study space complexity in the framework of propositional proofs. We consider a natural model analogous to Turing machines with a read-only input tape and such popular propositional proof systems as resolution, polynomial calculus, and Frege systems. We propose two different space measures, corresponding to the maximal number of bits, and clauses/monomials that need to be kept in the memory simultaneously. We prove a number of lower and upper bounds in these models, as well as some structural results concerning the clause space for resolution and Frege systems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1184–1211},
numpages = {28},
keywords = {resolution, Frege, proof complexity, polynomial calculus}
}

@article{10.1137/S0097539799364912,
author = {Gafni, Eli and Mitzenmacher, Michael},
title = {Analysis of Timing-Based Mutual Exclusion with Random Times},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799364912},
doi = {10.1137/S0097539799364912},
abstract = {Various timing-based mutual exclusion algorithms have been proposed that guarantee mutual exclusion if certain timing assumptions hold. In this paper, we examine how these algorithms behave when the time for the basic operations is governed by probability distributions. In particular, we are concerned with how often such algorithms succeed in allowing a processor to obtain a critical region and how this success rate depends on the random variables involved. We explore this question in the case where operation times are governed by exponential and gamma distributions, using both theoretical analysis and simulations.},
journal = {SIAM J. Comput.},
month = mar,
pages = {816–837},
numpages = {22},
keywords = {locks, timed mutual exclusion, Markov chains, mutual exclusion}
}

@article{10.1137/S0097539799364092,
author = {Munro, J. Ian and Raman, Venkatesh},
title = {Succinct Representation of Balanced Parentheses and Static Trees},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799364092},
doi = {10.1137/S0097539799364092},
abstract = {We consider the implementation of abstract data types for the static objects: binary tree, rooted ordered tree, and a balanced sequence of parentheses. Our representations use an amount of space within a lower order term of the information theoretic minimum and support, in constant time, a richer set of navigational operations than has previously been considered in similar work. In the case of binary trees, for instance, we can move from a node to its left or right child or to the parent in constant time while retaining knowledge of the size of the subtree at which we are positioned. The approach is applied to produce a succinct representation of planar graphs in which one can test adjacency in constant time.},
journal = {SIAM J. Comput.},
month = mar,
pages = {762–776},
numpages = {15},
keywords = {binary trees, abstract data type, rooted ordered trees, balanced parenthesis, planar graphs, succinct representation}
}

@article{10.1137/S0097539799355314,
author = {Kolliopoulos, Stavros G. and Stein, Clifford},
title = {Approximation Algorithms for Single-Source Unsplittable Flow},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799355314},
doi = {10.1137/S0097539799355314},
abstract = {In the single-source unsplittable flow problem, we are given a network G, a source vertex s, and k commodities with sinks ti and real-valued demands $rho_i,$ $1leq i leq k.$ We seek to route the demand $rho_i$ of each commodity i along a single s-ti flow path so that the total flow routed across any edge e is bounded by the edge capacity ue. The conceptual difficulty of this NP-hard problem arises from combining packing constraints due to the existence of capacities with path selection in a  graph of arbitrary topology.  In this paper we give a generic framework, which yields approximation algorithms that are simpler than those previously known and achieve significant improvements upon the approximation ratios.  Our framework, with appropriate subroutines, applies to all optimization versions previously considered and, unlike previous work, treats in a unified manner directed and undirected graphs. We provide extensions of our algorithms which yield the best possible approximation guarantees for restricted sets of demand values and an associated scheduling problem.},
journal = {SIAM J. Comput.},
month = mar,
pages = {919–946},
numpages = {28},
keywords = {unsplittable flow, disjoint paths, parallel machine scheduling, network algorithms, routing, network flow, approximation algorithms}
}

@article{10.1137/S0097539799355053,
author = {Moore, Cristopher and Nilsson, Martin},
title = {Parallel Quantum Computation  and Quantum Codes},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799355053},
doi = {10.1137/S0097539799355053},
abstract = {We study the class  QNC of efficient parallel quantum circuits, the quantum analog of NC.  We exhibit several useful gadgets and prove that various classes of circuits can be parallelized to logarithmic depth, including circuits for encoding and decoding standard quantum error-correcting codes, or, more generally, any circuit consisting of controlled-not gates, controlled $pi$-shifts, and Hadamard gates. Finally, while we note the exact quantum Fourier transform can be parallelized to linear depth, we conjecture that neither it nor a simpler "staircase" circuit can be parallelized to less than this.},
journal = {SIAM J. Comput.},
month = mar,
pages = {799–815},
numpages = {17},
keywords = {quantum complexity classes, quantum error-correcting codes, parallel computation, group theory, quantum circuits}
}

@article{10.1137/S0097539799351717,
author = {Gavoille, Cyril and Peleg, David},
title = {The Compactness of Interval Routing for  Almost All Graphs},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799351717},
doi = {10.1137/S0097539799351717},
abstract = {Interval routing is a compact way of representing routing tables on a graph. It is based on grouping together, in each node, destination addresses that use the same outgoing edge in the routing table. Such groups of addresses are represented by some intervals of consecutive integers.  We show that almost all the graphs, i.e., a fraction of at least 1-1/n2 of all the n-node graphs, support a shortest path interval routing with  three intervals per outgoing edge, even if the addresses of the nodes are arbitrarily fixed in advance and cannot be chosen by the designer of the routing scheme.  In case the addresses are initialized randomly, we show that two intervals per outgoing edge suffice, and, conversely, that two intervals are required for almost all graphs. Finally, if the node addresses can be chosen as desired, we show how to design in polynomial time a shortest path interval routing with a single interval per outgoing edge for all but at most O(log3n) outgoing edges in each node. It follows that almost all graphs support a shortest path routing scheme which requires at most n+O(log4n) bits of routing information per node, improving on the previous upper bound.},
journal = {SIAM J. Comput.},
month = mar,
pages = {706–721},
numpages = {16},
keywords = {random graphs, interval routing, compact routing}
}

@article{10.1137/S009753979834388X,
author = {Buhrman, Harry and Fortnow, Lance and Laplante, Sophie},
title = {Resource-Bounded Kolmogorov Complexity Revisited},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979834388X},
doi = {10.1137/S009753979834388X},
abstract = {We take a fresh look at CD complexity, where CD t( x) is the size of the smallest program that distinguishes x from all other strings in time t(| x|). We also look at CND complexity, a new nondeterministic variant of CD complexity, and time-bounded Kolmogorov complexity, denoted by C complexity. We show several results relating time-bounded C, CD, and CND complexity and their applications to a variety of questions in computational complexity theory, including the following: Showing how to approximate the size of a set using CD complexity without using the random string as needed in Sipser's earlier proof of a similar result. Also, we give a new simpler proof of this result of Sipser's. Improving these bounds for almost all strings, using extractors. A proof of the Valiant--Vazirani lemma directly from Sipser's earlier CD lemma. A relativized lower bound for CND complexity. Exact characterizations of equivalences between C , CD , and CND complexity. Showing that satisfying assignments of a satisfiable Boolean formula can be enumerated in time polynomial in the size of the output if and only if a unique assignment can be found quickly. This answers an open question of Papadimitriou. A new Kolmogorov complexity-based proof that BPP subseteqSigma_2^p$. New Kolmogorov complexity based constructions of the following relativized worlds: There exists an infinite set in P with no sparse infinite NP subsets. EXP = NEXP but there exists a NEXP machine whose accepting paths cannot be found in exponential time. Satisfying assignments cannot be found with nonadaptive queries to SAT .},
journal = {SIAM J. Comput.},
month = mar,
pages = {887–905},
numpages = {19},
keywords = {Kolmogorov complexity, CD complexity, computational complexity}
}

@article{10.1137/S0097539798340217,
author = {Halpern, Joseph Y. and Moses, Yoram and Waarts, Orli},
title = {A Characterization of Eventual  Byzantine Agreement},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798340217},
doi = {10.1137/S0097539798340217},
abstract = {We investigate eventual Byzantine agreement (EBA) in the crash and omission failure modes.  The emphasis is on characterizing optimal EBA protocols in terms of the states  of knowledge required by the processors in order to attain EBA.  It is well known that common knowledge among the nonfaulty processors is a necessary and sufficient condition for attaining  simultaneous Byzantine agreement (SBA).  We define a new variant that we call  continual common knowledge and use it to provide necessary and sufficient conditions for attaining EBA. Using this characterization, we provide a technique that allows us to start with any EBA protocol and convert it to an optimal EBA protocol using a two-step process.},
journal = {SIAM J. Comput.},
month = mar,
pages = {838–865},
numpages = {28},
keywords = {fault-tolerance, continual common knowledge, common knowledge, optimal protocol, eventual Byzantine agreement}
}

@article{10.1137/S0097539797329397,
author = {Ben-Amram, Amir M. and Galil, Zvi},
title = {Topological Lower Bounds on Algebraic Random Access Machines},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797329397},
doi = {10.1137/S0097539797329397},
abstract = {We prove general lower bounds for set recognition on random access machines (RAMs) that operate on real numbers with algebraic operations ${+,-,times,/}$, as well as RAMs that use the operations ${+,-,times,lfloor;rfloor}$. We do it by extending a technique formerly used with respect to algebraic computation trees. In the case of algebraic computation trees, the complexity was related to the number of connected components of the set  W  to be recognized. For RAMs, four similar results apply to the number of connected components of $W^circ$, the topological interior of  W . Two results use $(overline W)^circ$, the interior of the topological closure of $W$. We present theorems that can be applied to a variety of problems and obtain lower bounds, many of them tight, for the following models:1. A RAM which operates on real numbers, using integers to address memory and either the operations ${+,-,times,/}$ or ${+,-,times,lfloor;rfloor}$.2. A RAM of each of the above instruction sets, extended by allowing arbitrary real numbers to be used as memory addresses and adding a test-for-integer instruction.3. A RAM of each of the above instruction sets which can compute with arbitrary real numbers, as well as use them for memory addressing, while the input is restricted to the integers. (For one result on this model, we require that all program constants be rational.)},
journal = {SIAM J. Comput.},
month = mar,
pages = {722–761},
numpages = {40},
keywords = {knapsack, algebraic computation trees, element distinctness, component counting arguments}
}

@article{10.1137/S0097539797322772,
author = {Th\'{e}rien, Denis and Wilke, Thomas},
title = {Temporal Logic and Semidirect Products: An Effective Characterization of the  Until Hierarchy},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797322772},
doi = {10.1137/S0097539797322772},
abstract = {We reveal an intimate connection between semidirect products of finite semigroups and substitution of formulas in linear temporal logic. We use this connection to obtain an algebraic characterization of the until hierarchy of linear temporal logic. (The kth level of that hierarchy is comprised of all temporal properties that are expressible by a formula of nesting depth k in the until operator.) Applying deep results from finite semigroup theory we are able to prove that each level of the until hierarchy is decidable. By means of Ehrenfeucht--Fraiss\'{e} games, we extend the results from linear temporal logic over finite sequences to linear temporal logic over infinite sequences.},
journal = {SIAM J. Comput.},
month = mar,
pages = {777–798},
numpages = {22},
keywords = {linear temporal logic, semidirect products, finite semigroups, until hierarchy, pseudovarieties of semigroups, aperiodic semigroups, substitution}
}

@article{10.1137/S0097539797317123,
author = {Buhrman, Harry and Longpr\'{e}, Luc},
title = {Compressibility and Resource Bounded Measure},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797317123},
doi = {10.1137/S0097539797317123},
abstract = {We give a new definition of resource bounded measure based on compressibility of infinite binary strings. We prove that the new definition is equivalent to the one commonly used. This new characterization offers us a different way to look at resource bounded measure, shedding more light on the meaning of measure zero results and providing one more tool to prove such results. The main contribution of the paper is the new definition and the proofs leading to the equivalence result. We then show how this new characterization can be used to prove that the class of linear autoreducible sets has p- measure 0. We also prove that the class of sets that are truth-table reducible to a p-selective set has p-measure 0 and that the class of sets that Turing reduce to a subpolynomial dense set has p-measure 0. This strengthens various results.},
journal = {SIAM J. Comput.},
month = mar,
pages = {876–886},
numpages = {11},
keywords = {resource bounded measure, Kolmogorov complexity, compressibility}
}

@article{10.1137/S0097539701395097,
author = {Frieze, Alan},
title = {Corrigendum: Edge-Disjoint Paths in Expander Graphs},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701395097},
doi = {10.1137/S0097539701395097},
journal = {SIAM J. Comput.},
month = mar,
pages = {988},
numpages = {1},
keywords = {uniform distribution, bin packing, best fit decreasing, convergence in distribution}
}

@article{10.1137/S0097539701392056,
author = {Charikar, Moses and Khuller, Samir and Raghavachari, Balaji},
title = {Algorithms for Capacitated Vehicle Routing},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701392056},
doi = {10.1137/S0097539701392056},
abstract = {Given n identical objects (pegs), placed at arbitrary initial locations, we consider the problem of transporting them efficiently to n target locations (slots) with a vehicle that can carry at most k pegs at a time.  This problem is referred to as k-delivery TSP, and it is a generalization of the traveling salesman problem. We give a 5-approximation algorithm for the problem of minimizing the total distance traveled by the vehicle.There are two kinds of transportations possible---one that could drop pegs at intermediate locations and pick them up later in the route for delivery (preemptive) and one that transports pegs to their targets directly (nonpreemptive). In the former case, by exploiting the freedom to drop, one may be able to find a shorter delivery route. We construct a nonpreemptive tour that is within a factor 5 of the optimal preemptive tour. In addition we show that the ratio of the distances traveled by an optimal nonpreemptive tour versus a preemptive tour is bounded by 4.},
journal = {SIAM J. Comput.},
month = mar,
pages = {665–682},
numpages = {18},
keywords = {graphs, traveling salesman problem, vehicle routing, approximation algorithms}
}

@article{10.1137/S0097539701387039,
author = {Pavan, A. and Selman, Alan L.},
title = {Separation of NP-Completeness Notions},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539701387039},
doi = {10.1137/S0097539701387039},
abstract = {We use hypotheses of structural complexity theory to separate various NP-completeness notions. In particular, we introduce an hypothesis from which we describe a set in NP that is $mbox{${leq}^{rm P}_{rm T}$}$-complete but not $mbox{${leq}^{rm P}_{tt}$}$-complete.  We provide fairly thorough analyses of the hypotheses that we introduce.},
journal = {SIAM J. Comput.},
month = mar,
pages = {906–918},
numpages = {13},
keywords = {p-genericity, many-one completeness, Turing completeness, truth-table completeness, p-selectivity}
}

@article{10.1137/S0097539700382108,
author = {Mart\'{\i}nez, Conrado and Roura, Salvador},
title = {Optimal Sampling Strategies in Quicksort and Quickselect},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700382108},
doi = {10.1137/S0097539700382108},
abstract = {It is well known that the performance of quicksort can be improved by selecting the median of a sample of elements as the pivot of each partitioning stage.  For large samples the partitions are better, but the amount of additional comparisons and exchanges to find the median of the sample also increases.  We show in this paper that the optimal sample size to minimize the average total cost of quicksort, as a function of the size n of the current subarray size, is $acdot sqrt{n} + o(sqrt{n},)$.  We give a closed expression for a, which depends on the selection algorithm and the costs of elementary comparisons and exchanges. Moreover, we show that selecting the medians of the samples as pivots is not the best strategy when exchanges are much more expensive than comparisons. We also apply the same ideas and techniques to the analysis of quickselect and get similar results.},
journal = {SIAM J. Comput.},
month = mar,
pages = {683–705},
numpages = {23},
keywords = {median-of-$(2k+1)$, selection, quickselect, sorting, divide-and-conquer, quicksort, sampling, analysis of algorithms}
}

@article{10.1137/S0097539700382005,
author = {Chakrabarti, Amit and Khot, Subhash and Shi, Yaoyun},
title = {Evasiveness of Subgraph Containment and Related Properties},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700382005},
doi = {10.1137/S0097539700382005},
abstract = {We prove new results on evasiveness of monotone graph properties by extending the techniques of Kahn, Saks, and Sturtevant [ Combinatorica, 4 (1984), pp. 297--306]. For the property of containing a subgraph isomorphic to a fixed graph, and a fairly large class of related n-vertex graph properties, we show evasiveness for an arithmetic progression of values of n. This implies a $frac12n^2 - O(n)$ lower bound on the decision tree complexity of these properties.We prove that properties that are preserved under taking graph minors are evasive for all sufficiently large n. This greatly generalizes a theorem due to Best, van Emde Boas, and Lenstra [A Sharpened Version of the Aanderaa--Rosenberg Conjecture, Report ZW 30/74, Mathematisch Centrum, Amsterdam, The Netherlands, 1974] which states that planarity is evasive. We prove a similar result for bipartite subgraph containment.},
journal = {SIAM J. Comput.},
month = mar,
pages = {866–875},
numpages = {10},
keywords = {monotone graph properties, evasiveness, topological method, decision tree complexity, graph property testing}
}

@article{10.1137/S0097539700380201,
author = {Rieger, J. H.},
title = {Corrigendum: Proximity in Arrangements  of Algebraic Sets},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700380201},
doi = {10.1137/S0097539700380201},
abstract = {This erratum corrects an error found in [J. H. Rieger, SIAM J. Comput., 29 (1999), pp. 433--458].},
journal = {SIAM J. Comput.},
month = mar,
pages = {987},
numpages = {1},
keywords = {convergence in distribution, uniform distribution, best fit decreasing, bin packing}
}

@article{10.1137/S0097539700377864,
author = {Boreale, Michele and Nicola, Rocco De and Pugliese, Rosario},
title = {Proof Techniques for Cryptographic Processes},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377864},
doi = {10.1137/S0097539700377864},
abstract = {Contextual equivalences for cryptographic process calculi, like the spi-calculus, can be used to reason about correctness of protocols, but their definition suffers from quantification over all possible contexts. Here, we focus on two such equivalences, namely may-testing and barbed equivalence, and investigate tractable proof methods for them. To this aim, we design an enriched labelled transition system, where transitions are constrained by the knowledge the environment has of names and keys. The new transition system is then used to define  a trace equivalence and a weak bisimulation equivalence that avoid quantification over contexts. Our main results are soundness and completeness of trace and weak bisimulation equivalence with respect to may-testing and barbed equivalence, respectively. They lead  to more direct proof methods for equivalence checking. The use of these methods is illustrated with a few examples concerning implementation of secure channels and verification of protocol correctness.},
journal = {SIAM J. Comput.},
month = mar,
pages = {947–986},
numpages = {40},
keywords = {reasoning about security, process calculi, semantics, formal methods}
}

@article{10.1137/S0097539799358847,
author = {Chen, Gen-Huey and Kao, Ming-Yang and Lyuu, Yuh-Dauh and Wong, Hsing-Kuo},
title = {Optimal Buy-and-Hold Strategies for Financial Markets with Bounded Daily Returns},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799358847},
doi = {10.1137/S0097539799358847},
abstract = {In the context of investment analysis, we formulate an abstract online computing problem called a planning game and develop general tools for solving such a game.  We then use the tools to investigate a practical buy-and-hold trading problem faced by long-term investors in stocks.  We obtain the unique optimal static online algorithm for the problem and determine its exact competitive ratio. We also compare this algorithm with the popular dollar averaging strategy using actual market data.},
journal = {SIAM J. Comput.},
month = feb,
pages = {447–459},
numpages = {13},
keywords = {minimax theorem, linear programming, planning games, dollar averaging strategy, balanced strategy, online algorithms, competitive analysis, zero-sum two-person games, buy-and-hold trading problems}
}

@article{10.1137/S0097539799354138,
author = {Bar-Noy, Amotz and Guha, Sudipto},
title = {Approximating the Throughput of Multiple Machines in Real-Time Scheduling},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799354138},
doi = {10.1137/S0097539799354138},
abstract = {We consider the following fundamental scheduling problem. The input to the problem consists of n jobs and k machines. Each of the jobs is associated with a release time, a deadline, a weight, and a processing time on each of the machines. The goal is to find a nonpreemptive schedule that maximizes the weight of jobs that meet their respective deadlines. We give constant factor approximation algorithms for four variants of the problem, depending on the type of the machines (identical vs. unrelated) and the weight of the jobs (identical vs. arbitrary). All these variants are known to be NP-hard, and the two variants involving unrelated machines are also MAX-SNP hard. The specific results obtained are as follows: For identical job weights and unrelated machines: a greedy $2$-approximation algorithm. For identical job weights and k identical machines: the same greedy algorithm achieves a tight $frac{(1+1/k)^k}{(1+1/k)^k-1}$ approximation factor. For arbitrary job weights and a single machine: an LP formulation achieves a 2-approximation for polynomially bounded integral input and a 3-approximation for arbitrary input. For unrelated machines, the factors are 3 and 4, respectively. For arbitrary job weights and k identical machines: the LP-based algorithm applied repeatedly achieves a $frac{(1+1/k)^k}{(1+1/k)^k-1}$ approximation factor for polynomially bounded integral input and a $frac{(1+1/2k)^k}{(1+1/2k)^k-1}$ approximation factor for arbitrary input. For arbitrary job weights and unrelated machines: a combinatorial $(3+2sqrt{2} approx 5.828)$-approximation algorithm.},
journal = {SIAM J. Comput.},
month = feb,
pages = {331–352},
numpages = {22},
keywords = {real-time scheduling, parallel machines scheduling, scheduling, throughput, approximation algorithms, multiple machines scheduling}
}

@article{10.1137/S0097539799348670,
author = {Hoffmann, Frank and Icking, Christian and Klein, Rolf and Kriegel, Klaus},
title = {The Polygon Exploration Problem},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799348670},
doi = {10.1137/S0097539799348670},
abstract = {We present an on-line strategy that enables a mobile robot with vision to explore an unknown simple polygon. We prove that the resulting tour is less than 26.5 times as long as the shortest watchman tour that could be computed off-line.Our analysis is doubly founded on a novel geometric structure called  angle hull. Let D be a connected region inside a simple polygon, P. We define the  angle hull of D, ${cal AH}(D)$, to be the set of all points in P that can see two points of D at a right angle. We show that the perimeter of ${cal AH}(D)$ cannot exceed in length the perimeter of D by more than a factor of 2. This upper bound is tight.},
journal = {SIAM J. Comput.},
month = feb,
pages = {577–600},
numpages = {24},
keywords = {robot, motion planning, optimum watchman tour, computational geometry, angle hull, polygon, navigation, on-line algorithm, curve length, competitive strategy}
}

@article{10.1137/S0097539798346135,
author = {Bar-Noy, Amotz and Freund, Ari},
title = {On-Line Load Balancing in a Hierarchical Server Topology},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798346135},
doi = {10.1137/S0097539798346135},
abstract = {In a hierarchical server environment jobs are to be assigned in an on-line fashion to a collection of servers which form a hierarchy of capability: each job requests a specific server meeting its needs, but the system is free to assign it either to that server or to any other server higher in the hierarchy. Each job carries a certain load, which it imparts to the server it is assigned to. The goal is to find a competitive assignment in which the maximum total load on a server is minimized. We consider the linear hierarchy in which the servers are totally ordered in terms of their capabilities. We investigate several variants of the problem. In the  unweighted  (as opposed to  weighted ) problem all jobs have unit weight. In the  fractional  (as opposed to  integral ) model a job may be assigned to several servers, each receiving some fraction of its weight. Finally,  temporary  (as opposed to  permanent ) jobs may depart after being active for some finite duration of time. We show an optimal  e -competitive algorithm for the unweighted integral permanent model. The same algorithm is (  e +1)-competitive in the weighted case. Its fractional version is  e -competitive even if temporary jobs are allowed. For the integral model with temporary jobs we show an algorithm which is 4-competitive in the unweighted case and 5-competitive in the weighted case. We show a lower bound of  e  for the unweighted case (both integral and fractional). This bound is valid even with respect to randomized algorithms. We also show a lower bound of 3 for the unweighted integral model when temporary jobs are allowed.We generalize the problem and consider hierarchies in which the servers form a tree. In the tree hierarchy, any job assignable to a node is also assignable to the node's ancestors. We show a deterministic algorithm which is 4-competitive in the unweighted case and 5-competitive in the weighted case, where only permanent jobs are allowed. Randomizing this algorithm improves its competitiveness to  e  and  e +1, respectively. We also show an $Omega(sqrt{n})$ lower bound when temporary jobs are allowed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {527–549},
numpages = {23},
keywords = {on-line algorithms, resource procurement, temporary jobs, load balancing, hierarchical servers}
}

@article{10.1137/S0097539798342496,
author = {Cryan, Mary and Goldberg, Leslie Ann and Goldberg, Paul W.},
title = {Evolutionary Trees Can Be Learned in Polynomial Time in the Two-State General Markov Model},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798342496},
doi = {10.1137/S0097539798342496},
abstract = {The j-state general Markov model of evolution (due to Steel) is a stochastic model concerned with the evolution of strings over an alphabet of size j. In particular, the two-state general Markov model of evolution generalizes the well-known Cavender--Farris--Neyman model of evolution by removing the symmetry restriction (which requires that the probability that a "0" turns into a "1" along an edge is the same as the probability that a "1" turns into a "0" along the edge). Farach and Kannan showed how to probably approximately correct (PAC)-learn Markov evolutionary trees in the Cavender--Farris--Neyman model provided that the target tree satisfies the additional restriction that all pairs of leaves have a sufficiently high probability of being the same. We show how to remove both restrictions and thereby obtain the first polynomial-time PAC-learning algorithm (in the sense of Kearns et al. [Proceedings of the  26th Annual ACM Symposium on the Theory of Computing, 1994, pp. 273--282]) for the general class of two-state Markov evolutionary trees.},
journal = {SIAM J. Comput.},
month = feb,
pages = {375–397},
numpages = {23},
keywords = {PAC-learning, computational learning theory, evolutionary trees, learning of distributions, Markov model}
}

@article{10.1137/S0097539798337613,
author = {Erg\"{u}n, Funda and Kumar, S. Ravi and Rubinfeld, Ronitt},
title = {Checking Approximate Computations of Polynomials and Functional Equations},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798337613},
doi = {10.1137/S0097539798337613},
abstract = {A majority of the results on self-testing and correcting deal with programs which purport to compute the correct results precisely. We relax this notion of correctness and show how to check programs that compute only a numerical approximation to the correct answer. The types of programs that we deal with are those computing polynomials and functions defined by certain types of functional equations.  We present results showing how to perform approximate checking, self-testing, and self-correcting of polynomials, settling in the affirmative a question raised by [P. Gemmell et al., Proceedings of the 23rd ACM Symposium on Theory of Computing, 1991, pp. 32--42; R. Rubinfeld and M. Sudan, Proceedings of the Third Annual ACM-SIAM Symposium on Discrete Algorithms, Orlando, FL, 1992, pp. 23--43; R. Rubinfeld and M. Sudan, SIAM J. Comput., 25 (1996), pp. 252--271]. We obtain this by first building approximate self-testers for linear and multilinear functions.  We then show how to perform approximate checking, self-testing, and self-correcting for those functions that satisfy addition theorems, settling a question raised by [R. Rubinfeld, SIAM J. Comput., 28 (1999), pp. 1972--1997]. In both cases, we show that the properties used to test programs for these functions are both robust (in the approximate sense) and stable. Finally, we explore the use of reductions between functional equations in the context of approximate self-testing. Our results have implications for the stability theory of functional equations.},
journal = {SIAM J. Comput.},
month = feb,
pages = {550–576},
numpages = {27},
keywords = {program testing, approximate testing, polynomials, functional equations, property testing}
}

@article{10.1137/S0097539797327209,
author = {Henzinger, Monika R. and King, Valerie},
title = {Maintaining Minimum Spanning Forests in Dynamic Graphs},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797327209},
doi = {10.1137/S0097539797327209},
abstract = {We present the first fully dynamic algorithm for maintaining a minimum spanning forest in time $o(sqrt n)$ per operation. To be precise, the algorithm uses O(n1/3 log n) amortized time per update operation. The algorithm is fairly simple and deterministic. An immediate consequence is the first fully dynamic deterministic algorithm for maintaining connectivity and bipartiteness in amortized time O(n1/3 log n) per update, with O(1) worst case time per query.},
journal = {SIAM J. Comput.},
month = feb,
pages = {364–374},
numpages = {11},
keywords = {dynamic graph, data structure, graph algorithm, minimum spanning tree}
}

@article{10.1137/S0097539797321602,
author = {Vadhan, Salil P.},
title = {The Complexity of Counting in Sparse, Regular,  and Planar Graphs},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797321602},
doi = {10.1137/S0097539797321602},
abstract = {We show that a number of graph-theoretic counting problems remain ${cal NP}$-hard, indeed $#{cal P}$-complete, in very restricted classes of graphs. In particular, we prove that the problems of counting matchings, vertex covers, independent sets, and extremal variants of these all remain hard when restricted to planar bipartite graphs of bounded degree or regular graphs of constant degree.  We obtain corollaries about counting cliques in restricted classes of graphs and counting satisfying assignments to restricted classes of monotone 2-CNF formulae. To achieve these results, a new interpolation-based reduction technique which preserves properties such as constant degree is introduced.},
journal = {SIAM J. Comput.},
month = feb,
pages = {398–427},
numpages = {30},
keywords = {completeness, matchings, $#cal P$, independent sets, polynomial interpolation, Fibonacci numbers, vertex covers}
}

@article{10.1137/S009753979732147X,
author = {SIAM Staff},
title = {A 2-Approximation Algorithm for the Directed Multiway Cut Problem},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732147X},
doi = {10.1137/S009753979732147X},
abstract = {A directed multiway cut separates a set of terminals T={s1, . . . , sk} in a directed capacitated graph G=(V,E). Finding a minimum directed multiway cut is an NP-hard problem. We give a polynomial-time algorithm that achieves an approximation factor of 2 for this problem. This improves the result of Garg, Vazirani, and Yannakakis [Proceedings of the 21st International Colloquium on Automata, Languages, and Programming, Jerusalem, Israel, 1994,  pp. 487--498], who gave an algorithm that achieves an approximation factor of 2 log k. Our approximation algorithm uses a novel technique for relaxing a multiway flow function in order to find a directed multiway cut. It also implies that the integrality gap of the linear program for the directed multiway cut problem is at most 2.},
journal = {SIAM J. Comput.},
month = feb,
pages = {477–482},
numpages = {6},
keywords = {approximation algorithms, combinatorial optimization, multiway cut, multicommodity flow, directed graph}
}

@article{10.1137/S0097539794277123,
author = {Garg, Ashim and Tamassia, Roberto},
title = {On the Computational Complexity of Upward and Rectilinear Planarity Testing},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794277123},
doi = {10.1137/S0097539794277123},
abstract = {A directed graph is upward planar if it can be drawn in the plane such that every edge is a monotonically increasing curve in the vertical direction and no two edges cross. An undirected graph is rectilinear planar if it can be drawn in the plane such that every edge is a horizontal or vertical segment and no two edges cross. Testing upward planarity and rectilinear planarity are fundamental problems in the effective visualization of various graph and network structures. For example, upward planarity is useful for the display of order diagrams and subroutine-call graphs, while rectilinear planarity is useful for the display of circuit schematics and entity-relationship diagrams. We show that upward planarity testing and rectilinear planarity testing are NP-complete problems. We also show that it is NP-hard to approximate the minimum number of bends in a planar orthogonal drawing of an  n -vertex graph with an $O(n^{1-epsilon})$ error for any $epsilon &gt; 0$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {601–625},
numpages = {25},
keywords = {graph drawing, ordered set, upward drawing, layout, approximation algorithm, orthogonal drawing, NP-complete problem, planar graph, computational complexity, planar drawing, algorithm, rectilinear drawing}
}

@article{10.1137/S009753970038715X,
author = {Mulmuley, Ketan D. and Sohoni, Milind},
title = {Geometric Complexity Theory I: An Approach to the <i>P</i> vs. <i>NP</i> and Related Problems},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970038715X},
doi = {10.1137/S009753970038715X},
abstract = {We suggest an  approach based on geometric invariant theory to the fundamental lower bound problems in complexity theory concerning formula and circuit size. Specifically, we introduce the notion of a  partially stable point in a reductive-group representation, which generalizes the notion of stability   in geometric invariant theory due to Mumford [Geometric Invariant Theory, Springer-Verlag, Berlin, 1965]. Then we reduce fundamental lower bound problems in complexity theory to problems  concerning infinitesimal neighborhoods of the orbits of  partially stable points. We also suggest an approach to tackle the latter class of problems via construction of   explicit  obstructions.},
journal = {SIAM J. Comput.},
month = feb,
pages = {496–526},
numpages = {31},
keywords = {stability, geometric invariant theory, representation theory, algebraic geometry, computational complexity}
}

@article{10.1137/S0097539700379760,
author = {Leighton, Tom and Lu, Chi-Jen and Rao, Satish and Srinivasan, Aravind},
title = {New Algorithmic Aspects of the Local Lemma  with Applications to Routing and Partitioning},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700379760},
doi = {10.1137/S0097539700379760},
abstract = {The Lov\'{a}sz local lemma (LLL) is a powerful tool that is increasingly playing a valuable role in computer science. The original lemma was nonconstructive; a breakthrough of Beck and its generalizations (due to Alon and Molloy and Reed) have led to constructive versions. However, these methods do not capture some classes of applications of the LLL. We make progress on this by providing algorithmic approaches to two families of applications of the LLL. The first provides constructive versions of certain applications of an extension of the LLL (modeling, e.g., hypergraph-partitioning and low-congestion routing problems); the second provides new algorithmic results on constructing disjoint paths in graphs. Our results can also be seen as constructive upper bounds on the integrality gap of certain packing problems. One common theme of our work is a "gradual rounding" approach.},
journal = {SIAM J. Comput.},
month = feb,
pages = {626–641},
numpages = {16},
keywords = {integer programming, disjoint paths, randomized rounding}
}

@article{10.1137/S0097539700371053,
author = {R\"{o}dl, Vojtech and Rucinski, Andrzej and Wagner, Michelle},
title = {Matchings Meeting Quotas and Their Impact on the Blow-Up Lemma},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700371053},
doi = {10.1137/S0097539700371053},
abstract = {A bipartite graph G = (U,V;E) is called $epsilon$-regular if the edge density of every sufficiently large induced subgraph differs from the edge density of G by no more than $epsilon$. If, in addition, the degree of each vertex in G is between $(d-epsilon)n$ and $(d+epsilon)n$, where d is the edge density of G and |U|=|V|=n, then G is called super $(d,epsilon)$-regular. In [Combinatorica, 19 (1999), pp. 437--452] it was shown that if $S subset U$ and $T subset V$ are subsets of vertices in a super-regular bipartite graph G = (U,V;E), and if a perfect matching M of G is chosen randomly, then the number of edges of M that go between the sets S and T is roughly |S||T|/n. In this paper, we derandomize this result using the Erdos--Selfridge method of conditional probabilities. As an application, we give an alternative constructive proof of the blow-up lemma of $komlos$, $sarkozy$, and $szemeredi$ (see [Combinatorica, 17 (1997), pp. 109--123] and [Random Structures Algorithms, 12 (1998), pp. 297--312]).},
journal = {SIAM J. Comput.},
month = feb,
pages = {428–446},
numpages = {19},
keywords = {$eps$-regular graphs, perfect matchings, blow-up lemma, derandomization, randomized algorithms, conditional probabilities}
}

@article{10.1137/S0097539700370965,
author = {Roychowdhury, Vwani P. and Vatan, Farrokh},
title = {Quantum Formulas: A Lower Bound and Simulation},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700370965},
doi = {10.1137/S0097539700370965},
abstract = {We show that Nechiporuk's method [I. Wegener, The Complexity of Boolean Functions, Teubner-Wiley, New York, 1987] for proving lower bounds for Boolean formulas can be extended to the quantum case. This leads to an $Omega(n^2/log^2 n)$ lower bound for quantum formulas computing an explicit function. The only known previous explicit lower bound for quantum formulas [A. Yao, Proceedings of 34th IEEE Symposium on Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1993, pp. 352--361] states that the majority function does not have a linear-size quantum formula. We also show that quantum formulas can be simulated by Boolean circuits of almost the same size.},
journal = {SIAM J. Comput.},
month = feb,
pages = {460–476},
numpages = {17},
keywords = {density matrix, lower bound, mixed state, quantum formula}
}

@article{10.1137/S0097539700369909,
author = {Pagh, Rasmus},
title = {Low Redundancy in Static Dictionaries with Constant Query Time},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700369909},
doi = {10.1137/S0097539700369909},
abstract = {A  static dictionary is a data structure storing subsets of a finite universe U, answering membership queries. We show that on a unit cost RAM with word size $Theta(log |U|)$, a static dictionary for n-element sets with constant worst case query time can be obtained using $B+O(loglog |U|)+o(n)$ bits of storage, where $B=ceiling{log_2binom{|U|}{n}}$ is the minimum number of bits needed to represent all n-element subsets of U.},
journal = {SIAM J. Comput.},
month = feb,
pages = {353–363},
numpages = {11},
keywords = {information retrieval, hashing, redundancy, compression, dictionary}
}

@article{10.1137/S0097539700366711,
author = {Merkle, Wolfgang},
title = {The Global Power of Additional Queries to <i>P</i>-Random Oracles},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700366711},
doi = {10.1137/S0097539700366711},
abstract = {We consider separations of reducibilities by random sets. First, we show a result on polynomial time-bounded reducibilities that query their oracle nonadaptively: for every p-random set R, there is a set that is reducible to R with k+1 queries but is not reducible to any other p-random set with at most k queries. This result solves an open problem stated in a recent survey paper by Lutz and Mayordomo [EATCS Bulletin, 68 (1999), pp. 64--80]. Second, we show that the separation result above can be transferred from the setting of polynomial time-bounds to a setting of rec-random sets and recursive reducibilities. This extends the main result of Book, Lutz, and Martin [Inform. and Comput., 120 (1995), pp. 49--54] who, by using different methods, showed a similar separation with respect to Martin-L\"{o}f-random sets. Moreover, in both settings we obtain similar separation results for truth-table versus bounded truth-table reducibility.},
journal = {SIAM J. Comput.},
month = feb,
pages = {483–495},
numpages = {13},
keywords = {truth-table reducibility, effective measure, separation of reducibilities, random sets, effective reducibilities, bounded truth-table reducibility, resource-bounded measure, resource-bounded reducibilities}
}

@article{10.1137/S0097539700366000,
author = {Attiya, Hagit and Fouren, Arie},
title = {Adaptive and Efficient Algorithms for Lattice Agreement and Renaming},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700366000},
doi = {10.1137/S0097539700366000},
abstract = {In a shared-memory system,  n  independent asynchronous processes, with distinct names in the range {0, ...,  N -1}, communicate by reading and writing to shared registers. An algorithm is  wait-free  if a process completes its execution regardless of the behavior of other processes. This paper considers wait-free algorithms whose complexity adjusts to the level of contention in the system: An algorithm is  adaptive  (to total contention) if its step complexity depends only on the actual number of active processes,  k ; this number is unknown in advance and may change in different executions of the algorithm. Adaptive algorithms are presented for two important decision problems,  lattice agreement  and (6  k -1)-  renaming ; the step complexity of both algorithms is  O (  k  log  k ). An interesting component of the (6  k -1)-renaming algorithm is an  O (  N ) algorithm for (2  k -1)-renaming; this improves on the best previously known (2  k -1)-renaming algorithm, which has  O (  Nnk ) step complexity.The efficient renaming algorithm can be modified into an  O (  N ) implementation of atomic snapshots using  dynamic single -writer multi-reader registers. The best known implementations of atomic snapshots have step complexity  O (  N  log  N ) using  static single -writer multi-reader registers, and  O (  N ) using  multi -writer multi-reader registers.},
journal = {SIAM J. Comput.},
month = feb,
pages = {642–664},
numpages = {23},
keywords = {wait-free computation, lattice agreement, atomic read/write registers, renaming, atomic snapshots, shared-memory systems}
}

@article{10.1137/S0097539799361786,
author = {Boyar, Joan and Larsen, Kim S. and Nielsen, Morten N.},
title = {The Accommodating Function: A Generalization of the Competitive Ratio},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799361786},
doi = {10.1137/S0097539799361786},
abstract = {A new measure, the  accommodating function , for the quality of on-line algorithms is presented. The accommodating function, which is a generalization of both the competitive ratio and the competitive ratio on accommodating sequences, measures the quality of an on-line algorithm as a function of the resources that would be sufficient for an optimal off-line algorithm to fully grant all requests. More precisely, if we have some amount of resources  n , the function value at $alpha$ is the usual ratio (still on some fixed amount of resources  n ), except that input sequences are restricted to those where the optimal off-line algorithm will not obtain a better result by having more than the amount $alpha n$ of resources. The accommodating functions for three specific on-line problems are investigated: a variant of bin packing in which the goal is to maximize the number of items put in  n  bins, the seat reservation problem, and the problem of optimizing total flow time when preemption is allowed.We also show that when trying to distinguish between two algorithms, the decision as to which one performs better cannot necessarily be made from the competitive ratio or the competitive ratio on accommodating sequences alone. For the variant of bin-packing considered, we show that Worst-Fit has a strictly better competitive ratio than First-Fit, while First-Fit has a strictly better competitive ratio on accommodating sequences than Worst-Fit.},
journal = {SIAM J. Comput.},
month = jan,
pages = {233–258},
numpages = {26},
keywords = {restricted adversaries, seat reservations, on-line algorithms, bin packing, performance measures, flow time, competitive analysis}
}

@article{10.1137/S0097539799361208,
author = {Kao, Ming-Yang and Lam, Tak-Wah and Sung, Wing-Kin and Ting, Hing-Fung},
title = {A Decomposition Theorem for Maximum Weight Bipartite Matchings},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799361208},
doi = {10.1137/S0097539799361208},
abstract = {Let G be a bipartite graph with positive integer weights on the edges and without isolated nodes.  Let n, N, and W be the node count, the largest edge weight, and the total weight of G. Let k(x, y) be log x / log (x2/y). We present a new decomposition theorem for maximum weight bipartite matchings and use it to design an $O(sqrt{n}W / k(n, W/N))$-time algorithm for computing a maximum weight matching of G.  This algorithm bridges a long-standing gap between the best known time complexity of computing a maximum weight matching and that of computing a maximum cardinality matching.  Given G and a maximum weight matching of G, we can further compute the weight of a maximum weight matching of G - {u} for all nodes u in O(W) time.},
journal = {SIAM J. Comput.},
month = jan,
pages = {18–26},
numpages = {9},
keywords = {maximum weight matchings, graph algorithms, minimum weight covers, unfolded graphs, all-cavity matchings}
}

@article{10.1137/S0097539799360768,
author = {Flum, J\"{o}rg and Grohe, Martin},
title = {Fixed-Parameter Tractability, Definability, and Model-Checking},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799360768},
doi = {10.1137/S0097539799360768},
abstract = {In this article, we study parameterized complexity theory from the perspective of logic, or more specifically, descriptive complexity theory.  We propose to consider parameterized  model-checking  problems for various fragments of first-order logic as generic parameterized problems and show how this approach can be useful in studying both fixed-parameter tractability and intractability. For example, we establish the equivalence between the model-checking for existential first-order logic, the homomorphism problem for relational structures, and the substructure isomorphism problem. Our main tractability result shows that model-checking for first-order formulas is fixed-parameter tractable when restricted to a class of input structures with an excluded minor. On the intractability side, for every $tge 0$ we prove an equivalence between model-checking for first-order formulas with  t  quantifier alternations and the parameterized halting problem for alternating Turing machines with  t  alternations. We discuss the close connection between this  alternation hierarchy  and Downey and Fellows' W-hierarchy. On a more abstract level, we consider two forms of definability, called  Fagin definability  and  slicewise definability , that are appropriate for describing parameterized problems. We give a characterization of the class FPT of all fixed-parameter tractable problems in terms of slicewise definability in finite variable least fixed-point logic, which is reminiscent of the Immerman--Vardi theorem characterizing the class PTIME in terms of definability in least fixed-point logic.},
journal = {SIAM J. Comput.},
month = jan,
pages = {113–145},
numpages = {33},
keywords = {model-checking, parameterized complexity, descriptive complexity}
}

@article{10.1137/S0097539799360355,
author = {Luby, Michael and Randall, Dana and Sinclair, Alistair},
title = {Markov Chain Algorithms for Planar Lattice Structures},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799360355},
doi = {10.1137/S0097539799360355},
abstract = {Consider the following Markov chain, whose states are all domino tilings of a 2n\texttimes{} 2n chessboard: starting from some arbitrary tiling, pick a 2\texttimes{}2 window uniformly at random.  If the four squares appearing in this window are covered by two parallel dominoes, rotate the dominoes $90^{rm o}$ in place.  Repeat many times. This process is used in practice to generate a random tiling and is a widely used tool in the study of the combinatorics of tilings and the behavior of dimer systems in statistical physics. Analogous Markov chains are used to randomly generate other structures on various two-dimensional lattices.  This paper presents techniques which prove for the first time that, in many interesting cases, a small number of random moves suffice to obtain a uniform distribution.},
journal = {SIAM J. Comput.},
month = jan,
pages = {167–192},
numpages = {26},
keywords = {dimer systems, rapid mixing, Markov chains, domino tilings, Eulerian orientations}
}

@article{10.1137/S0097539799359683,
author = {Bouchitt\'{e}, Vincent and Todinca, Ioan},
title = {Treewidth and Minimum Fill-in: Grouping the Minimal Separators},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799359683},
doi = {10.1137/S0097539799359683},
abstract = {We use the notion of potential maximal clique to characterize the maximal cliques appearing in minimal triangulations of a graph. We show that if these objects can be listed in polynomial time for a class of graphs, the treewidth and the minimum fill-in are polynomially tractable for these graphs. We prove that for all classes of graphs for which polynomial algorithms computing the treewidth and the minimum fill-in exist, we can list their potential maximal cliques in polynomial time. Our approach unifies these algorithms. Finally we show how to compute in polynomial time the potential maximal cliques of weakly triangulated graphs for which the treewidth and the minimum fill-in problems were open.},
journal = {SIAM J. Comput.},
month = jan,
pages = {212–232},
numpages = {21},
keywords = {graph algorithms, treewidth, minimum fill-in, weakly triangulated graphs}
}

@article{10.1137/S0097539799358070,
author = {Liu, Pangfeng and Aiello, William and Bhatt, Sandeep},
title = {Tree Search on an Atomic Model for Message Passing},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799358070},
doi = {10.1137/S0097539799358070},
abstract = {This paper presents a simple atomic model of message-passing multicomputers.  Within one synchronous time step each processor can receive one atomic message, perform local computation, and send one message.  When several messages are destined to the same processor, then one is transmitted and the rest are blocked. Blocked messages cannot be retrieved by their sending processors; each processor must wait for its blocked message to clear before sending more messages into the network.  Depending on the traffic pattern, messages can remain blocked for arbitrarily long periods.The model is conservative when compared with existing message-passing systems.  Nonetheless, we prove linear message throughput when destinations are chosen at random; this rigorously justifies an instance of folklore.  Based on this result we also prove linear speedup for backtrack and branch-and-bound searches using simple randomized algorithms.},
journal = {SIAM J. Comput.},
month = jan,
pages = {67–85},
numpages = {19},
keywords = {parallel communication model, randomized algorithm, parallel tree search}
}

@article{10.1137/S0097539799357441,
author = {Kucera, Anton\'{\i}n and Slaman, T.},
title = {Randomness and Recursive Enumerability},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799357441},
doi = {10.1137/S0097539799357441},
abstract = {One recursively enumerable real $alpha$ dominates another one $beta$ if there are nondecreasing recursive sequences of rational numbers $(a[n]:ninomega)$ approximating $alpha$ and $(b[n]:ninomega)$ approximating $beta$ and a positive constant C such that for all n, $C(alpha-a[n])geq(beta-b[n])$.  See [R. M. Solovay, Draft of a Paper (or Series of Papers) on Chaitin's Work, manuscript, IBM Thomas J. Watson Research Center, Yorktown Heights, NY, 1974, p. 215] and [G. J. Chaitin, IBM J. Res. Develop., 21 (1977), pp. 350--359]. We show that every recursively enumerable random real dominates all other recursively enumerable reals. We conclude that the recursively enumerable random reals are exactly the $Omega$-numbers [G. J. Chaitin, IBM J. Res. Develop., 21 (1977), pp. 350--359]. Second, we show that the sets in a universal Martin-L\"{o}f test for randomness have random measure, and every recursively enumerable random number is the sum of the measures represented in a universal Martin-L\"{o}f test.},
journal = {SIAM J. Comput.},
month = jan,
pages = {199–211},
numpages = {13},
keywords = {Kolmogorov, $Omega$-number, random real, Chaitin}
}

@article{10.1137/S0097539799350840,
author = {Eiter, Thomas and Ibaraki, Toshihide and Makino, Kazuhisa},
title = {Disjunctions of Horn Theories and Their Cores},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799350840},
doi = {10.1137/S0097539799350840},
abstract = {In this paper, we study issues on disjunctions of propositional Horn theories. In particular, we consider the problems of deciding whether a disjunction of Horn theories is Horn, and, if not, computing a Horn core (i.e., a maximal Horn theory included in this disjunction) and the Horn envelope (i.e., the minimum Horn theory including the disjunction), where a Horn core and the Horn envelope are important approximations of the original theory in artificial intelligence. The problems are investigated for two different representations of Horn theories, namely, for Horn conjunctive normal forms (CNFs) and characteristic models. While the problems are shown to be intractable in general, in the case of bounded disjunctions, we present polynomial time algorithms for testing the Horn property in both representations and for computing a Horn core in the CNF representation. Even in the case of bounded disjunction, no polynomial algorithm exists (unless P=NP) for computing a Horn core in the characteristic model representation. Computing the Horn envelope is polynomial in the characteristic model representation, while it is exponential in the CNF representation, even for bounded disjunction.},
journal = {SIAM J. Comput.},
month = jan,
pages = {269–288},
numpages = {20},
keywords = {$!$computational issues in artificial intelligence, Horn theory, logic in computer science}
}

@article{10.1137/S0097539798348110,
author = {Chen, Jianer and Miranda, Antonio},
title = {A Polynomial Time Approximation Scheme for General Multiprocessor Job Scheduling},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798348110},
doi = {10.1137/S0097539798348110},
abstract = {Recently, there have been considerable interests in the multiprocessor job scheduling problem, in which a job can be processed in parallel on one of several alternative subsets of processors.  In this paper, a polynomial time approximation scheme is presented for the problem in which the number of processors in the system is a fixed constant.  This result is the best possible because of the strong NP-hardness of the problem and is a significant improvement over the past results: the best previous result was an approximation algorithm of ratio $7/6 + epsilon$ for 3-processor systems based on Goemans's algorithm for a restricted version of the problem.},
journal = {SIAM J. Comput.},
month = jan,
pages = {1–17},
numpages = {17},
keywords = {multiprocessor processing, polynomial time approximation scheme, approximation algorithm, job scheduling}
}

@article{10.1137/S0097539798346706,
author = {Leonardi, Stefano and Marchetti-Spaccamela, Alberto and Presciutti, Alessio and Ros\'{e}n, Adi},
title = {On-Line Randomized Call Control Revisited},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798346706},
doi = {10.1137/S0097539798346706},
abstract = {We consider the problem of on-line call admission and routing on trees and meshes. Previous work gave randomized on-line algorithms for these problems and proved that they have optimal (up to constant factors)  competitive ratios. However, these algorithms can obtain very low profit with high probability. We investigate the question of devising for these problems on-line competitive algorithms that also guarantee a "good" solution with "good" probability.We give a new family of randomized algorithms with asymptotically optimal competitive ratios and "good" probability to get a profit close to the expectation. We complement these results by providing bounds on the probability of any optimally competitive randomized on-line algorithm for the problems we consider to get a profit close to the expectation. To the best of our knowledge, this is  the first  study of the relationship between the tail distribution and the competitive ratio of randomized on-line benefit algorithms.},
journal = {SIAM J. Comput.},
month = jan,
pages = {86–112},
numpages = {27},
keywords = {on-line algorithms, competitive analysis, randomized algorithms, call admission control}
}

@article{10.1137/S0097539798342903,
author = {Chen, Jing-Chao},
title = {Proportion Extend Sort},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798342903},
doi = {10.1137/S0097539798342903},
abstract = {PROPORTION EXTEND SORT is a new sorting algorithm, the basic principle of which is similar to PROPORTION SPLIT SORT. This algorithm sorts a sequence by constructing three subproblems, using a QuickSort-like pivot technique and solving recursively each subproblem. The original problem and three subproblems all are of such a structure: a sorted subsequence followed by an unsorted subsequence. The size of the original problem always equals the size of the third subproblem, but in general, the sorted subsequence of the third subproblem is p+1 times as much as the sorted subsequence of the original, where p is a fixed positive constant. The worst case number of comparisons required by this algorithm is less than 1/log (1+1/(2p2+2p-1))nlog n for $p geq 1$. Empirical results show that the average number of comparisons is close to n log n-O(n) for some p. From our experiments for sorting integers, when p = 16, this algorithm is yet faster, on average, than PROPORTION SPLIT SORT which is faster than CLEVER QUICKSORT.},
journal = {SIAM J. Comput.},
month = jan,
pages = {323–330},
numpages = {8},
keywords = {algorithm, partition, sort, insertion sort, quick sort}
}

@article{10.1137/S0097539797327180,
author = {Chekuri, C. and Motwani, R. and Natarajan, B. and Stein, C.},
title = {Approximation Techniques for Average Completion Time Scheduling},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797327180},
doi = {10.1137/S0097539797327180},
abstract = {We consider the problem of nonpreemptive scheduling to minimize average (weighted) completion time, allowing for release dates, parallel machines, and precedence constraints. Recent work has led to constant-factor approximations for this problem based on solving a preemptive or linear programming relaxation and then using the solution to get an ordering on the jobs. We introduce several new techniques which generalize this basic paradigm. We use these ideas to obtain improved approximation algorithms for one-machine scheduling to minimize average completion time with release dates. In the process, we obtain an optimal randomized on-line algorithm for the same problem that beats a lower bound for deterministic on-line algorithms.  We consider extensions to the case of parallel machine scheduling, and for this we introduce two new ideas: first, we show that a preemptive one-machine relaxation is a powerful tool for designing parallel machine scheduling algorithms that simultaneously produce good approximations and have small running times; second, we show that a nongreedy "rounding" of the relaxation yields better approximations than a greedy one. We also prove a general theorem relating the value of one-machine relaxations to that of the schedules obtained for the original m-machine problems. This theorem applies even when there are precedence constraints on the jobs. We apply this result to obtain improved approximation ratios for precedence graphs such as in-trees, out-trees, and series-parallel graphs.},
journal = {SIAM J. Comput.},
month = jan,
pages = {146–166},
numpages = {21},
keywords = {scheduling, release dates, precedence constraints, parallel machine scheduling, approximation algorithms}
}

@article{10.1137/S0097539700379346,
author = {Cucker, Felipe and Grigoriev, Dima},
title = {There Are No Sparse  NP<sub><i>w</i></sub>-Hard Sets},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700379346},
doi = {10.1137/S0097539700379346},
abstract = {In this paper we prove that, in the context of weak machines over $Bbb R$, there are no sparse $NP$-hard sets.},
journal = {SIAM J. Comput.},
month = jan,
pages = {193–198},
numpages = {6},
keywords = {structural complexity, real number computations}
}

@article{10.1137/S009753970037905X,
author = {Csur\"{o}s, Mikl\'{o}s and Kao, Ming-Yang},
title = {Provably Fast and Accurate Recovery  of Evolutionary Trees through Harmonic Greedy Triplets},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753970037905X},
doi = {10.1137/S009753970037905X},
abstract = {We give a greedy learning algorithm for reconstructing an evolutionary tree based on a certain harmonic average on triplets of terminal taxa. After the pairwise distances between terminal taxa are estimated from sequence data, the algorithm runs in $smallbigO{numtaxa^2}$ time using $smallbigO{numtaxa}$ work space, where $numtaxa$ is the number of terminal taxa.  These time and space complexities are optimal in the sense that the size of an input distance matrix is $numtaxa^2$ and the size of an output tree is $numtaxa$.  Moreover, in the Jukes--Cantor model of evolution, the algorithm recovers the correct tree topology with high probability using sample sequences of length polynomial in (1) $numtaxa$, (2) the logarithm of the error probability, and (3) the inverses of two  small parameters.},
journal = {SIAM J. Comput.},
month = jan,
pages = {306–322},
numpages = {17},
keywords = {harmonic greedy triplets, evolutionary trees, computational learning, the Jukes--Cantor model of evolution}
}

@article{10.1137/S0097539700377037,
author = {Sawada, Joe},
title = {Generating Bracelets in Constant Amortized Time},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700377037},
doi = {10.1137/S0097539700377037},
abstract = {A bracelet is the lexicographically smallest element in an equivalence class of strings under string rotation and reversal. We  present a fast, simple, recursive algorithm for generating (i.e., listing) k-ary bracelets. Using simple bounding techniques, we prove that the algorithm is optimal in the sense that the running time is proportional to the number of bracelets produced. This is an improvement by a factor of n (where n is the length of the bracelets being generated) over the fastest, previously known algorithm to generate bracelets.},
journal = {SIAM J. Comput.},
month = jan,
pages = {259–268},
numpages = {10},
keywords = {bracelet, forbidden substring, generate, necklace, CAT algorithm}
}

@article{10.1137/S0097539700372216,
author = {Hell, Pavol and Shamir, Ron and Sharan, Roded},
title = {A Fully Dynamic Algorithm for Recognizing and Representing Proper Interval Graphs},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700372216},
doi = {10.1137/S0097539700372216},
abstract = {In this paper we study the problem of recognizing and representing dynamically changing proper interval graphs. The input to the problem consists of a series of modifications to be performed on a graph, where a modification can be a deletion or an addition of a vertex or an edge. The objective is to maintain a representation of the graph as long as it remains a proper interval graph, and to detect when it ceases to be so. The representation should enable one to efficiently construct a realization of the graph by an inclusion-free family of intervals. This problem has important applications in physical mapping of DNA.We give a near-optimal fully dynamic algorithm for this problem. It operates in O(log n) worst-case time per edge insertion or deletion. We prove a close lower bound of $Omega(log n/(loglog n+log b))$ amortized time per operation in the cell probe model with word-size b. We also construct optimal incremental and decremental algorithms for the problem, which handle each edge operation in O(1) time. As a byproduct of our algorithm, we solve in O(log n) worst-case time the problem of maintaining connectivity in a dynamically changing proper interval graph.},
journal = {SIAM J. Comput.},
month = jan,
pages = {289–305},
numpages = {17},
keywords = {lower bounds, fully dynamic algorithms, proper interval graphs, graph algorithms}
}

@article{10.1137/S0097539700366115,
author = {Althaus, Ernst and Mehlhorn, Kurt},
title = {Traveling Salesman-Based Curve Reconstruction in Polynomial Time},
year = {2002},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {31},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700366115},
doi = {10.1137/S0097539700366115},
abstract = {An instance of the curve reconstruction problem is a finite sample set V of an unknown collection of curves $gamma$. The task is to connect the points in V in the order in which they lie on $gamma$. Giesen [ Proceedings of the 15 th Annual ACM Symposium on Computational Geometry ( SCG '99), 1999, pp. 207--216] showed recently that the traveling salesman tour of V solves the reconstruction problem for single closed curves under otherwise weak assumptions on $gamma$ and V; $gamma$ must be a single closed curve. We extend his result along several directions: we weaken the assumptions on the sample; we show that traveling salesman-based reconstruction also works for single open curves (with and without specified endpoints) and for collections of closed curves; we give alternative proofs; and we show that in the context of curve reconstruction, the traveling salesman tour can be constructed in polynomial time.},
journal = {SIAM J. Comput.},
month = jan,
pages = {27–66},
numpages = {40},
keywords = {traveling salesman, curve reconstruction, polynomial time}
}

@article{10.5555/586841.586892,
author = {Agarwal, Pankaj K. and Wang, Hongyan},
title = {Approximation Algorithms for Curvature-Constrained Shortest Paths},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
abstract = {Let $B$ be a point robot in the plane, whose path is constrained to have curvature of at most 1, and let $Omega$ be a set of polygonal obstacles with n vertices. We study the collision-free, optimal path-planning problem for B. Given a parameter $varepsilon$, we present an $O( (n^2/ eps^4) log n)$-time algorithm for computing a collision-free, curvature-constrained path between two given positions, whose length is at most $(1+varepsilon)$ times the length of an optimal path, provided it is robust. (Roughly speaking, a path is robust if it remains collision-free even if certain positions on the path are perturbed). Our algorithm thus runs significantly faster than the previously best known algorithm by Jacobs and Canny whose running time is $O( (frac{n+L}{eps^2})^2 + n^2 (frac{n+L}{eps^2}) log n)$, where L is the total edge length of the obstacles. More importantly, the running time of our algorithm does not depend on the size of obstacles. The path returned by this algorithm is not necessarily robust. We present an $O((n^{2.5}/ eps^4) log n)$-time algorithm that returns a robust path whose length is at most $(1+varepsilon)$ times the length of an optimal path, provided it is robust. We also give a stronger characterization of curvature-constrained shortest paths, which, apart from being crucial for our algorithm, is interesting in its own right. Roughly speaking, we prove that,  except in some special cases, a shortest path touches obstacles at points that have a visible vertex nearby.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1739–1772},
numpages = {34},
keywords = {motion planning, robotics, approximation algorithms, configuration space}
}

@article{10.1137/S0097539799361683,
author = {Jiang, Tao and Kearney, Paul and Li, Ming},
title = {A Polynomial Time Approximation Scheme  for Inferring Evolutionary Trees from Quartet Topologies and Its Application},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799361683},
doi = {10.1137/S0097539799361683},
abstract = {Inferring evolutionary trees has long been a challenging problem for both biologists and computer scientists. In recent years research has concentrated on the  quartet method paradigm for inferring evolutionary trees.  Quartet methods proceed by first inferring the evolutionary history for every set of four species (resulting in a set Q of inferred quartet topologies) and then recombining these inferred quartet topologies to form an evolutionary tree. This paper presents two results on the quartet method paradigm. The first is a polynomial time approximation scheme (PTAS) for recombining the inferred quartet topologies optimally. This is an important result since, to date, there have been no polynomial time algorithms with performance guarantees for quartet methods. To achieve this result the natural denseness of the set Q is exploited. The second result is a new technique, called quartet cleaning, that detects and corrects errors in the set Q with performance guarantees. This result has particular significance since quartet methods are usually very sensitive to errors in the data.  It is shown how quartet cleaning can dramatically increase the accuracy of quartet methods.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1942–1961},
numpages = {20},
keywords = {quartet method, smooth polynomial, dense instance, approximation algorithm, evolutionary tree}
}

@article{10.1137/S009753979935431X,
author = {Mereghetti, Carlo and Pighizzini, Giovanni},
title = {Optimal Simulations between Unary Automata},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979935431X},
doi = {10.1137/S009753979935431X},
abstract = {We consider the problem of computing the costs--- in terms of states---of optimal simulations between different kinds of finite automata recognizing  unary languages. Our main result is a tight simulation of unary n-state two-way nondeterministic automata by $O({{rm e}^{sqrt{{n}ln{n}}}})$-state one-way deterministic automata. In addition, we show that, given a unary n-state two-way nondeterministic automaton, one can construct an equivalent O(n2)-state two-way nondeterministic automaton performing  both input head reversals and nondeterministic choices only at the ends of the input tape. Further results on simulating unary one-way alternating finite automata are also discussed.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1976–1992},
numpages = {17},
keywords = {formal languages; deterministic, and alternating finite state automata; unary languages, nondeterministic}
}

@article{10.1137/S0097539799349948,
author = {Khanna, Sanjeev and Sudan, Madhu and Trevisan, Luca and Williamson, David P.},
title = {The Approximability of Constraint Satisfaction Problems},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799349948},
doi = {10.1137/S0097539799349948},
abstract = {We study optimization problems that may be expressed as "Boolean constraint satisfaction problems." An instance of a Boolean constraint satisfaction problem is given by m constraints applied to n Boolean variables. Different computational problems arise from constraint satisfaction problems depending on the nature of the "underlying" constraints as well as on the goal of the optimization task. Here we consider four possible goals: Max CSP (Min CSP) is the class of problems where the goal is to find an assignment maximizing the number of satisfied constraints (minimizing the number of unsatisfied constraints).  Max Ones (Min Ones) is the class of optimization problems where the goal is to find an assignment satisfying all constraints with maximum (minimum) number of variables set to 1. Each class consists of infinitely many problems and a problem within a class is specified by a finite collection of finite Boolean functions that describe the possible constraints that may be used.Tight bounds on the approximability of every problem in  Max CSP were obtained by Creignou [ J. Comput. System Sci., 51 (1995), pp. 511--522]. In this work we determine tight bounds on the "approximability" (i.e., the ratio to within which each problem may be approximated in polynomial time) of every problem in Max Ones, Min CSP, and Min Ones. Combined with the result of Creignou, this completely classifies all optimization problems derived from Boolean constraint satisfaction. Our results capture a diverse collection of optimization problems such as MAX 3-SAT,  Max Cut, Max Clique, Min Cut, Nearest Codeword, etc.  Our results unify recent results on the (in-)approximability of these optimization problems and yield a compact presentation of most known results. Moreover, these results provide a formal basis to many statements on the behavior of natural optimization problems that have so far been observed only empirically.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1863–1920},
numpages = {58},
keywords = {complete problems, approximation classes, hardness of approximation, approximation-preserving reductions, Boolean constraint satisfaction problems, approximation algorithms}
}

@article{10.1137/S009753979834669X,
author = {Chu, Chengbin and La, R\'{e}my},
title = {Variable-Sized Bin Packing: Tight Absolute Worst-Case Performance Ratios for Four Approximation Algorithms},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979834669X},
doi = {10.1137/S009753979834669X},
abstract = {In this paper we consider a one-dimensional bin packing problem where the bins do not have identical sizes, or a variable-sized bin packing problem, to minimize the bin consumption, i.e., the total size of the opened bins. The identical size problem has been extensively studied in the literature both for static and dynamic settings. The worst-case or average-case performance has been analyzed. Our problem setting particularly arises in metal cutting industries. Therefore, it presents a great practical relevance. Four greedy approximation algorithms based on a construction approach called largest object first with least absolute waste (LFLAW), largest object first with least relative waste (LFLRW), least absolute waste (LAW), and least relative waste (LRW) are examined. Their absolute worst-case performances are analyzed. The worst case bounds are 2 for LFLAW and LFLRW, 3 for LAW, and 2+ln 2 for LRW. We also show that these worst-case bounds are tight.},
journal = {SIAM J. Comput.},
month = dec,
pages = {2069–2083},
numpages = {15},
keywords = {variable-sized bin packing, absolute worst-case performance ratios, approximation algorithms}
}

@article{10.1137/S009753979834610X,
author = {Meleis, Waleed M.},
title = {Dual-Issue Scheduling for Binary Trees with Spills and Pipelined Loads},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979834610X},
doi = {10.1137/S009753979834610X},
abstract = {We describe an algorithm that finds a minimum cost schedule, including spill code, for a register-constrained machine that can issue up to one arithmetic operation and one memory access operation at a time, under the restrictions that the dependence graph is a full binary tree, all arithmetic and store operations have unit latency, and all load operations have a latency of 1 or all load operations have a latency of 2.  This problem is a generalization of two problems whose efficient solutions are well understood: optimal dual-issue scheduling without spills for binary expression trees, solved by Bernstein, Jaffe, and Rodeh [SIAM J. Comput., 18 (1989), pp. 1098--1127], and optimal single-issue scheduling with spill code and delayed loads, solved by Kurlander, Proebsting, and Fischer [ ACM Transactions on Programming Languages and Systems, 17 (1995), pp. 740--776], both assuming a fixed number of registers.  We show that the algorithm's complexity is O(nk) where n is the number of operations to be scheduled and k is the number of spills in the schedule.  The cost of a "contiguous" schedule (i.e., its length) is shown to be $rho + 2k + g + |A|$, where $rho$ is the number of registers used, |A| is the number of arithmetic operations, k is the number of spills, and g is the number of empty slots in the associated single processor schedule.  Therefore all contiguous schedules formed from optimal single processor schedules have minimum cost.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1921–1941},
numpages = {21},
keywords = {code generations, parallel functional units, registers, scheduling algorithms}
}

@article{10.1137/S0097539798338163,
author = {Cai, Mao-cheng and Deng, Xiaotie and Zang, Wenan},
title = {An Approximation Algorithm for Feedback Vertex Sets in Tournaments},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798338163},
doi = {10.1137/S0097539798338163},
abstract = {We obtain a necessary and sufficient condition in terms of forbidden structures for tournaments to possess the min-max relation on packing and covering directed cycles, together with strongly polynomial time algorithms for the feedback vertex set problem and the cycle packing problem in this class of tournaments. Applying the local ratio technique of Bar-Yehuda and Even to the forbidden structures, we find a 2.5-approximation polynomial time algorithm for the feedback vertex set problem in any tournament.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1993–2007},
numpages = {15},
keywords = {tournament, feedback vertex set, approximation algorithm, min-max relation}
}

@article{10.1137/S0097539798335596,
author = {Srinivasan, Aravind and Teo, Chung-Piaw},
title = {A Constant-Factor Approximation Algorithm for Packet Routing and Balancing Local vs. Global Criteria},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798335596},
doi = {10.1137/S0097539798335596},
abstract = {We present the first constant-factor approximation algorithm for a fundamental problem: the  store-and-forward packet routing problem on arbitrary networks. Furthermore, the queue sizes required at the edges are bounded by an absolute constant. Thus, this algorithm balances a  global criterion (routing time) with a  local criterion (maximum queue size) and shows how to get simultaneous good bounds for both. For this particular problem, approximating the routing time well, even without considering the queue sizes, was open. We then consider a class of such local vs. global problems in the context of covering integer programs and show how to improve the local criterion by a logarithmic factor by losing a constant factor in the global criterion.},
journal = {SIAM J. Comput.},
month = dec,
pages = {2051–2068},
numpages = {18},
keywords = {randomized algorithms, covering integer programs, packet routing, multicommodity flow, rounding theorems, linear programming, randomized rounding, approximation algorithms, discrete ham-sandwich theorems}
}

@article{10.1137/S0097539797331671,
author = {Shahrokhi, Farhad and S\'{y}kora, Ondrej and Sz\'{e}kely, L\'{a}szl\'{o} A. and Vrto, Imrich},
title = {On Bipartite Drawings and the Linear Arrangement Problem},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797331671},
doi = {10.1137/S0097539797331671},
abstract = {The bipartite crossing number problem is studied and a connection between this problem and the linear arrangement problem is established.  A lower bound and an upper bound for the optimal number of crossings are derived, where the main terms are the optimal arrangement values. Two polynomial time approximation algorithms for the bipartite crossing number are obtained. The performance guarantees are O(log n) and O(log2 n) times the optimal, respectively, for a large class of bipartite graphs on n vertices. No polynomial time approximation algorithm which could generate a provably good solution had been known. For a tree, a formula is derived that expresses the optimal number of crossings in terms of the optimal value of the linear arrangement and the degrees, resulting in an O(n1.6) time algorithm for computing the bipartite crossing number.The problem of computing a maximum weight biplanar subgraph of an acyclic graph is also studied and a linear time algorithm for solving it is derived. No polynomial time algorithm for this problem was known, and the unweighted version of the problem had been known to be NP-hard, even for planar bipartite graphs of degree at most 3.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1773–1789},
numpages = {17},
keywords = {approximation algorithms, bipartite crossing number, linear arrangement, biplanar graph, bipartite drawing}
}

@article{10.1137/S0097539797324886,
author = {Buhrman, Harry and Cleve, Richard and van Dam, Wim},
title = {Quantum Entanglement and Communication Complexity},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797324886},
doi = {10.1137/S0097539797324886},
abstract = {We consider a variation of the communication complexity scenario, where the parties are supplied with an extra resource: particles in an entangled quantum state. We note that "quantum nonlocality" can be naturally expressed in the language of communication complexity. These are communication complexity problems where the "output" is embodied in the correlations between the outputs of the individual parties. Without entanglement, the parties must communicate to produce the required correlations; whereas, with entanglement,  no communication is necessary to produce the correlations. In this sense, nonlocality proofs can also be viewed as communication complexity problems where the presence of quantum entanglement reduces the amount of necessary communication. We show how to transform examples of nonlocality into more traditional communication complexity problems, where the output is explicitly determined by each individual party. The resulting problems require communication with or without entanglement, but the required communication is less when entanglement is available. All these results are a noteworthy contrast to the well-known fact that entanglement cannot be used to actually simulate or compress classical communication between remote parties.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1829–1841},
numpages = {13},
keywords = {communication complexity, quantum computing, complexity theory}
}

@article{10.1137/S0097539797322528,
author = {Mirkowska, Grazyna and Salwicki, Andrzej and Srebrny, Marian and Tarlecki, Andrzej},
title = {First-Order Specifications  of Programmable Data Types},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797322528},
doi = {10.1137/S0097539797322528},
abstract = {We consider first-order specifications together with the restriction to accept only programmable algebras as models. We provide a criterion which links this approach with the "generation principle": all programmable models of any specification SP that meets this criterion are reachable. We also show an example of a specification which does not satisfy the criterion and admits a programmable yet nonreachable model. Moreover, a general method of showing the existence of programmable but nonreachable models for a class of first-order specifications is given.},
journal = {SIAM J. Comput.},
month = dec,
pages = {2084–2096},
numpages = {13},
keywords = {algebraic specification, data types, reachable algebra}
}

@article{10.1137/S0097539700373039,
author = {Micciancio, Daniele},
title = {The Shortest Vector in a Lattice is Hard to Approximate to within Some Constant},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700373039},
doi = {10.1137/S0097539700373039},
abstract = {We show that approximating the  shortest vector problem (in any $ell_p$ norm) to within any constant factor less than $sqrt[p]2$ is hard for NP under  reverse unfaithful random reductions with inverse polynomial error probability. In particular, approximating the  shortest vector problem is not in RP (random polynomial time), unless NP equals RP. We also prove a proper NP-hardness result (i.e., hardness under deterministic many-one reductions) under a reasonable number theoretic conjecture on the distribution of square-free smooth numbers. As part of our proof, we give an alternative construction of Ajtai's constructive variant of Sauer's lemma that greatly simplifies Ajtai's original proof.},
journal = {SIAM J. Comput.},
month = dec,
pages = {2008–2035},
numpages = {28},
keywords = {shortest vector problem, point lattices, NP-hardness, sphere packing, geometry of numbers}
}

@article{10.1137/S0097539700372708,
author = {Dyer, Martin and Goldberg, Leslie Ann and Greenhill, Catherine and Jerrum, Mark and Mitzenmacher, Michael},
title = {An Extension of Path Coupling and Its Application to the Glauber Dynamics for Graph Colorings},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700372708},
doi = {10.1137/S0097539700372708},
abstract = {A new method for analyzing the mixing time of Markov chains is described.  This method is an extension of path coupling and involves analyzing the coupling over multiple steps.  The expected behavior of the coupling at a certain stopping time is used to bound the expected behavior of the coupling after a fixed number of steps.  The new method is applied to analyze the mixing time of the Glauber dynamics for graph colorings.   We show that the Glauber dynamics has O(n log(n)) mixing time for triangle-free $Delta$-regular graphs if k colors are used, where $kgeq (2-eta)Delta$, for some small positive constant $eta$.    This is the first proof of an optimal upper bound for the mixing  time of the Glauber dynamics for some values of k in the range $kleq 2Delta$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1962–1975},
numpages = {14},
keywords = {Markov chains, graph coloring, coupling, stopping times, Glauber dynamics}
}

@article{10.1137/S0097539700370072,
author = {Boros, Endre and Gurvich, Vladimir and Khachiyan, Leonid},
title = {Dual-Bounded Generating Problems: Partial and Multiple Transversals of a Hypergraph},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700370072},
doi = {10.1137/S0097539700370072},
abstract = {We consider two  generalizations of the notion of transversal to a finite hypergraph, the so-called  multiple and partial transversals. Multiple transversals naturally arise in 0-1 programming, while partial transversals are related to data mining and  machine learning. We show that for an arbitrary hypergraph the families of multiple and  partial transversals are both dual-bounded in the sense that the size of the corresponding dual hypergraph is bounded by a polynomial in the cardinality and the length of description of the input hypergraph. Our bounds are based on new inequalities of extremal set theory and threshold Boolean logic, which may be of independent interest. We also show that the problems of generating all multiple and all partial transversals for a given hypergraph are polynomial-time reducible to the generation of all ordinary transversals for another hypergraph, i.e., to the well-known dualization problem for hypergraphs.  As a corollary, we obtain incremental quasi-polynomial-time algorithms for both of the above problems, as well as for the generation of all the minimal binary solutions for an arbitrary monotone system of linear inequalities.},
journal = {SIAM J. Comput.},
month = dec,
pages = {2036–2050},
numpages = {15},
keywords = {hypergraph, data mining, minimal infrequent set, maximal frequent set, independent set, dualization, incremental polynomial time, threshold function, transversal, monotone Boolean function}
}

@article{10.1137/S0097539700367984,
author = {Berkman, Omer and Parnas, Michal and Sgall, Jir\'{\i}},
title = {Efficient Dynamic Traitor Tracing},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700367984},
doi = {10.1137/S0097539700367984},
abstract = {The notion of traitor tracing was introduced by Chor, Fiat, and Naor [  Tracing Traitors , Lecture Notes in Comput. Sci. 839, 1994, pp. 257--270] in order to combat piracy scenarios. Recently, Fiat and Tassa [  Tracing Traitors , Lecture Notes in Comput. Sci. 1666, 1999, pp. 354--371] proposed a dynamic traitor tracing scenario, in which the algorithm adapts dynamically according to the responses of the pirate. Let  n  be the number of users and  p  the number of traitors. Our main result is an algorithm which locates  p  traitors, even if  p  is unknown, using a watermarking alphabet of size  p +1 and an optimal number of $Theta(p^2 + plog n)$ rounds. This improves the exponential number of rounds achieved by Fiat and Tassa in this case. We also present two algorithms that use a larger alphabet: for an alphabet of size  p +  c +1, $cgeq1$, an algorithm that uses  O (  p 2/  c +  p  log  n ) rounds; for an alphabet of size  pc +1, an algorithm that uses  O (  p  log  c   n ) rounds.Our final result is a lower bound of $Omega(p^2/c+plog_{c+1}n)$ rounds for any algorithm that uses an alphabet of size  p +  c , assuming that  p  is not known in advance.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1802–1828},
numpages = {27},
keywords = {cryptography, analysis of algorithms, asymptotic complexity, traitor tracing}
}

@article{10.1137/S0097539700366528,
author = {Alon, Noga and Krivelevich, Michael and Newman, Ilan and Szegedy, Mario},
title = {Regular Languages Are Testable with a Constant Number of Queries},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700366528},
doi = {10.1137/S0097539700366528},
abstract = {We continue the study of combinatorial property testing, initiated by Goldreich, Goldwasser, and Ron in [J. ACM, 45 (1998), pp. 653--750]. The subject of this paper is testing regular languages. Our main result is as follows. For a regular language $Lin {0,1}^*$ and an integer n there exists a randomized algorithm which always accepts a word w of length n if $win L$ and rejects it with high probability if $w$ has to be modified in at least $epsilon n$ positions to create a word in L. The algorithm queries $tilde{O}(1/epsilon)$ bits of w. This query complexity is shown to be optimal up to  a factor polylogarithmic in $1/epsilon$. We also discuss the testability of more complex languages and show, in particular, that the query complexity required for testing context-free languages cannot be bounded by any function of $epsilon$. The problem of testing regular languages can be viewed as a part of a very general approach, seeking to probe testability of properties defined by logical means.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1842–1862},
numpages = {21},
keywords = {regular languages, context-free languages, property testing}
}

@article{10.1137/S0097539700366103,
author = {Frieze, Alan M.},
title = {Edge-Disjoint Paths in Expander Graphs},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700366103},
doi = {10.1137/S0097539700366103},
abstract = {Given a graph G=(V,E)and a set of $kappa$ pairs of vertices in V, we are interested in finding, for each pair (ai, bi), a path connecting ai to bi such that the set of $kappa$ paths so found is edge-disjoint.  For arbitrary graphs the problem is ${cal NP}$-complete, although it is in ${cal P}$ if $kappa$ is fixed. We present a polynomial time randomized algorithm for finding edge-disjoint paths in an r-regular expander graph G. We show that if G has sufficiently strong  expansion properties and r is sufficiently large, then  all sets of $kappa=Omega(n/log n)$ pairs of vertices can be joined. This is within a constant factor of best possible.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1790–1801},
numpages = {12},
keywords = {randomized algorithms, edge-disjoint paths, expander graphs}
}

@article{10.1137/S0097539799362627,
author = {Har-Peled, Sariel},
title = {Taking a Walk in a Planar Arrangement},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799362627},
doi = {10.1137/S0097539799362627},
abstract = {We present a randomized algorithm for computing portions of an arrangement of n arcs in the plane, each pair of which intersect in at most t points.  We use this algorithm to perform online walks inside such an arrangement (i.e., compute all the faces that a curve, given in an online manner, crosses) and to compute a level in an arrangement, both in an output-sensitive manner.  The expected running time of the algorithm is $O(lambda_{t+2}(m+n)log n)$, where m is the number of intersections between the walk and the given arcs.  No similarly efficient algorithm is known for the general case of arcs. For the case of lines and for certain restricted cases involving line segments, our algorithm improves the best known algorithm of [M. H. Overmars and J. van Leeuwen,  J. Comput. System Sci., 23 (1981), pp. 166--204] by almost a logarithmic factor.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1341–1367},
numpages = {27},
keywords = {planar arrangements, computational geometry, single face, levels}
}

@article{10.1137/S0097539799359361,
author = {Han, Xiaoxu and Oliveira, Suely and Stewart, David},
title = {Finding Sets Covering a Point with Application to Mesh-Free Galerkin Methods},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799359361},
doi = {10.1137/S0097539799359361},
abstract = {For a collection of sets in Rd we consider the task of finding all sets in the collection that cover or contain a given point. The algorithms introduced in this paper are based on quadtrees and their generalizations to Rd. The advantages of our new splitting algorithm to find the covering sets of a point over the basic algorithm are detailed by means of hit rates and the expected depth traversed in the quadtree search, numerically and theoretically. This solves a difficult problem faced by mesh-free discretizations of partial differential equations.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1368–1383},
numpages = {16},
keywords = {quadtree and octree search methods, computational geometry}
}

@article{10.1137/S0097539799358227,
author = {Arvind, V. and Beigel, R. and Lozano, A.},
title = {The Complexity of Modular Graph Automorphism},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799358227},
doi = {10.1137/S0097539799358227},
abstract = {Motivated by the question of the relative complexities of the graph isomorphism and the graph automorphism problems, we define and study the modular graph automorphism problems. These are the decision problems modk-GA which consist, for each k &gt; 1, of deciding whether the number of automorphisms of a graph is divisible by k. The modk-GA problems all turn out to be intermediate in difficulty between graph automorphism and graph isomorphism.We define an appropriate search problem corresponding to modk-GA and design an algorithm that polynomial-time reduces the modk-GA search problem to the decision problem.  Combining this algorithm with an IP protocol, we obtain a randomized polynomial-time checker for mod$_{k}$-GA $forall k&gt;1$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1299–1320},
numpages = {22},
keywords = {graph isomorphism, IP protocols, search problems, graph automorphism, decision problems, program checking}
}

@article{10.1137/S0097539799353431,
author = {Scheideler, Christian and V\"{o}cking, Berthold},
title = {From Static to Dynamic Routing: Efficient Transformations of Store-and-Forward Protocols},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799353431},
doi = {10.1137/S0097539799353431},
abstract = {We investigate how static store-and-forward routing algorithms can be transformed into efficient dynamic algorithms, that is, how algorithms that have been designed for the case that all packets are injected at the same time can be adapted to more realistic scenarios in which packets are continuously injected into the network. Besides describing specific transformations for well-known static routing algorithms, we present a black box transformation scheme applicable to every static, oblivious routing algorithm. We analyze the performance of our protocols under a stochastic and an adversarial model of packet injections. One result of our specific transformations is the first dynamic routing algorithm for leveled networks that is stable for arbitrary admissible injection rates and that works with packet buffers of size depending solely on the injection rate and the node degree, but not on the size of the network. Furthermore, we prove strong delay bounds for the packets. Our results imply, for example, that a throughput of 99% can be achieved on an  n -input butterfly network with buffers of constant size while each packet is delivered in time  O (log  n ), with high probability.Our black box transformation ensures that if the static algorithm is pure (i.e., no extra packets apart from the original packets are routed), its dynamic variant is stable up to a maximum possible injection rate. Furthermore, in the stochastic model, the routing time of a packet depends on local parameters such as the length of its routing path, rather than on the maximum possible path length, even if the static algorithm chosen for the transformation does not provide this locality feature and is not pure. In the adversarial model, the delay bound of the packets is closely related to the time bound given for the static algorithm.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1126–1155},
numpages = {30},
keywords = {packet scheduling, store-and-forward routing, communication networks}
}

@article{10.1137/S0097539799352759,
author = {Varadarajan, Kasturi R. and Agarwal, Pankaj K.},
title = {Approximating Shortest Paths on a Nonconvex Polyhedron},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799352759},
doi = {10.1137/S0097539799352759},
abstract = {We present an approximation algorithm that, given the boundary P of a simple, nonconvex polyhedron in ${mathbb R}^3$ and two points s and t on P, constructs a path on P between s and t whose length is at most ${7(1+{varepsilon})} dP(s,t), where dP(s,t) is the length of the shortest path between s and t on P, and ${varepsilon} &gt; 0$ is an arbitrarily small positive constant. The algorithm runs in O(n5/3 log5/3 n) time, where n is the number of vertices in P. We also present a slightly faster algorithm that runs in O(n8/5 log8/5 n) time and returns a path whose length is at most ${15(1+{varepsilon})} d_{P}(s,t)$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1321–1340},
numpages = {20},
keywords = {approximation algorithms, computational geometry, Euclidean shortest paths}
}

@article{10.1137/S0097539799351729,
author = {Czygrinow, Andrzej and R\"{o}dl, Vojtech},
title = {An Algorithmic Regularity Lemma for Hypergraphs},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799351729},
doi = {10.1137/S0097539799351729},
abstract = {In this paper, we will consider the problem of designing an efficient algorithm that finds an $epsilon$-regular partition of an l-uniform hypergraph.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1041–1066},
numpages = {26},
keywords = {regularity lemma, hypergraphs, algorithms}
}

@article{10.1137/S0097539798343908,
author = {Bassino, Fr\'{e}d\'{e}rique and B\'{e}al, Marie-Pierre and Perrin, Dominique},
title = {A Finite State Version of the Kraft--McMillan Theorem},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798343908},
doi = {10.1137/S0097539798343908},
abstract = {The main result is a finite-state version of the Kraft--McMillan theorem characterizing the generating sequence of a k-ary regular tree. The proof uses a new construction called the multiset construction, which is a version with multiplicities of the well-known subset construction of automata theory.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1211–1230},
numpages = {20},
keywords = {nonnegative matrices, generating series, regular trees}
}

@article{10.1137/S0097539798340047,
author = {Even, Guy},
title = {An 8-Approximation Algorithm for the Subset Feedback Vertex Set Problem},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798340047},
doi = {10.1137/S0097539798340047},
abstract = {We present an 8-approximation algorithm for the problem of finding a minimum weight  subset feedback vertex set (or  subset-fvs, in short).  The input in this problem consists of an undirected graph G=(V,E) with vertex weights c(v) and a subset of vertices S called  special vertices. A cycle is called  interesting if it contains at least one special vertex. A subset of vertices is called a  subset-fvs with respect to S if it intersects every interesting cycle. The goal is to find a minimum weight  subset-fvs. The best previous algorithm for the general case provided only a logarithmic approximation factor. The minimum weight subset-fvs problem generalizes two NP-complete problems: the minimum weight feedback vertex set problem in undirected graphs and the minimum weight multiway vertex cut problem. The main tool that we use in our algorithm and its analysis is a new version of multicommodity flow, which we call  relaxed multicommodity flow. Relaxed multicommodity flow is a hybrid of multicommodity flow and multiterminal flow.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1231–1252},
numpages = {22},
keywords = {approximation algorithms, combinatorial optimization, multicut, feedback vertex set, mul-ticommodity flow}
}

@article{10.1137/S0097539798336073,
author = {Natanzon, Assaf and Shamir, Ron and Sharan, Roded},
title = {A Polynomial Approximation Algorithm for the Minimum Fill-In Problem},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798336073},
doi = {10.1137/S0097539798336073},
abstract = {In the  minimum fill-in problem, one wishes to find a set of edges of smallest size, whose addition to a given graph will make it chordal. The problem has important applications in numerical algebra and has been studied intensively since the 1970s. We give the first polynomial approximation algorithm for the problem. Our algorithm constructs a triangulation whose size is at most eight times the optimum size squared. The algorithm builds on the recent parameterized algorithm of Kaplan, Shamir, and Tarjan for the same problem.For bounded degree graphs we give a polynomial approximation algorithm with a polylogarithmic approximation ratio. We also improve the parameterized algorithm.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1067–1079},
numpages = {13},
keywords = {chordal completion, parameterized algorithms, chordal graphs, chain graphs, minimum fill-in, chain completion, approximation algorithms, graph algorithms}
}

@article{10.1137/S0097539797349959,
author = {Pan, Victor Y.},
title = {Parallel Complexity of Computations with   General and Toeplitz-Like Matrices   Filled with Integers and Extensions},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797349959},
doi = {10.1137/S0097539797349959},
abstract = {Computations with Toeplitz and Toeplitz-like matrices are fundamental for many areas of algebraic and numerical computing. The list of computational problems reducible to Toeplitz and Toeplitz-like computations includes, in particular, the evaluation of the greatest common divisor (gcd), the least common multiple (lcm), and the resultant of two polynomials, computing Pad\'{e} approximation and the Berlekamp--Massey recurrence coefficients, as well as numerous problems reducible to these. Transition to Toeplitz and Toeplitz-like computations is currently the basis for the design of the parallel randomized NC (RNC) algorithms for these computational problems. Our main result is in constructing nearly optimal randomized parallel algorithms for Toeplitz and Toeplitz-like computations and, consequently, for numerous related computational problems (including the computational problems listed above), where all the input values are integers and all the output values are computed exactly. This includes randomized parallel algorithms for computing the rank, the determinant, and a basis for the null-space of an  n  \texttimes{}  n  Toeplitz or Toeplitz-like matrix  A  filled with integers, as well as a solution  x  to a linear system  A   x =  f  if the system is consistent. Our algorithms use  O ((log  n ) log (  n  log |  A |)) parallel time and  O (  n  log  n ) processors, each capable of performing (in unit time) an arithmetic operation, a comparision, or a rounding of a rational number to a closest integer. The cost bounds cover the cost of the verification of the correctness of the output. The computations by these algorithms can be performed with the precision of  O (  n  log |  A |) bits, which matches the precision required in order to represent the output, except for the rank computation, where the precision of the computation decreases. The algorithms involve either a single random parameter or at most 2  n -1 parameters.The cited processor bounds are less by roughly factor  n  than ones supported by the known algorithms that run in polylogarithmic arithmetic time and do not use rounding to the closest integers.  Technically, we first devise new algorithms supporting our old nearly optimal complexity estimates for parallel computations with general matrices filled with integers. Then we decrease dramatically, by roughly factor  n 1.376, the processor bounds required in these algorithms in the case where the input matrix is Toeplitz-like. Our algorithms exploit and combine some new techniques (which may be of independent interest, e.g., in the study of parallel and sequential computation of recursive factorization of integer matrices) as well as our earlier techniques of variable diagonal (relating to each other several known algebraic and numerical methods), stream contraction, and the truncation of displacement generators in Toeplitz-like computations; our development and application of these techniques may be of independent},
journal = {SIAM J. Comput.},
month = oct,
pages = {1080–1125},
numpages = {46},
keywords = {randomized algorithms, displacement rank, parallel algorithms, Newton--Hensel's lifting, Toeplitz-like matrices, $p$-adic lifting, computational complexity, Toeplitz matrix computations, block Gauss--Jordan decomposition, polynomial gcd}
}

@article{10.1137/S0097539797329439,
author = {Ruppert, Eric},
title = {Determining Consensus Numbers},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797329439},
doi = {10.1137/S0097539797329439},
abstract = {Conditions on a shared object type T are given that are both necessary and sufficient for wait-free n-process consensus to be solvable using objects of type T and registers. The conditions apply to two large classes of deterministic shared objects: read-modify-write objects [C. P. Kruskal, L. Rudolph, and M. Snir, [ACM Trans. Prog. Lang. Syst., 10 (1988), pp. 579--601] and readable objects, which have operations that allow processes to read the state of the object. These classes include most objects that are used as the primitives of distributed systems. When the sequential specification of T is finite, the conditions may be checked in a finite amount of time to decide the question "Is the consensus number of T at least n?"  The conditions are also used to provide a clear proof of the robustness of the consensus hierarchy for read-modify-write and readable objects.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1156–1168},
numpages = {13},
keywords = {robust, asynchronous, consensus, consensus hierarchy, distributed computing, read-modify-write, shared memory, wait-free, readable}
}

@article{10.1137/S0097539797321547,
author = {Lutz, Jack H. and Zhao, Yong},
title = {The Density of Weakly Complete Problems under Adaptive Reductions},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797321547},
doi = {10.1137/S0097539797321547},
abstract = {Given a real number $alpha &lt; 1$, every language that is weakly $leq_{n^{alpha / 2} - {rm T}}^{{rm P}} $-hard for  E or weakly $leq_{n^{alpha} - {rm T}}^{rm P}$-hard for E2 is shown to be exponentially dense.  This simultaneously strengthens the results of Lutz and Mayordomo (1994) and Fu (1995).},
journal = {SIAM J. Comput.},
month = oct,
pages = {1197–1210},
numpages = {14},
keywords = {polynomial reductions, weakly complete problems, computational complexity, resource-bounded measure, complexity classes}
}

@article{10.1137/S0097539796312745,
author = {Herzberg, Amir and Kutten, Shay},
title = {Early Detection of Message Forwarding Faults},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796312745},
doi = {10.1137/S0097539796312745},
abstract = {In most communication networks, pairs of processors communicate by sending messages over a path connecting them. We present communication-efficient protocols that quickly detect and locate any failure along the path. Whenever there is excessive delay in forwarding messages along the path, the protocols detect a failure (even when the delay is caused by maliciously programmed processors). The protocols ensure optimal time for either message delivery or failure detection. We observe that the actual delivery time $delta$ of a message over a link is usually much smaller than the a priori known upper bound  D  on that delivery time. The main contribution of this paper is the way to model and take advantage of this observation. We introduce the notion of asynchronously early-terminating protocols, as well as protocols that are asynchronously early-terminating, i.e., time optimal in both worst case and typical cases. More precisely, we present a time complexity measure according to which one evaluates protocols both in terms of $D$ and $delta$. We observe that asynchronously early termination is a form of competitiveness.The protocols presented here are asynchronously early terminating since they are time optimal both in terms of $D$ and of $delta$. Previous communication-efficient solutions were slow in the case where $delta ll D$. We observe that this is the most typical case.It is suggested that the time complexity measure introduced, as well as the notion of asynchronously early-terminating, can be useful when evaluating protocols for other tasks in communication networks. The model introduced can be a useful step towards a formal analysis of real-time systems.Our protocols have  O (  n  log  n ) worst-case communication complexity. We show that this is the best possible for protocols that send immediately any acknowledgment they ever send. Then we show an early-terminating protocol which uses timing and delay to reduce the communication complexity in the typical executions where the number of failures is small and $delta ll D$. In such executions, its message complexity is linear, as is the complexity of nonfault tolerant protocols.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1169–1196},
numpages = {28},
keywords = {real time, competitive algorithms, time adaptive, distributed algorithms, network protocols, fault tolerance}
}

@article{10.1137/S0097539795284959,
author = {Micali, Silvio},
title = {Computationally Sound Proofs},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795284959},
doi = {10.1137/S0097539795284959},
abstract = {This paper puts forward a new notion of a proof based on computational complexity and explores its implications for computation at large. Computationally sound proofs provide, in a novel and meaningful framework, answers to old and new questions in complexity theory. In particular, given a random oracle or a new complexity assumption, they enable us to prove that verifying is easier than deciding for all theorems; provide a quite effective way to prove membership in computationally hard languages (such as ${cal C}o$-$cal N cal P$-complete ones); and show that every computation possesses a short certificate vouching its correctness. Finally, if a special type of computationally sound proof exists, we show that Blum's notion of program checking can be meaningfully broadened so as to prove that $cal N cal P$-complete languages are checkable.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1253–1298},
numpages = {46},
keywords = {probabilistically checkable proofs, random oracles, interactive proofs, Merkle trees}
}

@article{10.5555/586846.586967,
author = {Narasimhan, Giri and Smid, Michiel},
title = {Approximating the Stretch Factor  of Euclidean Graphs},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
abstract = {There are several results available in the literature dealing with efficient construction of t-spanners for a given set S of n points in $IR^d$.  t-spanners are Euclidean graphs in which distances between vertices in G are at most t times the Euclidean distances between them; in other words, distances in G are "stretched" by a factor of at most t. We consider the interesting dual problem: given a Euclidean graph G whose vertex set corresponds to the set S, compute the stretch factor of G, i.e., the maximum ratio between distances in G and the corresponding Euclidean distances.  It can trivially be solved by solving the all-pairs-shortest-path problem. However, if an approximation to the stretch factor is sufficient, then we show it can be efficiently computed by making only O(n) approximate shortest path queries in the graph G. We apply this surprising result to obtain efficient algorithms for approximating the stretch factor of Euclidean graphs such as paths, cycles, trees, planar graphs, and general graphs. The main idea behind the algorithm is to use Callahan and Kosaraju's well-separated pair decomposition.},
journal = {SIAM J. Comput.},
month = may,
pages = {978–989},
numpages = {12},
keywords = {approximate shortest paths, well-separated pairs, spanners, computational geometry}
}

@article{10.1137/S0097539799360148,
author = {Buhrman, Harry and Torenvliet, Leen},
title = {Randomness is Hard},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799360148},
doi = {10.1137/S0097539799360148},
abstract = {We study the set of incompressible strings for various resource bounded versions of Kolmogorov complexity. The resource bounded versions of Kolmogorov complexity we study are polynomial time CD complexity defined by Sipser, the nondeterministic variant CND due to Buhrman and Fortnow, and the polynomial space bounded Kolmogorov complexity CS introduced by Hartmanis. For all of these measures we define the set of random strings $mathrm{R}^{mathit{CD}}_t$, $mathrm{R}^{mathit{CND}}_t$, and $mathrm{R}^{mathit{CS}}_t$ as the set of strings $x$ such that $mathit{CD}^t(x)$, $mathit{CND}^t(x)$, and $mathit{CS}^s(x)$ is greater than or equal to the length of $x$ for $s$ and $t$ polynomials. We show the following: $mathrm{MA} subseteq mathrm{NP}^{mathrm{R}^{mathit{CD}}_t}$, where $mathrm{MA}$ is the class of Merlin--Arthur games defined by Babai. $mathrm{AM} subseteq mathrm{NP}^{mathrm{R}^{mathit{CND}}_t}$, where $mathrm{AM}$ is the class of Arthur--Merlin games. $mathrm{PSPACE} subseteq mathrm{NP}^{mathrm{cR}^{mathit{CS}}_s}$. In the last item $mathrm{cR}^{mathit{CS}}_s$ is the set of pairs $langle x,y rangle$ so that x is random given y . These results show that the set of random strings for various resource bounds is hard for complexity classes under nondeterministic reductions. This paper contrasts the earlier work of Buhrman and Mayordomo where they show that for polynomial time deterministic reductions the set of exponential time Kolmogorov random strings is not complete for EXP.},
journal = {SIAM J. Comput.},
month = may,
pages = {1485–1501},
numpages = {17},
keywords = {randomness, Arthur--Merlin, $mathit{CD}$ complexity, Merlin--Arthur, interactive proofs, relativization, Kolmogorov complexity, complexity classes, $mathit{CND}$ complexity}
}

@article{10.1137/S0097539799359117,
author = {He, Xin and Kao, Ming-Yang and Lu, Hsueh-I},
title = {A Fast General Methodology for Information-Theoretically Optimal  Encodings of Graphs},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799359117},
doi = {10.1137/S0097539799359117},
abstract = {We propose a fast methodology for encoding graphs with information-theoretically minimum numbers of bits. Specifically, a graph with property $pi$ is called a {em $pi$-graph}.  If $pi$ satisfies certain properties, then an n-node m-edge $pi$-graph G can be encoded by a binary string X such that (1) G and X can be obtained from each other in O(n log n) time, and (2) X has at most $beta(n)+o(beta(n))$ bits for any continuous superadditive function $beta(n)$ so that there are at most $2^{beta(n)+o(beta(n))}$ distinct $n$-node $pi$-graphs.  The methodology is applicable to general classes of graphs; this paper focuses on planar graphs. Examples of such $pi$ include all conjunctions over the following groups of properties: (1) G is a planar graph or a plane graph; (2) $G$ is directed or undirected; (3) $G$ is triangulated, triconnected, biconnected, merely connected, or not required to be connected; (4) the nodes of G are labeled with labels from ${1,ldots, ell_1}$ for $ell_1leq n$; (5) the edges of G are labeled with labels from ${1,ldots, ell_2}$ for $ell_2leq m$; and (6) each node (respectively, edge) of G has at most $ell_3=O(1)$ self-loops (respectively, $ell_4=O(1)$ multiple edges). Moreover, $ell_3$ and $ell_4$ are not required to be O(1) for the cases of $pi$ being a plane triangulation.  These examples are novel applications of small cycle separators of planar graphs and are the only nontrivial classes of graphs, other than rooted trees, with known polynomial-time information-theoretically optimal coding schemes.},
journal = {SIAM J. Comput.},
month = may,
pages = {838–846},
numpages = {9},
keywords = {data compression, graph encoding, planar graphs, triangulations, biconnected graphs, cycle separators, triconnected graphs}
}

@article{10.1137/S0097539799358926,
author = {Devroye, Luc and Jabbour, Jean and Zamora-Cura, Carlos},
title = {Squarish <i>k</i>-<i>d</i> Trees},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799358926},
doi = {10.1137/S0097539799358926},
abstract = {We modify the k-d tree on [0,1]d by always cutting the longest edge instead of rotating through the coordinates.  This modification makes the expected time behavior of lower-dimensional partial match queries behave as perfectly balanced complete k-d trees on n nodes. This is in contrast to a result of Flajolet and Puech [ J. Assoc. Comput. Mach., 33 (1986), pp. 371--407], who proved that for (standard) random k-d trees with cuts that rotate among the coordinate axes, the expected time behavior is much worse than for balanced complete k-d trees. We also provide results for range searching and nearest neighbor search for our trees.},
journal = {SIAM J. Comput.},
month = may,
pages = {1678–1700},
numpages = {23},
keywords = {data structures, k-d trees, probabilistic analysis of algorithms, expected time, partial match query, range search}
}

@article{10.1137/S0097539799357775,
author = {Brandst\"{a}dt, Andreas and Dragan, Feodor F. and K\"{o}hler, Ekkehard},
title = {Linear Time Algorithms for Hamiltonian Problems on (Claw,Net)-Free Graphs},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799357775},
doi = {10.1137/S0097539799357775},
abstract = {We prove that claw-free graphs, containing an induced dominating path, have a Hamiltonian path, and that 2-connected claw-free graphs, containing an induced doubly dominating cycle or a pair of vertices such that there exist two internally disjoint induced dominating paths connecting them, have a Hamiltonian cycle. As a consequence, we obtain linear time algorithms for both problems if the input is  restricted to (claw,net)-free graphs. These graphs enjoy those interesting structural properties.},
journal = {SIAM J. Comput.},
month = may,
pages = {1662–1677},
numpages = {16},
keywords = {dominating pair, Hamiltonian cycle, net)-free graphs, claw-free graphs, linear time algorithms, Hamiltonian path, dominating path, (claw}
}

@article{10.1137/S0097539799356812,
author = {Knessl, Charles and Szpankowski, Wojciech},
title = {Asymptotic Behavior of the Height in a Digital Search Tree and the Longest Phrase of the Lempel--Ziv Scheme},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799356812},
doi = {10.1137/S0097539799356812},
abstract = {We study the height of a  digital search tree (DST) built from n random strings generated by an unbiased memoryless source (i.e., all symbols are equally likely). We shall argue that the height of such a tree is equivalent to the length of the longest phrase in the Lempel--Ziv parsing scheme that partitions a random sequence into n phrases. We also analyze the longest phrase in the Lempel--Ziv scheme in which a string of fixed length m is parsed into a random number of phrases. In the course of our analysis, we shall identify four natural regions of the height distribution and characterize them asymptotically for large n. In particular, for the region where most of the probability mass is concentrated, the asymptotic distribution of the height exhibits an exponential of a Gaussian distribution (with an oscillating term) around the most probable value $k_1  =  lfloor log_2 n + sqrt{2log_2 n} - log_2 ( sqrt{2 log_2 n} ) + frac{1}{log 2} - frac{1}{2} rfloor +1$. More precisely, we shall prove that the asymptotic distribution of a DST is concentrated on either the one point k1 or the two points k1-1 and k1, which actually proves (slightly modified) Kesten's conjecture quoted in [Probab. Theory Related Fields, 79 (1988), pp. 509--542]. Finally, we compare our findings for DST with the asymptotic distributions of the height for other digital trees such as tries and PATRICIA tries.  We derive these results by a combination of analytic methods such as generating functions, Laplace transform, the saddle point method, and ideas of applied mathematics such as linearization, asymptotic matching, and the WKB method. Our analysis makes certain assumptions about the forms of some of the asymptotic expansions as well as their asymptotic matching. We also present detailed numerical verification of our results.},
journal = {SIAM J. Comput.},
month = may,
pages = {923–964},
numpages = {42},
keywords = {elliptic theta function, matched asymptotics, WKB method, height distribution, Lempel--Ziv algorithm, longest phrase distribution, saddle point method, digital search trees, linearization, Laplace transform}
}

@article{10.1137/S0097539799352474,
author = {Bonet, Maria Luisa and Esteban, Juan Luis and Galesi, Nicola and Johannsen, Jan},
title = {On the Relative Complexity of Resolution Refinements and Cutting Planes Proof Systems},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799352474},
doi = {10.1137/S0097539799352474},
abstract = {An exponential lower bound for the size of tree-like cutting planes refutations of a certain family of conjunctive normal form (CNF) formulas with polynomial size resolution refutations is proved. This implies an exponential separation between the tree-like versions and the dag-like versions of resolution and cutting planes. In both cases only superpolynomial separations were known [A. Urquhart,  Bull. Symbolic Logic,  1 (1995), pp. 425--467; J. Johannsen,  Inform. Process. Lett. , 67 (1998), pp. 37--41; P. Clote and A. Setzer, in  Proof Complexity and Feasible Arithmetics,  Amer. Math. Soc., Providence, RI, 1998, pp. 93--117]. In order to prove these separations, the lower bounds on the depth of monotone circuits of Raz and McKenzie in [  Combinatorica,  19 (1999), pp. 403--435] are extended to monotone real circuits. An exponential separation is also proved between tree-like resolution and several refinements of resolution: negative resolution and regular resolution. Actually, this last separation also provides a separation between tree-like resolution and ordered resolution, and thus the corresponding superpolynomial separation of [A. Urquhart,  Bull. Symbolic Logic , 1 (1995), pp. 425--467] is extended. Finally, an exponential separation between ordered resolution and unrestricted resolution (also negative resolution) is proved. Only a superpolynomial separation between ordered and unrestricted resolution was previously known [A. Goerdt,  Ann. Math. Artificial Intelligence , 6 (1992), pp. 169--184].},
journal = {SIAM J. Comput.},
month = may,
pages = {1462–1484},
numpages = {23},
keywords = {cutting planes proof system, resolution, circuit complexity, computational complexity, proof complexity}
}

@article{10.1137/S0097539799351882,
author = {Blum, Avrim and Karloff, Howard and Rabani, Yuval and Saks, Michael},
title = {A Decomposition Theorem for Task Systems and Bounds for Randomized Server Problems},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799351882},
doi = {10.1137/S0097539799351882},
abstract = {A lower bound of $Omega(sqrt{log k / log log k})$ is proved for the competitive ratio of randomized algorithms for the k-server problem against an oblivious adversary. The bound holds for arbitrary metric spaces (having at least k+1 points) and provides a new lower bound for the metrical task system problem as well. This improves the previous best lower bound of $Omega(log log k)$ for arbitrary metric spaces [H. J. Karloff, Y. Rabani, and Y. Ravid,  SIAM J. Comput., 23 (1994), pp. 293--312] and more closely approaches the conjectured lower bound of $Omega(log k)$. For the server problem on k+1 equally spaced points on a line, which corresponds to a natural motion-planning problem, a lower bound of $Omega(frac{log k}{log log k})$ is obtained.The results are deduced from a general decomposition theorem for a simpler version of both the k-server and the metrical task system problems, called the "pursuit-evasion game." It is shown that if a metric space $cal M$ can be decomposed into two spaces $cal M_L$ and $cal M_R$ such that the distance between them is sufficiently large compared to their diameter, then the competitive ratio for this game on $cal M$ can be expressed nearly exactly in terms of the ratios on each of the two subspaces. This yields a divide-and-conquer approach to bounding the competitive ratio of a space.},
journal = {SIAM J. Comput.},
month = may,
pages = {1624–1661},
numpages = {38},
keywords = {randomized algorithms, $k$-server, competitive analysis, on-line algorithms, task systems, lower bounds}
}

@article{10.1137/S009753979935061X,
author = {Andrews, Matthew and Fern\'{a}ndez, Antonio and Harchol-Balter, Mor and Leighton, Tom and Zhang, Lisa},
title = {General Dynamic Routing with Per-Packet Delay Guarantees of <i>O</i>(Distance + 1/Session Rate)},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979935061X},
doi = {10.1137/S009753979935061X},
abstract = {A central issue in the design of modern communication networks is that of providing performance guarantees. This issue is particularly important if the networks support real-time traffic such as voice and video. The most critical performance parameter to bound is the delay experienced by a packet as it travels from its source to its destination. We study dynamic routing in a connection-oriented packet-switching network. We consider a network with arbitrary topology on which a set of sessions is defined. For each session  i , packets are injected at a rate  r i to follow a predetermined path of length  d i. Due to limited bandwidth, only one packet at a time may advance on an edge (link). Session paths may overlap subject to the constraint that the total rate of sessions using any particular edge is at most $1-varepsilon$ for any constant $varepsilon in (0,1)$.We address the problem of scheduling the sessions at each switch, so as to minimize worst-case packet delay and queue buildup at the switches. We show the existence of a periodic schedule that achieves a delay bound of  O (1/  r i +  d i ) with only constant-size queues at the switches. This bound is asymptotically optimal for periodic schedules.A consequence of this result is an asymptotically optimal schedule for the static routing problem, wherein all packets are present at the outset. We obtain a delay bound of  O (  c i  +  d i ) for packets on path  P i , where  d i  is the number of edges in  P i  and  c i  is the maximum congestion along edges in  P i . This improves upon the previous known bound of  O (  c  +  d ), where  d  = max  i   d i  and  c  = max  i   c i .We also present a simple distributed algorithm that, with high probability, delivers every session-  i  packet to its destination within  O (1/  r i +  d i log(  m /  r min)) steps of its injection, where  r  min is the minimum session rate and  m  is the number of edges in the network. Our results can be generalized to (leaky-bucket constrained) bursty traffic, where session  i  tolerates a burst size of  b i . In this case, our delay bounds become  O (  b i /  r i  +  d i ) and  O (  b i /  r i +  d i log(  m /  r min)), respectively.},
journal = {SIAM J. Comput.},
month = may,
pages = {1594–1623},
numpages = {30},
keywords = {delay bounds, scheduling, communication networks, packet routing}
}

@article{10.1137/S0097539799180408,
author = {Gambosi, Giorgio and Postiglione, Alberto and Talamo, Maurizio},
title = {Algorithms for the Relaxed Online Bin-Packing Model},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799180408},
doi = {10.1137/S0097539799180408},
abstract = {The typical online bin-packing problem requires the fitting of a sequence of rationals in (0,1] into a minimum number of bins of unit capacity, by packing the  i th input element without any knowledge of the sizes or the number of input elements that follow. Moreover, unlike typical online problems, this one issue does not admit any data reorganization, i.e., no element can be moved from one bin to another. In this paper, first of all, the "Relaxed" online bin-packing model will be formalized; this model allows a constant number of elements to move from one bin to another, as a consequence of the arrival of a new input element. Then, in the context of this new model, two online algorithms will be described. The first presents linear time and space complexities with a 1.5 approximation ratio and moves, at most once, only "small" elements; the second, instead, is an  O (  n  log  n ) time and linear space algorithm with a 1.33. . . approximation ratio and moves each element a constant number of times. In the worst case, as a result of the arrival of a new input element, the first algorithm moves no more than three elements, while the second moves as many as seven elements. Please note that the number of movements performed is explicitly considered in the complexity analysis. Both algorithms are below the theoretical 1.536. . . lower bound, effective for the online bin-packing algorithms without the movement of elements. Moreover, our algorithms are "more online" than any other linear space online bin-packing algorithm because, unlike the algorithms already known, they allow the return of a (possibly relevant) fraction of bins before the work is carried out.},
journal = {SIAM J. Comput.},
month = may,
pages = {1532–1551},
numpages = {20},
keywords = {bin packing, complexity, approximation algorithms, online algorithms}
}

@article{10.1137/S0097539798367892,
author = {B\"{u}rgisser, Peter},
title = {The Computational Complexity to Evaluate Representations of General Linear Groups},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798367892},
doi = {10.1137/S0097539798367892},
abstract = {We describe a fast algorithm to evaluate irreducible matrix representations of complex general linear groups ${rm GL}_{m}$ with respect to a symmetry adapted basis (Gelfand--Tsetlin basis). This is complemented by a lower bound, which shows that our algorithm is optimal up to a factor $m^2$ with regard to nonscalar complexity. Our algorithm can be used for the fast evaluation of special functions: for instance, we obtain an $O(elllogell)$ algorithm to evaluate all associated Legendre functions of degree $ell$. As a further application we obtain an algorithm to evaluate immanants, which is faster than previous algorithms due to Hartmann and Barvinok.},
journal = {SIAM J. Comput.},
month = may,
pages = {1010–1022},
numpages = {13},
keywords = {lower bounds, Gelfand--Tsetlin bases, special functions, fast algorithms, immanants, representations of general linear groups, completeness}
}

@article{10.1137/S0097539798367880,
author = {B\"{u}rgisser, Peter},
title = {The Computational Complexity of Immanants},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798367880},
doi = {10.1137/S0097539798367880},
abstract = {Permanents and determinants are special cases of immanants. The latter are polynomial matrix functions defined in terms of characters of symmetric groups and corresponding to Young diagrams. Valiant has proved that the evaluation of permanents is a complete problem in both the Turing machine model (#P-completeness) as well as in his algebraic model (VNP-completeness). We show that the evaluation of immanants corresponding to hook diagrams or rectangular diagrams of polynomially growing width is both #P-complete and VNP-complete.},
journal = {SIAM J. Comput.},
month = may,
pages = {1023–1040},
numpages = {18},
keywords = {computational complexity, immanants, permanents, algebraic completeness}
}

@article{10.1137/S0097539798349164,
author = {Lennerstad, Hakan and Lundberg, Lars},
title = {Optimal Worst Case Formulas Comparing Cache Memory Associativity},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798349164},
doi = {10.1137/S0097539798349164},
abstract = {In this paper we derive a worst case formula comparing the number of cache hits for two different cache memories. From this various other bounds for cache memory performance may be derived. Consider an arbitrary program  P  which is to be executed on a computer with two alternative cache memories. The first cache is set-associative or direct-mapped. It has  k  sets and  u  blocks in each set; this is called a (  k ,  u )-cache. The other is a fully associative cache with  q  blocks---a (1,  q )-cache.We derive an explicit formula for the ratio of the number of cache hits  h (  P ,  k ,  u ) for a (  k ,  u )-cache compared to a (1,  q )-cache for a worst case program  P . We assume that the mappings of the program variables to the cache blocks are optimal.The formula quantifies the ratio $$ inf_P frac{h(P,k,u)}{h(P,1,q)}, $$ where the infimum is taken over all programs  P  with  n  variables. The formula is a function of the parameters  n ,  k ,  u , and  q  only. Note that the quantity $h(P,k,u)$ is NP-hard.We assume the commonly used LRU (least recently used) replacement policy, that each variable can be stored in one memory block, and that each variable is free to be mapped to any set.Since the bound is decreasing in the parameter  n , it is an optimal bound for all programs with at most  n  variables. The formula for cache hits allows us to derive optimal bounds comparing the access times for cache memories. The formula also gives bounds (these are not optimal, however) for any other replacement policy, for direct-mapped versus set-associative caches, and for programs with variables larger than the cache memory blocks.},
journal = {SIAM J. Comput.},
month = may,
pages = {872–905},
numpages = {34},
keywords = {performance bound, 1$-matrices, extremal matrices, fully associative cache, set-associative cache, direct-mapped cache, cache memory, $0}
}

@article{10.1137/S0097539798347190,
author = {Brazil, M. and Thomas, D. A. and Weng, J. F.},
title = {Minimum Networks in Uniform Orientation Metrics},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798347190},
doi = {10.1137/S0097539798347190},
abstract = {In this paper we use the variational method to systematically study properties of minimum networks connecting any given set of points (called terminals) in a $\lambda$-plane, in which all lines are in $\lambda$ uniform orientations $i\pi /\lambda\ (0\le i<\lambda )$. We prove a number of angle conditions for Steiner minimum $\lambda$-trees, which are similar to the ones in the Euclidean case. In particular, we show that there exists a Steiner minimum $\lambda$-tree whose minimum angles at Steiner points are $\lfloor 2\lambda /3\rfloor\pi /\lambda$ and whose maximum angles are $\lceil 2\lambda /3\rceil\pi /\lambda$. We also investigate the assignment of nonstraight edges and unequal angles in Steiner minimum $\lambda$-trees, and we prove that there exists a Steiner minimum $\lambda$-tree in which every full component has at most one nonstraight edge. From these properties we are able to devise a number of finite methods for constructing Steiner minimum $\lambda$-trees. One of these methods is based on using algorithms for finding graphical Steiner minimum trees, and the other uses a generalization of the method of Melzak for Euclidean Steiner trees.},
journal = {SIAM J. Comput.},
month = may,
pages = {1579–1593},
numpages = {15},
keywords = {fixed orientations, VLSI design, variational method, Steiner tree}
}

@article{10.1137/S0097539798346676,
author = {Buchsbaum, Adam L. and Giancarlo, Raffaele and Westbrook, Jeffery R.},
title = {On the Determinization of Weighted Finite Automata},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798346676},
doi = {10.1137/S0097539798346676},
abstract = {We study the problem of constructing the deterministic equivalent of a nondeterministic weighted finite-state automaton (WFA). Determinization of WFAs has important applications in automatic speech recognition (ASR). We provide the first polynomial-time algorithm to test for the  twins property, which determines if a WFA admits a deterministic equivalent. We also give upper bounds on the size of the deterministic equivalent; the bound is tight in the case of acyclic WFAs. Previously, Mohri presented a superpolynomial-time algorithm to test for the twins property, and he also gave an algorithm to determinize WFAs. He showed that the latter runs in time linear in the size of the output when a deterministic equivalent exists; otherwise, it does not terminate. Our bounds imply an upper bound on the running time of this algorithm.Given that WFAs can expand exponentially in size when determinized, we explore why those that occur in ASR tend to  shrink when determinized. According to ASR folklore, this phenomenon is attributable solely to the fact that ASR WFAs have simple topology, in particular, that they are acyclic and layered. We introduce a very simple class of WFAs with this structure,  but we show that the expansion under determinization depends on the transition weights: some weightings cause them to shrink, while others, including random weightings, cause them to expand exponentially. We provide experimental evidence that ASR WFAs exhibit this weight dependence. That they shrink when determinized, therefore, is a result of favorable weightings in addition to special topology. These analyses and observations have been used to design a new, approximate WFA determinization algorithm, reported in a separate paper along with experimental results showing that it achieves significant WFA size reduction with negligible impact on ASR performance.},
journal = {SIAM J. Comput.},
month = may,
pages = {1502–1531},
numpages = {30},
keywords = {speech recognition, rational functions and power series, weighted automata, algorithms}
}

@article{10.1137/S0097539798343647,
author = {Agrawal, Manindra and Thierauf, Thomas},
title = {The Formula Isomorphism Problem},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798343647},
doi = {10.1137/S0097539798343647},
abstract = {We investigate the computational complexity of the  formula isomorphism  problem (FI): on input of two boolean formulas  F  and  G  decide whether there exists a permutation of the variables of  G  such that  F  and  G  become equivalent. FI is contained in ${Sigma_{2}{bf P}}$, the second level of the polynomial hierarchy. Our main result is a one-round interactive proof for the complementary  formula nonisomorphism  problem (FNI), where the verifier has access to an  NP -oracle. To obtain this, we use a result from learning theory by Bshouty et al. that boolean formulas can be learned probabilistically with equivalence queries and access to an  NP -oracle. As a consequence, FI cannot be ${Sigma_{2}{bf P}}$-complete unless the polynomial hierarchy collapses.Further properties of FI are shown: FI has and- and or-functions, the counting version, #FI, can be computed in polynomial time relative to FI, and FI is self-reducible.},
journal = {SIAM J. Comput.},
month = may,
pages = {990–1009},
numpages = {20},
keywords = {interactive proofs, learning theory, complexity theory, boolean isomorphism problems}
}

@article{10.1137/S0097539798343362,
author = {Ma, Bin and Li, Ming and Zhang, Louxin},
title = {From Gene Trees to Species Trees},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798343362},
doi = {10.1137/S0097539798343362},
abstract = {This paper studies various algorithmic issues in reconstructing a species tree from gene trees under the duplication and the mutation cost model. This is a fundamental problem in computational molecular biology. Our main results are as follows. A linear time algorithm is presented for computing all the losses in duplications associated with the least common ancestor mapping from a gene tree to a species tree. This answers a problem raised recently by Eulenstein, Mirkin, and Vingron [ J. Comput. Bio. , 5 (1998), pp. 135--148]. The complexity of finding an optimal species tree from gene trees is studied. The problem is proved to be NP-hard for the duplication cost and for the mutation cost. Further, the concept of reconciled trees was introduced by Goodman et al. and formalized by Page for visualizing the relationship between gene and species trees. We show that constructing an optimal reconciled tree for gene trees is also NP-hard. Finally, we consider a general reconstruction problem and show it to be NP-hard even for the well-known nearest neighbor interchange distance. A new and efficiently computable metric is defined based on the duplication cost. We show that the problem of finding an optimal species tree from gene trees is NP-hard under this new metric but it can be approximated within factor 2 in polynomial time. Using this approximation result, we propose a heuristic method for finding a species tree from gene trees with uniquely labeled leaves under the duplication cost. Our experimental tests demonstrate that when the number of species is larger than 15 and gene trees are close to each other, our heuristic method is significantly better than the existing program in Page's GeneTree 1.0 that starts the search from a random tree.},
journal = {SIAM J. Comput.},
month = may,
pages = {729–752},
numpages = {24},
keywords = {NP-hardness, algorithms, gene trees, species trees}
}

@article{10.1137/S0097539798339430,
author = {Kaplan, Haim and Okasaki, Chris and Tarjan, Robert E.},
title = {Simple Confluently Persistent Catenable Lists},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798339430},
doi = {10.1137/S0097539798339430},
abstract = {We consider the problem of maintaining persistent lists subject to concatenation and to insertions and deletions at both ends.  Updates to a persistent data structure are nondestructive---each operation produces a new list incorporating the change, while keeping intact the list or lists to which it applies. Although general techniques exist for making data structures persistent, these techniques fail for structures that are subject to operations, such as catenation, that combine two or more versions.  In this paper we develop a simple implementation of persistent double-ended queues (deques) with catenation that supports all deque operations in constant amortized time. Our implementation is functional if we allow memoization.},
journal = {SIAM J. Comput.},
month = may,
pages = {965–977},
numpages = {13},
keywords = {data structures, functional programming, double-ended queue (deque), stack-ended queue (steque), memoization, persistent data structures, queue, stack}
}

@article{10.1137/S0097539798337716,
author = {Barrett, Chris and Jacob, Riko and Marathe, Madhav},
title = {Formal-Language-Constrained Path Problems},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798337716},
doi = {10.1137/S0097539798337716},
abstract = {Given an alphabet $Sigma$, a (directed) graph G whose edges are weighted and $Sigma$-labeled, and a formal language $LsubseteqSigma^*$, the formal-language-constrained shortest/simple path problem consists of finding a shortest (simple) path p in G complying with the additional constraint that l( p) in L$. Here l( p) denotes the unique word obtained by concatenating the $Sigma$-labels of the edges along the path p. The main contributions of this paper include the following: We show that the formal-language-constrained shortest path problem is solvable efficiently in polynomial time when L is restricted to be a context-free language (CFL). When L is specified as a regular language we provide algorithms with improved space and time bounds. In contrast, we show that the problem of finding a simple path between a source and a given destination is NP-hard, even when L is restricted to fixed simple regular languages and to very simple classes of graphs (e.g., complete grids). For the class of treewidth-bounded graphs, we show that (i) the problem of finding a regular-language-constrained simple path between source and destination is solvable in polynomial time and (ii) the extension to finding CFL-constrained simple paths is NP-complete. Our results extend the previous results in [ SIAM J. Comput., 24 (1995), pp. 1235--1258; Proceedings of the 76 th Annual Meeting of the Transportation Research Board, 1997; and Proceedings of the 9 th ACM SIGACT-SIGMOD-SIGART Symposium on Database Systems, 1990, pp. 230--242]. Several additional extensions and applications of our results in the context of transportation problems are presented. For instance, as a corollary of our results, we obtain a polynomial-time algorithm for the best k-similar path problem studied in Proceedings of the 76 th Annual Meeting of the Transportation Reasearch Board, 1997]. The previous best algorithm was given by [ Proceedings of the 76 th Annual Meeting of the Transportation Research Board, 1997] and takes exponential time in the worst case.},
journal = {SIAM J. Comput.},
month = may,
pages = {809–837},
numpages = {29},
keywords = {World Wide Web, computational complexity, transportation planning, query processing, formal languages, shortest paths, multicriteria problems, algorithms}
}

@article{10.1137/S0097539798335766,
author = {Lo, Wai-Kau and Hadzilacos, Vassos},
title = {All of Us Are Smarter than Any of Us: Nondeterministic Wait-Free Hierarchies  Are Not Robust},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798335766},
doi = {10.1137/S0097539798335766},
abstract = {A wait-free hierarchy ACM Transactions on Programming Languages and Systems, 11 (1991), pp. 124--149; Proceedings of the 12th ACM Symposium on Principles of Distributed Computing, 1993, pp. 145--158] classifies object types on the basis of their strength in supporting wait-free implementations of other types. Such a hierarchy is robust if it is impossible to implement objects of types that it classifies as "strong" by combining objects of types that it classifies as "weak." We prove that if nondeterministic types are allowed, the only wait-free hierarchy that is robust is the trivial one, which lumps all types into a single level. In particular, the consensus hierarchy (the most closely studied wait-free hierarchy) is not robust. Our result implies that, in general, it is not possible to determine the power of a concurrent system that supports a given set of primitive object types by reasoning about the power of each primitive type in isolation.},
journal = {SIAM J. Comput.},
month = may,
pages = {689–728},
numpages = {40},
keywords = {robustness, wait-free, consensus number}
}

@article{10.1137/S0097539797330045,
author = {Dinitz, Yefim and Vainshtein, Alek},
title = {The General Structure of Edge-Connectivity of a Vertex Subset in a Graph and Its Incremental Maintenance. Odd Case},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797330045},
doi = {10.1137/S0097539797330045},
abstract = {Let G=(V,E) be an undirected graph, S be a subset of its vertices, ${frak C}_S$ be the set of minimum edge-cuts partitioning S, and $lambda_S$ be the cardinality of such a cut. We suggest a graph structure, called the connectivity carcass of S, that represents both cuts in $frak C_S$ and the partition of V by all these cuts; its size is $O(min{|E|,lambda_S|V|})$. In this paper we present general constructions and study in detail the case $lambda_S$ odd; the specifics of the case $lambda_S$ even are considered elsewhere. For an adequate description of the connectivity carcass we introduce a new type of graph: locally orientable graphs, which generalize digraphs. The connectivity carcass consists of a locally orientable quotient graph of G, a cactus tree (in case $lambda_S$ odd, just a tree) representing all distinct partitions of S by cuts in ${frak C}_S$, and a mapping connecting them. One can build it in O(|S|) max-flow computations in G. For an arbitrary sequence of u edge insertions not changing $lambda_S$, the connectivity carcass can be maintained in time $O(|V|min{|E|,lambda_S|V|}+u)$. For two vertices of G,  queries asking whether they are separated by a cut in $frak C_S$ are answered in O(1) worst-case time per query. Another possibility is to maintain the carcass in $O(|S|min{|E|,lambda_S|V|}+u)$ time, but to answer the queries in O(1) time only if at least one of the vertices belongs to S.},
journal = {SIAM J. Comput.},
month = may,
pages = {753–808},
numpages = {56},
keywords = {incremental maintenance, minimum cuts, dynamic algorithms, edge-connectivity, graph structures}
}

@article{10.1137/S0097539797329889,
author = {Andersson, Arne and Hagerup, Torben},
title = {Tight Bounds for Searching a Sorted Array of Strings},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797329889},
doi = {10.1137/S0097539797329889},
abstract = {Given a k-character query string and an array of n strings arranged in lexicographical order, computing the rank of the query string among the n strings or deciding whether it occurs in the array requires the inspection of $$ Thetaleft( frac {klog {log n}} {log {log {(4+frac{k log{log n}}{log n})}}}+k+log nright) $$ characters in the worst case.},
journal = {SIAM J. Comput.},
month = may,
pages = {1552–1578},
numpages = {27},
keywords = {potential functions, dictionaries, string searching, lower bounds, character comparisons}
}

@article{10.1137/S0097539797325727,
author = {Dyer, Martin E. and Sen, Sandeep},
title = {Fast and Optimal Parallel Multidimensional Search in PRAMs with Applications to Linear Programming and Related Problems},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797325727},
doi = {10.1137/S0097539797325727},
abstract = {We describe a deterministic parallel algorithm for linear programming in fixed dimension d that takes poly(log log n) time in the common concurrent read concurrent write (CRCW) PRAM model and does optimal O(n) work. In the exclusive read exclusive write (EREW) model, the algorithm runs in O(log n · log logd-1 n) time. Our algorithm is based on multidimensional search and effective use of approximation algorithms to speed up the basic search in the CRCW model. Our method also yields very fast poly(log log n) algorithms for smallest enclosing sphere and approximate ham-sandwich cuts and an O(log n) time work-optimal algorithm for exact ham-sandwich cuts of separable point sets. For these problems, in particular for fixed-dimensional linear programming, o(log n) time efficient deterministic PRAM algorithms were not known until very recently.},
journal = {SIAM J. Comput.},
month = may,
pages = {1443–1461},
numpages = {19},
keywords = {linear programming, parallel algorithms, computational geometry}
}

@article{10.1137/S009753979731981X,
author = {Milidi\'{u}, Ruy Luiz and Laber, Eduardo Sany},
title = {The WARM-UP Algorithm: A Lagrangian Construction of Length Restricted Huffman Codes},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979731981X},
doi = {10.1137/S009753979731981X},
abstract = {Given an alphabet {a,1, . . . ,an} with the corresponding list of weights [w1, . . . ,wn], and a number $L geq lceil log n rceil $,  we introduce the WARM-UP algorithm, a Lagrangian algorithm for constructing suboptimal length restricted  prefix codes. Two implementations of the algorithm are proposed. The first one has time complexity $ O(n log n + n log fMax) $, where  {mbox{$overline{w}$} } is the highest presented weight. The second one  runs in O(nL  log (n/L)) time. The number of additional bits per symbol generated by WARM-UP when comparing to Huffman encoding is not greater than ${1/ psi^{L-lceil log (n+ lceil log n rceil -L) rceil-2}}$. Even though the algorithm is approximated it presents an optimal behavior for practical settings.An important feature of the proposed algorithm is its implementation simplicity. The algorithm is basically a selected sequence of Huffman tree constructions for modified weights. The approach gives some new insights on the problem.},
journal = {SIAM J. Comput.},
month = may,
pages = {1405–1426},
numpages = {22},
keywords = {Huffman trees, Lagrangian duality, prefix codes}
}

@article{10.1137/S0097539796313477,
author = {Cole, Richard and Farach-Colton, Martin and Hariharan, Ramesh and Przytycka, Teresa and Thorup, Mikkel},
title = {An <i>O</i>(<i>n</i>Log <i>n</i>) Algorithm for the Maximum Agreement Subtree Problem for Binary Trees},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796313477},
doi = {10.1137/S0097539796313477},
abstract = {The maximum agreement subtree problem is the following. Given two rooted trees whose leaves are drawn from the same set of items (e.g., species), find the largest subset of these items so that the portions of the two trees restricted to these items are isomorphic. We consider the case which occurs frequently in practice, i.e., the case when the trees are binary, and give an O(nlog n) time algorithm for this problem.},
journal = {SIAM J. Comput.},
month = may,
pages = {1385–1404},
numpages = {20},
keywords = {agreement subtree, algorithms}
}

@article{10.1137/S0097539795290350,
author = {Gaujal, Bruno and Jean-Marie, Alain and Mairesse, Jean},
title = {Computations of Uniform Recurrence Equations Using  Minimal Memory Size},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795290350},
doi = {10.1137/S0097539795290350},
abstract = {We consider a system of uniform recurrence equations of dimension 1 and we show how its computation can be carried out using minimal memory size with several synchronous processors. This result is then  applied to register minimization for digital circuits and parallel computation of task graphs.},
journal = {SIAM J. Comput.},
month = may,
pages = {1701–1738},
numpages = {38},
keywords = {+) linear system, register minimization, task graph, (max, circuit design, uniform recurrence equation}
}

@article{10.1137/S0097539795253591,
author = {Kapoor, Sanjiv and Maheshwari, S. N.},
title = {Efficiently Constructing the Visibility Graph  of a Simple Polygon with Obstacles},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795253591},
doi = {10.1137/S0097539795253591},
abstract = {This paper describes an output-sensitive scheme to construct the visibility graph of a simple polygon with m obstacles and n vertices in optimal O(|E| +T + m log n ) time where |E| is the size of the visibility graph and T is the time required to triangulate the simple polygon with obstacles. We use a partition of the space into regions called corridors which eases the efforts of the construction. Our algorithms are simple and the data structures used are only linked lists.},
journal = {SIAM J. Comput.},
month = may,
pages = {847–871},
numpages = {25},
keywords = {output-sensitive, obstacles, triangulation, simple polygon, visibility graph, linked lists}
}

@article{10.1137/S0097539794268042,
author = {Karlin, Anna R. and Phillips, Steven J. and Raghavan, Prabhakar},
title = {Markov Paging},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268042},
doi = {10.1137/S0097539794268042},
abstract = {This paper considers the problem of paging under the assumption that the sequence of pages accessed is generated by a Markov chain. We use this model to study the fault-rate of paging algorithms. We first draw on the theory of Markov decision processes to characterize the paging algorithm that achieves optimal fault-rate on any Markov chain. Next, we address the problem of devising a paging strategy with low fault-rate for a given Markov chain. We show that a number of intuitive approaches fail. Our main result is a polynomial-time procedure that, on any Markov chain, will give a paging algorithm with fault-rate at most a constant times optimal. Our techniques show also that some algorithms that do poorly in practice fail in the Markov setting, despite known (good) performance guarantees when the requests are generated independently from a probability distribution.},
journal = {SIAM J. Comput.},
month = may,
pages = {906–922},
numpages = {17},
keywords = {paging, Markov chains, competitive analysis, locality of reference}
}

@article{10.1137/S0097539700369740,
author = {Peleg, David and Rubinovich, Vitaly},
title = {A Near-Tight Lower Bound on the Time Complexity of Distributed Minimum-Weight Spanning Tree Construction},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539700369740},
doi = {10.1137/S0097539700369740},
abstract = {This paper presents a lower bound of $Omega(D+sqrt n/log n)$ on the time required for the distributed construction of a minimum-weight spanning tree (MST) in weighted n-vertex networks of diameter $D=Omega(log n)$, in the bounded message model. This establishes the asymptotic near-optimality of existing time-efficient distributed algorithms for the problem, whose complexity is $O(D + sqrt n log^* n)$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1427–1442},
numpages = {16},
keywords = {minimum weight spanning tree, distributed algorithm, lower bound}
}

@article{10.1137/S0097539799352735,
author = {Trevisan, Luca},
title = {When Hamming Meets Euclid: The Approximability of Geometric TSP and Steiner Tree},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799352735},
doi = {10.1137/S0097539799352735},
abstract = {We prove that the traveling salesman problem ({sc Min TSP}) is {sf Max SNP}-hard (and  thus {sf NP}-hard to approximate within some constant r&gt;1) even  if all cities  lie in a Euclidean space of dimension $log n$ ($n$ is the number of cities) and distances  are computed  with respect to any lp norm. The running time of recent approximation schemes for geometric {sc Min TSP} is doubly exponential in the number of dimensions. Our result implies that this dependence is necessary unless NP has subexponential algorithms. As an intermediate step, we also prove the hardness of approximating {sc Min TSP}  in Hamming spaces. Finally,  we prove a similar, but weaker, inapproximability result for the Steiner minimal tree problem ({sc Min ST}).  The reduction for {sc Min TSP} uses error-correcting codes; the reduction for {sc Min ST} uses the integrality property of {sc Min-Cut} linear programming relaxations. The only previous inapproximability results for metric {sc Min TSP} involved metrics where all distances are 1 or 2.},
journal = {SIAM J. Comput.},
month = apr,
pages = {475–485},
numpages = {11},
keywords = {computational complexity, combinatorial optimization, Steiner tree problem, traveling salesman problem, hardness of approximation}
}

@article{10.1137/S0097539798349188,
author = {Chan, Timothy M.},
title = {Random Sampling, Halfspace Range Reporting, and Construction of \lowercase$(\le k)$-Levels in Three Dimensions},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798349188},
doi = {10.1137/S0097539798349188},
abstract = {Given n points in three dimensions, we show how to answer halfspace range reporting queries in O(log n+k) expected time for an output size k. Our data structure can be preprocessed in optimal O(n log n) expected time. We apply this result to obtain the first optimal randomized algorithm for the construction of the $(le k)$-level in an arrangement of n planes in three dimensions. The algorithm runs in O(n log n+nk2) expected time. Our techniques are based on random sampling. Applications in two dimensions include an improved data structure for "k nearest neighbors" queries and an algorithm that constructs the order-k Voronoi diagram in O(n log n+nk log k) expected time.},
journal = {SIAM J. Comput.},
month = apr,
pages = {561–575},
numpages = {15},
keywords = {Voronoi diagrams, levels in arrangements, randomized algorithms, range searching, nearest neighbor searching, computational geometry, randomized data structures}
}

@article{10.1137/S0097539798348870,
author = {Bertram--Kretzberg, Claudia and Hofmeister, Thomas and Lefmann, Hanno},
title = {An Algorithm for Heilbronn's Problem},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798348870},
doi = {10.1137/S0097539798348870},
abstract = {Heilbronn conjectured that given arbitrary n points from the 2-dimensional unit square, there must be three points which form a triangle of area at most O(1/n2). This conjecture was disproved by a nonconstructive argument of Koml\'{o}s, Pintz, and Szemer\'{e}di [ J. London Math. Soc., 25 (1982), pp. 13--24] who showed that for every n there is a configuration of n points in the unit square where all triangles have area at least $Omega({log n}/{n^2})$. Considering a discretization of Heilbronn's problem, we give an alternative proof of the result from [J. London Math. Soc., 25 (1982), pp. 13--24]. Our approach has two advantages: First, it yields a polynomial-time algorithm which for every n computes a configuration of n points where all triangles have area $Omega({log n}/{n^2})$. Second, it allows us to consider a generalization of Heilbronn's problem to convex hulls of k points where we can show that an algorithmic solution is also available.},
journal = {SIAM J. Comput.},
month = apr,
pages = {383–390},
numpages = {8},
keywords = {hypergraphs, Heilbronn, triangles, independent sets}
}

@article{10.1137/S0097539798347906,
author = {Bar-Noy, Amotz and Guha, Sudipto},
title = {Message Multicasting in Heterogeneous Networks},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798347906},
doi = {10.1137/S0097539798347906},
abstract = {In heterogeneous networks, sending messages may incur different delays on different links, and each node may have a different switching time between messages. The well-studied telephone model is obtained when all link delays and switching times are equal to one unit. We investigate the problem of finding the minimum time required to multicast a message from one source to a subset of the nodes of size k. The problem is NP-hard even in the basic telephone model. We present a polynomial-time algorithm that approximates the minimum multicast time within a factor of O(log k). Our algorithm improves on the best known approximation factor for the telephone model by a factor of $O(frac{log n}{loglog k})$. No approximation algorithms were known for the general model considered in this paper.},
journal = {SIAM J. Comput.},
month = apr,
pages = {347–358},
numpages = {12},
keywords = {multicast, LogP model, approximation algorithms, postal model, heterogeneous networks, combinatorial optimization}
}

@article{10.1137/S0097539798347189,
author = {Gabow, Harold N. and Jord\'{a}n, Tibor},
title = {How to Make a Square Grid Framework  with Cables Rigid},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798347189},
doi = {10.1137/S0097539798347189},
abstract = {This paper solves the problem of making a bipartite digraph strongly connected by adding the smallest number of new edges that preserve bipartiteness.  A result of Baglivo and Graver shows that this corresponds to making a two-dimensional square grid framework with cables rigid by adding the smallest number of new cables.  We prove a min-max formula for the smallest number of new edges in the digraph problem and give a corresponding linear-time algorithm.  We generalize these results to the problem of making an arbitrary digraph strongly connected by adding the smallest number of new edges, each of which joins vertices in distinct blocks of a given partition of the vertex set.},
journal = {SIAM J. Comput.},
month = apr,
pages = {649–680},
numpages = {32},
keywords = {rigidity, square grid framework, graph algorithms, strong connectivity, min-max theorems, connectivity augmentation}
}

@article{10.1137/S0097539798347177,
author = {Kushilevitz, Eyal and Ostrovsky, Rafail and Rabani, Yuval},
title = {Efficient Search for Approximate Nearest Neighbor in High Dimensional Spaces},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798347177},
doi = {10.1137/S0097539798347177},
abstract = {We address the problem of designing data structures that allow efficient search for approximate nearest neighbors. More specifically, given a database consisting of a set of vectors in some high dimensional Euclidean space, we want to construct a space-efficient data structure that would allow us to search, given a query vector, for the closest or nearly closest vector in the database. We also address this problem when distances are measured by the L1 norm and in the Hamming cube. Significantly improving and extending recent results of Kleinberg, we construct data structures whose size is polynomial in the size of the database and search algorithms that run in time nearly linear or nearly quadratic in the dimension. (Depending on the case, the extra factors are polylogarithmic in the size of the database.)},
journal = {SIAM J. Comput.},
month = apr,
pages = {457–474},
numpages = {18},
keywords = {data structures, random projections, nearest neighbor search}
}

@article{10.1137/S0097539798345944,
author = {Bergman, Clifford and Slutzki, Giora},
title = {Complexity of Some Problems Concerning  Varieties and Quasi-Varieties of Algebras},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798345944},
doi = {10.1137/S0097539798345944},
abstract = {In this paper we consider the complexity of several problems involving finite algebraic structures.  Given finite  algebras  A and B, these problems ask the following. (1) Do  A and  B satisfy precisely the same identities? (2) Do they satisfy the same quasi-identities?  (3) Do  A and  B have the same set of term operations?In addition to the general case in which we allow arbitrary (finite) algebras, we consider each of these problems under the restrictions that all operations are unary and that  A and  B have cardinality two.  We briefly discuss the relationship of these problems to algebraic specification theory.},
journal = {SIAM J. Comput.},
month = apr,
pages = {359–382},
numpages = {24},
keywords = {quasi-variety, term-equivalence, nondeterminism, variety, clone, computational complexity, hyperexponential time, logarithmic space, polynomial space}
}

@article{10.1137/S0097539798343891,
author = {Buhrman, Harry and van Melkebeek, Dieter and Regan, Kenneth W. and Sivakumar, D. and Strauss, Martin},
title = {A Generalization of Resource-Bounded Measure, with Application to the BPP vs. EXP Problem},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798343891},
doi = {10.1137/S0097539798343891},
abstract = {We introduce  resource-bounded betting games and propose a generalization of Lutz's resource-bounded measure in which the choice of the next string to bet on is fully adaptive. Lutz's martingales are equivalent to betting games constrained to bet on strings in lexicographic order. We show that if strong pseudorandom number generators exist, then betting games are equivalent to martingales for measure on E and EXP. However, we construct betting games that succeed on certain classes whose Lutz measures are important open problems: the class of polynomial-time Turing-complete languages in EXP and its superclass of polynomial-time Turing-autoreducible languages. If an EXP-martingale succeeds on either of these classes, or if betting games have the "finite union property" possessed by Lutz's measure, one obtains the nonrelativizable consequence $mbox{BPP} neq mbox{EXP}$. We also show that if $mbox{EXP} neq mbox{MA}$, then the polynomial-time truth-table-autoreducible languages have Lutz measure zero, whereas if $mbox{EXP} = mbox{BPP}$, they have measure one.},
journal = {SIAM J. Comput.},
month = apr,
pages = {576–601},
numpages = {26},
keywords = {theory of computation, autoreducibility, computational complexity, betting games, probabilistic computation, polynomial reductions, complexity classes, pseudorandom generators, resource-bounded measure, sampling}
}

@article{10.1137/S009753979833920X,
author = {Cheriyan, Joseph and Thurimella, Ramakrishna},
title = {Approximating Minimum-Size <i>k</i>-Connected Spanning Subgraphs via Matching},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979833920X},
doi = {10.1137/S009753979833920X},
abstract = {An efficient heuristic is presented for the problem of finding a minimum-size k-connected spanning subgraph of an (undirected or directed) simple graph G=( V, E). There are four versions of the problem, and the approximation guarantees are as follows: minimum-size k - node connected spanning subgraph of an undirected graph 1 + [1/ k ], minimum-size k - node connected spanning subgraph of a directed graph 1 + [1/ k ], minimum-size k - edge connected spanning subgraph of an undirected graph 1+[2/( k +1)], minimum-size k - edge connected spanning subgraph of a directed graph 1 + [4/sqrt{k}]. The heuristic is based on a subroutine for the degree-constrained subgraph ( b-matching) problem. It is simple and deterministic and runs in time O( k| E| 2). The following result on simple undirected graphs is used in the analysis: The number of edges required for augmenting a graph of minimum degree k to be k-edge connected is at most k,|V|/(k+1). For undirected graphs and k=2, a (deterministic) parallel NC version of the heuristic finds a 2-node connected (or 2-edge connected) spanning subgraph whose size is within a factor of ($1.5+epsilon$) of minimum, where $epsilon&gt;0$ is a constant.},
journal = {SIAM J. Comput.},
month = apr,
pages = {528–560},
numpages = {33},
keywords = {matchings, approximation algorithms, node connectivity, directed graphs, graphs, NP-complete problems, degree constrained subgraphs, network design, graph connectivity, edge connectivity}
}

@article{10.1137/S0097539797332275,
author = {Kao, Ming-Yang and Lam, Tak-Wah and Sung, Wing-Kin and Ting, Hing-Fung},
title = {Cavity Matchings, Label Compressions, and Unrooted Evolutionary Trees},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797332275},
doi = {10.1137/S0097539797332275},
abstract = {We present an algorithm for computing a maximum agreement subtree of two unrooted evolutionary trees.  It takes O(n1.5 log n) time for trees with unbounded degrees, matching the best known time complexity for the rooted case.  Our algorithm allows the input trees to be mixed trees, i.e., trees that may contain directed and undirected edges at the same time.  Our algorithm adopts a recursive strategy exploiting a technique called label compression.  The backbone of this technique is an algorithm that computes the maximum weight matchings over many subgraphs of a bipartite graph as fast as it takes to compute a single matching.},
journal = {SIAM J. Comput.},
month = apr,
pages = {602–624},
numpages = {23},
keywords = {computational biology, label compressions, unrooted trees, all-cavity maximum weight matchings, evolutionary trees, mixed trees}
}

@article{10.1137/S009753979732760X,
author = {Varghese, George},
title = {Self-Stabilization by Counter Flushing},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732760X},
doi = {10.1137/S009753979732760X},
abstract = {A useful way to design simple and robust protocols is to make them self-stabilizing. A protocol is said to be self-stabilizing if it begins to exhibit correct behavior even after starting in an arbitrary state. We describe a simple technique for self-stabilization called  counter flushing. We show how counter flushing helps us to understand and improve some existing distributed algorithms for tasks such as mutual exclusion and request-response protocols. We also use counter flushing to create  new self-stabilizing protocols for propagation of information with feedback and resets. The resulting protocols are simple, require few changes from the nonstabilizing equivalents, and have fast stabilization times.},
journal = {SIAM J. Comput.},
month = apr,
pages = {486–510},
numpages = {25},
keywords = {self-stabilization, distributed algorithms}
}

@article{10.1137/S009753979732712X,
author = {Pietracaprina, Andrea and Pucci, Geppino and Sibeyn, Jop F.},
title = {Constructive, Deterministic Implementation of Shared Memory on Meshes},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732712X},
doi = {10.1137/S009753979732712X},
abstract = {This paper describes a scheme to implement a shared address space of size m on an n-node mesh, with m polynomial in n, where each mesh node hosts a processor and a memory module. At the core of the simulation is a hierarchical memory organization scheme (HMOS), which governs the distribution of the shared variables, each replicated into multiple copies, among the memory modules, through a cascade of bipartite graphs. Based on the expansion properties of such graphs, we devise a protocol that accesses any n-tuple of shared variables in worst-case time $O(n^{1/2+eta})$, for any constant $eta &gt; 0$, using $O(1/eta^{1.59})$ copies per variable, or in worst-case time O(n1/2 log n), using O(log1.59 n) copies per variable. In both cases the access time is close to the natural $O(sqrt{n})$ lower bound imposed by the network diameter. A key feature of the scheme is that it can be made fully constructive when m is not too large, thus providing in this case the first efficient, constructive, deterministic scheme in the literature for bounded-degree processor networks. For larger memory sizes, the scheme relies solely on a nonconstructive graph of weak expansion. Finally, the scheme can be efficiently ported to other architectures, as long as they exhibit certain structural properties. In the paper we discuss the porting to multidimensional meshes and to the pruned butterfly, an area-universal network which is a variant of the fat-tree.},
journal = {SIAM J. Comput.},
month = apr,
pages = {625–648},
numpages = {24},
keywords = {PRAM simulation, expander graphs, networks of processors, meshes, parallel computation, shared memory machines}
}

@article{10.1137/S0097539797326241,
author = {Koren, Gilad and Dar, Emanuel and Amir, Amihood},
title = {The Power of Migration in Multiprocessor Scheduling of Real-Time Systems},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797326241},
doi = {10.1137/S0097539797326241},
abstract = {In this paper we study the performance of off-line multiprocessor real-time schedules that allow task migration compared to those that forbid migration. We consider an  off-line  scheduling problem in which a given collection of tasks, each with a release time, computation time, and  deadline , are to be run on a multiprocessor system. A preemptive schedule allows the execution of a task to be temporarily suspended and resumed at a later time. A  migrative  schedule allows the task to resume on any processor whereas a  nonmigrative  schedule allows the task to resume only on the processor in which it was initially started. A schedule  value  is the summation of all the values of all the tasks that were completed by their deadlines. In this paper we assume that a task's value is proportional to its computation time. We present lower and upper bound results. For a system with  n  processors, we construct a nonmigrative schedule that is guaranteed to achieve at least $1-( 1-frac 1{2n}) ^n$ of the  optimal  migrative schedule value. In addition, we show task sets for which even an optimal nonmigrative schedule achieves at most  n /(2  n -1) of the optimal migrative value. Asymptotically (as $nrightarrow infty $) our upper bound approaches 1/2 and the lower bound approaches $1 - {1over sqrt{e}} sim 0.3935$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {511–527},
numpages = {17},
keywords = {off-line scheduling, multiprocessor migration, real-time, deadline}
}

@article{10.1137/S0097539797324643,
author = {Song, Nah-Oak and Teneketzis, Demosthenis},
title = {On a Conjecture by Coffman, Flatto, and Wright on Stochastic Machine Minimization},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797324643},
doi = {10.1137/S0097539797324643},
abstract = {We investigate a conjecture stated by Coffman, Flatto, and Wright within the context of a stochastic machine minimization problem with a hard deadline. We prove that the conjecture is true.},
journal = {SIAM J. Comput.},
month = apr,
pages = {681–687},
numpages = {7},
keywords = {time thresholds, stochastic allocation, machine minimization, hard deadlines, Bellman equation}
}

@article{10.1137/S0097539797317299,
author = {Jayanti, Prasad and Tan, King and Toueg, Sam},
title = {Time and Space Lower Bounds for Nonblocking Implementations},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797317299},
doi = {10.1137/S0097539797317299},
abstract = {We show the following time and space complexity lower bounds. Let $cal{I}$ be any randomized nonblocking  n -process implementation of any object in set  A  from any combination of objects in set  B , where  A  = {increment, fetch&amp;add, modulo  k  counter (for any $k ge 2n$), LL/SC bit,  k -valued compare&amp;swap (for any $k ge n$), single-writer snapshot}, and  B  = {resettable consensus} $cup$ {historyless objects such as registers and swap registers}. The space complexity of $cal{I}$ is at least  n -1. Moreover, if $cal{I}$ is deterministic, both its time and space complexity are at least  n -1. These lower bounds hold even if objects used in the implementation are of unbounded size. This improves on some of the $Omega(sqrt{n})$ space complexity lower bounds of Fich, Herlihy, and Shavit [  i  Proceedings of the 12  th Annual ACM Symposium on Principles of Distributed Computing , Ithaca, NY, 1993, pp. 241--249;  J. Assoc. Comput. Mach. , 45 (1998), pp. 843--862]. It also shows the near optimality of some known wait-free implementations in terms of space complexity.},
journal = {SIAM J. Comput.},
month = apr,
pages = {438–456},
numpages = {19},
keywords = {nonblocking, time complexity, lower bounds, asynchronous shared memory algorithms, synchronization, space complexity, wait-free, randomized shared object implementations}
}

@article{10.1137/S0097539795291562,
author = {Dolev, Danny and Dwork, Cynthia and Naor, Moni},
title = {Nonmalleable Cryptography},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795291562},
doi = {10.1137/S0097539795291562},
abstract = {The notion of nonmalleable cryptography, an extension of semantically secure cryptography, is defined. Informally, in the context of encryption the additional requirement is that given the ciphertext it is impossible to generate a different ciphertext so that the respective plaintexts are related. The same concept makes sense in the contexts of string commitment and zero-knowledge proofs of possession of knowledge. Nonmalleable schemes for each of these three problems are presented. The schemes do not assume a trusted center; a user need not know anything about the number or identity of other system users. Our cryptosystem is the first proven to be secure against a strong type of chosen ciphertext attack proposed by Rackoff and Simon, in which the attacker knows the ciphertext she wishes to break and can query the decryption oracle on any ciphertext other than the target.},
journal = {SIAM J. Comput.},
month = apr,
pages = {391–437},
numpages = {47},
keywords = {chosen ciphertext security, randomized algorithms, encryption, zero-knowledge, commitment schemes, auction protocols, nonmalleability, authentication, cryptanalysis, cryptography}
}

@article{10.1137/S0097539798331975,
author = {Reif, John H. and Wang, Hongyan},
title = {Nonuniform Discretization for Kinodynamic Motion Planning and Its Applications},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798331975},
doi = {10.1137/S0097539798331975},
abstract = {The first main result of this paper is  a novel nonuniform discretization approximation method for the kinodynamic motion-planning problem. The kinodynamic motion-planning problem is to compute a collision-free, time-optimal trajectory for a robot whose accelerations and velocities are bounded. Previous approximation methods are all based on a uniform discretization in the time space. On the contrary, our method employs a nonuniform discretization in the configuration space (thus also a nonuniform one in the time space). Compared to the previously best algorithm of Donald and Xavier, the running time of our algorithm reduces in terms of $1/varepsilon$, roughly from $O((1/varepsilon)^{6d-1})$ to $O((1/varepsilon)^{4d-2})$, in computing a trajectory in a $d$-dimensional configuration space, such that the time length of the trajectory is within a factor of $(1+varepsilon)$ of the optimal. More importantly, our algorithm is able to take advantage of the obstacle distribution and is expected to perform much better than the analytical result. This is because our nonuniform discretization has the property that it is coarser in regions that are farther from all obstacles. So for situations where the obstacles are sparse, or the obstacles are unevenly distributed, the size of the discretization is significantly smaller.Our second main result is the  first known polynomial-time approximation algorithm for the curvature-constrained shortest-path problem in three and higher dimensions. We achieved this by showing that the approximation techniques for the kinodynamic motion-planning problem are applicable to this problem.},
journal = {SIAM J. Comput.},
month = apr,
pages = {161–190},
numpages = {30},
keywords = {kinodynamic motion planning, robotic motion planning, nonuniform discretization, nonholonomic motion planning}
}

@article{10.1137/S0097539797330057,
author = {Angluin, Dana and Westbrook, Jeffery and Zhu, Wenhong},
title = {Robot Navigation with Distance Queries},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797330057},
doi = {10.1137/S0097539797330057},
abstract = {We consider the problem of online robot navigation in an unfamiliar two-dimensional environment, using comparatively limited sensing information. In particular, the robot has local sensors to detect the proximity of obstacles and permit boundary-following, and it is able to determine its current distance and relative bearing to its final destination (via distance queries). By contrast, most previous algorithms for online navigation have assumed that the robot knows its exact current position.  Because determining exact location is prone to error that accumulates over time, the usefulness of such algorithms may be limited. In contrast, distance queries give less information, but the accuracy of each query is independent of the number of queries, which means distance queries can be more robust.  We formally define our model and give new, efficient navigation algorithms and lower bounds for this setting.},
journal = {SIAM J. Comput.},
month = apr,
pages = {110–144},
numpages = {35},
keywords = {range query, robot navigation, distance query, analysis of algorithms, robot exploration}
}

@article{10.1137/S0097539797329142,
author = {Kleinberg, Jon and Rabani, Yuval and Tardos, \'{E}va},
title = {Allocating Bandwidth for Bursty Connections},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797329142},
doi = {10.1137/S0097539797329142},
abstract = {In this paper, we undertake the first study of statistical multiplexing from the perspective of approximation algorithms. The basic issue underlying statistical multiplexing is the following: in high-speed networks, individual connections (i.e., communication sessions) are very  bursty , with transmission rates that vary greatly over time. As such, the problem of packing multiple connections together on a link becomes more subtle than in the case when each connection is assumed to have a fixed demand. We consider one of the most commonly studied models in this domain: that of two communicating nodes connected by a set of parallel edges, where the rate of each connection between them is a random variable. We consider three related problems: (1) stochastic load balancing, (2) stochastic bin-packing, and (3) stochastic knapsack. In the first problem the number of links is given and we want to minimize the expected value of the maximum load. In the other two problems the link capacity and an allowed  overflow probability   p  are given, and the objective is to assign connections to links, so that the probability that the load of a link exceeds the link capacity is at most $p$. In bin-packing we need to assign each connection to a link using as few links as possible. In the knapsack problem each connection has a value, and we have only one link. The problem is to accept as many connections as possible.For the stochastic load balancing problem we give an  O (1)-approximation algorithm for arbitrary random variables. For the other two problems we have algorithms restricted to on-off sources (the most common special case studied in the statistical multiplexing literature), with a somewhat weaker range of performance guarantees.A standard approach that has emerged for dealing with probabilistic resource requirements is the notion of  effective bandwidth ---this is a means of associating a fixed demand with a bursty connection that "represents" its distribution as closely as possible. Our approximation algorithms make use of the standard definition of effective bandwidth and also a new one that we introduce; the performance guarantees are based on new results showing that a combination of these measures can be used to provide bounds on the optimal solution.},
journal = {SIAM J. Comput.},
month = apr,
pages = {191–217},
numpages = {27},
keywords = {approximation algorithms, combinatorial optimization, statistical multiplexing, effective bandwidth}
}

@article{10.1137/S009753979732699X,
author = {Cole, Richard},
title = {On the Dynamic Finger Conjecture for Splay Trees. Part II: The Proof},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732699X},
doi = {10.1137/S009753979732699X},
abstract = {The following result is shown: On an n-node splay tree, the amortized cost of an access at distance d from the preceding access is O(log (d+1)). In addition, there is an O(n) initialization cost. The accesses include searches, insertions, and deletions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {44–85},
numpages = {42},
keywords = {binary search tree, finger search tree, amortized analysis, splay tree}
}

@article{10.1137/S0097539797326988,
author = {Cole, Richard and Mishra, Bud and Schmidt, Jeanette and Siegel, Alan},
title = {On the Dynamic Finger Conjecture for Splay Trees. Part I: Splay Sorting Log <i>n</i>-Block Sequences},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797326988},
doi = {10.1137/S0097539797326988},
abstract = {A special case of the dynamic finger conjecture is proved; this special case introduces a number of useful techniques.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1–43},
numpages = {43},
keywords = {splay tree, amortized analysis, finger search tree, binary search tree}
}

@article{10.1137/S0097539797326289,
author = {Boissonnat, Jean-Daniel and Devillers, Olivier and Lazard, Sylvain},
title = {Motion Planning of Legged Robots},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797326289},
doi = {10.1137/S0097539797326289},
abstract = {We study the problem of computing the free space ${cal F}$ of a simple legged robot called the spider robot. The body of this robot is a single point and the legs are attached to the body.  The robot is subject to two constraints: each leg has a maximal extension R (accessibility constraint) and the body of the robot must lie above the convex hull of its feet (stability constraint). Moreover, the robot can only put its feet on some regions, called the foothold regions.  The free space ${mathcal{F}}$ is the set of positions of the body of the robot such that there exists a set of accessible footholds for which the robot is stable.  We present an efficient algorithm that computes ${cal F}$ in $O(n^2log n)$ time using $O(n^2alpha(n))$ space for $n$ discrete point footholds where $alpha(n)$ is an extremely slowly growing function ($alpha(n)leq 3$ for any practical value of $n$).  We also present an algorithm for computing ${cal F}$ when the foothold regions are pairwise disjoint polygons with $n$ edges in total.  This algorithm computes ${cal F}$ in $O(n^2alpha_8(n)log n)$ time using $O(n^2alpha_8(n))$ space. ($alpha_8(n)$ is also an extremely slowly growing function.)  These results are close to optimal since $Omega(n^2)$ is a lower bound for the size of ${cal F}$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {218–246},
numpages = {29},
keywords = {motion planning, legged robots, computational geometry}
}

@article{10.1137/S009753979732565X,
author = {Greenhalgh, David and Marshall, Stephen},
title = {Convergence Criteria for Genetic Algorithms},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732565X},
doi = {10.1137/S009753979732565X},
abstract = {In this paper we discuss convergence properties for genetic algorithms. By looking at the effect of mutation on convergence, we show that by running the genetic algorithm for a sufficiently long time we can guarantee convergence to a global optimum with any specified level of confidence. We obtain an upper bound for the number of iterations necessary to ensure this, which improves previous results. Our upper bound decreases as the population size increases. We produce examples to show that in some cases this upper bound is asymptotically optimal for large population sizes. The final section discusses implications of these results for optimal coding of genetic algorithms.},
journal = {SIAM J. Comput.},
month = apr,
pages = {269–282},
numpages = {14},
keywords = {probability, genetic algorithms, upper bounds, optimal coding, convergence criteria}
}

@article{10.1137/S0097539797325375,
author = {Feige, Uriel and Kilian, Joe},
title = {Two-Prover Protocols---Low Error at Affordable Rates},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797325375},
doi = {10.1137/S0097539797325375},
abstract = {We introduce the  miss-match  form for two-prover one-round proof systems. Any two-prover one-round proof system can be easily modified so as to be in miss-match form. Proof systems in miss-match form have the "projection" property that is important for deriving hardness of approximation results for NP-hard combinatorial optimization problems. Our main result is an upper bound on the number of parallel repetitions that suffice in order to reduce the error of miss-match proof systems from  p  to $epsilon$. This upper bound depends only on  p  and on $epsilon$ (polynomial in 1/(1-  p ) and in $1/epsilon$). Based on previous work, it follows that for any $epsilon &gt;0,$ NP has two-prover one-round proof systems with logarithmic-sized questions, constant-sized answers, and error at most $epsilon$.As part of our proof we prove upper bounds on the influence of random variables on multivariate functions, which may be of independent interest.},
journal = {SIAM J. Comput.},
month = apr,
pages = {324–346},
numpages = {23},
keywords = {interactive proof systems, complexity theory}
}

@article{10.1137/S0097539797319109,
author = {Kutten, Shay and Peleg, David},
title = {Tight Fault Locality},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797319109},
doi = {10.1137/S0097539797319109},
abstract = {This paper lays a theoretical foundation for scaling fault tolerant tasks to large and diversified networks such as the Internet. In such networks, there are always parts of the network that fail. On the other hand, various subtasks interest only parts of the network, and it is desirable that those parts, if nonfaulty, do not suffer from faults in other parts. Our approach is to refine the previously suggested notion of fault local algorithms (that was best suited for global tasks) for which the complexity of recovering was proportional to the number of faults. We refine this notion by introducing the concept of  tight fault locality to deal with problems whose complexity (in the absence of faults) is sublinear in the size of the network. For a problem whose time complexity on an n-node network is T(n) (where possibly T(n)= o(n)), a tightly fault local algorithm recovers a legal global state in O(T(x)) time when the (unknown) number of faults is x.This concept is illustrated by presenting a general transformation for maximal independent set (MIS) algorithms to make them tightly fault local. In particular, our transformation yields an O(log x) randomized mending algorithm and an $exp(O(sqrt{log x}))$ deterministic mending algorithm for MIS. The methods used in the transformation may be of interest by themselves.},
journal = {SIAM J. Comput.},
month = apr,
pages = {247–268},
numpages = {22},
keywords = {recovery, stabilization, distributed algorithms, fault tolerance}
}

@article{10.1137/S0097539797315598,
author = {Deng, Xiaotie and Gu, Nian and Brecht, Tim and Lu, Kaicheng},
title = {Preemptive Scheduling of Parallel Jobs  on Multiprocessors},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797315598},
doi = {10.1137/S0097539797315598},
abstract = {We study the problem of processor scheduling for n parallel jobs applying the method of competitive analysis. We prove that for jobs with a single phase of parallelism, a preemptive scheduling algorithm without information about job execution time can achieve a mean completion time within $2-{2over n+1}$ times the optimum. In other words, we prove a competitive ratio of $2-{2over n+1}$. The result is extended to jobs with multiple phases of parallelism (which can be used to model jobs with sublinear speedup) and to interactive jobs (with phases during which the job has no CPU requirements) to derive solutions guaranteed to be within $4-{4over n+1}$ times the optimum. In comparison with previous work, our assumption that job execution times are unknown prior to their completion is more realistic, our multiphased job model is more general, and our approximation ratio (for jobs with a single phase of parallelism) is tighter and cannot be improved. While this work presents theoretical results obtained using competitive analysis, we believe that the results provide insight into the performance of practical multiprocessor scheduling algorithms that operate in the absence of complete information.},
journal = {SIAM J. Comput.},
month = apr,
pages = {145–160},
numpages = {16},
keywords = {competitive analysis, processor scheduling, unknown information, parallel programs}
}

@article{10.1137/S0097539796313507,
author = {Wang, Lusheng and Jiang, Tao and Gusfield, Dan},
title = {A More Efficient Approximation Scheme for Tree Alignment},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796313507},
doi = {10.1137/S0097539796313507},
abstract = {We present a new polynomial time approximation scheme (PTAS) for tree alignment, which is an important variant of multiple sequence alignment. As in the existing PTASs in the literature, the basic approach of our algorithm is to partition the given tree into overlapping components of a constant size and then apply local optimization on each such component. But the new algorithm uses a clever partitioning strategy and achieves a better efficiency for the same performance ratio. For example, to achieve approximation ratios 1.6 and 1.5, the best existing PTAS has to spend time O(kdn5) and O(kdn9), respectively, where n is the length of each leaf sequence and d,k are the depth and number of leaves of the tree, while the new PTAS only has to spend time O(kdn4) and O(kdn5). Moreover, the performance of the PTAS is more sensitive to the size of the components, which basically determines the running time, and we obtain an improved approximation ratio for each size. Some experiments of the algorithm on simulated and real data are also given.},
journal = {SIAM J. Comput.},
month = apr,
pages = {283–299},
numpages = {17},
keywords = {evolutionary tree, computational biology, phylogeny, approximation algorithm, multiple sequence alignment}
}

@article{10.1137/S009753979630814X,
author = {Grigni, Michelangelo and Mirelli, Vincent and Papadimitriou, Christos H.},
title = {On the Difficulty of Designing Good Classifiers},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979630814X},
doi = {10.1137/S009753979630814X},
abstract = {We consider the problem of designing a near-optimal linear decision tree to classify two given point sets B and W in $Re^n$. A linear decision tree defines a polyhedral subdivision of space; it is a classifier if no leaf region contains points from both sets. We show hardness results for computing such a classifier with approximately optimal depth or size in polynomial time. In particular, we show that unless NP = ZPP, the depth of a classifier cannot be approximated within any constant factor, and that the total number of nodes cannot be approximated within any fixed polynomial. Our proof uses a simple connection between this problem and graph coloring and uses the result of Feige and Kilian on the inapproximability of the chromatic number. We also study the problem of designing a classifier with a single inequality that involves as few variables as possible and point out certain aspects of the difficulty of this problem.},
journal = {SIAM J. Comput.},
month = apr,
pages = {318–323},
numpages = {6},
keywords = {parameterized complexity, linear decision tree, hardness of approximation}
}

@article{10.1137/S0097539796299540,
author = {Koutsoupias, Elias and Papadimitriou, Christos H.},
title = {Beyond Competitive Analysis},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796299540},
doi = {10.1137/S0097539796299540},
abstract = {The competitive analysis of online algorithms has been criticized as being too crude and unrealistic. We propose refinements of competitive analysis in two directions: The first restricts the power of the adversary by allowing only certain input distributions, while the other allows for comparisons between information regimes for online decision-making.  We illustrate the first with an application to the paging problem; as a byproduct we characterize completely the work functions of this important special case of the k-server problem.  We use the second refinement to explore the power of lookahead in server and task systems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {300–317},
numpages = {18},
keywords = {competitive analysis, metrical task systems, online algorithms, paging problem}
}

@article{10.1137/S0097539795288246,
author = {Thorup, Mikkel},
title = {On RAM Priority Queues},
year = {2000},
issue_date = {2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {30},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795288246},
doi = {10.1137/S0097539795288246},
abstract = {Priority queues are some of the most fundamental data structures. For example, they are used directly for task scheduling in operating systems. Moreover, they are essential to greedy algorithms. We study the complexity of integer priority queue operations on a RAM with arbitrary word size, modeling the possibilities in standard imperative programming languages such as C. We present exponential improvements over previous bounds, and we show tight relations to sorting. Our first result is a RAM priority queue supporting find-min in constant time and insert and delete-min in time  O (log log  n ), where  n  is the current number of keys in the queue. This is an exponential improvement over the $O(sqrt{log n})$ bound of Fredman and Willard [  Proceedings of the 22  nd ACM Symposium on the Theory of Computing , Baltimore, MD, pp. 1--7]. Plugging this priority queue into Dijkstra's algorithm gives an  O (  m log log  m ) algorithm for the single source shortest path problem on a graph with  m  edges, as compared with the previous $O(msqrt{log m})$ bound based on Fredman and Willard's priority queue. The above bounds assume $O(n 2^{{varepsilon} w})$ space, where  w  is the word length and ${varepsilon}&gt;0$. They can, however, be achieved in linear space using randomized hashing.Our second result is a general equivalence between sorting and priority queues. A priority queue is  monotone  if the minimum is nondecreasing over time, as in many greedy algorithms. We show that on a RAM, the amortized operation cost of a monotone priority queue is equivalent to the per-key cost of sorting. For example, the equivalence implies that the single source shortest paths problem on a graph with  m  edges is no harder than that of sorting  m  keys. With the current RAM sorting, this gives an  O (  m  log log  m ) time bound, as above, but the relation holds regardless of the future developments in RAM sorting.From the equivalence result, for any fixed ${varepsilon}&gt;0$, we derive a randomized monotone $O(sqrt{log n}^{1+{varepsilon}})$ priority queue with expected constant time decrease-key. Plugging this into Dijkstra's algorithm gives an $O(nsqrt{log n}^{1+{varepsilon}}+m)$ algorithm for the single source shortest path problem on a graph with  n  nodes and  m  edges, complementing the above  O (  m log log  m ) algorithm if $mgg n$. This improves the  O (  n log  n /log log  n  +  m ) bound by Fredman and Willard [  Proceedings of the 31  st IEEE Symposium on the Foundations of Computer Science , St. Louis, MO, 1990, pp. 719--725], based on their  O (log  n /log log  n ) priority queue with constant decrease-key.},
journal = {SIAM J. Comput.},
month = apr,
pages = {86–109},
numpages = {24},
keywords = {sorting, greedy algorithms, RAM model, shortest paths, priority queues}
}

@article{10.1137/S0097539799350232,
author = {Har-Peled, Sariel},
title = {Constructing Planar Cuttings in Theory and Practice},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799350232},
doi = {10.1137/S0097539799350232},
abstract = {We present several variants of a new randomized incremental algorithm for computing a cutting in an arrangement of n lines in the plane. The algorithms produce cuttings whose expected size is O(r2), and the expected running time of the algorithms is O(nr). Both bounds are asymptotically optimal for nondegenerate arrangements. The algorithms are also simple to implement, and we present empirical results showing that they perform well in practice. We also present another efficient algorithm (with slightly worse time bound) that generates small cuttings whose size is guaranteed to be close to the best known upper bound of J. Matou{s}ek [Discrete Comput. Geom., 20 (1998), pp. 427--448].},
journal = {SIAM J. Comput.},
month = apr,
pages = {2016–2039},
numpages = {24},
keywords = {computational geometry, cuttings, range-searching}
}

@article{10.1137/S0097539799294398,
author = {Lennerstad, H\r{A}kan and Lundberg, Lars},
title = {Optimal Combinatorial Functions Comparing Multiprocess Allocation Performance in Multiprocessor Systems},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799294398},
doi = {10.1137/S0097539799294398},
abstract = {For the execution of an arbitrary parallel program P, consisting of a set of processes with any executable interprocess dependency structure, we consider two alternative multiprocessors. The first multiprocessor has q processors and allocates parallel programs dynamically; i.e., processes may be reallocated from one processor to another. The second employs cluster allocation with k clusters and u processors in each cluster: here processes may be reallocated within a cluster only. Let Td(P,q) and Tc(P,k,u) be execution times for the parallel program P with optimal allocations. We derive a formula for the program independent performance function $$ G(k,u,q)=sup_{mbox{{footnotesize all parallel programs $P$}}} :frac{T_c(P,k,u)}{T_d(P,q)}. $$ Hence, with optimal allocations, the execution of P can never take more than a factor G(k,u,q) longer time with the second multiprocessor than with the first, and there exist programs showing that the bound is sharp. The supremum is taken over all parallel programs consisting of any number of processes. Overhead for synchronization and reallocation is neglected only. We further present a tight bound which exploits a priori knowledge of the class of parallel programs intended for the multiprocessors, thus resulting in a sharper bound. The function g(n,k,u,q) is the above maximum taken over all parallel programs consisting of n processes. The functions G and g can be used in various ways to obtain tight performance bounds, aiding in multiprocessor architecture decisions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1816–1838},
numpages = {23},
keywords = {cluster allocation, optimal performance, 1-matrices, optimal partition, 0, extremal combinatorics, multiprocessor, static allocation, dynamic allocation, combinatorial formula, scheduling}
}

@article{10.1137/S0097539798353230,
author = {Bonet, Maria Luisa and Pitassi, Toniann and Raz, Ran},
title = {On Interpolation and Automatization for Frege Systems},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798353230},
doi = {10.1137/S0097539798353230},
abstract = {The interpolation method has been one of the main tools for proving lower bounds for propositional proof systems. Loosely speaking, if one can prove that a particular proof system has the  feasible interpolation property, then a generic reduction can (usually) be applied to prove lower bounds for the proof system, sometimes assuming a (usually modest) complexity-theoretic assumption. In this paper, we show that this method  cannot be used to obtain lower bounds for Frege systems, or even for TC0-Frege systems. More specifically, we show that unless factoring (of Blum integers) is feasible, neither Frege nor TC0-Frege has the feasible interpolation property. In order to carry out our argument, we show how to carry out proofs of many elementary axioms/theorems of arithmetic in polynomial-sized TC0-Frege.As a corollary, we obtain that TC0-Frege, as well as any proof system that polynomially simulates it, is not automatizable (under the assumption that factoring of Blum integers is hard). We also show under the same hardness assumption that the k-provability problem for Frege systems is hard.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1939–1967},
numpages = {29},
keywords = {Diffie--Hellman, propositional proof systems, Frege proof systems, threshold circuits}
}

@article{10.1137/S0097539798348365,
author = {Kapoor, Sanjiv},
title = {Dynamic Maintenance of Maxima of 2-d Point Sets},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798348365},
doi = {10.1137/S0097539798348365},
abstract = {This paper describes an efficient scheme for the dynamic maintenance of the set of maxima of a 2-d set of points. Using the fact that the maxima can be stored in a staircase structure, we use a technique in which we maintain approximations to the staircase structure. We first describe how to maintain the maxima in O(log n) time per insertion and deletion when there are n insertions and deletions. O(log n) is charged per change for reporting changes to the staircase structure which stores the maxima. O(n) space is used. We also show another scheme which requires a total of O(n log n + r) time when r maximal points are listed. We finally consider extensions to higher dimensions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1858–1877},
numpages = {20},
keywords = {dynamic maintenance, maximal points, balanced trees}
}

@article{10.1137/S0097539798341296,
author = {Aguilera., Marcos Kawazoe and Chen, Wei and Toueg, Sam},
title = {On Quiescent Reliable Communication},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798341296},
doi = {10.1137/S0097539798341296},
abstract = {We study the problem of achieving reliable communication with  quiescent algorithms (i.e., algorithms that eventually stop sending messages) in asynchronous systems with process crashes and lossy links. We first show that it is impossible to solve this problem in asynchronous systems (with no failure detectors). We then show that, among failure detectors that output lists of suspects, the weakest one that can be used to solve this problem is $diamond cal P,$ a failure detector that cannot be implemented. To overcome this difficulty, we introduce an implementable failure detector called  Heartbeat and show that it can be used to achieve quiescent reliable communication. Heartbeat is novel: in contrast to typical failure detectors, it does not output lists of suspects and it is implementable without timeouts. With Heartbeat, many existing algorithms that tolerate only process crashes can be transformed into quiescent algorithms that tolerate both process crashes and message losses. This can be applied to consensus, atomic broadcast, k-set agreement, atomic commitment, etc.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2040–2073},
numpages = {34},
keywords = {link failures, quiescence, crash failures, reliability, reliable communication, failure detection, message passing, fault-tolerance, processor failures, heartbeat, algorithms, asynchronous systems}
}

@article{10.1137/S0097539798337212,
author = {Erickson, Jeff},
title = {Space-Time Tradeoffs for Emptiness Queries},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798337212},
doi = {10.1137/S0097539798337212},
abstract = {We develop the first nontrivial lower bounds on the complexity of online hyperplane and halfspace emptiness queries.  Our lower bounds apply to a general class of geometric range query data structures called partition graphs.  Informally, a partition graph is a directed acyclic graph that describes a recursive decomposition of space.  We show that any partition graph that supports hyperplane emptiness queries implicitly defines a halfspace range query data structure in the Fredman/Yao semigroup arithmetic model, with the same asymptotic space and time bounds.  Thus, results of Br\"{o}nnimann, Chazelle, and Pach imply that any partition graph of size s that supports hyperplane emptiness queries in time t satisfies the inequality $st^d = Omega((n/log n)^{d - (d-1)/(d+1)})$.  Using different techniques, we improve previous lower bounds for Hopcroft's problem---Given a set of points and hyperplanes, does any hyperplane contain a point?---in dimensions four and higher.  Using this offline result, we show that for online hyperplane emptiness queries, $Omega(n^d/{mbox{ polylog }} n)$ space is required to achieve polylogarithmic query time, and $Omega(n^{(d-1)/d}/{mbox{ polylog }} n)$ query time is required if only O(n polylog n) space is available.  These two lower bounds are optimal up to polylogarithmic factors.  For two-dimensional queries, we obtain an optimal continuous tradeoff $st^2=Omega(n^2)$ between these two extremes.  Finally, using a lifting argument, we show that the same lower bounds hold for both offline and online halfspace emptiness queries in ${mathbb{R}}^{d(d+3)/2}$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1968–1996},
numpages = {29},
keywords = {lower bounds, space-time tradeoff, partition graph, range searching}
}

@article{10.1137/S0097539797328847,
author = {Trevisan, Luca and Sorkin, Gregory B. and Sudan, Madhu and Williamson, David P.},
title = {Gadgets, Approximation, and Linear Programming},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797328847},
doi = {10.1137/S0097539797328847},
abstract = {We present a linear programming-based method for finding "gadgets," i.e., combinatorial structures reducing constraints of one optimization problem to constraints of another. A key step in this method is a simple observation which limits the search space to a  finite one. Using this new method we present a number of new, computer-constructed gadgets for several different reductions. This method also answers a question posed by Bellare, Goldreich, and Sudan [SIAM J.  Comput., 27 (1998), pp. 804--915] of how to prove the optimality of gadgets: linear programming duality gives such proofs.The new gadgets, when combined with recent results of H\r{a} stad [ Proceedings of the 29th ACM Symposium on Theory of Computing, 1997, pp. 1--10], improve the known inapproximability results for MAX CUT and MAX DICUT, showing that approximating these problems to within factors of $16/17 + epsilon$ and $12/13+ epsilon,$ respectively, is NP-hard for every $epsilon &gt; 0$. Prior to this work, the best-known inapproximability thresholds for both problems were 71/72 (M. Bellare, O. Goldreich, and M. Sudan [ SIAM J. Comput., 27 (1998), pp. 804--915]). Without using the gadgets from this paper, the best possible hardness that would follow from Bellare, Goldreich, and Sudan and H\r{a}{s}tad is $18/19$. We also use the gadgets to obtain an improved approximation algorithm for MAX3 SAT which guarantees an approximation ratio of .801. This improves upon the previous best bound (implicit from M. X. Goemans and D. P. Williamson [ J. ACM, 42 (1995), pp. 1115--1145]; U. Feige and M. X. Goemans [ Proceedings of the Third Israel Symposium on Theory of Computing and Systems, 1995, pp. 182--189]) of .7704.},
journal = {SIAM J. Comput.},
month = apr,
pages = {2074–2097},
numpages = {24},
keywords = {combinatorial optimization, probabilistic proof systems, approximation algorithms, NP-completeness, intractability, reductions}
}

@article{10.1137/S0097539797328070,
author = {Gathen, Joachim vonzur and Shparlinski, Igor E.},
title = {The CREW PRAM Complexity of Modular Inversion},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797328070},
doi = {10.1137/S0097539797328070},
abstract = {One of the long-standing open questions in the theory of parallel computation is the parallel complexity of the integer gcd and related problems, such as modular inversion. We present a lower bound $Omega (log n)$ for the parallel time on a concurrent-read exclusive-write parallel random access machine (CREW PRAM) computing the inverse modulo certain n-bit integers, including all such primes. For infinitely many moduli, our lower bound matches asymptotically the known upper bound. We obtain a similar lower bound for computing a specified bit in a large power of an integer. Our main tools are certain estimates for exponential sums in finite fields.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1839–1857},
numpages = {19},
keywords = {modular inversion, CREW PRAM complexity, parallel computation, exponential sums}
}

@article{10.1137/S0097539797325235,
author = {Malkhi, Dahlia and Reiter, Michael K. and Wool, Avishai},
title = {The Load and Availability of Byzantine Quorum Systems},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797325235},
doi = {10.1137/S0097539797325235},
abstract = {Replicated services accessed via quorums enable each access to be performed at only a subset (quorum) of the servers and achieve consistency across accesses by requiring any two quorums to intersect. Recently, b-masking quorum systems, whose intersections contain at least 2b+1 servers, have been proposed to construct replicated services tolerant of b-arbitrary (Byzantine) server failures. In this paper we consider a hybrid fault model allowing benign failures in addition to the Byzantine ones. We present four novel constructions for b-masking quorum systems in this model, each of which has optimal load (the probability of access of the busiest server) or optimal availability (probability of some quorum surviving failures). To show optimality we also prove lower bounds on the load and availability of any b-masking quorum system in this model.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1889–1906},
numpages = {18},
keywords = {distributed computing, Byzantine failures, quorum systems, replication, load, availability}
}

@article{10.1137/S0097539797315884,
author = {Adler, Micah and Byers, John W. and Karp, Richard M.},
title = {Parallel Sorting with Limited Bandwidth},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797315884},
doi = {10.1137/S0097539797315884},
abstract = {We study the problem of sorting on a parallel computer with limited communication bandwidth. By using the PRAM(m) model, where p processors communicate through a globally shared memory which can service m requests per unit time, we focus on the trade-off between the amount of local computation and the amount of interprocessor communication required for parallel sorting algorithms.  Our main result is a lower bound of $Omega(frac{n log m}{m log n})$ on the time required to sort n numbers on the exclusive-read and queued-read variants of the PRAM(m).  We also show that Leighton's Columnsort can be used to give an asymptotically matching upper bound in the case where m grows as a fractional power of n.  The bounds are of a surprising form in that they have little dependence on the parameter p.  This implies that attempting to distribute the workload across more processors while holding the problem size and the size of the shared memory fixed will not improve the optimal running time of sorting in this model.  We also show that both the lower and the upper bounds can be adapted to bridging models that address the issue of limited communication bandwidth: the LogP model and the bulk-synchronous parallel (BSP) model. The lower bounds provide further convincing evidence that efficient parallel algorithms for sorting rely strongly on high communication bandwidth.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1997–2015},
numpages = {19},
keywords = {limited bandwidth, LogP, PRAM, BSP, parallel sorting}
}

@article{10.1137/S0097539795290593,
author = {Blum, Avrim and Chalasani, Prasad},
title = {An Online Algorithm for Improving Performance in Navigation},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795290593},
doi = {10.1137/S0097539795290593},
abstract = {We consider the following scenario. A point robot is placed at some start location  s  in a 2-dimensional scene containing oriented rectangular obstacles. The robot must repeatedly travel back and forth between  s  and a second location  t  in the scene. The robot knows the coordinates of  s  and  t  but initially knows nothing about the positions or sizes of the obstacles. It can only determine the obstacles' locations by bumping into them. We would like an intelligent strategy for the robot so that its trips between  s  and  t  both are relatively fast initially and improve as more trips are taken and more information is gathered. In this paper we describe an algorithm for this problem with the following guarantee: in the first $k leq n$ trips, the average distance per trip is at most $O(sqrt{n/k})$ times the length of the shortest  s -  t  path in the scene, where  n  is the Euclidean distance between  s  and  t . We also show a matching lower bound for deterministic strategies. These results generalize known bounds on the one-trip problem. Our algorithm is based on a novel method for making an optimal trade-off between search effort and the goodness of the path found. We improve this algorithm to a "smooth" variant having the property that for  every  $i leq n,$ the robot's  i th trip length is $O(sqrt{n/i})$ times the shortest  s -  t  path length.A key idea of this paper is a method for analyzing obstacle scenes using a tree structure that can be defined based on the positions of the obstacles.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1907–1938},
numpages = {32},
keywords = {competitive analysis, learning, robot path planning, navigation, exploration vs. exploitation, lower bounds, online algorithms, unfamiliar terrain}
}

@article{10.1137/S0097539794276853,
author = {Cai, Jin-yi and Lipton, Richard J. and Zalcstein, Yechezkel},
title = {The Complexity of the <i>A B C</i> Problem},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794276853},
doi = {10.1137/S0097539794276853},
abstract = {We present a deterministic polynomial-time algorithm for the A B C problem, which is the membership problem for 2-generated commutative linear semigroups over an algebraic number field. We also obtain a polynomial-time algorithm for the (easier) membership  problem for 2-generated abelian linear groups. Furthermore, we provide a polynomial-sized encoding for the set of all solutions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {1878–1888},
numpages = {11},
keywords = {membership problem, semigroup, lattice, polynomial-time algorithm, commutative}
}

@article{10.1137/S0097539794263907,
author = {Henzinger, Monika R.},
title = {Improved Data Structures for Fully Dynamic Biconnectivity},
year = {2000},
issue_date = {April 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794263907},
doi = {10.1137/S0097539794263907},
abstract = {We present fully dynamic algorithms for maintaining the biconnected components in general and plane graphs.A fully dynamic algorithm maintains a graph during a sequence of insertions and deletions of edges or isolated vertices.  Let m be the number of edges and n be the number of vertices in a graph.  The time per operation of the best deterministic algorithms is $O(sqrt n)$ in general graphs and O(log n) in plane graphs for fully dynamic connectivity and O(min m2/3,n) in general graphs and $O(sqrt n)$ in plane graphs for fully dynamic biconnectivity. We improve the later running times to $O(sqrt {mlog n})$ in general graphs and O(log 2 n) in plane graphs. Our algorithm for general graphs can also find the biconnected components of all vertices in time O(n).},
journal = {SIAM J. Comput.},
month = apr,
pages = {1761–1815},
numpages = {55},
keywords = {biconnectivity, data structures, dynamic graph algorithms}
}

@article{10.5555/352746.352777,
author = {Khanna, Sanjeev and Liberatore, Vincenzo},
title = {On Broadcast Disk Paging},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
abstract = {Broadcast disks are an emerging paradigm for massive data dissemination. In a broadcast disk, data is divided into n equal-sized pages, and pages are broadcast in a round-robin fashion by a server. Broadcast disks are effective because many clients can simultaneously retrieve any transmitted data. Paging is used by the clients to improve performance, much as in virtual memory systems. However, paging on broadcast disks differs from virtual memory paging in at least two fundamental aspects: A page fault in the broadcast disk model has a variable cost that depends on the requested page as well as the current state of the broadcast. Prefetching is both natural and a provably essential mechanism for achieving significantly better competitive ratios in broadcast disk paging. In this paper, we design a deterministic algorithm that uses prefetching to achieve an O(n log k) competitive ratio for the broadcast disk paging problem, where k denotes the size of the client's cache. We also show a matching lower bound of $Omega(nlog k)$ that applies even when the adversary is not allowed to use prefetching. In contrast, we show that when prefetching is not allowed, no deterministic online algorithm can achieve a competitive ratio better than $Omega(nk)$. Moreover, we show a lower bound of $Omega(n log k)$ on the competitive ratio achievable by any nonprefetching randomized algorithm against an oblivious adversary. These lower bounds are trivially matched from above by known results about deterministic and randomized marking algorithms for paging. An interpretation of our results is that in the broadcast disk paging, prefetching is a perfect substitute for randomization.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1683–1702},
numpages = {20},
keywords = {distributed systems, design of algorithms, client-server architecture, broadcast disks, paging, competitive analysis, online algorithms}
}

@article{10.5555/352746.352776,
author = {Benedikt, Michael and Libkin, Leonid},
title = {Safe Constraint Queries},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
abstract = {We extend some of the classical characterization theorems of relational database theory---particularly those related to query safety---to the context where database elements come with fixed interpreted structure and where formulae over elements of that structure can be used in queries. We show that the addition of common interpreted functions, such as real addition and multiplication, to the relational calculus preserves important characterization theorems of the relational calculus and also preserves certain combinatorial properties of queries. Our main result of the first kind is that there is a syntactic characterization of the collection of safe queries over the relational calculus supplemented by a wide class of interpreted functions---a class that includes addition, multiplication, and exponentiation---and that this characterization gives us an interpreted analog of the concept of range-restricted query from the uninterpreted setting. Furthermore, our range-restricted queries are particularly intuitive for the relational calculus with real arithmetic and give a natural syntax for safe queries in the presence of polynomial functions. We use these characterizations to show that safety is decidable for Boolean combinations of conjunctive queries for a large class of interpreted structures. We show a dichotomy theorem that sets a polynomial bound on the growth of the output of a query that might refer to addition, multiplication, and exponentiation.We apply the above results for finite databases to get results on constraint databases representing potentially infinite objects. We start by getting syntactic characterizations of the queries on constraint databases that preserve geometric conditions in the constraint data model. We consider classes of convex polytopes, polyhedra, and compact semilinear sets, the latter corresponding to many spatial applications. We show how to give an effective syntax to safe queries and prove that for conjunctive queries the preservation properties are decidable.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1652–1682},
numpages = {31},
keywords = {query safety, constraints, first-order logic, databases}
}

@article{10.5555/352746.352771,
author = {Sellen, J\"{u}rgen and Choi, Joonsoo and Yap, Chee-Keng},
title = {Precision-Sensitive Euclidean Shortest Path  in 3-Space},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
abstract = {This paper introduces the concept of  precision-sensitive algorithms , analogous to the well-known output-sensitive algorithms. We exploit this idea in studying the complexity of the 3-dimensional  Euclidean shortest path  problem. Specifically, we analyze an incremental approximation approach and show that this approach yields an asymptotic improvement of running time. By using an optimization technique to improve paths on fixed edge sequences, we modify this algorithm to guarantee a relative error of  O (2 -r) in a time polynomial in  r  and $1/delta$, where $delta$ denotes the relative difference in path length between the shortest and the second shortest path. Our result is the best possible in some sense: if we have a  strongly precision-sensitive  algorithm, then we can show that unambiguous SAT (USAT) is in polynomial time, which is widely conjectured to be unlikely.Finally, we discuss the practicability of this approach. Experimental results are provided.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1577–1595},
numpages = {19},
keywords = {exact geometric algorithms, shortest path, precision-sensitivity, bit complexity}
}

@article{10.5555/352746.352770,
author = {Kao, Ming-Yang and Wang, Jie},
title = {Linear-Time Approximation Algorithms for Computing Numerical Summation with Provably Small Errors},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
abstract = {Given a multiset X={x1,. . .,xn} of real numbers, the floating-point set summation problem asks for Sn=x1 + . . . + xn. Let $E^*_n$ denote the minimum worst-case error over all possible orderings of evaluating Sn. We prove that if X has both positive and negative numbers, it is NP-hard to compute Sn with the worst-case error equal to $E^*_n$. We then give the first known polynomial-time approximation algorithm that has a provably small error for arbitrary X. Our algorithm incurs a worst-case error at most $2(lceillog(n-1)rceil+1)E^*_n$. (All logarithms log in this paper are base 2.) After X is sorted, it runs in O(n) time. For the case where X is either all positive or all negative, we give another approximation algorithm with a worst-case error at most $lceilloglog nrceil E^*_n$. Even for unsorted X, this algorithm runs in O(n)  time. Previously, the best linear-time approximation algorithm had a worst-case error at most $lceillog nrceil E^*_n$, while $E^*_n$ was known to be attainable in O(n log n) time using Huffman coding.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1568–1576},
numpages = {9},
keywords = {approximation algorithms, combinatorial optimization, error analysis, NP-hardness, floating-point summation, addition trees}
}

@article{10.5555/352746.352767,
author = {Vincent., Millist W. and Levene, Mark},
title = {Restructuring Partitioned Normal Form Relations without Information Loss},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
abstract = {Nested relations in partitioned normal form (PNF) are an important subclass of nested relations that are useful in many applications. In this paper we address the question of determining when every PNF relation stored under one nested relation scheme  can be transformed into another PNF relation stored under a different nested relation scheme without loss of information, referred to as the two schemes being data equivalent. This issue is important in many database application areas such as view processing, schema integration, and schema evolution. The main result of the paper provides two characterizations of data equivalence for nested schemes. The first is that two schemes are data equivalent if and only if the two sets of multivalued dependencies induced by the two corresponding scheme trees are equivalent. The second is that the schemes are equivalent if and only if  the corresponding scheme trees can be transformed into the other by a sequence of applications of a local restructuring operator and its inverse.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1550–1567},
numpages = {18},
keywords = {multivalued dependency, nested relations, partitioned normal form, database}
}

@article{10.5555/352746.352766,
author = {Poutr\'{e}, Han La},
title = {Maintenance of 2- and  3-Edge-Connected Components of Graphs II},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
abstract = {Data structures and algorithms are presented to efficiently maintain the 2- and 3-edge-connected components of a general graph, under insertions of edges and nodes in the graph. At any moment, the data structure can answer whether two nodes are 2- or 3-edge-connected. The algorithms run in O(n+ .alpha(m,n)) time, where m is the total number of queries and edge insertions. Furthermore, a linear-time algorithm is presented for maintaining the 2-edge-connected components in case the initial graph is connected. Finally, a new solution is presented for the 2-vertex-connected components of a graph.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1521–1549},
numpages = {29},
keywords = {dynamic data structures, vertex connectivity, analysis of algorithms, edge connectivity}
}

@article{10.1137/S0097539798334736,
author = {Buhrman, Harry and Fortnow, Lance and van Melkebeek, Dieter and Torenvliet, Leen},
title = {Separating Complexity Classes Using Autoreducibility},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798334736},
doi = {10.1137/S0097539798334736},
abstract = {A set is autoreducible if it can be reduced to itself by a Turing machine that does not ask its own input to the oracle. We use autoreducibility to separate the polynomial-time hierarchy from exponential space by showing that all Turing complete sets for certain levels of the exponential-time hierarchy are autoreducible but there exists some Turing complete set for doubly exponential space that is not. Although we already knew how to separate these classes using diagonalization, our proofs separate classes solely by showing they have different structural properties, thus applying Post's program to complexity theory. We feel such techniques may prove unknown separations in the future. In particular, if we could settle the question as to whether all Turing complete sets for doubly exponential time are autoreducible, we would separate either polynomial time from polynomial space, and nondeterministic logarithmic space from nondeterministic polynomial time, or else the polynomial-time hierarchy from exponential time.We also look at the autoreducibility of complete sets under nonadaptive, bounded query, probabilistic, and nonuniform reductions. We show how settling some of these autoreducibility questions will also lead to new complexity class separations.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1497–1520},
numpages = {24},
keywords = {coherence, autoreducibility, complexity classes, completeness}
}

@article{10.1137/S0097539797329373,
author = {Boissonnat, Jean-Daniel and Preparata, Franco P.},
title = {Robust Plane Sweep for Intersecting Segments},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797329373},
doi = {10.1137/S0097539797329373},
abstract = {In this paper, we reexamine in the framework of robust computation the Bentley--Ottmann algorithm for reporting intersecting pairs of segments in the plane. This algorithm has been reported as being very sensitive to numerical errors. Indeed, a simple analysis reveals that it involves predicates of degree 5, presumably never evaluated exactly in most implementations. Within the exact-computation paradigm we introduce two models of computation aimed at replacing the conventional model of real-number arithmetic. The first model (predicate arithmetic) assumes the exact evaluation of the signs of algebraic expressions of some degree, and the second model (exact arithmetic) assumes the exact computation of the value of such (bounded-degree) expressions. We identify the characteristic geometric property enabling the correct report of all intersections by plane sweeps. Verification of this property involves only predicates of (optimal) degree 2, but its straightforward implementation appears highly inefficient. We then present algorithmic variants that have low degree under these models and achieve the same performance as the original Bentley--Ottmann algorithm. The technique is applicable to a more general case of curved segments.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1401–1421},
numpages = {21},
keywords = {plane sweep, robust algorithms, segment intersection, computational geometry}
}

@article{10.1137/S0097539797327908,
author = {Dor, Dorit and Halperin, Shay and Zwick, Uri},
title = {All-Pairs Almost Shortest Paths},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797327908},
doi = {10.1137/S0097539797327908},
abstract = {Let  G =(  V ,  E ) be an unweighted undirected graph on  n  vertices. A simple argument shows that computing all distances in  G  with an additive one-sided error of at most 1 is as hard as Boolean matrix multiplication. Building on recent work of Aingworth et al. [  SIAM J. Comput ., 28 (1999), pp. 1167--1181], we describe an $Ot(min{n^{3/2}m^{1/2},n^{7/3}})$-time algorithm  APASP  2 for computing all distances in  G  with an additive one-sided error of at most 2. Algorithm  APASP  2 is simple, easy to implement, and faster than the fastest known matrix-multiplication algorithm. Furthermore, for every even  k &gt;2, we describe an ${tilde{O}}(min{n^{2-{2}/{(k+2)}}m^{{2}/{(k+2)}}, n^{2+{2}/{(3k-2)}}})$-time algorithm  APASP    k  for computing all distances in  G  with an additive one-sided error of at most  k . We also give an ${tilde{O}}(n^2)$-time algorithm ${bf APASP}_infty$ for producing stretch 3 estimated distances in an unweighted and undirected graph on  n  vertices. No constant stretch factor was previously achieved in ${tilde{O}}(n^2)$ time. We say that a weighted graph  F =(  V ,  E ')  k-emulates  an unweighted graph  G =(  V ,  E ) if for every $u,vin V$ we have $delta_G(u,v)le delta_F(u,v)le delta_G(u,v)+k$. We show that every unweighted graph on  n  vertices has a 2-emulator with ${tilde{O}}(n^{3/2})$ edges and a 4-emulator with ${tilde{O}}(n^{4/3})$ edges. These results are asymptotically tight.Finally, we show that any  weighted  undirected graph on  n  vertices has a 3-spanner with ${tilde{O}}(n^{3/2})$ edges and that such a 3-spanner can be built in ${tilde{O}}(mn^{1/2})$ time. We also describe an ${tilde{O}}(n(m^{2/3}+n))$-time algorithm for estimating all distances in a  weighted  undirected graph on  n  vertices with a stretch factor of at most 3.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1740–1759},
numpages = {20},
keywords = {shortest paths, approximation algorithms, graph algorithms, spanners, emulators}
}

@article{10.1137/S0097539797320578,
author = {Agarwal, Pankaj K. and Grove, Edward F. and Murali, T. M. and Vitter, Jeffrey Scott},
title = {Binary Space Partitions for Fat Rectangles},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797320578},
doi = {10.1137/S0097539797320578},
abstract = {We consider the practical problem of constructing binary space partitions (BSPs) for a set S of n orthogonal, nonintersecting, two-dimensional rectangles in ${Bbb R}^3$ such that the aspect ratio of each rectangle in $S$ is at most $alpha$, for some constant $alpha geq 1$. We present an $n2^{O(sqrt{log n})}$-time algorithm to build a binary space partition of size $n2^{O(sqrt{log n})}$ for $S$. We also show that if $m$ of the $n$ rectangles in $S$ have aspect ratios greater than $alpha$, we can construct a BSP of size $nsqrt{m}2^{O(sqrt{log n})}$ for $S$ in $nsqrt{m}2^{O(sqrt{log n})}$ time. The constants of proportionality in the big-oh terms are linear in $log alpha$. We extend these results to cases in which the input contains nonorthogonal or intersecting objects.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1422–1448},
numpages = {27},
keywords = {aspect ratio, rectangles, computational geometry, solid modelling, computer graphics, binary space partitions}
}

@article{10.1137/S0097539797315306,
author = {Dagum, Paul and Karp, Richard and Luby, Michael and Ross, Sheldon},
title = {An Optimal Algorithm for Monte Carlo Estimation},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797315306},
doi = {10.1137/S0097539797315306},
abstract = {A typical approach to estimate an unknown quantity $mu$ is to design an experiment that produces a random variable Z, distributed in [0,1] with  E[Z]=mu$, run this experiment independently a number of times, and use the average of the outcomes as the estimate.  In this paper, we consider the case when no a priori information about Z is known except that is distributed in [0,1].  We describe an approximation algorithm ${cal A}{cal A}$ which, given $epsilon$ and $delta$, when running independent experiments with respect to any Z, produces an estimate that is within a factor $1+epsilon$ of $mu$ with probability at least $1-delta$.  We prove that the expected number of experiments run by ${cal A}{cal A}$ (which depends on Z) is optimal to within a constant factor {for every} Z.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1484–1496},
numpages = {13},
keywords = {sequential estimation, approximation algorithm, stochastic approximation, stopping rule, Monte Carlo estimation}
}

@article{10.1137/S0097539797314465,
author = {Etzioni, Oren and Hanks, Steve and Jiang, Tao and Madani, Omid},
title = {Optimal Information Gathering on the Internet  with Time and Cost Constraints},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797314465},
doi = {10.1137/S0097539797314465},
abstract = {The World Wide Web provides access to vast amounts of information, but content providers are considering charging for the information and services they supply. Thus the consumer may face the problem of balancing the benefit of asking for information against the cost (in terms of both money and time) of acquiring it. We study information-gathering strategies that maximize the expected value to the consumer. In our model there is a single information request, which has a known  benefit  to the consumer. To satisfy the request,  queries  can be sent simultaneously or in sequence to any of a finite set of independent  information sources . For each source we know the monetary cost of making the query, the amount of time it will take, and the probability that the source will be able to provide the requested information. A  policy  specifies which sources to contact at which times, and the  expected value  of the policy can be defined as some function of the likelihood that the policy will yield an answer, the expected benefit, and the monetary cost and time delay associated with executing the policy. The problem is to find an expected-value-maximizing policy. We explore four variants of the objective function V: (i) V consists only of the benefit term subject to threshold constraints on both total cost and total elapsed time, (ii) V is linear in the expected total cost of the policy subject to the constraint that the total elapsed time never exceeds some deadline, (iii) V is linear in the expected total elapsed time subject to the constraint that the total cost never exceeds some threshold, and (iv) V is linear in the expected total monetary cost and the expected time delay of the policy. The problems of devising an optimal querying policy for all four variants and approximating an optimal querying policy for variants (iii) and (iv) are shown to be NP-hard. For (i), and with a mild simplifying assumption for (iii), we give a fully polynomial time approximation scheme. For (ii), we consider  batched  querying policies, and design an  O (  n 2) time approximation algorithm with ratio $frac{1}{2}$ and a polynomial time approximation scheme for optimal single-batch policies, and an  O (  kn 2) time approximation algorithm with ratio $frac{1}{5}$ for optimal  k -batch policies.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1596–1620},
numpages = {25},
keywords = {Internet, time and cost trade off, information gathering, World Wide Web, information retrieval, batched policy, approximation algorithm, scheduling, computational complexity}
}

@article{10.1137/S0097539796311168,
author = {Erg\"{u}n, Funda and Kumar, S. Ravi and Sivakumar, D.},
title = {Self-Testing without the Generator Bottleneck},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796311168},
doi = {10.1137/S0097539796311168},
abstract = {Suppose P is a program designed to compute a function f defined on a group G. The task of self-testing P, that is, testing if P computes f correctly on most inputs, usually involves testing explicitly if P computes f correctly on every generator of G. In the case of multivariate functions, the number of generators, and hence the number of such tests, becomes prohibitively large.  We refer to this problem as the  generator bottleneck. We develop a technique that can be used to overcome the generator bottleneck for functions that have a certain nice structure, specifically if the relationship between the values of the function on the set of generators is easily checkable. Using our technique, we build the first efficient self-testers for many linear, multilinear, and some nonlinear functions. This includes the FFT, and various polynomial functions. All of the self-testers we present make only O(1) calls to the program that is being tested. As a consequence of our techniques, we also obtain efficient program result-checkers for all these problems.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1630–1651},
numpages = {22},
keywords = {generator bottleneck, program correctness, self-testing}
}

@article{10.1137/S0097539796308151,
author = {Stacho, Ladislav and Vrto, Imrich},
title = {Virtual Path Layouts in ATM Networks},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796308151},
doi = {10.1137/S0097539796308151},
abstract = {We study virtual path layouts in a very popular type of fast interconnection networks, namely asynchronous transfer mode (ATM) networks. One of the main problems in such networks is to construct path layouts that minimize the hop-number (i.e., the number of virtual paths between any two nodes) as a function of the edge congestion  c  (i.e., the number of virtual paths going through a link). In this paper we construct for any  n  vertex network  H  and any  c  a virtual path layout with hop-number $O(frac{diam(H)logDelta}{log c})$, where  diam (  H ) is the diameter of the network  H  and $Delta$ is its maximum degree. Involving a general lower bound from [E. Kranakis, D. Krizanc, and A. Pelc,  Seventh IEEE Symposium on Parallel and Distributed Processing , IEEE Computer Society, 1995, pp. 662--668], we see that these hop-numbers are optimal for bounded degree networks with the diameter  O (log  n ) for any congestion  c . In the case of unbounded degree networks (with the diameter  O (log  n )) these hop-numbers are optimal for any $cgeqDelta$. For instance, this gives optimal hop-numbers for hypercube related networks. Moreover, we improve known results for paths and meshes and prove optimal hop-numbers for hypercubes.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1621–1629},
numpages = {9},
keywords = {virtual paths layout, congestion, ATM network, hop-number}
}

@article{10.1137/S0097539796307698,
author = {Saks, Michael and Zaharoglou, Fotios},
title = {Wait-Free <i>k</i>-Set Agreement is Impossible: The Topology of Public Knowledge},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796307698},
doi = {10.1137/S0097539796307698},
abstract = {In the classical consensus problem, each of  n  processors receives a private input value and produces a decision value which is one of the original input values, with the requirement that all processors decide the same value. A central result in distributed computing is that, in several standard models including the asynchronous shared-memory model, this problem has no deterministic solution. The  k -set agreement problem is a generalization of the classical consensus proposed by Chaudhuri [  Inform. and Comput. , 105 (1993), pp. 132--158], where the agreement condition is weakened so that the decision values produced may be different, as long as the number of distinct values is at most  k . For $n&gt;kgeq 2$ it was not known whether this problem is solvable deterministically in the asynchronous shared memory model. In this paper, we resolve this question by showing that for any  k  &lt;  n , there is no deterministic wait-free protocol for  n  processors that solves the  k -set agreement problem. The proof technique is new: it is based on the development of a topological structure on the set of possible processor schedules of a protocol. This topological structure has a natural interpretation in terms of the knowledge of the processors of the state of the system. This structure reveals a close analogy between the impossibility of wait-free  k -set agreement and the Brouwer fixed point theorem for the  k -dimensional ball.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1449–1483},
numpages = {35},
keywords = {Sperner's lemma, distributed computing, consensus, wait-free}
}

@article{10.1137/S009753979529564X,
author = {Czumaj, Artur and der, Friedhelm Meyerauf},
title = {Contention Resolution in Hashing Based Shared Memory Simulations},
year = {2000},
issue_date = {March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979529564X},
doi = {10.1137/S009753979529564X},
abstract = {In this paper we study the problem of simulating shared memory on the distributed memory machine (DMM). Our approach uses multiple copies of shared memory cells, distributed among the memory modules of the DMM via universal hashing. The main aim is to design strategies that resolve contention at the memory modules. Extending results and methods from random graphs and very fast randomized algorithms, we present new simulation techniques that enable us to improve the previously best results exponentially. In particular, we show that an $n$-processor CRCW PRAM can be simulated by an  n -processor DMM with delay $O(logloglog n log^*n)$, with high probability. Next we describe a general technique that can be used to turn these simulations into time-processor optimal ones, in the case of EREW PRAMs to be simulated. We obtain a time-processor optimal simulation of an (  n  log log log  n  log*  n )-processor EREW PRAM on an  n -processor DMM with delay $O(logloglog n log^*n)$, with high probability. When an (  n  log log log  n  log*  n )-processor CRCW PRAM is simulated, the delay is only by a log*  n  factor larger.We further demonstrate that the simulations presented can not be significantly improved using our techniques. We show an $Omega(logloglog n / loglogloglog n)$ lower bound on the expected delay for a class of PRAM simulations, called topological simulations, that covers all previously known simulations as well as the simulations presented in the paper.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1703–1739},
numpages = {37},
keywords = {randomized shared memory simulations, hashing, PRAM, distributed memory machine}
}

@article{10.1137/S0097539798341600,
author = {Chen, Zhi-Zhong and Kao, Ming-Yang},
title = {Reducing Randomness via Irrational Numbers},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798341600},
doi = {10.1137/S0097539798341600},
abstract = {We propose a general methodology for testing whether a given polynomial with integer coefficients is identically zero.  The methodology evaluates the polynomial at efficiently computable approximations of suitable irrational points.  In contrast to the classical technique of DeMillo, Lipton, Schwartz, and Zippel, this methodology can decrease the error probability by increasing the precision of the approximations instead of using more random bits. Consequently, randomized algorithms that use the classical technique can generally be improved using the new methodology.  To demonstrate the methodology, we discuss two nontrivial applications.  The first is to decide whether a graph has a perfect matching in parallel.  Our new NC algorithm uses fewer random bits while doing less work than the previously best NC algorithm by Chari, Rohatgi, and Srinivasan. The second application is to test the equality of two multisets of integers.  Our new algorithm improves upon the previously best algorithms by Blum and Kannan and can speed up their checking algorithm for sorting programs on a large range of inputs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1247–1256},
numpages = {10},
keywords = {parallel algorithms, perfect matchings, polynomial identification, program checking, randomized algorithms, Galois theory, multiset equality test}
}

@article{10.1137/S0097539798340850,
author = {Grolmusz, Vince and Tardos, G\'{a}bor},
title = {Lower Bounds for (MOD<i><sub>p</sub></i> - MOD<i><sub>m</sub></i>) Circuits},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798340850},
doi = {10.1137/S0097539798340850},
abstract = {Modular gates are known to be immune for the random restriction techniques of Ajtai (1983), Furst, Saxe, and Sipser (1984), Yao (1985), and H\r{a} stad (1986). We demonstrate here a random clustering technique which overcomes this difficulty and is capable of proving generalizations of several known modular circuit lower bounds of Barrington, Straubing, and Th\'{e}rien (1990), Krause and Pudl\'{a}k (1994), and others, characterizing symmetric functions computable by small (MOD  p , AND  t , MOD  m ) circuits. Applying a degree-decreasing technique together with random restriction methods for the AND gates at the bottom level, we also prove a hard special case of the constant degree hypothesis of Barrington, Straubing, and Th\'{e}rien (1990) and other related lower bounds for certain (MOD  p , MOD  m , AND) circuits.Most of the previous lower bounds on circuits with modular gates used special definitions of the modular gates (i.e., the gate outputs one if the sum of its inputs is divisible by  m  or is  not  divisible by  m ) and were not valid for more general MOD  m  gates. Our methods are applicable, and our lower bounds are valid for the most general modular gates as well.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1209–1222},
numpages = {14},
keywords = {composite modulus, modular gates, lower bounds}
}

@article{10.1137/S0097539798339041,
author = {Reinhardt, Klaus and Allender, Eric},
title = {Making Nondeterminism Unambiguous},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798339041},
doi = {10.1137/S0097539798339041},
abstract = {We show that in the context of nonuniform complexity, nondeterministic logarithmic space bounded computation can be made unambiguous. An analogous result holds for the class of problems reducible to context-free languages. In terms of complexity classes, this can be stated as NL/poly = UL/poly, LogCFL/poly = UAuxPDA($log n, n^{O(1)}$)/poly.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1118–1131},
numpages = {14},
keywords = {nondeterministic space, LogCFL, ULOG, NLOG, unambiguous computation}
}

@article{10.1137/S0097539797326976,
author = {Kimbrel, Tracy and Karlin, Anna R.},
title = {Near-Optimal Parallel Prefetching and Caching},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797326976},
doi = {10.1137/S0097539797326976},
abstract = {Recently there has been a great deal of interest in the operating systems research community in prefetching and caching data from parallel disks, as a technique for enabling serial applications to improve input--output (I/O) performance. In this paper, algorithms are considered for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks).  The integration of caching and prefetching with a single disk was previously considered by Cao, Felten, Karlin, and Li.  Here, it is shown that the natural extension of their aggressive algorithm to the parallel disk case is suboptimal by a factor near the number of disks in the worst case.  The main result is a new algorithm, reverse aggressive, with near-optimal performance for integrated prefetching and caching in the presence of multiple disks.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1051–1082},
numpages = {32},
keywords = {prefetching, algorithms, file systems, caching, operating systems}
}

@article{10.1137/S0097539797325387,
author = {Rajagopalan, Sridhar and Schulman, Leonard J.},
title = {Verification of Identities},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797325387},
doi = {10.1137/S0097539797325387},
abstract = {We provide an $O(n^2 log {1 over delta})$ time randomized algorithm to check whether a given operation $circ :S times S rightarrow S$ is associative (where $n=|S|$ and $delta&gt;0$ is the error probability required of the algorithm). We prove that (for any constant $delta$) this performance is optimal up to a constant factor, even if the operation is "cancellative." No sub-$n^3$ time algorithm was previously known for this task.More generally we give an $O(n^c)$ time randomized algorithm to check whether a collection of $c$-ary operations satisfy any given "read-once" identity.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1155–1163},
numpages = {9},
keywords = {computer aided verification, randomized algorithms}
}

@article{10.1137/S009753979732428X,
author = {Albers, Susanne and Henzinger, Monika R.},
title = {Exploring Unknown Environments},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732428X},
doi = {10.1137/S009753979732428X},
abstract = {We consider exploration problems where a robot has to construct a complete map of an unknown environment. We assume that the environment is modeled by a directed, strongly connected graph. The robot's task is to visit all nodes and edges of the graph using the minimum number R of edge traversals. Deng and Papadimitriou [ Proceedings of the 31st Symposium on the Foundations of Computer Science, 1990, pp. 356--361] showed an upper bound for R of dO(d) m and Koutsoupias (reported by Deng and Papadimitriou) gave a lower bound of $Omega(d^2 m)$, where m is the number of edges in the graph and d is the minimum number of edges that have to be added to make the graph Eulerian. We give the first subexponential algorithm for this exploration problem, which achieves an upper bound of dO(log d) m. We also show  a matching lower bound of $d^{Omega(log d)}m$ for our algorithm. Additionally, we give lower bounds of $2^{Omega(d)}m$, respectively, $d^{Omega(log d)}m$ for various other natural exploration algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1164–1188},
numpages = {25},
keywords = {exploration algorithm, directed graph}
}

@article{10.1137/S0097539797324278,
author = {Barve, Rakesh D. and Grove, Edward F. and Vitter, Jeffrey Scott},
title = {Application-Controlled Paging for a Shared Cache},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797324278},
doi = {10.1137/S0097539797324278},
abstract = {We propose a provably efficient application-controlled global strategy for organizing a cache of size k shared among P application processes. Each application has access to information about its own future page requests, and by using that local information along with randomization in the context of a global caching algorithm, we are able to break through the conventional $H_k sim ln k$ lower bound on the competitive ratio for the caching problem. If the P  application processes always make good cache replacement decisions, our online application-controlled caching algorithm attains a competitive ratio of $2H_{P-1}+2 sim 2 ln P$. Typically, P is much smaller than k, perhaps by several orders of magnitude. Our competitive ratio improves upon the 2P+2 competitive ratio achieved by the deterministic application-controlled strategy of Cao, Felten, and Li. We show that no online application-controlled algorithm can have a competitive ratio better than min{HP-1,Hk}, even if each application process has perfect knowledge of its individual page request sequence. Our results are with respect to a worst-case interleaving of the individual page request sequences of the P application processes.We introduce a notion of fairness in the more realistic situation when application processes do not always make good cache replacement decisions. We show that our algorithm ensures that no application process needs to evict one of its cached pages to service some page fault caused by a mistake of some other application. Our algorithm not only is fair but remains efficient; the global paging performance can be bounded in terms of the number of mistakes that application processes make.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1290–1303},
numpages = {14},
keywords = {online, application-controlled, caching, randomized, competitive}
}

@article{10.1137/S0097539797323005,
author = {Pacholski, Leszek and Szwast, WiesL aw and Tendera, Lidia},
title = {Complexity Results for First-Order Two-Variable Logic with Counting},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797323005},
doi = {10.1137/S0097539797323005},
abstract = {Let $C^2_p$ denote the class of first-order sentences with two variables and with additional quantifiers "there exists exactly (at most, at least) $i$" for $ileq p$, and let $C^2$ be the union of $C^2_p$ taken over all integers $p$. We prove that the satisfiability problem for $C^2_1$ sentences is NEXPTIME-complete. This strengthens the results by [E. Gr\"{a}del, Ph. Kolaitis, and M. Vardi,  Bull. Symbolic Logic , 3 (1997), pp. 53--69], who showed that the satisfiability problem for the first-order two-variable logic $L^2$ is NEXPTIME-complete and by [E. Gr\"{a}del, M. Otto, and E. Rosen, 12  th Annual IEEE Symposium on Logic in Computer Science , 1997, pp. 306--317], who proved the decidability of $C^2$. Our result easily implies that the satisfiability problem for $C^2$ is in nondeterministic, doubly exponential time. It is interesting that $C^2_1$ is in NEXPTIME in spite of the fact that there are sentences whose minimal (and only) models are of doubly exponential size. It is worth noticing that by a recent result of [E. Gr\"{a}del, M. Otto, and E. Rosen,  Proceedings of  14  th Annual Symposium on Theoretical Aspects of Computer Science , Lecture Notes in Comput. Sci. 1200, Springer-Verlag, Berlin, 1997], extensions of two-variable logic $L^2$ by a weak access to cardinalities through the H\"{a}rtig (or equicardinality) quantifier is undecidable. The same is true for extensions of $L^2$ by very weak forms of recursion.The satisfiability problem for logics with a bounded number of variables has applications in artificial intelligence, notably in modal logics (see, e.g., [W. van der Hoek and M. De Rijke,  J. Logic Comput ., 5 (1995), pp. 325--345]), where counting comes in the context of graded modalities and in description logics, where counting can be used to express so-called number restrictions (see, e.g., [A. Borgida,  Artificial Intelligence , 82 (1996), pp. 353--367]).},
journal = {SIAM J. Comput.},
month = feb,
pages = {1083–1117},
numpages = {35},
keywords = {first-order logic, computational complexity, decision problem}
}

@article{10.1137/S0097539797321742,
author = {Kilian, Joe and Kushilevitz, Eyal and Micali, Silvio and Ostrovsky, Rafail},
title = {Reducibility and Completeness in Private Computations},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797321742},
doi = {10.1137/S0097539797321742},
abstract = {We define the notions of  reducibility and  completeness in (two-party and multiparty) private computations.  Let g be an n-argument function.  We say that a function f is  reducible to a function g if n honest-but-curious players can compute the function f n-privately, given a black box for g (for which they secretly give inputs and get the result of operating g on these inputs).  We say that g is  complete (for private computations) if  every function f is reducible to g.In this paper, we characterize the complete boolean functions: we show that a boolean function g is complete if and only if g itself cannot be computed n-privately (when there is no black box available).  Namely, for n-argument boolean functions, the notions of completeness and n-privacy are  complementary.  This characterization provides a huge collection of complete functions  any nonprivate boolean function!) compared to very few examples that were given (implicitly) in previous work. On the other hand, for nonboolean functions, we show that these two notions are  not complementary.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1189–1208},
numpages = {20},
keywords = {completeness, reducibility, private computation, oblivious-transfer}
}

@article{10.1137/S0097539797315744,
author = {Goldreich, Oded and Safra, Shmuel},
title = {A Combinatorial Consistency Lemma with Application to Proving the PCP Theorem},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797315744},
doi = {10.1137/S0097539797315744},
abstract = {The current proof of the probabilistically checkable proofs (PCP) theorem (i.e., ${cal NP}={cal PCP}(log,O(1))$) is very complicated. One source of difficulty is the technically involved analysis of low-degree tests. Here, we refer to the difficulty of obtaining strong results regarding low-degree tests; namely, results of the type obtained and used by Arora and Safra [J. ACM, 45 (1998), pp. 70--122] and Arora et al. [J. ACM, 45 (1998), pp. 501--555].In this paper, we eliminate the need to obtain such strong results on low-degree tests when proving the PCP theorem. Although we do not remove the need for low-degree tests altogether, using our results it is now possible to prove the PCP theorem using a simpler analysis of low-degree tests (which yields weaker bounds). In other words, we replace the strong algebraic analysis of low-degree tests presented by Arora and Safra and Arora et al. by a combinatorial lemma (which does not refer to low-degree tests or polynomials).},
journal = {SIAM J. Comput.},
month = feb,
pages = {1132–1154},
numpages = {23},
keywords = {NP, parallelization of probabilistic proof systems, probabilistically checkable proofs (PCP), low-degree tests}
}

@article{10.1137/S0097539796335480,
author = {Lin, Wei-Liang and Farrahi, Amir H. and Sarrafzadeh, M.},
title = {On the Power of Logic Resynthesis},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796335480},
doi = {10.1137/S0097539796335480},
abstract = {A linear arrangement problem, called the minmax mincut problem, emerging from circuit design is investigated. Its input is a series-parallel directed hypergraph (SPDH), and the output is a linear arrangement (and a layout). The primary objective is to minimize the longest path, and  the secondary objective is to minimize the cutwidth. It is shown that cutwidth D, subject to longest path minimization, is affected by two terms:  pattern number k and  balancing number m. Also, k and m are both lower bounds on the cutwidth.  An algorithm, running in linear time, produces  layouts with cutwidths $D leq 2(k+m)$.  There exist examples with $k=Omega (N)$, where $N$ is the number of vertices; however, m is always O(log N). We show that every SPDH, after $local logic resynthesis$ (specifically, after reordering the  serial paths), can be linearly placed with cutwidth D=O(log N). Simultaneously, its dual SPDH can be linearly placed with the same vertex order and with cutwidth D=O(log N). Therefore, after local resynthesis the area can be reduced by a factor of N/log N. Application to gate-matrix layout style is demonstrated.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1257–1289},
numpages = {33},
keywords = {VLSI design, timing, VLSI layout, linear arrangement, graphs and large scale networks, resynthesis}
}

@article{10.1137/S0097539796314124,
author = {Mitchell, Scott A. and Vavasis, Stephen A.},
title = {Quality Mesh Generation in Higher Dimensions},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796314124},
doi = {10.1137/S0097539796314124},
abstract = {We consider the problem of triangulating a d-dimensional region. Our mesh generation algorithm, called QMG, is a quadtree-based algorithm that can triangulate any polyhedral region including nonconvex regions with holes. Furthermore, our algorithm guarantees a bounded aspect ratio triangulation provided that the input domain itself has no sharp angles. Finally, our algorithm is guaranteed never to overrefine the domain, in the sense that the number of simplices produced by QMG is bounded above by a factor times the number produced by any competing algorithm, where the factor depends on the aspect ratio bound satisfied by the competing algorithm. The QMG algorithm has been implemented in C++ and is used as a mesh generator for the finite element method.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1334–1370},
numpages = {37},
keywords = {mesh generation, tetrahedra, triangulation, polyhedron, aspect ratio}
}

@article{10.1137/S0097539796312733,
author = {Aggarwal, Alok and Kleinberg, Jon and Williamson, David P.},
title = {Node-Disjoint Paths on the Mesh and a New Trade-Off in VLSI Layout},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796312733},
doi = {10.1137/S0097539796312733},
abstract = {A number of basic models for VLSI layout are based on the construction of node-disjoint paths between terminals on a multilayer grid.  In this setting, one is interested in minimizing both the number of  layers required and the  area of the underlying grid.  Building on work of Cutler and Shiloach [ Networks, 8 (1978), pp. 253--278], Aggarwal et al. [ Proc. 26th IEEE Symposium on Foundations of Computer Science , Portland, OR, 1985;  Algorithmica, 6 (1991), pp. 241--255], and Aggarwal, Klawe, and Shor [ Algorithmica, 6 (1991), pp. 129--151], we prove an upper-bound trade-off between these two quantities in a general multilayer grid model. As a special case of our main result, we obtain significantly improved bounds for the problem of routing a full permutation on the mesh using node-disjoint paths; our new bound here is within polylogarithmic factors of the bisection bound. Our algorithms involve some new techniques for analyzing the structure of node-disjoint paths in planar graphs and indicate some respects in which this problem, at least in the planar case, is fundamentally different from its edge-disjoint counterpart.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1321–1333},
numpages = {13},
keywords = {VLSI layout, disjoint paths problem, combinatorial optimization}
}

@article{10.1137/S0097539796307194,
author = {Chen, Danny Z. and Klenk, Kevin S. and Tu, Hung-Yi T.},
title = {Shortest Path Queries Among Weighted Obstacles in the Rectilinear Plane},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796307194},
doi = {10.1137/S0097539796307194},
abstract = {We study the problems of processing single-source and two-point shortest path queries among weighted polygonal obstacles in the rectilinear plane. For the single-source case, we construct a data structure in  O (  n log 3/2  n ) time and  O (  n log  n ) space, where  n  is the number of obstacle vertices; this data structure enables us to report the length of a shortest path between the source and any query point in  O (log  n ) time, and an actual shortest path in  O (log  n +  k ) time, where  k  is the number of edges on the output path. For the two-point case, we construct a data structure in  O (  n  2 log 2n) time and space; this data structure enables us to report the length of a shortest path between two arbitrary query points in  O (log 2  n ) time, and an actual shortest path in  O (log 2  n  +  k ) time. Our work improves and generalizes the previously best-known results on computing rectilinear shortest paths among weighted polygonal obstacles. We also apply our techniques to processing two-point  L  1 shortest obstacle-avoiding path queries among arbitrary (i.e., not necessarily rectilinear) polygonal obstacles in the plane. No algorithm for processing two-point shortest path queries among weighted obstacles was previously known.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1223–1246},
numpages = {24},
keywords = {path planning, data structures, analysis of algorithms, computational geometry}
}

@article{10.1137/S0097539796307182,
author = {Boppana, Ravi B. and Narayanan, Babu O.},
title = {Perfect-Information Leader Election with  Optimal Resilience},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796307182},
doi = {10.1137/S0097539796307182},
abstract = {This paper investigates the leader-election problem in the perfect-information model of distributed computing.  It is shown that for every $epsilon &lt; half$, there exist leader-election protocols for $n$ processors that tolerate $eps n$ faults.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1304–1320},
numpages = {17},
keywords = {perfect information, probabilistic methods, leader election, fault tolerance, distributed computing}
}

@article{10.1137/S0097539794262446,
author = {Chan, Edward P. F. and vander Meyden, Ron},
title = {Containment and Optimization of Object-Preserving  Conjunctive Queries},
year = {2000},
issue_date = {Feb. 2000 to March 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794262446},
doi = {10.1137/S0097539794262446},
abstract = {In the optimization of queries in an object-oriented database (OODB) system, a natural first step is to use the typing constraints imposed by the schema to transform a query into an equivalent one that logically accesses a minimal set of objects. We study a class of queries for OODBs called conjunctive queries. Variables in a conjunctive query range over heterogeneous sets of objects. Consequently, a conjunctive query is equivalent to a union of conjunctive queries of a special kind, called terminal conjunctive queries. Testing containment is a necessary step in solving the equivalence and minimization problems. We first characterize the containment and minimization conditions for the class of terminal conjunctive queries. We then characterize containment for the class of all conjunctive queries and derive an optimization algorithm for this class. The equivalent optimal query produced is expressed as a union of terminal conjunctive queries, which has the property that the number of variables as well as their search spaces are minimal among all unions of terminal conjunctive queries. Finally, we investigate the complexity of the containment problem. We show that it is complete in $Pi^{p}_{2}$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1371–1400},
numpages = {30},
keywords = {equivalence, containment, conjunctive queries, query optimization, complexity, object-oriented database, minimization}
}

@article{10.5555/337729.337809,
author = {Willard, Dan E.},
title = {Examining Computational Geometry, Van Emde Boas Trees, and Hashing from the Perspective of the Fusion Tree},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
abstract = {This article illustrates several examples of computer science problems whose performance can be improved with the use of either the fusion trees [Fredman and Willard, J. Comput. System Sci., 47 (1993), pp. 424--436; Fredman and Willard, J. Comput. System Sci., 48 (1994), pp. 533--551] or one of several recent improvements to this data structure. It is likely that many other data structures can also have their performance improved with fusion trees. The examples here are only illustrative.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1030–1049},
numpages = {20},
keywords = {hashing, searching, computational geometry, multidimensional retrieval, sorting}
}

@article{10.5555/337729.337784,
author = {Decatur, Scott E. and Goldreich, Oded and Ron, Dana},
title = {Computational Sample Complexity},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
abstract = {In a variety of PAC learning models, a trade-off between time and information seems to exist: with unlimited time, a small amount of information suffices, but with time restrictions, more information sometimes seems to be required. In addition, it has long been known that there are concept classes that can be learned in the absence of computational restrictions, but (under standard cryptographic assumptions) cannot be learned in polynomial time (regardless of sample size). Yet, these results do not answer the question of whether there are classes for which learning from a small set of examples is computationally infeasible, but becomes feasible when the learner has access to (polynomially) more examples.To address this question, we introduce a new measure of learning complexity called  computational sample complexity  that represents the number of examples sufficient for  polynomial time learning with respect to a fixed distribution.  We then show concept classes that (under similar cryptographic assumptions) possess arbitrarily sized gaps between their standard (information-theoretic) sample complexity and their computational sample complexity.  We also demonstrate such gaps for learning from membership queries and learning from noisy examples.},
journal = {SIAM J. Comput.},
month = dec,
pages = {854–879},
numpages = {26},
keywords = {pseudo-random functions, information vs. efficient computation, wire-tap channel, error correcting codes, computational learning theory}
}

@article{10.5555/337729.337739,
author = {Natarajan, B.},
title = {On Learning Functions from Noise-Free and Noisy Samples via Occam's Razor},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
abstract = {An Occam approximation is an algorithm that takes as input a set of samples of a function and a tolerance $epsilon$ and produces as output a compact representation of a function that is within $epsilon$ of the given samples. We show that the existence of an Occam approximation is sufficient to guarantee the probably approximate learnability of classes of functions on the reals even in the presence of arbitrarily large but random additive noise. One consequence of our results is a general technique for the design and analysis of nonlinear filters in digital signal processing.},
journal = {SIAM J. Comput.},
month = dec,
pages = {712–727},
numpages = {16},
keywords = {noisy data, probably approximate learning}
}

@article{10.1137/S0097539798334207,
author = {Kaplan, Haim and Shamir, Ron and Tarjan, Robert E.},
title = {A Faster and Simpler Algorithm for Sorting Signed Permutations by Reversals},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798334207},
doi = {10.1137/S0097539798334207},
abstract = {We give a quadratic time algorithm for finding the minimum number of reversals needed to sort a signed permutation. Our algorithm is faster than the previous algorithm of Hannenhalli and Pevzner and its faster implementation by Berman and Hannenhalli. The algorithm is conceptually simple and does not require special data structures. Our study also considerably simplifies the combinatorial structures used by the analysis.},
journal = {SIAM J. Comput.},
month = dec,
pages = {880–892},
numpages = {13},
keywords = {reversal distance, sorting permutations, computational molecular biology}
}

@article{10.1137/S0097539797331105,
author = {Kosaraju, S. Rao and Manzini, Giovanni},
title = {Compression of Low Entropy Strings with Lempel--Ziv Algorithms},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797331105},
doi = {10.1137/S0097539797331105},
abstract = {We compare the compression ratio of the Lempel--Ziv algorithms with the empirical entropy of the input string. This approach makes it possible to analyze the performance of these algorithms without any assumption on the input and to obtain worst case results. We show that in this setting the standard definition of optimal compression algorithm is not satisfactory. In fact, although Lempel--Ziv algorithms are optimal according to the standard definition, there exist families of  low entropy strings which are not compressed optimally. More precisely, the compression ratio achieved by  LZ78 (resp.,  LZ77) can be much higher than the zeroth order entropy H0 (resp., the first order entropy H1).For this reason we introduce the concept of $lambda$-optimal algorithm. An algorithm is $lambda$-optimal with respect to Hk if, loosely speaking, its compression ratio is asymptotically bounded by $lambda$ times the kth order empirical entropy Hk.  We prove that  LZ78 cannot be $lambda$-optimal with respect to any Hk with $kgeq 0$. Then, we describe a new algorithm which combines LZ78 with run length encoding (RLE) and is 3-optimal with respect to H0.  Finally, we prove that  LZ77  is 8-optimal with respect to H0, and that it cannot be $lambda$-optimal with respect to Hk for any $kgeq 1$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {893–911},
numpages = {19},
keywords = {Lempel--Ziv parsing, empirical entropy, data compression}
}

@article{10.1137/S009753979732253X,
author = {Wu, Bang Ye and Lancia, Giuseppe and Bafna, Vineet and Chao, Kun-Mao and Ravi, R. and Tang, Chuan Yi},
title = {A Polynomial-Time Approximation Scheme for Minimum Routing Cost Spanning Trees},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979732253X},
doi = {10.1137/S009753979732253X},
abstract = {Given an undirected graph with nonnegative costs on the edges, the routing cost of any of its spanning trees is the sum over all pairs of vertices of the cost of the path between the pair in the tree. Finding a spanning tree of minimum routing cost is NP-hard, even when the costs obey the triangle inequality. We show that the general case is in fact reducible to the metric case and present a polynomial-time approximation scheme valid for both versions of the problem. In particular, we show how to build a spanning tree of an n-vertex weighted graph with routing cost at most $(1+epsilon)$ of the minimum in time $O(n^{O({frac{1}{epsilon}}% )})$. Besides the obvious connection to network design, trees with small routing cost also find application in the construction of good multiple sequence alignments in computational biology. The communication cost spanning tree problem is a generalization of the minimum routing cost tree problem where the routing costs of different pairs are weighted by different requirement amounts. We observe that a randomized O(log n log log n)-approximation for this problem follows directly from a recent result of Bartal, where n is the number of nodes in a metric graph. This also yields the same approximation for the generalized sum-of-pairs alignment problem in computational biology.},
journal = {SIAM J. Comput.},
month = dec,
pages = {761–778},
numpages = {18},
keywords = {network design, spanning trees, approximation algorithms, computational biology}
}

@article{10.1137/S0097539797318864,
author = {Goldberg, Leslie Ann and Jerrum, Mark},
title = {Randomly Sampling Molecules},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797318864},
doi = {10.1137/S0097539797318864},
abstract = {We give a polynomial-time algorithm for the following problem: Given a degree sequence in which each degree is bounded from above by a constant, select, uniformly at random, an unlabelled connected multigraph with the given degree sequence. We also give a polynomial-time algorithm for the following related problem: Given a molecular formula, select, uniformly at random, a structural isomer having the given formula.},
journal = {SIAM J. Comput.},
month = dec,
pages = {834–853},
numpages = {20},
keywords = {random graphs, structural isomers, P\'{o}lya theory}
}

@article{10.1137/S0097539797316610,
author = {Dolev, Shlomi and Kranakis, Evangelos and Krizanc, Danny and Peleg, David},
title = {Bubbles: Adaptive Routing Scheme for High-Speed Dynamic Networks},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797316610},
doi = {10.1137/S0097539797316610},
abstract = {This paper presents the first dynamic routing scheme for high-speed networks. The scheme is based on a hierarchical bubbles partition of the underlying communication graph. Dynamic routing schemes are ranked by their  adaptability, i.e., the maximum number of sites to be updated upon a topology change. An advantage of our scheme is that it implies a small number of updates upon a topology change. In particular, for the case of a bounded degree network it is proved that our scheme is optimal in its adaptability by presenting a matching tight lower bound. Our bubble routing scheme is a combination of a distributed routing database, a routing strategy, and a routing database update. It is shown how to perform the routing database update on a dynamic network in a distributed manner.},
journal = {SIAM J. Comput.},
month = dec,
pages = {804–833},
numpages = {30},
keywords = {adaptability, routing, communication network, dynamic, fiber optics}
}

@article{10.1137/S0097539796324661,
author = {Sweedyk, Z.},
title = {\boldmath A $2\frac12$-Approximation Algorithm for   Shortest Superstring},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796324661},
doi = {10.1137/S0097539796324661},
abstract = {Given a set of strings  S ={  s  1,  s  2. . . ,  s n } over a finite alphabet $Sigma$, a  superstring  of  S  is a string that contains each  s i  as a contiguous substring. The  shortest superstring  (SS) problem is to find a superstring of minimum length. This problem has important applications in computational biology and in data compression (see, respectively, [A. Lesk, ed.,  Computational Molecular Biology, Sources and Methods for Sequence Analysis , Oxford University Press, Oxford, 1988]; [J. Storer,  Data Compression: Methods and Theory , Computer Science Press, Rockville, MD, 1988]). SS is MAX SNP-hard [A. Blum et al.,  Proc.  23  rd Annual ACM Symposium on Theory of Computing , ACM, New York, 1991, pp. 328--336] so it is unlikely that the length of a shortest superstring can be approximated to within an arbitrary constant. Several heuristics have been suggested and it is conjectured that GREEDY achieves an approximation factor of 2. This, unfortunately, remains an open question.Several linear approximation algorithms for SS have been proposed. The first, by Blum et al. [  Proc.  23  rd Annual ACM Symposium on Theory of Computing , ACM, New York, 1991, pp. 328--336], guarantees a performance factor of 3. The factor has been successively improved to $2frac{8}{9}$, $2 frac{5}{6}$, $2 frac{50}{63}$, $2 frac{3}{4}$, $2frac{2}{3}$, and $2.596$ (see, respectively, [S. Teng and F. Yao,  Proc.  34  th Annual IEEE Symposium on Foundations of Computer Science , IEEE Computer Society Press, Piscataway, NJ, 1993, pp. 158--165]; [A. Czumaj et al.,  Proc. First Scandinavian Workshop on Algorithm Theory , Lecture Notes in Comput. Sci. 824, Springer-Verlag, Berlin, 1994, pp. 95--106]; [R. Kosaraju, J. Park, and C. Stein,  Proc.  35  th Annual IEEE Symposium on Foundations of Computer Science , IEEE Computer Society Press, Piscataway, NJ, 1994, pp. 166--177]; [C. Armen and C. Stein,  Proc.  5  th Internat. Workshop on Algorithms and Data Structures, Lecture Notes in Comput. Sci.  955, Springer-Verlag, Berlin, 1995, pp. 494--505]; [C. Armen and C. Stein,  Proc. Combinatorial Pattern Matching , Lecture Notes in Comput. Sci. 1075, Springer-Verlag, Berlin, 1996, pp. 87--101]; and [D. Breslauer, T. Jiang, and Z. Jiang,  J. Algorithms , 24 (1997), pp. 340--353]). In this paper we give an algorithm that guarantees a $2frac{1}{2}$-approximation factor.},
journal = {SIAM J. Comput.},
month = dec,
pages = {954–986},
numpages = {33},
keywords = {algorithm, data compression, shortest superstring, shotgun sequencing}
}

@article{10.1137/S009753979631391X,
author = {Miyazawa, F. K. and Wakabayashi, Y.},
title = {Approximation Algorithms for the Orthogonal <i>Z</i>-Oriented Three-Dimensional Packing Problem},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979631391X},
doi = {10.1137/S009753979631391X},
abstract = {We present approximation algorithms for the  orthogonal z-oriented three-dimensional packing problem  (TPP   z ) and analyze their asymptotic performance bound. This problem consists in packing a list of rectangular boxes  L =(  b  1,  b  2,. . . ,  b  n) into a rectangular box  B =(l,w,infty)$, orthogonally and oriented in the  z -axis, in such a way that the height of the packing is minimized. We say that a packing is oriented in the  z -axis when the boxes in  L  are allowed to be rotated (by ninety degrees) around the  z -axis. This problem has some nice applications but has been less investigated than the well-known variant of it---denoted by TPP (three-dimensional orthogonal packing problem)---in which rotations of the boxes are not allowed. The problem TPP can be reduced to TPP   z . Given an algorithm for TPP   z , we can obtain an algorithm for TPP with the same asymptotic bound. We present an algorithm for TPP   z , called  R , and three other algorithms, called  LS ,  BS , and  SS , for special cases of this problem in which the instances are more restricted. The algorithm  LS  is for the case in which all boxes in  L  have square bottoms;  BS  is for the case in which the box  B  has a square bottom, and  SS  is for the case in which the box  B  and all boxes in  L  have square bottoms. For an algorithm $wa$, we denote by $r(wa)$ the asymptotic performance bound of $wa$. We show that $2.5leq r(R)&lt;2.67$, $ 2.5leq r(LS)leq 2.528$,$ 2.5leq r(BS)leq 2.543$, and $ 2.333leq r(SS)leq 2.361$. The algorithms presented here have the same complexity ${cal O}(nlog n)$ as the other known algorithms for these problems, but they have better asymptotic performance bounds.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1008–1029},
numpages = {22},
keywords = {asymptotic performance bound, three-dimensional packing, approximation algorithms}
}

@article{10.1137/S0097539796312721,
author = {Aggarwal, Alok and Coppersmith, Don and Khanna, Sanjeev and Motwani, Rajeev and Schieber, Baruch},
title = {The Angular-Metric Traveling Salesman Problem},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796312721},
doi = {10.1137/S0097539796312721},
abstract = {Motivated by applications in robotics, we formulate the problem of minimizing the total angle cost of a TSP tour for a set of points in Euclidean space, where the angle cost of a tour is the sum of the direction changes at the points. We establish the NP-hardness of both this problem and its relaxation to the cycle cover problem. We then consider the issue of designing approximation algorithms for these problems and show that both problems can be approximated to within a ratio of O(log n) in polynomial time. We also consider the problem of simultaneously approximating both the angle and the length measure for a TSP tour. In studying the resulting tradeoff, we choose to focus on the sum of the two performance ratios and provide tight bounds on the sum. Finally, we consider the extremal value of the angle measure and obtain essentially tight bounds for it. In this paper we restrict our attention to the  planar setting, but all our results are easily extended to higher dimensions.},
journal = {SIAM J. Comput.},
month = dec,
pages = {697–711},
numpages = {15},
keywords = {combinatorial optimization, computational complexity, robotics, angle metric, traveling salesman problem, extremal point sets, approximation algorithms}
}

@article{10.1137/S0097539796310801,
author = {Boldi, Paolo and Vigna, Sebastiano},
title = {Complexity of Deciding Sense of Direction},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796310801},
doi = {10.1137/S0097539796310801},
abstract = {In this paper we prove that deciding whether a distributed system (represented as a colored digraph with n nodes) has weak sense of direction is in AC1 (using n6 processors). Moreover, we show that deciding sense of direction is in P. Our algorithms can also be used to decide in  AC1 whether a colored graph is a Cayley color graph.},
journal = {SIAM J. Comput.},
month = dec,
pages = {779–789},
numpages = {11},
keywords = {sense of direction, Cayley graphs, computational complexity, distributed systems}
}

@article{10.1137/S0097539796298339,
author = {Macarie, Ioan I.},
title = {On the Structure of Logspace Probabilistic Complexity Classes},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796298339},
doi = {10.1137/S0097539796298339},
abstract = {We investigate  hierarchical properties and logspace reductions of languages recognized by logspace probabilistic Turing machines, Arthur--Merlin games, and games against nature with logspace probabilistic verifiers. Each logspace complexity class is decomposed into a hierarchy based on corresponding two-way multihead finite-state automata and we (eventually) prove the separation of the hierarchy levels (even for languages over a single-letter alphabet); furthermore, we show efficient reductions of each logspace complexity class to, or between, low levels  of its corresponding hierarchy.We find  probabilistic and probabilistic-plus-nondeterministic variants of Savitch's maze threading problem which are logspace complete for PL (the class of languages recognized by logspace probabilistic Turing machines) and, respectively, PPP (the class of languages recognized by polynomial-time deterministic Turing machines), and which can be recognized by one-way non-sensing two-head (or one-way one-head  one-counter) finite-state automata with probabilistic and both probabilistic and nondeterministic states, respectively.},
journal = {SIAM J. Comput.},
month = dec,
pages = {987–1007},
numpages = {21},
keywords = {games against nature, probabilistic Turing machines, Arthur--Merlin games, multihead finite automata, heads hierarchy, logspace reductions, probabilistic computation}
}

@article{10.1137/S0097539795295936,
author = {Agarwal, Pankaj K. and Efrat, Alon and Sharir, Micha},
title = {Vertical Decomposition of Shallow Levels  in 3-Dimensional Arrangements  and Its Applications},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795295936},
doi = {10.1137/S0097539795295936},
abstract = {Let ${cal F}$ be a collection of n bivariate algebraic functions of constant maximum degree. We show that the combinatorial complexity of the vertical decomposition of the $({le}k)$-level of the arrangement $A({cal F})$ is $O(k^{3+varepsilon}psi({n/k}))$ for any $varepsilon&gt;0$, where $psi (r)$ is the maximum complexity of the lower envelope of a subset of at most $r$ functions of ${cal F}$. This bound is nearly optimal in the worst case and implies the existence of shallow cuttings, in the sense of [J. Matousek, Comput. Geom., 2 (1992), pp. 169--186], of small size in arrangements of bivariate algebraic functions. We also present numerous applications of these results, including (i) data structures for several generalized 3-dimensional range-searching problems; (ii) dynamic data structures for planar nearest- and farthest-neighbor searching under various fairly general distance functions; (iii) an improved (near-quadratic) algorithm for minimum-weight bipartite Euclidean matching in the plane; and (iv) efficient algorithms for certain geometric optimization problems in static and dynamic settings.},
journal = {SIAM J. Comput.},
month = dec,
pages = {912–953},
numpages = {42},
keywords = {arrangements, geometric optimization, range searching, parametric searching, divide-and-conquer, nearest-neighbor searching}
}

@article{10.1137/S0097539795282730,
author = {Levene, Mark and Loizou, George},
title = {Navigation in Hypertext Is Easy Only Sometimes},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795282730},
doi = {10.1137/S0097539795282730},
abstract = {One of the main unsolved problems confronting Hypertext is the navigation problem, namely, the problem of having to know where you are in the database graph representing the structure of a Hypertext database, and knowing how to get to some other place you are searching for in the database graph. In order to tackle this problem we introduce a formal model for Hypertext. In this model a Hypertext database consists of an information repository, which stores the contents of the database in the form of pages, and a reachability relation, which is a directed graph describing the structure of the database. The notion of a trail, which is a path in the database graph describing some logical association amongst the pages in the trail, is central to our model. We define a Hypertext query language for our model based on a subset of propositional linear temporal logic, which we claim to be a natural formalism as a basis for establishing navigation semantics for Hypertext. The output of a trail query in this language is the set (which may be infinite) of all trails that satisfy the query. We show that there is a strong connection between the output of a trail query and finite automata in the sense that, given a Hypertext database and a trail query, we can construct a finite automaton representing the output of the query, which accepts a star-free regular language. We show that the construction of the finite automaton can be done in time exponential in the number of conjunctions, between the subformulas of the trail query, plus one.Given a Hypertext database and a trail query, the problem of deciding whether there exists a trail in the database that satisfies the trail query is referred to as the model checking problem. We show that, although this problem is NP-complete for different subsets of our query language, it can be solved in polynomial time for some significant special cases. Thus the navigation problem can only be efficiently solved in some special cases, and therefore in practice Hypertext systems could include algorithms which return randomized and/or fuzzy solutions.},
journal = {SIAM J. Comput.},
month = dec,
pages = {728–760},
numpages = {33},
keywords = {computational complexity, trail query, temporal logic, navigation, finite automata, Hypertext}
}

@article{10.1137/S0097539795280512,
author = {Fiat, Amos and Naor, Moni},
title = {Rigorous Time/Space Trade-Offs for Inverting Functions},
year = {1999},
issue_date = {Dec. 1999 to Jan. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795280512},
doi = {10.1137/S0097539795280512},
abstract = {We provide rigorous time/space trade-offs for inverting any function. Given a function f, we give a time/space trade-off of T S2 = N3 q(f), where q(f) is the probability that two random elements (taken with replacement) are mapped to the same image under f. We also give a more general trade-off, T S3 = N3, that can invert  any function at  any point.},
journal = {SIAM J. Comput.},
month = dec,
pages = {790–803},
numpages = {14},
keywords = {hashing data encryption standard, randomized algorithms, cryptography, random graphs, cryptanalysis, one-way functions}
}

@article{10.5555/333115.333133,
author = {Nedev, Zhivko Prodanov},
title = {Finding an Even Simple Path in a Directed Planar Graph},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {In this paper we show that the following problem, the  even simple path  (ESP)  problem for directed planar graphs , is solvable in polynomial time:   Given : a directed planar graph  G =(  V ,  E ) and two nodes  s , (  starting node ),  t  ,(  targetnode ) in  V ;   Find : a simple path (i.e., without repeated nodes) from  s  to  t  of even length. (The length of the path is the number of edges it contains.)},
journal = {SIAM J. Comput.},
month = oct,
pages = {685–695},
numpages = {11},
keywords = {regular expressions, labeled directed graphs, planar graphs, simple paths, polynomial-time algorithms, NP-completeness}
}

@article{10.5555/333115.333132,
author = {Ruskey, Frank and Sawada, Joe},
title = {An Efficient Algorithm for Generating Necklaces with Fixed Density},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {A k-ary necklace is an equivalence class of k-ary strings under rotation. A necklace of fixed density is a necklace where the number of zeros is fixed. We present a fast, simple, recursive algorithm for generating (i.e., listing) fixed-density k-ary necklaces or aperiodic necklaces. The algorithm is optimal in the sense that it runs in time proportional to the number of necklaces produced.},
journal = {SIAM J. Comput.},
month = oct,
pages = {671–684},
numpages = {14},
keywords = {difference covers, CAT algorithm, fixed density, Lyndon words, generate, necklaces}
}

@article{10.5555/333115.333130,
author = {Andrews, Matthew and Leighton, Tom and Metaxas, P. Takis and Zhang, Lisa},
title = {Automatic Methods for Hiding Latency in Parallel and Distributed Computation},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {In this paper we describe methods for mitigating the degradation in performance caused by high latencies in parallel and distributed networks.  For example, given any "dataflow" type of algorithm that runs in T steps on an n-node ring with unit link delays, we show how to run the algorithm in O(T) steps on any n-node bounded-degree connected network with  average link delay O(1). This is a significant improvement over prior approaches to latency hiding, which require slowdowns proportional to the  maximum link delay. In the case when the network has average link delay $dave$, our simulation runs in $O(sqrt{dave} T)$ steps using $n/sqrt{dave}$ processors, thereby preserving efficiency.  We also show how to efficiently simulate an n X n array with unit link delays using slowdown $tilde O(dave^{2/3})$ on a two-dimensional array with average link delay $dave$.  Last, we present results for the case in which large local databases are involved in the computation.},
journal = {SIAM J. Comput.},
month = oct,
pages = {615–647},
numpages = {33},
keywords = {linear and two-dimensional arrays, complementary slackness, parallel and distributed computation, hiding latency}
}

@article{10.5555/333115.333127,
author = {K\"{a}rkk\"{a}inen, Juha and Ukkonen, Esko},
title = {Two- and Higher-Dimensional Pattern Matching in Optimal Expected Time},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {Algorithms with optimal expected running time are presented for searching the occurrences of a two-dimensional m X m pattern P in a two-dimensional n X n text T over an alphabet of size c. The algorithms are based on placing in the text a static grid of test points, determined only by n, m, and c (not dynamically by earlier test results). Using test strings read from the test points the algorithms eliminate as many potential occurrences of P as possible. The remaining potential occurrences are separately checked for actual occurrences. A suitable choice of the test point set leads to algorithms with expected running time O(n2logc m2/m2) using the uniform Bernoulli model of randomness. This is shown to be optimal by a generalization of a one-dimensional lower bound result by Yao. Experimental results show that the algorithms are efficient in practice, too. The method is also generalized for the k mismatches problem. The resulting algorithm has expected running time O(kn2logc m2/m2), provided that $kleq(mlfloor m/lceillog_c m^2rceilrfloor-1)/2$. All algorithms need preprocessing of P which takes time and space O(m2). The text processing can be done on-line, using a rather small window. The algorithms easily generalize to d-dimensional matching for any d.},
journal = {SIAM J. Comput.},
month = oct,
pages = {571–589},
numpages = {19},
keywords = {multidimensional matching, approximate matching, average case analysis}
}

@article{10.5555/333115.333125,
author = {Arkin, Esther M. and Chiang, Yi-Jen and Mitchell, Joseph S. B. and Skiena, Steven S. and Yang, Tae-Cheon},
title = {On the Maximum Scatter Traveling Salesperson Problem},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {We study the problem of computing a Hamiltonian tour (cycle) or path on a set of points in order to maximize the minimum edge length in the tour or path. This "maximum scatter" traveling salesperson problem (TSP) is closely related to the bottleneck TSP and is motivated by applications in manufacturing (e.g., sequencing of rivet operations) and medical imaging. In this paper, we give the first algorithmic study of these problems, including complexity results, approximation algorithms, and exact algorithms for special cases. In an attempt to model more accurately the real problems that arise in practice, we also generalize the basic problem to consider a more general measure of "scatter" in which points on a tour or path should be far not only from their immediate predecessor and successor, but also from other near-neighbors along the tour or path.},
journal = {SIAM J. Comput.},
month = oct,
pages = {515–544},
numpages = {30},
keywords = {traveling salesperson problem, Posa conjecture, Hamiltonian cycle/path, traveling salesman problem, Dirac's theorem, maximum scatter TSP, optimization, matching, bottleneck TSP, approximation algorithms}
}

@article{10.5555/333115.333124,
author = {Karger, David R.},
title = {A Randomized Fully Polynomial Time Approximation Scheme for the All-Terminal Network Reliability Problem},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability. The goal is to determine the probability that the network becomes disconnected due to edge failures.  This problem has obvious applications in the design of communication networks.  Since the problem is $SP$-complete and thus believed hard to solve exactly, a great deal of research has been devoted to  estimating the failure probability.  In this paper, we give a  fully polynomial randomized approximation scheme that, given any n-vertex graph with specified failure probabilities, computes in time polynomial in n and $1/epsilon$ an estimate for the failure probability that is accurate to within a relative error of $1pmepsilon$ with high probability.  We also give a deterministic polynomial approximation scheme for the case of small failure probabilities.  Some extensions to evaluating probabilities of k-connectivity, strong connectivity in directed Eulerian graphs and r-way disconnection, and to evaluating the Tutte polynomial are also described.},
journal = {SIAM J. Comput.},
month = oct,
pages = {492–514},
numpages = {23},
keywords = {approximation scheme, minimum cut, network reliability}
}

@article{10.5555/333115.333122,
author = {Albers, Susanne},
title = {Better Bounds for Online Scheduling},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {We study a classical problem in online scheduling. A sequence of jobs must be scheduled on m identical parallel machines. As each job arrives, its processing time is known. The goal is to minimize the makespan. Bartal et al. [ J. Comput. System Sci., 51 (1995), pp. 359--366] gave a deterministic online algorithm that is 1.986-competitive. Karger, Phillips, and Torng  [ J. Algorithms, 20 (1996), pp. 400--430] generalized the algorithm and proved an upper bound of 1.945. The best lower bound currently known on the competitive ratio that can be achieved by deterministic online algorithms is equal to 1.837. In this paper we present an improved deterministic online scheduling algorithm that is 1.923-competitive; for all $mgeq 2$. The algorithm is based on a new scheduling strategy, i.e., it is not a generalization of the approach by Bartal  et al. Also, the algorithm has a simple structure. Furthermore, we develop a better lower bound. We prove that, for general m, no deterministic online scheduling algorithm can be better than 1.852-competitive.},
journal = {SIAM J. Comput.},
month = oct,
pages = {459–473},
numpages = {15},
keywords = {online algorithm, competitive analysis, makespan minimization}
}

@article{10.5555/333115.333120,
author = {Goodrich, Michael T.},
title = {Communication-Efficient Parallel Sorting},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
abstract = {We study the problem of sorting n numbers on a p-processor bulk-synchronous parallel (BSP) computer, which is a parallel multicomputer that allows for general processor-to-processor communication rounds provided each processor sends and receives at most h items in any round. We provide parallel sorting methods that use internal computation time that is $O({nlog n over p})$ and a number of communication rounds that is $O({log n over log (h+1)})$ for $h=Theta(n/p)$. The internal computation bound is optimal for any comparison-based sorting algorithm. Moreover, the number of communication rounds is bounded by a constant for the (practical) situations when $ple n^{1-{1/c}}$ for a constant $cge 1$. In fact, we show that our bound on the number of communication rounds is asymptotically optimal for the full range of values for p, for we show that just computing the "or" of n bits distributed evenly to the first O(n/h) of an arbitrary number of processors in a BSP computer requires $Omega(log n/log (h+1))$ communication rounds.},
journal = {SIAM J. Comput.},
month = oct,
pages = {416–432},
numpages = {17},
keywords = {parallel algorithms, parallel sorting, parallel processing}
}

@article{10.1137/S0097539798427156,
author = {Bruell, Steven C. and Ghosh, Sukumar and Karaata, Mehmet Hakan and Pemmaraju, Sriram V.},
title = {Self-Stabilizing Algorithms for Finding Centers and Medians of Trees},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798427156},
doi = {10.1137/S0097539798427156},
abstract = {Locating a center or a median in a graph is a fundamental graph-theoretic problem. Centers and medians are especially important in distributed systems because they are ideal locations for placing resources that need to be shared among different processes in a network. This paper presents simple self-stabilizing algorithms for locating centers and medians of trees. Since these algorithms are self-stabilizing, they can tolerate transient failures. In addition, they can automatically adjust to a dynamically changing tree topology. After the algorithms are presented, their correctness is proven and upper bounds on their time complexity are established. Finally, extensions of our algorithms to trees with arbitrary, positive edge costs are sketched.},
journal = {SIAM J. Comput.},
month = oct,
pages = {600–614},
numpages = {15},
keywords = {self-stabilization, distributed algorithm, tree, median, center}
}

@article{10.1137/S0097539798338175,
author = {Bubley, Russ and Dyer, Martin and Greenhill, Catherine and Jerrum, Mark},
title = {On Approximately Counting Colorings   of Small Degree Graphs},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798338175},
doi = {10.1137/S0097539798338175},
abstract = {We consider approximate counting of colorings of an n-vertex graph using rapidly mixing Markov chains. It has been shown by Jerrum and by Salas and Sokal that a simple random walk on graph colorings would mix rapidly, provided the number of colors k exceeded the maximum degree $Delta$ of the graph by a factor of at least 2.   We prove that this is not a necessary condition for rapid mixing by considering the simplest case of 5-coloring graphs of maximum degree 3. Our proof involves a computer-assisted proof technique to establish rapid mixing of a new "heat bath" Markov chain on colorings using the method of path coupling. We outline an extension to 7-colorings of triangle-free 4-regular graphs.  Since rapid mixing implies approximate counting in polynomial time, we show in contrast that exact counting is unlikely to be possible (in polynomial time). We give a general proof that the problem of exactly counting the number of proper k-colorings of graphs with maximum degree $Delta$ is $# P$-complete whenever $kgeq 3$ and $Delta geq 3$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {387–400},
numpages = {14},
keywords = {rapidly mixing Markov chains, graph colorings, transportation problems, approximate counting}
}

@article{10.1137/S0097539797327805,
author = {Buhrman, Harry and Li, Ming and Tromp, John and Vit\'{a}nyi, Paul},
title = {Kolmogorov Random Graphs and the Incompressibility Method},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797327805},
doi = {10.1137/S0097539797327805},
abstract = {We investigate topological, combinatorial, statistical, and enumeration properties of finite graphs with high Kolmogorov complexity (almost all graphs) using the novel incompressibility method. Example results are (i) the mean and variance of the number of (possibly overlapping) ordered labeled subgraphs of a labeled graph as a function of its randomness deficiency (how far it falls short of the maximum possible Kolmogorov complexity) and (ii) a new elementary proof for the number of unlabeled graphs.},
journal = {SIAM J. Comput.},
month = oct,
pages = {590–599},
numpages = {10},
keywords = {incompressibility method, algorithmic information theory, random graphs, enumeration of graphs, Kolmogorov complexity}
}

@article{10.1137/S0097539797323571,
author = {Downey, Rod G. and Fellows, Michael R. and Vardy, Alexander and Whittle, Geoff},
title = {The Parametrized Complexity of Some Fundamental Problems in Coding Theory},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797323571},
doi = {10.1137/S0097539797323571},
abstract = {The parametrized complexity of a number of fundamental problems in the theory of linear codes and integer lattices is explored. Concerning codes, the main results are that  MAXIMUM-LIKELIHOOD DECODING and WEIGHT DISTRUBUTION are hard for the parametrized complexity class W[1]. The NP-completeness of these two problems was established by Berlekamp, McEliece, and van Tilborg in 1978 using by means of a reduction from THREE-DIMENSIONAL MATCHING. On the other hand, our proof of hardness for W[1] is based on a parametric polynomial-time transformation from PERFECT CODE in graphs. An immediate consequence of our results is that bounded-distance decoding is likely to be hard for binary linear codes. Concerning lattices, we address the THETA SERIES problem of determining for an integer lattice $L$ %given by a set of generators, and a positive integer k whether there is a vector $x in L$ of Euclidean norm k. We prove here for the first time that THETA SERIES is NP-complete and show that it is also hard for W[1]. Furthermore, we prove that the NEAREST VECTOR problem for integer lattices is hard for W[1]. These problems are the counterparts of WEIGHT DISTRUBUTION and MAXIMUM-LIKELIHOOD DECODING for lattices. Relations between all these problems and combinatorial problems in graphs are discussed.},
journal = {SIAM J. Comput.},
month = oct,
pages = {545–570},
numpages = {26},
keywords = {linear codes, decoding, parametrized complexity, codes in graphs, integer lattices}
}

@article{10.1137/S0097539797322334,
author = {Eschen, Elaine and Hayward, Ryan B. and Spinrad, Jeremy and Sritharan, R.},
title = {Weakly Triangulated Comparability Graphs},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797322334},
doi = {10.1137/S0097539797322334},
abstract = {The class of weakly triangulated comparability graphs and their complements are generalizations of interval graphs and chordal comparability graphs. We show that problems on these classes of graphs can be solved efficiently by transforming them into problems on chordal bipartite graphs. We show that recognition and independent set on weakly triangulated comparability graphs can be solved in O(n2) time in this manner, and that the number of weakly triangulated comparability graphs is $2^{Theta ( n {{log}^2} n)}$.  We also give algorithms to compute transitive closure and transitive reduction in O(n2loglogn) time if the underlying undirected graph of the transitive closure is a weakly triangulated comparability graph.},
journal = {SIAM J. Comput.},
month = oct,
pages = {378–386},
numpages = {9},
keywords = {weakly triangulated, comparability, partial orders, algorithm}
}

@article{10.1137/S0097539796314240,
author = {Srinivasan, Aravind},
title = {Improved Approximation Guarantees for Packing and Covering Integer Programs},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796314240},
doi = {10.1137/S0097539796314240},
abstract = {Several important NP-hard combinatorial optimization problems can be posed as  packing/covering integer programs; the  randomized rounding technique of Raghavan and Thompson is a powerful tool with which to approximate them well. We present one elementary unifying property of all these integer linear programs and use the FKG correlation inequality to derive an improved analysis of randomized rounding on them. This yields a  pessimistic estimator, thus presenting deterministic polynomial-time algorithms for them with approximation guarantees that are significantly better than those known.},
journal = {SIAM J. Comput.},
month = oct,
pages = {648–670},
numpages = {23},
keywords = {packing integer programs, approximation algorithms, correlation inequalities, covering integer programs, positive correlation, integer programming, derandomization, linear programming, linear relaxations, randomized rounding, rounding theorems, combinatorial optimization}
}

@article{10.1137/S0097539796308710,
author = {Bhatt, Sandeep and Greenberg, David and Leighton, Tom and Liu, Pangfeng},
title = {Tight Bounds for On-Line Tree Embeddings},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796308710},
doi = {10.1137/S0097539796308710},
abstract = {Tree-structured computations are relatively easy to process in parallel.  As leaf processes are recursively spawned they can be assigned to independent processors in a multicomputer network. However, to achieve good performance the on-line mapping algorithm must maintain load balance, i.e., distribute processes equitably among processors.  Additionally, the algorithm itself must be distributed in nature, and process allocation must be completed via message-passing with minimal communication overhead.This paper investigates bounds on the performance of deterministic and randomized algorithms for on-line tree embeddings.  In particular, we study trade-offs between computation overhead (load imbalance) and communication overhead (message congestion).  We give a simple technique to derive lower bounds on the congestion that any on-line allocation algorithm must incur in order to guarantee load balance. This technique works for both randomized and deterministic algorithms. We prove that the advantage of randomization is limited.  Optimal bounds are achieved for several networks, including multidimensional grids and butterflies.},
journal = {SIAM J. Comput.},
month = oct,
pages = {474–491},
numpages = {18},
keywords = {graph embedding, randomized algorithm}
}

@article{10.1137/S0097539796300945,
author = {Rieger, J. H.},
title = {Proximity in Arrangements of Algebraic Sets},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796300945},
doi = {10.1137/S0097539796300945},
abstract = {Let X be an arrangement of n algebraic sets Xi in d-space, where the Xi are either parametrized or zero-sets of dimension $0le m_ile d-1$. We study a number of decompositions of d-space into connected regions in which the distance-squared function to X has certain invariances. Each region is contained in a single connected component of the complement of the bifurcation set $cB$ of the family of distance-squared functions or of certain subsets of $cB$. The decompositions can be used in the following proximity problems: given some point, find the k nearest sets Xi in the arrangement, find the nearest point in X, or (assuming that X is compact) find the farthest point in X and hence the smallest enclosing $(d-1)$-sphere. We give bounds on the complexity of the decompositions in terms of n, d, and the degrees and dimensions of the algebraic sets Xi.},
journal = {SIAM J. Comput.},
month = oct,
pages = {433–458},
numpages = {26},
keywords = {$k$ nearest points, critical points, Voronoi regions, symbolic computation, bifurcation sets}
}

@article{10.1137/S0097539795294979,
author = {Chor, Benny and Nelson, Lee-Bath},
title = {Solvability in Asynchronous Environments II: Finite Interactive Tasks},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795294979},
doi = {10.1137/S0097539795294979},
abstract = {Identifying what problems can be solved in a given distributed system is a central question in distributed computing. In this series of works, we study this question in the context of asynchronous fault tolerant systems that can execute consensus. These systems can be those executing deterministic protocols with access to a consensus routine or those running randomized error-free protocols. A previous work handled the class of distributed decision tasks. In these tasks,  each processor receives one local input and has to respond with one local output.  In an  interactive distributed task each of n processors receives a sequence of local inputs and has to respond  on line with an output for every new input (before getting its next input). Different processors can be at different stages concurrently, so that additional inputs are received by fast processors while slow processors are still working on early inputs. An interactive task is called finite if the number of local inputs (and outputs) is finite. Interactive tasks can neither be described as a single huge decision task nor be decomposed into distinct, independent decision tasks.  The main result of this work is an exact characterization of the finite interactive tasks which can be solved by t-resilient protocols in either of the above two models. The major tool we use in the characterization is a directed acyclic graph that is associated with an interactive task. Properties of this graph are used to determine the resiliency of the task and to devise a "generic" resilient algorithm which solves such tasks. This generic algorithm can be viewed as a repeated, deterministic reduction to a consensus subroutine. This implies that any finite interactive task is solvable by randomized error-free protocols iff it is solvable by deterministic protocols with access to consensus.},
journal = {SIAM J. Comput.},
month = oct,
pages = {351–377},
numpages = {27},
keywords = {fault tolerance, asynchronous distributed systems, consensus, randomized algorithms, interactive tasks, decision tasks, solvability, adversary scheduler}
}

@article{10.1137/S009753979528175X,
author = {Bellantoni, Stephen J. and Niggl, Karl-Heinz},
title = {Ranking Primitive Recursions: The Low Grzegorczyk Classes Revisited},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979528175X},
doi = {10.1137/S009753979528175X},
abstract = {Traditional results in subrecursion theory are integrated with the recent work in "predicative recursion" by defining a simple ranking $rho$ of all primitive recursive functions. The hierarchy defined by this ranking coincides with the Grzegorczyk hierarchy at and above the linear-space level. Thus, the result is like an extension of the Schwichtenberg--M\"{u}ller theorems. When primitive recursion is replaced by recursion on notation, the same series of classes is obtained except with the polynomial time computable functions at the first level.},
journal = {SIAM J. Comput.},
month = oct,
pages = {401–415},
numpages = {15},
keywords = {polynomial time, computational complexity, ramified recursion, subrecursion, linear space, Heinermann classes, predicativity}
}

@article{10.1137/S0097539797324308,
author = {Chen, Weimin and Turau, Volker},
title = {On Regular Tree Embeddings},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797324308},
doi = {10.1137/S0097539797324308},
abstract = {Regular trees are a natural extension of finite trees, which have many applications. The path-embedding problem is to determine whether a regular tree S can be obtained from another regular tree T by deleting (probably infinitely many) subtrees of T.  This paper explores efficient algorithms for the path-embedding problem in ordered and unordered trees.  Given two regular trees S and T represented by rational graphs, our algorithms solve the ordered version of path-embedding problem in O(|E_S||E_T|) time and the unordered version in O(|ES||ET|DSDT) time. Here |ES| denotes the number of edges in the rational graph for S, and DS denotes the maximum outdegree of a vertex inS. We also demonstrate that our approach can be applied to pattern matching problems for regular trees recently studied by Fu  J. Algorithms, 22 (1997), pp. 372--391].},
journal = {SIAM J. Comput.},
month = sep,
pages = {288–301},
numpages = {14},
keywords = {regular trees, directed graph pattern matching, embedding, boolean equations}
}

@article{10.1137/S0097539797323716,
author = {Bertram-Kretzberg, Claudia and Lefmann, Hanno},
title = {The Algorithmic Aspects of Uncrowded Hypergraphs},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797323716},
doi = {10.1137/S0097539797323716},
abstract = {We consider the problem of finding deterministically a large independent set of guaranteed size in a hypergraph on n vertices and with m edges. With respect to the Tur\'{a}n bound, the quality of our solutions is better for hypergraphs with not too many small cycles by a logarithmic factor in the input size. The algorithms are fast; they often have a running time of O(m) + o(n3). Indeed, the denser the hypergraphs are the closer the running times are to the linear times. For the first time, this gives for some combinatorial problems algorithmic solutions with state-of-the-art quality, solutions of which only the existence was known to date. In some cases, the corresponding upper bounds match the lower bounds up to constant factors.  The involved concepts are uncrowded hypergraphs.},
journal = {SIAM J. Comput.},
month = sep,
pages = {201–230},
numpages = {30},
keywords = {independence number, approximation algorithm}
}

@article{10.1137/S0097539797323108,
author = {Anily, Shoshana and Gendreau, Michel and Laporte, Gilbert},
title = {The Swapping Problem on a Line},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797323108},
doi = {10.1137/S0097539797323108},
abstract = {We consider the problem of optimally swapping objects between N workstations, which we refer to as nodes, located on a line. There are m types of objects, and the set of object-types is denoted by S = {1, ..., m}. Object-type 0 is a dummy type, the null object. Each node v contains one unit of a certain object-type $a_v in S cup {0}$ and requires one unit of object-type $b_v in S cup {0}$. We assume that the total supply equals the total demand for each of the object-types separately. A vehicle of unit capacity ships the objects so that the requirements of all nodes are satisfied. The set of object-types is partitioned into two sets: objects that may be temporarily dropped at intermediate nodes before reaching their destination and objects that have to be shipped directly from their origin to their destination. The objective is to design a route that starts and ends at the depot and a feasible assignment of object-types to the route's arcs so that the total distance is minimized. We propose an O(N 2) algorithm to compute the optimal solution for this problem.},
journal = {SIAM J. Comput.},
month = sep,
pages = {327–335},
numpages = {9},
keywords = {transshipment problem, the swapping problem}
}

@article{10.1137/S0097539797322255,
author = {He, Xin and Chen, Zhi-Zhong},
title = {An Algorithm for Shortest Paths in Bipartite Digraphs with Concave Weight Matrices  and Its Applications},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797322255},
doi = {10.1137/S0097539797322255},
abstract = {The traveling salesman problem on an n-point convex polygon and the minimum latency tour problem for n points on a straight line are two basic problems in graph theory and have been studied in the past. Previously, it was known that both problems can be solved in O(n2) time. However, whether they can be solved in o(n2)  time was left open by Marcotte and Suri [SIAM J. Comput., 20 (1991), pp. 405--422] and Afrati et al. [Informatique Theorique Appl., 20 (1986), pp. 79--87], respectively. In this paper we show that both problems can be solved in O(n log n) time by reducing them to the following problem: Given an edge-weighted complete bipartite digraph G=(X, Y, E) with X={x0, . . ., xn} and Y={y0, . . ., ym}, we wish to find the shortest path from x0 to xn in G. This new problem requires $Omega(nm)$ time to solve in general, but we show that it can be solved in O(n + m log n) time if the weight matrices A and B of G are both concave, where for $0leq ileq n$ and $0leq jleq m$, A[i,j] and B[j,i] are the weights of the edges (xi, yj) and (yj, xi) in G, respectively. As demonstrated in this paper, the new problem is a powerful tool and we believe that it can be used to solve more problems.},
journal = {SIAM J. Comput.},
month = sep,
pages = {65–80},
numpages = {16},
keywords = {shortest path, concave matrix, graph algorithm, traveling salesman problem, minimum latency tour problem}
}

@article{10.1137/S0097539797322140,
author = {Marcinkowski, Jerzy},
title = {Achilles, Turtle, and Undecidable Boundedness Problems for Small DATALOG Programs},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797322140},
doi = {10.1137/S0097539797322140},
abstract = {DATALOG is the language of logic programs without function symbols. It is considered to be the paradigmatic database query language. If it is possible to eliminate recursion from a DATALOG program then it is  bounded . Since bounded programs can be executed in parallel constant time, the possibility of automatized boundedness detecting is believed to be an important issue and has been studied in many papers. Boundedness was proved to be undecidable for different kinds of semantical assumptions and syntactical restrictions. Many different proof techniques were used. In this paper we propose a uniform proof method based on the discovery of, as we call it, the Achilles--Turtle machine, and make strong improvements on most of the known undecidability results. In particular we solve the famous open problem of Kanellakis showing that uniform boundedness is undecidable for single rule programs (called also  sirups ).This paper is the full version of [J. Marcinkowski,  Proc. 13  th STACS , Lecture Notes in Computer Science 1046, pp. 427--438], and [J. Marcinkowski, 11  th IEEE Symposium on Logic in Computer Science , pp. 13--24].},
journal = {SIAM J. Comput.},
month = sep,
pages = {231–257},
numpages = {27},
keywords = {DATALOG, query optimization, decidability}
}

@article{10.1137/S0097539797321481,
author = {Karloff, Howard},
title = {How Good is the Goemans--Williamson MAX CUT Algorithm?},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797321481},
doi = {10.1137/S0097539797321481},
abstract = {The celebrated semidefinite programming algorithm for MAX CUT introduced by Goemans and Williamson was known to have a performance ratio of at least $\alpha=\frac 2 {\pi} \min_{0<\theta\le \pi} \frac \theta {1-\cos \theta}$ ($0.87856<\alpha<0.87857$); the exact performance ratio was unknown. We prove that the performance ratio of their algorithm is exactly $\alpha$. Furthermore, we show that it is impossible to add valid linear constraints to improve the performance ratio.},
journal = {SIAM J. Comput.},
month = sep,
pages = {336–350},
numpages = {15},
keywords = {optimization, approximation algorithm, MAX CUT, semidefinite programming}
}

@article{10.1137/S0097539796324636,
author = {Bonet, Maria and Phillips, Cynthia and Warnow, Tandy and Yooseph, Shibu},
title = {Constructing Evolutionary Trees in the Presence of Polymorphic Characters},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796324636},
doi = {10.1137/S0097539796324636},
abstract = {Most phylogenetics literature and construction methods based upon characters presume monomorphism (one state per character per species), yet polymorphism (multiple states per character per species) is well documented in both biology and historical linguistics.  In this paper we consider the problem of inferring evolutionary trees for polymorphic characters.  We show efficient algorithms for the construction of perfect phylogenies from polymorphic data.  These methods have been used to help construct the evolutionary tree proposed by Warnow, Ringe, and Taylor for the Indo-European family of languages and presented by invitation at the National Academy of Sciences in November 1995.},
journal = {SIAM J. Comput.},
month = sep,
pages = {103–131},
numpages = {29},
keywords = {algorithms, graphs, evolutionary trees}
}

@article{10.1137/S0097539796305298,
author = {Leighton, Tom and Ma, Yuan},
title = {Tight Bounds on the Size of Fault-Tolerant Merging and Sorting Networks with Destructive Faults},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796305298},
doi = {10.1137/S0097539796305298},
abstract = {We study networks that can sort  n,  items even when a large number of the comparators in the network are faulty. We restrict our attention to networks that consist of registers, comparators, and replicators. (  Replicators  are used to copy an item from one register to another, and they are assumed to be fault free.) We consider the scenario of both random and worst-case comparator faults, and we follow the general model of  destructive  comparator failure proposed by Assaf and Upfal [  Proc.  31  st IEEE Symposium on Foundations of Computer Science , St. Louis, MO, 1990, pp. 275--284] in which the two outputs of a faulty comparator can fail independently of each other. In the case of random faults, Assaf and Upfal showed how to construct a network with  O (  n  log2  n ) comparators that (with high probability) can sort  n  items even if a constant fraction of the comparators are faulty. Whether the bound on the number of comparators can be improved (to, say,  O (  n  log  n )) for sorting (or merging) has remained an interesting open question. We resolve this question in this paper by proving that any  n -item sorting or merging network which can tolerate a constant fraction of random failures has $Omega(n log^2 n)$ comparators.In the case of worst-case faults, we show that $Omega(kn log n)$ comparators are necessary to construct a sorting or merging network that can tolerate up to  k  worst-case faults. We also show that this bound is tight for  k  =  O (log  n ). The lower bound is particularly significant since it formally proves that the cost of being tolerant to worst-case failures is very high. Both the lower bound for random faults and the lower bound for worst-case faults are the first nontrivial lower bounds on the size of a fault-tolerant sorting or merging network.},
journal = {SIAM J. Comput.},
month = sep,
pages = {258–273},
numpages = {16},
keywords = {lower bounds, comparator networks, sorting, fault-tolerance, circuits, probabilistic analysis of algorithms, merging}
}

@article{10.1137/S0097539796303123,
author = {Szkaliczki, Tibor},
title = {Routing with Minimum Wire Length in the Dogleg-Free Manhattan Model is $\cal NP$-Complete},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796303123},
doi = {10.1137/S0097539796303123},
abstract = {The  present  article  concentrates  on  the dogleg-free Manhattan model where horizontal  and  vertical  wire  segments  are positioned on different sides of the board and each net  (wire)  has at most one horizontal segment. While the minimum width can be found in linear time in the single row routing, apparently there  was  no  efficient algorithm to find the minimum wire length. We show that there is  no hope to find such an algorithm because this problem  is  ${cal NP}$-complete even if each  net  has only  two  terminals.  The  results  on dogleg-free  Manhattan  routing  can   be   connected   with   other application areas related to  interval  graphs.  In  this  paper  we define the minimum value interval placement problem. There is  given a set of weighted intervals and $w$ rows and the intervals have to  be placed without overlapping into rows so that  the  sum  of the interval values, which is the value of a function of the weight and  the  row number assigned to the interval,  is  minimum.  We  show  that  this problem is ${cal NP}$-complete. This implies the  ${cal NP}$-completeness  of other problems including the minimum wire length routing and the sum coloring on interval graphs.},
journal = {SIAM J. Comput.},
month = sep,
pages = {274–287},
numpages = {14},
keywords = {single row routing, $cal NP$-complete problems, interval graph, VLSI, minimum wire length}
}

@article{10.1137/S0097539796302269,
author = {Breutzmann, Josef M. and Lutz, Jack H.},
title = {Equivalence of Measures of Complexity Classes},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796302269},
doi = {10.1137/S0097539796302269},
abstract = {The resource-bounded measures of complexity classes are shown to be robust with respect to certain changes in the underlying probability measure. Specifically, for any real number $delta &gt; 0$, any uniformly polynomial-time computable sequence $mv{beta} = (beta_0, beta_1, beta_2, ldots )$ of real numbers (biases) $beta_i in [delta, 1-delta]$, and for any complexity class ${bf cal C}$ (such as P, NP, BPP, P/Poly, PH, PSPACE, etc.) that is closed under positive, polynomial-time, truth-table reductions with queries of at most linear length, it is shown that the following two conditions are equivalent. (1) ${bf cal C}$ has p-measure 0 (respectively, measure 0 in E, measure 0 in E 2) relative to the coin-toss probability measure given by the sequence ${mv{beta}}$. (2) ${bf cal C}$ has p-measure 0 (respectively, measure 0 in E, measure 0 in E 2) relative to the uniform probability measure. The proof introduces three techniques that may be useful in other contexts, namely, (i) the transformation of an efficient martingale for one probability measure into an efficient martingale for a "nearby" probability measure; (ii) the construction of a positive bias reduction, a truth-table reduction that encodes a positive, efficient, approximate simulation of one bias sequence by another; and (iii) the use of such a reduction to dilate an efficient martingale for the simulated probability measure into an efficient martingale for the simulating probability measure.},
journal = {SIAM J. Comput.},
month = sep,
pages = {302–326},
numpages = {25},
keywords = {resource-bounded measure, complexity classes, martingales}
}

@article{10.1137/S0097539795292208,
author = {Ghosh, Bhaskar and Leighton, F. T. and Maggs, Bruce M. and Muthukrishnan, S. and Plaxton, C. Greg and Rajaraman, R. and Richa, Andr\'{e}a W. and Tarjan, Robert E. and Zuckerman, David},
title = {Tight Analyses of Two Local Load Balancing Algorithms},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795292208},
doi = {10.1137/S0097539795292208},
abstract = {This paper presents an analysis of the following load balancing algorithm.  At each step, each node in a network examines the number of tokens at each of its neighbors and sends a token to each neighbor with at least 2d+1 fewer tokens, where d is the maximum degree of any node in the network.  We show that within $O(Delta / alpha)$ steps, the algorithm reduces the maximum difference in tokens between any two nodes to at most $O((d^2 log n)/alpha)$, where $Delta$ is the global imbalance in tokens (i.e., the maximum difference between the number of tokens at any node initially and the average number of tokens), n is the number of nodes in the network, and $alpha$ is the edge expansion of the network.  The time bound is tight in the sense that for any graph with edge expansion $alpha$, and for any value $Delta$, there exists an initial distribution of tokens with imbalance $Delta$ for which the time to reduce the imbalance to even $Delta/2$ is at least $Omega(Delta/alpha)$.  The bound on the final imbalance is tight in the sense that there exists a class of networks that can be locally balanced everywhere (i.e., the maximum difference in tokens between any two neighbors is at most 2d), while the global imbalance remains $Omega((d^2 log n) / alpha)$. Furthermore, we show that upon reaching a state with a global imbalance of $O((d^2 log n)/alpha)$, the time for this algorithm to locally balance the network can be as large as $Omega(n^{1/2})$.  We extend our analysis to a variant of this algorithm for dynamic and asynchronous networks. We also present tight bounds for a randomized algorithm in which each node sends at most one token in each step.},
journal = {SIAM J. Comput.},
month = sep,
pages = {29–64},
numpages = {36},
keywords = {load balancing, distributed network algorithms}
}

@article{10.1137/S0097539795288490,
author = {Azar, Yossi and Broder, Andrei Z. and Karlin, Anna R. and Upfal, Eli},
title = {Balanced Allocations},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795288490},
doi = {10.1137/S0097539795288490},
abstract = {Suppose that we sequentially place $n$ balls into n boxes by putting each ball into a randomly chosen box.  It is well known that when we are done, the fullest box has with high probability (1 + o(1))ln n/ln ln n balls in it.  Suppose instead that for each ball we choose two boxes at random and place the ball into the one which is less full at the time of placement.  We show that with high probability, the fullest box contains only ln ln n/ln 2 + O(1) balls---exponentially less than before.  Furthermore, we show that a similar gap exists in the infinite process, where at each step one ball, chosen uniformly at random, is deleted,  and one ball is added in the manner above. We discuss consequences of this and related theorems for dynamic resource allocation, hashing, and on-line load balancing.},
journal = {SIAM J. Comput.},
month = sep,
pages = {180–200},
numpages = {21},
keywords = {occupancy problems, on-line algorithms, load balancing, urn models, resource allocation, hashing}
}

@article{10.1137/S009753979528682X,
author = {Bertsch, Eberhard and Nederhof, Mark-Jan},
title = {Regular Closure of Deterministic Languages},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979528682X},
doi = {10.1137/S009753979528682X},
abstract = {We recall the notion of regular closure of classes of languages. We present two important results. The first result is that all languages which are in the regular closure of the class of deterministic (context-free) languages can be recognized in linear time. This is a nontrivial result, since this closure contains many inherently ambiguous languages. The second result is that the class of deterministic languages is contained in the closure of the class of deterministic languages with the prefix property or, stated in an equivalent way, all LR(k) languages are in the regular closure of the class of LR(0) languages.},
journal = {SIAM J. Comput.},
month = sep,
pages = {81–102},
numpages = {22},
keywords = {regular languages, context-free languages}
}

@article{10.1137/S0097539794271692,
author = {Garg, Naveen and Saran, Huzur and Vazirani, Vijay V.},
title = {Finding Separator Cuts in Planar Graphs within Twice the Optimal},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794271692},
doi = {10.1137/S0097539794271692},
abstract = {A factor 2 approximation algorithm for the problem of finding a minimum-cost b-balanced cut in planar graphs is presented, for $b leq {1 over 3}$. We assume that the vertex weights are given in unary; for the case of binary vertex weights, a pseudoapproximation algorithm is presented. This problem is of considerable practical significance, especially in VLSI design.The natural algorithm for this problem accumulates sparsest cuts iteratively. One of our main ideas is to give a definition of sparsity, called  net-sparsity, that reflects precisely the cost of the cuts accumulated by this algorithm. However, this definition is too precise: we believe it is NP-hard to compute a minimum--net-sparsity cut, even in planar graphs. The rest of our machinery is built to work with this definition and still make it computationally feasible. Toward this end, we use several ideas from the works of Rao [ Proceedings, 28th Annual IEEE Symposium on Foundations of Computer Science, 1987, pp. 225--237;  Proceedings, 24th Annual ACM Symposium on Theory of Computing, 1992, pp. 229--240] and Park and Phillips [ Proceedings, 25th Annual ACM Symposium on Theory of Computing, 1993, pp. 766--775].},
journal = {SIAM J. Comput.},
month = sep,
pages = {159–179},
numpages = {21},
keywords = {separators, planar graphs, approximation algorithms}
}

@article{10.1137/S0097539793304741,
author = {Emerson, E. Allen and Jutla, Charanjit S.},
title = {The Complexity of Tree Automata and Logics of Programs},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793304741},
doi = {10.1137/S0097539793304741},
abstract = {The complexity of testing nonemptiness of finite state automata on infinite trees is investigated. It is shown that for tree automata with the pairs (or complemented pairs) acceptance condition having m states and n pairs, nonemptiness can be tested in deterministic time (mn)O(n); however, it is shown that the problem is in general NP-complete (or co-NP-complete, respectively). The new nonemptiness algorithm yields exponentially improved, essentially tight upper bounds for numerous important modal logics of programs, interpreted with the usual semantics over structures generated by binary relations. For example, it follows that satisfiability for the full branching time logic CTL* can be tested in deterministic double exponential time. Another consequence is that satisfiability for propositional dynamic logic (PDL) with a repetition construct (PDL-delta) and for the propositional Mu-calculus ($Lmu$) can be tested in deterministic single exponential time.},
journal = {SIAM J. Comput.},
month = sep,
pages = {132–158},
numpages = {27},
keywords = {complexity, games, logics of programs, tree automata}
}

@article{10.1137/S0097539792230010,
author = {Feige, Uriel and Lapidot, Dror and Shamir, Adi},
title = {Multiple NonInteractive Zero Knowledge Proofs    Under General Assumptions},
year = {1999},
issue_date = {Feb. 2000},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {29},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792230010},
doi = {10.1137/S0097539792230010},
abstract = {In this paper we show how to construct noninteractive zero knowledge proofs for any NP statement under general (rather than number theoretic) assumptions, and how to enable polynomially many provers to give polynomially many such proofs based on a single random string. Our constructions can be used in cryptographic applications in which the prover is restricted to polynomial time.},
journal = {SIAM J. Comput.},
month = sep,
pages = {1–28},
numpages = {28},
keywords = {witness indistinguishability, Hamiltonian cycle}
}

@article{10.1137/S0097539797327118,
author = {Leoncini, Mauro and Manzini, Giovanni and Margara, Luciano},
title = {Parallel Complexity of Numerically Accurate Linear System Solvers},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797327118},
doi = {10.1137/S0097539797327118},
abstract = {We prove a number of negative results about practical (i.e., work efficient and numerically accurate) algorithms for computing the main matrix factorizations. In particular, we prove that the popular Householder and Givens methods for computing the QR decomposition are P-complete, and hence presumably inherently sequential, under both real and floating point number models. We also prove that Gaussian elimination (GE) with a weak form of pivoting, which aims only at making the resulting algorithm nondegenerate, is likely to be inherently sequential as well. Finally, we prove that GE with partial pivoting is P-complete over GF(2) or when restricted to symmetric positive definite matrices, for which it is known that even standard GE (no pivoting) does not fail. Altogether, the results of this paper give further formal support to the widespread belief that there is a tradeoff between parallelism and accuracy in numerical algorithms.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2030–2058},
numpages = {29},
keywords = {numerical stability, parallel complexity, inherently sequential algorithms, matrix factorization, NC algorithms, P-complete problems}
}

@article{10.1137/S0097539797326307,
author = {Anderson, Richard J.},
title = {Tree Data Structures for <i>N</i>-Body Simulation},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797326307},
doi = {10.1137/S0097539797326307},
abstract = {In this paper, we study data structures for use in N-body simulation. We concentrate on the spatial decomposition tree used in particle-cluster force evaluation algorithms such as the Barnes--Hut algorithm.  We prove that a k-d tree is asymptotically inferior to a spatially balanced tree.  We show that the worst case complexity of the force evaluation algorithm using a k-d tree is $Theta(nlog^3nlog L)$ compared with $Theta(nlog L)$ for an oct-tree.  (L is the separation ratio of the set of points.)We also investigate improving the constant factor of the algorithm and present several methods which improve over the standard oct-tree decomposition.  Finally, we consider whether or not the bounding box of a point set should be "tight" and show that it is safe to use tight bounding boxes only for binary decompositions.  The results are all directly applicable to practical implementations of N-body algorithms.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1923–1940},
numpages = {18},
keywords = {it N-body simulation, spatial data structures, Barnes--Hut algorithm}
}

@article{10.1137/S0097539797325636,
author = {Andreev, Alexander E. and Clementi, Andrea E. F. and Rolim, Jos\'{e} D. P. and Trevisan, Luca},
title = {Weak Random Sources, Hitting Sets, and BPP Simulations},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797325636},
doi = {10.1137/S0097539797325636},
abstract = {We show how to simulate any BPP algorithm in polynomial time by using a weak random source of r bits and min-entropy $r^{gamma}$ for any $gamma &gt;0$. This follows from a more general result about  sampling with weak random sources. Our result matches an information-theoretic lower bound and solves a question that has been open for some years. The previous best results were a polynomial time simulation of RP [M. Saks, A. Srinivasan, and S. Zhou,  Proc. 27th ACM Symp. on Theory of Computing, 1995, pp. 479--488] and a quasi-polynomial time simulation of BPP [A. Ta-Shma,  Proc. 28th ACM Symp. on Theory of Computing, 1996, pp. 276--285].Departing significantly from previous related works, we do not use  extractors; instead, we use the OR-disperser of Saks, Srinivasan, and  Zhou in combination with a tricky use of hitting sets borrowed  from [Andreev, Clementi, and Rolim,  J. ACM, 45 (1998), pp. 179--213].},
journal = {SIAM J. Comput.},
month = aug,
pages = {2103–2116},
numpages = {14},
keywords = {imperfect sources of randomness, randomized computations, derandomization, hitting sets, expander graphs}
}

@article{10.1137/S0097539797324291,
author = {Reif, John H.},
title = {Approximate Complex Polynomial Evaluation in Near Constant Work Per Point},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797324291},
doi = {10.1137/S0097539797324291},
abstract = {Given the n complex coefficients of a degree n-1 complex polynomial, we wish to evaluate the polynomial at a large number $m ge n$ of points on the complex plane. This problem is required by many algebraic computations and so is considered in most basic algorithm texts (e.g., [A. V. Aho, J. E. Hopcroft, and J. D. Ullman, The Design and Analysis of Computer Algorithms, Addison-Wesley, 1974]). We assume an arithmetic model of computation, where on each step we can execute an arithmetic operation, which is computed exactly. All previous exact algorithms [C. M. Fiduccia, Proceeding 4 th Annual ACM Symposium on Theory of Computing, 1972, pp. 88--93; H. T. Kung, Fast Evaluation and Interpolation, Carnegie-Mellon, 1973; A. B. Borodin and I. Munro, The Computational Complexity of Algebraic and Numerical Problems, American Elsevier, 1975; V. Pan, A. Sadikou, E. Landowne, and O. Tiga, Comput. Math. Appl., 25 (1993), pp. 25--30] cost at least work $Omega(log^2 n)$ per point, and previously, there were no known approximation algorithms for complex polynomial evaluation within the unit circle with work bounds better than the fastest known exact algorithms. There are known approximation algorithms [V. Rokhlin, J. Complexity, 4 (1988), pp. 12--32; V. Y. Pan, J. H. Reif, and S. R. Tate, in Proceedings 32 nd Annual IEEE Symposium on Foundations of Computer Science, 1992, pp. 703--713] for polynomial evaluation at real points, but these do not extend to evaluation at general points on the complex plane. We provide approximation algorithms for complex polynomial evaluation that cost, in many cases, near constant amortized work per point. Let $k = log(|P|/epsilon)$, where |P| is the sum of the moduli of the coefficients of the input polynomial P(z). Let {it ${tilde{P}}(z_j)$ be an $epsilon$-approx of $P(z)$} if $epsilon$ upper bounds the modulus of the error of the approximation ${tilde{P}}(z_j)$ at each evaluation point zj, that is, $|P(z_j)-{tilde{P}}(z_j)| le epsilon;$ note that $epsilon$ is an absolute error bound rather than a relative error bound. In many applications (particularly in signal processing) the evaluation points zj are fixed and require only polylogarithmic $k = log(|P|/epsilon) = O(log^{O(1)} n)$; for these cases we get a surprising reduction in work by use of approximation algorithms, as compared to the fastest known exact algorithms. We $epsilon$-approx complex degree n-1 polynomial evaluation at $m ge nlog n/log^2 k $ fixed points on or within the unit disk in the complex plane in amortized work O(log2 k) per point, which is O(log2 log n) for polylogarithmic k. If the m points are not fixed, then we have increased amortized work O(log2 k + log m) per point, which is O(log m) for polylogarithmic k and $m ge nlog n/log k,$ and is still substantially below the previous bound of $Omega(log^2 m)$ for known exact algorithms. We further reduce our amortized bounds for special sets of evaluation points widely used in signal processing applications. The chirp transform is equivalent to evaluating a complex degree n-1 polynomial at the chirp points, which are $zeta^j, j = 0,dots,m-1$, for some fixed complex number $zeta.$ We $epsilon$-approx complex degree $n-1$ polynomial evaluation at these $m$ chirp points, where $m ge n log n/log^2 k$ and $|zeta| le 1$ % or (ii) $m ge n$ and $|zeta| le $ a function that limits to $1$ %for %$k = o(n)$ and large $n$) in amortized work O(log k) per point, whereas the previous best bounds for exact evaluation (via the chirp transform) were $Omega(log m)$ per point [A. V. Aho, K. Steiglitz, and J. D. Ullman, SIAM J. Comput., 4 (1975), pp. 533--539]. Using instead a reduction to approximate real polynomial evaluation (by interpolation at the Chebyshev points), in total work O(n log k), we $epsilon$-approx the evaluation of a degree n polynomial at the first n powers of the n' th root of unity, where $n' ge Omega(n^2/k), $ and $epsilon$-approx the n -point DFT for certain inputs with descending coefficient magnitude. All of our results require polylogarithmic (that is, logO(1)n)depth with the same work bounds.We also provide a lower bound for a wide class of schemes for approximate evaluation of a degree n-1 polynomial on the unit circle; namely, we prove that if a scheme uses an approximation polynomial of degree k-1, then it can be convergent only over a small fraction O(k/n) of the unit circle. We believe this is the first lower bound of this sort proved, and the proof uses an interesting reduction to the approximation of a matrix product by a matrix of reduced rank.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2059–2089},
numpages = {31},
keywords = {algebraic computation, approximate algorithm, discrete Fourier transform (DFT), multipoint polynomial evaluation, complex plane, fast Fourier transform (FFT)}
}

@article{10.1137/S009753979731858X,
author = {Ben-Asher, Yosi and Farchi, Eitan and Newman, Ilan},
title = {Optimal Search in Trees},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979731858X},
doi = {10.1137/S009753979731858X},
abstract = {It is well known that the optimal solution for searching in a finite total order set is binary search. In binary search we divide the set into two "halves" by querying the middle element and continue the search on the suitable half. What is the equivalent of binary search when the set P is partially ordered? A query in this case is to a point $xin P$, with two possible answers: "yes" indicates that the required element is "below" x or "no" if the element is not below x. We show that the problem of computing an optimal strategy for search in posets that are tree-like (or forests) is polynomial in the size of the tree and requires at most O(n4 log3 n) steps.  Optimal solutions of such search problems are often needed in program testing and debugging, where a given program is represented as a tree and a bug should be found using a minimal set of queries. This type of search is also applicable in searching classified large tree-like databases (e.g., the Internet).},
journal = {SIAM J. Comput.},
month = aug,
pages = {2090–2102},
numpages = {13},
keywords = {binary search, optimal search, posets, search in trees, search in graphs}
}

@article{10.1137/S0097539797317263,
author = {Alstrup, Stephen and Harel, Dov and Lauridsen, Peter W. and Thorup, Mikkel},
title = {Dominators in Linear Time},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797317263},
doi = {10.1137/S0097539797317263},
abstract = {A linear-time algorithm is presented for finding dominators in control flow graphs.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2117–2132},
numpages = {16},
keywords = {dominators, algorithms, control flow analysis}
}

@article{10.1137/S0097539797316622,
author = {Brouwer, A. E.},
title = {An Associative Block Design ABD(8,5)},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797316622},
doi = {10.1137/S0097539797316622},
abstract = {An associative block design is a certain balanced partition of a hypercube into smaller hypercubes. We construct such a design, thus settling the smallest open case.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1970–1971},
numpages = {2},
keywords = {feedback vertex set, tournament, min-max relation, approximation algorithm}
}

@article{10.1137/S0097539796308874,
author = {He, Xin},
title = {On Floor-Plan of Plane Graphs},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796308874},
doi = {10.1137/S0097539796308874},
abstract = {A floor-plan is a rectangle partitioned into a set of disjoint rectilinear polygonal regions (called  modules). A floor-plan F represents a plane graph G as follows: Each vertex of G corresponds to a module of F and two vertices are adjacent in G iff their corresponding modules share a common boundary. Floor-plans find applications in VLSI chip design.If a module M is a union of k disjoint rectangles, M is called a k-rectangle module. It was shown in [K.-H. Yeap and M. Sarrafzadeh,  SIAM J. Comput., 22 (1993), pp. 500--526] that every triangulated plane graph G has a floor-plan using 1-, 2-, and 3-rectangle modules. In this paper, we present a simple linear time algorithm that constructs a floor-plan for G using only 1- and 2-rectangle modules.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2150–2167},
numpages = {18},
keywords = {plane graph, algorithm, rectangular dual, floor-plan}
}

@article{10.1137/S0097539796308217,
author = {Even, Guy},
title = {Fast Approximate Graph Partitioning Algorithms},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796308217},
doi = {10.1137/S0097539796308217},
abstract = {We study graph partitioning problems on graphs with edge capacities and vertex weights. The problems of b-balanced cuts and k-balanced partitions are unified into a new problem called minimum capacity $rho$-separators. A $rho$-separator is a subset of edges whose removal partitions the vertex set into connected components such that the sum of the vertex weights in each component is at most $rho$ times the weight of the graph. We present a new and simple O(log n)-approximation algorithm for minimum capacity $rho$-separators which is based on spreading metrics yielding an O(log n)-approximation algorithm both for b-balanced cuts and k-balanced partitions. In particular, this result improves the previous best known approximation factor for k-balanced partitions in undirected graphs by a factor of O(log k).  We enhance these results by presenting a version of the algorithm that obtains an O(log OPT)-approximation factor. The algorithm is based on a technique called spreading metrics that enables us to formulate directly the minimum capacity $rho$-separator problem as an integer program. We also introduce a generalization called the simultaneous separator problem, where the goal is to find a minimum capacity subset of edges that separates a given collection of subsets simultaneously. We extend our results to directed graphs for values of $rho geq 1/2$. We conclude with an efficient algorithm for computing an optimal spreading metric for $rho$-separators. This yields more efficient algorithms for computing b-balanced cuts than were previously known.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2187–2214},
numpages = {28},
keywords = {graph separator, approximation algorithms, spreading metrics, graph partitioning}
}

@article{10.1137/S0097539796298625,
author = {Rubinfeld, Ronitt},
title = {On the Robustness of Functional Equations},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796298625},
doi = {10.1137/S0097539796298625},
abstract = {In this paper, we study the general question of how characteristics of functional equations influence whether or not they are robust. We isolate examples of properties which are necessary for the functional equations to be robust. On the other hand, we show other properties which are sufficient for robustness. We then study a general class of functional equations, which are of the form $forall x,y   F[f(x-y), f(x+y), f(x),f(y)]=0, where F is an algebraic function. We give conditions on such functional equations that imply robustness. Our results have applications to the area of self-testing/correcting programs. We show that self-testers and self-correctors can be found for many functions satisfying robust functional equations, including algebraic functions of trigonometric functions such as $tan{x},{1 over {1+cot{x}}},$ ${Ax over {1-Ax}},cosh x.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1972–1997},
numpages = {26},
keywords = {functional equations, property testing, program testing}
}

@article{10.1137/S0097539796297954,
author = {Makino, Kazuhisa and Hatanaka, Ken-ichi and Ibaraki, Toshihide},
title = {Horn Extensions of a Partially Defined   Boolean Function},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796297954},
doi = {10.1137/S0097539796297954},
abstract = {Given a partially defined Boolean function (pdBf) (T,F), we investigate in this paper how to find a Horn extension $f: {0,1}^n mapsto {0,1}$, which is consistent with (T,F), where $T subseteq {0,1}^n$ denotes a set of true Boolean vectors (or positive examples) and $F subseteq {0,1}^n$ denotes a set of false Boolean vectors (or negative examples). Given a pdBf (T,F), it is known that the existence of a Horn extension can be checked in polynomial time. As there are many Horn extensions, however, we consider those extensions f which have maximal and minimal sets T(f) of the true vectors of f, respectively. For a pdBf (T,F), there always exists the unique maximal (i.e., maximum) Horn extension, but there are in general many minimal Horn extensions. We first show that a polynomial time membership oracle can be constructed for the maximum extension, even if its disjunctive normal form (DNF) can be very long. Our main contribution is to show that checking if a given Horn DNF represents a minimal extension and generating a Horn DNF of a minimal Horn extension can both be done in polynomial time. We also can check in polynomial time if a pdBf (T,F) has the unique minimal Horn extension. However, the problems of finding a Horn extension f with the smallest |T(f)| and of obtaining a Horn DNF, whose number of literals is smallest, are both NP-hard.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2168–2186},
numpages = {19},
keywords = {extension, partially defined Boolean function, knowledge acquisition, Horn function}
}

@article{10.1137/S0097539795295948,
author = {Edmonds, Jeff and Poon, Chung Keung and Achlioptas, Dimitris},
title = {Tight Lower Bounds for <i>St</i>-Connectivity on the NNJAG Model},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795295948},
doi = {10.1137/S0097539795295948},
abstract = {Directed st-connectivity is the problem of deciding whether or not there exists a path from a distinguished node s to a distinguished node t in a directed graph.  We prove a time--space lower bound on the probabilistic NNJAG model of Poon [ Proc. 34th Annual Symposium on Foundations of Computer Science, Palo Alto, CA, 1993, pp. 218--227]. Let n be the number of nodes in the input graph and S and T be the space and time used by the NNJAG, respectively. We show that, for any $delta &gt; 0$, if an NNJAG uses space $S in O(n^{1-delta})$, then $T in 2^{ Omega(log^2 (n/S)) }$; otherwise $T in 2^{ Omega( log^2({nlog n over S}) / loglog n )} times (nS / log n)^{1/2}$. (In a preliminary version of this paper by Edmonds and Poon [Proc. 27th Annual ACM Symposium on Theory of Computing, Las Vegas, NV, 1995, pp. 147--156.], a lower bound of $T in 2^{ Omega( log^2({nlog n over S}) / loglog n )} times (nS/log n)^{1/2}$ was proved.) Our result greatly improves the previous lower bound of $ST in  Omega(n^2/log n)$ on the JAG model by Barnes and Edmonds [ Proc. 34th Annual Symposium on Foundations of Computer Science, Palo Alto, CA, 1993, pp. 228--237] and that of $S^{1/3}T in Omega(n^{4/3})$ on the NNJAG model by Edmonds [ Time-Space Lower Bounds for Undirected and Directed ST-Connectivity on JAG Models, Ph. D. thesis, University of Toronto, Toronto, ON, Canada, 1993]. Our lower bound is tight for $S in O(n^{1-delta})$, for any $delta &gt; 0$, matching the upper bound of Barnes etal [ Proc. 7th Annual IEEE Conference on Structure in Complexity Theory, Boston, MA, 1992, pp. 27--33]. As a corollary of this improved lower bound, we obtain the first tight space lower bound of $Omega( log^2 n )$ on the NNJAG model. No tight space lower bound was previously known even for the more restricted JAG model.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2257–2284},
numpages = {28},
keywords = {space--time tradeoffs, lower bounds, space complexity, connectivity}
}

@article{10.1137/S0097539795295468,
author = {Chalasani, Prasad and Motwani, Rajeev},
title = {Approximating Capacitated Routing  and Delivery Problems},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795295468},
doi = {10.1137/S0097539795295468},
abstract = {We provide approximation algorithms for some capacitated vehicle routing and delivery problems. These problems can all be viewed as instances of the following k-delivery TSP: given n source points and n sink points in a metric space, with exactly one item at each source, find a minimum length tour by a vehicle of finite capacity k to pick up and deliver exactly one item to each sink. The only known approximation algorithm for this family of problems is the 2.5-approximation algorithm of Anily and Hassin [ Networks, 22 (1992), pp. 419--433] for the special case k=1.  For this case, we use matroid intersection to obtain a 2-approximation algorithm. Based on this algorithm and some additional lower bound arguments, we devise a factor-approximation for k-delivery TSP with arbitrary finite k. We also present a 2-approximation algorithm for the case $k = infty$.We then initiate the study of dynamic variants of k-delivery TSP that model problems in industrial robotics and other applications. Specifically, we consider the situation where a robot arm (with finite or infinite capacity) must collect n point-objects  moving in the Euclidean plane, and deliver them to the origin. The point-objects are moving in the plane with known, identical velocities---they might, for instance, be on a moving conveyor belt. We derive several useful structural properties that lead to constant-factor approximations for problems of this type that are relevant to the robotics application. Along the way, we show that maximum latency TSP is implicit in the dynamic problems, and  that the natural "farthest neighbor" heuristic produces a good approximation for several notions of latency.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2133–2149},
numpages = {17},
keywords = {matroid intersection, maximum latency problem, NP-hard, traveling salesperson problem, approximation algorithms, capacitated delivery, capacitated vehicle routing}
}

@article{10.1137/S009753979528977X,
author = {Harvey, Warwick},
title = {Computing Two-Dimensional Integer Hulls},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979528977X},
doi = {10.1137/S009753979528977X},
abstract = {An optimal algorithm is presented for computing the smallest set of linear inequalities that define the integer hull of a possibly unbounded two-dimensional convex polygon R. Input to the algorithm is a set of linear inequalities defining R, and the integer hull computed is the convex hull of the integer points of R. It is proven that the integer hull has at most O(n log Amax) inequalities, where n is the number of input inequalities and Amax is the magnitude of the largest input coefficient. It is shown that the algorithm presented has complexity O(n log Amax) and that this is optimal by proving that the integer hull may have $Omega(n log A_{max})$ inequalities in the worst case.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2285–2299},
numpages = {15},
keywords = {linear inequalities, integer convex hull, continued fractions}
}

@article{10.1137/S0097539795289604,
author = {Hershberger, John and Suri, Subhash},
title = {An Optimal Algorithm for Euclidean Shortest Paths in the Plane},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795289604},
doi = {10.1137/S0097539795289604},
abstract = {We propose an optimal-time algorithm for a classical problem in plane computational geometry: computing a shortest path between two points in the presence of polygonal obstacles. Our algorithm runs in worst-case time O(n log n) and requires O(n log n) space, where n is the total number of vertices in the obstacle polygons. The algorithm is based on an efficient implementation of wavefront propagation among polygonal obstacles, and it actually computes a planar map encoding shortest paths from a fixed source point to all other points of the plane; the map can be used to answer single-source shortest path queries in O(log n) time. The time complexity of our algorithm is a significant improvement over all previously published results on the shortest path problem. Finally, we also discuss extensions to more general shortest path problems, involving nonpoint and multiple sources.},
journal = {SIAM J. Comput.},
month = aug,
pages = {2215–2256},
numpages = {42},
keywords = {shortest path map, planar subdivision, weighted distance, Euclidean distance, quad-tree, shortest path, obstacle avoidance}
}

@article{10.1137/S0097539793251244,
author = {Chandra, Barun and Karloff, Howard and Tovey, Craig},
title = {New Results on the Old <i>k</i>-Opt Algorithm  for the Traveling Salesman Problem},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793251244},
doi = {10.1137/S0097539793251244},
abstract = {Local search with k-change neighborhoods is perhaps the oldest and most widely used heuristic method for the traveling salesman problem, yet almost no theoretical performance guarantees for it were previously known. This paper develops several results, some worst-case and some probabilistic, on the performance of 2- and k-opt local search for the traveling salesman problem, with respect to both the quality of the solution and the speed with which it is obtained.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1998–2029},
numpages = {32},
keywords = {explicit machine computation and programs (in optimization heading), graph algorithms, analysis of algorithms, explicit machine computation and programs (in computer science heading)}
}

@article{10.1137/S0097539793249694,
author = {Case, John},
title = {The Power of Vacillation in Language Learning},
year = {1999},
issue_date = {Dec. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793249694},
doi = {10.1137/S0097539793249694},
abstract = {Some extensions are considered of Gold's influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The main theorem of this paper is that there are classes of languages that can be learned if convergence in the limit to up to (  n  + 1) exactly correct grammars is allowed but which cannot be learned if convergence in the limit is to no more than  n  grammars, where the no more than  n  grammars can each make finitely many mistakes. This contrasts sharply with results of Barzdin and Podnieks and, later, Case and Smith for learnability from both positive and negative data.  A subset principle from a 1980 paper of Angluin is extended to the vacillatory and other criteria of this paper. This principle provides a necessary condition for avoiding overgeneralization in learning from positive data. It is applied to prove another theorem to the effect that one can optimally eliminate half of the mistakes from final programs for vacillatory criteria if one is willing to converge in the limit to infinitely many different programs instead.Child language learning may be sensitive to the order or timing of data presentation. It is shown, though, that for the vacillatory success criteria of this paper, there is no loss of learning power for machines which are  in sensitive to order in several ways simultaneously. For example,  partly set-driven  machines attend only to the  set  and  length of sequence  of positive data, not the actual sequence itself. A machine  M  is  weakly n-ary order independent  ${stackrel{rm def}Leftrightarrow}$ for each language  L  on which, for some ordering of the positive data about  L ,  M  converges in the limit to a finite set of grammars, there is a finite set of grammars  D  (of cardinality $leq n$) such that  M  converges to a subset of this same  D  for  each  ordering of the positive data for  L . The theorem most difficult to prove in the paper implies that machines which are simultaneously partly set-driven and weakly  n -ary order independent do not lose learning power for converging in the limit to up to  n  grammars. Several variants of this theorem are obtained by modifying its proof, and some of these variants have application in this and other papers. Along the way it is also shown, for the vacillatory criteria, that learning power is not increased if one restricts the sequence of positive data presentation to be computable. Some of these results are nontrivial lifts of prior work for the  n =1 case done by the Blums; Wiehagen; Osherson, Stob, and Weinstein; Sch\"{a}fer; and Fulk.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1941–1969},
numpages = {29},
keywords = {recursion theory, inductive reference, topology, language learning, computational learning theory}
}

@article{10.5555/347566.347620,
author = {Bar-Noy, Amotz and Canetti, Ran and Kutten, Shay and Mansour, Yishay and Schieber, Baruch},
title = {Bandwidth Allocation with Preemption},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
abstract = {Bandwidth allocation is a fundamental problem in the design of networks where bandwidth has to be reserved for connections in advance.  The problem is intensified when the overall requested bandwidth exceeds the capacity and not all requests can be served. Furthermore, acceptance/rejection decisions regarding connections have to be made online, without knowledge of future requests. We show that the ability to  preempt (i.e., abort) connections while in service in order to schedule "more valuable" connections substantially improves the throughput of some networks. We present bandwidth allocation strategies that use preemption and show that they achieve  constant competitiveness with respect to the throughput, given that any single call requests at most a constant fraction of the bandwidth.  Our results should be contrasted with recent works showing that nonpreemptive strategies have at most inverse logarithmic competitiveness.},
journal = {SIAM J. Comput.},
month = may,
pages = {1806–1828},
numpages = {23},
keywords = {call control, online algorithms, bandwidth allocation, preemption, call admission}
}

@article{10.5555/347566.347616,
author = {Talamo, Maurizio and Vocca, Paola},
title = {An Efficient Data Structure for Lattice Operations},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
abstract = {In this paper, we consider the representation and management of an element set on which a lattice partial order relation is defined. In particular, let  n  be the element set size. We present an nradn-space  implicit  data structure for performing the following set of basic operations:1. Test the presence of an order relation between two given elements, in constant time. 2. Find a path between two elements whenever one exists, in  O (  l ) steps, where  l  is the path length. 3. Compute the successors and/or predecessors set of a given element, in  O (  h ) steps, where  h  is the size of the returned set. 4. Given two elements, find all elements between them, in time  O (  k  log  d ), where  k  is the size of the returned set and  d  is the maximum in-degree or out-degree in the transitive reduction of the order relation. 5. Given two elements, find the least common ancestor and/or the greatest common successor in $O(sqrt{n})$-time. 6. Given  k  elements, find the least common ancestor and/or the greatest common successor in $O(sqrt{n}+k log n)$time. (Unless stated otherwise, all logarithms are to the base 2.)  The preprocessing time is  O (  n 2). Focusing on the first operation, representing the building-box for all the others, we derive an overall nradn-space,$times$,time bound which beats the order  n 2 bottleneck representing the present complexity for this problem. Moreover, we will show that the complexity bounds for the first three operations are optimal with respect to the worst case. Additionally, a stronger result can be derived. In particular, it is possible to represent a lattice in space $O(nsqrt{t})$, where  t  is the minimum number of disjoint chains which partition the element set.},
journal = {SIAM J. Comput.},
month = may,
pages = {1783–1805},
numpages = {23},
keywords = {least common ancestors, reachability, graph decomposition, data structure, lattices}
}

@article{10.1137/S0097539796311077,
author = {Parker, D. Stott and Ram, Prasad},
title = {The Construction of Huffman Codes   is a Submodular ("Convex") Optimization Problem   Over a Lattice of Binary Trees},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796311077},
doi = {10.1137/S0097539796311077},
abstract = {We show that the space of all binary Huffman codes for a finite alphabet defines a  lattice, ordered by the imbalance of the code trees. Representing code trees as path-length sequences, we show that the imbalance ordering is closely related to a majorization ordering on real-valued sequences that correspond to discrete probability density functions. Furthermore, this tree imbalance is a partial ordering that is consistent with the total orderings given by either the external path length (sum of tree path lengths) or the entropy determined by the tree structure. On the imbalance lattice, we show the weighted path-length of a tree (the usual objective function for Huffman coding) is a  submodular function, as is the corresponding function on the majorization lattice. Submodular functions are discrete analogues of convex functions. These results give perspective on Huffman coding and suggest new approaches to coding as optimization over a lattice.},
journal = {SIAM J. Comput.},
month = may,
pages = {1875–1905},
numpages = {31},
keywords = {lattices, Huffman coding, tree imbalance, Fortuin--Kasteleyn--Ginibre (FKG) inequality, enumeration of trees, combinatorial optimization, greedy algorithms., entropy, combinatorial inequalities, adaptive coding, submodular functions, quadrangle inequality, prefix codes, majorization, dynamic programming, Schur convex functions, convexity, Moebius inversion, Monge matrices}
}

@article{10.1137/S0097539796309326,
author = {Mahajan, Sanjeev and Ramesh, H.},
title = {Derandomizing Approximation Algorithms Based on Semidefinite Programming},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796309326},
doi = {10.1137/S0097539796309326},
abstract = {Remarkable breakthroughs have been made recently in obtaining approximate solutions to some fundamental NP-hard problems, namely Max-Cut, Max k-Cut, Max-Sat, Max-Dicut, Max-bisection, k-vertex coloring, maximum independent set, etc. All these breakthroughs  involve polynomial time  randomized algorithms based upon  semidefinite programming, a technique pioneered by Goemans and Williamson.  In this paper, we give techniques to derandomize the above class of randomized algorithms, thus obtaining polynomial time deterministic algorithms with the same approximation ratios for the above problems. At the heart of our technique is the use of spherical symmetry to convert a nested sequence of n integrations, which cannot be approximated sufficiently well in polynomial time, to a nested sequence  of just a constant number of integrations, which can be approximated sufficiently well in polynomial time.},
journal = {SIAM J. Comput.},
month = may,
pages = {1641–1663},
numpages = {23},
keywords = {NP-hard, semidefinite programming, derandomization, approximation algorithm}
}

@article{10.1137/S0097539796304220,
author = {Crescenzi, Pierluigi and Kann, Viggo and Silvestri, Riccardo and Trevisan, linebreak Luca},
title = {Structure in Approximation Classes},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796304220},
doi = {10.1137/S0097539796304220},
abstract = {The study of the approximability properties of NP-hard optimization problems has recently made great advances mainly due to the results obtained in the field of proof checking.  The last important breakthrough proves the APX-completeness of several important optimization problems and thus reconciles "two distinct views of approximation classes: syntactic and  computational" [S. Khanna et al., in  Proc. 35th IEEE Symp. on Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1994, pp. 819--830]. In this paper we obtain new results on the structure of several computationally-defined approximation classes. In particular, after defining a new approximation preserving reducibility to be used for as many approximation classes as possible, we give the first examples of natural NPO-complete problems and the first examples of natural APX-intermediate problems.  Moreover, we state new connections between the approximability properties and the query complexity of NPO problems.},
journal = {SIAM J. Comput.},
month = may,
pages = {1759–1782},
numpages = {24},
keywords = {complexity classes, approximation algorithms, reducibilities}
}

@article{10.1137/S0097539796303044,
author = {Kaplan, Haim and Shamir, Ron and Tarjan, Robert E.},
title = {Tractability of Parameterized Completion Problems  on Chordal, Strongly Chordal, and  Proper Interval Graphs},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796303044},
doi = {10.1137/S0097539796303044},
abstract = {We study the parameterized complexity of three NP-hard graph completion problems. The minimum fill-in problem asks if a graph can be triangulated by adding at most k edges. We develop O(ck m) and O(k2mn+f(k)) algorithms for this problem on a graph with n vertices and m edges. Here f(k) is exponential in k and the constants hidden by the big-O notation are small and do not depend on k. In particular, this implies that the problem is fixed-parameter tractable (FPT). The proper interval graph completion problem, motivated by molecular biology, asks if a graph can be made proper interval by adding no more than k edges. We show that the problem is FPT by providing a simple search-tree-based algorithm that solves it in O(ck m)-time. Similarly, we show that the parameterized version of the strongly chordal graph completion problem is FPT by giving an O(ck m log n)-time algorithm for it. All of our algorithms can actually enumerate all possible k-completions within the same time bounds.},
journal = {SIAM J. Comput.},
month = may,
pages = {1906–1922},
numpages = {17},
keywords = {design and analysis of algorithms, physical mapping of DNA, minimum fill-in, proper interval graphs, chordal graphs, strongly chordal graphs, parameterized complexity}
}

@article{10.1137/S0097539796302749,
author = {Maurer, Ueli M. and Wolf, Stefan},
title = {The Relationship Between Breaking the Diffie--Hellman Protocol and Computing Discrete Logarithms},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796302749},
doi = {10.1137/S0097539796302749},
abstract = {Both uniform and nonuniform results concerning the security of the Diffie--Hellman key-exchange protocol are proved.  First, it is shown that in a cyclic group G of order |G|=prod{p_i^{e_i}}$, where all the multiple prime factors of |G| are polynomial in log|G|, there exists an algorithm that reduces the computation of discrete logarithms in G to breaking the Diffie--Hellman protocol in G and has complexity $sqrt{max{nu(p_i)}}cdot(log|G|)^{O(1)}$, where $nu(p)$ stands for the minimum of the set of largest prime factors of all the numbers d in the interval $[p-2sqrt{p}+1,p+2sqrt{p}+1]$. Under the unproven but plausible assumption that $nu(p)$ is polynomial in log p, this reduction implies that the Diffie--Hellman problem and the discrete logarithm problem are polynomial-time equivalent in G.  Second, it is proved that the Diffie--Hellman problem and the discrete logarithm problem are equivalent in a uniform sense for groups whose orders belong to certain classes: there exists a polynomial-time reduction algorithm that works for all those groups. Moreover, it is shown that breaking the Diffie--Hellman protocol for a small but nonnegligible fraction of the instances is equally difficult as breaking it for all instances.  Finally, efficient constructions of groups are described for which the algorithm reducing the discrete logarithm problem to the Diffie--Hellman problem is efficiently constructible.},
journal = {SIAM J. Comput.},
month = may,
pages = {1689–1721},
numpages = {33},
keywords = {finite fields, discrete logarithms, Diffie--Hellman protocol, elliptic curves, public-key cryptography}
}

@article{10.1137/S0097539796260321,
author = {Br\"{o}nnimann, Herv\'{e} and Chazelle, Bernard and Matousek, Jiri},
title = {Product Range Spaces, Sensitive Sampling, and Derandomization},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796260321},
doi = {10.1137/S0097539796260321},
abstract = {We introduce the concept of a {em sensitive $varepsilon$-approximation} and use it to derive a more efficient algorithm for computing $varepsilon$-nets. We define and investigate  product range spaces, for which we establish sampling theorems analogous to the standard finite  VC-dimensional case. This generalizes and simplifies results from previous works. Using these tools, we give a new deterministic algorithm for computing the convex hull of n points in $mbox{smallBbb R}^d$. The algorithm is obtained by derandomization of a randomized incremental algorithm, and its running time of O(nlog n + n{lfloor d/2rfloor})$ is optimal for any fixed dimension $dgeq 2$.},
journal = {SIAM J. Comput.},
month = may,
pages = {1552–1575},
numpages = {24},
keywords = {deterministic algorithm, optimal, convex hull}
}

@article{10.1137/S009753979529595X,
author = {Bik, Aart J. C. and Wijshoff, Harry A. G.},
title = {Automatic Nonzero Structure Analysis},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979529595X},
doi = {10.1137/S009753979529595X},
abstract = {The efficiency of sparse codes heavily depends on the size and structure of the input data. Peculiarities of the nonzero structure of each sparse matrix must be accounted for to avoid unsatisfying performance. Therefore, it is important to have an efficient analyzer that automatically determines characteristics of nonzero structures. In this paper, some efficient algorithms are presented that automatically detect particular nonzero structures.},
journal = {SIAM J. Comput.},
month = may,
pages = {1576–1587},
numpages = {12},
keywords = {sparse matrices, nonzero structures, sparse computations}
}

@article{10.1137/S0097539795294165,
author = {Brodnik, Andrej and Munro, J. Ian},
title = {Membership in Constant Time  and Almost-Minimum Space},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795294165},
doi = {10.1137/S0097539795294165},
abstract = {This paper deals with the problem of storing a subset of elements from the bounded universe $mathcal{M} = {0, ldots, M-1}$ so that membership queries can be performed efficiently. In particular, we introduce a data structure to represent a subset of $N$ elements of $mathcal{M}$ in a number of bits close to the information-theoretic minimum, $B = leftlceil lg {Mchoose N} rightrceil$, and use the structure to answer membership queries in constant time.},
journal = {SIAM J. Comput.},
month = may,
pages = {1627–1640},
numpages = {14},
keywords = {minimum space, information retrieval, efficient algorithms hashing, search strategy, lower bound, data structures, dictionary problem}
}

@article{10.1137/S0097539795291550,
author = {Heath, Lenwood S. and Pemmaraju, Sriram V.},
title = {Stack and Queue Layouts of Directed Acyclic Graphs: Part II},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795291550},
doi = {10.1137/S0097539795291550},
abstract = {Stack layouts and queue layouts of undirected graphs have been used to model problems in fault tolerant computing and in parallel process scheduling. However, problems in parallel process scheduling are more accurately modeled by stack and queue layouts of  directed acyclic graphs (dags). A  stack layout of a dag is similar to a stack layout of an undirected graph, with the additional requirement that the nodes of the dag be in some topological order. A  queue layout is defined in an analogous manner. The  stacknumber ( queuenumber) of a dag is the smallest number of stacks (queues) required for its stack layout (queue layout). This paper presents algorithmic results---in particular, linear time algorithms for recognizing 1-stack dags and 1-queue dags, and proofs of NP-completeness for the problem of recognizing a 4-queue dag and the problem of recognizing a 6-stack dag. The companion paper (Part I [ SIAM J. Comput., 28 (1999), pp. 1510--1539.]) presents combinatorial results.},
journal = {SIAM J. Comput.},
month = may,
pages = {1588–1626},
numpages = {39},
keywords = {queue layout, posets, stack layout, graph algorithms, NP-complete, directed acyclic graphs, leveled-planar graphs, graph embedding, book embedding, dags}
}

@article{10.1137/S0097539795290507,
author = {Goldberg, Leslie Ann and Matias, Yossi and Rao, Satish},
title = {An Optical Simulation of Shared Memory},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795290507},
doi = {10.1137/S0097539795290507},
abstract = {We present a work-optimal randomized algorithm for simulating a shared memory machine (PRAM) on an optical communication parallel computer (OCPC). The OCPC model is motivated by the potential of optical communication for parallel computation. The memory of an OCPC is divided into modules, one module per processor. Each memory module only services a request on a timestep if it receives exactly one memory request.Our algorithm simulates each step of an n lg lg n-processor EREW PRAM on an n-processor OCPC in O(lg lg n) expected delay. (The probability that the delay is longer than this is at most $n^{-alpha}$ for any constant $alpha$.) The best previous simulation, due to Valiant, required $Theta(log n)$ expected delay.},
journal = {SIAM J. Comput.},
month = may,
pages = {1829–1847},
numpages = {19},
keywords = {optical networks, PRAM, PRAM simulation}
}

@article{10.1137/S0097539795288611,
author = {Dor, Dorit and Zwick, Uri},
title = {Selecting the Median},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795288611},
doi = {10.1137/S0097539795288611},
abstract = {Improving a long-standing result of Sch\"{o}nhage, Paterson, and Pippenger [ J. Comput. System Sci., 13 (1976), pp. 184--199] we show that the median of a set containing $n$ elements can always be found using at most $c cdot n$ comparisons, where c&lt;2.95.},
journal = {SIAM J. Comput.},
month = may,
pages = {1722–1758},
numpages = {37},
keywords = {concrete complexity, comparison algorithms, median selection}
}

@article{10.1137/S0097539795288118,
author = {Shi, Weiping and West, Douglas B.},
title = {Diagnosis of Wiring Networks: An Optimal Randomized Algorithm for Finding Connected Components of Unknown Graphs},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795288118},
doi = {10.1137/S0097539795288118},
abstract = {We want to find the vertex sets of components of a graph G with a known vertex set V and unknown edge set E. We learn about G by sending an oracle a query set $S subseteq V$hspace*{-1pt}, and the oracle tells us the vertices connected to S.  The objective is to use the minimum number of queries to partition the vertex set into components. The problem is also known as interconnect diagnosis of wiring networks in VLSI. We present a deterministic algorithm using O(min{k, lg n}) queries and a randomized algorithm using expected O(min{k,lg k + lg lg n}) queries, where n is the number of vertices and k is the number of components. We also prove matching lower bounds.},
journal = {SIAM J. Comput.},
month = may,
pages = {1541–1551},
numpages = {11},
keywords = {fault diagnosis, component, graph, lower bound, randomized algorithm, connection class}
}

@article{10.1137/S0097539795281724,
author = {Miller, Gary L. and Teng, Shang-Hua},
title = {The Dynamic Parallel Complexity of Computational Circuits},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795281724},
doi = {10.1137/S0097539795281724},
abstract = {We establish connections between parallel circuit evaluation and uniform algebraic closure properties of unary function classes. We use this connection in the development of time-efficient and processor-efficient parallel algorithms for the evaluation of algebraic circuits. Our algorithm provides a nontrivial upper bound on the parallel complexity of the circuit value problem over ${{Bbb R},min,max,+}$ and  ${{Bbb R}^{+},min,max,times}$. We partially answer an open question of Miller, Ramachandran, and Kaltofen by showing that circuits over a polynomial-bounded noncommutative semiring and circuits over infinite noncommutative semirings with a polynomial-bounded dimension over a commutative semiring can be evaluated in polylogarithmic time in their size and degree using a polynomial number of processors. We also present an improved parallel algorithm for Boolean circuits.},
journal = {SIAM J. Comput.},
month = may,
pages = {1664–1688},
numpages = {25},
keywords = {the circuit value problem, NC problems, Boolean circuits, parallel algorithms, algebraic computations, complexity}
}

@article{10.1137/S0097539793243685,
author = {Dwork, Cynthia and Herlihy, Maurice and Plotkin, Serge and Waarts, Orli},
title = {Time-Lapse Snapshots},
year = {1999},
issue_date = {April/May 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793243685},
doi = {10.1137/S0097539793243685},
abstract = {A snapshot scan algorithm produces an "instantaneous" picture of a region of shared memory that may be updated by concurrent processes. Many complex shared memory algorithms can be greatly simplified by structuring them around the snapshot scan abstraction. Unfortunately, the substantial decrease in conceptual complexity quite often is counterbalanced by an increase in computational complexity. In this paper, we introduce the notion of a  weak snapshot scan , a slightly weaker primitive that has a more efficient implementation. We propose the following methodology for using this abstraction: first, design and verify an algorithm using the more powerful snapshot scan; second, replace the more powerful but less efficient snapshot with the weaker but more efficient snapshot, and show that the weaker abstraction nevertheless suffices to ensure the correctness of the enclosing algorithm. We give two examples of algorithms whose performance is enhanced while retaining a simple modular structure: bounded concurrent timestamping and bounded randomized consensus. The resulting timestamping protocol dominates all other currently known timestamping protocols: it matches the speed of the fastest known bounded concurrent timestamping protocol while actually reducing the register size by a logarithmic factor. The resulting randomized consensus protocol matches the computational complexity of the best known protocol that uses only bounded values.},
journal = {SIAM J. Comput.},
month = may,
pages = {1848–1874},
numpages = {27},
keywords = {shared-memory algorithms, timestamping, distributed computing, distributed algorithms, asynchronous PRAMS, time-lapse snapshots, atomic snapshots}
}

@article{10.5555/312173.312180,
author = {Devroye, Luc},
title = {The Height and Size of Random Hash Trees and Random Pebbled Hash Trees},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
abstract = {The random hash tree and the N-tree were introduced by Ehrlich in 1981. In the random hash tree,  n data points are hashed to values X1, . . . , Xn, independently and identically distributed random variables taking values that are uniformly distributed on [0,1]. Place the Xi's in  n equal-sized buckets as in hashing with chaining. For each bucket with at least two points, repeat the same process, keeping the branch factor always equal to the number of bucketed points. If Hn is the height of tree obtained in this manner, we show that Hn/log2 n to 1 in  probability.  We also show that the expected number of nodes in the random hash tree and random pebbled hash tree is asymptotic to 2.3020238 . . . n and 1.4183342. . . n, respectively.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1215–1224},
numpages = {10},
keywords = {hash tables, expected complexity, data structures, N-trees, probabilistic analysis, random hash trees, hashing with chaining}
}

@article{10.5555/312173.312174,
author = {Kellerer, Hans and Tautenhahn, T. and Woeginger, G.},
title = {Approximability and Nonapproximability Results for Minimizing Total Flow Time on a Single Machine},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
abstract = {We consider the problem of scheduling n jobs that are released over time on a single machine in order to minimize the total flow time. This problem is well known to be NP-complete, and the best polynomial-time approximation algorithms constructed so far had (more or less trivial) worst-case performance guarantees of O(n). In this paper, we present one positive and one negative result on polynomial-time approximations for the minimum total flow time problem: The positive result is the first approximation algorithm with a sublinear worst-case performance guarantee of $O(sqrt{n})$. This algorithm is based on resolving the preemptions of the corresponding optimum preemptive schedule. The performance guarantee of our approximation algorithm is not far from best possible, as our second, negative result demonstrates: Unless P=NP, no polynomial-time approximation algorithm for minimum total flow time can have a worst-case performance guarantee of $O(n^{1/2-eps})$ for any $eps&gt;0$.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1155–1166},
numpages = {12},
keywords = {total flow time, release time, worst-case analysis, scheduling, approximation algorithm, single machine}
}

@article{10.1137/S0097539798335511,
author = {Tetali, Prasad},
title = {Design of On-Line Algorithms Using Hitting Times},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539798335511},
doi = {10.1137/S0097539798335511},
abstract = {Random walks are well known for playing a crucial role in the design of randomized off-line as well as on-line algorithms. In this work we prove some basic identities for ergodic Markov chains (e.g., an interesting characterization of  reversibility in Markov chains is obtained in terms of first passage times). Besides providing new insight into random walks on weighted  graphs, we show how these identities give us a way of designing competitive randomized on-line algorithms for certain well-known problems.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1232–1246},
numpages = {15},
keywords = {competitive ratio, first passage time, reversibility, random walk, Markov chain, M-matrices, graph}
}

@article{10.1137/S0097539797332263,
author = {Wang, Jie},
title = {Distributional Word Problem for Groups},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797332263},
doi = {10.1137/S0097539797332263},
abstract = {This paper studies the word problem for finitely presented groups under the restriction that words can only be rewritten for a bounded number of times. We obtain a similar result to the Novikov--Boone theorem in the setting of average-case NP-completeness. The word problem we consider here is to decide, when given a finite presentation of a group G, words x, y, z, and an integer k, whether (x-1yx)z can be derived from z(x-1yx)z in the presentation of G in k steps. We show that when each component of the instance is chosen uniformly at random, the problem cannot be solved fast on average unless every NP problem under every reasonable distribution on instances can be solved fast on average.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1264–1283},
numpages = {20},
keywords = {finitely presented groups, word problem, average-case NP-completeness}
}

@article{10.1137/S0097539797325223,
author = {Har-Peled, Sariel},
title = {Constructing Approximate Shortest Path Maps  in Three Dimensions},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797325223},
doi = {10.1137/S0097539797325223},
abstract = {We present a new technique for constructing a data structure that approximates shortest path maps in $Re^d$. By applying this technique, we get the following two results on approximate shortest path maps in $Re^3$.(i) Given a polyhedral surface or a convex polytope $P$ with n edges in $Re^3$, a source point  s on $P$, and a real parameter $0 &lt; eps leq 1$, we present an algorithm that computes a subdivision of $P$ of size $O((n/eps) log( 1/eps ))$ which can be used to answer efficiently approximate shortest path queries. Namely, given any point t on $P$, one can compute, in $O(log{(n/eps)})$ time, a distance $Delta_{P,s}(t)$, such that $d_{P,s}(t) leq Delta_{P,s}(t) leq (1 + eps)d_{P,s}(t)$, where $d_{P,s}(t)$ is the length of a shortest path between s and t on $P$.  The map can be computed in $O(n^2 log{n} + (n/eps) log{(1/eps)} log{(n/eps)})$ time, for the case of a polyhedral surface, and in $O((n/eps^3) log ( 1/eps ) + (n/eps^{1.5}) log{(1/eps)} log{n})$ time if $P$ is a convex polytope.  (ii) Given a set of polyhedral obstacles $O$ with a total of n edges in $Re^3$, a source point {it s} in $Re^3 {rm setminus inter} cupscriptstyle{_{O in O}} O$, and a real parameter $0 &lt; eps leq 1$, we present an algorithm that computes a subdivision of $Re^3$, which can be used to answer efficiently approximate shortest path queries. That is, for any point $t in Re^3$, one can compute, in $O(log{(n/eps)})$ time, a distance $Delta_{O,s}(t)$ that $eps$-approximates the length of a shortest path from {it s} to {it t} that avoids the interiors of the obstacles. This subdivision can be computed in roughly $O(n^4/eps^6)$ time.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1182–1197},
numpages = {16},
keywords = {approximation algorithms, Voronoi diagrams, Euclidean shortest paths}
}

@article{10.1137/S0097539797315410,
author = {Erickson, Jeff},
title = {New Lower Bounds for Convex Hull Problems in Odd Dimensions},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539797315410},
doi = {10.1137/S0097539797315410},
abstract = {We show that in the worst case, $Omega(n^{ceil{d/2}-1} + nlog n)$ sidedness queries are required to determine whether the convex hull of n points in $Real^d$ is simplicial or to determine the number of convex hull facets.  This lower bound matches known upper bounds in any odd dimension.  Our result follows from a straightforward adversary argument.  A key step in the proof is the construction of a quasi-simplicial n-vertex polytope with $Omega(n^{ceil{d/2}-1})$ degenerate facets.  While it has been known for several years that  d-dimensional convex hulls can have $Omega(n^{floor{d/2}})$ facets, the previously best lower bound for these problems is only $Omega(nlog n)$.  Using similar techniques, we also obtain simple and correct proofs of Erickson and Seidel's lower bounds for detecting affine degeneracies in arbitrary dimensions and circular degeneracies in the plane.  As a related result, we show that detecting simplicial convex hulls in $Real^d$ is $ceil{d/2}$SUM-hard in the sense of Gajentaan and Overmars.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1198–1214},
numpages = {17},
keywords = {lower bounds, degeneracy, computational geometry, decision trees, convex polytopes, adversary arguments}
}

@article{10.1137/S0097539796313921,
author = {Lin, Guo-Hui and Du, Ding-Zhu and Hu, Xiao-Dong and Xue, Guoliang},
title = {On Rearrangeability of Multirate Clos Networks},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796313921},
doi = {10.1137/S0097539796313921},
abstract = {Chung and Ross [SIAM J. Comput., 20 (1991), pp. 726--736] conjectured that the multirate three-stage Clos network C(n,2n-1,r) is rearrangeable in the general discrete bandwidth case; i.e., each connection has a weight chosen from a given finite set {p1, p2,. . .,pk} where $1 geq p_1 &gt; p_2 &gt; cdots &gt; p_k &gt; 0$ and pi is an integer multiple of pi, denoted by $p_k mid p_i$, for $1 leq i leq k-1$. In this paper, we prove that multirate three-stage Clos network C(n,2n-1,r) is rearrangeable when each connection has a weight chosen from a given finite set {p1, p2,. . .,pk} where $1 geq p_1 &gt; p_2 &gt; cdots &gt; p_{h} &gt; 1/2 geq p_{h+1} &gt; cdots &gt; p_k &gt; 0$ and ph+2 | ph+1,ph+3 |ph+2,. . . ,pk | ph+1. We also prove that C(n,2n-1,r) is two-rate rearrangeable and $C(n, lceil frac{7n}{3} rceil, r)$ is three-rate rearrangeable.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1225–1231},
numpages = {7},
keywords = {rearrangeability, minimization of the number of center switches, multirate Clos networks}
}

@article{10.1137/S0097539796313490,
author = {Cherkassky, Boris V. and Goldberg, Andrew V. and Silverstein, Craig},
title = {Buckets, Heaps, Lists, and Monotone Priority Queues},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796313490},
doi = {10.1137/S0097539796313490},
abstract = {We introduce the heap-on-top (hot) priority queue data structure that combines the multilevel bucket data structure of Denardo and Fox with a heap.  Our data structure has superior operation bounds than either structure taken alone.  We use the new data structure to obtain an improved bound for Dijkstra's shortest path algorithm. We also discuss a practical implementation of hot queues.  Our experimental results in the context of Dijkstra's algorithm show that this implementation of hot queues performs very well and is more robust than implementations based only on heap or multilevel bucket data structures.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1326–1346},
numpages = {21},
keywords = {shortest paths, priority queues, data structures}
}

@article{10.1137/S0097539796311715,
author = {Cai, Jin-Yi and Selman, Alan L.},
title = {Fine Separation of Average-Time Complexity Classes},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796311715},
doi = {10.1137/S0097539796311715},
abstract = {We extend Levin's definition of average polynomial time to arbitrary time-bounds in accordance with the following general principles: (1) It essentially agrees with Levin's notion when applied to polynomial time-bounds. (2) If a language L belongs to DTIME(T(n)) for some time-bound T(n), then every distributional problem $(L,mu)$ is T on the $mu$-average. (3) If L does not belong to DTIME(T(n)) almost everywhere, then no distributional problem $(L,mu)$ is T on the $mu$-average.  We present hierarchy theorems for average-case complexity, for arbitrary time-bounds, that are as tight as the well-known Hartmanis--Stearns  hierarchy theorem for deterministic complexity. As a consequence, for every time-bound T(n), there are distributional problems $(L,mu)$ that can be solved using only a slight increase in time but that cannot be solved on the $mu$-average in time T(n).},
journal = {SIAM J. Comput.},
month = mar,
pages = {1310–1325},
numpages = {16},
keywords = {Average-P, average-time complexity classes, logarithmico-exponential functions, computational complexity, hierarchy}
}

@article{10.1137/S0097539796309764,
author = {Mitchell, Joseph S. B.},
title = {Guillotine Subdivisions Approximate Polygonal Subdivisions: A Simple Polynomial-Time Approximation Scheme for Geometric TSP, <i>k</i>-MST, and Related Problems},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796309764},
doi = {10.1137/S0097539796309764},
abstract = {We show that any polygonal subdivision in the plane can be converted into an "m-guillotine" subdivision whose length is at most $(1+{cover m})$ times that of the original subdivision, for a small constant c.  "m-Guillotine" subdivisions have a simple recursive structure that allows one to search for the shortest of such subdivisions in polynomial time, using dynamic programming.  In particular, a consequence of our main theorem is a simple polynomial-time approximation scheme for geometric instances of several network optimization problems, including the Steiner minimum spanning tree, the traveling salesperson problem (TSP), and the k-MST problem.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1298–1309},
numpages = {12},
keywords = {traveling salesperson problem, Steiner minimal trees, guillotine subdivisions, approximation algorithms, polynomial-time approximation scheme, k-MST, computational geometry}
}

@article{10.1137/S0097539796308485,
author = {Buhrman, Harry and Hoepman, Jaap-Henk and Vit\'{a}nyi, Paul},
title = {Space-Efficient Routing Tables for Almost All Networks and the Incompressibility Method},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796308485},
doi = {10.1137/S0097539796308485},
abstract = {We use the incompressibility method based on Kolmogorov complexity to determine the total number of bits of routing information for almost all network topologies. In most models for routing, for almost all labeled graphs, $Theta (n^2)$ bits are necessary and sufficient for shortest path routing. By "almost all graphs" we mean the Kolmogorov random graphs which constitute a fraction of 1 - 1/nc of all graphs on n nodes, where c &gt; 0 is an arbitrary fixed constant. There is a model for which the average case lower bound rises to $Omega(n^2 log n )$ and another model where the average case upper bound drops to $O(n log^2 n)$. This clearly exposes the sensitivity of such bounds to the model under consideration. If paths have to be short, but need not be shortest (if the stretch factor may be larger than 1), then much less space is needed on average, even in the more demanding models. Full-information routing requires $Theta (n^3)$ bits on average. For worst-case static networks we prove an $Omega(n^2 log n )$ lower bound for shortest path routing and all stretch factors &lt; 2 in some networks where free relabeling is not allowed.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1414–1432},
numpages = {19},
keywords = {incompressibility method, compact routing tables, space complexity, routing algorithms, computer networks, Kolmogorov complexity, average-case complexity, random graphs}
}

@article{10.1137/S0097539796303421,
author = {Aingworth, D. and Chekuri, C. and Indyk, P. and Motwani, R.},
title = {Fast Estimation of Diameter and Shortest Paths (Without Matrix Multiplication)},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796303421},
doi = {10.1137/S0097539796303421},
abstract = {In the recent past, there has been considerable progress in devising algorithms for the all-pairs shortest paths (APSP) problem running in time significantly smaller than the obvious time bound of O(n3). Unfortunately, all the new algorithms are based on fast matrix multiplication algorithms that are notoriously impractical. Our work is motivated by the goal of devising purely combinatorial algorithms that match these improved running times. Our results come close to achieving this goal, in that we present algorithms with a small additive error in the length of the paths obtained. Our algorithms are easy to implement, have the desired property of being combinatorial in nature, and the hidden constants in the running time bound are fairly small.Our main result is an algorithm which solves the APSP problem in unweighted, undirected graphs with an additive error of 2 in time $O(n^{2.5}sqrt{log n})$. This algorithm returns actual paths and not just the distances. In addition, we give more efficient algorithms with running time {footnotesize $O(n^{1.5} sqrt{k log n} + n^2 log^2 n)$} for the case where we are only required to determine shortest paths between k specified pairs of vertices rather than all pairs of vertices. The starting point for all our results is an $O(m sqrt{n log n})$ algorithm for distinguishing between graphs of diameter 2 and 4, and this is later extended to obtaining a ratio 2/3 approximation to the diameter in time $O(m sqrt{n log n} + n^2 log n)$. Unlike in the case of APSP, our results for approximate diameter computation can be extended to the case of  directed graphs with arbitrary positive real weights on the edges.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1167–1181},
numpages = {15},
keywords = {shortest paths, matrix multiplication, diameter}
}

@article{10.1137/S009753979630091X,
author = {Srinivasan, Aravind and Zuckerman, David},
title = {Computing with Very Weak Random Sources},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979630091X},
doi = {10.1137/S009753979630091X},
abstract = {We give an efficient algorithm to extract randomness from a very weak random source using a small additional number t of truly random bits. Our work extends that of Nisan and Zuckerman [ J. Comput. System Sci., 52 (1996), pp. 43--52] in that t remains small even if the entropy rate is well below constant. A key application of this is in running randomized algorithms using such a very weak source of randomness. For any fixed $gamma &gt; 0$, we show how to simulate RP algorithms in time $n^{O(log n)}$ using the output of a ds with min-entropy $R^gamma$. Such a weak random source is asked once for $R$ bits; it outputs an $R$-bit string according to any probability distribution that places probability at most $2^{-R^gamma}$ on each string. If $gamma &gt; 1/2$, our simulation also works for BPP; for $gamma &gt; 1-1/(k+1)$, our simulation takes time $n^{O(logk n)}$ (log(k) is the logarithm iterated k times). We also give a polynomial-time BPP simulation using Chor--Goldreich sources of min-entropy $R^{Omega(1)}$, which is optimal. We present applications to time-space tradeoffs, expander constructions, and to the hardness of approximation. Of independent interest is our randomness-efficient Leftover Hash Lemma, a key tool for extracting randomness from weak random sources.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1433–1459},
numpages = {27},
keywords = {pseudorandomness, randomized computation, hardness of approximation, time-space tradeoffs, measures of information, derandomization, hashing lemmas, pseudorandom generators, imperfect sources of randomness, expander graphs}
}

@article{10.1137/S009753979628292X,
author = {Suzuki, Ichiro and Yamashita, Masafumi},
title = {Distributed Anonymous Mobile Robots: Formation of Geometric Patterns},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979628292X},
doi = {10.1137/S009753979628292X},
abstract = {Consider a system of multiple mobile robots in which each robot, at infinitely many unpredictable time instants, observes the positions of all the robots and moves to a new position determined by the given algorithm. The robots are anonymous in the sense that they all execute the same algorithm and they cannot be distinguished by their appearances. Initially they do not have a common x-y coordinate system. Such a system can be viewed as a distributed system of anonymous mobile processes in which the processes (i.e., robots) can "communicate" with each other only by means of their moves. In this paper we investigate a number of formation problems of geometric patterns in the plane by the robots. Specifically, we present algorithms for  converging the robots to a single point and moving the robots to a single point in finite steps. We also characterize the class of geometric patterns that the robots can form in terms of their initial configuration. Some impossibility results are also presented.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1347–1363},
numpages = {17},
keywords = {formation of geometric patterns, anonymous robots, multiagent systems, distributed algorithms, mobile robots}
}

@article{10.1137/S0097539795285643,
author = {Attiya, Hagit and Shachnai, Hadas and Tamir, Tami},
title = {Local Labeling and Resource Allocation Using Preprocessing},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795285643},
doi = {10.1137/S0097539795285643},
abstract = {This paper studies the power of nonrestricted preprocessing on a communication graph G, in a synchronous, reliable system. In our scenario, arbitrary preprocessing can be performed on G, after which a sequence of labeling problems has to be solved on different subgraphs of G. We suggest a preprocessing that produces an orientation of G. The goal is to exploit this preprocessing for minimizing the radius of the neighborhood around each vertex from which data has to be collected in order to determine a label. We define a set of labeling problems for which this can be done. The time complexity of labeling a subgraph depends on the topology of the graph G and is always less than $min{chi(G), O((log n)^{2})}$. On the other hand, we show the existence of a graph for which even unbounded preprocessing does not allow fast solution of a simple labeling problem. Specifically, it is shown that a processor needs to know its $Omega(log n / log log n)$-neighborhood in order to pick a label.Finally, we derive some results for the resource allocation problem. In particular, we show that $Omega(log n / log log n)$ communication rounds are needed if resources are to be fully utilized. In this context, we define the  compact coloring problem, for which the orientation preprocessing provides fast distributed labeling algorithm. This algorithm suggests efficient solution for the resource allocation problem.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1397–1414},
numpages = {18},
keywords = {locality, preprocessing, resource allocation, orientation, response time, labeling}
}

@article{10.1137/S0097539795282377,
author = {Corneil, Derek G. and Olariu, Stephan and Stewart, Lorna},
title = {Linear Time Algorithms for Dominating Pairs in Asteroidal Triple-Free Graphs},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795282377},
doi = {10.1137/S0097539795282377},
abstract = {An independent set of three vertices is called an  asteroidal triple if between each pair in the triple there exists a path that avoids the neighborhood of the third. A graph is asteroidal triple-free (AT-free) if it contains no asteroidal triple. The motivation for this investigation is provided, in part, by the fact that AT-free graphs offer a common generalization of interval, permutation, trapezoid, and cocomparability graphs.Previously, the authors have given an existential proof of the fact that every connected AT-free graph contains a dominating pair, that is, a pair of vertices such that every path joining them is a dominating set in the graph. The main contribution of this paper is a constructive proof of the existence of dominating pairs in connected AT-free graphs. The resulting simple algorithm, based on the well-known lexicographic breadth-first search, can be implemented to run in time linear in the size of the input, whereas the best algorithm previously known for this problem has complexity O(|V|3) for input graph G=(V,E). In addition, we indicate how our algorithm can be extended to find, in time linear in the size of the input, all dominating pairs in a connected AT-free graph with diameter greater than 3. A remarkable feature of the extended algorithm is that, even though there may be O(|V|2) dominating pairs, the algorithm can compute and represent them in linear time.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1284–1297},
numpages = {14},
keywords = {lexicographic breadth-first search, dominating pairs, asteroidal triple-free graphs, algorithms}
}

@article{10.1137/S0097539795280287,
author = {Heath, Lenwood S. and Pemmaraju, Sriram V. and Trenk, Ann N.},
title = {Stack and Queue Layouts of Directed Acyclic Graphs: Part I},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795280287},
doi = {10.1137/S0097539795280287},
abstract = {Stack layouts and queue layouts of undirected graphs have been used to model problems in fault-tolerant computing and in parallel process scheduling. However, problems in parallel process scheduling are more accurately modeled by stack and queue layouts of  directed acyclic graphs (dags). A  stack layout of a dag is similar to a stack layout of an undirected graph, with the additional requirement that the nodes of the dag be in some topological order. A  queue layout is defined in an analogous manner. The  stacknumber ( queuenumber) of a dag is the smallest number of stacks (queues) required for its stack layout (queue layout). In this paper, bounds are established on the stacknumber and queuenumber of two classes of dags: tree dags and unicyclic dags. In particular, any tree dag can be laid out in 1 stack and in at most 2 queues; and any unicyclic dag can be laid out in at most 2 stacks and in at most 2 queues. Forbidden subgraph characterizations of 1-queue tree dags and 1-queue cycle dags are also presented. Part II of this paper presents algorithmic results---in particular, linear time algorithms for recognizing 1-stack dags and 1-queue dags and proof of NP-completeness for the problem of recognizing a 4-queue dag and the problem of recognizing a 9-stack dag.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1510–1539},
numpages = {30},
keywords = {stack layout, dags, queue layout, forbidden subgraph, directed acyclic graphs, graph embedding, book embedding}
}

@article{10.1137/S0097539794282930,
author = {Mulmuley, Ketan},
title = {Lower Bounds in a Parallel Model without Bit Operations},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794282930},
doi = {10.1137/S0097539794282930},
abstract = {We define a natural and realistic model of parallel computation called the  PRAM model without bit operations. It is like the usual PRAM model, the main difference being that no bit operations are provided. It encompasses virtually all known parallel algorithms for (weighted) combinatorial optimization and algebraic problems. In this model we prove that for some large enough constant b, the mincost-flow problem for graphs with n vertices cannot be solved deterministically (or with randomization) in $sqrt n /b$ (expected) time using $2^{sqrt {n}/b}$  processors; this is so even if we restrict  every cost and capacity to be an integer (nonnegative if it is a capacity) of bitlength at most an for some large enough constant a. A similar lower bound is also proved for the max-flow problem. It follows that these problems cannot be solved in our model deterministically (or with randomization) in $Omega(N^{c})$ (expected) time with $2^{Omega(N^{c})}$ processors, where c is an appropriate positive constant and N is the total bitlength of the input. Since these problems were known to be P-complete, this provides  concrete  support for the belief that P-completeness implies high parallel complexity and for the $Pnot = NC$ conjecture. Our lower bounds also extend to the PRAM model with limited bit operations, which provides instructions for parity and   left or right shift by one bit.Our proof is based on basic algebraic geometry. So we investigate if the algebrogeometric approach could also work for the P versus NC problem. Our results support this possibility, and a close analysis of the limitation of our technique in this context suggests that such a proof of $P not = NC$ should somehow use geometric invariant theory  in a deep way.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1460–1509},
numpages = {50},
keywords = {lower bounds, computational complexity, parallel algorithms}
}

@article{10.1137/S0097539793244708,
author = {H\r{A}stad, Johan and Impagliazzo, Russell and Levin, Leonid A. and Luby, Michael},
title = {A Pseudorandom Generator from Any One-Way Function},
year = {1999},
issue_date = {Aug. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793244708},
doi = {10.1137/S0097539793244708},
abstract = {Pseudorandom generators are fundamental to many theoretical and applied aspects of computing. We show how to construct a pseudorandom generator from any one-way function. Since it is easy to construct a one-way function from a pseudorandom generator, this result shows that there is a pseudorandom generator if and only if there is a one-way function.},
journal = {SIAM J. Comput.},
month = mar,
pages = {1364–1396},
numpages = {33},
keywords = {complexity theory, pseudorandom generator, one-way function, cryptography}
}

@article{10.5555/305673.305724,
author = {Kao, Ming-Yang and Qi, Junfeng and Tan, Lei},
title = {Optimal Bidding Algorithms Against Cheating in Multiple-Object Auctions},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
abstract = {This paper studies some basic problems in a multiple-object auction model using methodologies from theoretical computer science.  We are especially concerned with situations where an adversary bidder knows the bidding algorithms of all the other bidders.  In the two-bidder case, we derive an optimal randomized bidding algorithm, by which the disadvantaged bidder can procure at least half of the auction objects despite the adversary's a priori knowledge of his algorithm.  In the general k-bidder case, if the number of objects is a multiple of k, an optimal randomized bidding algorithm is found. If the k -- 1 disadvantaged bidders employ that same algorithm, each of them can obtain at least 1/k of the objects regardless of the bidding algorithm the adversary uses.  These two algorithms are based on closed-form solutions to certain multivariate probability distributions.  In situations where a closed-form solution cannot be obtained, we study a restricted class of bidding algorithms as an approximation to desired optimal algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {955–969},
numpages = {15},
keywords = {auction theory, automated negotiation mechanisms, bidding algorithms, market-based control, electronic commerce, software agents}
}

@article{10.5555/305673.305720,
author = {Chen, Chi-Chang and Chen, Jianer},
title = {The Maximum Partition Matching Problem with Applications},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
abstract = {Let ${cal S} = {C1, C2, . . . , Ck}$ be a collection of pairwise disjoint subsets of U = { 1, 2, . . . , n} such that $bigcup_{i = 1}^k Ci = U.  A  partition matching of $cal S$ consists of two subsets {a1, . . . , am} and {b1, . . ., bm} of U together with a sequence of distinct partitions of $cal S$: $({cal A}_1, {cal B}_1), ldots, ({cal A}_m, {cal B}_m)$ such that ai is contained in a subset in the collection ${cal A}_i$ and bi is contained in a subset in the collection ${cal B}_i$ for all i = 1, . . . , m.  An efficient algorithm is developed that constructs a maximum partition matching for a given collection $cal S$.  The algorithm can be used to construct optimal parallel routing between two nodes in interconnection networks.},
journal = {SIAM J. Comput.},
month = feb,
pages = {935–954},
numpages = {20},
keywords = {parallel routing, star network, maximum matching, greedy algorithm}
}

@article{10.5555/305673.305700,
author = {Schrijver, Alexander},
title = {Bipartite Edge Coloring in $O(\Delta m)$ Time},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
abstract = {We show that a minimum edge coloring of a bipartite graph can be found in $O(Delta m)$ time, where $Delta$ and m denote the maximum degree and the number of edges of G, respectively. It is equivalent to finding a perfect matching in a k-regular bipartite graph in O(km) time.By sharpening the methods, a minimum edge coloring of a bipartite graph can be found in $O((p_{max}(Delta)+log Delta)m)$ time, where $p_{max}(Delta)$ is the largest prime factor of $Delta$. Moreover, a perfect matching in a k-regular bipartite graph can be found in O(pmax(k)m)time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {841–846},
numpages = {6},
keywords = {timetabling, perfect, matching, edge-coloring, complexity, bipartite}
}

@article{10.1137/S0097539796312915,
author = {Aguilera, Marcos Kawazoe and Toueg, Sam},
title = {Failure Detection and Randomization: A Hybrid Approach to Solve Consensus},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796312915},
doi = {10.1137/S0097539796312915},
abstract = {We present a consensus algorithm that combines unreliable failure detection  and randomization,  two well-known techniques  for solving consensus in asynchronous systems with crash failures. This hybrid algorithm combines advantages from both approaches:  it guarantees deterministic termination  if the failure detector is accurate,  and probabilistic termination otherwise. In executions with no failures or failure detector mistakes,  the most likely ones in practice,  consensus is reached in only two asynchronous rounds.},
journal = {SIAM J. Comput.},
month = feb,
pages = {890–903},
numpages = {14},
keywords = {crash failures, failure detection, processor failures, asynchronous systems, reliability, Byzantine generals' problem, fault-tolerance, algorithms, randomized algorithms, consensus problem, agreement problem, message passing}
}

@article{10.1137/S0097539796311818,
author = {Maggs, Bruce M. and Sitaraman, Ramesh K.},
title = {Simple Algorithms for Routing  on Butterfly Networks with Bounded Queues},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796311818},
doi = {10.1137/S0097539796311818},
abstract = {This paper examines several simple algorithms for routing packets on butterfly networks with bounded queues.  We show that for any greedy queuing protocol, a routing problem in which each of the N inputs sends a packet to a randomly chosen output requires O(log N) steps, with high probability, provided that the queue size is a sufficiently large, but fixed, constant.  We also show that for any deterministic nonpredictive queuing protocol, there exists a permutation that requires $Omega(N/q log N)$ time to route, where q is the maximum queue size.  We present a new algorithm for routing log N packets from each input to randomly chosen outputs on a butterfly with bounded-size queues in O(log N) steps, with high probability.  The algorithm is simpler than the previous algorithms of Ranade and Pippenger because it does not use ghost messages, it does not compare the ranks or destinations of packets as they pass through switches, and it cannot deadlock.  Finally, using Valiant's idea of random intermediate destinations, we generalize a result of Koch's by showing that if each wire can support $q$ messages, then for any permutation, the expected number of messages that succeed in locking down paths from their origins to their destinations in back-to-back butterflies is $Omega(N/(log N)^{1/q})$. The analysis also applies to store-and-forward algorithms that drop packets if they attempt to enter full queues.},
journal = {SIAM J. Comput.},
month = feb,
pages = {984–1003},
numpages = {20},
keywords = {routing algorithms, parallel computers, performance analysis, interconnection networks, communication protocols, circuit-switching}
}

@article{10.1137/S0097539796305766,
author = {Gafni, Eli and Koutsoupias, Elias},
title = {Three-Processor Tasks Are Undecidable},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796305766},
doi = {10.1137/S0097539796305766},
abstract = {We show that no algorithm exists for deciding whether a finite task for three or more processors is wait-free solvable in the asynchronous read-write shared-memory model. This impossibility result implies that there is no constructive (recursive) characterization of wait-free solvable tasks. It also applies to other shared-memory models of distributed computing, such as the comparison-based model.},
journal = {SIAM J. Comput.},
month = feb,
pages = {970–983},
numpages = {14},
keywords = {asynchronous distributed computation, contractibility problem, task-solvability, wait-free computation}
}

@article{10.1137/S0097539796305365,
author = {Liotta, Giuseppe and Preparata, Franco P. and Tamassia, Roberto},
title = {Robust Proximity Queries: An Illustration of Degree-Driven Algorithm Design},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796305365},
doi = {10.1137/S0097539796305365},
abstract = {In the context of methodologies intended to confer robustness to geometric algorithms, we elaborate on the exact-computation paradigm and formalize the notion of degree of a geometric algorithm as a worst-case quantification of the precision (number of bits) to which arithmetic calculation have to be executed in order to guarantee topological correctness. We also propose a formalism for the expeditious evaluation of algorithmic degree. As an application of this paradigm and an illustration of our general approach where algorithm design is driven also by the degree, we consider the important classical problem of proximity queries in two and three dimensions and develop a new technique for the efficient and robust execution of such queries based on an implicit representation of Voronoi diagrams. Our new technique offers both low degree and fast query time and for 2D queries is optimal with respect to both cost measures of the paradigm, asymptotic number of operations, and arithmetic degree.},
journal = {SIAM J. Comput.},
month = feb,
pages = {864–889},
numpages = {26},
keywords = {arithmetic precision, proximity queries, geometric computing, robustness}
}

@article{10.1137/S0097539796303299,
author = {Mitchell, Joseph S. B. and Blum, Avrim and Chalasani, Prasad and Vempala, Santosh},
title = {A Constant-Factor Approximation Algorithm for the Geometric <i>k</i>-MST Problem in the Plane},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796303299},
doi = {10.1137/S0097539796303299},
abstract = {We show that any rectilinear polygonal subdivision in the plane can be converted into a "guillotine" subdivision whose length is at most twice that of the original subdivision.  "Guillotine" subdivisions have a simple recursive structure that allows one to search for "optimal" such subdivisions in polynomial time, using dynamic programming.  In particular, a consequence of our main theorem is a very simple proof that the k-MST problem in the plane has a constant-factor polynomial-time approximation algorithm: we obtain a factor of 2 (resp., 3) for the L1 metric, and a factor of $2sqrt{2}$ (resp., 3.266) for the L2 (Euclidean) metric in the case in which Steiner points are allowed (resp., not allowed).},
journal = {SIAM J. Comput.},
month = feb,
pages = {771–781},
numpages = {11},
keywords = {approximation algorithms polynomial, guillotine subdivisions, minimum spanning trees, k-MST, dynamic programming, computational geometry, prize-collecting salesman problem, network optimization, quota traveling salesman problem, bank robber (orienteering) problem}
}

@article{10.1137/S0097539796301811,
author = {Louchard, Guy and Szpankowski, Wojciech and Tang, Jing},
title = {Average Profile of the Generalized Digital Search Tree and the Generalized Lempel--Ziv Algorithm},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796301811},
doi = {10.1137/S0097539796301811},
abstract = {The goal of this research is threefold: (i) to analyze generalized digital search trees, (ii) to derive the average profile (i.e., phrase length) of a generalization of the well-known parsing algorithm due to Lempel and Ziv, and (iii) to provide analytic tools to analyze asymptotically certain partial differential functional equations often arising in the analysis of digital trees. In the generalized Lempel--Ziv parsing scheme, one partitions a sequence of symbols from a finite alphabet into phrases such that the new phrase is the shortest substring seen in the past by at most b-1 phrases (b=1 corresponds to the original Lempel--Ziv scheme). Such a scheme can be analyzed through a generalized digital search tree in which every node is capable of storing up to b strings. In this paper, we investigate the depth of a randomly selected node in such a tree and the length of a randomly selected phrase in the generalized Lempel--Ziv scheme. These findings and some recent results allow us to compute the average redundancy of the generalized Lempel--Ziv code and compare it to the ordinary Lempel--Ziv code, leading to an optimal value of b. Analytic techniques of (precise) analyses of algorithms are used to establish most of these conclusions.},
journal = {SIAM J. Comput.},
month = feb,
pages = {904–934},
numpages = {31},
keywords = {generalized Lempel--Ziv parsing scheme, generalized digital search trees, partial differential functional equations, singularity analysis, Mellin transform, average redundancy, asymptotic expansions, depoissonization}
}

@article{10.1137/S0097539795294578,
author = {Hind, Hugh and Molloy, Michael and Reed, Bruce},
title = {Total Coloring With $\Delta + \mbox\lowercasepoly(\log \Delta)$ Colors},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795294578},
doi = {10.1137/S0097539795294578},
abstract = {We provide a polynomial time algorithm which finds a total coloring of any graph with maximum degree $D$, $D$ sufficiently large, using at most $D+8log^8D$ colors. This improves the best previous upper bound on the total chromatic number of $D+18D^{1/3}log(3D)$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {816–821},
numpages = {6},
keywords = {total coloring, probabilistic method, algorithms}
}

@article{10.1137/S0097539795293123,
author = {Bshouty, Nader H. and Jackson, Jeffrey C.},
title = {Learning DNF over the Uniform Distribution  Using a Quantum Example Oracle},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795293123},
doi = {10.1137/S0097539795293123},
abstract = {We generalize the notion of probably approximately correct (PAC) learning from an example oracle to a notion of efficient learning on a quantum computer using a quantum example oracle.  This quantum example oracle is a natural extension of the traditional PAC example oracle, and it immediately follows that all PAC-learnable function classes are learnable in the quantum model. Furthermore, we obtain positive quantum learning results for classes that are not known to be PAC learnable.  Specifically, we show that disjunctive normal form (DNF) is efficiently learnable with respect to the uniform distribution by a quantum algorithm using a quantum example oracle.  While it was already known that DNF is uniform-learnable using a membership oracle, we prove that a quantum example oracle with respect to uniform is less powerful than a membership oracle.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1136–1153},
numpages = {18},
keywords = {machine learning, quantum example oracle, Fourier transform, quantum computing, disjunctive normal form (DNF)}
}

@article{10.1137/S0097539795290349,
author = {Ponzio, Stephen},
title = {A Lower Bound for Integer Multiplication with Read-Once Branching Programs},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795290349},
doi = {10.1137/S0097539795290349},
abstract = {We prove that read-once branching programs computing integer multiplication require size $2^{Omega(sqrt{n})}$. This is the first nontrivial lower bound for multiplication on branching programs that are not oblivious. By the appropriate problem reductions, we obtain the same lower bound for other arithmetic functions.},
journal = {SIAM J. Comput.},
month = feb,
pages = {798–815},
numpages = {18},
keywords = {multiplication, branching programs, read-once, BDD, verification}
}

@article{10.1137/S0097539795287824,
author = {Lund, Carsten and Reingold, Nick and Westbrook, Jeffery and Yan, Dicky},
title = {Competitive On-Line Algorithms for Distributed Data Management},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795287824},
doi = {10.1137/S0097539795287824},
abstract = {Competitive on-line algorithms for data management in a network of processors are studied in this paper. A data object such as a file or a page of virtual memory is to be read and updated by various processors in the network. The goal is to minimize the communication costs incurred in serving a sequence of such requests. Distributed data management on important classes of networks---trees and bus-based networks---are studied. Optimal algorithms with constant competitive ratios and matching lower bounds are obtained. Our algorithms use different interesting techniques, such as work functions [Chrobak and Larmore, Proc. DIMACS Workshop on On-Line Algorithms, AMS, 1991, pp. 11--64] and "factoring."},
journal = {SIAM J. Comput.},
month = feb,
pages = {1086–1111},
numpages = {26},
keywords = {competitive analysis, data management, on-line algorithms, memory management}
}

@article{10.1137/S0097539795282444,
author = {Nisan, Noam and Rudich, Steven and Saks, Michael},
title = {Products and Help Bits in Decision Trees},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795282444},
doi = {10.1137/S0097539795282444},
abstract = {We investigate two problems concerning the complexity of evaluating a function  f  on  k  distinct inputs by  k  parallel decision-tree algorithms. In the  product problem , for some fixed depth bound  d , we seek to maximize the fraction of input  k -tuples for which all  k  decision trees are correct. Assume that for a single input to  f , the best depth-  d  decision tree is correct on a fraction  p  of inputs. We prove that the maximum fraction of  k -tuples on which  k  depth-  d  algorithms are all correct is at most  p k , which is the trivial lower bound. We show that if we replace the restriction to depth  d  by "expected depth  d ," then this result need not hold.In the  help-bits problem , before the decision-tree computations begin, up to  k -1  arbitrary  binary questions (help-bit queries) can be asked about the  k -tuple of inputs. In the second stage, for each possible (  k -1)-tuple of answers to the help-bit queries, there is a  k -tuple of decision trees where the  i th tree is supposed to correctly compute the value of the function on the  i th input, for any input that is consistent with the help bits. The complexity here is the maximum depth of any of the trees in the algorithm. We show that for all  k  sufficiently large, this complexity is equal to  deg s (  f ), which is the minimum degree of a multivariate polynomial whose sign is equal to  f .},
journal = {SIAM J. Comput.},
month = feb,
pages = {1035–1050},
numpages = {16},
keywords = {help bits, decision trees}
}

@article{10.1137/S0097539795280081,
author = {Jayanti, Prasad},
title = {Solvability of Consensus: Composition Breaks Down for NonDeterministic Types},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795280081},
doi = {10.1137/S0097539795280081},
abstract = {Consensus, which requires processes with different input values to eventually agree on one of these values, is a fundamental problem in fault-tolerant computing. We study this problem in the context of asynchronous shared-memory systems. Prior research on consensus focused on its solvability using shared objects of specific types. In this paper, we investigate the following general question: Let T and T' be any two types. Consider the consensus problem among N processes. Suppose that this problem is unsolvable if processes may use only objects of any one type (T or T') for communication. Does it follow that the problem is unsolvable even if processes may use objects of both types? Recent results imply that the answer is positive if T and T' are both deterministic types. We prove that the answer is negative even if one of T and T' is nondeterministic.},
journal = {SIAM J. Comput.},
month = feb,
pages = {782–797},
numpages = {16},
keywords = {asynchronous distributed computation, wait-free algorithms, nondeterministic object type, consensus}
}

@article{10.1137/S009753979427741X,
author = {Gathen, Joachim vonzur and Shparlinski, Igor},
title = {Computing Components and Projections of Curves over Finite Fields},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979427741X},
doi = {10.1137/S009753979427741X},
abstract = {This paper provides an algorithmic approach to some basic algebraic and combinatorial properties of algebraic curves over finite fields: the number of points on a curve or a projection, its number of absolutely irreducible components, and the property of being "exceptional."},
journal = {SIAM J. Comput.},
month = feb,
pages = {822–840},
numpages = {19},
keywords = {computational algebraic geometry, approximation algorithms, curves over finite fields}
}

@article{10.1137/S009753979427011X,
author = {Sibeyn, Jop F.},
title = {Row-Major Sorting on Meshes},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979427011X},
doi = {10.1137/S009753979427011X},
abstract = {In all recent near-optimal sorting algorithms for meshes, the packets are sorted with respect to some snake-like indexing. In this paper we present deterministic algorithms for sorting with respect to the more natural row-major indexing.  For 1-1 sorting on an  n  \texttimes{}  n  mesh, we give an algorithm that runs in 2 ·  n  +  o (  n ) steps, matching the distance bound, with maximal queue size five. It is considerably simpler than earlier algorithms. Another algorithm performs  k -  k  sorting in  k  · n / 2 +  o (  k  ·  n ) steps, matching the bisection bound. Furthermore, we present  uniaxial  algorithms for row-major sorting. We show that 1-1 sorting can be performed in $2 frac{1}{2} ·  n  +  o (  n ) steps. Alternatively, this problem is solved with maximal queue size five in $4 frac{1}{3} ·  n  steps, without any additional terms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {847–863},
numpages = {17},
keywords = {row-major indexing, sorting, meshes, uniaxial routing, parallel computation}
}

@article{10.1137/S0097539793282947,
author = {Beame, Paul and Borodin, Allan and Raghavan, Prabhakar and Ruzzo, Walter L. and Tompa, Martin},
title = {A Time-Space Tradeoff for Undirected Graph Traversal by Walking Automata},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793282947},
doi = {10.1137/S0097539793282947},
abstract = {We prove a time-space tradeoff for traversing undirected graphs, using a structured model that is a nonjumping variant of Cook and Rackoff's "jumping automata for graphs."},
journal = {SIAM J. Comput.},
month = feb,
pages = {1051–1072},
numpages = {22},
keywords = {graph reachability, time-space tradeoff, JAG, walking automaton, jumping automaton, graph connectivity}
}

@article{10.1137/S009753979325799X,
author = {Torlone, Riccardo and Atzeni, Paolo},
title = {Efficient Database Updates with Independent Schemes},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979325799X},
doi = {10.1137/S009753979325799X},
abstract = {The weak instance model is a framework for considering the relations in a database as a whole, regardless of the way attributes are grouped in the individual relations. Queries and updates can be performed for any set of attributes. The management of updates is based on a lattice structure on the set of legal states, and inconsistencies and ambiguities can arise.In the general case,  the test for consistency and  determinism may involve the whole database. In this paper it is shown how, for the highly significant class of independent schemes, updates can be handled efficiently, considering only the relevant portion of the database.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1112–1135},
numpages = {24},
keywords = {weak instance model, relational database, update operations, chase procedure, optimization, lattice on database states}
}

@article{10.1137/S009753979325247X,
author = {Karger, David R. and Nisan, Noam and Parnas, Michal},
title = {Fast Connected Components Algorithms for the EREW PRAM},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979325247X},
doi = {10.1137/S009753979325247X},
abstract = {We present fast and efficient parallel algorithms for finding the connected components of an undirected graph. These algorithms run on the exclusive-read, exclusive-write (EREW) PRAM. On a graph with  n  vertices and  m  edges, our randomized algorithm runs in  O (log  n ) time using $(m+n^{1+epsilon})/log n$ EREW processors (for any fixed $epsilon&gt;0$). A variant uses (  m +  n )/log  n  processors and runs in  O (log  n  log log n) time. A deterministic version of the algorithm runs in $O(log^{1.5}n)$ time using  m +  n  EREW processors.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1021–1034},
numpages = {14},
keywords = {random walks, parallel algorithms, graph algorithms, connected components}
}

@article{10.1137/S0097539792224814,
author = {Hsu, Wen-Lian and Ma, Tze-Heng},
title = {Fast and Simple Algorithms for Recognizing Chordal  Comparability Graphs and Interval Graphs},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792224814},
doi = {10.1137/S0097539792224814},
abstract = {In this paper, we present a linear-time algorithm for substitution decomposition on chordal graphs. Based on this result, we develop a linear-time algorithm for transitive orientation on chordal comparability graphs, which reduces the complexity of chordal comparability recognition from O(n2) to O(n+m). We also devise a simple linear-time algorithm for interval graph recognition where no complicated data structure is involved.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1004–1020},
numpages = {17},
keywords = {graph recognition, substitution decomposition, triangulated graph, graph partitioning, modular decomposition, transitive orientation, cycle-free poset, interval graph, chordal graph, graph theory, cardinality lexicographic ordering, analysis of algorithms}
}

@article{10.5555/299868.299890,
author = {Raghavan, Prabhakar and Upfal, Eli},
title = {Stochastic Contention Resolution With Short Delays},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
abstract = {We study contention resolution protocols under a stochastic model of continuous request generation from a set of contenders. The performance of such a protocol is characterized by two parameters: the maximum arrival rate for which the protocol is stable and the expected delay of a request from arrival to service.Known solutions       are either unstable for any constant injection rate or have at least polynomial (in the number of contenders) expected delay. Our main contribution is a protocol that is stable for a constant injection rate, while achieving logarithmic expected delay. We extend our results to the case of multiple servers, with each request being targeted for a specific server. This is related to the optically connected parallel computer (or OCPC) model. Finally, we prove a lower bound showing that long delays are inevitable in a class of protocols including backoff-style protocols, if the arrival rate is large enough (but still smaller than 1).},
journal = {SIAM J. Comput.},
month = feb,
pages = {709–719},
numpages = {11},
keywords = {stochastic analysis, randomized algorithms, contention resolution}
}

@article{10.5555/299868.299889,
author = {Walsh, P. G.},
title = {A Polynomial Time Complexity Bound for Computations on Curves},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
abstract = {In this paper, we use a recent quantitative version of Eisenstein's theorem on power series expansions of algebraic functions to compute a polynomial-time bit complexity bound for the computation of the genus of an algebraic curve over the rationals. The result is extendable to any field of characteristic zero which is finitely generated over the rationals.},
journal = {SIAM J. Comput.},
month = feb,
pages = {704–708},
numpages = {5},
keywords = {algebraic curves, genus, complexity, Puiseux expansion}
}

@article{10.5555/299868.299888,
author = {Yacobi, Yacov},
title = {Fast Exponentiation Using Data Compression},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
abstract = {We present the first exponentiation algorithm that uses the entropy of the source of the exponent  to improve on existing exponentiation algorithms when the entropy is smaller than $(1+w(S)/l(S))^{-1}$,  where $w(S)$ is the Hamming weight of the exponent, and $l(S)$  is its length.  For entropy 1 it is comparable to the best-known general purpose exponentiation algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {700–703},
numpages = {4},
keywords = {discrete-log, fast exponentiation, cryptography, compression}
}

@article{10.5555/299868.299883,
author = {Ivkovic, Zoran and Lloyd, Errol L.},
title = {Fully Dynamic Algorithms for Bin Packing: Being (Mostly) Myopic Helps},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
abstract = {The problem of maintaining an approximate solution for  one-dimensional bin packing when items may arrive and depart dynamically is studied. In accordance with various work on fully dynamic algorithms, and in contrast to prior work on bin packing, it is assumed that the packing may be arbitrarily rearranged to accommodate arriving and departing items. In this context our main result is a fully dynamic approximation algorithm for bin packing MMP that is $frac{5}{4}$-competitive and requires $Theta(log n)$ time per operation (i.e., for an Insert or a Delete of an item). This competitive ratio of $frac{5}{4}$ is nearly as good as that of the best practical off-line algorithms. Our algorithm utilizes the technique (introduced here) whereby the packing of an item is done with a total disregard for already packed items of a smaller size.  This myopic packing of an item may then cause several smaller items to be repacked (in a similar fashion). With a bit of additional sophistication to avoid certain "bad" cases, the number of items (either individual items or "bundles" of very small items treated as a whole) that needs to be repacked is bounded by a constant.},
journal = {SIAM J. Comput.},
month = feb,
pages = {574–611},
numpages = {38},
keywords = {bin packing, fully dynamic algorithm}
}

@article{10.5555/299868.299876,
author = {Du, D. Z. and Gao, B. and Hwang, F. K. and Kim, J. H.},
title = {On Multirate Rearrangeable Clos Networks},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
abstract = {In the multirate switching environment each (connection) request is associated with a bandwidth weight. We consider a three-stage Clos network and assume that each link has a capacity of one (after normalization). The network is rearrangeable if for all possible sets of requests such that each input and output link generates a total weight not exceeding one, there always exists a set of paths, one for each request, such that the sum of weights of all paths going through a link does not exceed the link capacity. The question is to determine the minimum number of center switches which guarantees rearrangeability. We obtain a lower bound of 11n/9 and an upper bound of 41n/16. We then extend the result for the three-stage Clos network to the multistage Clos network. Finally, we propose the weighted version of the edge-coloring problem, which somehow has escaped the literature, associated with our switching network problem.},
journal = {SIAM J. Comput.},
month = feb,
pages = {463–470},
numpages = {8},
keywords = {multirate switching, rearrangeable, Clos network}
}

@article{10.1137/S0097539796310102,
author = {Evans, William and Pippenger, Nicholas},
title = {Average-Case Lower Bounds for Noisy Boolean Decision Trees},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796310102},
doi = {10.1137/S0097539796310102},
abstract = {We present a new method for deriving lower bounds to the expected number of queries made by noisy decision trees computing Boolean functions. The new method has the feature that expectations are taken with respect to a uniformly distributed random input, as well as with respect to the random noise, thus yielding stronger lower bounds. It also applies to many more functions than do previous results. The method yields a simple proof of the result (previously established by Reischuk and Schmeltz) that almost all Boolean functions of n arguments require $Me(n log n)$ queries, and strengthens this bound from the worst-case over inputs to the average over inputs. The method also yields bounds for specific Boolean functions in terms of their spectra (their Fourier transforms). The simplest instance of this spectral bound yields the result (previously established by Feige, Peleg, Raghavan, and Upfal) that the parity function of n arguments requires $Me(n log n)$ queries and again strengthens this bound from the worst-case over inputs to the average over inputs. In its full generality, the spectral bound applies to the "highly resilient" functions introduced by Chor, Friedman, Goldreich, Hastad, Rudich, and Smolensky, and it yields nonlinear lower bounds whenever the resiliency is asymptotic to the number of arguments.},
journal = {SIAM J. Comput.},
month = feb,
pages = {433–446},
numpages = {14},
keywords = {reliability, error-correction, noisy computation, fault-tolerance}
}

@article{10.1137/S0097539796306474,
author = {Hemaspaandra, Edith and Hemaspaandra, Lane A. and Hempel, Harald},
title = {A Downward Collapse within the Polynomial  Hierarchy},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796306474},
doi = {10.1137/S0097539796306474},
abstract = {Downward collapse (also known as upward separation) refers to cases where the equality of two larger classes implies the equality of two smaller classes. We provide an unqualified downward collapse result completely within the polynomial hierarchy.  In particular, we prove that, for k &gt; 2, if ${rm P}^{Sigma^p_k[1]} = {rm P}^{Sigma^p_k[2]}$ then $Sigma^p_k = Pi^p_k = {rm PH}$. We extend this to obtain a more general downward collapse result.},
journal = {SIAM J. Comput.},
month = feb,
pages = {383–393},
numpages = {11},
keywords = {downward collapse, polynomial hierarchy, computational complexity theory, easy-hard arguments}
}

@article{10.1137/S009753979630235X,
author = {Wang, Yongge},
title = {Genericity, Randomness, and Polynomial-Time Approximations},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979630235X},
doi = {10.1137/S009753979630235X},
abstract = {Polynomial-time safe and unsafe approximations for intractable sets were introduced by Meyer and Paterson [Technical Report TM-126, Laboratory for Computer Science, MIT, Cambridge, MA, 1979] and Yesha [SIAM J. Comput., 12 (1983), pp. 411--425], respectively. The question of which sets have optimal safe and unsafe approximations has been investigated  extensively. Duris and Rolim [Lecture Notes in Comput. Sci. 841, Springer-Verlag, Berlin, New York, 1994, pp. 38--51] and Ambos-Spies [Proc. 22nd ICALP, Springer-Verlag, Berlin, New York, 1995, pp. 384--392] showed that the existence of optimal polynomial-time approximations for the safe and unsafe cases is independent. Using the law of the iterated logarithm for p-random sequences (which has been recently proven in [Proc. 11th Conf. Computational Complexity, IEEE Computer Society Press, Piscataway, NJ, 1996, pp. 180--189]), we extend this observation by showing that both the class of polynomial-time $Delta$-levelable sets and the class of sets which have optimal polynomial-time unsafe approximations have p-measure 0. Hence typical sets in E (in the sense of p-measure) do not have optimal polynomial-time unsafe approximations. We will also establish the relationship between resource bounded genericity concepts and the polynomial-time safe and unsafe approximation concepts.},
journal = {SIAM J. Comput.},
month = feb,
pages = {394–408},
numpages = {15},
keywords = {resource bounded genericity, approximation, resource bounded randomness, computational complexity}
}

@article{10.1137/S0097539796297632,
author = {Hemaspaandra, Lane A. and Hempel, Harald and Wechsung, Gerd},
title = {Query Order},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796297632},
doi = {10.1137/S0097539796297632},
abstract = {We study the effect of query order on computational power and show that ${rm P}^{{rm BH}_j[1]:{rm BH}_k[1]}$allowbreak---the languages computable via a polynomial-time machine given one query to the $j$th level of the boolean hierarchy followed by one query to the $k$th level of the boolean hierarchy---equals ${rm R}_{{j+2k-1}{scriptsizembox{-tt}}}^{p}({rm NP})$ if $j$ is even and $k$ is odd and equals ${rm R}_{{j+2k}{scriptsizembox{-tt}}}^{p}({rm NP})$ otherwise. Thus unless the polynomial hierarchy collapses it holds that, for each $1leq j leq k$, ${rm P}^{{rm BH}_j[1]:{rm BH}_k[1]} = {rm P}^{{rm BH}_k[1]:{rm BH}_j [1]} iff (j=k) lor (jmbox{ is even}, land k=j+1)$. We extend our analysis to apply to more general query classes.},
journal = {SIAM J. Comput.},
month = feb,
pages = {637–651},
numpages = {15},
keywords = {computational complexity theory, bounded queries, ordered computation}
}

@article{10.1137/S0097539796297577,
author = {Ar, Sigal and Lipton, Richard J. and Rubinfeld, Ronitt and Sudan, Madhu},
title = {Reconstructing Algebraic Functions from Mixed Data},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796297577},
doi = {10.1137/S0097539796297577},
abstract = {We consider a variant of the traditional task of explicitly reconstructing algebraic functions from black box representations. In the traditional setting for such problems, one is given access to an unknown function  f  that is represented by a black box, or an oracle, which can be queried for the value of  f  at any input. Given a guarantee that this unknown function  f  is some nice algebraic function, say a polynomial in its input of degree bound  d , the goal of the reconstruction problem is to explicitly determine the coefficients of the unknown polynomial. All work on polynomial interpolation, especially sparse ones, are or may be presented in such a setting. The work of Kaltofen and Trager [  Computing with polynomials given by black boxes for their evaluations: Greatest common divisors, factorization, separation of numerators and denominators , in Proc. 29th Ann. IEEE Symp. on Foundations of Computer Science, 1988, pp. 296--305], for instance, highlights the utility of this setting, by performing numerous manipulations on polynomials presented as black boxes. The variant considered in this paper differs from the traditional setting in that our black boxes represent several algebraic functions  f 1,...,  f   k , where at each input  x , the box arbitrarily chooses a subset of  f 1(  x ),...,  f k (  x ) to output and we do not know which subset it outputs. We show how to reconstruct the functions  f 1,...,  f k  from the black box, provided the black box outputs according to these functions "often." This allows us to  group  the sample points into sets, such that for each set, all outputs to points in the set are from the same algebraic function. Our methods are robust in the presence of a small fraction of arbitrary errors in the black box.Our model and techniques can be applied in the areas of computer vision, machine learning, curve fitting and polynomial approximation, self-correcting programs, and bivariate polynomial factorization.},
journal = {SIAM J. Comput.},
month = feb,
pages = {487–510},
numpages = {24},
keywords = {error correcting codes, polynomial factoring, Bezout's theorem, noisy interpolation, PAC learning, multivariate polynomials, polynomial interpolation}
}

@article{10.1137/S0097539795290805,
author = {Broder, Andrei Z. and Frieze, Alan M. and Suen, Stephen and Upfal, Eli},
title = {Optimal Construction of Edge-Disjoint Paths in Random Graphs},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795290805},
doi = {10.1137/S0097539795290805},
abstract = {Given a graph G=(V,E) with n vertices, m edges, and a family of $kappa$ pairs of vertices in $V$, we are interested in finding for each pair (ai, bi) a path connecting ai to bi such that the set of $kappa$ paths so found is edge disjoint.  (For arbitrary graphs the problem is ${cal NP}$-complete, although it is in ${cal P}$ if $kappa$ is fixed.)We present a polynomial time randomized algorithm for finding the optimal number of edge disjoint paths (up to constant factors) in the random graph Gn,m for all edge densities above the connectivity threshold.  (The graph is chosen first; then an adversary chooses the pairs of endpoints.)  Our results give the first tight bounds for the edge-disjoint paths problem for any nontrivial class of graphs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {541–573},
numpages = {33},
keywords = {eigenvalues of random graphs, random graphs, edge-disjoint paths}
}

@article{10.1137/S0097539795290477,
author = {Eppstein, David},
title = {Finding the <i>k</i> Shortest Paths},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795290477},
doi = {10.1137/S0097539795290477},
abstract = {We give algorithms for finding the k shortest paths (not required to be simple) connecting a pair of vertices in a digraph.  Our algorithms output an implicit representation of these paths in a digraph with n vertices and m edges, in time O(m + n log n + k).  We can also find the k shortest paths from a given source s to each vertex in the graph, in total time O(m + n log n + kn).  We describe applications to dynamic programming problems including the knapsack problem, sequence alignment, maximum inscribed polygons, and genealogical relationship discovery.},
journal = {SIAM J. Comput.},
month = feb,
pages = {652–673},
numpages = {22},
keywords = {knapsack problem, path enumeration, dynamic programming, network programming, shortest paths, inscribed polygon, near-optimal solutions, sequence alignment, genealogy}
}

@article{10.1137/S0097539795288799,
author = {Higham, Lisa and Przytycka, Teresa},
title = {Asymptotically Optimal Election on Weighted Rings},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795288799},
doi = {10.1137/S0097539795288799},
abstract = {In a network of asynchronous processors, the cost to send a message can differ significantly from one communication link to another. In such a setting, it is desirable to factor the cost of links into the cost of distributed computation. Assume that associated with each link is a positive weight representing the cost of sending one message along the link, and the cost of an algorithm executed on a weighted network is the sum of the costs of all messages sent during its execution. We determine the asymptotic complexity of distributed leader election on a weighted unidirectional asynchronous ring assuming this notion of cost, by exhibiting a simple algorithm and a matching lower bound for the problem for any collection of edge weights. As a consequence, we see that algorithms designed for unweighted rings are not in general efficient for the weighted case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {720–732},
numpages = {13},
keywords = {distributed election, asynchronous network, weighted ring, message complexity}
}

@article{10.1137/S0097539795285916,
author = {Chin, Francis and Wang, Cao An},
title = {Finding the Constrained Delaunay Triangulation and Constrained Voronoi Diagram of a Simple Polygon in Linear Time},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795285916},
doi = {10.1137/S0097539795285916},
abstract = {In this paper, we present an $Theta (n)$ time worst-case deterministic algorithm for finding the constrained Delaunay triangulation and constrained Voronoi diagram of a simple n-sided polygon in the plane. Up to now, only an O(n log n) worst-case deterministic and an O(n) expected time bound have been shown, leaving an O(n) deterministic solution open to conjecture.},
journal = {SIAM J. Comput.},
month = feb,
pages = {471–486},
numpages = {16},
keywords = {polygon, Voronoi diagram, algorithm, constrained Delaunay triangulation, computational geometry}
}

@article{10.1137/S0097539795283954,
author = {Devroye, Luc},
title = {Universal Limit Laws for Depths in Random Trees},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795283954},
doi = {10.1137/S0097539795283954},
abstract = {Random binary search trees, b-ary search trees, median-of-(2k+1) trees, quadtrees, simplex trees, tries, and digital search trees are special cases of random split trees. For these trees, we offer a universal law of large numbers and a limit law for the depth of the last inserted point, as well as a law of large numbers for the height.},
journal = {SIAM J. Comput.},
month = feb,
pages = {409–432},
numpages = {24},
keywords = {expected time analysis, data structures, random tree, depth of a node, binary search tree, law of large numbers}
}

@article{10.1137/S0097539795279943,
author = {Fiat, Amos and Foster, Dean P. and Karloff, Howard and Rabani, Yuval and Ravid, Yiftach and Vishwanathan, Sundar},
title = {Competitive Algorithms for Layered Graph Traversal},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795279943},
doi = {10.1137/S0097539795279943},
abstract = {A layered graph is a connected graph whose vertices are partitioned into sets L0=s, L1, L2,..., and whose edges,  which have nonnegative integral weights, run between consecutive layers.  Its width is $max{|L_i|}$. In the on-line layered graph traversal problem,  a searcher starts at s in a layered graph of unknown width and tries to reach a target vertex t; however, the vertices in layer i and the edges between layers i-1 and i are only revealed when the searcher reaches layer i-1. We give upper and lower bounds on the competitive ratio of layered graph traversal algorithms. We give a deterministic on-line algorithm which is O(9w)-competitive on width-w graphs and prove that for no w can a deterministic on-line algorithm have a competitive ratio better than 2w-2 on width-w graphs. We prove that for all w, w/2 is a lower bound on the competitive ratio of any randomized on-line layered graph traversal algorithm. For traversing layered graphs consisting of w disjoint paths tied together at a common source, we give a randomized on-line algorithm with a competitive ratio of O(log w) and prove that this is optimal up to a constant factor.},
journal = {SIAM J. Comput.},
month = feb,
pages = {447–462},
numpages = {16},
keywords = {competitive analysis, search strategies, layered graphs}
}

@article{10.1137/S0097539795279931,
author = {Awerbuch, Baruch and Cidon, Israel and Kutten, Shay and Mansour, Yishay and Peleg, David},
title = {Optimal Broadcast with Partial Knowledge},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795279931},
doi = {10.1137/S0097539795279931},
abstract = {This work is concerned with the problem of broadcasting a large message efficiently when each processor has partial prior knowledge about the contents of the broadcast message. The partial information held by the processors might be out of date or otherwise erroneous, and consequently, different processors may hold conflicting information. Tight bounds are established for broadcast under such conditions, and applications of the broadcast protocol to other distributed computing problems are discussed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {511–524},
numpages = {14},
keywords = {error correcting code, distributed algorithms, topology update, self stabilization, universal hash}
}

@article{10.1137/S009753979427491,
author = {Gibbons, Phillip B. and Matias, Yossi and Ramachandran, Vijaya},
title = {The Queue-Read Queue-Write PRAM Model: Accounting for Contention in Parallel Algorithms},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979427491},
doi = {10.1137/S009753979427491},
abstract = {This paper introduces the queue-read queue-write ({sc qrqw}) parallel random access machine ({sc pram}) model, which permits concurrent reading and writing to shared-memory locations, but at a cost proportional to the number of readers/writers to any one memory location in a given step. Prior to this work there were no formal complexity models that accounted for the contention to memory locations, despite its large impact on the performance of parallel programs. The {sc qrqw pram} model reflects the contention properties of most commercially available parallel machines more accurately than either the well-studied {sc crcw pram} or {sc erew pram} models: the {sc crcw} model does not adequately penalize algorithms with high contention to shared-memory locations, while the {sc erew} model is too strict in its insistence on zero contention at each step.The {sc qrqw pram} is strictly more powerful than the {sc erew pram}. This paper shows a separation of $sqrt{log n}$ between the two models, and presents faster and more efficient {sc qrqw} algorithms for several basic problems, such as linear compaction, leader election, and processor allocation. Furthermore, we present a work-preserving emulation of the {sc qrqw pram} with only logarithmic slowdown on Valiant's  {sc bsp} model, and hence on hypercube-type noncombining networks, even when latency, synchronization, and memory granularity overheads are taken into account. This matches the best-known emulation result for the {sc erew pram}, and considerably improves upon the best-known efficient emulation for the {sc crcw pram} on such networks. Finally, the paper presents several lower bound results for this model, including lower bounds on the time required for broadcasting and for leader election.},
journal = {SIAM J. Comput.},
month = feb,
pages = {733–769},
numpages = {37},
keywords = {sc pram, memory contention, work-time framework, parallel algorithms, models of parallel computation}
}

@article{10.1137/S0097539794274246,
author = {Bshouty, Nader H. and Goldberg, Paul W. and Goldman, Sally A. and Mathias, H. David},
title = {Exact Learning of Discretized Geometric Concepts},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794274246},
doi = {10.1137/S0097539794274246},
abstract = {We first present an algorithm that uses membership and equivalence queries to exactly identify a discretized geometric concept defined by the union of  m  axis-parallel boxes in  d -dimensional discretized Euclidean space where each coordinate can have  n  discrete values. This algorithm receives at most  md  counterexamples and uses time and membership queries polynomial in  m  and log  n  for any constant  d . Furthermore, all equivalence queries can be formulated as the union of  O (  md  log  m ) axis-parallel boxes. Next, we show how to extend our algorithm to efficiently learn, from  only  equivalence queries, any discretized geometric concept generated from any number of halfspaces with any number of known (to the learner) slopes in a constant dimensional space. In particular, our algorithm exactly learns (from equivalence queries  only ) unions of discretized axis-parallel boxes in constant dimensional space in polynomial time. Furthermore, this equivalence query only algorithm can be modified to handle a polynomial number of lies in the counterexamples provided by the environment.Finally, we introduce a new complexity measure that better captures the complexity of the union of $m$ boxes than simply the number of boxes and the dimension. Our new measure, $sigma$, is the number of segments in the target, where a segment is a maximum portion of one of the sides of the target that lies entirely inside or entirely outside each of the other halfspaces defining the target. We present a modification of our first algorithm that uses time and queries polynomial in $sigma$ and log  n . In fact, the time and queries (both membership and equivalence) used by this single algorithm are polynomial for  either   m  or  d  constant.},
journal = {SIAM J. Comput.},
month = feb,
pages = {674–699},
numpages = {26},
keywords = {exact learning, geometric concepts, membership and equivalence queries, computational learning}
}

@article{10.1137/S0097539793260763,
author = {Rajagopalan, Sridhar and Vazirani, Vijay V.},
title = {Primal-Dual RNC Approximation Algorithms for Set Cover and Covering Integer Programs},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793260763},
doi = {10.1137/S0097539793260763},
abstract = {We build on the classical greedy sequential set cover algorithm, in the spirit of the primal-dual schema, to obtain simple parallel approximation algorithms for the set cover problem and its generalizations. Our algorithms use randomization, and our randomized voting lemmas may be of independent interest. Fast parallel approximation algorithms were known before for set cover, though not for the generalizations considered in this paper.},
journal = {SIAM J. Comput.},
month = feb,
pages = {525–540},
numpages = {16},
keywords = {primal-dual, set cover, voting lemmas, algorithms, approximation, parallel}
}

@article{10.1137/S0097539793254376,
author = {Goodrich, Michael T. and Tamassia, Roberto},
title = {Dynamic Trees and Dynamic Point Location},
year = {1999},
issue_date = {April 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793254376},
doi = {10.1137/S0097539793254376},
abstract = {This paper describes new methods for maintaining a point-location data structure for a dynamically changing monotone subdivision $cal S$.  The main approach is based on the maintenance of two interlaced spanning trees, one for $cal S$ and one for the graph-theoretic planar dual of $cal S$.  Queries are answered by using a centroid decomposition of the dual tree to drive searches in the primal tree.  These trees are maintained via the link-cut trees structure of Sleator and Tarjan [J. Comput. System Sci., 26 (1983), pp. 362--381], leading to a scheme that achieves vertex insertion/deletion in O(log n) time, insertion/deletion of k-edge monotone chains in O(log n + k) time, and answers queries in O(log2 n) time, with O(n) space, where n is the current size of subdivision $cal S$.  The techniques described also allow for the dual operations expand and contract to be implemented in O(log n) time, leading to an improved method for spatial point location in a 3-dimensional convex subdivision.  In addition, the interlaced-tree approach is applied to on-line point location (where one builds $cal S$ incrementally), improving the query bound to $O(log nloglog n)$ time and the update bounds to O(1)amortized time in this case.  This appears to be the first on-line method to achieve a polylogarithmic query time and constant update time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {612–636},
numpages = {25},
keywords = {on-line algorithms, point location, computational geometry, dynamic data structures, centroid decomposition}
}

@article{10.1137/S0097539796301306,
author = {Geffert, Viliam and Mereghetti, Carlo and Pighizzini, Giovanni},
title = {Sublogarithmic Bounds on Space and Reversals},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796301306},
doi = {10.1137/S0097539796301306},
abstract = {The complexity measure under consideration is $mbox{rm SPACE}!times!mbox{rm REVERSALS}$ for Turing machines that are able to branch both existentially and universally. We show that, for any function $h(n)$ between $loglog n$ and $log n$, $Pi_1 mbox{rm SPACE}!times!mbox{rm REVERSALS} (h(n))$ is separated {}from $Sigma_1 mbox{rm SPACE}!times!mbox{rm REVERSALS} (h(n))$ as well as {}from $mbox{sf co}Sigma_1 mbox{rm SPACE}!times!mbox{rm REVERSALS} (h(n))$, for middle,  accept, and weak modes of this complexity measure. This also separates determinism from the higher levels of the alternating hierarchy. For "well-behaved" functions h(n) between log log n and log n, almost all of the above separations can be obtained by using unary witness languages.In addition, the construction of separating languages contributes to the research on minimal resource requirements for computational devices capable of recognizing nonregular languages. For any (arbitrarily slow growing) unbounded monotone recursive function f(n), a nonregular unary language is presented that can be accepted by a middle mbox{$Pi_1$ alternating} Turing machine in s(n) space and i(n) input head reversals, with $s(n)cdot i(n)in{cal O}(loglog ncdot f(n))$. Thus, there is no exponential gap for the optimal lower bound on the product $s(n)cdot i(n)$ between unary and general nonregular language acceptance---in sharp contrast with the one-way case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {325–340},
numpages = {16},
keywords = {alternation, computational lower bounds, computational complexity, formal languages}
}

@article{10.1137/S0097539796300441,
author = {Fortnow, Lance and Goldsmith, Judy and Levy, Matthew A. and Mahaney, Stephen},
title = {L-Printable Sets},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796300441},
doi = {10.1137/S0097539796300441},
abstract = {A language is L-printable if there is a logspace algorithm which, on input 1n, prints all members in the language of length n.  Following the work of Allender and Rubinstein [SIAM J. Comput., 17 (1988), pp. 1193--1202] on P-printable sets, we present some simple properties of the L-printable sets. This definition of "L-printable" is robust and allows us to give alternate characterizations of  the L-printable sets in terms of tally sets and Kolmogorov complexity.  In addition, we show that a regular or context-free language is L-printable if and only if it is sparse, and  we investigate the relationship between L-printable sets, L-rankable sets (i.e., sets A having a logspace algorithm that, on input x, outputs the number of elements of A that precede x in the standard lexicographic ordering of strings), and the sparse sets in L.  We prove that under reasonable complexity-theoretic assumptions, these three classes of sets are all different.  We also show that the class of sets of small generalized Kolmogorov space complexity is exactly the class of sets that are L-isomorphic to tally languages.},
journal = {SIAM J. Comput.},
month = feb,
pages = {137–151},
numpages = {15},
keywords = {sparse sets, regular languages, ranking, context-free languages, logspace, computational complexity, L-isomorphisms, Kolmogorov complexity}
}

@article{10.1137/S0097539795296206,
author = {K\"{o}bler, Johannes and Watanabe, Osamu},
title = {New Collapse Consequences of NP Having Small Circuits},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795296206},
doi = {10.1137/S0097539795296206},
abstract = {We show that if a self-reducible set has polynomial-size circuits, then it is low for the probabilistic class ZPP (NP). As a consequence we get a deeper collapse of the polynomial-time hierarchy PH to ZPP(NP) under the assumption that NP has polynomial-size circuits. This improves on the well-known result in Karp and Lipton [ Proceedings of the 12th ACM Symposium on Theory of Computing, ACM Press, New York, 1980, pp. 302--309] stating a collapse of PH to its second level $Sigmap_2$ under the same assumption.  Furthermore, we derive new collapse consequences under the assumption that complexity classes like UP, FewP, and C=P have polynomial-size circuits.  Finally, we investigate the circuit-size complexity of several language classes. In particular, we show that for every fixed polynomial s, there is a set in ZPP(NP) which does not have O(s(n))-size circuits.},
journal = {SIAM J. Comput.},
month = feb,
pages = {311–324},
numpages = {14},
keywords = {randomized computation, lowness, polynomial-size circuits, advice classes}
}

@article{10.1137/S0097539795294980,
author = {Malajovich, Gregorio and Meer, Klaus},
title = {On the Structure of $\cal NP_\Bbb C$},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795294980},
doi = {10.1137/S0097539795294980},
abstract = {This paper deals with complexity classes ${cal P}_{Bbb C}$ and ${cal NP}_{Bbb C}$ as they were introduced over the complex numbers by Blum, Shub, and Smale [Bull. Amer. Math. Soc., 21 (1989), p. 1]. Under the assumption ${cal P}_{Bbb C} ne {cal NP}_{Bbb C}$ the existence of noncomplete problems in ${cal NP}_{Bbb C}$ not belonging to ${cal P}_{Bbb C}$ is established.},
journal = {SIAM J. Comput.},
month = feb,
pages = {27–35},
numpages = {9},
keywords = {complexity, BSS machines over $Bbb C$, Hilbert Nullstellensatz, NP-completeness}
}

@article{10.1137/S0097539795291598,
author = {Hampapuram, Haripriyan and Fredman, Michael L.},
title = {Optimal Biweighted Binary Trees and the Complexity of Maintaining Partial Sums},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795291598},
doi = {10.1137/S0097539795291598},
abstract = {Let A be an array.  The partial sum problem concerns the design of a data structure for implementing the following operations. The operation update (j,x) has the effect $A[j] leftarrow A[j]+x ,$, and the query operation $ssum(j)$ returns the partial sum $sum_{i=1}^j , A[i] ,$.  Our interest centers upon the optimal efficiency with which sequences of such operations can be performed, and we derive new upper and lower bounds in the semigroup model of computation. Our analysis relates the optimal complexity of the partial sum problem to optimal binary trees relative to a type of weighting scheme that defines the notion of biweighted binary tree.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–9},
numpages = {9},
keywords = {lower bounds, data structures, partial sums}
}

@article{10.1137/S009753979528826X,
author = {Awerbuch, Baruch and Azar, Yossi and Blum, Avrim and Vempala, Santosh},
title = {New Approximation Guarantees for Minimum-Weight  <i>k</i>-Trees and Prize-Collecting Salesmen},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979528826X},
doi = {10.1137/S009753979528826X},
abstract = {We consider a formalization of the following problem.  A salesperson must sell some quota of brushes in order to win a trip to Hawaii. This salesperson has a map (a weighted graph) in which each city has an attached demand specifying the number of brushes that can be sold in that city.  What is the best route to take to sell the quota while traveling the least distance possible? Notice that unlike the standard traveling salesman problem, not only do we need to figure out the order in which to visit the cities, but we must decide the more fundamental question: which cities do we want to visit?In this paper we give the first approximation algorithm having a polylogarithmic performance guarantee for this problem, as well as for the slightly more general "prize-collecting traveling salesman problem" (PCTSP) of Balas, and a variation we call the "bank robber problem" (also called the "orienteering problem" by Golden, Levi, and Vohra).  We do this by providing an O(log2 k) approximation to the somewhat cleaner k-MST problem which is defined as follows. Given an undirected graph on n nodes with nonnegative edge weights and an integer $k leq n$, find the tree of least weight that spans k vertices. (If desired, one may specify in the problem a "root vertex" that must be in the tree as well.)  Our result improves on the previous best bound of $O(sqrt{k})$ of Ravi et al.},
journal = {SIAM J. Comput.},
month = feb,
pages = {254–262},
numpages = {9},
keywords = {approximation algorithm, k-MST, prize-collecting traveling salesman problem}
}

@article{10.1137/S0097539795286831,
author = {Schwiegelshohn, Uwe and Ludwig, Walter and Wolf, Joel L. and Turek, John and Yu, Philip S.},
title = {Smart SMART Bounds for Weighted Response Time Scheduling},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795286831},
doi = {10.1137/S0097539795286831},
abstract = {Consider a system of independent tasks to be scheduled without preemption on a parallel computer.  For each task the number of processors required, the execution time, and a weight are known. The problem is to find a schedule with minimum weighted average response time. We present an algorithm called SMART (which stands for scheduling to minimize average response time) for this problem that produces solutions that are within a factor of 8.53 of optimal. To our knowledge this is the first polynomial-time algorithm for the minimum weighted average response time problem that achieves a constant bound. In addition, for the unweighted case (that is, where all the weights are unity) we describe a variant of SMART that produces solutions that are within a factor of 8 of optimal, improving upon the best known bound of 32 for this special case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {237–253},
numpages = {17},
keywords = {scheduling, approximate algorithms, parallel computing}
}

@article{10.1137/S0097539795286612,
author = {Khanna, Sanjeev and Motwani, Rajeev and Sudan, Madhu and Vazirani, Umesh},
title = {On Syntactic versus Computational Views of Approximability},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795286612},
doi = {10.1137/S0097539795286612},
abstract = {We attempt to reconcile the two distinct views of approximation classes:  syntactic  and  computational . Syntactic classes such as MAX SNP permit structural results and have natural complete problems, while computational classes such as APX allow us to work with classes of problems whose approximability is well understood. Our results provide a syntactic characterization of computational classes and give a computational framework for syntactic classes. We compare the syntactically defined class MAX SNP with the computationally defined class APX and show that every problem in APX can be "placed" (i.e., has approximation-preserving reduction to a problem) in MAX SNP. Our methods introduce a simple, yet general, technique for creating approximation-preserving reductions which shows that any "well"-approximable problem can be reduced in an approximation-preserving manner to a problem which is hard to approximate to corresponding factors. The reduction then follows easily from the recent nonapproximability results for MAX SNP-hard problems. We demonstrate the generality of this technique by applying it to other classes such as MAX SNP-RMAX(2) and MIN F$^{+}Pi_2(1)$ which have the clique problem and the set cover problem, respectively, as complete problems.The syntactic nature of MAX SNP was used by Papadimitriou and Yannakakis [  J. Comput. System Sci. , 43 (1991), pp. 425--440] to provide approximation algorithms for every problem in the class. We provide an alternate approach to demonstrating this result using the syntactic nature of MAX SNP. We develop a general paradigm,  nonoblivious local search , useful for developing simple yet efficient approximation algorithms. We show that such algorithms can find good approximations for all MAX SNP problems, yielding approximation ratios comparable to the best known for a variety of specific MAX SNP-hard problems. Nonoblivious local search provably outperforms standard local search in both the degree of approximation achieved and the efficiency of the resulting algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {164–191},
numpages = {28},
keywords = {computational complexity, computational classes, approximation algorithms, polynomial reductions, local search, complete problems}
}

@article{10.1137/S0097539795285114,
author = {Kavvadias, Dimitris and Sideri, Martha},
title = {The Inverse Satisfiability Problem},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795285114},
doi = {10.1137/S0097539795285114},
abstract = {We study the complexity of telling whether a set of bit-vectors represents the set of all satisfying truth assignments of a Boolean expression of a certain type. We show that the problem is coNP-complete when the expression is required to be in conjunctive normal form with three literals per clause (3CNF).  We also prove a dichotomy theorem analogous to the classical one by Schaefer, stating that, unless P=NP, the problem can be solved in polynomial time if and only if the clauses allowed are all Horn, or all anti-Horn, or all 2CNF, or all equivalent to equations modulo two.},
journal = {SIAM J. Comput.},
month = feb,
pages = {152–163},
numpages = {12},
keywords = {computational complexity, Boolean satisfiability, model, coNP-completeness, polynomial-time algorithms}
}

@article{10.1137/S0097539795285102,
author = {Zimand, Marius},
title = {Weighted NP Optimization Problems: Logical Definability and Approximation Properties},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795285102},
doi = {10.1137/S0097539795285102},
abstract = {Extending a well-known property of NP optimization problems in which the value of the optimum is guaranteed to be polynomially bounded in the length of the input, it is observed that, by attaching weights to tuples over the domain of the input, all NP optimization problems admit a logical characterization. It is shown that any NP optimization problem can be stated as a problem in which the constraint conditions can be expressed by a $Pi_2$ first-order formula. The paper analyzes the weighted analogue of all syntactically defined classes of optimization problems that are known to have good approximation properties in the nonweighted case. Dramatic changes occur when negative weights are allowed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {36–56},
numpages = {21},
keywords = {NP optimization problems, approximation properties, logical definability, multiprover interactive systems.}
}

@article{10.1137/S0097539795283681,
author = {Cormen, Thomas H. and Sundquist, Thomas and Wisniewski, Leonard F.},
title = {Asymptotically Tight Bounds for Performing BMMC Permutations on Parallel Disk Systems},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795283681},
doi = {10.1137/S0097539795283681},
abstract = {This paper presents asymptotically equal lower and upper bounds for the number of parallel I/O operations required to perform bit-matrix-multiply/complement (BMMC) permutations on the Parallel Disk Model proposed by Vitter and Shriver. A BMMC permutation maps a source index to a target index by an affine transformation over  GF (2), where the source and target indices are treated as bit vectors. The class of BMMC permutations includes many common permutations, such as matrix transposition (when dimensions are powers of 2), bit-reversal permutations, vector-reversal permutations, hypercube permutations, matrix reblocking, Gray-code permutations, and inverse Gray-code permutations. The upper bound improves upon the asymptotic bound in the previous best known BMMC algorithm and upon the constant factor in the previous best known bit-permute/complement (BPC) permutation algorithm. The algorithm achieving the upper bound uses basic linear-algebra techniques to factor the characteristic matrix for the BMMC permutation into a product of factors, each of which characterizes a permutation that can be performed in one pass over the data. The factoring uses new subclasses of BMMC permutations: memoryload-dispersal (MLD) permutations and their inverses. These subclasses extend the catalog of one-pass permutations.Although many BMMC permutations of practical interest fall into subclasses that might be explicitly invoked within the source code, this paper shows how to quickly detect whether a given vector of target addresses specifies a BMMC permutation. Thus, one can determine efficiently at run time whether a permutation to be performed is BMMC and then avoid the general-permutation algorithm and save parallel I/Os by using the BMMC permutation algorithm herein.},
journal = {SIAM J. Comput.},
month = feb,
pages = {105–136},
numpages = {32},
keywords = {potential functions, parallel I/O, universal lower bounds, BMMC permutations, parallel disk systems, bit-defined permutations, matrix factoring}
}

@article{10.1137/S0097539794277871,
author = {Avis, David and Beresford-Smith, Bryan and Devroye, Luc and Elgindy, Hossam and Gu\'{e}vremont, Eric and Hurtado, Ferran and Zhu, Binhai},
title = {Unoriented $Theta$-Maxima in the Plane: Complexity and Algorithms},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794277871},
doi = {10.1137/S0097539794277871},
abstract = {We introduce the unoriented $Theta$-maximum as a new criterion for describing the shape of a set of planar points. We present efficient algorithms for computing the unoriented $Theta$-maximum of a set of planar points. We also propose a simple linear expected time algorithm for computing the unoriented $Theta$-maximum of a set of planar points when $Theta=pi/2$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {278–296},
numpages = {19},
keywords = {lower bound, maxima, expected complexity, plane sweep, probabilistic analysis}
}

@article{10.1137/S0097539794272582,
author = {Poutr\'{e}, Johannes A. La and Westbrook, Jeffery},
title = {Dynamic 2-Connectivity with Backtracking},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794272582},
doi = {10.1137/S0097539794272582},
abstract = {We give algorithms and data structures that maintain the 2-edge and 2-vertex-connected components of a graph under insertions and deletions of edges and vertices, where deletions occur in a backtracking fashion (i.e., deletions undo the insertions in the reverse order). Our algorithms run in $Theta (log n)$ worst-case time per operation and use $Theta (n)$ space, where n is the number of vertices. Using our data structure we can answer queries, which ask whether vertices u and v belong to the same 2-connected component, in $Theta (log n)$ worst-case time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {10–26},
numpages = {17},
keywords = {dynamic graph algorithms, backtracking}
}

@article{10.1137/S0097539794271898,
author = {Awerbuch, Baruch and Berger, Bonnie and Cowen, Lenore and Peleg, David},
title = {Near-Linear Time Construction of Sparse Neighborhood Covers},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794271898},
doi = {10.1137/S0097539794271898},
abstract = {This paper introduces a near-linear time sequential algorithm for constructing a sparse neighborhood cover.  This implies analogous improvements (from quadratic to near-linear time) for any problem whose solution relies on network decompositions, including small edge cuts in planar graphs, approximate shortest paths, and weight- and distance-preserving graph spanners.  In particular, an O(log n) approximation to the k-shortest paths problem on an n-vertex, E-edge graph is obtained that runs in $soh{n + E + k}$ time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {263–277},
numpages = {15},
keywords = {spanners, neighborhood covers, network decompositions, approximate shortest paths}
}

@article{10.1137/S0097539794269072,
author = {Eppstein, David and Galil, Zvi and Italiano, Giuseppe F. and Spencer, Thomas H.},
title = {Separator-Based Sparsification II: Edge and Vertex Connectivity},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794269072},
doi = {10.1137/S0097539794269072},
abstract = {We consider the problem of maintaining a dynamic planar graph subject to edge insertions and edge deletions that preserve planarity but that can change the embedding.  We describe algorithms and data structures for maintaining information about 2- and 3-vertex-connectivity, and 3- and 4-edge-connectivity in a planar graph in O(n1/2) amortized time per insertion, deletion, or connectivity query.  All of the data structures handle insertions that keep the graph planar without regard to any particular embedding of the graph. Our algorithms are based on a new type of sparsification combined with several properties of separators in planar graphs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {341–381},
numpages = {41},
keywords = {edge connectivity, vertex connectivity, planar graphs, dynamic data structures, analysis of algorithms}
}

@article{10.1137/S0097539794266766,
author = {Feder, Tom\'{a}s and Vardi, Moshe Y.},
title = {The Computational Structure of Monotone Monadic SNP and Constraint Satisfaction: A Study through Datalog and Group Theory},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794266766},
doi = {10.1137/S0097539794266766},
abstract = {This paper starts with the project of finding a large subclass of NP which exhibits a dichotomy. The approach is to find this subclass via syntactic prescriptions. While the paper does not achieve this goal, it does isolate a class (of problems specified by) "monotone monadic SNP without inequality" which may exhibit this dichotomy. We justify the placing of all these restrictions by showing, essentially using Ladner's theorem, that classes obtained by using only two of the above three restrictions do not show this dichotomy. We then explore the structure of this class. We show that all problems in this class reduce to the seemingly simpler class CSP. We divide CSP into subclasses and try to unify the collection of all known polytime algorithms for CSP problems and extract properties that make CSP problems NP-hard. This is where the second part of the title, "a study through Datalog and group theory," comes in. We present conjectures about this class which would end in showing the dichotomy.},
journal = {SIAM J. Comput.},
month = feb,
pages = {57–104},
numpages = {48},
keywords = {group theory, graph coloring, satisfiability, linear equations, datalog}
}

@article{10.1137/S0097539794266171,
author = {Felsner, Stefan and Wernisch, Lorenz},
title = {Maximum <i>k</i>-Chains in Planar Point Sets: Combinatorial Structure and Algorithms},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794266171},
doi = {10.1137/S0097539794266171},
abstract = {A chain of a set  P  of  n  points in the plane is a chain of the dominance order on  P . A  k -chain is a subset  C  of  P  that can be covered by  k  chains. A  k -chain  C  is a  maximum k-chain  if no other  k -chain contains more elements than  C . This paper deals with the problem of finding a maximum  k -chain of  P  in the cardinality and in the weighted case. Using the skeleton  S (  P ) of a point set  P  introduced by Viennot we describe a fairly simple algorithm that computes maximum k-chains in time  O (  kn  log  n ) and linear space. The basic idea is that the canonical chain partition of a maximum (  k -1)-chain in the skeleton  S (  P ) provides  k  regions in the plane such that a maximum  k -chain for  P  can be obtained as the union of a maximal chain from each of these regions.By the symmetry between chains and antichains in the dominance order we may use the algorithm for maximum  k -chains to compute maximum  k -antichains for planar points in time  O (  kn  log  n ). However, for large  k  one can do better. We describe an algorithm computing maximum  k -antichains (and, by symmetry,  k -chains) in time  O ((  n 2  k ) log  n ) and linear space. Consequently, a maximum  k -chain can be computed in time  O (  n 3/2 log  n ) for arbitrary  k .The background for the algorithms is a geometric approach to the Greene--Kleitman theory for permutations. We include a skeleton-based exposition of this theory and give some hints on connections with the theory of Young tableaux.The concept of the skeleton of a planar point set is extended to the case of a weighted point set. This extension allows to compute maximum weighted  k -chains with an algorithm that is similar to the algorithm for the cardinality case. The time and space requirements of the algorithm for weighted  k -chains are  O (2kn log(2  kn )) and  O (2  kn ), respectively.},
journal = {SIAM J. Comput.},
month = feb,
pages = {192–209},
numpages = {18},
keywords = {Young tableaux, skeletons, antichains, point sets, algorithms, orders, chains}
}

@article{10.1137/S0097539794261295,
author = {Cohen, Edith},
title = {Fast Algorithms for Constructing <i>t</i>-Spanners and Paths with Stretch <i>t</i>},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {28},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794261295},
doi = {10.1137/S0097539794261295},
abstract = {The distance between two vertices in a weighted graph is the weight of a minimum-weight path between them (where the weight of a path is the sum of the weights of the edges in the path).  A path has stretch t if its weight is at most t times the distance between its end points. We present algorithms that compute paths of stretch $2leq tleqlog n$ on undirected graphs G=(V,E) with nonnegative weights.  The stretch t is of the form $t=beta(2+epsilon')$, where $beta$ is integral and $epsilon'&gt;0$ is at least as large as some fixed $epsilon&gt;0$. We present an $tilde{O}((m+k)n^{(2+epsilon)/t})$ time randomized algorithm that finds paths between k specified pairs of vertices and an $tilde{O}((m+ns)n^{2(1+log_n m+epsilon)/t})$ deterministic algorithm that finds paths from $s$ specified sources to all other vertices (for any fixed $epsilon&gt;0$), where n=|V| and m=|E|. This improves significantly over the slower $tilde{O}(min{k,n}m)$ exact shortest paths algorithms and a previous $tilde{O}(mn^{64/t}+kn^{32/t})$ time algorithm by Awerbuch {et al.} [Proc. 34th IEEE Annual Symposium on Foundations of Computer Science, IEEE, Piscataway, NJ, 1993, pp. 638--647]. A t-spanner of a graph G is a set of weighted edges on the vertices of G such that distances in the spanner are not smaller and within a factor of t from the corresponding distances in G. Previous work was concerned with bounding the size and efficiently constructing t-spanners. We construct t-spanners of size $tilde{O}(n^{1+(2+epsilon)/t})$  in $tilde{O}(mn^{(2+epsilon)/t})$ expected time (for any fixed $epsilon&gt;0$), which constitutes a faster construction (by a factor of n3+2/t /m) of sparser spanners than was previously attainable. We also provide efficient parallel constructions. Our algorithms are based on pairwise covers and a novel approach to construct them efficiently.},
journal = {SIAM J. Comput.},
month = feb,
pages = {210–236},
numpages = {27},
keywords = {parallel algorithms, shortest paths, graph spanners}
}

@article{10.5555/291511.291519,
author = {Chang, Maw-Shang},
title = {Efficient Algorithms for the Domination Problems on Interval and Circular-Arc Graphs},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
abstract = {This paper first presents a unified approach to design efficient algorithms for the weighted domination problem and its three variants, i.e., the weighted independent, connected, and total domination problems, on interval graphs. Given an interval model with endpoints sorted, these algorithms run in time O(n) or O(n log log n) where n is the number of vertices. The results are then extended to solve the same problems on circular-arc graphs in O(n + m) time where m is the number of edges of the input graph.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1671–1694},
numpages = {24},
keywords = {circular-arc graphs, domination, interval graphs, graph algorithms}
}

@article{10.5555/291511.291518,
author = {Attiya, Hagit and Friedman, Roy},
title = {A Correctness Condition for High-Performance Multiprocessors},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
abstract = {Hybrid consistency, a consistency condition for shared memory multiprocessors, attempts to capture the guarantees provided by contemporary high-performance architectures. It combines the expressiveness of strong consistency conditions (e.g., sequential consistency, linearizability) and the efficiency of  weak consistency conditions (e.g., pipelined RAM, causal memory). Memory access operations are classified as either  strong or weak. A global ordering of strong operations at different processes is guaranteed, but there is very little guarantee on the ordering of weak operations at different processes, except for what is implied by their interleaving with the strong operations. A formal and precise definition of this condition is given and an algorithm for providing hybrid consistency on distributed memory machines is presented. The response time of the algorithm is proved to be within a constant multiplicative factor of the (theoretical) optimal time bounds.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1637–1670},
numpages = {34},
keywords = {hybrid consistency, distributed shared memory, sequential consistency, weak consistency, consistency conditions}
}

@article{10.5555/291511.291517,
author = {Krishnan, P. and Vitter, Jeffrey Scott},
title = {Optimal Prediction for Prefetching  in the Worst Case},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
abstract = {Response time delays caused by I/O are a major problem in many systems and database applications. Prefetching and cache replacement methods are attracting renewed attention because of their success in avoiding costly I/Os.  Prefetching can be looked upon as a type of online sequential prediction, where the predictions must be accurate as well as  made in a computationally efficient way. Unlike other online problems, prefetching cannot admit a competitive analysis, since the optimal offline prefetcher incurs no cost when it knows the future page requests. Previous analytical work on prefetching [. Vitter Krishnan 1991.] [J. Assoc. Comput. Mach., 143 (1996), pp. 771--793] consisted  of modeling the user as a probabilistic Markov source. In this paper, we look at the much stronger form of worst-case analysis and derive a randomized algorithm for pure prefetching. We compare our algorithm for every page request sequence with the important class of finite state prefetchers, making no assumptions as to how the sequence of page requests is generated. We prove analytically that the fault rate of our online prefetching algorithm converges almost surely for every page request sequence to the fault rate of the optimal finite state prefetcher for the sequence. This analysis model can be looked upon as a generalization of the competitive framework, in that it compares an online algorithm in a worst-case manner over all sequences with a powerful yet nonclairvoyant opponent. We simultaneously achieve the computational goal of implementing our prefetcher in optimal constant expected time per prefetched page using the optimal dynamic discrete random variate generator of [. Matias Matias, Vitter, and Ni [Proc. 4th Annual SIAM/ACM Symposium on Discrete Algorithms, Austin, TX, January 1993].},
journal = {SIAM J. Comput.},
month = dec,
pages = {1617–1636},
numpages = {20},
keywords = {hypertext, finite state prefetchers, competitive analysis, caching, operating systems, prefetching, fault rate, machine learning, databases, prediction, response time}
}

@article{10.5555/291511.291512,
author = {Aizenstein, Howard and Blum, Avrim and Khardon, Roni and Kushilevitz, Eyal and Pitt, Leonard and Roth, Dan},
title = {On Learning Read-<i>k</i>-Satisfy-<i>j</i> DNF},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
abstract = {We study the learnability of read-k-satisfy-j (RkSj) DNF formulas. These are boolean formulas in disjunctive normal form (DNF), in which the maximum number of occurrences of a variable is bounded by k, and the number of terms satisfied by any assignment is at most j. After motivating the investigation of this class of DNF formulas, we present an algorithm that for any unknown RkSj DNF formula to be learned, with high probability finds a logically equivalent DNF formula using the well-studied protocol of equivalence and membership queries.  The algorithm runs in polynomial time for $kcdot j=O({log noverloglog n})$, where n is the number of input variables.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1515–1530},
numpages = {16},
keywords = {computational learning theory, decision trees, learning, DNF}
}

@article{10.1137/S009753979629766,
author = {Paredaens, Jan and Vanden Bussche, Jan and Van Gucht, Dirk},
title = {First-Order Queries on Finite Structures Over the Reals},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979629766},
doi = {10.1137/S009753979629766},
abstract = {We investigate properties of finite relational structures over the reals expressed by first-order sentences whose predicates are the relations of the structure plus arbitrary polynomial inequalities, and whose quantifiers can range over the whole set of reals.  In constraint programming terminology, this corresponds to Boolean real polynomial constraint queries on finite structures.  The fact that quantifiers range over all reals seems crucial; however, we observe that each sentence in the first-order theory of the reals can be evaluated by letting each quantifier range over only a finite set of real numbers without changing its truth value. Inspired by this observation, we then show that when all polynomials used are linear, each query can be expressed uniformly on all finite structures by a sentence of which the quantifiers range only over the finite domain of the structure. In other words, linear constraint programming on finite structures can be reduced to ordinary query evaluation as usual in finite model theory and databases. Moreover, if only "generic" queries are taken into consideration, we show that this can be reduced even further by proving that such queries can be expressed by sentences using as polynomial inequalities only those of the simple form x &lt; y.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1747–1763},
numpages = {17},
keywords = {constraint programming, linear arithmetic, relational databases, first-order logic}
}

@article{10.1137/S0097539795296760,
author = {Kushilevitz, Eyal and Ostrovsky, Rafail and Ros\'{e}n, Adi},
title = {Log-Space Polynomial End-to-End Communication},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795296760},
doi = {10.1137/S0097539795296760},
abstract = {Communication between processors is the essence of distributed computing: clearly, without communication, distributed computation is impossible. However, as networks become larger and larger, the frequency of link failures increases. The end-to-end communication problem asks how to efficiently carry out fault-free communication between two processors over a network, in spite of such  frequent  link failures. The sole minimum assumption is that the two processors that are trying to communicate are not permanently disconnected (i.e., the communication should proceed even when there does not (ever) simultaneously exist an operational path between the two processors that are trying to communicate). We present a protocol to solve the end-to-end problem with logarithmic-space and polynomial communication at the same time. This is an exponential memory improvement to all previous polynomial communication solutions. That is, all previous polynomial communication solutions needed at least  linear  (in  n , the size of the network) amount of memory per link.Our protocol transfers packets over the network, maintains a simple-to-compute  O (log  n )-bits potential function at each link in order to perform routing, and uses a novel technique of packet canceling which allows us to keep only  one  packet per link. The computations of both our potential function and our packet-canceling policy are totally local in nature.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1531–1549},
numpages = {19},
keywords = {unreliable networks, space complexity, end-to-end communication}
}

@article{10.1137/S0097539795289859,
author = {Bodlaender, Hans L. and Hagerup, Torben},
title = {Parallel Algorithms with Optimal Speedup for Bounded Treewidth},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795289859},
doi = {10.1137/S0097539795289859},
abstract = {We describe the first parallel algorithm with optimal speedup for constructing minimum-width tree decompositions of graphs of bounded treewidth. On n-vertex input graphs, the algorithm works in O((log n)2) time using O(n) operations on the EREW PRAM. We also give faster parallel algorithms with optimal speedup for the problem of deciding whether the treewidth of an input graph is bounded by a given constant and for a variety of problems on graphs of bounded treewidth, including all decision problems expressible in monadic second-order logic. On n-vertex input graphs, the algorithms use O(n) operations together with O(log n log* n) time on the EREW PRAM, or O(log n) time on the CRCW PRAM.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1725–1746},
numpages = {22},
keywords = {monadic second-order logic, tree decomposition, derandomization, pathwidth, treewidth, graph reduction, graph algorithms, parallel algorithms, partial k-trees}
}

@article{10.1137/S0097539795287642,
author = {Kannan, Sampath and Warnow, Tandy and Yooseph, Shibu},
title = {Computing the Local Consensus of Trees},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795287642},
doi = {10.1137/S0097539795287642},
abstract = {The inference of consensus from a set of evolutionary trees is a fundamental problem in a number of fields such as biology and historical linguistics, and many models for inferring this consensus have been proposed. In this paper we present a model for deriving what we call a local consensus tree T  from a set of trees ${cal T}$. The model we propose presumes a function f, called a  total local consensus function, which determines for every triple A of species, the form that the local consensus tree should take on A. We show that all local consensus trees, when they exist, can be constructed in polynomial time and that many fundamental problems can be solved in linear time. We also consider partial local consensus functions and study optimization problems under this model. We present linear time algorithms for several variations. Finally we point out that the local consensus approach ties together many previous approaches to constructing consensus trees.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1695–1724},
numpages = {30},
keywords = {evolutionary trees, algorithms, graphs}
}

@article{10.1137/S0097539795283504,
author = {Kao, Ming-Yang},
title = {Tree Contractions and Evolutionary Trees},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795283504},
doi = {10.1137/S0097539795283504},
abstract = {An evolutionary tree is a rooted tree where each internal vertex has at least two children and where the leaves are labeled with distinct symbols representing species.  Evolutionary trees are useful for modeling the evolutionary history of species.  An agreement subtree of two evolutionary trees is an evolutionary tree which is also a topological subtree of the two given trees.  We give an algorithm to determine the largest possible number of leaves in any agreement subtree of two trees T1 and T2 with n leaves each.  If the maximum degree d of these trees is bounded by a constant, the time complexity is O(n log2n) and is within a log n factor of optimal. For general d, this algorithm runs in O(nd2 log d log2 n) time or alternatively in $O(ndsqrt{d}log^3{n})$ time.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1592–1616},
numpages = {25},
keywords = {evolutionary trees, tree contractions, computational biology, minimal condensed forms}
}

@article{10.1137/S009753979426513X,
author = {Kushilevitz, Eyal and Mansour, Yishay and Rabin, Michael O. and Zuckerman, David},
title = {Lower Bounds for Randomized Mutual Exclusion},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979426513X},
doi = {10.1137/S009753979426513X},
abstract = {We establish, for the first time, lower bounds for randomized mutual exclusion algorithms (with a read-modify-write operation). Our main result is that a constant-size shared variable cannot guarantee strong fairness, even if randomization is allowed. In fact, we prove a lower bound of $Omega (loglog n)$ bits on the size of the shared variable, which is also tight.We investigate weaker fairness conditions and derive tight (upper and lower) bounds for them as well. Surprisingly, it turns out that slightly weakening the fairness condition results in an exponential reduction in the size of the required shared variable. Our lower bounds rely on an analysis of Markov chains that may be of interest on its own and may have applications elsewhere.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1550–1563},
numpages = {14},
keywords = {randomized distributed algorithms, lower bounds, mutual exclusion, Markov chains}
}

@article{10.1137/S0097539794262847,
author = {Battista, Giuseppe Di and Liotta, Giuseppe and Vargiu, Francesco},
title = {Spirality and Optimal Orthogonal Drawings},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794262847},
doi = {10.1137/S0097539794262847},
abstract = {We deal with the problem of constructing the orthogonal drawing of a graph with the minimum number of bends along the edges. The problem has been recently shown to be NP-complete in the general case. In this paper we introduce and study the new concept of spirality, which is a measure of how an orthogonal drawing is "rolled up," and develop a theory on the interplay between spirality and number of bends of orthogonal drawings. We exploit this theory to present polynomial time algorithms for two significant classes of graphs: series-parallel graphs and 3-planar graphs.  Series-parallel graphs arise in a variety of problems such as scheduling, electrical networks, data-flow analysis, database logic programs, and circuit layout. Also, they play a central role in planarity problems. Furthermore, drawings of 3-planar graphs are a classical field of investigation.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1764–1811},
numpages = {48},
keywords = {planar embedding, bend minimization, orthogonal representation, graph drawing}
}

@article{10.1137/S0097539793250329,
author = {Lai, Tony W. and Wood, Derick},
title = {Adaptive Heuristics for Binary Search Trees and Constant Linkage Cost},
year = {1998},
issue_date = {Dec. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250329},
doi = {10.1137/S0097539793250329},
abstract = {We present lower and upper bounds on adaptive heuristics for maintaining binary search trees using a constant number of link or pointer changes for each operation (constant linkage cost (CLC)). We show that no adaptive heuristic with an amortized linkage cost of o(log n) can be competitive. In particular, we show that any heuristic that performs f( n)= o(log n) promotions (rotations) amortized over each access has a competitive ratio of at least $Omega(log n/f(n))$ against an oblivious adversary, and any heuristic that performs f( n)= o(log n) pointer changes amortized over each access has a competitive ratio of at least $Omega(frac{log n}{f(n)log(log n/f(n))})$ against an adaptive online adversary. In our investigation of upper bounds we present four adaptive heuristics: a randomized, worst-case-CLC heuristic randomized two-promotion (R2P) whose expected search time is within a constant factor of the search time using an optimal tree; that is, it is statically competitive against an oblivious adversary; a randomized, expected-CLC heuristic (locally optimized randomized partial splay (LORPS)) that has O (log n ) expected-amortized update time and is statically competitive against an oblivious adversary; a deterministic, amortized-CLC heuristic (locally optimized partial splay (LOPS)) that has O (log n ) amortized update time and is statically competitive against an adaptive adversary; a practical, randomized heuristic (randomized partial splay (RPS)) that is not CLC but has performance bounds comparable with those of the splay heuristic of Sleator and Tarjan; it is statically competitive against an adaptive adversary. The randomized heuristics use only constant extra space, whereas the deterministic heuristic uses O ( n ) extra space.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1564–1591},
numpages = {28},
keywords = {self-organization, binary search trees, expected amortization, constant linkage cost, adaptivity, self-adjustment, competitive ratio}
}

@article{10.1137/S0097539795295924,
author = {Ogihara, Mitsunori},
title = {The PL Hierarchy Collapses},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795295924},
doi = {10.1137/S0097539795295924},
abstract = {It is shown that the PL hierarchy PLH = PL ,bigcuplimits, PLPL ,bigcuplimits, PLPLPL ,bigcuplimits, cdots$, defined in terms of the Ruzzo--Simon--Tompa relativization, collapses to PL.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1430–1437},
numpages = {8},
keywords = {logspace reducibility, probabilistic complexity classes, constant-depth circuits, nondeterministic complexity classes, relativization}
}

@article{10.1137/S0097539795295626,
author = {Heckler, C. and Thiele, L.},
title = {Complexity Analysis of a Parallel Lattice Basis Reduction Algorithm},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795295626},
doi = {10.1137/S0097539795295626},
abstract = {Lattice basis reduction is an important problem in geometry of numbers with applications in combinatorial optimization, computer algebra, and cryptography. The well-known sequential LLL algorithm finds a short vector in O(n4 log B) arithmetic operations on integers having binary length O(n log B), where n denotes the dimension of the lattice and B denotes the maximum L2 norm of the initial basis vectors. In this paper a new analysis of the parallel algorithm of Roch and Villard is presented. It is shown that on an n x n mesh it needs O(n2 log B) arithmetic operations on integers having binary length O(n log B). This improves the previous analysis and shows that an asymptotical speedup of n2 is possible using n2 processors.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1295–1302},
numpages = {8},
keywords = {parallel algorithms, lattice basis reduction, size of the numbers, parallel computational complexity}
}

@article{10.1137/S0097539795285631,
author = {Goldmann, Mikael and H\r{a}stad, Johan},
title = {Monotone Circuits for Connectivity Have Depth (Log <i>n</i>)<sup>2-<i>o</i>(1)</sup>},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795285631},
doi = {10.1137/S0097539795285631},
abstract = {We prove that a monotone circuit of size nd recognizing connectivity must have depth $Omega((log n)^2/log d)$.  For formulas this implies depth $Omega((log n)^2/loglog n)$. For polynomial-size circuits the bound becomes $Omega((log n)^2)$ which is optimal up to a constant.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1283–1294},
numpages = {12},
keywords = {connectivity, circuit complexity, lower bounds, monotone circuits}
}

@article{10.1137/S0097539795285254,
author = {Marathe, Madhav V. and Hunt, Harry B. and Stearns, Richard E. and Radhakrishnan, Venkatesh},
title = {Approximation Algorithms for PSPACE-Hard Hierarchically  and Periodically Specified Problems},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795285254},
doi = {10.1137/S0097539795285254},
abstract = {We study the efficient approximability of basic graph and logic problems in the literature when instances are specified hierarchically as in [T. Lengauer, J. Assoc. Comput. Mach., 36(1989), pp. 474--509] or are specified by one-dimensional finite narrow periodic specifications as in [E. Wanke, Paths and cycles in finite periodic graphs, in Lecture Notes in Comp. Sci. 711, Springer-Verlag, New York, 1993, pp. 751--760]. We show that, for most of the problems $Pi$ considered when specified using k-level-restricted hierarchical specifications or k-narrow periodic specifications, the following hold. Let $rho$ be any performance guarantee of a polynomial time approximation algorithm for $Pi$, when instances are specified using standard specifications. Then $forall epsilon &gt; 0$, $ Pi$ has a polynomial time approximation algorithm with performance guarantee $(1 + epsilon) rho$. $Pi$ has a polynomial time approximation scheme when restricted to planar instances. These are the first polynomial time approximation schemes for PSPACE-hard hierarchically or periodically specified problems. Since several of the problems considered are PSPACE-hard, our results provide the first examples of natural PSPACE-hard optimization problems that have polynomial time approximation schemes. This answers an open question in Condon et al. [Chicago J. Theoret. Comput. Sci., 1995, Article 4].},
journal = {SIAM J. Comput.},
month = oct,
pages = {1237–1261},
numpages = {25},
keywords = {computational complexity, PSPACE-hardness, hierarchical specifications, approximation algorithms, VLSI design, periodic specifications, CAD systems}
}

@article{10.1137/S0097539794291580,
author = {Gil, Joseph and Matias, Yossi},
title = {Simple Fast Parallel Hashing by Oblivious Execution},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794291580},
doi = {10.1137/S0097539794291580},
abstract = {A hash table is a representation of a set in a linear size data structure that supports constant-time membership queries. We show how to construct a hash table for any given set of n keys in O(lg lg n) parallel time with high probability, using n processors on a weak version of a concurrent-read concurrent-write parallel random access machine ( crcw pram ). Our algorithm uses a novel approach of hashing by "oblivious execution" based on probabilistic analysis. The algorithm is simple and has the following structure: Partition the input set into buckets by a random polynomial of constant degree. For t := 1 to O (lg lg n ) do Allocate M t memory blocks, each of size K t . Let each bucket select a block at random, and try to injectively map its keys into the block using a random linear function. Buckets that fail carry on to the next iteration. The crux of the algorithm is a careful a priori selection of the parameters M t and K t . The algorithm uses only O (lg lg n ) random words and can be implemented in a work-efficient manner.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1348–1375},
numpages = {28},
keywords = {hashing, parallel computation, data structures, randomization}
}

@article{10.1137/S0097539794277421,
author = {Beigel, R. and Goldsmith, J.},
title = {Downward Separation Fails Catastrophically for Limited Nondeterminism Classes},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794277421},
doi = {10.1137/S0097539794277421},
abstract = {The $beta$ hierarchy consists of classes $beta_k={rm NP}[logkn]subseteq {rm NP}$.  Unlike collapses in the polynomial hierarchy and the Boolean hierarchy, collapses in the $beta$ hierarchy do not seem to translate up, nor does closure under complement seem to cause the hierarchy to collapse.  For any consistent set of collapses and separations of levels of the hierarchy that respects ${rm P} = beta_1subseteq beta_2subseteq cdots subseteq {rm NP}$, we can construct an oracle relative to which those collapses and separations hold; at the same time we can make distinct levels of the hierarchy closed under computation or not, as we wish.  To give two relatively tame examples: for any $k geq 1$, we construct an oracle relative to which [ {rm P} = beta_{k} neq beta_{k+1} neq beta_{k+2} neq cdots ] and another oracle relative to which [ {rm P} = beta_{k} neq beta_{k+1} = {rm PSPACE}. ] We also construct an oracle relative to which $beta_{2k} = beta_{2k+1} neq beta_{2k+2}$ for all k.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1420–1429},
numpages = {10},
keywords = {structural complexity theory, oracles, hierarchies, limited nondeterminism}
}

@article{10.1137/S0097539794277135,
author = {Edmonds, Jeff A.},
title = {Time--Space Tradeoffs For Undirected <i>St</i>-Connectivity on a Graph Automata},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794277135},
doi = {10.1137/S0097539794277135},
abstract = {Undirected st-connectivity is an important problem in computing.  There are algorithms for this problem that use O(n) time and ones that use O(log n) space. The main result of this paper is that, in a very natural structured model, these upper bounds are not simultaneously achievable.  Any probabilistic jumping automaton for graphs (JAG) requires either space $Omega( log^2 n / log log n )$ or time $n^{(1 + Omega ( 1 / log log n )) }$ to solve undirected st-connectivity.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1492–1513},
numpages = {22},
keywords = {time--space tradeoffs, undirected st-connectivity, JAG graph, lower bounds}
}

@article{10.1137/S0097539794275860,
author = {Dezani-Ciancaglini, Mariangiola and de'Liguoro, Ugo and Piperno, Adolfo},
title = {A Filter Model for Concurrent $\lambda$-Calculus},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794275860},
doi = {10.1137/S0097539794275860},
abstract = {Type-free lazy $lambda$-calculus is enriched with angelic parallelism and demonic nondeterminism. Call-by-name and call-by-value abstractions are considered and the operational semantics is stated in terms of a must convergence predicate. We introduce a type assignment system with intersection and union types, and we prove that the induced logical semantics is fully abstract.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1376–1419},
numpages = {44},
keywords = {functional programming, nondeterminism, $lambda$-calculus, parallelism, full abstraction, concurrency}
}

@article{10.1137/S0097539794275136,
author = {Beals, Robert and Nishino, Tetsuro and Tanaka, Keisuke},
title = {On the Complexity of Negation-Limited  Boolean Networks},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794275136},
doi = {10.1137/S0097539794275136},
abstract = {A theorem of Markov precisely determines the number  r  of NEGATION gates necessary and sufficient to compute a system of boolean functions  F . For a system of boolean functions on  n  variables, $rleq b(n)=lceillog_2(n+1)rceil$. We call a circuit using  b (  n ) NEGATION gates  negation-limited . We continue recent investigations into negation-limited circuit complexity, giving both upper and lower bounds. A circuit with inputs  x 1,...,  x   n  and outputs $neg x_1, ldots, neg x_n$ is called an  inverter , for which $r=lceillog_2(n+1)rceil$. Fischer has constructed negation-limited inverters of size  O (  n 2 log  n ) and depth  O (log  n ). Recently, Tanaka and Nishino have reduced the circuit size to  O (  n  log2  n ) at the expense of increasing the depth to log2  n . We construct negation-limited inverters of size  O (  n  log  n ), with depth only  O (log  n ), and we conjecture that this is optimal. We also improve a technique of Valiant for constructing monotone circuits for slice functions (introduced by Berkowitz).Next, we introduce some lower bound techniques for negation-limited circuits. We provide a 5  n +3 log(  n +1)-  c  lower bound for the size of a negation-limited inverter. In addition, we show that for two different restricted classes of circuit, negation-limited inverters require superlinear size.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1334–1347},
numpages = {14},
keywords = {lower bounds, negation-limited circuit, upper bounds, circuit complexity}
}

@article{10.1137/S0097539794268753,
author = {Kortsarz, Guy and Peleg, David},
title = {Generating Low-Degree 2-Spanners},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268753},
doi = {10.1137/S0097539794268753},
abstract = {A k-spanner of a connected (undirected unweighted) graph G=(V,E) is a subgraph G' consisting of all the vertices of V and a subset of the edges, with the additional property that the distance between any two vertices in G' is larger than that distance in G by no more than a factor of k. This paper is concerned with approximating the problem of finding a 2-spanner in a given graph, with minimum maximum degree. We first show that the problem is at least as hard to approximate as set cover. Then a randomized approximation algorithm is provided for this problem, with approximation ratio of $tilde O(Delta^{1/4})$. We then present a probabilistic algorithm that is more efficient for sparse graphs. Our algorithms are converted into deterministic ones using derandomization.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1438–1456},
numpages = {19},
keywords = {NP-hardness, graph spanners, randomized rounding, approximation}
}

@article{10.1137/S0097539794268637,
author = {Coffman, E. G. and Kahale, Nabil and Leighton, F. T.},
title = {Processor-Ring Communication: A Tight Asymptotic Bound on Packet Waiting Times},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268637},
doi = {10.1137/S0097539794268637},
abstract = {We consider N processors communicating unidirectionally over a closed transmission channel, or ring. Each message is assembled into a fixed-length packet. Packets to be sent are generated at random times by the processors, and the transit times spent by packets on the ring are also random. Packets being forwarded, i.e., packets already on the ring, have priority over waiting packets. The objective of this paper is to analyze packet waiting times under a greedy policy within a discrete Markov model that retains the overall structure of a practical system but is simple enough so that explicit results can be proved. Independent, identical Bernoulli processes model message generation at the processors, and independently and identically distributed (i.i.d.) geometric random variables model the transit times. Our emphasis is on asymptotic behavior for large ring sizes, $N$, when the respective rate parameters have the scaling $lambda /N$ and $mu /N$. Our main result shows that, if the traffic intensity is fixed at $rho = lambda / mu &lt; 1$, then as $N to infty$ the expected time a message waits to be put on the ring is bounded by a constant. This result verifies that the expected waiting time under the greedy policy is within a constant factor of that under an optimal policy.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1221–1236},
numpages = {16},
keywords = {routing algorithm analysis, queuing networks, processor interconnection networks, processor rings, asymptotic analysis}
}

@article{10.1137/S009753979426112X,
author = {Dyer, Martin and Frieze, Alan and Jerrum, Mark},
title = {Approximately Counting Hamilton Paths and Cycles in Dense Graphs},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979426112X},
doi = {10.1137/S009753979426112X},
abstract = {We describe fully polynomial randomized approximation schemes for the problems of determining the number of Hamilton paths and cycles in an  n -vertex graph with minimum degree $(frac{1}{2}+a)n$, for any fixed  a  &gt; 0. We show that the exact counting problems are #P-complete. We also describe fully polynomial randomized approximation schemes for counting paths and cycles of all sizes in such graphs.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1262–1272},
numpages = {11},
keywords = {Hamilton cycles, fpras, dense}
}

@article{10.1137/S0097539793283151,
author = {Barnes, Greg and Buss, Jonathan F. and Ruzzo, Walter L. and Schieber, Baruch},
title = {A Sublinear Space, Polynomial Time Algorithm for Directed <i>s</i>-<i>t</i> Connectivity},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793283151},
doi = {10.1137/S0097539793283151},
abstract = {Directed s-t connectivity is the problem of detecting whether there is a path from vertex s to vertex t in a directed graph. We present the first known deterministic sublinear space, polynomial time algorithm for directed s-t connectivity. For $n$-vertex graphs, our algorithm can use as little as $n/2^{Theta(sqrt{log n})}$ space while still running in polynomial time.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1273–1282},
numpages = {10},
keywords = {time-space tradeoff, graph reachability, s-t connectivity, NNJAG, graph connectivity, NL, JAG}
}

@article{10.1137/S0097539793255527,
author = {Dwork, Cynthia and Halpern, Joseph Y. and Waarts, Orli},
title = {Performing Work Efficiently in the Presence of Faults},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255527},
doi = {10.1137/S0097539793255527},
abstract = {We consider a system of t synchronous processes that communicate only by sending messages to one another, and together the processes must perform n independent units of work. Processes may fail by crashing; we want to guarantee that in every execution of the protocol in which at least one process survives, all n units of work will be performed. We consider three parameters: the number of messages sent, the total number of units of work performed (including multiplicities), and time. We present three protocols for solving the problem. All three are work optimal, doing O(n+t) work. The first has moderate costs in the remaining two parameters, sends $O(tsqrt{t})$ messages, and takes O(n+t) time. This protocol can be easily modified to run in any completely asynchronous system equipped with a failure detection mechanism. The second sends only O(t log t) messages, but its running time is large (O(t2(n+t) 2n+t)). The third is essentially time optimal in the (usual) case in which there are no failures, and its time complexity degrades gracefully as the number of failures increases.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1457–1491},
numpages = {35},
keywords = {Byzantine agreement, work, load balancing, distributed systems, fault tolerance}
}

@article{10.1137/S0097539793255163,
author = {Leighton, F. Thomson and Maggs, Bruce M. and Sitaraman, Ramesh K.},
title = {On the Fault Tolerance of Some Popular Bounded-Degree Networks},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255163},
doi = {10.1137/S0097539793255163},
abstract = {In this paper, we analyze the fault tolerance of several bounded-degree networks that are commonly used for parallel computation. Among other things, we show that an N-node butterfly network containing $N^{1-epsilon}$ worst-case faults (for any constant $epsilon &gt; 0$) can emulate a fault-free butterfly of the same size with only constant slowdown.  The same result is proved for the shuffle-exchange network.  Hence, these networks become the first connected bounded-degree networks known to be able to sustain more than a constant number of worst-case faults without suffering more than a constant-factor slowdown in performance.  We also show that an N-node butterfly whose nodes fail with some constant probability p can emulate a fault-free network of the same type and size with a slowdown of 2O(log* N).  These emulation schemes combine the technique of redundant computation with new algorithms for routing packets around faults in hypercubic networks.  We also present techniques for tolerating faults that do not rely on redundant computation.  These techniques tolerate fewer faults but are more widely applicable because they can be used with other networks such as binary trees and meshes of trees.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1303–1333},
numpages = {31},
keywords = {butterfly network, network emulation, fault tolerance}
}

@article{10.5555/284943.284974,
author = {Hunt, Harry B. and Marathe, Madhav V. and Radhakrishnan, Venkatesh and Stearns, Richard E.},
title = {The Complexity of Planar Counting Problems},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
abstract = {We prove the #P-hardness of the counting problems associated with various satisfiability, graph, and combinatorial problems, when restricted to planar instances. These problems include 3Sat, 1-3Sat, 1-Ex3Sat, Minimum Vertex Cover, Minimum Dominating Set, Minimum Feedback Vertex Set, X3C, Partition Into Triangles, and Clique Cover. We also prove the NP-completeness of the Ambiguous Satisfiability problems [J. B. Saxe,  Two Papers on Graph Embedding Problems , Tech. Report CMU-CS-80-102, Dept. of Computer Science, Carnegie Mellon Univ., Pittsburgh, PA, 1980] and the D   P -completeness (with respect to random polynomial reducibility) of the unique satisfiability problems [L. G. Valiant and V. V. Vazirani,  NP is as easy as detecting unique solutions , in Proc. 17th ACM Symp. on Theory of Computing, 1985, pp. 458--463] associated with several of the above problems, when restricted to planar instances. Previously, very few #P-hardness results, no {sf NP}-hardness results, and no D   P -completeness results were known for counting problems, ambiguous satisfiability problems, and unique satisfiability problems, respectively, when restricted to planar instances. Assuming {sf P neq $ NP}, one corollary of the above results is that there are no $epsilon$-approximation algorithms for the problems of maximizing or minimizing a linear objective function subject to a planar system of linear inequality constraints over the integers.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1142–1167},
numpages = {26},
keywords = {graphs, DP-complete, #P-complete, planar, 3Sat, NP-complete}
}

@article{10.5555/284943.284968,
author = {Goldberg, Leslie Ann and Jerrum, Mark and MacKenzie, Philip D.},
title = {An $\Omega(\sqrt{\,\log\log N}\,)$ Lower Bound for Routing in Optical Networks},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
abstract = {Optical communication is likely to significantly speed up parallel computation because the vast bandwidth of the optical medium can be divided to produce communication networks of very high degree. However, the problem of contention in high-degree networks makes the routing problem in these networks theoretically (and practically) difficult.  In this paper we examine Valiant's h-relation routing problem, which is a fundamental problem in the theory of parallel computing.  The h-relation routing problem arises both in the direct implementation of specific parallel algorithms on distributed-memory machines and in the general simulation of shared-memory models such as the PRAM on distributed-memory machines.  In an h-relation routing problem each processor has up to h messages that it wishes to send to other processors and each processor is the destination of at most h messages.  We present a lower bound for routing an h-relation (for any h &gt; 1) on a complete optical network of size n.  Our lower bound applies to any randomized distributed algorithm for this task.  Specifically, we show that the expected number of communication steps required to route an arbitrary h-relation is $Omega(h + sqrt{,loglog n},)$. This is the first known lower bound for this problem which does not restrict the class of algorithms under consideration.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1083–1098},
numpages = {16},
keywords = {randomized algorithms, parallel algorithms, routing, optical networks}
}

@article{10.5555/284943.284963,
author = {Golin, Mordecai and Raman, Rajeev and Schwarz, Christian and Smid, Michiel},
title = {Randomized Data Structures for the Dynamic Closest-Pair Problem},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
abstract = {We describe a new randomized data structure, the sparse partition, for solving the dynamic closest-pair problem.  Using this data structure the closest pair of a set of n points in D-dimensional space, for any fixed D, can be found in constant time. If a frame containing all the points is known in advance, and if the floor function is available at unit cost, then the data structure supports insertions into and deletions from the set in expected O(log n) time and requires expected O(n) space. This method is more efficient than any deterministic algorithm for solving the problem in dimension D &gt; 1. The data structure can be modified to run in O(log2 n) expected time per update in the algebraic computation tree model. Even this version is more efficient than the best currently known deterministic algorithm for D &gt; 2. Both results assume that the sequence of updates is not determined in any way by the random choices made by the algorithm.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1036–1072},
numpages = {37},
keywords = {randomization, dynamic data structures, proximity, computational geometry}
}

@article{10.5555/284943.284957,
author = {Shallcross, D. F. and Pan, V. Y. and Lin-Kriz, Y.},
title = {Planar Integer Linear Programming is NC Equivalent to Euclidean GCD},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
abstract = {It is not known if planar integer linear programming is P-complete or if it is in NC, and the same can be said about the computation of the remainder sequence of the Euclidean algorithm applied to two integers. However, both computations are NC equivalent. The latter computational problem was reduced in NC to the former one by Deng [Mathematical Programming: Complexity and Application, Ph. D. dissertation, Stanford University, Stanford, CA, 1989; Proc. ACM Symp. on Parallel Algorithms and Architectures, 1989, pp. 110--116]. We now prove the converse NC-reduction.},
journal = {SIAM J. Comput.},
month = aug,
pages = {960–971},
numpages = {12},
keywords = {Euclidean algorithm, integer linear programming, parallel computational complexity, greatest common divisor}
}

@article{10.1137/S0097539796305109,
author = {Bar-Yehuda, Reuven and Geiger, Dan},
title = {Approximation Algorithms for the Feedback Vertex Set Problem with Applications to Constraint Satisfaction and Bayesian Inference},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796305109},
doi = {10.1137/S0097539796305109},
abstract = {A feedback vertex set of an undirected graph is a subset of vertices that intersects with the vertex set of each cycle in the graph. Given an undirected graph G with n vertices and weights on its vertices, polynomial-time algorithms are provided for approximating the problem of finding a feedback vertex set of G with smallest weight. When the weights of all vertices in G are equal, the performance ratio attained by these algorithms is 4-(2/n). This improves a previous algorithm which achieved an approximation factor of $O(sqrt{log n})$ for this case. For general vertex weights, the performance ratio becomes $min{2Delta^2, 4 log_2 n}$ where $Delta$ denotes the maximum degree in G. For the special case of planar graphs this ratio is reduced to 10. An interesting special case of weighted graphs where a performance ratio of 4-(2/n) is achieved is the one where a prescribed subset of the vertices, so-called blackout vertices, is not allowed to participate in any feedback vertex set.It is shown how these algorithms can improve the search performance for constraint satisfaction problems. An application in the area of Bayesian inference of graphs with blackout vertices is also presented.},
journal = {SIAM J. Comput.},
month = aug,
pages = {942–959},
numpages = {18},
keywords = {vertex feedback set, constraint satisfaction, combinatorial optimization, approximation algorithms, Bayesian networks}
}

@article{10.1137/S0097539795294402,
author = {Barnes, Greg and Edmonds, Jeff A.},
title = {Time--Space Lower Bounds for Directed <i>St</i>-Connectivity on Graph Automata Models},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795294402},
doi = {10.1137/S0097539795294402},
abstract = {Directed st-connectivity is the problem of detecting whether there is a path from a distinguished vertex s to a distinguished vertex t in a directed graph.  We prove time--space lower bounds of $ST = Omega({n^{2} log n over log (n log n/S)})$ and $S^{1 over 2}T = Omega(m (n log n)^{1 over 2})$ for directed st-connectivity on Cook and Rackoff's jumping automaton for graphs (JAG) model [SIAM J. Comput., 9(1980), pp. 636--652], where n is the number of vertices and m the number of edges in the input graph, S is the space, and T the time used by the JAG.  These lower bounds are simple and elegant, they approach the known upper bound of T = O(m) when S approaches $Theta(n log n)$, and they are the first time--space tradeoffs for JAGs with an unrestricted number of jumping pebbles.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1190–1202},
numpages = {13},
keywords = {JAG graph st-connectivity, lower bounds, time--space tradeoffs}
}

@article{10.1137/S0097539795288489,
author = {Schmidt, Jeanette P.},
title = {All Highest Scoring Paths in Weighted Grid Graphs and Their Application to Finding All Approximate Repeats in Strings},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795288489},
doi = {10.1137/S0097539795288489},
abstract = {Weighted paths in directed grid graphs of dimension (m X n) can be used to model the string edit problem, which consists of obtaining optimal (weighted) alignments between substrings of A, |A|=m, and substrings of B, |B|=n. We build a data structure (in O(mn log m) time) that supports O(log m) time queries about the weight of any of the O(m2n)  best  paths from the vertices in column 0 of the graph to all other vertices.  Using these techniques we present a simple O(n2 log n) time and $Theta(n^2)$ space algorithm to find  all (the locally optimal) approximate  tandem (or nontandem) repeats xy within a string of size n.  This improves (by a factor of log n) upon several previous algorithms for this problem and is the first algorithm to find all locally optimal repeats. For edit graphs with weights in {0, -1, 1}, a slight modification of our techniques yields an O(n2) algorithm for the cyclic string comparison problem, as compared to O(n2 log n) for the case of general weights.},
journal = {SIAM J. Comput.},
month = aug,
pages = {972–992},
numpages = {21},
keywords = {string matching, dynamic programming, edit-distance, tandem repeats}
}

@article{10.1137/S0097539795283619,
author = {Bermond, Jean-Claude and Gargano, Luisa and Rescigno, Adele A. and Vaccaro, Ugo},
title = {Fast Gossiping by Short Messages},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795283619},
doi = {10.1137/S0097539795283619},
abstract = {Gossiping is the process of information diffusion in which each node of a network holds a packet that must be communicated to all other nodes in the network. We consider the problem  of gossiping in communication networks under the restriction that communicating nodes can exchange up to a fixed number p of packets at each round. In the first part of the paper we study the extremal case p=1 and we exactly determine the optimal  number of communication rounds to perform gossiping for several classes of graphs, including Hamiltonian graphs and complete k-ary trees. For arbitrary graphs we give asymptotically matching upper and lower bounds. We also study the case of arbitrary  p and we exactly determine the optimal  number of communication rounds to perform gossiping under this hypothesis for complete graphs, hypercubes, rings, and paths. Finally, we investigate the problem of determining sparse networks in which gossiping can be performed in the minimum possible number of rounds.},
journal = {SIAM J. Comput.},
month = aug,
pages = {917–941},
numpages = {25},
keywords = {gossiping, graphs, networks}
}

@article{10.1137/S0097539795283292,
author = {Canetti, Ran and Irani, Sandy},
title = {Bounding the Power of Preemption in Randomized Scheduling},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795283292},
doi = {10.1137/S0097539795283292},
abstract = {We study on-line scheduling in overloaded systems. Requests for jobs arrive one by one as time proceeds; the serving agents have limited capacity and not all requests can be served. Still, we want to serve the "best" set of requests according to some criterion. In this situation, the ability to  preempt  (i.e., abort) jobs in service in order to make room for better jobs that would otherwise be rejected has proven to be of great help in some scenarios. We show that, surprisingly, in many other scenarios this is not the case. In a simple, generic model, we prove a polylogarithmic lower bound on the competitiveness of randomized and preemptive on-line scheduling algorithms. Our bound applies to several recently studied problems. In fact, in certain scenarios our bound is quite close to the competitiveness achieved by known  deterministic, nonpreemptive  algorithms.},
journal = {SIAM J. Comput.},
month = aug,
pages = {993–1015},
numpages = {23},
keywords = {preemption, lower bounds, scheduling, randomized algorithms}
}

@article{10.1137/S0097539795282092,
author = {Bar-Noy, Amotz and Mayer, Alain and Schieber, Baruch and Sudan, Madhu},
title = {Guaranteeing Fair Service to Persistent Dependent Tasks},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795282092},
doi = {10.1137/S0097539795282092},
abstract = {We introduce a new scheduling problem that is motivated by applications in the area of access and flow control in high-speed and wireless networks. An instance of the problem consists of a set of persistent tasks that have to be scheduled repeatedly. Each task has a demand to be scheduled "as often as possible." There is no explicit limit on the number of tasks that can be scheduled concurrently. However, such limits are imposed implicitly because some tasks may be in conflict and cannot be scheduled simultaneously. These conflicts are presented in the form of a conflict graph. We define parameters which quantify the fairness and regularity of a given schedule. We then proceed to show lower bounds on these parameters and present fair and efficient scheduling algorithms for the case where the conflict graph is an interval graph. Some of the results presented here extend to the case of perfect graphs and circular-arc graphs as well.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1168–1189},
numpages = {22},
keywords = {dining philosophers problem, interval graphs, scheduling, fairness}
}

@article{10.1137/S0097539795280524,
author = {Goldreich, Oded and Ostrovsky, Rafail and Petrank, Erez},
title = {Computational Complexity and Knowledge Complexity},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795280524},
doi = {10.1137/S0097539795280524},
abstract = {We study the computational complexity of languages which have interactive proofs of logarithmic knowledge complexity.  We show that all such languages can be recognized in ${cal BPP}^{cal NP}$.  Prior to this work, for languages with greater-than-zero knowledge complexity only trivial computational complexity bounds were known. In the course of our proof, we relate statistical knowledge complexity to perfect knowledge complexity; specifically, we show that, for the honest verifier, these hierarchies coincide up to a logarithmic additive term.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1116–1141},
numpages = {26},
keywords = {zero knowledge, complexity classes, interactive proofs, randomness, cryptography., knowledge complexity}
}

@article{10.1137/S0097539794269801,
author = {Agarwal, Pankaj K. and Suri, Subhash},
title = {Surface Approximation and Geometric Partitions},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794269801},
doi = {10.1137/S0097539794269801},
abstract = {Motivated by applications in computer graphics, visualization, and scientific computation, we study the computational complexity of the following problem: given a set S of n points sampled from a bivariate function f(x,y) and an input parameter $eps &gt; 0$, compute a piecewise-linear function $Sigma(x,y)$ of minimum complexity (that is, an xy-monotone polyhedral surface, with a minimum number of vertices, edges, or faces) such that $| Sigma(x_p, y_p) ; - ; z_p | ::leq:: eps$ for all $(x_p, y_p, z_p) in S$. We give hardness evidence for this problem, by showing that a closely related problem is NP-hard. The main result of our paper is a polynomial-time approximation algorithm that computes a piecewise-linear surface of size O(Ko log Ko), where Ko is the complexity of an optimal surface satisfying the constraints of the problem.The technique developed in our paper is more general and applies to several other problems that deal with partitioning of points (or other objects) subject to certain geometric constraints.  For instance, we get the same approximation bound for the following problem arising in machine learning: given n "red" and m "blue" points in the plane, find a minimum number of pairwise disjoint triangles such that each blue point is covered by some triangle and no red point lies in any of the triangles.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1016–1035},
numpages = {20},
keywords = {approximation algorithms, simplification, terrains, levels of detail, visualization, machine learning, dynamic programming}
}

@article{10.1137/S0097539794268765,
author = {Gillman, David},
title = {A Chernoff Bound for Random Walks on Expander Graphs},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268765},
doi = {10.1137/S0097539794268765},
abstract = {We consider a finite random walk on a weighted graph G; we show that the fraction of time spent in a set of vertices A converges to the stationary probability $pi (A)$ with error probability exponentially small in the length of the random walk and the square of the size of the deviation from $pi (A)$. The exponential bound is in terms of the expansion of G and improves previous results of [D. Aldous, Probab. Engrg. Inform. Sci., 1 (1987), pp. 33--46], [L. Lov\'{a}sz and M. Simonovits, {it Random Structures Algorithms}, 4 (1993), pp. 359--412], [M. Ajtai, J. Koml\'{o}s, and E. Szemer\'{e}di, Deterministic simulation of logspace, in Proc. 19th ACM Symp. on Theory of Computing, 1987].We show that taking the sample average from one trajectory gives a more efficient estimate of $pi (A)$ than the standard method of generating independent sample points from several trajectories. Using this more efficient sampling method, we improve the algorithms of Jerrum and Sinclair for approximating the number of perfect matchings in a dense graph and for approximating the partition function of a ferromagnetic Ising system, and we give an efficient algorithm to estimate the entropy of a random walk on an unweighted graph.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1203–1220},
numpages = {18},
keywords = {random walk, graph, partition function, eigenvalue, Ising system, expander, matching, approximate counting, Markov source, entropy, large deviations}
}

@article{10.1137/S0097539793252092,
author = {Leung, Hing},
title = {Separating Exponentially Ambiguous Finite Automata from Polynomially Ambiguous Finite Automata},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252092},
doi = {10.1137/S0097539793252092},
abstract = {We resolve an open problem raised by Ravikumar and Ibarra [SIAM J. Comput., 18 (1989), pp. 1263--1282] on the succinctness of representations relating to the types of ambiguity of finite automata. We show that there exists a family of nondeterministic finite automata {An} over a two-letter alphabet such that, for any positive integer n, An is exponentially ambiguous and has n states, whereas the smallest equivalent deterministic finite automaton has 2n states, and any smallest equivalent polynomially ambiguous finite automaton has 2n -1  states.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1073–1082},
numpages = {10},
keywords = {ambiguity, succinctness of representation, nondeterministic finite automata}
}

@article{10.1137/S0097539790182482,
author = {Bini, Dario and Pan, Victor Y.},
title = {Computing Matrix Eigenvalues and Polynomial Zeros Where the Output is Real},
year = {1998},
issue_date = {Aug. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790182482},
doi = {10.1137/S0097539790182482},
abstract = {Surprisingly simple corollaries from the Courant--Fischer minimax characterization theorem enable us to devise a very effective algorithm for the evaluation of a set S interleaving the set E of the eigenvalues of an n X n real symmetric tridiagonal (rst) matrix Tn (as well as a point that splits E into two subsets of comparable cardinalities). Furthermore, we extend this algorithm so as to approximate all the n eigenvalues of Tn at nearly optimal sequential and parallel cost, that is, at the cost of staying within polylogarithmic factors from the straightforward lower bounds. The resulting improvement of the known processor bound in NC algorithms for the rst-eigenproblem is roughly by factor n. Our approach extends the previous works [M. Ben-Or and P. Tiwari, J. Complexity, 6(1990), pp. 417--442] and [M. Ben-Or et al.,  SIAM J. Comput., 17(1988), pp. 1081--1092] for the approximation of the zeros of a polynomial having only real zeros, and our algorithm leads to an alternative and simplified derivation of the known record parallel and sequential complexity estimates for the latter problem.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1099–1115},
numpages = {17},
keywords = {real polynomial zeros, approximation algorithms, symmetric tridiagonal eigenvalues, computational complexity}
}

@article{10.5555/284995.285000,
author = {Crochemore, Maxime and Gasieniec, Leszek and Hariharan, Ramesh and Muthukrishnan, S. and Rytter, Wojciech},
title = {A Constant Time Optimal Parallel Algorithm  for Two-Dimensional Pattern Matching},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
abstract = {We give an alphabet-independent deterministic parallel algorithm for finding all occurrences of a pattern array of size mh x mw in a text array of size nh x nw in the concurrent-read-concurrent-write--parallel-random-access-machine (CRCW--PRAM) model. Our algorithm runs in O(1) time performing optimal, that is, O(nh x nw) work, following preprocessing of the pattern. This improves the previous best bound of O(log log m ) time with optimal work [A. Amir, G. Benson, and M. Farach, Proceedings 5th Annual ACM Symposium on Parallel Algorithms and Architectures, ACM, New York, 1993, pp. 79--85], following preprocessing of the pattern, where m=max{mh, mw}.The preprocessing required by our algorithm (and that due to  Amir, Benson, and Farach) can be accomplished in O(log log m) time and O(mh x mw) work [M. Crochemore et al.,  manuscript, 1993], [R. Cole et al., manuscript, 1993].},
journal = {SIAM J. Comput.},
month = jun,
pages = {668–681},
numpages = {14},
keywords = {duelling, two-dimensional, pattern matching, witnesses, periodicity, PRAM}
}

@article{10.1137/SMJCAT000027000003000737000001,
author = {Goldwasser, Shafi},
title = {Introduction to Special Section on Probabilistic Proof Systems},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000027000003000737000001},
doi = {10.1137/SMJCAT000027000003000737000001},
abstract = {The study of probabilistically verifiable proofs originated in the mid 1980s with the introduction of Interactive Proof Systems (IPs). The primary focus of research in this area in the '80s has been twofold: the role of zero-knowledge interactive proofs within cryptographic protocols, and characterizing which languages are efficiently interactively provable. In the 1990s, the focus of research on the topic shifted. Extensions of the interactive proof model, such as Multiprover Interactive Proofs (MIPs) and Probabilistically Checkable Proofs (PCPs), were considered with the intention of expanding our notion of what should be considered efficiently verifiable. In addition, researchers have taken a closer look at the exact resources (and tradeoffs amongst them) needed to verify a proof using various proof systems. This culminated in the important discovery that it is possible to verify NP statements (with a constant error probability) by only examining a constant number of bits of a PCP and using logarithmic amount of randomness. Perhaps, however, the most dramatic development has been the connection which was found between probabilistically verifiable proofs and proving hardness of approximation for optimization problems. It has been shown that a large variety of optimization versions of NP-hard problems (e.g., the maximum size of a clique in a graph, the minimum number of colors necessary to color a graph, and the maximum number of clauses satisfiable in a CNF formula) are not only NP-hard to solve exactly but also NP-hard to approximate in a very strong sense. The tools to establish hardness of approximation came directly from results on MIPs and PCPs. Indeed, almost every improvement in the efficiency of these proof systems translates directly into showing larger factors within which these optimization problems are hard to approximate. In 1994--1995 two exciting workshops were held at the Weizmann Institute in Israel on the new developments in probabilistically verifiable proofs and their applications to approximation problems, cryptography, program checking, and complexity theory at large. Over 60 papers were presented in the workshop series, and we are proud to include three of them in this special section. "On the Power of Finite Automata with Both Nondeterministic and Probabilistic States" by Anne Condon, Lisa Hellerstein, Samuel Pottle, and Avi Wigderson, considers constant round interactive proof systems where the verifier is restricted to use constant space and public coins. An equivalent characterization is finite automata with both nondeterministic and random states (npfa's), which accept their languages with a small probability of error. The paper shows that npfa's restricted to run in polynomial expected time accept only the regular languages in the case of npfa with 1-way input head, and that if L is a nonregular language, then either L or its complement is not accepted by any npfa with a 2-way input head. "A Parallel Repetition Theorem" by Ran Raz, addresses and resolves the Parallel Repetition Conjecture which has eluded researchers for some time. The broader topic is what happens to the error probability of proof systems when they are composed. It has been known for awhile that sequential composition of proof systems (both single and multiprover interactive proofs) reduces the error exponentially, but this increases the number of rounds. For interactive proof systems, parallel repetition is known to reduce the error exponentially, and the Parallel Repetition Conjecture asserts that the same holds in a one-round two-prover proof system. Raz proves a constructive bound on the probability of error which indeed reduces at an exponential rate. The constant in the exponent is logarithmic in the total number of possible answers of the two provers, which means one can achieve two-prover one-round MIPs for NP statements with arbitrarily small constant error probability. This, in turn, has played a crucial role in further developments in the area and in particular in those reported in the next paper. "Free Bits, PCPs, and Nonapproximability---Towards Tight Results" by Mihir Bellare, Oded Goldreich, and Madhu Sudan, continues the investigation of PCPs and nonapproximability with emphasis on trying to get closer to tight results. The work consists of three parts. The first part presents several PCP proof systems for NP, based on a new error-correcting code called the Long Code. The second part shows that the connection between PCPs and hardness of approximation is not accidental. In particular, it shows that the transformation of a PCP for NP into hardness results for MaxClique can be reversed. Finally, the third part initiates a systematic investigation of the properties of PCPs as a function of the various parameters: randomness, query complexity, free-bit complexity, amortized free-bit complexity, proof size, etc. Two more papers submitted for this special section were not ready at this time for publication. They will appear in future issues of the SIAM Journal on Computing.},
journal = {SIAM J. Comput.},
month = jun,
pages = {737–738},
numpages = {2},
keywords = {learning theory, read-once formula, parallel algorithm}
}

@article{10.1137/S0097539796302531,
author = {Bellare, Mihir and Goldreich, Oded and Sudan, Madhu},
title = {Free Bits, PCPs, and Nonapproximability---Towards Tight Results},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796302531},
doi = {10.1137/S0097539796302531},
abstract = {This paper continues the investigation of the connection between probabilistically checkable proofs (PCPs) and the approximability of  NP -optimization problems. The emphasis is on proving  tight  nonapproximability results via consideration of measures such as the "free-bit complexity" and the "amortized free-bit complexity" of proof systems. The first part of the paper presents a collection of new proof systems based on a new error-correcting code called the long code. We provide a proof system that has amortized free-bit complexity of $2 + epsilon$, implying that approximating MaxClique within $N^{frac13-e}$, and approximating the Chromatic Number within $N^{frac15-e}$, are hard, assuming $NPneqcoRP$, for any  e  &gt;  0 . We also derive the first explicit and reasonable constant hardness factors for Min Vertex Cover, $MSAT{2}$, and Max Cut, and we improve the hardness factor for $MSAT{3}$. We note that our nonapproximability factors for $maxsnp$ problems are appreciably close to the values known to be achievable by polynomial-time algorithms. Finally, we note a general approach to the derivation of strong nonapproximability results under which the problem reduces to the construction of certain "gadgets."The increasing strength of nonapproximability results obtained via the PCP connection motivates us to ask how far this can go and whether PCPs are inherent in any way. The second part of the paper addresses this. The main result is a "reversal" of the connection due to Feige et al. (FGLSS connection) [  J. ACM , 43 (1996), pp. 268--292]: where the latter had shown how to translate proof systems for  NP  into  NP -hardness of approximation results for MaxClique, we show how any  NP -hardness of approximation result for MaxClique yields a proof system for  NP . Roughly, our result says that for any constant  f , if MaxClique is  NP -hard to approximate within  N  1(1+  f ), then $NPsubseteq overline{fpcp}[log,f]$, the latter being the class of languages possessing proofs of logarithmic randomness and amortized free-bit complexity  f . This suggests that PCPs are inherent to obtaining nonapproximability results. Furthermore, the tight relation suggests that reducing the amortized free-bit complexity is necessary for improving the nonapproximability results for MaxClique.The third part of our paper initiates a systematic investigation of the properties of PCP and FPCP (free PCP) as a function of the following various parameters: randomness, query complexity, free-bit complexity, amortized free-bit complexity, proof size, etc. We are particularly interested in  triviality  results, which indicate which classes are  not  powerful enough to capture  NP . We also distill the role of randomized reductions in this area and provide a variety of useful transformations between proof checking complexity classes.},
journal = {SIAM J. Comput.},
month = jun,
pages = {804–915},
numpages = {112},
keywords = {approximation, intractability, NP-hardness, probabilistic proof systems}
}

@article{10.1137/S0097539795286119,
author = {Ferragina, Paolo and Grossi, Roberto},
title = {Optimal On-Line Search and Sublinear Time Update in String Matching},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795286119},
doi = {10.1137/S0097539795286119},
abstract = {This paper investigates the problem of searching on-line for the occurrences (occ) of an arbitrary pattern of length p in a text of length n subjected to some updates after its preprocessing.  Each text update consists of inserting  or deleting an arbitrary string of length y.  We present the first dynamic algorithm that achieves optimal query time, i.e., $Theta(p+occ)$, sublinear  time per update, i.e., $O(sqrt{n} + y)$, and optimal space,  i.e., $Theta(n)$, in the worst case. As a result, our algorithm obtains the same query time and space usage of suffix trees [McCreight, J. Assoc. Comput. Mach., 23 (1976), pp. 262--272] while improving their O(n + y) update performance.},
journal = {SIAM J. Comput.},
month = jun,
pages = {713–736},
numpages = {24},
keywords = {dynamic data structures, text indexing, suffix tree, string matching}
}

@article{10.1137/S0097539795281840,
author = {Agarwal, Pankaj K. and Berg, Mark de and Matousek, Jir\'{\i} and Schwarzkopf, Otfried},
title = {Constructing Levels in Arrangements and Higher Order Voronoi Diagrams},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795281840},
doi = {10.1137/S0097539795281840},
abstract = {We give simple randomized incremental algorithms for computing the Amk-level in an arrangement of n lines in the plane or in an arrangement of n planes in $Reals^3$. The expected running time of our algorithms is $O(nk+nalpha(n)log n)$ for the planar case and O(nk2 + n log3  n) for the three-dimensional case. Both bounds are optimal unless k is very small. The algorithm generalizes to computing the Amk-level in an arrangement of discs or x-monotone Jordan curves in the plane. Our approach can also compute the k-level; this yields a randomized algorithm for computing the order-k Voronoi diagram of n points in the plane in expected time O(k(n-k)log n + n log3 n).},
journal = {SIAM J. Comput.},
month = jun,
pages = {654–667},
numpages = {14},
keywords = {random sampling, arrangements, Voronoi diagrams}
}

@article{10.1137/S0097539795280895,
author = {Raz, Ran},
title = {A Parallel Repetition Theorem},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795280895},
doi = {10.1137/S0097539795280895},
abstract = {We show that a parallel repetition of any two-prover one-round proof system (MIP(2,1)) decreases the probability of error at an exponential rate. No constructive bound was previously known. The constant in the exponent (in our analysis) depends only on the original probability of error and on the total number of possible answers of the two provers. The dependency on the total number of possible answers is logarithmic, which was recently proved to be almost the best possible [U. Feige and O. Verbitsky, Proc.11th Annual IEEE Conference on Computational Complexity, IEEE Computer Society Press, Los Alamitos, CA, 1996, pp. 70--76].},
journal = {SIAM J. Comput.},
month = jun,
pages = {763–803},
numpages = {41},
keywords = {direct product, interactive proofs, parallel repetition}
}

@article{10.1137/S0097539795279724,
author = {Buhrman, Harry and Hoene, Albrecht and Torenvliet, Leen},
title = {Splittings, Robustness, and Structure of Complete Sets},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795279724},
doi = {10.1137/S0097539795279724},
abstract = {We investigate the structure of EXP-complete and hard sets under various kinds of reductions. In particular, we are interested in the way in which information that makes the set complete is stored in the set. We study for various types of reductions the question of whether the set difference A-S for a hard set A and a sparse set S is still hard. We also address the question of which complete sets A can be split into sets A1 and A2 such that $Aequiv^P_r A_1equiv^P_r A_2$ for reduction type r, i.e., which complete sets are  mitotic. We obtain both positive and negative answers to these questions depending on the reduction type and the structure of the sparse set.},
journal = {SIAM J. Comput.},
month = jun,
pages = {637–653},
numpages = {17},
keywords = {completeness, mitoticity, complexity, reductions}
}

@article{10.1137/S0097539794279109,
author = {Kushilevitz, Eyal and Mansour, Yishay},
title = {An $\Omega(D\log (N/D))$ Lower Bound for Broadcast in Radio Networks},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794279109},
doi = {10.1137/S0097539794279109},
abstract = {We show that for any randomized broadcast protocol for radio networks, there exists a network in which the expected time to broadcast a message is $Omega(Dlog (N/D))$, where D is the diameter of the network and N is the number of nodes. This implies a tight lower bound of $Omega(Dlog N)$ for any $D le N^{1-varepsilon}$, where $varepsilon &gt; 0$ is any constant.},
journal = {SIAM J. Comput.},
month = jun,
pages = {702–712},
numpages = {11},
keywords = {radio networks, lower bounds, broadcast}
}

@article{10.1137/S0097539794277858,
author = {Albers, Susanne},
title = {Improved Randomized On-Line Algorithms  for the List Update Problem},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794277858},
doi = {10.1137/S0097539794277858},
abstract = {The best randomized on-line algorithms known so far for the list update problem achieve a competitiveness of $sqrt{3} approx 1.73$. In this paper we present a new family of randomized on-line algorithms that beat this competitive ratio. Our improved algorithms are called TIMESTAMP algorithms and achieve a competitiveness of $max{2-p, 1+p(2-p)}$, for any real number $pin[0,1]$. Setting $p =  (3-sqrt{5})/2$, we obtain a $phi$-competitive algorithm, where $phi = (1+sqrt{5})/2approx 1.62$ is the golden ratio. TIMESTAMP algorithms coordinate the movements of items using some information on past requests. We can reduce the required information at the expense of increasing the competitive ratio. We present a very simple version of the TIMESTAMP algorithms that is mbox{$1.68$-competitive}. The family of TIME-STAMP algorithms also includes a new deterministic 2-competitive on-line algorithm that is different from the MOVE-TO-FRONT rule.},
journal = {SIAM J. Comput.},
month = jun,
pages = {682–693},
numpages = {12},
keywords = {competitive analysis, linear lists, on-line algorithms}
}

@article{10.1137/S009753979427087X,
author = {Kloks, T. and Kratsch, D.},
title = {Listing All Minimal Separators of a Graph},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979427087X},
doi = {10.1137/S009753979427087X},
abstract = {An efficient algorithm listing all minimal vertex separators of an undirected graph is given. The algorithm needs polynomial time per separator that is found.},
journal = {SIAM J. Comput.},
month = jun,
pages = {605–613},
numpages = {9},
keywords = {good pair, algorithm, minimal pair, graph, listing algorithm, minimal separator}
}

@article{10.1137/S0097539794270364,
author = {Tamaki, Hisao},
title = {Efficient Self-Embedding of Butterfly Networks with Random Faults},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794270364},
doi = {10.1137/S0097539794270364},
abstract = {We study the embedding of the butterfly network in its faulty version, where each node is independently faulty with some constant probability $p$. We give a method of such self-embedding of the  N -node butterfly with  O (1) load,  O ((log log  N ) 2.6) dilation, and  O ((log log  N )   c ) congestion, which succeeds with probability at least 1 -  N  -1 if  p  &lt; 1 - sqrt{2/3} simeq 0.1835$, where  c  is a constant that depends on  p ;  c  is about 8.84 for  p  = 0.1 and approaches log 2 40 simeq 5.32$ as $p rightarrow 0$. The method is constructive and in fact yields an  N  log   O (1)  N  time deterministic algorithm to construct the claimed embedding with the claimed success probability when given the random faulty butterfly. We also show that we can make the dilation as low as  O (log log  N ), although at the cost of log   O (1)  N  congestion. These embeddings are level-preserving in the sense that each node is mapped to a node in the same level of the butterfly as the original node. We also derive a lower bound of log log  N  -  o (log log  N ) on the dilation of a level-preserving embedding with $N^alpha$ load, for any constant $alpha &lt; 1/3$ and any constant node-failure probability  p  &gt; 0. Thus, the bounds on dilation are tight up to a constant factor, as far as level-preserving embeddings are concerned.},
journal = {SIAM J. Comput.},
month = jun,
pages = {614–636},
numpages = {23},
keywords = {network embedding, butterfly network, interconnection networks, random faults, embedding}
}

@article{10.1137/S0097539794265578,
author = {Condon, Anne and Hellerstein, Lisa and Pottle, Samuel and Wigderson, Avi},
title = {On the Power of Finite Automata with Both Nondeterministic and Probabilistic States},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794265578},
doi = {10.1137/S0097539794265578},
abstract = {We study finite automata with both nondeterministic and random states (npfa's). We restrict our attention to those npfa's that accept their languages with a small probability of error and run in polynomial expected time. Equivalently, we study Arthur--Merlin games where Arthur is limited to polynomial time and constant space. Dwork and Stockmeyer [  SIAM J. Comput. , 19 (1990), pp. 1011--1023] asked whether these npfa's accept only the regular languages (this was known if the automaton has only randomness or only nondeterminism). We show that the answer is yes in the case of npfa's with a 1-way input head. We also show that if  L  is a nonregular language, then either  L  or $bar{L}$ is not accepted by any npfa with a 2-way input head.Toward this end, we define a new measure of the complexity of a language  L , called its 1-tiling complexity. For each $n$, this is the number of tiles needed to cover the 1's in the "characteristic matrix" of  L , namely, the binary matrix with a row and column for each string of length $le n$, where entry [  x,y ]=1 if and only if the string $xy in L$. We show that a language has constant 1-tiling complexity if and only if it is regular, from which the result on 1-way input follows. Our main result regarding the general 2-way input tape follows by contrasting two bounds: an upper bound of polylog(  n ) on the 1-tiling complexity of every language computed by our model and a lower bound stating that the 1-tiling complexity of a nonregular language or its complement exceeds a function in $2^{Omega (sqrt{log n})}$ infinitely often.The last lower bound follows by proving that the characteristic matrix of  every  nonregular language has rank  n  for infinitely many  n . This is our main technical result, and its proof extends techniques of Frobenius and Iohvidov developed for Hankel matrices [  Sitzungsber. der K\"{o}nigl. Preuss. Akad. der Wiss. , 1894, pp. 407--431], [  Hankel and Toeplitz Matrices and Forms: Algebraic Theory , Birkhauser, Boston, 1982].},
journal = {SIAM J. Comput.},
month = jun,
pages = {739–762},
numpages = {24},
keywords = {Arthur--Merlin games, Hankel matrices, matrix tiling, interactive proof systems, nondeterministic probabilistic finite automata}
}

@article{10.1137/S0097539793258313,
author = {Grigoriev, Dima and Karpinski, Marek},
title = {Computing the Additive Complexity of Algebraic Circuits with Root Extracting},
year = {1998},
issue_date = {June 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793258313},
doi = {10.1137/S0097539793258313},
abstract = {We design an algorithm for computing the generalized (algebraic circuits with root extracting; cf. Pippenger [  J. Comput. System Sci ., 22 (1981), pp. 454--470], Ja'Ja' [  Proc . 22  nd  IEEE FOCS, 1981, pp. 95--100], Grigoriev, Singer, and Yao [  SIAM J. Comput ., 24 (1995), pp. 242--246])  additive complexity  of any rational function. It is the first computability result of this sort on the additive complexity of algebraic circuits.},
journal = {SIAM J. Comput.},
month = jun,
pages = {694–701},
numpages = {8},
keywords = {minimal computation, algebraic circuits, root extracting, additive complexity}
}

@article{10.5555/279082.279125,
author = {Landau, Gad M. and Myers, Eugene W. and Schmidt, Jeanette P.},
title = {Incremental String Comparison},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
abstract = {The problem of comparing two sequences A and B to determine their longest common subsequence (LCS) or the edit distance between them has been much studied. In this paper we consider the following incremental version of these problems: given an appropriate encoding of a comparison between A and B, can one incrementally compute the answer for A and bB, and the answer for A and Bb with equal efficiency, where b is an additional symbol? Our main result is a theorem exposing a surprising relationship between the dynamic programming solutions for two such "adjacent" problems. Given a threshold k on the number of differences to be permitted in an alignment, the theorem leads directly to an O(k) algorithm for incrementally computing a new solution from an old one, as contrasts the O(k2) time required to compute a solution from scratch. We further show, with a series of applications, that this algorithm is indeed more powerful than its nonincremental counterpart. We show this  by solving the applications with greater asymptotic efficiency than heretofore possible.  For example, we obtain O(nk) algorithms for the longest prefix approximate match problem, the approximate overlap problem, and cyclic string comparison.},
journal = {SIAM J. Comput.},
month = apr,
pages = {557–582},
numpages = {26},
keywords = {dynamic programming, edit-distance, string matching}
}

@article{10.5555/279082.279123,
author = {Chazelle, Bernard},
title = {A Spectral Approach to Lower Bounds  with Applications to Geometric Searching},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
abstract = {We establish a nonlinear lower bound for halfplane range searching over a group. Specifically, we show that summing up the weights of n (weighted) points within n halfplanes requires $Omega(nlog n)$ additions and subtractions. This is the first nontrivial lower bound for range searching over a group. By contrast, range searching over a semigroup (which forbids subtractions) is almost completely understood.Our proof has two parts. First, we develop a general, entropy-based method for relating the linear circuit complexity of a linear map A to the spectrum of $A^top!A$. In the second part of the proof, we design a "high-spectrum" geometric set system for halfplane range searching and, using techniques from discrepancy theory, we estimate the median eigenvalue of its associated map. Interestingly, the method also shows that using up to a linear number of help gates cannot help; these are gates that can compute  any bivariate function.},
journal = {SIAM J. Comput.},
month = apr,
pages = {545–556},
numpages = {12},
keywords = {eigenvalues, lower bounds, range searching, circuit complexity}
}

@article{10.5555/279082.279100,
author = {Agarwal, Pankaj K. and Matousek, Jir\'{\i} and Schwarzkopf, Otfried},
title = {Computing Many Faces in Arrangements of Lines and Segments},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
abstract = {We present randomized algorithms for computing many faces in an arrangement of lines or of segments in the plane, which are considerably simpler and slightly faster than the previously known ones. The main new idea is a simple randomized $O(n log n)$ expected time algorithm for computing $sqrt{n}$ cells in an arrangement of n lines.},
journal = {SIAM J. Comput.},
month = apr,
pages = {491–505},
numpages = {15},
keywords = {duality, random sampling, arrangements}
}

@article{10.5555/279082.279099,
author = {Bradford, Phillip G. and Rawlins, Gregory J. E. and Shannon, Gregory E.},
title = {Efficient Matrix Chain Ordering in Polylog Time},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
abstract = {The matrix chain ordering problem is to find the cheapest way to multiply a chain of n matrices, where the matrices are pairwise compatible but of varying dimensions. Here we give several new parallel algorithms including $O(lg^3 n)$-time and $n/!lg n$-processor algorithms for solving the matrix chain ordering problem and for solving an optimal triangulation problem of convex polygons on the common CRCW PRAM model. Next, by using efficient algorithms for computing row minima of totally monotone matrices, this complexity is improved to $O(lg^2 n)$ time with $n$ processors on the EREW PRAM and to $O(lg^2 n lg lg n)$ time with $n/ ! lg lg n$ processors on a common CRCW PRAM@. A new algorithm for computing the row minima of totally monotone matrices improves our parallel MCOP algorithm to $O(n lg^{1.5} n)$ work and polylog time on a CREW PRAM@. Optimal log-time algorithms for computing row minima of totally monotone matrices will improve our algorithm and enable it to have the same work as the sequential algorithm of Hu and Shing [SIAM J. Comput., 11 (1982), pp. 362--373; SIAM J. Comput., 13 (1984), pp. 228--251].},
journal = {SIAM J. Comput.},
month = apr,
pages = {466–490},
numpages = {25},
keywords = {optimization., parallel, matrix chain ordering, dynamic programming}
}

@article{10.5555/279082.279092,
author = {Bshouty, Nader H. and Cleve, Richard},
title = {Interpolating Arithmetic Read-Once Formulas in Parallel},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
abstract = {A formula is read-once if each variable appears in it at most once. An arithmetic formula is one in which the operations are addition, subtraction, multiplication, and division (and constants are allowed). We present a randomized (Las Vegas) parallel algorithm for the exact interpolation of arithmetic read-once formulas over sufficiently large fields. More specifically, for $n$-variable read-once formulas and fields of size at least 3(n2+3n-2), our algorithm runs in $O(log^2 n)$ parallel steps using O(n4) processors (where the field operations are charged unit cost). This complements some results from [N. H. Bshouty and R. Cleve, Proc. 33rd Annual Symposium on the Foundations of Computer Science, IEEE Computer Science Press, Los Alamitos, CA, 1992, pp. 24--27] which imply that other classes of read-once formulas cannot be interpolated---or even learned with membership and equivalence queries---in polylogarithmic time with polynomially many processors (even though they can be learned sequentially in polynomial time). These classes include boolean read-once formulas and arithmetic read-once formulas over fields of size $o(n / log n)$ (for n variable read-once formulas).},
journal = {SIAM J. Comput.},
month = apr,
pages = {401–413},
numpages = {13},
keywords = {learning theory, parallel algorithm, read-once formula}
}

@article{10.5555/279082.279085,
author = {Cai, Liming and Chen, Jianer and H\r{A}stad, Johan},
title = {Circuit Bottom Fan-in and Computational Power},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
abstract = {We investigate the relationship between circuit bottom fan-in and circuit size when circuit depth is fixed.  We show that in order to compute certain functions, a moderate reduction in circuit bottom fan-in will cause significant increase in circuit size.  In particular, we prove that there are functions that are computable by circuits of linear size and depth k with bottom fan-in 2 but require exponential size for circuits of depth k with bottom fan-in 1.  A general scheme is established to study the trade-off between circuit bottom fan-in and circuit size.  Based on this scheme, we are able to prove, for example, that for any integer c, there are functions that are computable by circuits of linear size and depth k with bottom fan-in $O(log n)$ but that require exponential size for circuits of depth k with bottom fan-in c, and that for any constant $epsilon &gt; 0$, there are functions that are computable by circuits of linear size and depth k with bottom fan-in $log n$ but that require superpolynomial size for circuits of depth k with bottom fan-in $O(log^{1-epsilon} n)$. A consequence of these results is that the three input read-modes of alternating Turing machines proposed in the literature are all distinct.},
journal = {SIAM J. Comput.},
month = apr,
pages = {341–355},
numpages = {15},
keywords = {lower bound, alternating Turing machine, circuit complexity, computational complexity}
}

@article{10.1137/S0097539799527969,
author = {Li, Rongheng and Shi, Lijie},
title = {An On-Line Algorithm for Some Uniform Processor Scheduling},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539799527969},
doi = {10.1137/S0097539799527969},
abstract = {This paper considers the problem of on-line scheduling a set of independent jobs on m uniform machines (M1, M2,..., Mm) in which machine Mi's processing speed is si=1 (i=1,..., m-1) and sm=s &gt;1. List scheduling [Y. Cho and S. Sahni,  SIAM J. Comput., 9 (1980), pp. 91--103] guarantees a worst-case performance of $frac{3m-1}{m+1} (mge 3)$ and $frac{1+sqrt 5}2 (m=2)$ for this problem. We prove that this worst-case bound cannot be improved for m=2 and m=3 and for every $mge 4,$ an algorithm with worst-case performance at most $frac{3m-1}{m+1}-e$ is presented when sm=2,$ where e is a fixed positive number, and then we improve the bound for general sm=s &gt; 1.},
journal = {SIAM J. Comput.},
month = apr,
pages = {414–422},
numpages = {9},
keywords = {uniform machines, list scheduling, on-line scheduling}
}

@article{10.1137/S0097539795279463,
author = {Attiya, Hagit and Rachman, Ophir},
title = {Atomic Snapshots in <i>O</i> (<i>n</i> Log <i>n</i>) Operations},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795279463},
doi = {10.1137/S0097539795279463},
abstract = {The atomic snapshot object is an important primitive used for the design and verification of wait-free algorithms in shared-memory distributed systems. A snapshot object is a shared data structure partitioned into segments. Processors can either update an individual segment or instantaneously scan all segments of the object. This paper presents an implementation of an atomic snapshot object in which each high-level operation (scan or update) requires O(n log n) low-level operations on atomic read/write registers.},
journal = {SIAM J. Comput.},
month = apr,
pages = {319–340},
numpages = {22},
keywords = {atomic read/write registers, snapshot objects, single-reader multiwriter, asynchronous shared memory systems, wait-free computations, linearizability}
}

@article{10.1137/S0097539794279201,
author = {Dudek, Gregory and Romanik, Kathleen and Whitesides, Sue},
title = {Localizing a Robot with Minimum Travel},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794279201},
doi = {10.1137/S0097539794279201},
abstract = {We consider the problem of localizing a robot in a known environment modeled by a simple polygon P.  We assume that the robot has a map of P but is placed at an unknown location inside P.  From its initial location, the robot sees a set of points called the visibility polygon V of its location. In general, sensing at a single point will not suffice to uniquely localize the robot, since the set H of points in P with visibility polygon V may have more than one element.  Hence, the robot must move around and use range sensing and a compass to determine its position (i.e., localize itself).  We seek a strategy that minimizes the distance the robot travels to determine its exact location.We show that the problem of localizing a robot with minimum travel is NP-hard.  We then give a polynomial time approximation scheme that causes the robot to travel a distance of at most (k - 1)d, where k = |H|, which is no greater than the number of reflex vertices of P, and d is the length of a minimum length tour that would allow the robot to verify its true initial location by sensing.  We also show that this bound is the best possible.},
journal = {SIAM J. Comput.},
month = apr,
pages = {583–604},
numpages = {22},
keywords = {optimization, NP-hard, sensing, localization, positioning, navigation, visibility, robot, competitive strategy}
}

@article{10.1137/S0097539794278384,
author = {Dyer, Martin and Gritzmann, Peter and Hufnagel, Alexander},
title = {On The Complexity of Computing Mixed Volumes},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794278384},
doi = {10.1137/S0097539794278384},
abstract = {This paper gives various (positive and negative) results on the complexity of the problem of computing and approximating mixed volumes of polytopes and more general convex bodies in arbitrary dimension. On the negative side, we present several $#P$-hardness results that focus on the difference of computing mixed volumes versus computing the volume of polytopes. We show that computing the volume of zonotopes is $#P$-hard (while each corresponding mixed volume can be computed easily) but also give examples showing that computing mixed volumes is hard even when computing the volume is easy. On the positive side, we derive a randomized algorithm for computing the mixed volumes $$ V(overbrace{K_1ld K_1}^{m_1}, overbrace{K_2,dots,K_2}^{m_2},dots,overbrace{K_s,dots,K_s}^{m_s}) $$ of well-presented convex bodies $K_1,dots,K_s$, where $m_1,dots,m_s in N_0$ and $m_1 geq n-psi(n)$ with $psi(n)=o(frac{log n}{log log n})$. The algorithm is an interpolation method based on polynomial-time randomized algorithms for computing the volume of convex bodies. This paper concludes with applications of our results to various problems in discrete mathematics, combinatorics, computational convexity, algebraic geometry, geometry of numbers, and operations research.},
journal = {SIAM J. Comput.},
month = apr,
pages = {356–400},
numpages = {45},
keywords = {lattice point enumerator, deterministic algorithm, convex body, computation, $NP$-hardness, computational convexity, computational complexity, polynomial-time algorithm, approximation, $#P$-hardness, polynomial equations, zonotope, determinant problems, Newton polytope, volume, parallelotope, permanent, partial order, randomized algorithm, mixed volumes, polytope}
}

@article{10.1137/S0097539793246689,
author = {Goldreich, Oded and Goldwasser, Shafi and Linial, Nathan},
title = {Fault-Tolerant Computation in the Full Information Model},
year = {1998},
issue_date = {April 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793246689},
doi = {10.1137/S0097539793246689},
abstract = {We initiate an investigation of general fault-tolerant distributed computation in the  full-information  model. In the full information model no restrictions are made on the computational power of the faulty parties or the information available to them. (Namely, the faulty players may be infinitely powerful and there are no private channels connecting pairs of honest players). Previous work in this model has concentrated on the particular problem of simulating a single bounded-bias global coin flip (e.g., Ben-Or and Linial [  Randomness and Computation , S. Micali, ed., JAI Press, Greenwich, CT, 1989, pp. 91--115] and Alon and Naor [  SIAM J. Comput ., 22 (1993), pp. 403--417]). We widen the scope of investigation to the general question of how well arbitrary fault-tolerant computations can be performed in this model. The results we obtain should be considered as first steps in this direction.We present efficient two-party protocols for fault-tolerant computation of any bivariate function. We prove that the advantage of a dishonest player in these protocols is the minimum one possible (up to polylogarithmic factors).We also present efficient  m -party fault-tolerant protocols for sampling a general distribution (mbox{$mgeq2$}). Such an algorithm seems an important building block towards the design of efficient multiparty protocols for fault-tolerant computation of multivariate functions.},
journal = {SIAM J. Comput.},
month = apr,
pages = {506–544},
numpages = {39},
keywords = {sampling with weak sources of randomness, fault-tolerant multiparty protocols, influences in general two-party computations}
}

@article{10.5555/276234.586853,
author = {Parker, D. Stott},
title = {Conditions for Optimality of the Huffman Algorithm},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
journal = {SIAM J. Comput.},
month = feb,
pages = {317},
numpages = {1},
keywords = {tree height, convex functions, quasi-linear functions, weighted path length, optimal tree construction, Huffman algorithm, R\'{e}nyi entropy}
}

@article{10.5555/276234.276238,
author = {stad, Johan H\r{A}},
title = {The Shrinkage Exponent of de Morgan Formulas is 2},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
abstract = {We prove that if we hit a de Morgan formula of size L with a random restriction from Rp, then the expected remaining size is at most $O(p^2(log frac {1}{p})^{3/2}L+psqrt L)$. As a corollary we obtain an $Omega(n^{3-o(1)})$-formula-size lower bound for an explicit function in P. This is the strongest known lower bound for any explicit function in NP.},
journal = {SIAM J. Comput.},
month = feb,
pages = {48–64},
numpages = {17},
keywords = {lower bounds, formula size, random restrictions, computational complexity}
}

@article{10.1137/S0097539795298321,
author = {Amir, Amihood and Benson, Gary},
title = {Two-Dimensional Periodicity in Rectangular Arrays},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795298321},
doi = {10.1137/S0097539795298321},
abstract = {String matching is rich with a variety of algorithmic tools. In contrast, multidimensional matching has had a rather sparse set of techniques. This paper presents a new algorithmic technique for two-dimensional matching:  periodicity analysis . Its strength appears to lie in the fact that it is inherently two-dimensional. Periodicity in strings has been used to solve string matching problems. Multidimensional periodicity, however, is not as simple as it is in strings and was not formally studied or used in pattern matching. In this paper, we define and analyze two-dimensional periodicity in rectangular arrays. One definition of string periodicity is that a periodic string can self-overlap in a particular way. An analogous concept is true in two dimensions. The  self-overlap vectors  of a rectangle generate a regular pattern of locations where the rectangle may originate. Based on this regularity, we define four categories of periodic arrays---  nonperiodic, lattice periodic, line periodic, and radiant periodic ---and prove theorems about the properties of the classes. We give serial and parallel algorithms that find all locations where an overlap originates. In addition, our algorithms find a  witness  proving that the array does not self-overlap in any other location. The serial algorithm runs in time  O (  m 2) (linear time) when the alphabet size is finite, and in  O (  m 2log  m ) otherwise. The parallel algorithm runs in time  O (log  m ) using  O (  m 2) CRCW processors.},
journal = {SIAM J. Comput.},
month = feb,
pages = {90–106},
numpages = {17},
keywords = {periodicity, parallel algorithm, string matching, two-dimensional, sequential algorithm, witness}
}

@article{10.1137/S0097539794285983,
author = {Aumann, Yonatan and Rabani, Yuval},
title = {An <i>O</i>(Log <i>k</i>) Approximate Min-Cut Max-Flow Theorem and Approximation Algorithm},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794285983},
doi = {10.1137/S0097539794285983},
abstract = {It is shown that the minimum cut ratio is within a factor of O(log k) of the maximum concurrent flow for k-commodity flow instances with arbitrary capacities and demands. This improves upon the previously best-known bound of O(log2 k) and is existentially tight, up to a constant factor. An algorithm for finding a cut with ratio within a factor of O(log k) of the maximum concurrent flow, and thus of the optimal min-cut ratio, is presented.},
journal = {SIAM J. Comput.},
month = feb,
pages = {291–301},
numpages = {11},
keywords = {cuts, approximation algorithms, multicommodity flow, sparse cuts, network flow}
}

@article{10.1137/S0097539794279626,
author = {Bertolazzi, Paola and Battista, Giuseppe Di and Mannino, Carlo and Tamassia, Roberto},
title = {Optimal Upward Planarity Testing  of Single-Source Digraphs},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794279626},
doi = {10.1137/S0097539794279626},
abstract = {A digraph is upward planar if it has a planar drawing such that all the edges are monotone with respect to the vertical direction. Testing upward planarity and constructing upward planar drawings is important for displaying hierarchical network structures, which frequently arise in software engineering, project management, and visual languages. In this paper we investigate upward planarity testing of single-source digraphs; we provide a new combinatorial characterization of upward planarity and give an optimal algorithm for upward planarity testing. Our algorithm tests whether a single-source digraph with n vertices is upward planar in O(n) sequential time, and in O(log n) time on a CRCW PRAM with $n log log n/log n$ processors, using O(n,) space. The algorithm also constructs an upward planar drawing if the test is successful. The previously known best result is an O(n2)-time algorithm by Hutton and Lubiw [Proc. 2nd ACM--SIAM Symposium on Discrete Algorithms, SIAM, Philadelphia, 1991, pp. 203--211]. No efficient parallel algorithms for upward planarity testing were previously known.},
journal = {SIAM J. Comput.},
month = feb,
pages = {132–169},
numpages = {38},
keywords = {upward drawing, planar graph, graph drawing, triconnected components, parallel algorithm}
}

@article{10.1137/S0097539794278396,
author = {Attiya, Hagit and Chaudhuri, Soma and Friedman, Roy and Welch, Jennifer L.},
title = {Shared Memory Consistency Conditions for Nonsequential Execution: Definitions and Programming Strategies},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794278396},
doi = {10.1137/S0097539794278396},
abstract = {To enhance performance on shared memory multiprocessors, various techniques have been proposed to reduce the latency of memory accesses, including pipelining of accesses, out-of-order execution of accesses, and branch prediction with speculative execution. These optimizations can, however, complicate the user's model of memory. This paper attacks the problem of simplifying programming on two fronts. First, a general framework is presented for defining shared memory consistency conditions that allows nonsequential execution of memory accesses. The interface at which conditions are defined is between the program and the system and is architecture-independent. The framework is used to generalize three consistency conditions---sequential consistency, hybrid consistency, and weak consistency---for nonsequential execution. Thus, familiar consistency conditions can be precisely specified even in optimized architectures.Second, three techniques are described for structuring programs so that a shared memory that provides the weaker (and more efficient) condition of hybrid consistency appears to guarantee the stronger (and more costly) condition of sequential consistency. The benefit of these techniques is that sequentially consistent executions are easier to reason about. The first technique statically classifies accesses based on their type. This approach is extremely simple to use and leads to a general technique for writing efficient synchronization code. The third technique is to avoid data races in the program, which was previously studied in a somewhat different setting.Precise, yet short and comprehensible, proofs are provided for the correctness of the programming techniques. Such proofs shed light on the reasons these techniques work; we believe that the insight gained can lead to the development of other techniques.},
journal = {SIAM J. Comput.},
month = feb,
pages = {65–89},
numpages = {25},
keywords = {distributed shared memory, sequential consistency, consistency conditions}
}

@article{10.1137/S0097539794274519,
author = {Goldmann, Mikael and Karpinski, Marek},
title = {Simulating Threshold Circuits by Majority Circuits},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794274519},
doi = {10.1137/S0097539794274519},
abstract = {We prove that a single threshold gate with arbitrary weights can be simulated by an explicit polynomial-size, depth-2 majority circuit. In general we show that a polynomial-size, depth-d threshold circuit can be simulated uniformly by a polynomial-size majority circuit of depth d + 1. Goldmann, H\r{a}stad, and Razborov showed in [Comput. Complexity, 2 (1992), pp. 277--300] that a nonuniform simulation exists. Our construction answers two open questions posed by them: we give an explicit construction, whereas they use a randomized existence argument, and we show that such a simulation is possible even if the depth d grows with the number of variables n (their simulation gives polynomial-size circuits only when d is constant).},
journal = {SIAM J. Comput.},
month = feb,
pages = {230–246},
numpages = {17},
keywords = {majority circuits, threshold circuits, circuit complexity}
}

@article{10.1137/S0097539794270352,
author = {Cusick, Thomas W.},
title = {Value Sets of Some Polynomials Over Finite Fields},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794270352},
doi = {10.1137/S0097539794270352},
abstract = {This paper shows that there is a connection between the crosscorrelation functions of certain binary m-sequences and the value sets of the polynomials xk(1 + x)2m - 1 for k in pm 1,  pm 2, 4, where x is in the finite field GF(22m). In particular, the size of such value sets is determined by using finite field theory and known results about crosscorrelation functions.},
journal = {SIAM J. Comput.},
month = feb,
pages = {120–131},
numpages = {12},
keywords = {polynomial, finite field, value set}
}

@article{10.1137/S0097539794268406,
author = {Leighton, Tom and Plaxton, C. Greg},
title = {Hypercubic Sorting Networks},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268406},
doi = {10.1137/S0097539794268406},
abstract = {This paper provides an analysis of a natural d-round tournament over n = 2 d players and demonstrates that the tournament possesses a surprisingly strong ranking property. The ranking property of this tournament is used to design efficient sorting algorithms for several models of parallel computation: a comparator network of depth $ccdotlg n$, $capprox 7.44$, that sorts the vast majority of the n ! possible input permutations; an $O(lg n)$-depth hypercubic comparator network that sorts the vast majority of permutations; a hypercubic sorting network with nearly logarithmic depth; an $O(lg n)$-time randomized sorting algorithm for any hypercubic machine (other such algorithms have been previously discovered, but this algorithm has a significantly smaller failure probability than any previously known algorithm); and a randomized algorithm for sorting n O ( m )-bit records on an $(nlg n)$-node omega machine in $O(m+lg n)$ bit steps.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–47},
numpages = {47},
keywords = {parallel sorting, sorting networks, hypercubic machines}
}

@article{10.1137/S0097539794267243,
author = {Buss, Samuel R. and Yianilos, Peter N.},
title = {Linear and Time Minimum-Cost Matching Algorithms for Quasi-Convex Tours},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794267243},
doi = {10.1137/S0097539794267243},
abstract = {Let G be a complete, weighted, undirected, bipartite graph with n red nodes, n" blue nodes, and symmetric cost function c(x,y).  A maximum matching for G consists of $min{n,n^prime}$ edges from distinct red nodes to distinct blue nodes.  Our objective is to find a minimum-cost maximum matching, i.e., one for which the sum of the edge costs has minimal value.  This is the weighted bipartite matching problem or, as it is sometimes called, the assignment problem.  We report a new and very fast algorithm for an abstract special case of this problem.  Our first requirement is that the nodes of the graph are given as a "quasi-convex tour." This means that they are provided circularly ordered as x1,...,xN, where N = n + n", and that for any $x_i, x_j, x_k, x_ell$, not necessarily adjacent but in tour order, with xi, xj of one color and $x_k,x_ell$ of the opposite color, the following inequality holds:  [ c(x_i,x_ell) + c(x_j,x_k) le c(x_i,x_k) + c(x_j,x_ell). ]               If $n = n^prime$, our algorithm then finds a minimum-cost matching in $O(N log N)$ time.  Given an additional condition of ``weak analyticity," the time complexity is reduced to $O(N)$.  In both cases only linear space is required. In the special case where the circular ordering is a line-like ordering, these results apply even if $n ne n^prime$.  Our algorithm is conceptually elegant, straightforward to implement, and free of large hidden constants.  As such we expect that it may be of practical value in several problem areas.  Many natural graphs satisfy the quasi-convexity condition. These include graphs which lie on a line or circle with the canonical tour ordering, and costs given by any concave-down function of arclength --- or graphs whose nodes lie on an arbitrary convex planar figure with costs provided by Euclidean distance.  The weak-analyticity condition applies to points lying on a circle with costs given by Euclidean distance, and we thus obtain the first linear-time algorithm for the minimum-cost matching problem in this setting (and also where costs are given by the $L_1$ or $L_infty$ metrics).  Given two symbol strings over the same alphabet, we may imagine one to be red and the other blue and use our algorithms to compute string distances.  In this formulation, the strings are embedded in the real line and multiple independent assignment problems are solved, one for each distinct alphabet symbol.  While these examples are somewhat geometrical, it is important to remember that our conditions are purely abstract; hence, our algorithms may find application to problems in which no direct connection to geometry is evident.},
journal = {SIAM J. Comput.},
month = feb,
pages = {170–201},
numpages = {32},
keywords = {computational geometry, bipartite weighted matching, convexity, concave penalty function, assignment problem, linear time, Monge property, string comparison, quadrangle inequality}
}

@article{10.1137/S0097539794265232,
author = {Garay, Juan A. and Moses, Yoram},
title = {Fully Polynomial Byzantine Agreement for Processors in Rounds},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794265232},
doi = {10.1137/S0097539794265232},
abstract = {This paper  presents a polynomial-time protocol for reaching Byzantine agreement in t + 1 rounds whenever n &gt; 3t, where n is the number of processors and t is an a priori upper bound on the number of failures. This resolves an open problem presented by Pease, Shostak, and Lamport in 1980. An early-stopping variant of this protocol is also presented, reaching agreement in a number of rounds that is proportional to the number of processors that actually fail.},
journal = {SIAM J. Comput.},
month = feb,
pages = {247–290},
numpages = {44},
keywords = {fault tolerance, Byzantine agreement, computer security, distributed computing, consensus}
}

@article{10.1137/S0097539794261118,
author = {Garay, Juan A. and Kutten, Shay and Peleg, David},
title = {A SubLinear Time Distributed Algorithm for Minimum-Weight Spanning Trees},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794261118},
doi = {10.1137/S0097539794261118},
abstract = {This paper considers the question of identifying the parameters governing the behavior of fundamental global network problems. Many papers on distributed network algorithms consider the task of optimizing the running time successful when an O(n) bound is achieved on an n-vertex network. We propose that a more sensitive parameter is the network's diameter $Diam$. This is demonstrated in the paper by providing a distributed minimum-weight spanning tree algorithm whose time complexity is sublinear in n, but linear in $Diam$ (specifically, $O(Diam + n^varepsilon cdot log^* n)$ for $varepsilon = frac{ln 3}{ln 6} = 0.6131...$). Our result is achieved through the application of graph decomposition and edge-elimination-by-pipelining techniques that may be of independent interest.},
journal = {SIAM J. Comput.},
month = feb,
pages = {302–316},
numpages = {15},
keywords = {MST, min-weight spanning trees, distributed algorithms}
}

@article{10.1137/S0097539793259471,
author = {Blumofe, Robert D. and Leiserson, Charles E.},
title = {Space-Efficient Scheduling of Multithreaded Computations},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793259471},
doi = {10.1137/S0097539793259471},
abstract = {This paper considers the problem of scheduling dynamic parallel computations to achieve linear speedup without using significantly more space per processor than that required for a single-processor execution.  Utilizing a new graph-theoretic model of multithreaded computation, execution efficiency is quantified by three important measures: T1 is the time required for executing the computation on a 1 processor, $T_infty$ is the time required by an infinite number of processors, and S1 is the space required to execute the computation on a 1 processor.  A computation executed on P processors is time-efficient if the time is $O(T_1/P + T_infty)$, that is, it achieves linear speedup when $P=O(T_1/T_infty)$, and it is space-efficient if it uses O(S1P) total space, that is, the space per processor is within a constant factor of that required for a 1-processor execution.The first result derived from this model shows that there exist multithreaded computations such that no execution schedule can simultaneously achieve efficient time and efficient space.  But by restricting attention to "strict" computations---those in which all arguments to a procedure must be available before the procedure can be invoked---much more positive results are obtainable.  Specifically, for any strict multithreaded computation, a simple online algorithm can compute a schedule that is both time-efficient and space-efficient.  Unfortunately, because the algorithm uses a global queue, the overhead of computing the schedule can be substantial. This problem is overcome by a decentralized algorithm that can compute and execute a P-processor schedule online in expected time $O(T_1/P + T_inftylg P)$ and worst-case space $O(S_1Plg P)$, including overhead costs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {202–229},
numpages = {28},
keywords = {strict execution, multithreaded computing, stack memory, parallel computing, scheduling algorithms, parallel algorithms, randomized algorithms}
}

@article{10.1137/S0097539793256673,
author = {Brady, Martin L.},
title = {A Fast Discrete Approximation Algorithm  for the Radon Transform},
year = {1998},
issue_date = {Feb. 1998},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {27},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256673},
doi = {10.1137/S0097539793256673},
abstract = {This paper addresses fast parallel methods for the computation of the Radon (or Hough) transform. The Radon transform of an image is a set of projections of the image taken at different angles. Its computation is important in image processing and computer vision for problems such as pattern recognition and reconstruction of medical images. A unique new method for combining partial results is presented, from which an algorithm is constructed that computes a provably good approximation to the discrete Radon transform. The approximate discrete Radon transform (ADRT) algorithm computes 4, N - 4 projections through an $N times N$ image in time $O(N^2mathrm{lg}N)$ (the majority of previous algorithms are O(N 3,)). The method is quite simple and easy to parallelize. A parallel version of the ADRT requires only $O(mathrm{lg}N)$ parallel steps on O(N 2) processors, ignoring communication time. An additional property of the algorithm is that it can be applied directly to compute the backprojection step of the inverse RT.},
journal = {SIAM J. Comput.},
month = feb,
pages = {107–119},
numpages = {13},
keywords = {Radon transform, image reconstruction, image processing, Hough transform, approximation algorithms}
}

@article{10.1137/S0097539794279067,
author = {Kannan, Sampath and Warnow, Tandy},
title = {A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794279067},
doi = {10.1137/S0097539794279067},
abstract = {The perfect phylogeny problem is a classical problem in computational evolutionary biology, in which a set of species/taxa is described by a set of qualitative characters. In recent years, the problem has been shown to be NP-complete in general, while the different fixed parameter versions can each be solved in polynomial time. In particular, Agarwala and Fern\'{a}ndez-Baca have developed an O(23r (nk3 + k4)) algorithm for the perfect phylogeny problem for n species defined by k r-state characters [SIAM J. Comput., 23 (1994), pp. 1216--1224]. Since, commonly, the character data are drawn from alignments of molecular sequences, k is the length of the sequences and can thus be very large (in the hundreds or thousands). Thus, it is imperative to develop algorithms which run efficiently for large values of k. In this paper we make additional observations about the structure of the problem and produce an algorithm for the problem that runs in time O(22r k2 n). We also show how it is possible to efficiently build a structure that implicitly represents the set of all perfect phylogenies and to randomly sample from that set.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1749–1763},
numpages = {15},
keywords = {dynamic programming, combinatorial enumeration, perfect phylogeny, evolutionary trees, polynomial delay algorithms}
}

@article{10.1137/S0097539794274994,
author = {Bruck, Jehoshua and Cypher, Robert and Ho, Ching-Tien},
title = {Fault-Tolerant Meshes with Small Degree},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794274994},
doi = {10.1137/S0097539794274994},
abstract = {This paper presents constructions for fault-tolerant, two-dimensional mesh architectures. The constructions are designed to tolerate $k$ faults while maintaining a healthy n by n mesh as a subgraph. They utilize several novel techniques for obtaining trade-offs between the number of spare nodes and the degree of the fault-tolerant network.We consider both worst-case and random fault distributions. In terms of worst-case faults, we give a construction that has constant degree and O(k3) spare nodes. This is the first construction known in which the degree is constant and the number of spare nodes is independent of n. In terms of random faults, we present several new degree-6 and degree-8 constructions and show (both analytically and through simulations) that these constructions can tolerate large numbers of randomly placed faults.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1764–1784},
numpages = {21},
keywords = {graph theory, interconnection networks, fault-tolerance, array, parallel computing, mesh}
}

@article{10.1137/S0097539794270248,
author = {Alon, Noga and Kahale, Nabil},
title = {A Spectral Technique for Coloring Random 3-Colorable Graphs},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794270248},
doi = {10.1137/S0097539794270248},
abstract = {Let G3n,p,3 be a random 3-colorable graph on a set of 3n vertices generated as follows. First, split the vertices arbitrarily into three equal color classes, and then choose every pair of vertices of distinct color classes, randomly and independently, to be edges with probability p. We describe a polynomial-time algorithm that finds a proper 3-coloring of G3n,p,3  with high probability, whenever p $geq$ c/n, where c is a sufficiently large absolute constant. This settles a problem of Blum and Spencer, who asked if an algorithm can be designed that works almost surely for p $geq$ polylog(n)/n [J. Algorithms, 19 (1995), pp. 204--234]. The algorithm can be extended to produce optimal k-colorings of random k-colorable graphs in a similar model as well as in various related models. Implementation results show that the algorithm performs very well in practice even for moderate values of c.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1733–1748},
numpages = {16},
keywords = {random graphs, graph eigenvalues, graph coloring, algorithms}
}

@article{10.1137/S0097539794269461,
author = {Amir, Amihood and Keselman, Dmitry},
title = {Maximum Agreement Subtree in a Set of Evolutionary Trees: Metrics and Efficient Algorithms},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794269461},
doi = {10.1137/S0097539794269461},
abstract = {The  maximum agreement subtree  approach is one method of reconciling different evolutionary trees for the same set of species. An agreement subtree enables choosing a subset of the species for whom the restricted subtree is  equivalent  (under a suitable definition) in all given evolutionary trees. Recently, dynamic programming ideas were used to provide polynomial time algorithms for finding a maximum homeomorphic agreement subtree of  two  trees. Generalizing these methods to sets of more than two trees yields algorithms that are exponential in the number of trees. Unfortunately, it turns out that in reality one is usually presented with more than two trees, sometimes as many as thousands of trees.In this paper we prove that the maximum homeomorphic agreement subtree problem is $cal{NP}$-complete for three trees with unbounded degrees. We then show an approximation algorithm of time  O (  kn 5) for choosing the species that are  not  in a maximum agreement subtree of a set of  k  trees. Our approximation is guaranteed to provide a set that is no more than 4 times the optimum solution.While the set of evolutionary trees may be large in practice, the trees usually have very small degrees, typically no larger than three. We develop a new method for finding a maximum agreement subtree of  k  trees, of which one has degree bounded by  d . This new method enables us to find a maximum agreement subtree in time  O (  kn   d  + 1+  n 2  d ).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1656–1669},
numpages = {14},
keywords = {maximum agreement subtrees, classification, evolutionary trees}
}

@article{10.1137/S0097539794266602,
author = {Aronov, Boris and Sharir, Micha},
title = {On Translational Motion Planning of a Convex Polyhedron in 3-Space},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794266602},
doi = {10.1137/S0097539794266602},
abstract = {Let B be a convex polyhedron translating in 3-space amidst k convex polyhedral obstacles A1,...,Ak with pairwise disjoint interiors. The free configuration space (space of all collision-free placements) of B can be represented as the complement of the union of the Minkowski sums $P_i=A_ioplus (-B)$, for i= 1,...,k. We show that the combinatorial complexity of the free configuration space of B is O(nk log k), and that it can be $Omega(nkalpha(k))$ in the worst case, where n is the total complexity of the individual Minkowski sums P1,...,Pk. We also derive an efficient randomized algorithm that constructs this configuration space in expected time O(nk log k log n).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1785–1803},
numpages = {19},
keywords = {geometric algorithms, computational geometry, combinatorial geometry, combinatorial complexity, randomized algorithms, convex polyhedra, algorithmic motion planning}
}

@article{10.1137/S0097539794265724,
author = {Agarwal, Pankaj K. and Aronov, Boris and Sharir, Micha},
title = {Computing Envelopes in Four Dimensions with Applications},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794265724},
doi = {10.1137/S0097539794265724},
abstract = {Let ${cal F}$  be a collection of n d-variate, possibly partially defined, functions, all algebraic of some constant maximum degree. We present a randomized algorithm that computes the vertices, edges, and 2-faces of the lower envelope (i.e., pointwise minimum) of ${cal F}$ in expected time $O(n^{d+epsilon})$ for any $epsilon &gt; 0$. For d = 3, by combining this algorithm with the point-location technique of Preparata and Tamassia, we can compute, in randomized expected time $O(n^{3+epsilon})$, for any $epsilon &gt; 0$, a data structure of size $O(n^{3+epsilon})$ that, for any query point q, can determine in O(log2n) time the function(s) of ${cal F}$ that attain the lower envelope at q. As a consequence, we obtain improved algorithmic solutions to several problems in computational geometry, including (a) computing the width of a point set in 3-space, (b) computing the "biggest stick" in a simple polygon in the plane, and (c) computing the smallest-width annulus covering a planar point set. The solutions to these problems run in randomized expected time $O(n^{17/11+epsilon})$, for any $epsilon &gt; 0$, improving previous solutions that run in time $O(n^{8/5+epsilon})$. We also present data structures for (i) performing nearest-neighbor and related queries for fairly general collections of objects in 3-space and for collections of moving objects in the plane and (ii) performing ray-shooting and related queries among n spheres or more general objects in 3-space. Both of these data structures require $O(n^{3+epsilon})$ storage and preprocessing time, for any $epsilon &gt; 0$, and support polylogarithmic-time queries. These structures improve previous solutions to these problems.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1714–1732},
numpages = {19},
keywords = {ray shooting, lower envelopes, closest pair, point location}
}

@article{10.1137/S0097539793256223,
author = {Cheriyan, Joseph},
title = {Randomized $\tilde{O}(M(|V|))$ Algorithms for Problems in Matching Theory},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256223},
doi = {10.1137/S0097539793256223},
abstract = {A randomized (Las Vegas) algorithm is given for finding the Gallai--Edmonds decomposition of a graph. Let n denote the number of vertices, and let M( n) denote the number of arithmetic operations for multiplying two n $times$ n matrices. The sequential running time (i.e., number of bit operations) is within a poly-logarithmic factor of M( n). The parallel complexity is O((log n) 2) parallel time using a number of processors within a poly-logarithmic factor of M( n). The same complexity bounds suffice for solving several other problems: finding a minimum vertex cover in a bipartite graph finding a minimum X ---&gt; Y vertex separator in a directed graph, where X and Y are specified sets of vertices, finding the allowed edges (i.e., edges that occur in some maximum matching) of a graph, finding the canonical partition of the vertex set of an elementary graph. The sequential algorithms for problems (i), (ii), and (iv) are Las Vegas, and the algorithm for problem (iii) is Monte Carlo. The new complexity bounds are significantly better than the best previous ones, e.g., using the best value of M(n) currently known, the new sequential running time is O(n2.38) versus the previous best O(n2.5 /(log n)) or more.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1635–1655},
numpages = {21},
keywords = {Gallai--Edmonds decomposition, allowed edges, bipartite minimum vertex covers, matching theory, canonical partition, randomized algorithms, digraph minimum vertex separators}
}

@article{10.1137/S0097539793255011,
author = {Cole, Richard J. and Maggs, Bruce M. and Sitaraman, Ramesh K.},
title = {Reconfiguring Arrays with Faults Part I: Worst-Case Faults},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255011},
doi = {10.1137/S0097539793255011},
abstract = {In this paper we study the ability of array-based networks to tolerate worst-case faults.  We show that an $N times N$ two-dimensional array can sustain $N^{1-epsilon}$ worst-case faults, for any fixed $epsilon &gt; 0$, and still emulate $T$ steps of a fully functioning $N times N$ array in $O(T+N)$ steps, i.e., with only constant slowdown. Previously, it was known only that an array could tolerate a constant number of faults with constant slowdown.  We also show that if faulty nodes are allowed to communicate, but not compute, then an $N$-node one-dimensional array can tolerate $log^k N$ worst-case faults, for any constant $k &gt; 0$, and still emulate a fault-free array with constant slowdown, and this bound is tight.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1581–1611},
numpages = {31},
keywords = {array-based network, network emulation, mesh network, fault tolerance}
}

@article{10.1137/S0097539793253577,
author = {Hershberger, John and Suri, Subhash},
title = {Matrix Searching with the Shortest-Path Metric},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793253577},
doi = {10.1137/S0097539793253577},
abstract = {We present an O(n) time algorithm for computing row-wise maxima or minima of an implicit, totally monotone $n times n$ matrix whose entries represent shortest-path distances between pairs of vertices in a simple polygon. We apply this result to derive improved algorithms for several well-known problems in computational geometry. Most prominently, we obtain linear-time algorithms for computing the geodesic diameter, all farthest neighbors, and external farthest neighbors of a simple polygon, improving the previous best result by a factor of O(log n) in each case.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1612–1634},
numpages = {23},
keywords = {matrix searching, geodesic diameter, geometric matching, shortest paths, farthest neighbors}
}

@article{10.1137/S0097539793253371,
author = {Agarwal, Pankaj K. and Aronov, Boris and O'Rourke, Joseph and Schevon, Catherine A.},
title = {Star Unfolding of a Polytope with Applications},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793253371},
doi = {10.1137/S0097539793253371},
abstract = {We introduce the notion of a  star unfolding  of the surface ${cal P}$ of a three-dimensional convex polytope with  n  vertices, and use it to solve several problems related to shortest paths on ${cal P}$. The first algorithm computes the edge sequences traversed by shortest paths on ${cal P}$ in time $O(n^6 beta (n) log n)$, where $beta (n)$ is an extremely slowly growing function. A much simpler $O(n^6)$ time algorithm that finds a small superset of all such edge sequences is also sketched.The second algorithm is an $O(n^{8}log n)$ time procedure for computing the  geodesic diameter  of ${cal P}$: the maximum possible separation of two points on ${cal P}$ with the distance measured along ${cal P}$. Finally, we describe an algorithm that preprocesses ${cal P}$ into a data structure that can efficiently answer the queries of the following form: "Given two points, what is the length of the shortest path connecting them__ __" Given a parameter $1 le m le n^2$, it can preprocess ${cal P}$ in time $O(n^6 m^{1+delta})$, for any $delta &gt; 0$, into a data structure of size $O(n^6m^{1+delta})$, so that a query can be answered in time $O((sqrt{n}/m^{1/4}) log n)$. If one query point always lies on an edge of ${cal P}$, the algorithm can be improved to use $O(n^5 m^{1+delta})$ preprocessing time and storage and guarantee $O((n/m)^{1/3} log n)$ query time for any choice of $m$ between 1 and $n$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1689–1713},
numpages = {25},
keywords = {shortest paths, geodesics, convex polytopes, star unfolding}
}

@article{10.1137/S0097539793250755,
author = {Aronov, Boris and Sharir, Micha and Tagansky, Boaz},
title = {The Union of Convex Polyhedra in Three Dimensions},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250755},
doi = {10.1137/S0097539793250755},
abstract = {We show that the number of vertices, edges, and faces of the union of k convex polyhedra in 3-space, having a total of n faces, is O(k3 + kn log k). This bound is almost tight in the worst case, as there exist collections of polyhedra with $Omega(k^3+knalpha(k))$ union complexity. We also describe a rather simple randomized incremental algorithm for computing the boundary of the union in O(k3 + kn log k log n) expected time.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1670–1688},
numpages = {19},
keywords = {convex polyhedra, combinatorial complexity, computational geometry, randomized algorithms, geometric algorithms, combinatorial geometry}
}

@article{10.1137/S0097539791224030,
author = {MacKenzie, Philip D.},
title = {The Random Adversary: A Lower-Bound Technique for Randomized Parallel Algorithms},
year = {1997},
issue_date = {Dec. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791224030},
doi = {10.1137/S0097539791224030},
abstract = {The random-adversary technique is a general method for proving lower bounds on randomized parallel algorithms. The bounds apply to the number of communication steps, and they apply regardless of the processors' instruction sets, the lengths of messages, etc. This paper introduces the random-adversary technique and shows how it can be used to obtain lower bounds on randomized parallel algorithms for load balancing, compaction, padded sorting, and finding Hamiltonian cycles in random graphs. Using the random-adversary technique, we obtain the first lower bounds for randomized parallel algorithms which are provably faster than their deterministic counterparts (specifically, for load balancing and related problems).},
journal = {SIAM J. Comput.},
month = dec,
pages = {1559–1580},
numpages = {22},
keywords = {expected time, parallel computation, load balancing, PRAM model, parallel algorithms, randomized parallel algorithms, lower bounds}
}

@article{10.1137/SMJCAT000026000005001409000001,
author = {Vazirani, Umesh},
title = {Introduction to Special Section on Quantum Computation},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/SMJCAT000026000005001409000001},
doi = {10.1137/SMJCAT000026000005001409000001},
abstract = {The rapid evolution of computers in the half century since their invention has resulted in dramatically smaller and faster computers. However, from a computational point of view, all these computers look alike; for example, they are built out of simple logic gates. A fundamental thesis of computer science---the modern form of the Church--Turing thesis---asserts that this is inevitable in a deep sense. Any computer can be simulated with at most a polynomial factor slowdown by a probabilistic Turing machine. Quantum computation poses the first credible challenge to this thesis. It goes back to a suggestion by Feynman [4], who pointed out that there appears to be no efficient way of simulating a quantum mechanical system on a computer, and suggested that, perhaps, a computer based on quantum physical principles might be able to carry out the simulation efficiently. Two formal models for quantum computers---the quantum Turing machine [2] and quantum computational networks [3]---were defined by Deutsch.  The first three papers in this issue describe efficient quantum algorithms for computational tasks that we do not know how to solve classically. In "Quantum Complexity Theory," Bernstein and Vazirani give the first formal evidence that quantum computers violate the modern form of the Church--Turing thesis. They show that a certain problem---the recursive Fourier sampling problem---can be solved in polynomial time on a quantum Turing machine, but relative to an oracle, requires superpolynomial time on a classical probabilistic Turing machine. Simon, in the paper "On the Power of Quantum Computation" introduces a fundamental projection technique and uses it to design an efficient quantum algorithm to determine whether a certain type of function is 2-1 or 1-1. He further shows that, relative to an oracle, this problem requires exponential time on a classical probabilistic Turing machine. In the paper "Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer," Shor gives remarkable polynomial time quantum algorithms for two of the most famous problems in computer science: factoring and discrete log. Since the computational hardness of these problems is the basis of several famous cryptosystems, Shor's paper very dramatically underlines the power of quantum computers.  To understand the computational power of quantum computers, it is helpful to consider a quantum mechanical system of  n  particles, each of which can be in one of two states, labeled $|0rangle$ and $|1rangle$. If this were a classical system, then its instantaneous state could be described by  n  bits. However, in quantum physics, the system is allowed to be in a linear superposition of configurations, and indeed the instantaneous state of the system is described by a unit vector in the 2  n  dimensional vector space, whose basis vectors correspond to all the 2  n  classical configurations. Therefore, to describe the instantaneous state of the system, we must specify 2  n  complex numbers. Nature must update 2  n  complex numbers at each instant to evolve the system in time. This is an extraordinary amount of effort, since even for  n  = 200, 2  n  is larger than estimates of the number of elementary particles in the visible universe.  Nonetheless, there are limits to the power of quantum computers. In "Strengths and Weaknesses of Quantum Computing," Bennett, Bernstein, Brassard, and Vazirani show that, relative to a random oracle, with probability 1, the class  NP  cannot be solved on a quantum Turing machine in time  o (2  n /2). This bound is tight, since recent work of Grover [5] has shown how to accept any language in  NP  in time  O (2  n /2) on a quantum Turing machine.  Quantum computers are necessarily time reversible. Indeed, Bennett's work [1] on reversible computation inspired early work on quantum computation that preceded Feynman's paper [4]. The reversibility requirement makes it quite complex to implement even basic computational primitives such as looping or composition. In "Quantum Complexity Theory," Bernstein and Vazirani show how to implement quantum programming primitives and give a construction for an efficient universal quantum Turing machine. The structure of the universal quantum Turing machine is quite simple: it consists of a deterministic Turing machine with a single "quantum coin flip." In "Quantum Computability," Adleman, DeMarrais, and Huang greatly simplify this further by showing that a very simple type of coin flip is sufficient---a rotation by an angle $theta$ such that ${rm sin} theta = 3/5$.  Making quantum computers robust against noise and decoherence is an important and challenging problem. In "Stabilization of Quantum Computations by Symmetrization," Barenco, Berthiaume, Deutsch, Ekert, Jozsa, and Macchiavello show how to use the quantum watchdog effect to stabilize a quantum computation against noise. Their method is based on running several copies of the quantum computer in parallel and projecting its state into the symmetric subspace at frequent intervals. They show that the quantum watchdog effect results in the suppression of errors that lie outside the symmetric subspace.  Quantum computation touches upon the foundations of both computer science and quantum physics. It is not unlikely that the issues raised by quantum computation will stimulate further research into the foundations of quantum physics.  I wish to express my gratitude to several people who made this special section possible. Oded Goldreich acted as editor for two of the papers in the issue and dealt with them with his characteristic efficiency and judgment. The editorial staff at SIAM, most notably Lisa Dougherty, Beth Gallagher, Deidre Wunderlich, and Sam Young, were extremely helpful, patient, and resourceful. Finally, I would like to thank a number of referees whose careful and timely reviews were critical to putting together this issue.   Umesh Vazirani    References   [1] C. H. Bennett,  Logical reversibility of computation , IBM J. Res. Develop., 17 (1973), pp. 525--532.  [2] D. Deutsch,  Quantum theory, the Church-Turing principle and the universal quantum computer , Proc. Roy. Soc. London Ser. A., 400 (1985), pp. 97--117.  [3] D. Deutsch,  Quantum computational networks , Proc. Roy. Soc. London Ser. A, 425 (1989), pp. 73--90.  [4] R. Feyman,  Simulating physics with computers , Internat. J. Theoret. Phys., 21 (1982), pp. 467--488.  [5] L. Grover,  Searching for a Needle in a Haystack---A Fast Mechanical Algorithm , manuscript, 1995.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1409–1410},
numpages = {2},
keywords = {parallel algorithm, read-once formula, learning theory}
}

@article{10.1137/S0097539796302452,
author = {Barenco, Adriano and Berthiaume, Andr\'{e} and Deutsch, David and Ekert, Artur and Jozsa, Richard and Macchiavello, Chiara},
title = {Stabilization of Quantum Computations by Symmetrization},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796302452},
doi = {10.1137/S0097539796302452},
abstract = {We propose a method for the stabilization of quantum computations (including quantum state storage). The method is based on the operation of projection into $cal SYM$, the symmetric subspace of the full state space of $R$ redundant copies of the computer. We describe an efficient algorithm and quantum network effecting $cal SYM$--projection and discuss the stabilizing effect of the proposed method in the context of unitary errors generated by hardware imprecision, and nonunitary errors arising from external environmental interaction. Finally, limitations of the method are discussed.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1541–1557},
numpages = {17},
keywords = {quantum computation, error correction}
}

@article{10.1137/S0097539796300933,
author = {Bennett, Charles H. and Bernstein, Ethan and Brassard, Gilles and Vazirani, Umesh},
title = {Strengths and Weaknesses of Quantum Computing},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796300933},
doi = {10.1137/S0097539796300933},
abstract = {Recently a great deal of attention has been focused on quantum computation following a sequence of results [Bernstein and Vazirani, in  Proc . 25  th Annual ACM Symposium Theory Comput. , 1993, pp. 11--20,  SIAM J. Comput.,  26 (1997), pp. 1277--1339], [Simon, in  Proc.  35th Annual IEEE Symposium Foundations Comput. Sci., 1994, pp. 116--123,  SIAM J. Comput.,  26 (1997), pp. 1340--1349], [Shor, in  Proc.  35  th Annual IEEE Symposium Foundations Comput. Sci. , 1994, pp. 124--134] suggesting that quantum computers are more powerful than classical probabilistic computers. Following Shor's result that factoring and the extraction of discrete logarithms are both solvable in quantum polynomial time, it is natural to ask whether all of $NP$ can be efficiently solved in quantum polynomial time. In this paper, we address this question by proving that relative to an oracle chosen uniformly at random with probability 1 the class $NP$ cannot be solved on a quantum Turing machine (QTM) in time $o(2^{n/2})$. We also show that relative to a permutation oracle chosen uniformly at random with probability 1 the class $NP cap coNP$ cannot be solved on a QTM in time $o(2^{n/3})$. The former bound is tight since recent work of Grover [in {it Proc. $28$th Annual ACM Symposium Theory Comput.}, 1996] shows how to accept the class $NP$ relative to any oracle on a quantum computer in time $O(2^{n/2})$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1510–1523},
numpages = {14},
keywords = {oracle quantum Turing machines, quantum polynomial time, quantum Turing machines}
}

@article{10.1137/S0097539796300921,
author = {Bernstein, Ethan and Vazirani, Umesh},
title = {Quantum Complexity Theory},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796300921},
doi = {10.1137/S0097539796300921},
abstract = {In this paper we study quantum computation from a complexity theoretic viewpoint. Our first result is the existence of an efficient universal quantum Turing machine in Deutsch's model of a quantum Turing machine (QTM) [Proc. Roy. Soc. London Ser. A, 400 (1985), pp. 97--117]. This construction is substantially more complicated than the corresponding construction for classical Turing machines (TMs); in fact, even simple primitives such as looping, branching, and composition are not straightforward in the context of quantum Turing machines. We establish how these familiar primitives can be implemented and introduce some new, purely quantum mechanical primitives, such as changing the computational basis and carrying out an arbitrary unitary transformation of polynomially bounded dimension. We also consider the precision to which the transition amplitudes of a quantum Turing machine need to be specified. We prove that $O(log T)$ bits of precision suffice to support a $T$ step computation. This justifies the claim that the quantum Turing machine model should be regarded as a discrete model of computation and not an analog one. We give the first formal evidence that quantum Turing machines violate the modern (complexity theoretic) formulation of the Church--Turing thesis. We show the existence of a problem, relative to an oracle, that can be solved in polynomial time on a quantum Turing machine, but requires superpolynomial time on a bounded-error probabilistic Turing machine, and thus not in the class $BPP$. The class $BQP$ of languages that are efficiently decidable (with small error-probability) on a quantum Turing machine satisfies $BPP subseteq BQP subseteq Ptime^{SP}$. Therefore, there is no possibility of giving a mathematical proof that quantum Turing machines are more powerful than classical probabilistic Turing machines (in the unrelativized setting) unless there is a major breakthrough in complexity theory. },
journal = {SIAM J. Comput.},
month = oct,
pages = {1411–1473},
numpages = {63},
keywords = {quantum polynomial time, quantum Turing machines, Fourier sampling, universal quantum Turing machine, reversibility, quantum computation}
}

@article{10.1137/S0097539796298637,
author = {Simon, Daniel R.},
title = {On the Power of Quantum Computation},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539796298637},
doi = {10.1137/S0097539796298637},
abstract = {The quantum model of computation is a model, analogous to the probabilistic Turing machine (PTM), in which the normal laws of chance are replaced by those obeyed by particles on a quantum mechanical scale, rather than the rules familiar to us from the macroscopic world. We present here a problem of distinguishing between two fairly natural classes of functions, which can provably be solved exponentially faster in the quantum model than in the classical probabilistic one, when the function is given as an oracle drawn equiprobably from the uniform distribution on either class. We thus offer compelling evidence that the quantum model may have significantly more complexity theoretic power than the PTM. In fact, drawing on this work, Shor has recently developed remarkable new quantum polynomial-time algorithms for the discrete logarithm and integer factoring problems.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1474–1483},
numpages = {10},
keywords = {complexity theory, quantum computation, oracles}
}

@article{10.1137/S0097539795293639,
author = {Adleman, Leonard M. and DeMarrais, Jonathan and Huang, Ming-Deh A.},
title = {Quantum Computability},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795293639},
doi = {10.1137/S0097539795293639},
abstract = {In this paper some theoretical and (potentially) practical aspects of quantum computing are considered. Using the tools of transcendental number theory it is demonstrated that quantum Turing machines (QTM) with rational amplitudes are sufficient to define the class of bounded error quantum polynomial time (BQP) introduced by Bernstein and Vazirani [Proc. 25th ACM Symposium on Theory of Computation, 1993, pp. 11--20, SIAM J. Comput., 26 (1997), pp. 1277--1339]. On the other hand, if quantum Turing machines are allowed unrestricted amplitudes (i.e., arbitrary complex amplitudes), then the corresponding BQP class has uncountable cardinality and contains sets of all Turing degrees. In contrast, allowing unrestricted amplitudes does not increase the power of computation for error-free quantum polynomial time (EQP). Moreover, with unrestricted amplitudes, BQP is not equal to EQP. The relationship between quantum complexity classes and classical complexity classes is also investigated. It is shown that when quantum Turing machines are restricted to have transition amplitudes which are algebraic numbers, BQP, EQP, and nondeterministic quantum polynomial time (NQP) are all contained in PP, hence in ${rm P}^{#{rm P}}$ and PSPACE. A potentially practical issue of designing "machine independent" quantum programs is also addressed. A single ("almost universal") quantum algorithm based on Shor's method for factoring integers is developed which would run correctly on almost all quantum computers, even if the underlying unitary transformations are unknown to the programmer and the device builder.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1524–1540},
numpages = {17},
keywords = {quantum complexity classes, quantum Turing machines}
}

@article{10.1137/S0097539795293172,
author = {Shor, Peter W.},
title = {Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795293172},
doi = {10.1137/S0097539795293172},
abstract = {A digital computer is generally believed to be an efficient universal computing device; that is, it is believed able to simulate any physical computing device with an increase in computation time by at most a polynomial factor. This may not be true when quantum mechanics is taken into consideration. This paper considers factoring integers and finding discrete logarithms, two problems which are generally thought to be hard on a classical computer and which have been used as the basis of several proposed cryptosystems. Efficient randomized algorithms are given for these two problems on a hypothetical quantum computer. These algorithms take a number of steps polynomial in the input size, e.g., the number of digits of the integer to be factored.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1484–1509},
numpages = {26},
keywords = {Church's thesis, spin systems, quantum computers, discrete logarithms, algorithmic number theory, foundations of quantum mechanics, Fourier transforms, prime factorization}
}

@article{10.1137/S0097539794319126,
author = {Anderson, Richard J. and Woll, Heather},
title = {Algorithms for the Certified Write-All Problem},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794319126},
doi = {10.1137/S0097539794319126},
abstract = {In this paper, we prove new upper bounds on the complexity of the certified write-all problem with respect to an adaptive adversary. Our strongest result is that for any $epsilon &gt; 0$, there exists an $O(p^{1+epsilon})$ work algorithm for the $p$-processor $p$-memory cell write-all.  We also give a randomized $O(p^2log p)$ work algorithm for a $p$-processor $p^2$-memory cell write-all.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1277–1283},
numpages = {7},
keywords = {asynchronous computation, synchronization primitives, adversary models, certified write-all problem}
}

@article{10.1137/S0097539794276324,
author = {Makino, Kazuhisa and Ibaraki, Toshihide},
title = {The Maximum Latency and Identification of Positive Boolean Functions},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794276324},
doi = {10.1137/S0097539794276324},
abstract = {Consider the problem of identifying $min T(f)$ and $max F(f)$ of a positive (i.e., monotone) Boolean function $f$ by using membership queries only, where $min T(f),(max F(f))$ denotes the set of minimal true vectors (maximal false vectors) of $f$. It is known that an incrementally polynomial algorithm exists if and only if there is a polynomial time algorithm to check the existence of an unknown vector $u$ for given sets $MT subseteq min T(f)$ and $MF subseteq max F(f)$; that is, $u in {0,1}^n setminus ({v | v geq w {rm  for  some } w in MT } cup {v | v leq w {rm  for  some } w in MF })$. This paper introduces a measure for the difficulty to find an unknown vector, which is called the maximum latency. If the maximum latency is constant, then an unknown vector can be found in polynomial time and there is an incrementally polynomial algorithm for identification. Several subclasses of positive functions are shown to have constant maximum latency, e.g., $2$-monotonic positive functions, $Delta$-partial positive threshold functions, and matroid functions, while the class of general positive functions has $lfloor n/4 rfloor +1$ maximum latency  and the class of positive $k$-DNF functions has $Omega (sqrt{n})$ maximum latency.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1363–1383},
numpages = {21},
keywords = {maximum latency, identification of Boolean functions, partial function, transversal, positive Boolean function, dualization, unknown vector}
}

@article{10.1137/S0097539794268649,
author = {Katz, Matthew J. and Sharir, Micha},
title = {An Expander-Based Approach to Geometric Optimization},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268649},
doi = {10.1137/S0097539794268649},
abstract = {We present a new approach to problems in geometric optimization that are traditionally solved using the parametric-searching technique of Megiddo [J. ACM, 30 (1983), pp. 852--865]. Our new approach is based on expander graphs and range-searching techniques. It is conceptually simpler, has more explicit geometric flavor, and does not require parallelization or randomization. In certain cases, our approach yields algorithms that are asymptotically faster than those currently known (e.g., the second and third problems below) by incorporating into our (basic) technique a subtechnique that is equivalent to (though much more flexible than) Cole's technique for speeding up parametric searching [J. ACM, 34 (1987), pp. 200--208]. We exemplify the technique on three main problems---the slope selection problem, the planar distance selection problem, and the planar {em two-line center} problem. For the first problem we develop an $O(nlog^3 n)$ solution, which, although suboptimal, is very simple. The other two problems are more typical examples of our approach. Our solutions have running time $O(n^{4/3}log^2n)$ and $O(n^2 log^4 n)$, respectively, slightly better than the previous respective solutions of [Agarwal et al., Algorithmica, 9 (1993), pp. 495--514], [Agarwal and Sharir, Algorithmica, 11 (1994), pp. 185--195]. We also briefly mention two other problems that can be solved efficiently by our technique.In solving these problems, we also obtain some auxiliary results concerning batched range searching, where the ranges are congruent discs or annuli. For example, we show that it is possible to compute deterministically a compact representation of the set of all point-disc incidences among a set of $n$ congruent discs and a set of $m$ points in the plane in time $O((m^{2/3} n^{2/3}+m+n)log n)$, again slightly better than what was previously known.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1384–1408},
numpages = {25},
keywords = {parametric searching, slope selection, computational geometry, expander graphs, facility location, geometric optimization, range searching}
}

@article{10.1137/S0097539794263890,
author = {Kim, Sam Myo},
title = {Computational Modeling for Genetic Splicing Systems},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794263890},
doi = {10.1137/S0097539794263890},
abstract = {A genetic splicing system involves DNA molecules mixed with enzymes and a ligase that allow the molecules to be cleaved and recombined to produce other molecules in addition to the original ones. Recently, using formal language theory, several researchers have investigated the string properties of DNA molecules that may potentially arise from the original set of molecules under the effect of the given restriction enzymes.This paper introduces an algorithm which, given a splicing system whose initial set of strings is regular, constructs a finite state automaton that recognizes the set of DNA molecules spliced by the system. This algorithm solves the open problem of constructing such an automaton and shows a direct approach to the proof of regularity of spliced languages.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1284–1309},
numpages = {26},
keywords = {finite state automata, languages, genetic splicing, DNA molecules}
}

@article{10.1137/S0097539794229417,
author = {Babai, L\'{a}szl\'{o} and Luks, Eugene M. and Seress, \'{A}kos},
title = {Fast Management of Permutation Groups I},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794229417},
doi = {10.1137/S0097539794229417},
abstract = {We present new algorithms for permutation group manipulation. Our methods result in an improvement of nearly an order of magnitude in the worst-case analysis for the fundamental problems of finding strong generating sets and testing membership. The normal structure of the group is brought into play even for such elementary issues. An essential element is the recognition of large alternating composition factors of the given group and subsequent extension of the permutation domain to display the natural action of these alternating groups. Further new features include a novel fast handling of alternating groups and the sifting of defining relations in order to link these and other analyzed factors with the rest of the group. The analysis of the algorithm depends on the classification of finite simple groups. In a sequel to this paper, using an enhancement of the present method, we shall achieve a further order of magnitude improvement.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1310–1342},
numpages = {33},
keywords = {permutation group algorithm, strong generating set}
}

@article{10.1137/S0097539793246707,
author = {Baker, Brenda S.},
title = {Parameterized Duplication in Strings: Algorithms and an Application to Software Maintenance},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793246707},
doi = {10.1137/S0097539793246707},
abstract = {As an aid in software maintenance, it would be useful to be able to track down duplication in large software systems efficiently. Duplication in code is often in the form of sections of code that are the same except for a systematic change of parameters such as identifiers and constants. To model such parameterized duplication in code, this paper introduces the notions of parameterized strings and parameterized matches of parameterized strings. A data structure called a parameterized suffix tree is defined to aid in searching for parameterized matches. For fixed alphabets, algorithms are given to construct a parameterized suffix tree in linear time and to find all maximal parameterized matches over a threshold length in a parameterized p-string in time linear in the size of the input plus the number of matches reported. The algorithms have been implemented, and experimental results show that they perform well on C code.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1343–1362},
numpages = {20},
keywords = {pattern matching, string matching, duplication}
}

@article{10.5555/262543.262552,
author = {Driscoll, J. R. and Healy, D. M. and Rockmore, D. N.},
title = {Fast Discrete Polynomial Transforms with Applications to Data Analysis for Distance Transitive Graphs},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
abstract = {Let $poly = {P_0,dots,P_{n-1}}$ denote a set of polynomials with complex coefficients. Let $pts = {z_0,dots,z_{n-1}}subset cplx$ denote any set of {it sample points}. For any $f = (f_0,dots,f_{n-1}) in cplx^n$, the {it discrete polynomial transform} of $f$ (with respect to $poly$ and $pts$) is defined as the collection of sums, ${fhat(P_0),dots,fhat(P_{n-1})}$, where $fhat(P_j) = langle f,P_j rangle = sum_{i=0}^{n-1} f_iP_j(z_i)w(i)$ for some associated weight function $w$. These sorts of transforms find important applications in areas such as medical imaging and signal processing. In this paper, we present fast algorithms for computing discrete orthogonal polynomial transforms. For a system of $N$ orthogonal polynomials of degree at most $N-1$, we give an $O(Nlog^2 N)$ algorithm for computing a discrete polynomial transform at an arbitrary set of points instead of the $N^2$ operations required by direct evaluation. Our algorithm depends only on the fact that orthogonal polynomial sets satisfy a three-term recurrence and thus it may be applied to any such set of discretely sampled functions. In particular, sampled orthogonal polynomials generate the vector space of functions on a distance transitive graph. As a direct application of our work, we are able to give a fast algorithm for computing subspace decompositions of this vector space which respect the action of the symmetry group of such a graph. This has direct applications to treating computational bottlenecks in the spectral analysis of data on distance transitive graphs, and we discuss this in some detail.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1066–1099},
numpages = {34},
keywords = {fast Fourier transform, discrete polynomial transform, orthogonal polynomials, distance transitive graph, FFT, three-term recurrence}
}

@article{10.5555/262543.262549,
author = {Walicki, Michal and Meldal, Sigurd},
title = {Singular and Plural Nondeterministic Parameters},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
abstract = {The article defines algebraic semantics of singular (call-time-choice) and plural (run-time-choice) nondeterministic parameter passing and presents a specification language in which operations with both kinds of parameters can be defined simultaneously. Sound and complete calculi for both semantics are introduced. We study the relations between the two semantics and point out that axioms for operations with plural arguments may be considered as axiom schemata for operations with singular arguments.},
journal = {SIAM J. Comput.},
month = aug,
pages = {991–1005},
numpages = {15},
keywords = {many-sorted algebra, nondeterminism, algebraic specification, sequent calculus}
}

@article{10.5555/262543.262545,
author = {Storer, James A. and Reif, John H.},
title = {Error-Resilient Optimal Data Compression},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
abstract = {The problem of communication and computation in the presence of errors is difficult, and general solutions can be time consuming and inflexible (particularly when implemented with a prescribed error detection/correction). A reasonable approach is to investigate reliable communication in carefully selected areas of fundamental interest where specific solutions may be more practical than general purpose techniques. In this paper, we study the problem of error-resilient communication and computation in a particularly challenging area,  adaptive lossless data compression , where the devastating effect of error propagation is a long-standing open problem that was posed in the papers of Lempel and Ziv in the late 1970s. In fact, the non-error resilience of adaptive data compression has been a practical drawback of its use in many applications. Protocols that require the receiver to request retransmission from the sender when an error is detected can be impractical for many applications where such two-way communication is not possible or is self-defeating (e.g., with data compression, retransmission may be tantamount to losing the data that could have been transmitted in the mean time). In addition, bits of encoded data that are corrupted while data is in storage will in general not be recoverable and may corrupt the entire decompressed file. By  error resilience , we mean that even though errors may not be detected, there are strong guarantees that their effects will not propagate.Our main result is a provable error-resilient adaptive lossless data-compression algorithm which nevertheless maintains optimal compression over the usual input distributions (e.g., stationary ergodic sources). We state our result in the context of a more general model that we call  dynamic dictionary communication , where a sender and receiver work in a "lock-step" cooperation to maintain identical copies of a  dictionary D  that is constantly changing. For lossless data compression, the dictionary stores a set of strings that have been seen in the past and data is compressed by sending only indices of strings over the channel. Other applications of our model include robotics (e.g., remote terrain mapping) and computational learning theory.},
journal = {SIAM J. Comput.},
month = aug,
pages = {934–949},
numpages = {16},
keywords = {data compression, adaptive algorithm, communication channel, error propagation}
}

@article{10.1137/S009753979528007X,
author = {Crochemore, Maxime and Galil, Zvi and Gasieniec, Leszek and Park, Kunsoo and Rytter, Wojciech},
title = {Constant-Time Randomized Parallel String Matching},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979528007X},
doi = {10.1137/S009753979528007X},
abstract = {Given a pattern string of length m for the string-matching problem, we design an algorithm that computes deterministic samples of a sufficiently long substring of the pattern in constant time. This problem used to be the bottleneck in the pattern preprocessing for one- and two-dimensional pattern matching. The best previous time bound was O(log 2 m / log log m). We use this algorithm to obtain the following results (all algorithms below are optimal parallel algorithms on a CRCW PRAM): a deterministic string-matching algorithm which takes O (log log m ) time for preprocessing and constant time for text search, which are the best possible in both preprocessing and text search; a constant-time deterministic string-matching algorithm in the case where the text length n satisfies $n=Omega(m^{1+epsilon})$ for a constant $epsilon&gt;0$; a simple string-matching algorithm that has constant time with high probability for random input; the main result: a constant-expected-time Las Vegas algorithm for computing the period of the pattern and all witnesses and thus for string matching itself; in both cases, an $Omega(loglog m)$ lower bound is known for deterministic algorithms.},
journal = {SIAM J. Comput.},
month = aug,
pages = {950–960},
numpages = {11},
keywords = {parallel string matching, randomized algorithms, deterministic samples}
}

@article{10.1137/S0097539794279614,
author = {Gibbons, Phillip B. and Korach, Ephraim},
title = {Testing Shared Memories},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794279614},
doi = {10.1137/S0097539794279614},
abstract = {Sequential consistency is the most widely used correctness condition for multiprocessor memory systems. This paper studies the problem of testing shared-memory multiprocessors to determine if they are indeed providing a sequentially consistent memory. It presents the first formal study of this problem, which has applications to testing new memory system designs and realizations, providing run-time fault tolerance, and detecting bugs in parallel programs.A series of results are presented for testing an execution of a shared memory under various scenarios, comparing sequential consistency with linearizability, another well-known correctness condition. Linearizability imposes additional restrictions on the shared memory, beyond that of sequential consistency; these restrictions are shown to be useful in testing such memories.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1208–1244},
numpages = {37},
keywords = {linearizability, NP-completeness, sequential consistency, multiprocessors, testing, shared memory}
}

@article{10.1137/S0097539794263695,
author = {Karzanov, Alexander V. and McCormick, S. Thomas},
title = {Polynomial Methods for Separable Convex  Optimization in Unimodular Linear Spaces  with Applications},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794263695},
doi = {10.1137/S0097539794263695},
abstract = {We consider the problem of minimizing a separable convex objective function over the linear space given by a system Mx=0 with M a totally unimodular matrix. In particular, this generalizes the usual minimum linear cost circulation and cocirculation problems in a network and the problems of determining the Euclidean distance from a point to the perfect bipartite matching polytope and the feasible flows polyhedron.  We first show that the idea of minimum mean cycle canceling originally worked out for linear cost circulations by Goldberg and Tarjan [J. Assoc. Comput. Mach., 36 (1989), pp. 873--886.] and extended to some other problems [T. R. Ervolina and S. T. McCormick, Discrete Appl. Math., 46 (1993), pp. 133--165], [A. Frank and A. V. Karzanov, Technical Report RR 895-M, Laboratoire ARTEMIS IMAG, Universit\'{e} Joseph Fourier, Grenoble, France, 1992], [T. Ibaraki, A. V. Karzanov, and H. Nagamochi, private communication, 1993], [M. Hadjiat, Technical Report, Groupe Intelligence Artificielle, Facult\'{e} des Sciences de Luminy, Marseille, France, 1994] can be generalized to give a combinatorial method with geometric convergence for our problem. We also generalize the computationally more efficient cancel-and-tighten method.  We then consider objective functions that are piecewise linear, pure and piecewise quadratic, or piecewise mixed linear and quadratic, and we show how both methods can be implemented to find exact solutions in polynomial time (strongly polynomial in the piecewise linear case). These implementations are then further specialized for finding circulations and cocirculations in a network.  We finish by showing how to extend our methods to find optimal integer solutions, to linear spaces of larger fractionality, and to the case when the objective functions are given by approximate oracles.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1245–1275},
numpages = {31},
keywords = {unimodular linear spaces, separable convex optimization, network flows, min mean canceling}
}

@article{10.1137/S0097539793259483,
author = {Goldberg, Leslie Ann and Jerrum, Mark and Leighton, Tom and Rao, Satish},
title = {Doubly Logarithmic Communication Algorithms for Optical-Communication Parallel Computers},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793259483},
doi = {10.1137/S0097539793259483},
abstract = {In this paper, we consider the problem of interprocessor communication on parallel computers that have optical communication networks. We consider the completely connected optical-communication parallel computer (OCPC), which has a completely connected optical network, and also the mesh-of-optical-buses parallel computer (MOB-PC), which has a mesh of optical buses as its communication network. The particular communication problem that we study is that of realizing an h-relation. In this problem, each processor has at most h messages to send and at most h messages to receive. It is clear that any 1-relation can be realized in one communication step on an OCPC. However, the best previously known p-processor OCPC algorithm for realizing an arbitrary h-relation for h &gt; 1 requires $Theta(h + log p)$ expected communication steps. (This algorithm is due to Valiant and is based on earlier work of Anderson and Miller.) Valiant's algorithm is optimal only for $h=Omega(log p)$, and it is an open question of Ger\'{e}b-Graus and Tsantilas whether there is a faster algorithm for h=o(log p). In this paper, we answer this question in the affirmative and we extend the range of optimality by considering the case in which $hleq log p$. In particular, we present a $Theta(h + loglog p)$-communication-step randomized algorithm that realizes an arbitrary h-relation on a p-processor OCPC. We show that if $hleq log p$, then the failure probability can be made as small as $p^{-alpha}$ for any positive constant $alpha$. We use the OCPC algorithm as a subroutine in a $Theta(h + loglog p)$-communication-step randomized algorithm that realizes an arbitrary h-relation on a $ptimes p$-processor MOB-PC. Once again, we show that if $hleq log p$, then the failure probability can be made as small as $p^{-alpha}$ for any positive constant $alpha$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1100–1119},
numpages = {20},
keywords = {parallel algorithms, optical networks, randomized algorithms, routing}
}

@article{10.1137/S0097539793247439,
author = {Fenner, Stephen and Homer, Steven and Ogihara, Mitsunori and Selman, Alan},
title = {Oracles That Compute Values},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793247439},
doi = {10.1137/S0097539793247439},
abstract = {This paper focuses on complexity classes of partial functions that are computed in polynomial time with oracles in NPMV, the class of all multivalued partial functions that are computable nondeterministically in polynomial time. Concerning deterministic polynomial-time reducibilities, it is shown that a multivalued partial function is polynomial-time computable with k adaptive queries to NPMV if and only if it is polynomial-time computable via 2 k -1 nonadaptive queries to NPMV; a characteristic function is polynomial-time computable with k adaptive queries to NPMV if and only if it is polynomial-time computable with k adaptive queries to NP; unless the Boolean hierarchy collapses, for every k , k adaptive (nonadaptive) queries to NPMV are different than k +1 adaptive (nonadaptive) queries to NPMV. Nondeterministic reducibilities, lowness, and the difference hierarchy over NPMV are also studied. The difference hierarchy for partial functions does not collapse unless the Boolean hierarchy collapses, but, surprisingly, the levels of the difference and bounded query hierarchies do not interleave (as is the case for sets) unless the polynomial hierarchy collapses.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1043–1065},
numpages = {23},
keywords = {computational complexity, relativized computation, Boolean hierarchy, complexity classes, multivalued functions, bounded query classes, NPMV}
}

@article{10.1137/S0097539792240005,
author = {Berger, Bonnie},
title = {The Fourth Moment Method},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240005},
doi = {10.1137/S0097539792240005},
abstract = {Higher moment analysis has typically been used to upper bound certain functions. In this paper, we introduce a new combinatorial method to lower bound the expectation of the absolute value of a random variable X by the expectation of a quartic in X. In the special case where we are looking at the absolute value of a (weighted) sum of {-1,+1} unbiased random variables, we achieve tight bounds, using only a fourth moment, for the total discrepancy of a set system. Because the fourth moment depends only on 4-wise independence, our bounds will hold over polynomially sized distributions, and so these bounds will be directly applicable in removing randomness to obtain NC algorithms. We obtain the first NC algorithms for the problems of total discrepancy, maximum acyclic subgraph, tournament ranking, the Gale--Berlekamp switching game, and edge discrepancy. We show that for most of these applications it is truly necessary to consider a fourth moment by exhibiting a 3-wise independent distribution which does not achieve the required bounds. Our method is strong enough to give a new combinatorial bound on tournament ranking.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1188–1207},
numpages = {20},
keywords = {Gayle--Berlekamp switching game, maximum acyclic subgraph, removing randomness, set discrepancy}
}

@article{10.1137/S0097539792239461,
author = {Baliga, Ganesh and Jain, Sanjay and Sharma, Arun},
title = {Learning from Multiple Sources of Inaccurate Data},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792239461},
doi = {10.1137/S0097539792239461},
abstract = {Most theoretical models of inductive inference make the idealized assumption that the data available to a learner is from a  single  and  accurate  source. The subject of inaccuracies in data emanating from a single source has been addressed by several authors. The present paper argues in favor of a more realistic learning model in which data emanates from  multiple  sources, some or all of which may be  inaccurate . Three kinds of inaccuracies are considered: spurious data (modeled as  noisy  texts), missing data (modeled as  incomplete  texts), and a mixture of spurious and missing data (modeled as  imperfect  texts). Motivated by the above argument, the present paper introduces and theoretically analyzes a number of inference criteria in which a learning machine is fed data from multiple sources, some of which may be infected with inaccuracies. The learning situation modeled is the identification in the limit of programs from graphs of computable functions. The main parameters of the investigation are: the kind of inaccuracy, the total number of data sources, the number of faulty data sources which produce data within an acceptable bound, and the bound on the number of errors allowed in the final hypothesis learned by the machine.Sufficient conditions are determined under which, for the same kind of inaccuracy, for the same bound on the number of errors in the final hypothesis, and for the same bound on the number of inaccuracies, learning from multiple texts, some of which may be inaccurate, is equivalent to learning from a single inaccurate text. The general problem of determining when learning from multiple inaccurate texts is a restriction over learning from a single inaccurate text turns out to be combinatorially very complex. Significant partial results are provided for this problem. Several results are also provided about conditions under which the detrimental effects of multiple texts can be overcome by either allowing more errors in the final hypothesis or by reducing the number of inaccuracies in the texts.It is also shown that the usual hierarchies resulting from allowing extra errors in the final program (results in increased learning power) and allowing extra inaccuracies in the texts (results in decreased learning power) hold.Finally, it is demonstrated that in the context of learning from multiple inaccurate texts, spurious data is better than missing data, which in turn is better than a mixture of spurious and missing data.},
journal = {SIAM J. Comput.},
month = aug,
pages = {961–990},
numpages = {30},
keywords = {multiple sources, machine learning, inductive inference, inaccurate data}
}

@article{10.1137/S0097539792234226,
author = {Naor, Dalit and Gusfield, Dan and Martel, Charles},
title = {A Fast Algorithm for Optimally Increasing the Edge Connectivity},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792234226},
doi = {10.1137/S0097539792234226},
abstract = {Let G=(V,E) be an undirected, unweighted graph with n nodes, m edges and edge connectivity $lambda$. Given an input parameter $delta$, the edge augmentation problem is to find the smallest set of edges to add to G so that its edge connectivity is increased by $delta$.  In this paper, we present a solution to this problem which runs in $O(delta ^2 nm + delta^3 n^2 + n F(G))$, where F(G) is the time to perform one maximum flow on G. In fact, our solution gives the optimal augmentation for every $delta '$, $1 le delta ' le delta$, in the same time bound. By introducing minor modifications to the solution, we can solve the problem without knowing $delta$ in advance, and we can also solve the node-weighted version and the degree-constrained version of the problem. If $delta =1$, then our solution is particularly simple; it runs in O(nm) time, and it is a natural generalization of the algorithm in  [K. Eswaran and R. E. Tarjan, SIAM J. Comput., 5 (1976), pp. 653--665] for the case where $lambda+delta =2$. We also solve the converse problem in the same time bound: given an input number k, increase the connectivity of G as much as possible by adding at most k edges. Our solution makes extensive use of the structure of particular sets of cuts.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1139–1165},
numpages = {27},
keywords = {graph algorithms, network flow, graph connectivity, minimum cuts}
}

@article{10.1137/S0097539792233257,
author = {Guibas, Leonidas J. and Motwani, Rajeev and Raghavan, Prabhakar},
title = {The Robot Localization Problem},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792233257},
doi = {10.1137/S0097539792233257},
abstract = {We consider the following problem: given a simple polygon ${cal P}$ and a star-shaped polygon ${cal V}$, find a point (or the set of points) in ${cal P}$ from which the portion of ${cal P}$ that is visible is translation-congruent to ${cal V}$.  The problem arises in the localization of robots equipped with a range finder and a compass---${cal P}$ is a map of a known environment, ${cal V}$ is the portion visible from the robot's position, and the robot must use this information to determine its position in the map.  We give a scheme that preprocesses ${cal P}$ so that any subsequent query ${cal V}$ is answered in optimal time O(m + log n + A), where m and n are the number of vertices in ${cal V}$ and ${cal P}$ and A is the number of points in ${cal P}$ that are valid answers (the output size).  Our technique uses O(n5) space and preprocessing in the worst case; within certain limits, we can trade off smoothly between the query time and the preprocessing time and space. In the process of solving this problem, we also devise a data structure for output-sensitive determination of the visibility polygon of a query point inside a polygon ${cal P}$.  We then consider a variant of the localization problem in which there is a maximum distance to which the robot can "see"---this is motivated by practical considerations, and we outline a similar solution for this case. We finally show that a single localization query ${cal V}$ can be answered in time O(mn) with no preprocessing.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1120–1138},
numpages = {19},
keywords = {computational geometry, robotics, geometric algorithms, localization}
}

@article{10.1137/S0097539792229507,
author = {Dor, Dorit and Tarsi, Michael},
title = {Graph Decomposition is NP-Complete: A Complete Proof of Holyer's Conjecture},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792229507},
doi = {10.1137/S0097539792229507},
abstract = {An H-decomposition of a graph G=(V,E) is a partition of E into subgraphs isomorphic to H. Given a fixed graph H, the H-decomposition problem is to determine whether an input graph G admits an H-decomposition.In 1980, Holyer conjectured that H-decomposition is NP-complete whenever H is connected and has three edges or more. Some partial results have been obtained since then. A complete proof of Holyer's conjecture is the content of this paper. The characterization problem of all graphs H for which H-decomposition is NP-complete is hence reduced to graphs where every connected component contains at most two edges.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1166–1187},
numpages = {22},
keywords = {NP-completeness, graph, decomposition}
}

@article{10.1137/S0097539791196603,
author = {Louchard, G. and Kenyon, Claire and Schott, R.},
title = {Data Structures' Maxima},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791196603},
doi = {10.1137/S0097539791196603},
abstract = {The purpose of this paper is to analyze the maxima properties (value and position) of some data structures. Our theorems concern the  distribution of these random variables. Previously known results usually dealt with the mean and sometimes the variance of the random variables. Many of our results rely on diffusion techniques. This is a very powerful tool that has already been used with some success in algorithm complexity analysis.},
journal = {SIAM J. Comput.},
month = aug,
pages = {1006–1042},
numpages = {37},
keywords = {Brownian bridges, data structures, queuing theory, diffusion techniques, probabilistic analysis of algorithms}
}

@article{10.1137/S0097539790187084,
author = {Feldman, Pesech and Micali, Silvio},
title = {An Optimal Probabilistic Protocol for Synchronous Byzantine Agreement},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790187084},
doi = {10.1137/S0097539790187084},
abstract = {Broadcasting guarantees the recipient of a message that everyone else has received the same message. This guarantee no longer exists in a setting in which all communication is person-to-person and some of the people involved are untrustworthy: though he may claim to send the same message to everyone, an untrustworthy sender may send different messages to different people. In such a setting,  Byzantine agreement  offers the "best alternative" to broadcasting. Thus far, however, reaching Byzantine agreement has required either many rounds of communication (i.e., messages had to be sent back and forth a number of times that grew with the size of the network) or the help of some external trusted party. In this paper, for the standard communication model of synchronous networks in which each pair of processors is connected by a private communication line, we exhibit a protocol that, in probabilistic polynomial time and without relying on any external trusted party, reaches Byzantine agreement in an expected constant number of rounds and in the worst natural fault model. In fact, our protocol successfully tolerates that up to 1/3 of the processors in the network may deviate from their prescribed instructions in an arbitrary way, cooperate with each other, and perform arbitrarily long computations.Our protocol effectively demonstrates the power of randomization and zero-knowledge computation against errors. Indeed, it proves that "privacy" (a fundamental ingredient of one of our primitives), even when is not a desired goal in itself (as for the Byzantine agreement problem), can be a crucial tool for achieving correctness.Our protocol also introduces three new primitives---graded broadcast, graded verifiable secret sharing, and oblivious common coin---that are of independent interest, and may be effectively used in more practical protocols than ours.},
journal = {SIAM J. Comput.},
month = aug,
pages = {873–933},
numpages = {61},
keywords = {randomization, broadcasting, fault-tolerant computation, Byzantine agreement}
}

@article{10.1137/S0097539795281086,
author = {Borchers, Al and Du, Ding-Zhu},
title = {The <i>k</i>-Steiner Ratio in Graphs},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539795281086},
doi = {10.1137/S0097539795281086},
abstract = {A Steiner minimum tree (SMT) is the shortest-length tree in a metric space interconnecting a set of points, called the regular points, possibly using additional vertices. A k-size Steiner minimum tree (kSMT) is one that can be split into components where all regular points are leaves and all components have at most k leaves. The k-Steiner ratio, $rho_{k}$, is the infimum of the ratios SMT/kSMT over all finite sets of regular points in all possible metric spaces, where the distances are given by a complete graph. Previously, only $rho_{2}$ and $rho_{3}$ were known exactly in graphs, and some bounds were known for other values of k. In this paper, we determine $rho_{k}$ exactly for all k. From this we prove a better approximation ratio for the Steiner tree problem in graphs.},
journal = {SIAM J. Comput.},
month = jun,
pages = {857–869},
numpages = {13},
keywords = {Steiner trees, graph theory, approximation algorithms, Steiner ratio, graph algorithms}
}

@article{10.1137/S0097539794276865,
author = {Singh, Gurdip},
title = {Leader Election in Complete Networks},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794276865},
doi = {10.1137/S0097539794276865},
abstract = {Leader election is a fundamental problem in distributed computing and has a number of applications. This paper studies the problem of leader election in complete asynchronous networks. We present a message-optimal protocol that requires $O(Nlog{N})$ messages and $O(N/log{N})$ time, where $N$ is the number of nodes in the system. The time complexity of this protocol is a significant improvement over currently known protocols for this problem. We also give a family of protocols with message and time complexities $O(N k)$ and $O(N/k)$, respectively, where $log{N} leq k leq N$. Many problems such as spanning-tree construction and computing a global function are equivalent to leader election in terms of their message and time complexities, and therefore our result improves the time complexity of these problems as well.},
journal = {SIAM J. Comput.},
month = jun,
pages = {772–785},
numpages = {14},
keywords = {leader election, distributed algorithms, complete networks, time complexity}
}

@article{10.1137/S0097539794270881,
author = {Shioura, Akiyoshi and Tamura, Akihisa and Uno, Takeaki},
title = {An Optimal Algorithm for Scanning All Spanning Trees of Undirected Graphs},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794270881},
doi = {10.1137/S0097539794270881},
abstract = {Let G be an undirected graph with V vertices and E edges. Many algorithms have been developed for enumerating all spanning trees in G. Most of the early algorithms use a technique called "backtracking." Recently, several algorithms using a different technique have been proposed by Kapoor and Ramesh (1992), Matsui (1993), and Shioura and Tamura (1993). They find a new spanning tree by exchanging one edge of a current one. This technique has the merit of enabling us to compress the whole output of all spanning trees by outputting only relative changes of edges. Kapoor and Ramesh first proposed an O(N + V + E)-time algorithm by adopting such a "compact" output, where N is the number of spanning trees. Another algorithm with the same time complexity was constructed by Shioura and Tamura. These are optimal in the sense of time complexity but not in terms of space complexity because they take O(VE) space. We refine Shioura and Tamura's algorithm and decrease the space complexity from O(VE) to O(V + E) while preserving the time complexity. Therefore, our algorithm is optimal in the sense of both time and space complexities.},
journal = {SIAM J. Comput.},
month = jun,
pages = {678–692},
numpages = {15},
keywords = {undirected graphs, spanning trees, optimal algorithm}
}

@article{10.1137/S0097539794267255,
author = {Thomassen, Carsten},
title = {On the Complexity of Finding a Minimum Cycle  Cover of a Graph},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794267255},
doi = {10.1137/S0097539794267255},
abstract = {We prove that the problem of finding a cycle cover of smallest total length is NP-hard. This confirms a conjecture of Itai, Lipton, Papadimitriou, and Rodeh from 1981.},
journal = {SIAM J. Comput.},
month = jun,
pages = {675–677},
numpages = {3},
keywords = {complexity, minimum cycle cover}
}

@article{10.1137/S0097539794264809,
author = {Pudl\'{a}k, Pavel and R\"{o}dl, Vojtech and Sgall, Jir\'{\i}},
title = {Boolean Circuits, Tensor Ranks, and Communication Complexity},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794264809},
doi = {10.1137/S0097539794264809},
abstract = {We investigate two methods for proving lower bounds on the size of small-depth circuits, namely the approaches based on multiparty communication games and algebraic characterizations extending the concepts of the tensor rank and rigidity of matrices. Our methods are combinatorial, but we think that our main contribution concerns the algebraic concepts used in this area (tensor ranks and rigidity). Our main results are following. (i) An $o(n)$-bit protocol for a communication game for computing shifts, which also gives an upper bound of $o(n^2)$ on the contact rank of the tensor of multiplication of polynomials; this disproves some earlier conjectures. A related probabilistic construction gives an $o(n)$ upper bound for computing all permutations and an $O(nloglog n)$ upper bound on the communication complexity of pointer jumping with permutations. (ii) A lower bound on certain restricted circuits of depth 2 which are related to the problem of proving a superlinear lower bound on the size of logarithmic-depth circuits; this bound has interpretations both as a lower bound on the rigidity of the tensor of multiplication of polynomials and as a lower bound on the communication needed to compute the shift function in a restricted model. (iii) An upper bound on Boolean circuits of depth 2 for computing shifts and, more generally, all permutations; this shows that such circuits are more efficient than the model based on sending bits along vertex-disjoint paths.},
journal = {SIAM J. Comput.},
month = jun,
pages = {605–633},
numpages = {29},
keywords = {tensor rank, circuit, random graph, communication complexity}
}

@article{10.1137/S0097539794261970,
author = {Hemaspaandra, Lane A. and Rothe, J\"{o}rg},
title = {Unambiguous Computation: Boolean Hierarchies and Sparse Turing-Complete Sets},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794261970},
doi = {10.1137/S0097539794261970},
abstract = {It is known that for any class $tweak{cal C}$ closed under union and intersection, the Boolean closure of ${cal C}$, the Boolean hierarchy over $tweak{cal C}$, and the symmetric difference hierarchy over $tweak{cal C}$ all are equal. We prove that these equalities hold for any complexity class closed under intersection; in particular, they thus hold for unambiguous polynomial time (UP). In contrast to the NP case, we prove that the Hausdorff hierarchy and the nested difference hierarchy over UP both fail to capture the Boolean closure of UP in some relativized worlds.  Karp and Lipton proved that if nondeterministic polynomial time has sparse Turing-complete sets, then the polynomial hierarchy collapses. We establish the first consequences from the assumption that unambiguous polynomial time has sparse Turing-complete sets: (a) $up seq mbox{Low}_2$, where $mbox{Low}_2$ is the second level of the low hierarchy, and (b) each level of the unambiguous polynomial hierarchy is contained one level lower in the promise unambiguous polynomial hierarchy than is otherwise known to be the case.},
journal = {SIAM J. Comput.},
month = jun,
pages = {634–653},
numpages = {20},
keywords = {unambiguous computation, sparse Turing-complete sets, Boolean hierarchy}
}

@article{10.1137/S0097539793259185,
author = {Simon, Hans Ulrich},
title = {Bounds on the Number of Examples Needed for Learning Functions},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793259185},
doi = {10.1137/S0097539793259185},
abstract = {We prove general lower bounds on the number of examples needed for learning function classes within different natural learning models which are related to pac-learning (and coincide with the pac-learning model of Valiant in the case of {0,1}-valued functions). The lower bounds are obtained by showing that all nontrivial function classes contain a "hard binary-valued subproblem." Although (at first glance) it seems to be likely that real-valued function classes are much harder to learn than their hardest binary-valued subproblem, we show that these general lower bounds cannot be improved by more than a logarithmic factor. This is done by discussing some natural function classes like nondecreasing functions or piecewise-smooth functions (the function classes that were discussed in [M. J. Kearns and R. E. Schapire, Proc. 31st Annual Symposium on the Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1990, pp. 382--392, full version, J. Comput. System Sci., 48 (1994), pp. 464--497], [D. Kimber and P. M. Long, Proc. 5th Annual Workshop on Computational Learning Theory, ACM, New York, 1992, pp. 153--160]) with certain restrictions concerning their slope.},
journal = {SIAM J. Comput.},
month = jun,
pages = {751–763},
numpages = {13},
keywords = {function learning, sample complexity}
}

@article{10.1137/S0097539793258775,
author = {Chandrasekaran, R. and Chen, Bo and Galambos, G\'{a}bor and Narayanan, P. R. and Van Vliet, Andr\'{e} and Woeginger, Gerhard J.},
title = {A Note on "An On-Line Scheduling Heuristic with Better Worst Case Ratio than Graham's List Scheduling"},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793258775},
doi = {10.1137/S0097539793258775},
journal = {SIAM J. Comput.},
month = jun,
pages = {870–872},
numpages = {3},
keywords = {scheduling, combinatorial problems, worst-case bounds, on-line algorithms}
}

@article{10.1137/S0097539793258295,
author = {Cai, Liming and Chen, Jianer},
title = {On the Amount of Nondeterminism and the Power of Verifying},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793258295},
doi = {10.1137/S0097539793258295},
abstract = {The relationship between nondeterminism and other computational resources is investigated based on the "guess-then-check" model GC.  Systematic techniques are developed to construct natural complete languages for the classes defined by this model.  This improves a number of previous results in the study of limited nondeterminism.  Connections of the model GC to computational optimization problems are exhibited.},
journal = {SIAM J. Comput.},
month = jun,
pages = {733–750},
numpages = {18},
keywords = {nondeterminism, complete languages, computational optimization, computational complexity}
}

@article{10.1137/S0097539793256041,
author = {Maass, Wolfgang},
title = {Bounds for the Computational Power and Learning Complexity of Analog Neural Nets},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256041},
doi = {10.1137/S0097539793256041},
abstract = {It is shown that high-order feedforward neural nets of constant depth with piecewise-polynomial activation functions and arbitrary real weights can be simulated for Boolean inputs and outputs by neural nets of a somewhat larger size and depth with Heaviside gates and weights from {-1, 0, 1}. This provides the first known upper bound for the computational power of the former type of neural nets. It is also shown that in the case of first-order nets with piecewise-linear activation functions one can replace arbitrary real weights by rational numbers with polynomially many bits without changing the Boolean function that is computed by the neural net. In order to prove these results, we introduce two new methods for reducing nonlinear problems about weights in multilayer neural nets to linear problems for a transformed set of parameters. These transformed parameters can be interpreted as weights in a somewhat larger neural net.As another application of our new proof technique we show that neural nets with piecewise-polynomial activation functions and a constant number of analog inputs are probably approximately correct (PAC) learnable (in Valiant's model for PAC learning [Comm. Assoc. Comput. Mach., 27 (1984), pp. 1134--1142]).},
journal = {SIAM J. Comput.},
month = jun,
pages = {708–732},
numpages = {25},
keywords = {neural networks, circuit complexity, learning complexity, analog computing, threshold circuits}
}

@article{10.1137/S0097539793252080,
author = {Mohaban, Shai and Sharir, Micha},
title = {Ray Shooting Amidst Spheres in Three Dimensions and Related Problems},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252080},
doi = {10.1137/S0097539793252080},
abstract = {We consider the problem of ray shooting amidst spheres in 3-space: given n arbitrary (possibly intersecting) spheres in 3-space and any $epsilon$ &gt; 0, we show how to preprocess the spheres in time $O(n^{3+epsilon})$ into a data structure of size $O(n^{3+epsilon})$ so that any ray-shooting query can be answered in time $O(n^epsilon)$. Our result improves previous techniques (see [P. K. Aggarwal, L. Guibas, M. Pellegrini, and M. Sharir, "Ray shooting amidst spheres," unpublished note] and [P. K. Aggarwal and J. Matousek, Discrete Comput. Geom., 11 (1994), pp. 393-418]), where roughly $O(n^4)$ storage was required to support fast queries. Our result shows that ray shooting amidst spheres has complexity comparable with that of ray shooting amidst planes in 3-space.  Our technique applies to more general (convex) objects in 3-space, and we also discuss those extensions.},
journal = {SIAM J. Comput.},
month = jun,
pages = {654–674},
numpages = {21},
keywords = {computational geometry, ray shooting}
}

@article{10.1137/S009753979324694X,
author = {Cole, Richard and Hariharan, Ramesh},
title = {Tighter Upper Bounds on the Exact Complexity of String Matching},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979324694X},
doi = {10.1137/S009753979324694X},
abstract = {This paper considers how many character comparisons are needed to find all occurrences of a pattern of length m in a text of length n. The main contribution is to show an upper bound of the form of n + O(n/m) character comparisons, following preprocessing. Specifically, we show an upper bound of $n + frac{8}{3(m+1)}(n-m)$ character comparisons. This bound is achieved by an online algorithm which performs O(n) work in total and requires O(m) space and O(m2) time for preprocessing. The current best lower bound for online algorithms is $n + frac{16}{7m+27}(n-m)$ character comparisons for $m=16k+19$, for any integer $kgeq 1$, and for general algorithms is $n+frac{2}{m+3}(n-m)$ character comparisons, for $m=2k+1$, for any integer $kgeq 1$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {803–856},
numpages = {54},
keywords = {comparisons, periodicity, exact complexity, string matching}
}

@article{10.1137/S0097539792282965,
author = {Impagliazzo, Russell and Paturi, Ramamohan and Saks, Michael E.},
title = {Size--Depth Tradeoffs for Threshold Circuits},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792282965},
doi = {10.1137/S0097539792282965},
abstract = {The following size--depth tradeoff for threshold circuits is obtained: any threshold circuit of depth $d$ that computes the parity function on $n$ variables must have at least $n^{1 + ctheta^{-d }}$ edges, where $c&gt;0$ and $theta leq 3$ are constants independent of $n$ and $d$. Previously known constructions show that up to the choice of $c$ and $theta$ this bound is best possible. In particular, the lower bound implies an affirmative answer to the conjecture of Paturi and Saks that a bounded-depth threshold circuit that computes parity requires a superlinear number of edges. This is the first superlinear lower bound for an explicit function that holds for any fixed depth and the first that applies to threshold circuits with unrestricted weights. The tradeoff is obtained as a consequence of a general restriction theorem for threshold circuits with a small number of edges: For any threshold circuit with $n$ inputs, depth $d$, and at most $kn$ edges, there exists a partial assignment to the inputs that fixes the output of the circuit to a constant while leaving $lfloor n/(c_1k)^{c_2theta^{d}} rfloor$ variables unfixed, where $c_1,c_2 &gt; 0$ and $ theta leq 3$ are constants independent of $n$, $k$, and $d$.A tradeoff between the number of gates and depth is also proved: any threshold circuit of depth $d$ that computes the parity of $n$ variables has at least $(n/2)^{1/2(d-1)}$ gates. This tradeoff, which is essentially the best possible, was proved previously (with a better constant in the exponent) for the case of threshold circuits with polynomially bounded weights in [K. Siu, V. Roychowdury, and T. Kailath,  IEEE Trans. Inform. Theory , 40 (1994), pp. 455--466]; the result in the present paper holds for unrestricted weights.},
journal = {SIAM J. Comput.},
month = jun,
pages = {693–707},
numpages = {15},
keywords = {lower bounds, circuit complexity, threshold circuits}
}

@article{10.1137/S0097539791202301,
author = {Deng, Xiaotie and Mahajan, Sanjeev},
title = {The Cost of Derandomization: Computability or Competitiveness},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791202301},
doi = {10.1137/S0097539791202301},
abstract = {Recently, much work has been done in game theory towards understanding the bounded rationality of players in infinite games. This requires the strategies of realistic players to be restricted to have bounded resources of reasoning. (See [H. Simon,  Decision and Organization , North--Holland, Amsterdam, 1972, pp. 161--176] for an extensive discussion; also see [X. Deng and C. H. Papadimitriou,  Math. Oper. Res ., 19 (1994), pp. 257--266], [C. Futia,  J. Math. Econom ., 4 (1977), pp. 289--299], [V. Knoblauch,  Games Econom. Behav ., 7 (1994), pp. 381--389], [E. Kalai and W. Stanford,  Econometria , 56 (1988), pp. 397--410], [A. Neyman,  Econom. Lett ., 19 (1985), pp. 227--229], and [C. H. Papadimitriou,  Game Theory Econom. Behav ., 4 (1992), pp. 122--131].) In this paper, we discuss infinite two-person games, focusing on the case where our player follows a computable strategy and the adversary may use any strategy, which formulates the notion of computer against extremely formidable nature. In this context, we say that an infinite game is semicomputably determinate if either the adversary has a winning strategy or our player has a computable winning strategy. We show that, whereas all open games are semicomputably determinate, there is a semicomputably indeterminate closed game. Since we want to prove an indeterminacy result for closed games and since the adversary's strategy set is uncountable and our player's strategy set is countable, our proof for the indeterminacy result requires a new diagonalization technique, which might be useful in other similar cases. Our study of semicomputable games was inspired by online computing problems. In this direction, we discuss several possible applications to derandomization in online computing, with the restriction that the strategies of our player should be computable.We also study the power of randomization for the classical case where our player is allowed to play according to unrestricted strategies. An indeterminate game is obtained for which both players have a simple randomized winning strategy against all of the deterministic strategies of the opponent.},
journal = {SIAM J. Comput.},
month = jun,
pages = {786–802},
numpages = {17},
keywords = {computability, online algorithms, derandomization, game theory}
}

@article{10.1137/S0097539790179944,
author = {Varricchio, Stefano},
title = {A Pumping Condition for Regular Sets},
year = {1997},
issue_date = {June 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790179944},
doi = {10.1137/S0097539790179944},
abstract = {We prove that a language of a finitely generated free monoid is regular if and only if it satisfies the positive block pumping property. This gives a positive answer to a problem posed by Ehrenfeucht, Parikh, and Rozenberg [SIAM J. Comput., 10 (1981), pp. 536--541].},
journal = {SIAM J. Comput.},
month = jun,
pages = {764–771},
numpages = {8},
keywords = {automata theory, pumping conditions, regular languages}
}

@article{10.1137/S0097539794286125,
author = {Teng, Shang-Hua and Yao, Frances F.},
title = {Approximating Shortest Superstrings},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794286125},
doi = {10.1137/S0097539794286125},
abstract = {The shortest-superstring problem is to find a shortest possible string that contains every string in a given set as substrings.  This problem has applications to data compression and DNA sequencing.  Since the problem is NP-hard and MAX SNP-hard, approximation algorithms are of interest.  We present a new algorithm which always finds a superstring that is at most 2.89 times as long as the shortest superstring.  Our result improves the $3$-approximation result of Blum et al.},
journal = {SIAM J. Comput.},
month = apr,
pages = {410–417},
numpages = {8},
keywords = {approximation algorithms, the shortest-superstring problem, combinatorial optimization, data compression, DNA sequencing, optimal assignments}
}

@article{10.1137/S0097539794270236,
author = {Allender, Eric and Balc\'{a}zar, Jos\'{e} and Immerman, Neil},
title = {A First-Order Isomorphism Theorem},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794270236},
doi = {10.1137/S0097539794270236},
abstract = {We show that for most complexity classes of interest, all sets complete under first-order projections (fops) are isomorphic under first-order isomorphisms.  That is, a very restricted version of the Berman--Hartmanis conjecture holds.  Since "natural" complete problems seem to stay complete via fops, this indicates that up to first-order isomorphism there is only one "natural" complete problem for each "nice" complexity class.},
journal = {SIAM J. Comput.},
month = apr,
pages = {557–567},
numpages = {11},
keywords = {complexity classes, first-order projection, descriptive complexity, reduction}
}

@article{10.1137/S0097539794265244,
author = {Alur, Rajeev and Attiya, Hagit and Taubenfeld, Gadi},
title = {Time-Adaptive Algorithms for Synchronization},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794265244},
doi = {10.1137/S0097539794265244},
abstract = {We consider concurrent systems in which there is an unknown upper bound on memory access time. Such a model is inherently different from the asynchronous model, where no such bound exists, and also from timing-based models, where such a bound exists and is known a priori. The appeal of our model lies in the fact that while it abstracts from implementation details, it is a better approximation of real concurrent systems than  the asynchronous model. Furthermore, it is stronger than the asynchronous model, enabling us to design algorithms for problems that are unsolvable in the asynchronous model.Two basic synchronization problems, consensus and mutual exclusion, are investigated in a shared-memory environment that supports atomic read/write registers. We show that $Theta(Deltafrac{log Delta}{loglog Delta})$ is an upper and lower bound on the time complexity of consensus, where $Delta$ is the (unknown) upper bound on memory access time. For the mutual exclusion problem, we design an efficient algorithm that takes advantage of the fact that some  upper bound on memory access time exists. The solutions for both problems are even more efficient in the absence of contention, in which case their time complexity is a constant.},
journal = {SIAM J. Comput.},
month = apr,
pages = {539–556},
numpages = {18},
keywords = {consensus, mutual exclusion, distributed computing, timing-based algorithms}
}

@article{10.1137/S0097539793260738,
author = {Condon, Anne and Feigenbaum, Joan and Lund, Carsten and Shor, Peter},
title = {Random Debaters and the Hardness of Approximating Stochastic Functions},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793260738},
doi = {10.1137/S0097539793260738},
abstract = {A  probabilistically checkable debate system  (PCDS) for a language  L  consists of a probabilistic polynomial-time verifier  V  and a debate between Player 1, who claims that the input  x  is in  L , and Player 0, who claims that the input  x  is not in L. It is known that there is a PCDS for  L  in which  V  flips  O (log  n ) coins and reads  O (1) bits of the debate if and only if  L  is in PSPACE [A. Condon, J. Feigenbaum, C. Lund, and P. Shor,  Chicago J. Theoret. Comput. Sci. , 1995, No. 4]. In this paper, we restrict attention to RPCDSs, which are PCDSs in which Player 0 follows a very simple strategy: On each turn, Player 0 chooses uniformly at random from the set of legal moves. We prove the following result.   Theorem .  L has an RPCDS in which the verifier flips O (log  n )  coins and reads O (1)  bits of the debate if and only if L is in  PSPACE.This new characterization of PSPACE is used to show that certain  stochastic  PSPACE-hard functions are as hard to approximate closely as they are to compute exactly. Examples of such functions include optimization versions of Dynamic Graph Reliability, Stochastic Satisfiability, Mah-Jongg, Stochastic Generalized Geography, and other "games against nature" of the type introduced in [C. Papadimitriou,  J. Comput. System Sci ., 31 (1985), pp. 288--301].},
journal = {SIAM J. Comput.},
month = apr,
pages = {369–400},
numpages = {32},
keywords = {complexity theory, probabilistic games, PSPACE, proof systems, approximation algorithms}
}

@article{10.1137/S0097539793256053,
author = {Purdom, Paul Walton and Haven, G. Neil},
title = {Probe Order Backtracking},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256053},
doi = {10.1137/S0097539793256053},
abstract = {The algorithm for constraint-satisfaction problems, Probe Order Backtracking, has an average running time much faster than any previously analyzed algorithm under conditions where solutions are common. The algorithm uses a probing assignment (a preselected test assignment to unset variables) to help guide the search for a solution. If the problem is not satisfied when the unset variables are temporarily set to the probing assignment, the algorithm selects one of the relations which is not satisfied by the probing assignment and selects an unset variable which affects the value of that relation. It then does a backtracking (splitting) step, where it generates subproblems by setting the selected variable each possible way. Each subproblem is simplified and then solved recursively. For random problems with $v$ variables, $t$ clauses, and probability $p$ that a literal appears in a clause, the average time for Probe Order Backtracking is no more than $v^n$ when $pgeq(ln t)/v$ plus lower-order terms.  The best previous result was $pgeqsqrt{(ln t)/v}$. When the algorithm is combined with an algorithm of Franco that makes selective use of resolution, the average time for solving random problems is no more than $v^n$ for all values of $p$ when $tleq O(n^{1/3}(v/ln v)^{2/3})$.  The best previous result was $tleq O(n^{1/3}(v/ln v)^{1/6})$. Probe Order Backtracking also runs in polynomial average time when $pleq 1/v$, compared with the best previous result of $pleq 1/(2v)$. With Probe Order Backtracking, the range of $p$ that leads to more than polynomial time is much smaller than that for previously analyzed algorithms.},
journal = {SIAM J. Comput.},
month = apr,
pages = {456–483},
numpages = {28},
keywords = {satisfiability, searching, average time, backtracking, NP-complete, combinatorial search}
}

@article{10.1137/S0097539793255801,
author = {Steinberg, A.},
title = {A Strip-Packing Algorithm with Absolute Performance Bound 2},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255801},
doi = {10.1137/S0097539793255801},
abstract = {This paper proposes a new approximation algorithm $M$ for packing rectangles into a strip with unit width and unbounded height so as to minimize the total height of the packing. It is shown that for any list $L$ of rectangles, $M(L) leq 2cdot mbox{OPT}(L)$, where $M(L)$ is the strip height actually used by the algorithm $M$ when applied to $L$ and OPT$(L)$ is the minimum possible height within which the rectangles in $L$ can be packed.},
journal = {SIAM J. Comput.},
month = apr,
pages = {401–409},
numpages = {9},
keywords = {two-dimensional bin packing, packing rectangles, strip packing, absolute performance bound}
}

@article{10.1137/S0097539793253565,
author = {Ripphausen-Lipa, Heike and Wagner, Dorothea and Weihe, Karsten},
title = {The Vertex-Disjoint Menger Problem in Planar Graphs},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793253565},
doi = {10.1137/S0097539793253565},
abstract = {We consider the problem of finding a maximum collection of vertex-disjoint paths in undirected, planar graphs from a vertex $s$ to a vertex $t$. This problem is usually solved using flow techniques, which lead to ${cal O}(nk)$ and ${cal O}(nsqrt{n})$ running times, respectively, where $n$ is the number of vertices and $k$ the maximum number of vertex-disjoint $(s,t)$-paths.  The best previously known algorithm is based on a divide-and-conquer approach and has running time ${cal O}(nlog n)$. The approach presented here is completely different from these methods and yields a linear-time algorithm.},
journal = {SIAM J. Comput.},
month = apr,
pages = {331–349},
numpages = {19},
keywords = {graph algorithms, disjoint paths, planar graphs}
}

@article{10.1137/S0097539793250767,
author = {Panconesi, Alessandro and Srinivasan, Aravind},
title = {Randomized Distributed Edge Coloring via an Extension of the Chernoff--Hoeffding Bounds},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250767},
doi = {10.1137/S0097539793250767},
abstract = {Certain types of routing, scheduling, and resource-allocation problems in a distributed setting can be modeled as edge-coloring problems. We present fast and simple randomized algorithms for edge coloring a graph in the synchronous distributed point-to-point model of computation. Our algorithms compute an edge coloring of a graph $G$ with $n$ nodes and maximum degree $Delta$ with at most $1.6 Delta + O(log^{1+ delta} n)$ colors with high probability (arbitrarily close to 1) for any fixed $delta &gt; 0$; they run in polylogarithmic time. The upper  bound on the number of colors improves upon the $(2 Delta - 1)$-coloring achievable by a simple reduction to vertex coloring.To analyze the performance of our algorithms, we introduce new techniques for proving upper bounds on the tail probabilities of certain random variables. The Chernoff--Hoeffding bounds are fundamental tools that are used very frequently in estimating tail probabilities. However, they assume stochastic independence among certain random variables, which may not always hold. Our results extend the Chernoff--Hoeffding bounds to certain types of random variables which are not stochastically independent. We believe that these results are of independent interest and merit further study.},
journal = {SIAM J. Comput.},
month = apr,
pages = {350–368},
numpages = {19},
keywords = {stochastic dependence, Chernoff--Hoeffding bounds, parallel algorithms, $lambda$-correlation, large deviations, distributed algorithms, correlation inequalities, probabilistic algorithms, edge coloring}
}

@article{10.1137/S009753979324557X,
author = {Pedersen, Torben Pryds and Pfitzmann, Birgit},
title = {Fail-Stop Signatures},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979324557X},
doi = {10.1137/S009753979324557X},
abstract = {Fail-stop signatures can briefly be characterized as digital signatures that allow the signer to prove that a given forged signature is indeed a forgery. After such a proof has been published, the system can be stopped. This type of security is strictly stronger than that achievable with ordinary digital signatures as introduced by Diffie and Hellman in 1976 and formally defined by Goldwasser, Micali, and Rivest in 1988, which was widely regarded as the strongest possible definition.This paper formally defines fail-stop signatures and shows their relation to ordinary digital signatures. A general construction and actual schemes derived from it follow. They are efficient enough to be used in practice. Next, we prove lower bounds on the efficiency of any fail-stop signature scheme. In particular, we show that the number of secret random bits needed by the signer, the only parameter where the complexity of all our constructions deviates from ordinary digital signatures by more than a small constant factor, cannot be reduced significantly.},
journal = {SIAM J. Comput.},
month = apr,
pages = {291–330},
numpages = {40},
keywords = {fail-stop, authentication, information-theoretic security, computational security, randomization, cryptography, digital signatures, discrete logarithm, factorization}
}

@article{10.1137/S0097539792240583,
author = {Verma, Rakesh M.},
title = {General Techniques for Analyzing Recursive Algorithms with Applications},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240583},
doi = {10.1137/S0097539792240583},
abstract = {The complexity of divide-and-conquer algorithms is often described by recurrences of various forms. In this paper, we develop general techniques and master theorems for solving several kinds of recurrences, and we give several applications of our results. In particular, almost all of the earlier work on solving the recurrences considered here is subsumed by our work. In the process of solving such recurrences, we establish interesting connections between some elegant mathematics and analysis of recurrences. Using our results and improved bipartite matching algorithms, we also improve existing bounds in the literature for several problems, viz, associative-commutative (AC) matching of linear terms, associative matching of linear terms, rooted subtree isomorphism, and rooted subgraph homeomorphism for trees.},
journal = {SIAM J. Comput.},
month = apr,
pages = {568–581},
numpages = {14},
keywords = {subtree isomorphism, problem complexity, recurrences, graph algorithms, divide-and-conquer, analysis of algorithms, associative-commutative (AC) matching}
}

@article{10.1137/S0097539792226825,
author = {Frederickson, Greg N.},
title = {Ambivalent Data Structures for Dynamic 2-Edge-Connectivity and <i>k</i> Smallest Spanning Trees},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792226825},
doi = {10.1137/S0097539792226825},
abstract = {Ambivalent data structures are presented for several problems on undirected graphs. These data structures are used in finding the $k$ smallest spanning trees of a weighted undirected graph in $O(m log beta (m,n) + min { k^{3/2}, km^{1/2} } )$ time, where $m$ is the number of edges and $n$ the number of vertices in the graph. The techniques are extended to find the $k$ smallest spanning trees in an embedded planar graph in $O(n + k (log n)^3 )$ time. Ambivalent data structures are also used to  dynamically maintain 2-edge-connectivity information. Edges and vertices can be inserted or deleted in $O(m^{1/2})$ time, and a query as to whether two vertices are in the same 2-edge-connected component can be answered in $O(log n)$ time, where $m$ and $n$ are understood to be the current number of edges and vertices, respectively.},
journal = {SIAM J. Comput.},
month = apr,
pages = {484–538},
numpages = {55},
keywords = {embedded planar graph, analysis of algorithms, data structures, k smallest spanning trees, 2-edge-connectivity, topology tree, on-line updating, minimum spanning tree, fully persistent data structures}
}

@article{10.1137/S0097539790192647,
author = {Dolev, Danny and Shavit, Nir},
title = {Bounded Concurrent Time-Stamping},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790192647},
doi = {10.1137/S0097539790192647},
abstract = {We introduce concurrent time-stamping, a paradigm that allows processes to temporally order concurrent events in an asynchronous shared-memory system.  Concurrent time-stamp systems are powerful tools for concurrency control, serving as the basis for solutions to coordination problems such as mutual exclusion, $ell$-exclusion, randomized consensus, and multiwriter multireader atomic registers.  Unfortunately, all previously known methods for implementing concurrent time-stamp systems have been theoretically unsatisfying since they require unbounded-size time-stamps---in other words, unbounded-size memory.This work presents the first bounded implementation of a concurrent time-stamp system, providing a modular unbounded-to-bounded transformation of the simple unbounded solutions to problems such as those mentioned above.  It allows solutions to two formerly open problems, the bounded-probabilistic-consensus problem of Abrahamson and the fifo-$ell$-exclusion problem of Fischer, Lynch, Burns and Borodin, and a more efficient construction of multireader multiwriter atomic registers.},
journal = {SIAM J. Comput.},
month = apr,
pages = {418–455},
numpages = {38},
keywords = {distributed computing, concurrency, serialization, time-stamping, atomic registers, parallel computing}
}

@article{10.1137/S0097539790186704,
author = {Sebo, Andr\'{a}s},
title = {Potentials in Undirected Graphs and Planar Multiflows},
year = {1997},
issue_date = {April 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790186704},
doi = {10.1137/S0097539790186704},
abstract = {The duality relation between shortest paths and potentials in directed graphs and the significance of both of these in the theory of network flows is well known. In this paper, we work out the analogous undirected notions, which neither are contained in nor contain their directed counterpart. They  are more related to matching theory than to network flows: the corresponding min-path-max-potential theorem can be considered a weighted generalization of the Gallai--Edmonds structure theorem for matchings.In our earlier work [J. Combin. Theory Ser. B, 49 (1990), pp. 10--39], the corresponding theorems are proved in the special case of $pm 1$ bipartite weightings, and this special case already contains the main points of the general proof. The goal of the present paper is to extrapolate from this $pm 1$-weighted bipartite special case the arbitrarily weighted general min-path-max-potential theorem and to show some algorithmic consequences related to planar multiflows, the Chinese postman problem, the weighted and unweighted matching structure, etc. In order to make this paper self-contained, we also include a compact, revised variant of earlier proofs, adapted to the present context. In addition to good characterization theorems and polynomial algorithms, efficient (logarithmic polynomial) parallel algorithms follow for some of these problems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {582–603},
numpages = {22},
keywords = {T-joins, matching, structure, T-cuts, parallel algorithm, Chinese postman, multicommodity flows}
}

@article{10.1137/S0097539794275914,
author = {Alonso, Laurent and Reingold, Edward M. and Schott, Ren\'{e}},
title = {The Average-Case Complexity of Determining the Majority},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794275914},
doi = {10.1137/S0097539794275914},
abstract = {Given a set of $n$ elements each of which is either red or blue, it is known that in the worst case $n-nu(n)$ pairwise equal/not equal color comparisons are necessary and sufficient to determine the majority color, where $nu(n)$ is the number of 1-bits in the binary representation of $n$.  We prove that $frac{2n}{3} - sqrtfrac{8n}{9pi} + O(log n)$ such comparisons are necessary and sufficient in the average case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–14},
numpages = {14},
keywords = {algorithm analysis, lower bounds, average case, decision trees}
}

@article{10.1137/S0097539794273083,
author = {Karger, David R. and Motwani, Rajeev},
title = {An $\NC$ Algorithm for Minimum Cuts},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794273083},
doi = {10.1137/S0097539794273083},
abstract = {We show that the minimum-cut problem for weighted undirected graphs can be solved in $NC$ using three separate and independently interesting results.  The first is an $(m^2/n)$-processor $NC$ algorithm for finding a $(2+epsilon)$-approximation to the minimum cut.  The second is a randomized reduction from the minimum-cut problem to the problem of obtaining a $(2+epsilon)$-approximation to the minimum cut.  This reduction involves a natural combinatorial  set-isolation problem that can be solved easily in $RNC$.  The third result is a derandomization of this $RNC$ solution that requires a combination of two widely used tools: pairwise independence and random walks on expanders.  We believe that the set-isolation approach will prove useful in other derandomization problems.The techniques extend to two related problems: we describe $NC$ algorithms finding minimum $k$-way cuts for any constant $k$ and finding all cuts of value within any constant factor of the minimum. Another application of these techniques yields an $NC$ algorithm for finding a {em sparse $k$-connectivity certificate} for all polynomially bounded values of $k$.  Previously, an $NC$ construction was only known for polylogarithmic values of $k$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {255–272},
numpages = {18},
keywords = {edge connectivity, derandomization, parallel algorithms, connectivity certificate, minimum cut, randomized algorithms, multiway cut}
}

@article{10.1137/S0097539794270340,
author = {Cucker, Felipe and Grigoriev, Dima},
title = {On the Power of Real Turing Machines over Binary Inputs},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794270340},
doi = {10.1137/S0097539794270340},
abstract = {In this paper, we study the computational power of real Turing machines over binary inputs. Our main result is that the class of binary sets that can be decided by real Turing machines in parallel polynomial time is exactly the class PSPACE/poly.},
journal = {SIAM J. Comput.},
month = feb,
pages = {243–254},
numpages = {12},
keywords = {complexity classes, real-number machines and computations}
}

@article{10.1137/S0097539794266481,
author = {Chang, Richard and Gasarch, William I. and Lund, Carsten},
title = {On Bounded Queries and Approximation},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794266481},
doi = {10.1137/S0097539794266481},
abstract = {This paper investigates the computational complexity of approximating  several NP-optimization problems using the number of queries to an  NP oracle as a complexity measure.  The results show a tradeoff  between the closeness of the approximation and the number of queries  required.  For an approximation factor $k(n)$, $log log_{k(n)} n$  queries to an NP oracle can be used to approximate the maximum  clique size of a graph within a factor of $k(n)$.   However, this approximation cannot be achieved using fewer than  $log log_{k(n)} n - c$ queries to any oracle unless  $Pe = NP$, where $c$ is a constant that does not depend on $k$.   These results hold for approximation factors $k(n) geq 2$ that  belong to a class of functions which includes any integer constant  function, $log n$, $log^{a} n$, and $n^{1/a}$.  Similar results  are obtained for Graph Coloring, Set Cover, and other NP-optimization problems.},
journal = {SIAM J. Comput.},
month = feb,
pages = {188–209},
numpages = {22},
keywords = {maximum clique, bounded queries, approximation algorithm, set cover, NP-completeness, chromatic number}
}

@article{10.1137/S0097539794265402,
author = {Mak, Louis},
title = {Parallelism Always Helps},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794265402},
doi = {10.1137/S0097539794265402},
abstract = {It is shown that every unit-cost random-access machine (RAM) that runs in time $T$ can be simulated by a concurrent-read exclusive-write parallel random-access machine (CREW PRAM)  in time $O(rt{T} log T)$. The proof is constructive;  thus it gives a mechanical way to translate any sequential algorithm designed to run on a unit-cost RAM into a parallel algorithm that runs on a CREW PRAM and obtain a nearly quadratic speedup.   One implication is that there does not exist any recursive function that is "inherently not parallelizable."},
journal = {SIAM J. Comput.},
month = feb,
pages = {153–172},
numpages = {20},
keywords = {computational complexity, simulation, parallel random-access machine, speedup, random-access machine, time complexity}
}

@article{10.1137/S0097539794262422,
author = {Farach, Martin and Thorup, Mikkel},
title = {Sparse Dynamic Programming for Evolutionary-Tree Comparison},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794262422},
doi = {10.1137/S0097539794262422},
abstract = {Constructing evolutionary trees for species sets is a fundamental problem in biology. Unfortunately, there is no single agreed upon method for this task, and many methods are in use. Current practice dictates that trees be constructed using different methods and that the resulting trees should be compared for consensus. It has become necessary to automate this process as the number of species under consideration has grown. We study one formalization of the problem: the  maximum agreement-subtree  $($MAST$)$  problem . The $MAST$ problem is as follows: given a set $A$ and two rooted trees $cT_0$ and $cT_1$ leaf-labeled by the elements of $A$, find a maximum-cardinality subset $B$ of $A$ such that the topological restrictions of $cT_0$ and $cT_1$ to $B$ are isomorphic. In this paper, we will show that this problem reduces to unary weighted bipartite matching ($UWBM$) with an $O(n^{1+o(1)})$ additive overhead. We also show that $UWBM$ reduces linearly to $MAST$. Thus our algorithm is optimal unless $UWBM$ can be solved in near linear time. The overall running time of our algorithm is $O(n^{1.5} log n)$, improving on the previous best algorithm, which runs in $O(n^2)$. We also derive an $O(n c^{sqrt{log n}})$-time algorithm for the case of bounded degrees, whereas the previously best algorithm runs in $O(n^2),$ as in the unbounded case.},
journal = {SIAM J. Comput.},
month = feb,
pages = {210–230},
numpages = {21},
keywords = {computational biology, evolutionary trees, sparse dynamic programming}
}

@article{10.1137/S0097539793269089,
author = {Boros, Endre and Hammer, Peter L. and Ibaraki, Toshihide and Kawakami, Kazuhiko},
title = {Polynomial-Time Recognition of 2-Monotonic Positive Boolean Functions Given by an Oracle},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793269089},
doi = {10.1137/S0097539793269089},
abstract = {We consider the problem of identifying an unknown Boolean function $f$ by asking an oracle the functional values $f(a)$ for a selected set of test vectors $a in {0,1}^{n}$. Furthermore, we assume that $f$ is a positive (or monotone) function of $n$ variables.  It is not yet  known  whether or not the whole task of generating test vectors and checking if the identification is completed can be carried out in polynomial time in $n$ and $m$, where $m=|min T(f)| + |max F(f)|$ and $min T(f)$ (respectively, $max F(f))$ denotes the set of minimal true (respectively, maximal false) vectors of $f$.  To partially answer this question, we propose here two polynomial-time algorithms that, given an unknown positive function $f$ of $n$ variables, decide whether or not $f$ is 2-monotonic and, if $f$ is 2-monotonic, output both sets $min T(f)$ and $max F(f)$.  The first algorithm uses $O(nm^{2} + n^{2}m)$ time and $O(nm)$ queries, while the second one uses $O(n^{3}m)$ time and $O(n^{3}m)$ queries.},
journal = {SIAM J. Comput.},
month = feb,
pages = {93–109},
numpages = {17},
keywords = {2-monotonic Boolean function, polynomial-time identification, oracle}
}

@article{10.1137/S0097539793253589,
author = {Kao, Ming-Yang},
title = {Total Protection of Analytic-Invariant Information   in Cross-Tabulated Tables},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793253589},
doi = {10.1137/S0097539793253589},
abstract = {To protect sensitive information in a cross-tabulated table, it is a common practice to suppress some of the cells in the table. An  analytic invariant is a power series in terms of the suppressed cells that has a unique feasible value and a convergence radius equal to $+infty$. Intuitively, the information contained in an invariant is not protected even though the values of the suppressed cells are not disclosed. This paper gives an optimal linear-time algorithm for testing whether there exist nontrivial analytic invariants in terms of the suppressed cells in a given set of suppressed cells.  This paper also presents NP-completeness results and an almost linear-time algorithm for the problem of suppressing the minimum number of cells in addition to the sensitive ones so that the resulting table does not leak analytic-invariant information about a given set of suppressed cells.},
journal = {SIAM J. Comput.},
month = feb,
pages = {231–242},
numpages = {12},
keywords = {graph augmentation, mixed graph connectivity, analytic invariants, statistical tables, mathematical analysis, data security}
}

@article{10.1137/S0097539793249530,
author = {Beaudry, Martin and McKenzie, Pierre and P\'{e}ladeau, Pierre and Th\'{e}rien, Denis},
title = {Finite Monoids: From Word to Circuit Evaluation},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793249530},
doi = {10.1137/S0097539793249530},
abstract = {The problem of evaluating a circuit whose wires carry values from a finite monoid $M$ and whose gates perform the monoid operation provides a meaningful generalization to the well-studied problem of evaluating a word over $M$. Evaluating words over monoids is closely tied to the fine structure of the complexity class $NC^1$, and in this paper analogous ties between evaluating circuits over monoids and the structure of the complexity class $P$ are exhibited. It is shown that circuit evaluation in the case of any nonsolvable monoid is $P$ complete, while circuits over solvable monoids can be evaluated in $DET subseteq NC^2$. Then the case of aperiodic monoids is completely elucidated: their circuit evaluation problems are either in $AC^0$ or $L$- or $NL$-complete, depending on the precise algebraic properties of the monoids. Finally, it is shown that the evaluation of circuits over the cyclic group ${Bbb Z}_q$ for fixed $q geq 2$ is complete for the logspace counting class $co$-$MOD_qL$, that the problem for $p$-groups ($p$ a prime) is complete for $MOD_pL$, and that the more general case of nilpotent groups of exponent $q$ belongs to the Boolean closure of $MOD_qL$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {138–152},
numpages = {15},
keywords = {automata and formal languages, complexity theory, monoids}
}

@article{10.1137/S0097539793244198,
author = {Ge, Zhengyu and Hakimi, S. Louis},
title = {Disjoint Rooted Spanning Trees with Small Depths in DeBruijn and Kautz Graphs},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793244198},
doi = {10.1137/S0097539793244198},
abstract = {The problem of broadcasting long messages on store-and-forward communication networks, where a processor (node) can send and receive messages simultaneously to and from all its neighbors, was studied by Bermond and Fraigniaud. In such networks, the delays encountered by a message from a node $v$ to all other nodes over a broadcast spanning tree is directly proportional to the length of the paths in the tree over which the message is sent. Furthermore, the speed of the broadcast can be improved by the segmentation of the message at $v$ into equal-length segments and then the broadcast of these segments over arc-disjoint broadcast spanning trees simultaneously. These observations lead Bermond and Fraigniaud to look for the maximum number of arc-disjoint spanning trees in a deBruijn network rooted at an arbitrary node with small depths. This paper improves and extends the results of the above authors.},
journal = {SIAM J. Comput.},
month = feb,
pages = {79–92},
numpages = {14},
keywords = {communication networks, broadcasting, arc-disjoint spanning trees, Kautz networks, fault-tolerant networks, deBruijn networks, interconnection architectures}
}

@article{10.1137/S0097539792240467,
author = {Han, Yenjo and Hemaspaandra, Lane A. and Thierauf, Thomas},
title = {Threshold Computation and Cryptographic Security},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240467},
doi = {10.1137/S0097539792240467},
abstract = {Threshold machines are Turing machines whose acceptance is determined by what portion of the machine's computation paths are accepting paths. Probabilistic machines are Turing machines whose acceptance is determined by the probability weight of the machine's accepting computation paths. In 1975, Simon proved that for unbounded-error polynomial-time machines these two notions yield the same class, PP@. Perhaps because Simon's result seemed to collapse the threshold and probabilistic modes of computation, the relationship between threshold and probabilistic computing for the case of bounded error has remained unexplored. In this paper, we compare the bounded-error probabilistic class BPP with the analogous threshold class, $bpppath$, and, more generally, we study the structural properties of $bpppath$. We prove that $rm BPP_{path}$ contains both $np^{bpp}$ and $p^{rm NP[log]}$ and that $rm BPP_{path}$ is contained in $p^{{rm Sigma}_2^p[log]}$, $rm BPP^{NP}$, and PP@. We conclude that, unless the polynomial hierarchy collapses, bounded-error threshold computation is strictly more powerful than bounded-error probabilistic computation.We also consider the natural notion of secure access to a database: an adversary who watches the queries should gain no information about the input other than perhaps its length. We show for both $bpp$ and $bpppath$ that if there is  any  database for which this formalization of security differs from the security given by oblivious database access, then $pneq pspace$@. It follows that if any set lacking small circuits can be securely accepted, then $pneqpspace$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {59–78},
numpages = {20},
keywords = {threshold computation, cryptography, complexity theory, probabilistic computation}
}

@article{10.1137/S009753979223633X,
author = {Dubiner, Moshe and Zwick, Uri},
title = {Amplification by Read-Once Formulas},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223633X},
doi = {10.1137/S009753979223633X},
abstract = {Moore and Shannon have shown that relays with arbitrarily high reliability can be built from relays with arbitrarily poor reliability. Valiant used similar methods to construct monotone read-once formulas of size $O(n^{alpha+2})$ (where $alpha=log_{sqrt{5}-1}2simeq 3.27$) that amplify $(psi-frac{1}{n},psi+frac{1}{n})$ (where $psi=(sqrt{5}-1)/2simeq0.62$) to $(2^{-n},1-2^{-n})$ and deduced as a consequence the existence of monotone formulas of the same size that compute the majority of $n$ bits. Boppana has shown that any monotone read-once formula that amplifies $(p-frac{1}{n},p+frac{1}{n})$ to $(frac{1}{4},frac{3}{4})$ (where $0 We extend Boppana's results in two ways. We first show that his two lower bounds hold for general read-once formulas, not necessarily monotone, that may even include exclusive-or gates. We are then able to join his two lower bounds together and show that any read-once, not necessarily monotone, formula that amplifies $(p-frac{1}{n},p+frac{1}{n})$ to $(2^{-n},1-2^{-n})$ has size $Omega(n^{alpha+2})$. This result does not follow from Boppana's arguments, and it shows that the amount of amplification achieved by Valiant is the maximal achievable using read-once formulas. In a companion paper we construct monotone read-once contact networks of size $O(n^{2.99})$ that amplify $(frac{1}{2}-frac{1}{n},frac{1}{2}+frac{1}{n})$ to $(frac{1}{4},frac{3}{4})$. This shows that Boppana's lower bound for the first amplification stage does not apply to contact networks, even if they are required to be both monotone and read-once.},
journal = {SIAM J. Comput.},
month = feb,
pages = {15–38},
numpages = {24},
keywords = {Boolean formula, amplification, circuit complexity}
}

@article{10.1137/S0097539792235074,
author = {Dolev, Shlomi and Israeli, Amos and Moran, Shlomo},
title = {Resource Bounds for Self-Stabilizing Message-Driven Protocols},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235074},
doi = {10.1137/S0097539792235074},
abstract = {Self-stabilizing message-driven protocols are defined and discussed.      The class weak exclusion that contains many natural tasks      such as $ell$-exclusion and token passing is defined,      and it is shown that in any execution of any self-stabilizing      protocol for a task in this class, the configuration size must grow      at least in a logarithmic rate. This last lower bound is valid even      if the system is supported by a time-out mechanism that prevents      communication deadlocks. Then we present three self-stabilizing      message-driven protocols for token passing. The rate of growth of      configuration size for all three protocols matches the aforementioned      lower bound. Our protocols are presented for two-processor systems      but can be easily adapted to rings of arbitrary size. Our results      have an interesting interpretation in terms of automata theory.},
journal = {SIAM J. Comput.},
month = feb,
pages = {273–290},
numpages = {18},
keywords = {self-stabilization, shared memory, token passing, message passing}
}

@article{10.1137/S0097539791218949,
author = {Liu, Zhen and Sanlaville, Eric},
title = {Stochastic Scheduling with Variable Profile and Precedence Constraints},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791218949},
doi = {10.1137/S0097539791218949},
abstract = {In this paper, we consider the stochastic profile scheduling problem of a partially ordered set of tasks on uniform processors. The set of available processors varies in time. The running times of the tasks are independent random variables with exponential distributions. We obtain a sufficient condition under which a list policy stochastically minimizes the makespan within the class of preemptive policies. This result allows us to obtain a simple optimal policy when the partial order is an interval order, an in-forest, or an out-forest.},
journal = {SIAM J. Comput.},
month = feb,
pages = {173–187},
numpages = {15},
keywords = {interval order, precedence constraint, out-forest, stochastic ordering., in-forest, makespan, uniform processors, profile scheduling, stochastic scheduling}
}

@article{10.1137/S0097539791194931,
author = {Blum, Avrim and Raghavan, Prabhakar and Schieber, Baruch},
title = {Navigating in Unfamiliar Geometric Terrain},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791194931},
doi = {10.1137/S0097539791194931},
abstract = {Consider a robot that has to travel from a start location $s$ to a target $t$ in an environment with opaque obstacles that lie in its way.  The robot always knows its current absolute position and that of the target.  It does not, however, know the positions and extents of the obstacles in advance; rather, it finds out about obstacles as it encounters them.  We compare the distance walked by the robot in going from $s$ to $t$ to the length of the shortest (obstacle-free) path between $s$ and $t$ in the scene.  We describe and analyze robot strategies that minimize this ratio for different kinds of scenes. In particular, we consider the cases of rectangular obstacles aligned with the axes, rectangular obstacles in more general orientations, and wider classes of convex bodies both in two and three dimensions.  For many of these situations, our algorithms are optimal up to constant factors.    We study scenes with nonconvex obstacles, which are related to the study of maze traversal. We also show scenes where randomized algorithms are provably better than deterministic algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {110–137},
numpages = {28},
keywords = {computational geometry, on-line algorithms, robot navigation}
}

@article{10.1137/S0097539789164078,
author = {Nivant, Maurice and Podelski, Andreas},
title = {Minimal Ascending and Descending Tree Automata},
year = {1997},
issue_date = {Feb. 1997},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {26},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789164078},
doi = {10.1137/S0097539789164078},
abstract = {We propose a generalization of the notion "deterministic" to "l-r-deterministic" for descending tree automata (also called root-to-frontier). The corresponding subclass of recognizable tree languages is characterized by a structural property that we name "homogeneous." Given a descending tree automaton recognizing a homogeneous tree language, it can be left-to-right (l-r) determinized and then minimized. The obtained minimal l-r-deterministic tree automaton is characterized algebraically. We exhibit a formal correspondence between the two evaluation modes on trees (ascending and descending) and the two on words (right-to-left and left-to-right). This is possible by embedding trees into the free monoid of pointed trees. We obtain a unified view of the theories of minimization of deterministic ascending and l-r-deterministic descending tree automata.},
journal = {SIAM J. Comput.},
month = feb,
pages = {39–58},
numpages = {20},
keywords = {tree automata, minimization, Nerode congruence}
}

@article{10.1137/S0097539794268789,
author = {Kummer, Martin},
title = {Kolmogorov Complexity and Instance Complexity  of Recursively Enumerable Sets},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268789},
doi = {10.1137/S0097539794268789},
abstract = {The way in which way Kolmogorov complexity  and instance complexity affect properties of   recursively enumerable (r.e.) sets is studied.   The well-known $2log n$ upper bound on the Kolmogorov   complexity of initial segments of r. e. sets is shown to be optimal,   and the Turing degrees of r. e. sets which attain this bound are characterized.  The main part of the paper is concerned with instance  complexity, introduced by Ko, Orponen, Sch\"{o}ning, and Watanabe in 1986, as a measure of the complexity of individual instances of a decision problem.  They conjectured that for every r. e. nonrecursive set, the instance  complexity is infinitely often at least as high as the Kolmogorov complexity.  The conjecture is refuted by constructing an r. e. nonrecursive set  with instance complexity logarithmic in the Kolmogorov complexity.  This bound is optimal up to an additive constant. In the other extreme,   the conjecture is established for many classes of complete sets, such as   weak-truth-table-complete (wtt-complete) and Q-complete sets. However,  there is a Turing-complete set for which it fails.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1123–1143},
numpages = {21},
keywords = {complete sets, instance complexity, recursively enumerable sets, Kolmogorov complexity}
}

@article{10.1137/S0097539794268388,
author = {Golin, Mordecai J. and Young, Neal},
title = {Prefix Codes: Equiprobable Words, Unequal Letter Costs},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268388},
doi = {10.1137/S0097539794268388},
abstract = {We consider the following variant of Huffman coding in which the costs  of the letters, rather than the probabilities of the words, are   nonuniform: ``Given an alphabet of $r$ letters {em of nonuniform  length}, find a minimum-average-length prefix-free set of $n$ codewords  over the alphabet''; equivalently, ``Find an optimal $r$-ary search  tree with $n$ leaves, where each leaf is accessed with equal  probability but the cost to descend from a parent to its $i$th child  depends on $i$.''  We show new structural properties of such codes,  leading to an $O(nlog^2 r)$-time algorithm for finding them.  This  new algorithm is simpler and faster than the best previously known  $O(nr, min{log n, r})$-time algorithm, due to Perl, Garey, and  Even [{em J. Assoc. Comput. Mach.}, 22 (1975), pp. 202--214].},
journal = {SIAM J. Comput.},
month = dec,
pages = {1281–1292},
numpages = {12},
keywords = {Huffman codes, trees, algorithms, prefix codes}
}

@article{10.1137/S0097539794266407,
author = {Zuckerman, David},
title = {On Unapproximable Versions of <i>NP</i>-Complete  Problems},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794266407},
doi = {10.1137/S0097539794266407},
abstract = {We prove that all of Karp's 21 original $NP$-complete problems have  a version that is hard to approximate. These versions are obtained  from the original problems by adding essentially the same simple  constraint. We further show that these problems are absurdly hard to  approximate. In fact, no polynomial-time algorithm can even approximate  $log^{(k)}$ of the magnitude of these problems to within any constant  factor, where $logk$ denotes the logarithm iterated $k$ times, unless  $NP$ is recognized by slightly superpolynomial randomized machines.  We use the same technique to improve the constant $epsilon$ such that  MAX CLIQUE is hard to approximate to within a factor of $n^epsilon$.  Finally, we show that it is even harder to approximate two counting   problems: counting the number of satisfying assignments to a monotone  2SAT formula and computing the permanent of $-1$, $0$, $1$ matrices.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1293–1304},
numpages = {12},
keywords = {unapproximable, NP-complete, counting problems, randomized reduction, 2SAT, clique, permanent}
}

@article{10.1137/S009753979326091X,
author = {Bergadano, Francesco and Varricchio, Stefano},
title = {Learning Behaviors of  Automata from  Multiplicity and  Equivalence Queries},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979326091X},
doi = {10.1137/S009753979326091X},
abstract = {We consider the problem of identifying the behavior of an  unknown automaton with multiplicity in the field $Ratviii$ of rational  numbers ($Ratviii$-automaton) from multiplicity and equivalence queries.  We provide an algorithm which is polynomial in the size of  the $Ratviii$-automaton and in the maximum length of the given counterexamples.  As a consequence, we have that $Ratviii$-automata are probably   approximately correctly learnable (PAC-learnable) in polynomial time when   multiplicity queries are allowed. A corollary of this result is that regular languages  are polynomially predictable using membership queries  with respect to the representation of unambiguous nondeterministic  automata. This is important since there are unambiguous automata such that  the equivalent deterministic automaton has an exponentially  larger number of states.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1268–1280},
numpages = {13},
keywords = {probabilistic automata, equivalence queries, exact ientification, learning from queries, multiplicity automata, multiplicity queries, learning from examples, membership queries, PAC-learning, unambiguous nondeterministic automata}
}

@article{10.1137/S0097539793260404,
author = {Apostolico, Alberto and Breslauer, Dany},
title = {An Optimal  O(Log Log <i>n</i>)-Time  Parallel Algorithm for Detecting All Squares in a String},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793260404},
doi = {10.1137/S0097539793260404},
abstract = {An optimal $O(loglog n)$-time concurrent-read concurrent-write  parallel algorithm for detecting all squares in a string is presented.   A tight lower bound shows that over general alphabets,  this is the fastest possible optimal algorithm.  When $p$ processors are available,  the bounds become $Theta(lceil{({nlog n})/ p}rceil +  loglog_{lceil 1+p/n rceil} 2p)$.   The algorithm uses an optimal parallel string-matching algorithm  together with periodicity properties to locate the squares within the  input string.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1318–1331},
numpages = {14},
keywords = {string matching, lower bounds, repititions, parallel algorithms, squares}
}

@article{10.1137/S0097539793254959,
author = {Fischer, Michael J. and Moran, Shlomo and Rudich, Steven and Taubenfeld, Gadi},
title = {The Wakeup Problem},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793254959},
doi = {10.1137/S0097539793254959},
abstract = {We study a new problem---the wakeup problem---that seems to be  fundamental in distributed computing. We present efficient solutions  to the problem and show how these solutions can be used to solve the  consensus problem, the leader-election problem, and other related  problems. The main question we try to answer is ``How much memory is  needed to solve the wakeup problem?'' We assume a model that captures  important properties of real systems that have been largely ignored  by previous work on cooperative problems.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1332–1357},
numpages = {26},
keywords = {shared memory, algorithms, fault tolerance, concurrency}
}

@article{10.1137/S0097539793252432,
author = {Allenberg-Navony, Nechama and Itai, Alon and Moran, Shlomo},
title = {Average and Randomized Complexity of Distributed  Problems},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252432},
doi = {10.1137/S0097539793252432},
abstract = {Yao   proved that in the decision-tree model,  the average complexity of the best deterministic algorithm is a lower bound on the complexity of randomized algorithms   that solve the same problem.  Here it is  shown that a similar result does not always  hold in the common model of distributed computation,  the model  in which all the processors run the   same program (which may depend on the processors' input).    We therefore construct a new technique  that  together with Yao's method  enables us to show that in many cases,  a similar relationship does hold in the distributed model.  This relationship enables us to carry over known lower bounds on the  complexity of deterministic computations to the   realm of randomized computations,  thus obtaining new results.    The new technique can also be used for obtaining results  concerning algorithms with bounded error.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1254–1267},
numpages = {14},
keywords = {message complexity, bit complexity, randomized algorithms, lower bounds, distributed computing, Yao's lemma, average complexity}
}

@article{10.1137/S0097539793251219,
author = {Bodlaender, Hans L.},
title = {A Linear-Time Algorithm for Finding Tree-Decompositions of Small Treewidth},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793251219},
doi = {10.1137/S0097539793251219},
abstract = {In this paper, we give for constant $k$  a linear-time algorithm that, given  a graph $G=(V,E)$, determines whether  the treewidth of $G$ is at most $k$ and,  if so, finds a tree-decomposition of  $G$ with treewidth at most $k$.  A consequence is that every minor-closed  class of graphs that does not contain  all planar graphs has a linear-time recognition algorithm.  Another consequence is that a  similar result holds when we look instead for  path-decompositions with  pathwidth at most some constant $k$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1305–1317},
numpages = {13},
keywords = {treewidth, graph algorithms, pathwidth, partial k-trees, graph minors}
}

@article{10.1137/S0097539793243338,
author = {Sellen, J\"{u}rgen},
title = {Lower Bounds for Geometrical and Physical  Problems},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793243338},
doi = {10.1137/S0097539793243338},
abstract = {Motion planning involving arbitrarily many degrees of freedom is known  to be PSPACE-hard. In this paper, we examine the complexity of   generalized motion-planning  problems for planar mechanisms consisting of independently movable objects.    Our constructions constitute  a general framework for reducing problems in information processing   to motion planning, leading to easy proofs of known PSPACE-hardness   results and to exponential lower bounds for geometrical problems   related to   motion planning. Particulalrly, we show that   the problem of deciding whether a given mechanism $A$ can   always avoid a collision with another mechanism $B$ is EXPSPACE-hard.    New lower bounds are also obtained for the problem of planning  under given physical side conditions. We consider  the case that certain motions require forces, e.g., to subdue  friction, and ask for motions  that stay under a given energy limit. Within our framework, we show  that such shortest-path problems are EXPTIME-hard if we use number  representations by mantissa and exponent,  and even undecidable if we allow that some   motions require no force or an infinite amount.  The proof consists of a simulation of Turing machines with   infinite tape and shows that the notion of  Turing computability can be interpreted in purely geometrical terms.  The geometrical model obtained is capable of expressing a variety of  physical-planning problems.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1231–1253},
numpages = {23},
keywords = {motion planning, collision-avoidability problem, geometrical problems, dynamic problems, lower bounds, kinematic problems}
}

@article{10.1137/S0097539792234858,
author = {Ajtai, Miklos and Megiddo, Nimrod},
title = {A Deterministic Poly(Log Log <i>N</i>)-Time  <i>N</i>-Processor Algorithm for Linear Programming in Fixed Dimension},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792234858},
doi = {10.1137/S0097539792234858},
abstract = {It is shown that for any fixed number of variables,   linear-programming problems with $n$ linear inequalities can be solved  deterministically by $n$ parallel processors in sublogarithmic time.  The parallel time bound (counting only the arithmetic operations) is  $O((loglog n)^d)$, where $d$ is the number of variables. In the   one-dimensional case, this bound is optimal. If we take into account the  operations needed for processor allocation, the time bound is  $O((loglog n)^{d+c})$, where $c$ is an absolute constant.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1171–1195},
numpages = {25},
keywords = {parallel computation, expander graph, parallel random-access machine (PRAM), linear programming}
}

@article{10.1137/S0097539791278376,
author = {Cheriyan, Joseph and Hagerup, Torben and Mehlhorn, Kurt},
title = {An o(N^3)-Time Algorithm Maximun-Flow Algorithm},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791278376},
doi = {10.1137/S0097539791278376},
abstract = {We show that a maximum flow in a network with $n$ vertices can be computed deterministically in $O(n^3/log n)$ time on a uniform-cost RAM. For dense graphs, this improves the previous best bound of $O(n^3)$.  The bottleneck in our algorithm is a combinatorial problem on (unweighted) graphs. The number of operations executed on flow variables is $O(n^{8/3}(log n)^{4/3})$, in contrast with $Omega(nm)$ flow operations for all previous algorithms, where $m$ denotes the number of edges in the network. A randomized version of our algorithm executes $O(n^{3/2}m^{1/2}log n + n^2(log n)^2/log(2 + n(log n)^2/m))$ flow operations with high probability.  For the special case in which all capacities are integers bounded by $U$, we show that a maximum flow can be computed deterministically using $O(n^{3/2}m^{1/2} + n^2(log U)^{1/2} + log U)$ flow operations and $O(min{nm, n^3/log n} + n^2(log U)^{1/2} + log U)$ time. We finally argue that several of our results yield parallel algorithms with optimal speedup.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1144–1170},
numpages = {27},
keywords = {preflow-push algorithm, current-edge problem, graph algorithm, network flow, dynamic tree, scaling, maximum flow}
}

@article{10.1137/S0097539791224285,
author = {Dietzfelbinger, Martin and KutyLowski, MirosLaw and Reischuk, R\"{u}diger},
title = {Feasible Time-Optimal Algorithms for Boolean Functions  on Exclusive-Write Parallel Random-Access Machines},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791224285},
doi = {10.1137/S0097539791224285},
abstract = {It was shown some years ago that   the computation time for many important Boolean functions of $n$ arguments   on concurrent-read exclusive-write   parallel random-access machines (CREW PRAMs) of unlimited size   is at least $arphi (n) approx 0.72log_2 n$.   On the other hand, it is known that   every Boolean function of $n$ arguments can be computed in   $arphi (n)+1$ steps on a CREW PRAM with   $ncdot 2^{n-1}$ processors and memory cells.   In the case of the OR of $n$ bits, $n$ processors   and cells are sufficient.   In this paper, it is shown that for many important functions,   there are CREW PRAM algorithms that almost meet the lower bound   in that they take $arphi (n) + o(log n)$ steps   but use only a small number of processors and   memory cells (in most cases, $n$).   In addition, the cells only have to store   binary words of bounded length (in most cases, length 1).   We call such algorithms ``feasible.''   The functions concerned include the following:   the $PARITY$ function and, more generally,   all symmetric functions; a large class of Boolean formulas;   some functions over   non-Boolean domains ${0,ldots ,k-1}$ for small $k$, in particular,   parallel-prefix sums; addition of $n$-bit numbers; and   sorting $n/l$ binary numbers of length $l$. Further, it is shown that   Boolean circuits with fan-in 2, depth $d$, and size $s$   can be evaluated by CREW PRAMs with fewer than $s$   processors in $arphi(2^d)+o(d) approx 0.72d+ o(d)$ steps.   For the exclusive-read exclusive-write (EREW) PRAM model,   a feasible algorithm is described that  computes   $PARITY$ of $n$ bits in $ 0.86log_2 n$ steps.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1196–1230},
numpages = {35},
keywords = {parallel prefix, addition, parallel random-access machine, Boolean formulas, concurrent-read, parallel time complexity, exclusive-read, parity, sorting, symmetric functions, Boolean circuits, exclusive-write, Boolean functions}
}

@article{10.1137/S0097539794280736,
author = {Battista, Giuseppe Di and Tamassia, Roberto},
title = {On-Line Planarity Testing},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794280736},
doi = {10.1137/S0097539794280736},
abstract = {The on-line planarity-testing problem consists of performing the    following operations on a planar graph $G$:  (i) testing if a new    edge can be added to $G$ so that the resulting graph is itself planar;    (ii) adding vertices and edges such that planarity is preserved.  An    efficient technique for on-line planarity testing of a    graph is presented that    uses $O(n)$ space and supports tests and insertions of vertices and    edges in $O(log n)$ time, where $n$ is the current number of vertices    of $G$. The bounds for tests and vertex insertions are worst-case and    the bound for edge insertions is amortized.     We also present other applications of this technique to dynamic    algorithms for planar graphs.},
journal = {SIAM J. Comput.},
month = oct,
pages = {956–997},
numpages = {42},
keywords = {dynamic algorithm, on-line algorithm, planar graph}
}

@article{10.1137/S0097539794262161,
author = {Cypher, Robert and Konstantinidou, Smaragda},
title = {Bounds on the Efficiency of Message-Passing Protocols for Parallel Computers},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794262161},
doi = {10.1137/S0097539794262161},
abstract = {This paper considers the problem of creating message-passing  protocols for parallel computers.    It is assumed that the processors are connected by a network that   provides guaranteed delivery of every message,   provided that each message delivered by the network is removed by the  receiving processor unconditionally and in finite time.  Two models of  message passing are considered, namely, a selective model in which the  receiver specifies the source of the message and a nonselective model  in which the receiver accepts messages from all sources.  We consider  only space-efficient protocols in which each processor has storage for  a constant number of messages and message headers.  We present three main  results. First, we give a protocol for the selective  model that performs a constant amount of communication per send or  receive posted by the application.  Second, we prove that no such efficient  protocol exists for the nonselective model.  Third, we present a protocol  for the nonselective model that performs a logarithmic amount of communication  per send or receive posted by the application.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1082–1104},
numpages = {23},
keywords = {end-to-end protocols, communication protocols, parallel computing deadlock, message passing}
}

@article{10.1137/S0097539793256880,
author = {Pellegrini, Marco},
title = {On Point Location and Motion Planning Among  Simplices},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256880},
doi = {10.1137/S0097539793256880},
abstract = {Let $SS$ be a set of $n$ possibly intersecting    $(d-1)$-simplices in $d$-space  for $d geq 2$, and let ${cal A}(SS)$ be  the   arrangement of $SS$.  Let $K = |{cal A}(SS)|$ be the number of faces of any dimension in  the arrangement of $SS$.  A data structure  is described  that uses storage $O(n^{d-1+eps} +K)$ and is built {em   deterministically} in time  $O(n^{d-1+eps} +Klog n)$, where $eps &gt;0$ is an arbitrarily small   constant, such that   the face of ${cal A}(SS)$ containing a query point   is located in time $O(log^3 n)$.  If two query points are in the same cell of ${cal A}(SS)$,   a collision-free path connecting them is produced.  This result is obtained by exploiting powerful and so far overlooked   properties of sparse nets introduced by Chazelle   [{em Discrete Comput. Geom.}, 9 (1993), pp. 145--158].  If the $(d-1)$-simplices in  $SS$  have  pairwise-disjoint interiors   and $d geq 3$, improved bounds are obtained.    A data structure is described that uses $O(n^{d-1})$ storage   and is built deterministically in time $O(n^{d-1})$ such that     point-location queries are solved in time $O(log n)$.  Also, as a by-product, this method gives the first  optimal worst-case algorithm for  triangulating a nonsimple polyhedron in 3-space.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1061–1081},
numpages = {21},
keywords = {point location, arrangements of simplices, sparse nets, triangulations, motion planning}
}

@article{10.1137/S0097539793255722,
author = {Gil, Joseph and der, Friedhelm Meyerauf},
title = {The Tree Model for Hashing: Lower and Upper Bounds},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255722},
doi = {10.1137/S0097539793255722},
abstract = {We define a new simple and general model for hashing.  The basic model together with several variants  capture many natural (sequential and parallel)  hashing algorithms and represent common hashing practice.  Our main results exhibit tight tradeoffs between hash-table size  and the number of applications of a hash function   on a single key.},
journal = {SIAM J. Comput.},
month = oct,
pages = {936–955},
numpages = {20},
keywords = {parallel algorithms, randomization data structures}
}

@article{10.1137/S0097539793252870,
author = {Fujita, Satoshi and Yamashita, Masafumi},
title = {Optimal Group Gossiping in Hypercubes Under A Circuit-Switching Model},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252870},
doi = {10.1137/S0097539793252870},
abstract = {Let $U$ be a given set of nodes of a parallel computer system and assume  that each node $u$ in $U$ has a piece of information $t(u)$ called a token.  This paper discusses the problem of each $uin U$ broadcasting its token  $t(u)$ to all nodes in $U$.  We refer to this problem as   the group-gossiping  problem, which includes the (conventional) gossiping problem as a special  case.  In this paper, we consider the group-gossiping problem in $n$-cubes  under a circuit-switching model and propose an optimal group-gossiping  algorithm for $n$-cubes under the model.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1045–1060},
numpages = {16},
keywords = {optimal-time bound, n-cubes, gossiping, parallel algorithm, circuit-switching model}
}

@article{10.1137/S0097539792241941,
author = {Galil, Zvi and Park, Kunsoo},
title = {Alphabet-Independent Two-Dimensional Witness Computation},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792241941},
doi = {10.1137/S0097539792241941},
abstract = {We study two-dimensional periodicity, introduced by Amir and  Benson. We characterize periods of a two-dimensional array, namely, the vectors such that two copies of the array, one shifted by the vector over the other, overlap without a mismatch.  Using this characterization, we design an alphabet-independent  linear-time algorithm for two-dimensional witness computation, i.e., an $O(m^2)$-time algorithm that finds periods of an $mtimes m$  array as well as witnesses against nonperiods of the array among the vectors whose length is less than $m/4$. The constant in the $O$ notation does not depend on the alphabet size.  Combined with the alphabet-independent text-processing algorithm of Amir, Benson, and Farach [SIAM J. Comput., 23 (1994),  pp.~313--323], this leads to the first alphabet-independent linear-time algorithm for two-dimensional pattern matching.},
journal = {SIAM J. Comput.},
month = oct,
pages = {907–935},
numpages = {29},
keywords = {witness computation, pattern matching, two-dimensional periodicity}
}

@article{10.1137/S0097539792240881,
author = {Aspnes, James and Waarts, Orli},
title = {Randomized Consensus in Expected   O(n Log^ 2 n) Operations Per Processor},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240881},
doi = {10.1137/S0097539792240881},
abstract = {This paper presents a new randomized algorithm for achieving consensus among  asynchronous processors that communicate by reading and writing shared  registers.  The fastest previously known algorithm requires a processor to  perform an expected $O(n^2 log n)$ read and write operations in the  worst case.   In our algorithm, each processor executes at most an expected $O(n log^2 n)$  read and write operations, which is close to the trivial lower bound of  $Omega(n)$.    All previously known polynomial-time consensus algorithms  were structured around a shared-coin protocol   [J. Algorithms, 11 (1990), pp. 441--446]  in which each processor repeatedly adds random  $pm 1$ votes to a common pool. Consequently,  in all of these protocols, the worst-case expected bound on the number of read  and write operations done by a single processor  is asymptotically no better than  the bound on the total number of read and write operations done by all of the  processors together.  We succeed in breaking this tradition by  allowing the processors to cast votes of increasing weights.  This grants the adversary greater control since he can choose from up to  $n$ different weights (one for each processor)  when determining the weight of the next vote to be cast.  We prove that our shared-coin protocol is  nevertheless  correct using martingale arguments.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1024–1044},
numpages = {21},
keywords = {randomized algorithms, martingales, distributed algorithms, shared memory, asynchronous computation, consensus}
}

@article{10.1137/S0097539792233634,
author = {Shih, Wei-Kuan and Liu, Jane W. S.},
title = {On-Line Scheduling of Imprecise Computations to Minimize Error},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792233634},
doi = {10.1137/S0097539792233634},
abstract = {This paper describes three algorithms for scheduling  preemptive, imprecise tasks on a processor to minimize  the total error. Each imprecise task consists of a  mandatory task followed by an optional task. Some of the  tasks are on-line; they arrive after the processor begins  execution. The algorithms assume that when each new on-line  task arrives, its mandatory task and the portions of all  the mandatory tasks yet to be completed at the time can be  feasibly scheduled to complete by their deadlines. The  algorithms produce for such tasks feasible schedules whose  total errors are as small as possible. The three algorithms  are designed for three types of task systems: (1) when every  task is on-line and is ready upon its arrival, (2) when  every on-line task is ready upon arrival but there are also  off-line tasks with arbitrary ready times, and (3) when  on-line tasks have arbitrary ready times. Their running  times are $O(n log n)$, $O(n log n)$, and $O(n log^2 n)$,  respectively},
journal = {SIAM J. Comput.},
month = oct,
pages = {1105–1121},
numpages = {17},
keywords = {real-time systems, deterministic scheduling, scheduling to meet deadlines, on-line scheduling}
}

@article{10.1137/S0097539792190157,
author = {Kedem, Zvi M. and Landau, Gad M. and Palem, Krishna V.},
title = {Parallel Suffix--Prefix-Matching Algorithm and Applications},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792190157},
doi = {10.1137/S0097539792190157},
abstract = {Our main result in this paper is a parallel algorithm for   suffix--prefix- (s--p-) matching that has optimal speedup on a  concurrent-read/concurrent-write parallel random-access machine  (CRCW PRAM).  Given a string of length $m$, the algorithm  runs in time $O(log m)$ using $m/ log m$ processors.  This algorithm  is important because we utilize s--p matching as a fundamental  building block to solve several pattern- and string-matching problems,  such as the following:  {1. string matching;  2. multitext/multipattern string matching;  3. multidimensional pattern matching;  4. pattern-occurrence detection;  5. on-line string matching.}  In particular, our techniques and algorithms are the first to  preserve optimal speedup in the context of pattern matching in  higher dimensions and are the only known ones to do so for  dimensions $d &gt; 2$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {998–1023},
numpages = {26},
keywords = {amortized complexity, CRCW PRAMs, string matching, speedup, parallel algorithms, pattern-matching automaton, multidimensional pattern matching}
}

@article{10.1137/S0097539794268315,
author = {Hemaspaandra, Lane A. and Naik, Ashish V. and Ogihara, Mitsunori and Selman, Alan L.},
title = {Computing Solutions Uniquely Collapses the Polynomial Hierarchy},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794268315},
doi = {10.1137/S0097539794268315},
abstract = {Is there an NP function that, when given a satisfiable formula as   input, outputs one satisfying assignment uniquely?   That is, can a nondeterministic function cull just one satisfying   assignment from a possibly exponentially large collection of assignments?   We show that if there is such a nondeterministic function, then the   polynomial hierarchy collapses to    $zppnp$  (and thus,   in particular, to $npnp$).   As the existence of such a function is known to be equivalent to   the statement ``every NP function has an NP refinement with unique   outputs," our result provides the strongest evidence yet that   NP functions cannot be refined.      We prove our    result via a result of independent interest.     We say that a set $A$ is NPSV-selective (NPMV-selective) if there   is a 2-ary partial NP function with unique values (a 2-ary partial NP   function) that decides which of its inputs (if any) is   ``more likely'' to belong to $A$;     this is a nondeterministic analog of the recursion-theoretic notion of   the semi-recursive sets and the extant complexity-theoretic notion of   P-selectivity.  Our hierarchy collapse result follows by combining %%foo   the easy observation   that every set in NP is NPMV-selective with the following result:   If $A in np$ is NPSV-selective, then $A in (npcapconp)/poly$.   Relatedly, we prove that    if $A in np$ is NPSV-selective, then $A$ is Low$_2$.         We prove that the polynomial hierarchy collapses even further,   namely to NP, if all coNP sets are NPMV-selective.  This follows from   a more general result we prove: Every self-reducible NPMV-selective   set is in NP@.},
journal = {SIAM J. Comput.},
month = aug,
pages = {697–708},
numpages = {12},
keywords = {semi-decision algorithms, computational complexity, lowness, nonuniform complexity}
}

@article{10.1137/S0097539794267188,
author = {Rhee, WanSoo T. and Talagrand, Michel},
title = {Convergence in Distribution for Best Fit-Decreasing},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794267188},
doi = {10.1137/S0097539794267188},
abstract = {Consider independent random variables $X_1, dots,   X_n$ uniformly distributed over $[0,1]$, and denote by $B_n$ the number   of bins needed to pack items of these sizes using the best fit decreasing   algorithm.  We prove that the random variable $n^{-1/2}$ converges in   distribution to a nonnormal limit.  The method consists of showing that   the patterns created by the algorithm exhibit some kind of convergence.},
journal = {SIAM J. Comput.},
month = aug,
pages = {894–906},
numpages = {13},
keywords = {uniform distribution, convergence in distribution, best fit decreasing, bin packing}
}

@article{10.1137/S009753979326009X,
author = {Rajasekaran, Sanguthevar},
title = {Tree-Adjoining Language Parsing in o(<i>n</i>^6) Time},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979326009X},
doi = {10.1137/S009753979326009X},
abstract = {In this paper we present algorithms for parsing general tree-adjoining  languages (TALs). Tree-adjoining grammars (TAGs)  have been proposed as an elegant formalism for natural  languages.  It was an open question for the past ten years  as to whether TAL parsing can be done in time $o(n^6)$. We settle this question  affirmatively  by presenting an $O(n^3 M(n))$-time algorithm, where $M(k)$ is the  time needed for multiplying two Boolean matrices of size $ktimes k$ each.  Since $O(k^{2.376})$ is the current best-known value for $M(k)$, the time bound  of our algorithm is $O(n^{5.376})$. On an exclusive read exclusive write  parameter random-access machine (EREW PRAM) our algorithm runs in time  $O(nlog n)$ using $frac{n^2 M(n)}{log n}$ processors.  In comparison, the best-known  previous parallel algorithm had a run time of $O(n)$ using  $n^5$ processors (on a systolic array machine).    We also present algorithms for parsing context-free languages (CFLs) and  TALs  whose worst case run times are $O(n^3)$ and $O(n^6)$, respectively,  but whose average run times are better.  Therefore, these algorithms may be of practical interest.},
journal = {SIAM J. Comput.},
month = aug,
pages = {862–873},
numpages = {12},
keywords = {context-free grammars., natural language processing, parallel algorithms, parsing, tree-adjoining languages}
}

@article{10.1137/S0097539793259458,
author = {Kapoor, Sanjiv and Smid, Michiel},
title = {New Techniques for Exact and Approximate Dynamic Closest-Point},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793259458},
doi = {10.1137/S0097539793259458},
abstract = {Let $S$ be a set of $n$ points in $IR^{D}$. It is shown that   a range tree can be used to find an $L_{infty}$-nearest   neighbor in $S$ of any query point, in   $O((log n)^{D-1} loglog n)$ time. This data structure has   size $O(n (log n)^{D-1})$ and an amortized update time of   $O((log n)^{D-1} loglog n)$. This result is used to  solve the $(1+epsilon)$-approximate $L_{2}$-nearest   neighbor problem within the same bounds (up to a constant   factor that depends on $epsilon$ and $D$). In this o  problem, for any query point $p$, a point $q in S$ is   computed such that the euclidean distance between $p$   and $q$ is at most   $(1+epsilon)$ times the euclidean distance between $p$ and   its true nearest neighbor.  This is the first dynamic data structure for this problem   having close to linear size and polylogarithmic query and   update times.    New dynamic data structures are given that maintain a closest   pair of $S$. For $D geq 3$, a structure of size $O(n)$ is   presented with amortized update time   $O((log n)^{D-1} loglog n)$. The constant factor in this   space (resp. time bound) is of the form $O(D)^D$   (resp. $2^{O(D^2)}$). For $D=2$ and any non-negative   integer constant $k$, structures of size    $O(n log n / (loglog n)^{k})$ (resp. $O(n)$) are presented   having an amortized update time of   $O(log n loglog n)$ (resp.   $O((log n)^{2} / (loglog n)^{k})$).  Previously, no deterministic linear size data structure having   polylogarithmic update time was known for this problem.},
journal = {SIAM J. Comput.},
month = aug,
pages = {775–798},
numpages = {24},
keywords = {dynamic data structures, approximation, proximity, point location}
}

@article{10.1137/S0097539793252444,
author = {Liskiewicz, Maciej and Reischuk, R\"{u}diger},
title = {The Sublogarithmic Alternating Space World},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252444},
doi = {10.1137/S0097539793252444},
abstract = {This paper tries to fully characterize the properties and relationships of space classes defined by Turing machines that use less than logarithmic space -- may they be deterministic, nondeterministic or alternating (DTM, NTM, or ATM). We provide several examples of specific languages and show that such machines are unable to accept these languages. The basic proof method is a nontrivial extension of the $1^n mapsto 1^{n+n!}$ technique to alternating TMs.  Let $llog$ denote the logarithmic function $log$ iterated twice, and $SSS{k}$, $PSS{k}$ be the complexity classes defined by $S$--space-bounded ATMs that alternate at most $k-1$ times and start in an existential, resp. universal state. Our first result shows that for each $k &gt; 1$ the sets begin{eqnarray*} SSl{k} &amp;setminus&amp; PSu{k} quad hbox{ and}  PSl{k} &amp;setminus&amp; SSu{k} end{eqnarray*} are both not empty. This implies that for each $S in Omega(llog ) cap o(log )$ the classes begin{eqnarray*} SSS{1} &amp;spna&amp; SSS{2} spna SSS{3} spna ldots  &amp;spna &amp; SSS{k} spna SSS{k+1} spna ldots end{eqnarray*} form an infinite hierarchy. Furthermore, this separation is extended to space classes defined by ATMs with a nonconstant alternation bound $A$ provided that the product $A * S$ grows sublogarithmically.  These lower bounds can also be used to show that basic closure properties do not hold for such classes. We obtain that for any $S in Omega(llog ) cap o(log )$ and all $k &gt; 1$ $Sigma_k Space (S)$ and $Pi_k Space (S)$ are not closed under complementation and concatenation. Moreover, $Sigma_k Space (S)$ is not closed under intersection, and $Pi_k Space (S)$ is not closed under union. KURZ{ It is an interesting open question whether for sublogarithmic bounds $S$ the property that $PSS{k}$ is the complement of $SSS{k}$ is fulfilled. This is a nontrivial problem since there is no obvious way how to detect infinite computation paths. Here, } KURZ{ we generalize Sipser's result on halting space-bound computations for sublogarithmic space bounded deterministic TMs cite{S80} to }  It is also shown that ATMs recognizing bounded languages can always be guaranteed to halt. For the class of $Z$--bounded languages with $Z le exp S$ we obtain the equality ( combox{-}SSS{k} gla PSS{k}  . ) KURZ{ We also consider the space requirement for the recognition of nonregular context-free languages. Alt, Geffert and Mehlhorn have recently shown a logarithmic lower bound for nondeterministic TMs cite{AGM92}. We improve this result obtaining the same lower bound for ATMs. Thus this last result shows that even alternations do not increase the power of sublogarithmic machines substantially. }  Finally, for sublogarithmic bounded ATMs we give a separation between the weak and strong space measure, and prove a logarithmic lower space bound for the recognition of nonregular context-free languages.},
journal = {SIAM J. Comput.},
month = aug,
pages = {828–861},
numpages = {34},
keywords = {complementation of languages, sublogarithmic complexity bounds, context-free languages, space complexity, alternating Turing machines, closure properties, bounded languages, halting computations, complexity hierachies}
}

@article{10.1137/S0097539793248329,
author = {Jimbo, S. and Maruoka, A.},
title = {A Method of Constructing Selection Networks with  O(Log n) Depth},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793248329},
doi = {10.1137/S0097539793248329},
abstract = {A classifier with $n$ inputs is a comparator network   that classifies a set of $n$ values into two classes   with the same number of values in such a way that   each value in one class is at least as large as all of those   in the other.   Based on the utilization of expanders,   Pippenger constructed classifiers with $n$ inputs,   whose size is asymptotic to $2nlog_{2}n$.   In the same spirit, we obtain a relatively simple method to construct   classifiers   of depth $O(log n)$.   In consequence, for arbitrary constant $C &gt; 3/log_2 3 = 1.8927cdots$,   we construct classifiers of depth $O(log n)$ and   of size at most $Cnlog_{2}n + O(n)$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {709–739},
numpages = {31},
keywords = {expander, classifier, selection network, comparator network}
}

@article{10.1137/S0097539792233828,
author = {H\r{a}stad, Johan and Leighton, Tom and Rogoff, Brian},
title = {Analysis of Backoff Protocols for Mulitiple AccessChannels},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792233828},
doi = {10.1137/S0097539792233828},
abstract = {In this paper, we analyze the stochastic behavior of backoff protocols for multiple access channels such as the Ethernet. In particular, we prove that binary exponential backoff is unstable if the arrival rate of new messages at each station is $lam/N$ for any $lam &gt;{1over 2}$ and the number of stations N, is sufficiently large. For small $N$ we prove that $lam geq lam_0+{1over 4N-2}$ implies instability where $lam_0approx .567$. More importantly, we also prove that any superlinear polynomial backoff protocol (e.g., quadratic backoff) is stable for any set of arrival rates that sum to less than one, and any number of stations. The results significantly extend the previous work in the area, and provide the first examples of acknowledgment based protocols known to be stable for a nonnegligible overall arrival rate distributed over an arbitrarily large number of stations. The results also disprove a popular assumption that exponential backoff is the best choice among acknowledgment based protocols for systems with large overall arrival rates. Finally, we prove that any linear or sublinear backoff protocol is unstable if the arrival rate at each station is $lambda over N$ for any fixed $lambda$ and sufficiently large $N$.}},
journal = {SIAM J. Comput.},
month = aug,
pages = {740–774},
numpages = {35},
keywords = {Ethernet, backoff protocols, Markov chains, stochastic stability}
}

@article{10.1137/S0097539789166880,
author = {Klein, Philip N.},
title = {Efficient Parallel Algorithms for Chordal Graphs},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789166880},
doi = {10.1137/S0097539789166880},
abstract = {We give the first efficient parallel algorithms for recognizing  chordal graphs, finding a maximum clique and  a maximum independent  set in a chordal graph, finding an optimal coloring of a chordal  graph, finding a breadth-first search tree and a depth-first search  tree of a chordal graph, recognizing interval graphs, and testing  interval graphs for isomorphism.  The key to our results is an  efficient parallel algorithm for finding a perfect elimination  ordering.},
journal = {SIAM J. Comput.},
month = aug,
pages = {797–827},
numpages = {31},
keywords = {parallel algorithms, chordal graphs, perfect elimination ordering, interval graphs, PQ-tree}
}

@article{10.1137/0225039,
author = {Ramanan, Prakash},
title = {An Efficient Parallel Algorithm for the Matrix-Chain-Product Problem},
year = {1996},
issue_date = {Aug. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0225039},
doi = {10.1137/0225039},
journal = {SIAM J. Comput.},
month = aug,
pages = {874–893},
numpages = {20},
keywords = {PRAM model, dynamic programming, matrix-chain product, parallel algorithm, polygon triangulation, processor-time complexity}
}

@article{10.1137/S0097539794263191,
author = {Friedman, J. and Hershberger, J. and Snoeyink, J.},
title = {Efficiently  Planning Compliant Motion in ThePlane},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794263191},
doi = {10.1137/S0097539794263191},
abstract = {Any practical model of robotic motion must cope with the uncertainty and imprecision inherent in real robots.  One important model is compliant motion, in which a robot that encounters an obstacle obliquely may slide along the obstacle.  The authors start by investigating the geometry of compliant motion in the plane under perfect control and find a compact data structure encoding all paths to a goal.  When the authors introduce uncertainty in control and position sensing, the same data structure allows them to find efficiently a compliant motion that reaches the goal, if one exists, to compute the boundary of the nondirectional backprojection of the goal, and to compute multistep plans for sensorless robots.  This "preprocessing and query" approach has advantages of speed for online queries and flexibility for considering robots with different capabilities or initial positions in the same environment.},
journal = {SIAM J. Comput.},
month = jun,
pages = {562–599},
numpages = {38},
keywords = {computational geometry, path hull data structure, compliant motion}
}

@article{10.1137/S0097539794262677,
author = {Kannan, Sampath K. and Myers, Eugene W.},
title = {An Algorithm for Locating Nonoverlapping Regions of Maximum Alignment Score},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794262677},
doi = {10.1137/S0097539794262677},
abstract = {In this paper, we present an $O(N^2 log^2 ,N)$ algorithm for finding the two nonoverlapping substrings of a given string of length $N$ which have the highest-scoring alignment between them.  This significantly improves the previously best-known bound of  $O(N^3 )$ for the worst-case complexity of this problem.  One of the central ideas in the design of this algorithm is that of partitioning a matrix into pieces in such a way that all submatrices of interest for this problem can be put together as the union of very few of these pieces.  Other ideas include the use of candidate lists, an application of the ideas of Apostolico et al. [SIAM J. Comput., 19 (1990), pp. 968--988]  to our problem domain, and  divide-and-conquer techniques.},
journal = {SIAM J. Comput.},
month = jun,
pages = {648–662},
numpages = {15},
keywords = {efficient algorithms, sequence alignment, repeated regions}
}

@article{10.1137/S0097539794261428,
author = {Irani, Sandy and Rabani, Yuval},
title = {On the Value of Coordination in DistributedDecision Making},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794261428},
doi = {10.1137/S0097539794261428},
abstract = {We discuss settings where several "agents" combine efforts to solve problems. This is a well-known setting in distributed artificial intelligence. Our work addresses theoretical questions in this model which are motivated by the work of Deng and Papadimitriou [ Proc. 12th IFIPS Congress, Madrid, 1992; Proc. World Economic Congress, Moscow, 1992]. We consider optimization problems, in particular load balancing and virtual circuit routing, in which the input is divided among the agents. An underlying directed graph, whose nodes are the agents, defines the constraints on the information each agent may have about the portion of the input held by other agents. The questions we discuss are as follows: Given a  bound on the maximum out-degree in this graph, which is the best graph? What is the quality of the solution obtained as a function of the maximum out-degree?},
journal = {SIAM J. Comput.},
month = jun,
pages = {498–519},
numpages = {22},
keywords = {analysis of algorithms, competitive analysis, distributed computation, virtual circuit routing, load balancing}
}

@article{10.1137/S0097539793258143,
author = {Kaplan, Haim and Shamir, Ron},
title = {Pathwidth, Bandwidth, and Completion Problems to Proper Interval Graphs with Small Cliques},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793258143},
doi = {10.1137/S0097539793258143},
abstract = {We study two related problems motivated by molecular biology.  Given a graph $G$ and a constant $k$, does there exist a supergraph $G'$ of $G$ that is a unit interval graph and has clique size at most $k$__ __  Given a graph $G$ and a proper $k$-coloring $c$ of $G$, does there exist a supergraph $G'$ of $G$ that is properly colored by $c$ and is a unit interval graph__ __  We show that those problems are polynomial for fixed $k$. On the other hand, we prove that the first problem is equivalent to deciding if the bandwidth of $G$ is at most $k-1$. Hence, it is NP-hard and $W[t]$-hard for all $t$. We also show that the second problem is $W[1]$-hard. This implies that for fixed $k$, both of the problems are unlikely to have an $O(n^alpha)$ algorithm, where $alpha$ is a constant independent of $k$.  A central tool in our study is a new graph-theoretic parameter closely related to pathwidth. An unexpected useful consequence is the equivalence of this parameter to the bandwidth of the graph. },
journal = {SIAM J. Comput.},
month = jun,
pages = {540–561},
numpages = {22},
keywords = {pathwidth, bandwidth, parameterized complexity, interval graphs, design and analysis of algorithms}
}

@article{10.1137/S0097539793256879,
author = {Condon, Anne and Ladner, Richard and Lampe, Jordan and Sinha, Rakesh},
title = {Complexity of Sub-Bus Mesh Computations},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256879},
doi = {10.1137/S0097539793256879},
abstract = {The time complexity of several fundamental problems on the sub-bus mesh parallel computer with $p$ processors is investigated. The problems include  computing the PARITY and MAJORITY of $p$ bits, the SUM of $p$ numbers of length $O(log p)$, and the MINIMUM of $p$ numbers.  It is shown that in one dimension the time to compute any of these problems is $Theta(log p)$.  In two dimensions the time to compute any of  PARITY, MAJORITY, and SUM is $Theta(frac{log p}{loglog p})$. It was previously shown that the time to compute MINIMUM in two dimensions  is $Theta(loglog p)$ [R. Miller et al., IEEE Trans. Comput., 42 (1993), pp. 678--692; L. Valiant, SIAM J. Comput., 4 (1975), pp. 348--355]},
journal = {SIAM J. Comput.},
month = jun,
pages = {520–539},
numpages = {20},
keywords = {PRAM, time complexity, CRCW, sum, sub-bus mesh, reconfigurable mesh, parity, minimum, majority, complexity}
}

@article{10.1137/S0097539793255709,
author = {Kirousis, Lefteris M. and Thilikos, Dimitris M.},
title = {The Linkage of a Graph},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255709},
doi = {10.1137/S0097539793255709},
abstract = {The linkage of a graph is defined to be the maximum min-degree of any of its subgraphs. It is known that the linkage of a graph is equal to its width: for an arbitrary linear ordering of the vertices of the graph, consider the maximum, with respect to any vertex $v$, of the number of vertices connected with $v$ and preceding it in the ordering; the width of the graph is the minimum of these maxima over all possible linear orderings. Width has been used in artificial intelligence in the context of constraint satisfaction problems (CSPs). A more general notion is defined by considering not the number of vertices preceding and connected with $v$ but rather the least number of vertices preceding and connected with any cluster of at most $j$ consecutive vertices extending to the right up to $v$ ($j$ is a given integer). The graph parameter thus defined is called $j$-width. No efficient algorithm was known for computing the $j$-width. In this paper, we introduce a graph parameter depending on $j$ that refers to the subgraphs of the graph and generalizes the notion of linkage. We prove the min--max theorem that this graph parameter, which we call $j$-linkage, is equal to $j$-width, and we then give a polynomial-time algorithm for computing it (for constant $j$). We also find  tight  lower and upper bounds for the $j$-linkage (equivalently, the $j$-width) of graphs with given numbers of vertices and edges. It is interesting to note that a lower bound for the width of a graph had been found by Erdos; as we show, however, that bound is not tight. Moreover, we prove that our lower bound for width is also a  tight  lower bound for treewidth, pathwidth, and bandwidth, graph parameters that may be arbitrarily larger than width. Finally, we show that computing the $j$-linkage is a P-complete problem, whereas we prove that approximating it is a threshold problem: it is in NC for approximation factors $&lt; 1/{(2j)}$, and it is P-complete for approximation factors $&gt; 1/2$. },
journal = {SIAM J. Comput.},
month = jun,
pages = {626–647},
numpages = {22},
keywords = {extremal graph properties, P-complete problems, linkage of a graph, backtrack-free search, algorithms in NC, width parameters of a graph}
}

@article{10.1137/S0097539792236353,
author = {Irani, Sandy and Karlin, Anna R. and Phillips, Steven},
title = {Strongly Competitive Algorithms for Paging with Locality of Reference},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792236353},
doi = {10.1137/S0097539792236353},
abstract = {What is the best paging algorithm if one has partial information about the possible sequences of page requests__ __ We give a partial answer to this question by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference given by an arbitrary access graph.  We first consider optimal algorithms for undirected access graphs. Borodin et al. [  Proc. 23rd ACM Symposium on Theory of Computing , 1991, pp. 249--259] define an algorithm, called FAR, and prove that it is within a logarithmic factor of the optimal online algorithm. We prove that FAR is in fact strongly competitive, i.e., within a constant factor of the optimum. For directed access graphs, we present an algorithm that is strongly competitive on  structured program graphs ---graphs that model a subset of the request sequences of structured programs. },
journal = {SIAM J. Comput.},
month = jun,
pages = {477–497},
numpages = {21},
keywords = {analysis of algorithms, locality of reference, competitive analysis, online algorithms, paging}
}

@article{10.1137/S0097539791224212,
author = {Jim, Trevor and Meyer, Albert R.},
title = {Full Abstraction and the Context Lemma},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791224212},
doi = {10.1137/S0097539791224212},
abstract = {It is impossible to add a combinator to PCF to achieve full abstraction for models such as Berry's stable domains in a way analogous to the addition of the "parallel-or" combinator that achieves full abstraction for the familiar  complete partial order (cpo) model.  In particular, we define a general notion of rewriting system of the kind used for evaluating simply typed $lambda$-terms in Scott's PCF.  Any simply typed $lambda$-calculus with such a "PCF-like" rewriting semantics is shown necessarily to satisfy Milner's Context Lemma.  A simple argument demonstrates that any denotational semantics that is adequate for PCF, and in which certain simple Boolean functionals exist, cannot be fully abstract for any extension of PCF satisfying the Context Lemma.  An immediate corollary is that stable domains cannot be fully abstract for any extension of PCF definable by PCF-like rules.},
journal = {SIAM J. Comput.},
month = jun,
pages = {663–696},
numpages = {34},
keywords = {stable functions, full abstraction, standardization, PCF, Context Lemma}
}

@article{10.1137/S0097539791221499,
author = {Arora, Sanjeev and Leighton, F. T. and Maggs, Bruce M.},
title = {On-Line Algorithms for Path Selectionin a Nonblocking Network},
year = {1996},
issue_date = {June 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791221499},
doi = {10.1137/S0097539791221499},
abstract = {This paper presents the first optimal-time algorithms for path selection in an optimal-size nonblocking network.  In particular, we describe an $N$-input, $N$-output, nonblocking network with $O(N log N)$ bounded-degree nodes, and an algorithm that can satisfy any request for a connection or disconnection between an input and an output in $O(log N)$ bit steps, even if many requests are made at once.  Viewed in a telephone switching context, the algorithm can put through any set of calls among $N$ parties in $O(log N)$ bit steps, even if many calls are placed simultaneously.  Parties can hang up and call again whenever they like; every call is still put through $O(log N)$ bit steps after being placed.  Viewed in a distributed memory machine context, our algorithm allows any processor to access any idle block of memory within $O(log N)$ bit steps, no matter what other connections have been made previously or are being made simultaneously.},
journal = {SIAM J. Comput.},
month = jun,
pages = {600–625},
numpages = {26},
keywords = {routing algorithm, multi-Benes network, multibutterfly network, nonblocking network}
}

@article{10.1137/S0097539794266328,
author = {Attiya, Hagit and Herzberg, Amir and Rajsbaum, Sergio},
title = {Optimal Clock Synchronization Under Different Delay Assumptions},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794266328},
doi = {10.1137/S0097539794266328},
abstract = {The problem of achieving optimal clock synchronization in a communication network with arbitrary topology and perfect clocks (that do not drift) is studied. Clock synchronization algorithms are presented for a large family of delay assumptions. Our algorithms are modular and consist of three major components. The first component holds for any type of delay assumptions; the second component holds for a large, natural family of local delay assumptions; the third component must be tailored for each specific delay assumption.  Optimal clock synchronization algorithms are derived for several types of delay assumptions by appropriately tuning the third component. The delay assumptions include lower and upper delay bounds, no bounds at all, and bounds on the difference of the delay in opposite directions. In addition, our model handles systems where some processors are connected by broadcast networks in which every message arrives at all the processors at approximately the same time. A composition theorem allows combinations of different assumptions for different links or even for the same link; such mixtures are common in practice.  Our results achieve the best possible precision in each execution. This notion of optimality is stronger than the more common notion of worst-case optimality. The new notion of optimality applies to systems where the worst-case behavior of any clock synchronization algorithm is inherently unbounded. },
journal = {SIAM J. Comput.},
month = feb,
pages = {369–389},
numpages = {21},
keywords = {optimization, networks, real-time systems, distributed systems, message passing systems, message delay assumptions, precision, clock synchronization}
}

@article{10.1137/S0097539794264585,
author = {Khuller, Samir and Raghavachari, Balaji and Young, Neal},
title = {Low-Degree Spanning Trees of Small Weight},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794264585},
doi = {10.1137/S0097539794264585},
abstract = {Given $n$ points in the plane, the degree-$K$ spanning-tree problem asks for a spanning tree of minimum weight in which the degree of each vertex is at most $K$. This paper addresses the problem of computing low-weight degree-$K$ spanning trees for $K&gt;2$. It is shown that for an arbitrary collection of $n$ points in the plane, there exists a spanning tree of degree 3 whose weight is at most 1.5 times the weight of a minimum spanning tree. It is shown that there exists a spanning tree of degree 4 whose weight is at most 1.25 times the weight of a minimum spanning tree. These results solve open problems posed by Papadimitriou and Vazirani. Moreover, if a minimum spanning tree is given as part of the input, the trees can be computed in $O(n)$ time.  The results are generalized to points in higher dimensions. It is shown that for any $d ge 3$, an arbitrary collection of points in $Re^d$ contains a spanning tree of degree 3 whose weight is at most 5/3 times the weight of a minimum spanning tree. This is the first paper that achieves factors better than 2 for these problems. },
journal = {SIAM J. Comput.},
month = feb,
pages = {355–368},
numpages = {14},
keywords = {approximation algorithms, graphs, algorithms, geometry, spanning trees}
}

@article{10.1137/S0097539794200383,
author = {Rhee, C. and Liang, Y. D. and Dhall, S. K. and Lakshmivarahan, S.},
title = {An $O(N + M)$-Time Algorithm for Finding a Minimum-WeightDominating Set in a Permutation Graph},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794200383},
doi = {10.1137/S0097539794200383},
abstract = {Farber and Keil [ Algorithmica, 4 (1989), pp. 221--236] presented an $O(n^3)$-time algorithm for finding a minimum-weight dominating set in permutation graphs. This result was improved to $O(n^2 log^2n)$ by Tsai and Hsu [SIGAL '90  Algorithms, Lecture Notes in Computer Science, Springer-Verlag, New York, 1990, pp. 109--117] and to $O(n(n + m))$ by the authors of this paper [ Inform. Process. Lett., 37 (1991), pp. 219--224], respectively. In this paper, we introduce a new faster algorithm that takes only $O(n + m)$ time to solve the same problem, where $m$ is the number of edges in a graph of $n$ vertices.},
journal = {SIAM J. Comput.},
month = feb,
pages = {404–419},
numpages = {16},
keywords = {algorithm, dominating set, permutation graph}
}

@article{10.1137/S0097539793260775,
author = {Ramachandran, Vijaya and Yang, Honghua},
title = {An Efficient Parallel Algorithm for the General Planar MonotoneCircuit Value Problem},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793260775},
doi = {10.1137/S0097539793260775},
abstract = {A planar monotone circuit (PMC) is a Boolean circuit that can be embedded in the plane and that contains only AND and OR gates. Goldschlager, Dymond, Cook, and others have developed $NC^2$ algorithms to evaluate a special layered form of a PMC. These algorithms require a large number of processors ($Omega(n^6)$, where $n$ is the size of the input circuit). Yang and, more recently, Delcher and Kosaraju have given NC algorithms for the general planar monotone circuit value problem. These algorithms use at least as many processors as the algorithms for the layered case.  This paper gives an efficient parallel algorithm that evaluates a general PMC of size $n$ in polylog time using only a linear number of processors on an exclusive read exclusive write parameter random-access machine (EREW PRAM). This parallel algorithm is the best possible to within a polylog factor and is a substantial improvement over the earlier algorithms for the problem. The algorithm uses several novel techniques to perform the evaluation, including the use of the dual of the plane embedding of the circuit to determine the propagation of values within the circuit. },
journal = {SIAM J. Comput.},
month = feb,
pages = {312–339},
numpages = {28},
keywords = {dual graph, EREW PRAM, plane graph, circuit value problem, parallel algorithm, planar monotone circuit}
}

@article{10.1137/S0097539793257988,
author = {Satyanarayana, A. and Wood, R. K. and Camarinopoulos, L. and Pampoukis, G.},
title = {Note on "A Linear-Time Algorithm for Computing$K$-Terminal Reliability in a Series-Parallel Network"},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793257988},
doi = {10.1137/S0097539793257988},
abstract = {In an original and very interesting paper (Satyanarayana and  Wood [1]) concerning polygon-to-chain reductions in a  stochastic network, a small inconsistency occurs in the  proof of Theorem 1. In particular, this happens in cases  where the whole set of {bit K}-vertices lies in the remaining polygon. Such an example is the case of polygon  type 5, where the appropriate note has been made by the  authors for $|hbox{bit K}| = 2$. Analogous notes must also be made for polygon types 4, 6, and 7, when  {bit K}$ = 2$, 3, and 4, respectively. The correct transformations are given  in Table 1 (note that dark vertices are  {bit K}-vertices).},
journal = {SIAM J. Comput.},
month = feb,
pages = {290},
numpages = {1},
keywords = {network reliability, complexity, series-parallel graphs, reliability-preserving reductions, algorithms}
}

@article{10.1137/S0097539793255151,
author = {Rubinfeld, Ronitt and Sudan, Madhu},
title = {Robust Characterizations of Polynomials WithApplications to Program Testing},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793255151},
doi = {10.1137/S0097539793255151},
abstract = {The study of self-testing and self-correcting programs leads to the search for robust characterizations of functions. Here the authors make this notion precise and show such a characterization for polynomials.  From this characterization, the authors get the following applications. Simple and efficient self-testers for polynomial functions are constructed. The characterizations provide results in the area of coding theory by giving extremely fast and efficient error-detecting schemes for some well-known codes. This error-detection scheme plays a crucial role in subsequent results on the hardness of approximating some NP-optimization problems.},
journal = {SIAM J. Comput.},
month = feb,
pages = {252–271},
numpages = {20},
keywords = {low-degree polynomial testing, coding theory, program correctness}
}

@article{10.1137/S0097539793250627,
author = {Bafna, Vineet and Pevzner, Pavel A.},
title = {Genome Rearrangements and Sorting by Reversals},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250627},
doi = {10.1137/S0097539793250627},
abstract = {Sequence comparison in molecular biology is in the beginning of a major paradigm shift---a shift from gene comparison based on local mutations (i.e., insertions, deletions, and substitutions of nucleotides) to chromosome comparison based on global rearrangements (i.e.,  inversions and transpositions of fragments). The classical methods of sequence comparison do not work for global rearrangements, and little is known in computer science about the edit distance between sequences if global rearrangements are allowed. In the simplest form, the problem of gene rearrangements corresponds to sorting by reversals, i.e.,  sorting of an array using reversals of arbitrary fragments. Recently, Kececioglu and Sankoff gave the first approximation algorithm for sorting by reversals with guaranteed error bound 2 and identified open problems related to chromosome rearrangements. One of these problems is Gollan's conjecture on the reversal diameter of the symmetric group. This paper proves the conjecture.  Further, the problem of expected reversal distance between two random permutations is investigated. The reversal distance between two random permutations is shown to be very close to the reversal diameter, thereby indicating that reversal distance provides a good separation between related and nonrelated sequences in molecular evolution studies. The gene rearrangement problem forces us to consider reversals of signed permutations, as the genes in DNA could be positively or negatively oriented. An approximation algorithm for signed permutation is presented, which provides a performance guarantee of ${3 over 2}$. Finally, using the signed permutations approach, an approximation algorithm for sorting by reversals is described which achieves a performance guarantee of ${7 over 4}$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {272–289},
numpages = {18},
keywords = {sorting by reversals, genomerearrangements, computational molecular biology}
}

@article{10.1137/S0097539793246367,
author = {Mathur, Anmol and Reingold, Edward M.},
title = {Generalized Kraft's Inequality and Discrete $k$-Modal Search},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793246367},
doi = {10.1137/S0097539793246367},
abstract = {A function $f : Re rightarrow Re$ is {em $k$-modal} if its $k$th derivative has a unique zero.  We study the problem of finding the smallest possible interval containing the unique zero of the $k$th derivative of such a function, assuming that the function is evaluated only at integer points. We present optimal algorithms for the case when $k$ is even and for $k=3$ and near-optimal algorithms when $k geq 5$ and odd.  A novel generalization of Kraft's inequality is used to prove lower bounds on the number of function evaluations required.  We show how our algorithms lead to an efficient divide-and-conquer algorithm to determine all turning points or zeros of a $k$-modal function. Unbounded $k$-modal search is introduced and some problems in extending previous approaches for unbounded searching to the $k$-modal case are discussed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {420–447},
numpages = {28},
keywords = {$k$-modal search, binary search, optimal algorithms, Fibonaccinumbers, unimodal search, unbounded search, $k$-modal functions, bimodal search, Kraft's inequality}
}

@article{10.1137/S0097539793243016,
author = {Garg, Naveen and Vazirani, Vijay V. and Yannakakis, Mihalis},
title = {Approximate Max-Flow Min-(Multi)Cut Theorems and Their Applications},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793243016},
doi = {10.1137/S0097539793243016},
abstract = {Consider the multicommodity flow problem in which the object  is to maximize the sum of commodities routed. We prove the  following approximate max-flow min-multicut theorem: $$ dst frac{mbox{rm min multicut}}{O(log k)} leq  mbox{ rm max flow } leq mbox{ rm min multicut}, $$ noindent where $k$ is the number of commodities. Our proof  is constructive; it enables us to find a multicut within  $O(log k)$ of the max flow (and hence also the optimal  multicut). In addition, the proof technique provides a  unified framework in which one can also analyse the case of  flows with specified demands of Leighton and Rao and  Klein et al. and thereby obtain an improved bound for the  latter problem.},
journal = {SIAM J. Comput.},
month = feb,
pages = {235–251},
numpages = {17},
keywords = {approximation algorithm, minimum multicut, multicommodity flow}
}

@article{10.1137/S0097539793243004,
author = {Stearns, Richard E. and Hunt, Harry B.},
title = {An Algebraic Model for Combinatorial Problems},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793243004},
doi = {10.1137/S0097539793243004},
abstract = {A new algebraic model, called the generalized satisfiability problem (GSP) model, is introduced for representing and solving combinatorial problems. The GSP model is an alternative to the common method in the literature of representing such problems as language-recognition problems. In the GSP model, a problem instance is represented by a set of variables together with a set of terms, and the computational objective is to find a certain sum of products of terms over a commutative semiring. The model is general enough to express all the standard problems about sets of clauses and generalized clauses, all nonserial optimization problems, and all ${0,1}$-linear programming problems. The model can also describe many graph problems, often in a very direct structure-preserving way. Two important properties of the model are the following: begin{enumerate} item In the GSP model, one can naturally discuss the structure of individual problem instances. The structure of a GSP instance is displayed in a "structure tree."  The smaller  the "weighted depth" or "channelwidth" of the structure tree  for a GSP instance, the faster the instance can be solved by any one of several generic algorithms. item The GSP model extends easily so as to apply to hierarchically specified problems and enables solutions to instances of such problems to be found directly from the specification rather than from the (often exponentially) larger specified object.},
journal = {SIAM J. Comput.},
month = feb,
pages = {448–476},
numpages = {29},
keywords = {SAT, GSP, bounded bandwidth, structure tree, separator, hierarchical specifications, nonserial optimization, tree decomposition, treewidth}
}

@article{10.1137/S0097539792269095,
author = {Deng, Xiaotie and Hell, Pavol and Huang, Jing},
title = {Linear-Time Representation Algorithms for Proper Circular-Arc Graphs and Proper Interval Graphs},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792269095},
doi = {10.1137/S0097539792269095},
abstract = {Our main result is a linear-time (that is, time $O(m+n)$) algorithm to  recognize and represent proper circular-arc graphs. The best previous algorithm, due to A. Tucker, has time complexity $O(n^2)$. We take advantage of  the fact that (among connected graphs) proper circular-arc graphs are  precisely the graphs orientable as local tournaments, and we use a new  characterization of local tournaments. The algorithm depends on repeated  representation of portions of the input graph as proper interval graphs.  Thus we also find it useful to give a new linear-time algorithm to represent  proper interval graphs. This latter algorithm also depends on an orientation  characterization of proper interval graphs. It is conceptually simple and  does not use complex data structures. As a byproduct of the correctness proof of the algorithm, we also obtain a new proof of a characterization of proper interval graphs by forbidden subgraphs.},
journal = {SIAM J. Comput.},
month = feb,
pages = {390–403},
numpages = {14},
keywords = {local tournaments, representation algorithms, proper circular-arc graphs, proper interval graphs}
}

@article{10.1137/S0097539792235906,
author = {Hutton, Michael D. and Lubiw, Anna},
title = {Upward Planar Drawing of Single-Source AcyclicDigraphs},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235906},
doi = {10.1137/S0097539792235906},
abstract = {An upward plane drawing of a directed acyclic graph is a plane drawing of the digraph in which each directed edge is represented as a curve monotone increasing in the vertical direction. Thomassen has given a nonalgorithmic, graph-theoretic characterization of those directed graphs with a single source that admit an upward plane drawing. This paper presents an efficient algorithm to test whether a given single-source acyclic digraph has an upward plane drawing and, if so, to find a representation of one such drawing. This result is made more significant in light of the recent proof by Garg and Tamassia that the problem is NP-complete for general digraphs.  The algorithm decomposes the digraph into biconnected and triconnected components and defines conditions for merging the components into an upward plane drawing of the original digraph. To handle the triconnected components, we provide a linear algorithm to test whether a given plane drawing of a single-source digraph admits an upward plane drawing with the same faces and outer face, which also gives a simpler, algorithmic proof of Thomassen's result. The entire testing algorithm (for general single-source directed acyclic graphs) operates in $O(n^2)$ time and $O(n)$ space ($n$ being the number of vertices in the input digraph) and represents the first polynomial-time solution to the problem. },
journal = {SIAM J. Comput.},
month = feb,
pages = {291–311},
numpages = {21},
keywords = {upward planar, graph decomposition, directed graph, graph embedding, graph drawing, algorithms, planar graph, graph recognition}
}

@article{10.1137/S0097539790178069,
author = {Chang, Richard and Kadin, Jim},
title = {The Boolean Hierarchy and the Polynomial Hierarchy: A Closer Connection},
year = {1996},
issue_date = {February 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790178069},
doi = {10.1137/S0097539790178069},
abstract = {We show that if the Boolean hierarchy collapses to level $k$, then the polynomial hierarchy collapses to $BH_{3}(k)$, where $BH_{3}(k)$ is the $k$th level of the Boolean hierarchy over $Sigma^{P}_{2}$.  This is an improvement over the known results,  which show that the polynomial hierarchy would collapse to $P^{NP^{NP}[O(log n)]}$.  This result is significant in two ways.  First, the theorem says that a deeper collapse of the Boolean hierarchy implies a deeper collapse of the polynomial hierarchy. Also, this result points to some previously unexplored connections between the Boolean and query hierarchies of $Delta^{P}_{2}$ and $Delta^{P}_{3}$.  Namely, begin{eqnarray*}  &amp; BH(k) = {rm co-}BH(k) implies BH_{3}(k) = {rm co-}BH_{3}(k), [jot]  &amp; P^{{rm NP}|[k]} = P^{{rm NP}|[k+1]} implies   P^{{rm NP}^{rm NP}|[k+1]} = P^{{rm NP}^{rm NP}|[k+2]}. end{eqnarray*}},
journal = {SIAM J. Comput.},
month = feb,
pages = {340–354},
numpages = {15},
keywords = {oracle access, polynomial-timeTuring reductions, Boolean hierarchy, polynomial-time hierarchy, sparse sets, nonuniform algorithms}
}

@article{10.1137/S0097539794263452,
author = {Kapron, B. M. and Cook, S. A.},
title = {A New Characterization of Type-2 Feasibility},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539794263452},
doi = {10.1137/S0097539794263452},
abstract = {K. Mehlhorn introduced a class of  polynomial-time-computable  operators in order to study poly-time reducibilities between functions. This class is defined using a generalization of A. Cobham's definition of feasibility for type-1  functions to type-2 functionals. Cobham's feasible functions are equivalent to the familiar poly-time functions. We generalize this equivalence to type-2 functionals. This requires a definition of the notion "poly time in the length  of type-1 inputs." The proof of this equivalence is not a simple generalization of the proof for type-1 functions; it depends on the fact that Mehlhorn's class is closed under a strong form of simultaneous limited recursion on notation and requires an analysis of the structure of oracle queries in time-bounded computations.},
journal = {SIAM J. Comput.},
month = feb,
pages = {117–132},
numpages = {16},
keywords = {oracleTuring machine, notational recursion, polynomial time, computability}
}

@article{10.1137/S0097539793257034,
author = {Grove, Adam J. and Halpern, Joseph Y. and Koller, Daphne},
title = {Asymptotic Conditional Probabilities: The Unary Case},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793257034},
doi = {10.1137/S0097539793257034},
abstract = {Motivated by problems that arise in computing degrees of belief, we consider the problem of computing asymptotic conditional probabilities for first-order sentences.  Given first-order sentences $phi$ and $theta$, we consider the structures with domain ${1,ldots, N}$ that satisfy $theta$, and compute the fraction of them in which $phi$ is true.  We then consider what happens to this fraction as $N$ gets large.  This extends the work on 0-1 laws that considers the limiting probability of first-order sentences, by considering asymptotic conditional probabilities.  As shown by Liogon'kii [Math. Notes Acad. USSR, 6 (1969), pp. 856--861] and by Grove, Halpern, and Koller [Res. Rep. RJ 9564, IBM Almaden Research Center, San Jose, CA, 1993], in the general case, asymptotic conditional probabilities do not always exist, and most questions relating to this issue are highly undecidable.  These results, however, all depend on the assumption that $theta$ can use a nonunary predicate symbol. Liogonkii [Math. Notes Acad. USSR, 6 (1969), pp. 856--861] shows that if we condition on formulas $theta$ involving unary predicate symbols only (but no equality or constant symbols), then the asymptotic conditional probability does exist and can be effectively computed. This is the case even if we place no corresponding restrictions on $phi$. We extend this result here to the case where $theta$ involves equality and constants.  We show that the complexity of computing the limit depends on various factors, such as the depth of quantifier nesting, or whether the vocabulary is finite or infinite. We completely characterize the complexity of the problem in the different cases, and show related results for the associated approximation problem.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–51},
numpages = {51},
keywords = {degree of belief, labeled structures, 0-1 law, complexity, finite model theory, principle of indifference, asymptotic probability}
}

@article{10.1137/S0097539793251888,
author = {Regan, Kenneth W.},
title = {Linear Time and Memory-Efficient Computation},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793251888},
doi = {10.1137/S0097539793251888},
abstract = {A realistic model of computation called the  block-move (BM) model is developed. The BM regards computation as a sequence of finite transductions  in memory, and operations are timed according to a  memory cost parameter $mu$. Unlike previous memory-cost models, the BM provides a  rich theory of linear time, and in contrast to what is  known for Turing machines (TMs), the BM is proved to be highly robust for linear time.  Under a wide range of $mu$ parameters, many forms of the BM model, ranging from a fixed-wordsize random-access machine (RAM) down to a single finite automaton iterating itself on a single tape, are shown to simulate each other up to constant factors in running time.  The BM is proved to enjoy efficient universal simulation,  and to have a tight deterministic time hierarchy.  Relationships among BM and TM time complexity classes are studied.},
journal = {SIAM J. Comput.},
month = feb,
pages = {133–168},
numpages = {36},
keywords = {memory hierarchies, Turing machines, finite automata, linear time, caching, theory of computation, random-access machines, computational complexity, simulation, machine models}
}

@article{10.1137/S0097539793248305,
author = {Fenner, Stephen and Fortnow, Lance and Kurtz, Stuart A.},
title = {The Isomorphism Conjecture Holds Relative Toan Oracle},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793248305},
doi = {10.1137/S0097539793248305},
abstract = {The authors introduce symmetric perfect generic sets. These sets vary from the usual generic sets by allowing limited infinite encoding into the oracle. We then show that the Berman--Hartmanis isomorphism conjecture holds relative to any sp-generic oracle, i.e., for any symmetric perfect generic set $A$, all ${bf NP}^A$-complete sets are polynomial-time isomorphic relative to $A$. Prior to this work, there were no known oracles relative to which the isomorphism conjecture held.  As part of the proof that the isomorphism conjecture holds relative to symmetric perfect generic sets, it is also shown that ${bf P^A} {bf =} {bf FewP^A}$ for any symmetric perfect generic $A$. },
journal = {SIAM J. Comput.},
month = feb,
pages = {193–206},
numpages = {14},
keywords = {isomorphism conjecture, relativization, computational complexity}
}

@article{10.1137/S0097539793244368,
author = {Agarwal, Pankaj K. and Sharir, Micha},
title = {Ray Shooting Amidst Convex Polyhedra and PolyhedralTerrains in Three Dimensions},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793244368},
doi = {10.1137/S0097539793244368},
abstract = {We consider the problem of ray shooting in a three-dimensional scene consisting of $m$ (possibly intersecting) convex polyhedra or polyhedral terrains with a total of $n$ faces, i.e., we want to preprocess them into a data structure, so that the first intersection point of a query ray and the given polyhedra can be determined quickly. We present a technique that requires $O((mn)^{2+eps})$ preprocessing time and storage, and can answer ray-shooting queries in $O(log^2 n)$ time. This is a significant improvement over previously known techniques (which require $O(n^{4+eps})$ space and preprocessing) if $m$ is much smaller than $n$, which is often the case in practice. Next, we present a variant of the technique that requires $O(n^{1+eps})$ space and preprocessing, and answers queries in time $O(m^{1/4}n^{1/2+eps})$, again a significant improvement over previous techniques when $m ll n$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {100–116},
numpages = {17},
keywords = {data structures, ray shooting, random sampling, range searching, parametric search, arrangements}
}

@article{10.1137/S0097539792241928,
author = {Agarwala, Richa and Fernandez-Baca, David},
title = {Weighted Multidimensional Search and ItsApplication to Convex Optimization},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792241928},
doi = {10.1137/S0097539792241928},
abstract = {We present a weighted version of Megiddo's multidimensional search technique and use it to obtain faster algorithms for certain convex optimization problems in  $Reals^d$, for fixed $d$. This leads to speed-ups by a factor of $log^d n$ for applications such as solving the Lagrangian duals of matroidal knapsack problems and of constrained optimum subgraph problems on graphs of bounded tree-width.},
journal = {SIAM J. Comput.},
month = feb,
pages = {83–99},
numpages = {17},
keywords = {Lagrangian relaxation, multidimensional search, computational geometry, convex optimization}
}

@article{10.1137/S0097539792224516,
author = {Chiang, Yi-Jen and Preparata, Franco P. and Tamassia, Roberto},
title = {A Unified Approach to Dynamic Point Location, Ray Shooting, and Shortest Paths in Planar Maps},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792224516},
doi = {10.1137/S0097539792224516},
abstract = {We describe a new technique for dynamically maintaining the trapezoidal decomposition of a connected planar map $cal M$ with $n$ vertices and apply it to the development of a unified dynamic data structure that supports point-location, ray-shooting, and shortest-path queries in $cal M$.  The space requirement is $O(nlog n)$.  Point-location queries take time $O(log n)$.  Ray-shooting and shortest-path queries take time $O(log^3 n)$ (plus $O(k)$ time if the $k$ edges of the shortest path are reported in addition to its length).  Updates consist of insertions and deletions of vertices and edges, and take $O(log^3 n)$ time (amortized for vertex updates). This is the first polylog-time dynamic data structure for shortest-path and ray-shooting queries.  It is also the  first dynamic point-location data structure for connected planar maps that achieves optimal query time.},
journal = {SIAM J. Comput.},
month = feb,
pages = {207–233},
numpages = {27},
keywords = {ray shooting, point location, computational geometry, shortest path, dynamic algorithm}
}

@article{10.1137/S0097539791220688,
author = {Goldreich, Oded and Krawczyk, Hugo},
title = {On the Composition of Zero-Knowledge Proof Systems},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791220688},
doi = {10.1137/S0097539791220688},
abstract = {The wide applicability of zero-knowledge interactive proofs comes from the possibility of using these proofs as subroutines in cryptographic protocols. A basic question concerning this use is whether the (sequential and/or parallel) composition of zero-knowledge protocols is zero-knowledge too. We demonstrate the limitations of the composition of zero-knowledge protocols by proving that the original definition of zero-knowledge is not closed under sequential composition; and that even the strong formulations of zero-knowledge (e.g., black-box simulation) are not closed under parallel execution.  We present lower bounds on the round complexity of zero-knowledge proofs, with significant implications for the parallelization of zero-knowledge protocols. We prove that three-round interactive proofs and constant-round Arthur--Merlin proofs that are black-box simulation zero-knowledge exist only for languages in BPP. In particular, it follows that the "parallel versions" of the first interactive proofs systems presented for quadratic residuosity, graph isomorphism, and any language in NP, are not black-box simulation zero-knowledge, unless the corresponding languages are in BPP. Whether these parallel versions constitute zero-knowledge proofs was an intriguing open questions arising from the early works on zero-knowledge. Other consequences are a proof of optimality for the round complexity of various known zero-knowledge protocols and the necessity of using secret coins in the design of "parallelizable" constant-round zero-knowledge proofs. },
journal = {SIAM J. Comput.},
month = feb,
pages = {169–192},
numpages = {24},
keywords = {interactive proofs, cryptographic protocols, zero-knowledge}
}

@article{10.1137/S0097539790192702,
author = {Han, Yijie},
title = {A Fast Derandomization Scheme and Its Applications},
year = {1996},
issue_date = {Feb. 1996},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {25},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790192702},
doi = {10.1137/S0097539790192702},
abstract = {This paper presents a fast derandomization scheme for the PROFIT/COST problem. Through the applications of this scheme the time complexity of $O(log^2 n log log n)$ for the $Delta+1$ vertex-coloring problem using $O((m+n)/log log n)$ processors on the concurrent read exclusive write parallel random-access machine (CREW PRAM), the time complexity of $O( log^{2.5} n)$ for the maximal independent set problem using $O((m+n)/log^{1.5} n )$ processors on the CREW PRAM and the time complexity of $O(log^{2.5} n)$ for the maximal matching problem using $O((m+n)/log^{0.5} n)$ processors on the  exclusive read exclusive write (EREW) PRAM are shown.},
journal = {SIAM J. Comput.},
month = feb,
pages = {52–82},
numpages = {31},
keywords = {maximal matching, maximal independent set, graph coloring, parallel algorithms, graph algorithms, derandomization}
}

@article{10.1137/S0097539793254571,
author = {Naor, Moni and Stockmeyer, Larry},
title = {What Can Be Computed Locally?},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793254571},
doi = {10.1137/S0097539793254571},
abstract = {The purpose of this paper is a study of computation that can be done locally in a distributed network, where "locally" means within time (or distance) independent of the size of the network.  Locally checkable labeling (LCL)  problems are considered, where the legality of a labeling can be checked locally (e.g., coloring). The results include the following:  There are nontrivial LCL problems that have local algorithms.  There is a variant of the dining philosophers problem that can be solved locally.  Randomization cannot make an LCL problem local; i.e., if a problem has a local randomized algorithm then it has a local deterministic algorithm.  It is undecidable, in general, whether a given LCL has a local algorithm.  However, it is decidable whether a given LCL has an algorithm that operates in a given time $t$.  Any LCL problem that has a local algorithm has one that is order-invariant (the algorithm depends only on the order of the processor IDs). },
journal = {SIAM J. Comput.},
month = dec,
pages = {1259–1277},
numpages = {19},
keywords = {local computation, dining philosophers problem, resource allocation, distributed computation, randomized algorithms, graph labeling problem}
}

@article{10.1137/S0097539793251761,
author = {Kalorkoti, K.},
title = {On the Reuse of Additions in Matrix Multiplication},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793251761},
doi = {10.1137/S0097539793251761},
abstract = {We consider the problem of multiplying pairs of matrices by means of quadratic algorithms in terms of the reuse of additions.  We show that if such an algorithm is to be significantly faster than the naive matrix multiplication method then it must reuse additions to a great extent.  (For example, any quadratic or bilinear algorithm for $ntimes n$ matrix multiplication that does not reuse additions, except when reusing nonscalar steps, requires at least $n^3/8-n^2/4+n/8$ arithmetic operations.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1305–1312},
numpages = {8},
keywords = {formula, bilinear forms, matrixmultiplication, algebraic complexity}
}

@article{10.1137/S0097539793250299,
author = {Eiter, Thomas and Gottlob, Georg},
title = {Identifying the Minimal Transversals of a Hypergraph and Related Problems},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250299},
doi = {10.1137/S0097539793250299},
abstract = {The paper considers two decision problems on hypergraphs, hypergraph saturation and recognition of the transversal hypergraph, and discusses their significance for several search problems in applied computer science. Hypergraph saturation (i.e., given a hypergraph $cal H$, decide if every subset of vertices is contained in or contains some edge of $cal H$) is shown to be co-NP-complete. A certain subproblem of hypergraph saturation, the saturation of simple hypergraphs (i.e., Sperner families), is shown to be under polynomial transformation equivalent to transversal hypergraph recognition; i.e., given two hypergraphs ${cal H}_{1}, {cal H}_{2}$, decide if the sets in ${cal H}_{2}$ are all the minimal transversals of ${cal H}_{1}$. The complexity of the search problem related to the recognition of the transversal hypergraph, the computation of the transversal hypergraph, is an open problem. This task needs time exponential in the input size; it is unknown whether an output-polynomial algorithm exists. For several important subcases, for instance if an upper or lower bound is imposed on the edge size or for acyclic hypergraphs, output-polynomial algorithms are presented.  Computing or recognizing the minimal transversals of a hypergraph is a frequent problem  in practice, which is pointed out by identifying important applications  in database theory, Boolean switching theory, logic, and artificial intelligence (AI), particularly in model-based diagnosis.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1278–1304},
numpages = {27},
keywords = {model-based diagnosis, dependency inference, output-polynomial time, distributed databases, key computation, independent sets, satisfiability, database design, coteries, hypergraphs, hypergraphtransversals, polynomial time, hitting sets, graph algorithms, NP-complete, prime implicants}
}

@article{10.1137/S0097539793249700,
author = {Lutz, Jack H.},
title = {Weakly Hard Problems},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793249700},
doi = {10.1137/S0097539793249700},
abstract = {A weak completeness phenomenon is investigated in the complexity class ${rm E}= {rm DTIME}(2^{rm linear})$. According to standard terminology, a language $H$ is $leq^{rm P}_{m}$-  hard  for E if the set ${rm P}_{m}(H)$, consisting of all languages $A leq^{rm P}_{m}H$, contains the entire class E. A language $C$ is $leq^{rm P}_{m}$-  complete  for E if it is $leq^{rm P}_{m}$-hard for E and is also an element of E. Generalizing this, a language $H$ is  weakly  $leq^{rm P}_{m}$-  hard  for E if the set ${rm P}_{m}(H)$ does not have measure 0 in E. A language $C$ is  weakly  $leq^{rm P}_{m}$-  complete  for E if it is weakly $leq^{rm P}_{m}$-hard for E and is also an element of E.  The main result of this paper is the construction of a language that is weakly $leq^{rm P}_{m}$-complete, but not $leq^{rm P}_{m}$-complete, for E. The existence of such languages implies that previously known strong lower bounds on the complexity of weakly $leq^{rm P}_{m}$-hard problems for E (given by work of Lutz, Mayordomo, and Juedes) are indeed more general than the corresponding bounds for $leq^{rm P}_{m}$-hard problems for E.  The proof of this result introduces a new diagonalization method, called  martingale diagonalization . Using this method, one simultaneously develops an infinite family of polynomial time computable martingales (betting strategies) and a corresponding family of languages that defeat these martingales (prevent them from winning too much money) while also pursuing another agenda. Martingale diagonalization may be useful for a variety of applications. },
journal = {SIAM J. Comput.},
month = dec,
pages = {1170–1189},
numpages = {20},
keywords = {weak completeness, resource-bounded measure, complexity classes, computational complexity, complete problems}
}

@article{10.1137/S0097539793248317,
author = {Shmoys, David B. and Wein, Joel and Williamson, David P.},
title = {Scheduling Parallel Machines On-Line},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793248317},
doi = {10.1137/S0097539793248317},
abstract = {The problem of scheduling jobs on parallel machines is studied when (1) the existence of a job is not known until its unknown release date and (2) the processing requirement of a job is not known until the job is processed to completion.  Two general algorithmic techniques are demonstrated for converting existing polynomial-time algorithms that require complete knowledge about the input data into algorithms that need less advance knowledge.  Information-theoretic lower bounds on the length of on-line schedules are proven for several basic parallel machine models, and that almost all of our algorithms construct schedules with lengths that either match or come within a constant factor of the lower bound.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1313–1331},
numpages = {19},
keywords = {scheduling, approximation algorithms}
}

@article{10.1137/S0097539793246252,
author = {Sekar, R. C. and Ramesh, R. and Ramakrishnan, I. V.},
title = {Adaptive Pattern Matching},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793246252},
doi = {10.1137/S0097539793246252},
abstract = {Pattern matching is an important operation used in many applications such as functional programming, rewriting, and rule-based expert systems.  By preprocessing the patterns into a DFA-like automaton, we can rapidly select the matching pattern(s) in a single scan of the relevant portions of the input term.  This automaton is typically based on left-to-right traversal of the patterns.  By adapting the traversal order to suit the set of input patterns, it is possible to considerably reduce the space and matching time requirements of the automaton.  The design of such adaptive automata is the focus of this paper. We first formalize the notion of an adaptive traversal. We then present several strategies for synthesizing adaptive traversal orders aimed at reducing space and matching time complexity.  In the worst case, however, the space requirements can be exponential in the size of the patterns. We show this by establishing  an exponential lower bounds on space that is independent of the traversal order used. We then discuss an orthogonal approach to space minimization based on direct construction of optimal dag automata. Finally, our work brings forth the impact of typing in pattern matching. In particular, we show that several important problems (e.g., lazy pattern matching in ML) are computationally hard in the presence of type disciplines, whereas they can be solved efficiently in the untyped setting.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1207–1234},
numpages = {28},
keywords = {indexing, algorithms and complexity, discrimination nets, pattern matching, functional programming}
}

@article{10.1137/S0097539792242144,
author = {Buchsbaum, Adam L. and Sundar, Rajamani and Tarjan, Robert E.},
title = {Data-Structural Bootstrapping, Linear Path Compression, and Catenable Heap-Ordered Double-Ended Queues},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792242144},
doi = {10.1137/S0097539792242144},
abstract = {A  deque with heap order  is a linear list of elements with real-valued keys that allows insertions and deletions of elements at both ends of the list. It also allows the  findmin  (alternatively  findmax ) operation, which returns the element of least (greatest) key, but it does not allow a general  deletemin (deletemax)  operation. Such a data structure is also called a  mindeque (maxdeque) . Whereas implementing heap-ordered deques in constant time per operation is a solved problem, catenating heap-ordered deques in sublogarithmic time has until now remained open.  This paper provides an efficient implementation of catenable heap-ordered deques, yielding constant amortized time per operation. The important algorithmic technique employed is an idea that we call  data-structural bootstrapping : we abstract heap-ordered deques by representing them by their minimum elements, thereby reducing catenation to simple insertion. The efficiency of the resulting data structure depends upon the complexity of a special case of path compression that we prove takes linear time. },
journal = {SIAM J. Comput.},
month = dec,
pages = {1190–1206},
numpages = {17},
keywords = {lists, heap order, queues, catenation, path compression, deques, data-structural bootstrapping, priority queues}
}

@article{10.1137/S0097539792237541,
author = {Devroye, Luc and Reed, Bruce},
title = {On the Variance of the Height of Random Binary Search Trees},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792237541},
doi = {10.1137/S0097539792237541},
abstract = {Let $H_n$ be the height of a random binary search tree on $n$ nodes. We show that there exists a constant $alpha = 4.31107ldots$  such that ${rm P} { |H_n - alpha log n | &gt; beta log log n } to 0$, where $beta&gt;15 alpha / ln 2 = 93.2933ldots$. The proof uses the second moment method and does not rely on properties of branching processes. We also show that $Var { H_n } = O( (log log n)^2)$.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1157–1162},
numpages = {6},
keywords = {height, binary search tree, random tree, second moment method, asymptotics, probabilistic analysis}
}

@article{10.1137/S0097539792233245,
author = {Larmore, Lawrence L. and Przytycka, Teresa M.},
title = {Constructing Huffman Trees in Parallel},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792233245},
doi = {10.1137/S0097539792233245},
abstract = {We present a parallel algorithm for the Huffman coding problem. We reduce the Huffman coding problem to the concave least weight subsequence problem and give a parallel algorithm that solves the latter problem  in $O(sqrt n log n)$ time with $n$ processors on a concurrent read exclusive write parameter random-access machine (CREW PRAM). This leads to the first sublinear time $o(n^2)$-total work parallel algorithm for Huffman coding. This reduction of the Huffman coding problem to the CLWS problem also yields an alternative $O(n log n)$-time (or linear-time, for a sorted input sequence) algorithm for Huffman coding.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1163–1169},
numpages = {7},
keywords = {parallel algorithms, Huffman coding}
}

@article{10.1137/S0097539792224954,
author = {Devroye, Luc and Robson, John Michael},
title = {On the Generation of Random Binary Search Trees},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792224954},
doi = {10.1137/S0097539792224954},
abstract = {We consider the computer generation of random binary search trees with $n$ nodes for the standard random permutation model.  The algorithms discussed here output the number of external nodes at each level, but not the shape of the tree. This is important, for example, when one wishes to simulate the height of the binary search tree. Various paradigms are proposed, including depth-first search with pruning, incremental methods in which the tree grows with random-sized jumps, and a tree growing procedure gleaned from birth-and-death processes. The last method takes $O(log^4 n)$ expected time.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1141–1156},
numpages = {16},
keywords = {probabilistic analysis, height of a tree, expected complexity, point process, recursive procedure, random combinatorial object, simulation, binary search tree}
}

@article{10.1137/S0097539791224509,
author = {Han, Xiaofeng and Kelsen, Pierre and Ramachandran, Vijaya and Tarjan, Robert},
title = {Computing Minimal Spanning Subgraphs in Linear Time},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791224509},
doi = {10.1137/S0097539791224509},
abstract = {Let $P$ be a property of undirected graphs. We consider the following problem: given a graph $G$ that has property $P$, find a minimal spanning subgraph of $G$ with property $P$. We describe general algorithms for this problem and prove their correctness under fairly weak assumptions about $P$. We establish that the worst-case running time of these algorithms is $Theta(m+n log n)$ for 2-edge-connectivity and biconnectivity where $n$ and $m$ denote the number of vertices and edges, respectively, in the input graph. By refining the basic algorithms we obtain the first linear time algorithms for computing a minimal 2-edge-connected spanning subgraph and for computing a minimal biconnected spanning subgraph.  We also devise general algorithms for computing a minimal spanning subgraph in directed graphs. These algorithms allow us to simplify an earlier algorithm of Gibbons, Karp, Ramachandran, Soroker, and Tarjan for computing a minimal strongly connected spanning subgraph. We also provide the first tight analysis of the latter algorithm, showing that its worst-case time complexity is $Theta(m+n log n).$ },
journal = {SIAM J. Comput.},
month = dec,
pages = {1332–1358},
numpages = {27},
keywords = {linear-time algorithm, two-edge-connectivity, minimal subgraphs, biconnectivity, worst-case behavior, strong connectivity}
}

@article{10.1137/S009753979122370X,
author = {Mendelzon, Alberto O. and Wood, Peter T.},
title = {Finding Regular Simple Paths in Graph Databases},
year = {1995},
issue_date = {Dec. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979122370X},
doi = {10.1137/S009753979122370X},
abstract = {We consider the following problem: given a labelled directed graph $G$  and a regular expression $R$, find all pairs of nodes connected by a  simple path such that the concatenation of the labels along the path  satisfies $R$. The problem is motivated by the observation that many  recursive queries in relational databases can be expressed in this  form, and by the implementation of a query language, ${bf G}^+$, based on  this observation.  We show that the problem is in general intractable,  but present an algorithm than runs in polynomial time in the size of  the graph when the regular expression and the graph are free of   conflicts.  We also present a class of languages whose expressions  can always be evaluated in time polynomial in the size of both the  graph and the expression, and characterize syntactically the  expressions for such languages.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1235–1258},
numpages = {24},
keywords = {labelled directed graphs, regular expressions, polynomial-time algorithms, NP-completeness, simple paths}
}

@article{10.1137/S0097539793258131,
author = {Ogihara, Mitsunori},
title = {Polynomial-Time Membership Comparable Sets},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793258131},
doi = {10.1137/S0097539793258131},
abstract = {This paper studies a notion called polynomial-time membership comparable sets. For a function $g$, a set $A$ is polynomial-time $g$-membership comparable if there is a polynomial-time computable function $f$ such that for any $x_1, cdots, x_m$ with $m geq g(max{ |x_1|, cdots, |x_m| })$, outputs $b in {0,1}^m$ such that $(A(x_1), cdots, A(x_m)) neq b$. The following is a list of major results proven in the paper.  1. Polynomial-time membership comparable sets construct a proper hierarchy according to the bound on the number of arguments.  2. Polynomial-time membership comparable sets have polynomial-size circuits.  3. For any function $f$ and for any constant $c&gt;0$, if a set is $leq^p_{f(n)-tt}$-reducible to a P-selective set, then the set is polynomial-time $(1+c)log f(n)$-membership comparable.  4. For any $cal C$ chosen from ${ {rm PSPACE, UP, FewP, NP, C_{=}P, PP, MOD_{2}P, MOD_{3}}, cdots }$, if $cal C subseteq {rm P-mc}(clog n)$ for some $c&lt;1$, then $cal C = {rm P}$.  As a corollary of the last two results, it is shown that if there is some constant $c&lt;1$ such that all of $cal C$ are polynomial-time $n^c$-truth-table reducible to some P-selective sets, then $cal C = {rm P}$, which resolves a question that has been left open for a long time. },
journal = {SIAM J. Comput.},
month = oct,
pages = {1068–1081},
numpages = {14},
keywords = {polynomial-size circuits, P-selective sets, polynomial-time reducibilities}
}

@article{10.1137/S009753979325456X,
author = {Chou, Arthur W. and Ko, Ker-I},
title = {Computational Complexity of Two-Dimensional Regions},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979325456X},
doi = {10.1137/S009753979325456X},
abstract = {The computational complexity of bounded sets of the two-dimensional plane  is studied in the discrete computational model. We introduce four notions of polynomial-time computable sets in R$^2$   and study their relationship. The computational complexity of the winding number problem, membership   problem, distance problem, and area problem is   characterized by the relations between discrete  complexity classes of the  NP theory.},
journal = {SIAM J. Comput.},
month = oct,
pages = {923–947},
numpages = {25},
keywords = {simply closed curves, polynomial time, computational complexity, winding numbers}
}

@article{10.1137/S0097539793252687,
author = {Giesbrecht, Mark},
title = {Nearly Optimal Algorithms For Canonical Matrix Forms},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252687},
doi = {10.1137/S0097539793252687},
abstract = {A Las-Vegas-type probabilistic algorithm is presented for finding the Frobenius canonical form of an $ntimes n$ matrix $T$ over any field $KK$.  The algorithm requires $softO(MM(n))=MM(n)cdot(log n)^{O(1)}$ operations in $KK$, where $O(MM(n))$ operations in $KK$ are sufficient to multiply two $ntimes n$ matrices over $KK$.  This nearly matches the lower bound of $Omega(MM(n))$ operations in $KK$ for this problem, and improves on the $O(n^4)$ operations in $KK$ required by the previously best known algorithms.A fast parallel implementation of the algorithm is also demonstrated for the Frobenius form, which is processor-efficient on a PRAM.  As an application we give an algorithm to evaluate a polynomial $ginKK[x]$ at $T$ which requires only $softO(MM(n))$ operations in $KK$ when $deg gleq n^2$.  Other applications include sequential and parallel algorithms for computing the minimal and characteristic polynomials of a matrix, the rational Jordan form of a matrix (for testing whether two matrices are similar), and for matrix powering which are substantially faster than those previously known.},
journal = {SIAM J. Comput.},
month = oct,
pages = {948–969},
numpages = {22},
keywords = {matrix powering, Frobenius form, matrix multiplication, Jordan form, evaluating polynomials at matrices, processor-efficient parallelalgorithms}
}

@article{10.1137/S0097539793250330,
author = {Chari, Suresh and Rohatgi, Pankaj and Srinivasan, Aravind},
title = {Randomness-Optimal Unique Element Isolation WithApplications to Perfect Matching and Related Problems},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250330},
doi = {10.1137/S0097539793250330},
abstract = {In this paper, we precisely characterize the randomness complexity of the unique element isolation problem, a crucial step in the $RNC$ algorithm for perfect matching due to Mulmuley, Vazirani, and Vazirani [Combinatorica, 7 (1987), pp. 105--113] and in  several other applications. Given a set $S$ and an unknown family ${cal F} subseteq 2^S$  with $|{cal F}| leq Z$, we present a scheme to assign polynomially bounded weights to the elements of $S$, using only $O(log Z + log |S|)$ random bits, such that the minimum weight set in $cal F$ is unique with high probability. This generalizes the solution of Mulmuley, Vazirani, and Vazirani who use $O(Slog S)$ bits, independent of $Z$. We also provide a matching lower bound for the randomness complexity of this problem. The new weight assignment scheme yields a randomness-efficient $RNC^2$ algorithm for perfect matching which uses $O(log Z + log n)$ random bits where $Z$ is any given upper bound on the number of perfect matchings in the input graph. This generalizes the result of Grigoriev and Karpinski [Proc. IEEE Symposium on Foundations of Computer Science, 1987, pp. 166--172], who present an $NC^3$ algorithm when $Z$ is polynomial and also improves the running time in this case. The worst-case randomness complexity of our algorithm is $O(n log(m/n))$ random bits improving on the previous bound of $O(m log n)$. Our scheme also gives randomness-efficient solutions for several  problems where unique element isolation is used, such as $RNC$ algorithms for variants of matching and basic problems on linear matroids. We obtain a randomness-efficient random   reduction from $SAT$ to $USAT$, the language of uniquely satisfiable formulas which can be derandomized in the case of languages in $FewP$ to yield  new proofs of the results  $FewPsubseteq oplus P$ and $FewPsubseteq C_{!!=}P$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1036–1050},
numpages = {15},
keywords = {random reductions, matroids, parallel algorithms, probabilistic algorithms, matching}
}

@article{10.1137/S0097539793250287,
author = {Gartner, Bernd},
title = {A Subexponential Algorithm for Abstract Optimization Problems},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793250287},
doi = {10.1137/S0097539793250287},
abstract = {An  abstract optimization  problem (AOP) is a triple $(H,&lt;, Phi)$ where $H$ is a finite set, $&lt;$ a total order on $2^{H}$ and $Phi$ an oracle that, for given $Fsubseteq Gsubseteq H$, either reports that $F=min_{&lt;}{F'mid F'subseteq G}$ or returns a set $F'subseteq G$ with $F' $$e^{2sqrt{n}+O(sqrt[4]{n}ln n)}$$ oracle calls, $n=|H|$. In contrast, any deterministic algorithm needs to make $2^{n}-1$ oracle calls in the worst case.  The algorithm is applied to the problem of finding the distance between two $n$-vertex (or $n$-facet) convex polyhedra in $d$-space, and to the computation of the smallest ball containing $n$ points in $d$-space; for both problems we give the first subexponential bounds in the arithmetic model of computation.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1018–1035},
numpages = {18},
keywords = {randomized algorithm, smallest enclosing ball, computational geometry, distance between convex polyhedra, local optimization}
}

@article{10.1137/S0097539792241102,
author = {Andersson, Arne and Ottmann, Thomas},
title = {New Tight Bounds on Uniquely Represented Dictionaries},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792241102},
doi = {10.1137/S0097539792241102},
abstract = {We present a solution to the dictionary problem where each subset of size $n$ of an ordered universe is represented by a unique structure, containing  a (unique) binary search tree. The structure permits the execution of search,  insert, and delete operations in $O(n^{1/3})$ time in the worst case. We also give a general lower bound, stating that for any unique representation of a set in a graph of bounded outdegree, one of the operations search or update must require a cost of $Omega(n^{1/3})$. Therefore, our result sheds new light on previously claimed lower bounds for unique representation of dictionaries.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1091–1103},
numpages = {13},
keywords = {data structures, analysis of algorithms, dictionary problem, binary search trees, uniquely represented dictionaries}
}

@article{10.1137/S009753979223842X,
author = {Jiang, Tao and Li, Ming},
title = {On the Approximation of Shortest Common Supersequencesand Longest Common Subsequences},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223842X},
doi = {10.1137/S009753979223842X},
abstract = {The problems of finding shortest common supersequences (SCS) and longest common subsequences (LCS) are two well-known {bf NP}-hard problems that have applications in many areas including computational molecular biology, data compression, robot motion planning and scheduling, text editing, etc. A lot of fruitless effort has been spent in searching for good approximation algorithms for these problems. In this paper, we show that these problems are inherently hard to approximate in the worst case. In particular, we prove that (i) SCS does not have a polynomial time linear approximation algorithm, unless {bf P} = {bf NP}; (ii) There exists a constant $delta &gt; 0$ such that, if SCS has a polynomial time approximation algorithm with ratio $log^{delta} n$, where $n$ is the number of input sequences, then {bf NP} is contained in {bf DTIME}$(2^{polylog n})$; (iii) There exists a constant $delta &gt; 0$ such that, if LCS has a polynomial time approximation algorithm with performance ratio $n^{delta}$, then {bf P} = {bf NP}. The proofs utilize the recent results of Arora et al. [  Proc. 23rd IEEE Symposium on Foundations of Computer Science , 1992, pp. 14-23] on the complexity of approximation problems.  In the second part of the paper, we introduce a new method for analyzing the average-case performance of algorithms for sequences, based on Kolmogorov complexity. Despite the above nonapproximability results, we show that near optimal solutions for both SCS and LCS can be found on the average. More precisely, consider a fixed alphabet $Sigma$ and suppose that the input sequences are generated randomly according to the uniform probability distribution and are of the same length $n$. Moreover, assume that the number of input sequences is polynomial in $n$. Then, there are simple greedy algorithms which approximate SCS and LCS with expected additive errors $O(n^{0.707})$ and $O(n^{frac{1}{2}+epsilon})$ for any $epsilon &gt; 0$, respectively.  Incidentally, our analyses also provide tight upper and lower bounds on the expected LCS and SCS lengths for a set of random sequences, solving a generalization of another well-known open question on the expected LCS length for two random sequences [K. Alexander,  The rate of convergence of the mean length of the longest common subsequence , 1992, manuscript],[V. Chvatal and D. Sankoff,  J. Appl. Probab.,  12 (1975), pp. 306-315], [D. Sankoff and J. Kruskall, eds.,  Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison , Addison-Wesley, Reading, MA, 1983]. },
journal = {SIAM J. Comput.},
month = oct,
pages = {1122–1139},
numpages = {18},
keywords = {{bf NP}-hardness, average-case analysis, longest common subsequence, shortest common supersequence, random sequence, approximationalgorithm}
}

@article{10.1137/S0097539792237188,
author = {Fu, Bin},
title = {With Quasilinear Queries EXP is Not Polynomial Time Turing Reducible to Sparse Sets},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792237188},
doi = {10.1137/S0097539792237188},
abstract = {We investigate the lower bounds of queries required by the polynomial time Turing reductions from exponential time classes to the sets of small density. For complexity classes E= DTIME$(2^{O(n)})$ and EXP=DTIME$(2^{n^{O(1)}})$, the following results are shown in this paper. (1) For any $a&lt;1$, every EXP-$le^{rm P}_{n^a-{rm T}}$-hard set is exponentially dense. This yields EXP$notsubseteq$ P$_{n^a-{rm T}}$(SPARSE) for all $a&lt;1$. (2) For any $a&lt;{1over 2}$, every E-$le^{rm P}_{n^a-{rm T}}$-hard set is exponentially dense. (3) E$notsubseteq$P$_{o({nover log n})-{rm T}}$(TALLY). Our results substantially improve Watanabe's earlier theorem, E$notsubseteq$P$_{log n-{rm tt}}$(SPARSE) [  Proc. 2nd IEEE Conference on Structure in Complexity Theory , 1987, pp. 138-146],[  Proc. 7th IEEE Conference on Structure in Complexity Theory , 1992, pp. 222-238]. },
journal = {SIAM J. Comput.},
month = oct,
pages = {1082–1090},
numpages = {9},
keywords = {sparse sets, polynomial time Turing reducibilities, exponential time complexity classes}
}

@article{10.1137/S0097539792235724,
author = {Cohen, Robert F. and Battista, Giuseppe Di and Tamassia, Roberto and Tollis, Ioannis G.},
title = {Dynamic Graph Drawings: Trees, Series-Parallel Digraphs, and Planar <i>ST</i>-Digraphs},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235724},
doi = {10.1137/S0097539792235724},
abstract = {Drawing graphs is an important problem that combines elements of computational geometry and graph theory. Applications can be found in a variety of areas including circuit layout, network management, software engineering, and graphics.  The main contributions of this paper can be summarized as follows:  We devise a model for dynamic graph algorithms, based on performing queries and updates on an implicit representation of the drawing, and we show its applications.  We present efficient dynamic drawing algorithms for trees and series-parallel digraphs.  As further applications of the model, we give dynamic drawing algorithms for planar  st -digraphs and planar graphs. Our algorithms adopt a variety of representations (e.g., straight line, polyline, visibility) and update the drawing in a smooth way. },
journal = {SIAM J. Comput.},
month = oct,
pages = {970–1001},
numpages = {32},
keywords = {graph drawing, series-parallel digraphs, planar graphs, data structures, layout, dynamic algorithms, trees}
}

@article{10.1137/S0097539792234378,
author = {Hofting, Franz and Wanke, Egon},
title = {Minimum Cost Paths in Periodic Graphs},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792234378},
doi = {10.1137/S0097539792234378},
abstract = {We consider graphs with $d$-dimensional integral vector weights and rational cost values associated with the edges. We analyze the problem of finding  a minimum cost path between two given vertices such that the vector sum of all edges in the path equals a given target vector $m$. The present paper shows that there are polynomial time algorithms for finding such a minimum cost $m$-path if the dimension of the vector weights is bounded by a constant and the vector weights are represented unary, where the general version is NP-complete under various restrictions,},
journal = {SIAM J. Comput.},
month = oct,
pages = {1051–1067},
numpages = {17},
keywords = {shortest paths, integer linear programming, scheduling, NP-completeness, periodic graphs}
}

@article{10.1137/S0097539791218081,
author = {Han, Ching-Chih and Lin, Kwei-Jay and W, Jane and Liu, .-S.},
title = {Scheduling Jobs with Temporal Distance Constraints},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791218081},
doi = {10.1137/S0097539791218081},
abstract = {The job scheduling problems for real-time jobs with temporal distance constraints (JSD) are presented. In JSD, the start times of two related jobs must be within a given distance. The general JSD problem is NP-hard. We define the multilevel unit-time JSD (MUJSD) problem for systems with $m$ chains of unit-time jobs in which neighboring jobs in each chain must be scheduled within $c$ time units. We present an $O(n^2)$-time algorithm, where $n$ is the total number of jobs in the system, and also an $O(m^2 c^2)$-time algorithm. Some other variations of the JSD problems are also investigated.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1104–1121},
numpages = {18},
keywords = {precedence constraint, deadline, real-time systems, job scheduling, relative timing constraint, temporal distance}
}

@article{10.1137/S0097539789162997,
author = {Miller, Gary L.},
title = {Flow in Planar Graphs with Multiple Sources and Sinks},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789162997},
doi = {10.1137/S0097539789162997},
abstract = {The problem of maximum flow in planar graphs has always been investigated under the assumption that there is only one source and one sink. Here we consider the case where there are many sources and sinks (single commodity) in a directed planar graph. An algorithm for the case when the demands of the sources and sinks are fixed and given in advance is presented. It can be implemented efficiently sequentially and in parallel and its complexity is dominated by the complexity of computing all shortest paths from a single source in a planar graph. If the demands are not known, an algorithm for computing the maximum  flow is presented for the case where the number of faces that contain sources and sinks is bounded by a slowly growing function. Our result places the problem of computing a perfect matching in a planar bipartite graph in NC and it improves a previous parallel algorithm for the case of a single source, single sink in a planar directed1nd undirected) graph, both in terms of processor bounds and in its simple presentation.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1002–1017},
numpages = {16},
keywords = {circulation, planar graphs, flow}
}

@article{10.1137/S0097539793256685,
author = {Khuller, Samir and Raghavachari, Balaji and Young, Neal},
title = {Approximating the Minimum Equivalent Digraph},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793256685},
doi = {10.1137/S0097539793256685},
abstract = {The MEG (minimum equivalent graph) problem is the following: "Given a directed graph, find a smallest subset of the edges that maintains all reachability relations between nodes." This problem is NP-hard; this paper gives an approximation algorithm achieving a performance guarantee of about 1.64 in polynomial time. The algorithm achieves a performance guarantee of 1.75 in the time required for transitive closure.  The heart of the MEG problem is the minimum SCSS (strongly connected spanning subgraph) problem --- the MEG problem restricted to strongly connected digraphs. For the minimum SCSS problem, the paper gives a practical, nearly linear-time implementation achieving a performance guarantee of 1.75.  The algorithm and its analysis are based on the simple idea of contracting long cycles. The analysis applies directly to $2$-Exchange, a general "local improvement" algorithm, showing that its performance guarantee is 1.75. },
journal = {SIAM J. Comput.},
month = aug,
pages = {859–872},
numpages = {14},
keywords = {directed graph, local improvement, strong connectivity, approximation algorithm}
}

@article{10.1137/S0097539793245350,
author = {Poljak, Svatopluk},
title = {Integer Linear Programs and Local Search for Max-Cut},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793245350},
doi = {10.1137/S0097539793245350},
abstract = {The paper deals with the complexity of the local search, a topic introduced  by Johnson, Papadimitriou, and Yannakakis. One consequence of their work, and a recent paper by Schaffer and Yannakakis, is that the local search does not provide a polynomial time algorithm to find locally optimum solutions for several hard combinatorial optimization problems. This motivates us to seek "easier" instances for which  the local search is polynomial. In particular, it has been proved recently by Schaffer and Yannakakis that the max-cut problem with the FLIP neighborhood is PLS-complete, and hence belongs among the most difficult problems in the  PLS-class (polynomial time local search). The FLIP neighborhood of a 2-partition is defined by moving a single  vertex to the opposite class. We prove that, when restricted to cubic graphs, the FLIP local search becomes "easy" and finds a local max-cut in  $O(n^2) $ steps. To prove the result, we introduce a class of integer linear programs associated with cubic graphs, and provide a combinatorial characterization of their feasibility.},
journal = {SIAM J. Comput.},
month = aug,
pages = {822–839},
numpages = {18},
keywords = {local search, max-cut, integer linear program, local optima, cubic graph}
}

@article{10.1137/S0097539792240571,
author = {Lennerstad, Hakan and Lundberg, Lars},
title = {An Optimal Execution Time Estimate of Static versus Dynamic Allocation in Multiprocessor Systems},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240571},
doi = {10.1137/S0097539792240571},
abstract = {Consider a multiprocessor with $k$ identical processors, executing parallel programs consisting of $n$ processes.  Let $T_s(P)$ and $T_d(P)$ denote the execution times for the program $P$ with optimal static and dynamic allocations respectively, i. e. allocations giving minimal execution time.  We derive a general and explicit formula for the maximal execution time ratio $g(n,k)=max T_s(P)/T_d(P)$, where the maximum is taken over all programs $P$ consisting of $n$ processes. Any interprocess dependency structure for the programs $P$ is allowed, only avoiding deadlock. Overhead for synchronization and reallocation is neglected.  Basic properties of the function $g(n,k)$ are established, from which we obtain a global description of the function. Plots of $g(n,k)$ are included.  The results are obtained by investigating a mathematical formulation. The mathematical tools involved are essentially tools of elementary combinatorics. The formula is a combinatorial function applied on certain extremal matrices corresponding to extremal programs. It is mathematically complicated but rapidly computed for reasonable $n$ and $k$, in contrast to the np-completeness of the problems of finding optimal allocations. },
journal = {SIAM J. Comput.},
month = aug,
pages = {751–764},
numpages = {14},
keywords = {1-matrices, static allocation, extremal combinatories, combinational functions, 0, dynamic allocation}
}

@article{10.1137/S009753979223664X,
author = {Bshouty, Nader H. and Hancock, Thomas R. and Hellerstein, Lisa},
title = {Learning Arithmetic Read-Once Formulas},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223664X},
doi = {10.1137/S009753979223664X},
abstract = {A formula is read-once if each variable appears at most once in it. An arithmetic read-once formula is one in which the operators are addition, subtraction, multiplication, and division. We present polynomial time algorithms for exact learning  of arithmetic read-once formulas over a field. We present a membership and equivalence query algorithm that  identifies arithmetic read-once formulas over an arbitrary field.  We present a randomized membership query algorithm (i. e. a randomized black box interpolation algorithm) that identifies such formulas over finite fields with at least $2n+5$ elements (where $n$ is the number of variables), and over infinite fields. We also show the existence of non-uniform deterministic membership query algorithms for arbitrary read-once formulas over fields of characteristic 0, and for division-free read-once formulas over fields that have at least  $2n^3+1$ elements. For our algorithms, we assume we are able to efficiently perform arithmetic operations on field elements and to compute square roots in the field. It is shown that the ability to compute square roots is necessary, in the sense that the problem of computing $n-1$ square roots in a field can be reduced to the problem of identifying an arithmetic formula over $n$ variables in that field. Our equivalence queries are of a slightly non-standard form, in which counterexamples are required not to be inputs on which the formula evaluates to $0/0$. This assumption is shown to be necessary for fields of size $o(n/log {n})$, in the sense that we prove there exists no polynomial time identification algorithm that uses just membership and standard equivalence queries.},
journal = {SIAM J. Comput.},
month = aug,
pages = {706–735},
numpages = {30},
keywords = {exact identification, rational functions, polynomials, read-once formulas, learning theory, interpolation}
}

@article{10.1137/S0097539792235864,
author = {Feder, Tomas and Naor, Moni and Kushilevitz, Eyal and Nisan, Noam},
title = {Amortized Communication Complexity},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235864},
doi = {10.1137/S0097539792235864},
abstract = {In this work we study the  direct-sum  problem with respect to communication complexity: Consider a relation $f$ defined over ${0,1}^{n} times {0,1}^{n}$. Can the communication complexity of simultaneously computing $f$ on $cal l$ instances $(x_1,y_1),ldots,(x_{cal l},y_{cal l})$ be smaller than the communication complexity of computing $f$ on the $cal l$ instances, separately__ __  Let the  amortized  communication complexity of $f$ be the communication complexity of simultaneously computing $f$ on $cal l$ instances, divided by $cal l$. We study the properties of the amortized communication complexity. We show that the amortized communication complexity of a relation can be smaller than its communication complexity. More precisely, we present a  partial function  whose (deterministic) communication complexity is $Theta(log n)$ and its amortized (deterministic) communication complexity is $O(1)$. Similarly, for  randomized  protocols, we present a function whose randomized communication complexity is $Theta(log n)$ and its amortized randomized communication complexity is $O(1)$.  We also give a general lower bound on the amortized communication complexity of any  function  $f$ in terms of its communication complexity $C(f)$: for every function $f$ the amortized communication complexity of $f$ is $Omega left (sqrt{C(f)} - log n right)$. },
journal = {SIAM J. Comput.},
month = aug,
pages = {736–750},
numpages = {15},
keywords = {simultaneous computation, graph coloring, communication complexity}
}

@article{10.1137/S0097539792234901,
author = {Hemaspaandra, Lane A. and Silvestri, Riccardo},
title = {Easily Checked Generalized Self-Reducibility},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792234901},
doi = {10.1137/S0097539792234901},
abstract = {This paper explores two generalizations within NP of self-reducibility:  Arvind and Biswas's kernel  constructibility and Khadilkar and Biswas's committability. Informally stated, kernel constructible sets have (generalized) self-reductions that are easy to check, though perhaps hard to compute, and committable sets are those sets  for which the potential correctness of a partial  proof of set membership can be checked via a query to  the same set (that is, via a self-reduction). We study these two notions of generalized self-reducibility on non-dense sets.  We show that sparse kernel constructible sets are of low complexity, we extend previous results showing that sparse committable sets are of low complexity, and we provide structural evidence of  interest in its own right---namely that if all sparse disjunctively self-reducible sets are in P then $fewp ,cap, cofewp$ is not P-bi-immune---that our extension is unlikely to be further extended.   We obtain density-based sufficient conditions for kernel-constructibility: sets whose complements are captured by  non-dense sets are perforce kernel constructible. Using sparse languages and Kolmogorov complexity theory as tools, we argue that kernel constructibility is orthogonal to  standard notions of complexity.},
journal = {SIAM J. Comput.},
month = aug,
pages = {840–858},
numpages = {19},
keywords = {ambiguity-bounded computation, committable sets, kernel constructibility, self-reducibility, sparse sets}
}

@article{10.1137/S0097539792232586,
author = {Bshouty, Nader H. and Cleve, Richard and Eberly, Wayne},
title = {Size-Depth Tradeoffs for Algebraic Formulas},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792232586},
doi = {10.1137/S0097539792232586},
abstract = {Some tradeoffs between the size and depth of algebraic formulas are shown.  In particular, it is shown that, for any fixed $epsilon &gt; 0$, any algebraic formula of size $S$ can be converted into an equivalent formula of depth $O(log S)$ and size $O(S^{1+epsilon})$.  This result is an improvement over previously known results where, to obtain the same depth bound, the formula size is $Omega(S^{alpha})$, with~$alpha ge 2$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {682–705},
numpages = {24},
keywords = {parallel computation, arithmetic expressions, formulas}
}

@article{10.1137/S0097539792228228,
author = {Downey, Rod G. and Fellows, Michael R.},
title = {Fixed-Parameter Tractability and Completeness I: Basic Results},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792228228},
doi = {10.1137/S0097539792228228},
abstract = {For many fixed-parameter problems that are trivially soluable in polynomial-time, such as ($k$-)DOMINATING SET, essentially no better  algorithm is presently known than the one which tries all possible  solutions.   Other problems, such as ($k$-)FEEDBACK VERTEX SET, exhibit fixed-parameter tractability: for each fixed $k$ the problem is soluable in time bounded by a polynomial of degree $c$, where $c$ is a constant independent of $k$. We establish the main results of a completeness program which addresses the apparent fixed-parameter intractability of many parameterized problems.  In particular, we define a hierarchy of classes of parameterized problems $FPT subseteq W[1] subseteq W[2] subseteq cdots subseteq W[SAT] subseteq W[P]$ and  identify natural complete problems for $W[t]$ for $t geq 2$.  (In other papers we have shown many problems complete for $W[1]$.) DOMINATING SET is shown  to be complete for $W[2]$, and thus is not fixed-parameter tractable unless INDEPENDENT SET, CLIQUE, IRREDUNDANT SET and many other natural problems in $W[2]$ are also fixed-parameter tractable. We also give a compendium of currently known hardness results as an appendix.},
journal = {SIAM J. Comput.},
month = aug,
pages = {873–921},
numpages = {49},
keywords = {fixed-parameter tractable, $W$-hierarchy, $t$-NORMALIZED SATISFIABILITY, parameterized complexity, DOMINATING SET}
}

@article{10.1137/S0097539791218664,
author = {Gillies, Donald W. and W, Jane and Liu, .-S.},
title = {Scheduling Tasks with AND/OR Precedence Constraints},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791218664},
doi = {10.1137/S0097539791218664},
abstract = {In traditional precedence-constrained scheduling a task is ready to execute when all its predecessors are complete.  We call such a task an AND task.  In this paper we allow certain tasks to be ready when just one of their predecessors is complete.  These tasks are known as OR tasks.  We analyze the complexity of two types of real-time AND/OR task scheduling problems.  In the first type of problem, all the predecessors of every OR task must eventually be completed, but in the second type of problem, some OR predecessors may be left unscheduled. We show that most problems involving tasks with individual deadlines are NP-complete, and then present two priority-driven heuristic algorithms to minimize completion time on a multiprocessor.  These algorithms provide the same level of worst-case performance as some previous priority-driven algorithms for scheduling AND-only task systems.},
journal = {SIAM J. Comput.},
month = aug,
pages = {797–810},
numpages = {14},
keywords = {NP-complete problems, minimal length schedules, multiprocessor systems, algorithm analysis, nonpreemptive scheduling, list scheduling}
}

@article{10.1137/S0097539791201897,
author = {Murota, Kazuo},
title = {Computing the Degree of Determinants via Combinatorial Relaxation},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791201897},
doi = {10.1137/S0097539791201897},
abstract = {Let $A(x)=(A_{ij}(x))$ be a square matrix with $A_{ij}$ being a polynomial in $x$. This paper proposes "combinatorial relaxation" type algorithms for computing the degree of the determinant, $delta(A) = deg_x det A(x)$, based on its combinatorial upper bound $widehat delta(A)$, which is defined in terms of the maximum weight of a perfect matching in an associated graph. The graph is bipartite for a general square matrix $A$ and nonbipartite for a skew-symmetric $A$. The algorithm transforms $A$ to another matrix $A'$ for which $delta(A) = delta(A') = widehat delta(A')$ with successive elementary operations. The algorithm is efficient, making full use of the fast algorithms for weighted matchings; it is combinatorial in almost all cases (or generically) and invokes algebraic elimination routines only when accidental numerical cancellations occur.  It is shown in passing that for a (skew-)symmetric polynomial matrix $A(x)$ there exists a unimodular matrix $U(x)$ such that $A'(x)=U(x) A(x) U(x)^tp$ satisfies $delta(A) = delta(A') = widehat delta(A')$. },
journal = {SIAM J. Comput.},
month = aug,
pages = {765–796},
numpages = {32},
keywords = {computer algebra, polynomial matrix, combinatorial optimization, polyhedral combinatorics, determinant, matching}
}

@article{10.1137/0224051,
author = {Pan, Victor Y. and Preparata, Franco P.},
title = {Work-Preserving Speed-up of Parallel Matrix Computations},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0224051},
doi = {10.1137/0224051},
journal = {SIAM J. Comput.},
month = aug,
pages = {811–821},
numpages = {11},
keywords = {path algebras, paths in graphs, linear system of equations, work-optimal algorithms, parallel algorithms, processor efficiency}
}

@article{10.1137/0224044,
author = {Buhrman, Harry and Hemaspaandra, Edith and Longpr\'{e}, Luc},
title = {Sparse Reduces Conjunctively to Tally},
year = {1995},
issue_date = {Aug. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0224044},
doi = {10.1137/0224044},
journal = {SIAM J. Comput.},
month = aug,
pages = {673–681},
numpages = {9},
keywords = {truth table reductions, low density sets, conjunctive reductions, Kolmogorov complexity}
}

@article{10.5555/204695.586852,
author = {Pan, Victor Y. and Preparata, Franco P.},
title = {Work-Preserving Speed-Up of Parallel Matrix Computations},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
abstract = {Brent's scheduling principle provides a general simulation scheme when fewer processors are available than specified by the fastest parallel algorithm. Such a scheme preserves, under slow-down, the actual number of executed operations, also called work. In this paper we take the complementary viewpoint, and rather than consider the work-preserving slow-down of some fast parallel algorithm, we investigate the problem of the achievable speed-ups of computation while preserving the work of the best-known sequential algorithm for the same problem. The proposed technique, eminently applicable to problems of matrix-computational flavor, achieves its result through the interplay of two algorithms with significantly different features. Analogous but structurally different "interplays" have been used previously to improve the algorithmic efficiency of graph computations, selection, and list ranking. We demonstrate the efficacy of our technique for the computation of path algebras in graphs and digraphs and various fundamental computations in linear algebra. Some of the fundamental new algorithms may have practical value; for instance, we substantially improve the algorithmic performance of the parallel solution of triangular and Toeplitz linear systems of equations and the computation of the transitive closure of digraphs.},
journal = {SIAM J. Comput.},
month = jun,
pages = {811–821},
numpages = {11},
keywords = {paths in graphs, parallel algorithms, linear system of equations, processor efficiency, work-optimal algorithms, path algebras}
}

@article{10.5555/204695.586851,
author = {Buhrman, Harry and Hemaspaandra, Edith and Longpre, Luc},
title = {SPARSE Reduces Conjunctively to TALLY},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
abstract = {Polynomials over finite fields are used to show that any  sparse set can conjunctively reduce to a tally set. This  leads to new results and to simple proofs of known results  about various classes that lie between P and P/poly.},
journal = {SIAM J. Comput.},
month = jun,
pages = {673–681},
numpages = {9},
keywords = {truth table reductions, conjunctive reductions, low density sets, Kolmogorov complexity}
}

@article{10.1137/S0097539793260726,
author = {Hsu, Wen-Lian},
title = {$O(M<sup>.</sup>N)$ Algorithms for the Recognition and Isomorphism Problems on Circular-Arc Graphs},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793260726},
doi = {10.1137/S0097539793260726},
abstract = {Circular-arc graphs have a rich combinatorial structure. The  circular endpoint sequence of arcs in a model for a  circular-arc graph is usually far from unique. We present a  natural restriction on these models to make it meaningful to  define the unique representations for circular-arc graphs.  We characterize those circular-arc graphs which have unique  restricted models and give an $O(m cdot n)$ algorithm for  recognizing circular-arc graphs. We think a more careful  implementation could reduce the complexity to $O(n^2)$.  Our approach is to reduce  the recognition problem of circular-arc graphs to that of  circle graphs. This approach has the following advantages:  it is conceptually simpler than Tucker's $O(n^3)$  recognition algorithm; it exploits the similarity between  circle graphs and circular-arc graphs in a natural fashion;  it yields an isomorphism algorithm. A main contribution of  this result is an illustration of the transformed  decomposition technique. The decomposition tree developed  for circular-arc graphs generalizes the concept of the  PQ-tree, which is a data structure that keeps track of all  possible interval representations of a given interval graph.  As a consequence, our approach also yields an $O(m cdot n)$  isomorphism algorithm for circle graphs.},
journal = {SIAM J. Comput.},
month = jun,
pages = {411–439},
numpages = {29},
keywords = {complexity, graph decomposition, circle graph, circular-arc graph}
}

@article{10.1137/S0097539793252195,
author = {Kannan, Sampath K. and Warnow, Tandy J.},
title = {Tree Reconstruction from Partial Orders},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793252195},
doi = {10.1137/S0097539793252195},
abstract = {The problem of constructing trees given a matrix of interleaf distances is motivated by applications in computational evolutionary biology and linguistics. The general problem is to find an edge-weighted tree which most closely approximates (under some norm) the distance matrix. Although the construction problem is easy when the tree exactly fits the  distance matrix,  optimization problems under all  popular criteria are  either known or conjectured to be NP-complete. In this paper we consider the related problem where we are given a partial order on the pairwise distances, and wish to construct (if possible) an edge-weighted tree realizing the partial order. In particular we are interested in partial orders which arise from experiments on triples of species. We will show that the consistency problem is NP-hard in general, but that for certain special cases the construction problem can be solved in polynomial time.},
journal = {SIAM J. Comput.},
month = jun,
pages = {511–519},
numpages = {9},
keywords = {evolutionary trees, evolution, graphs, algorithms}
}

@article{10.1137/S0097539793247634,
author = {Duke, Richard A. and Lefmann, Hanno and Rodl, Vojtech},
title = {A Fast Approximation Algorithm for Computing TheFrequencies of Subgraphs in a Given Graph},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793247634},
doi = {10.1137/S0097539793247634},
abstract = {In this paper we give an algorithm which, given a labeled  graph on $n$ vertices and a list of all labeled graphs on $k$  vertices, provides for each graph $H$ of this list an approximation to  the number of induced copies of $H$ in $G$ with total error small.   This algorithm has running time $O(n^{{1 over log log n}} cdot M(n))$,  where $M(n)$ is the time needed to square a $n$ by $n$ matrix with 0, 1-entries over the integers.  The main tool in designing this algorithm is a variant of the regularity lemma of Szemeredi.},
journal = {SIAM J. Comput.},
month = jun,
pages = {598–620},
numpages = {23},
keywords = {regularity lemma, counting subgraphs}
}

@article{10.1137/S0097539792236730,
author = {Benczur, Andras A.},
title = {Counterexamples for Directed and Node Capacitated Cut-Trees},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792236730},
doi = {10.1137/S0097539792236730},
abstract = {We show that there is no cut-tree for various connectivity concepts, hence  pointing out to errors in the papers of Schnorr [SIAM J. Comput., 8 (1979), pp. 265-275] and Gusfield and Naor [Networks, 21 (1991), pp. 505-520]. Gomory and Hu [SIAM J. Appl. Math., 9 (1961), pp. 551-560] constructed a cut-tree for undirected graphs which compactly represents a minimum cut for each pair of vertices. This has a straightforward generalization to directed Eulerian graphs, cf. Gupta  [SIAM J. Appl. Math.,  15 (1967), pp. 168-171]. A generalization for arbitrary directed graphs was given by Schnorr.  There is a well-known transformation of vetex connectivity to directed edge  connectivity; directed edge cuts correspond to vertex cuts in some weak  sense. The result of Schnorr was later applied by Gusfield and Naor [8] for  such a cut-tree construction. In this paper counterexamples are described to  show that for directed graphs there is no cut-tree and therefore the cut-tree  results of Schnorr and Gusfield and Naor are incorrect. Our final   example shows that, without weakening the notion of vertex connectivity, it  is impossible to construct vertex cut-trees for undirected graphs in general.},
journal = {SIAM J. Comput.},
month = jun,
pages = {505–510},
numpages = {6},
keywords = {graph connectivity, minimum cuts, Gomory-Hu trees}
}

@article{10.1137/S0097539792236729,
author = {Tokuyama, Takeshi and Nakano, Jun},
title = {Efficient Algorithms for the Hitchcock Transportation Problem},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792236729},
doi = {10.1137/S0097539792236729},
abstract = {We consider the Hitchcock transportation problem on $n$ supply points and $k$ demand points when $n$ is much greater than $k$. The problem can be solved in $O(k n^2 log n + n^2 log^2 n)$ time if an efficient minimum-cost flow algorithm is directly applied. Applying a geometric method named splitter finding and a randomization technique, we can improve the time complexity when the ratio $c$ of the maximum supply to the minimum supply is sufficiently small. The expected running time of our randomized algorithm is $O(frac{kn log cn}{log (n/k^4 log^{2}k)})$ if $n &gt; k^4 log^{2} k$, and $O(k^5 log^{2} n log cn)$ if $n le k^4 log^{2} k$. If $n = Omega(k^{4 + epsilon}) (epsilon &gt; 0)$ and $c = mbox{poly}(n)$, the problem is solved in $O(kn)$ time, which is optimal.},
journal = {SIAM J. Comput.},
month = jun,
pages = {563–578},
numpages = {16},
keywords = {randomized algorithm, transportation problem, computational geometry}
}

@article{10.1137/S0097539792236717,
author = {Cohen, Edith},
title = {Approximate Max-Flow on Small Depth Networks},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792236717},
doi = {10.1137/S0097539792236717},
abstract = {We consider the maximum flow problem on directed acyclic networks with $m$ edges and depth $r$ (length of the longest $s$-$t$ path). Our main result is a new deterministic algorithm for solving the relaxed problem of computing an $s$-$t$ flow of value at least $(1-epsilon)$ of the maximum flow. For instances where $r$ and $epsilon^{-1}$ are small  (i.e., $O(polylog(m))$), this algorithm is in $NC$ and  uses only $O(m)$ processors, which is a significant improvement over existing parallel algorithms. As one consequence, we obtain an $NC$ $O(m)$ processor algorithm to find a bipartite matching of cardinality $(1-epsilon)$ of the maximum (for $epsilon^{-1}= O(polylog(m))$). We use a novel approach based on  path-counts to compute blocking flows in parallel. This approach produces fractional flow even when capacities are integral.  To encounter that,  we provide a rounding algorithm that is of independent interest. In polylogarithmic time using $O(m)$ processors, the algorithm rounds any fractional flow on a network with integral capacities  to an integral flow.  The rounding technique extends to networks with costs.},
journal = {SIAM J. Comput.},
month = jun,
pages = {579–597},
numpages = {19},
keywords = {bipartite matching, maximum flow, blocking flow, parallel algorithms}
}

@article{10.1137/S0097539792236237,
author = {Agrawal, Ajit and Klein, Philip and Ravi, R.},
title = {When Trees Collide: An Approximation Algorithm for TheGeneralized Steiner Problem on Networks},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792236237},
doi = {10.1137/S0097539792236237},
abstract = {We give the first approximation algorithm for the generalized network Steiner problem, a problem in network design.  An instance consists of a network with link-costs and, for each pair ${i,j}$ of nodes, an edge-connectivity requirement $r_{ij}$.  The goal is to find a minimum-cost network using the available links and satisfying the requirements.  Our algorithm outputs a solution whose cost is within $2lceil log_2(r+1)rceil$ of optimal, where $r$ is the highest requirement value. In the course of proving the performance guarantee, we prove a combinatorial min-max approximate equality relating minimum-cost networks to maximum packings of certain kinds of cuts.  As a consequence of the proof of this theorem, we obtain an approximation algorithm for optimally packing these cuts; we show that this algorithm has application to estimating the reliability of a probabilistic network.},
journal = {SIAM J. Comput.},
month = jun,
pages = {440–456},
numpages = {17},
keywords = {Steiner treeproblem, approximation algorithm, network design}
}

@article{10.1137/S0097539792235918,
author = {Emiris, Ioannis Z. and Canny, John F.},
title = {A General Approach to Removing Degeneracies},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235918},
doi = {10.1137/S0097539792235918},
abstract = {We wish to increase the power of an arbitrary algorithm designed for nondegenerate input, by allowing it to execute on all inputs. We concentrate on infinitesimal symbolic perturbations that do not affect the output for inputs in general position. Otherwise, if the problem mapping is continuous, the input and output space topology are at least as coarse as the real euclidean one and the output space is connected, then our perturbations make the algorithm produce an output arbitrarily close or identical to the correct one.  For a special class of algorithms, which includes several important algorithms in computational geometry, we describe a deterministic method that requires no symbolic computation. Ignoring polylogarithmic factors, this method increases only the worst-case bit complexity by a multiplicative factor which is linear in the dimension of the geometric space. For general algorithms, a randomized scheme with arbitrarily high probability of success is proposed; the bit complexity is then bounded by a small-degree polynomial in the original worst-case complexity. In addition to being simpler than previous ones, these are the first efficient perturbation methods.},
journal = {SIAM J. Comput.},
month = jun,
pages = {650–664},
numpages = {15},
keywords = {infinitesimals, randomization, determinants, symbolic perturbation, ill-conditioned problems, algorithmic complexity, input degeneracy, roots of polynomials}
}

@article{10.1137/S0097539792235384,
author = {Frieze, Alan and Karp, Richard M. and Reed, Bruce},
title = {When is the Assignment Bound Tight for the Asymmetric Traveling-Salesman Problem?},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235384},
doi = {10.1137/S0097539792235384},
abstract = {We consider the probabilistic relationship between the value of a random asymmetric traveling salesman problem $ATSP(M)$ and the value of its assignment relaxation $AP(M)$. We assume here that the costs are given by an $ntimes n$ matrix $M$ whose entries are independently and identically distributed. We focus on the relationship between $Pr(ATSP(M)=AP(M))$ and the probability $p_n$ that any particular entry is zero. If $np_nrightarrow infty$ with $n$ then we prove that $ATSP(M)=AP(M)$ with probability 1-o(1). This is shown to be best possible in the sense that if $np(n)rightarrow c$, $c&gt;0$ and constant, then $Pr(ATSP(M)=AP(M))&lt;1-phi(c)$ for some positive function $phi$. Finally, if $np_nrightarrow 0$ then $Pr(ATSP(M)=AP(M))rightarrow 0$. },
journal = {SIAM J. Comput.},
month = jun,
pages = {484–493},
numpages = {10},
keywords = {probabilistic analysis, traveling salesman}
}

@article{10.1137/S0097539792231982,
author = {Giancarlo, Raffaele},
title = {A Generalization of the Suffix Tree to Square Matrices, with Applications},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792231982},
doi = {10.1137/S0097539792231982},
abstract = {We describe a new data structure, the  Lsuffix tree , which generalizes McCreight's suffix tree for a string [  J. Assoc. Comput. Mach.,  23 (1976), pp. 262--272] to a square matrix. All matrices have entries from a totally ordered alphabet $Sigma$. Based on the Lsuffix tree, we give efficient algorithms for the static versions of the following dual problems that arise in low-level image processing and visual databases.   Two-dimensional pattern retrieval.  We have a library of texts $S={TEXT^1,cdots, TEXT^r}$, where $TEXT^i$ is an $n_itimes n_i$ matrix, $ 1 leq i leq r$. We may preprocess the library. Then, given an $m times m$, $m leq n_i$, $ 1 leq i leq r$, pattern matrix $PAT$, we want to find all occurrences of $PAT$ in $TEXT$, for all $TEXT in S$. Let $t(S)=Sigma_{i=1}^r n_i^2$ be the size of the library. The preprocessing step builds the Lsuffix tree for the matrices in $S$ and then transforms it into an index (a trie defined over $Sigma$). It takes $O(t(S)( log |Sigma| +log t(S)))$ time and $O(t(S))$ space. The index can be queried directly in $O(m^2log |Sigma|+totocc)$ time, where $totocc$ is the total number of occurrences of $PAT$ in $TEXT$, for all $TEXT in S$.   Two-dimensional dictionary matching . We have a dictionary of patterns $DC={PAT_1, cdots, PAT_s}$, where $PAT_i$ is of dimension $m_itimes m_i$, $ 1 leq i leq s$. We may preprocess the dictionary. Then, given an $n times n$ text matrix $TEXT$, we want to search for all occurrences of patterns in the dictionary in the text. Let $t(DC)=Sigma_{i=1}^s m^2_i$ be the size of the dictionary and let $overline{t}(DC)$ be the sum of the $m_i$'s. The preprocessing consists of building the Lsuffix tree for the matrices in $DC$. It takes $O(t(DC)log |Sigma| +overline{t}(DC)log overline{t}(DC)))$ time and $O(t(DC))$ space. The search step takes $O(n^2(log |Sigma|+log overline{t}(DC))+totocc)$ time, where $totocc$ is the total number of occurrences of patterns in the text.  Both problems have a dynamic version in which the library and the dictionary, respectively, can be updated by insertion or deletion of square matrices in them. In a companion paper, we will provide algorithms for the dynamic version. },
journal = {SIAM J. Comput.},
month = jun,
pages = {520–562},
numpages = {43},
keywords = {two-dimensional informative retrieval, image processing, data structures, pattern matching, dictionary matching}
}

@article{10.1137/S0097539792231179,
author = {Goldberg, Andrew V.},
title = {Scaling Algorithms for the Shortest Paths Problem},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792231179},
doi = {10.1137/S0097539792231179},
abstract = {We describe a new method for designing scaling algorithms for the single-source shortest paths problem and use this method to obtain an $O(sqrt n m log N)$ algorithm for the problem. (Here $n$ and $m$ is the number of nodes and arcs in the input network and $N$ is essentially the absolute value of the most negative arc length, and arc lengths are assumed to be integral.) This improves previous bounds for the problem. The method extends to related problems.},
journal = {SIAM J. Comput.},
month = jun,
pages = {494–504},
numpages = {11},
keywords = {graph theory, networks, scaling, shortest paths problem}
}

@article{10.1137/S0097539792230484,
author = {Mejean, Henri-M. and Morel, Henri and Reynaud, Gerard},
title = {A Variational Method for Analysing Unit Clause Search},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792230484},
doi = {10.1137/S0097539792230484},
abstract = {We expose a variational method for analysing algorithms, as applied to analyse the algorithm  UC , which is the Davis-Putnam procedure for a set of clauses of three literals. The variable from a unit clause or, if there is none, the first remaining variable from a fixed list is chosen. The algorithm  UC  finds all the solutions as a set of cylinders. Following the nomenclature of P. W. Purdom [J. Inform. Process., 13 (1990), pp. 449--455], we call this algorithm "unit clause backtracking with cylinders of solutions."  First we give an expression for the number of nodes of the calculation trees of all the inputs. Then we use a variational method to calculate the base $beta$ of the principal exponential part of the average time of calculation $T$. This "exponential base" is the maximum of three elementary functions $f_i$ of four real variables. These functions are defined on the product of the half positive real line by the 3-dimensional unit real cube. We finally obtain the following short statement. Let $v$ be the number of the variables. Let $c$ be the number of the clauses. Let $gamma=c/v&gt;1$. Let $gamma$ be constant when $v$ grows to infinity. The principal exponential part of the average time of  UC  is $beta^v$ where  $$beta=OO({max} ; 0leq lambdaleq 1) 2^lambda{bigl(1-{3lambda^2over 8}+{lambda^3over4}bigr)}^gamma.$$  We mean that $limlimits_{vrightarrowinfty}T^{1over v}=beta$.  As a first consequence of our method we match  UC , with the algorithm  B  without rearrangement (i. e. with a fixed order for introducing the variables). This gives a proof to a conjecture of P. W. Purdom [Artif. Intell., 21 (1983), pp. 117-133]. },
journal = {SIAM J. Comput.},
month = jun,
pages = {621–649},
numpages = {29},
keywords = {variational methods, satisfiability, analysis of algorithms, computational complexity}
}

@article{10.1137/S0097539792229672,
author = {Yang, Chung-Do and Lee, D. T. and Wong, C. K.},
title = {Rectilinear Path Problems Among Rectilinear ObstaclesRevisited},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792229672},
doi = {10.1137/S0097539792229672},
abstract = {Efficient algorithms are presented for finding rectilinear collision-free paths between two given points among a set of rectilinear obstacles. The results improve the time complexity of previous results for finding the shortest rectilinear path, the minimum-bend shortest rectilinear path, the shortest minimum-bend rectilinear path and the minimum-cost rectilinear path. For finding the shortest rectilinear path, a graph-theoretic approach is used and an algorithm is obtained with $O(mlog t+ tlog^{3/2} t)$ running time, where $t$ is the number of extreme edges of given obstacles and $m$ is the number of obstacle edges. Based on this result  an $O(Nlog N+(m+N)log t + (t+N)log^2 (t+N))$ running time algorithm for computing the $L_1$ minimum spanning tree of given $N$ terminals among rectilinear obstacles is obtained. For finding the minimum-bend shortest path, the shortest minimum-bend rectilinear path,  and the minimum-cost  rectilinear path, we devise a new dynamic-searching approach and derive algorithms that run in $O(mlog^2m)$ time using $O(mlog m)$ space or run in $O(mlog^{3/2}m)$ time and space.},
journal = {SIAM J. Comput.},
month = jun,
pages = {457–472},
numpages = {16},
keywords = {computational geometry, rectilinear shortest path, minimum-bend path, path preservinggraph, rectilinear obstacles}
}

@article{10.1137/S0097539792226771,
author = {Snyder, Timothy Law and Steele, J. Michael},
title = {A Priori Bounds on the Euclidean Traveling Salesman},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792226771},
doi = {10.1137/S0097539792226771},
abstract = {It is proved that there are constants $c_1$, $c_2$, and $c_3$  such that for any set $S$ of $n$ points in the unit square and for any minimum-length tour $T$ of $S$ (1) the sum of squares of the edge lengths of $T$ is bounded by  $c_1 log n$; (2) the number of edges having length $t$ or greater in $T$ is at most $c_2/t^2$; and  (3) the sum of edge lengths of any subset $E$ of $T$ is bounded by $c_3 |E|^{1/2}$. The second and third bounds are independent of the number of points in $S$, as well as their locations.   Extensions to dimensions $d&gt;2$ are also sketched. The presence of the logarithmic term in (1) is engaging because such a term is not needed in the case of the minimum spanning tree and several analogous problems, and, furthermore, we know that there always exists some tour of $S$ (which perhaps does not have minimal length) for which the sum of squared edges is bounded independently of $n$.},
journal = {SIAM J. Comput.},
month = jun,
pages = {665–671},
numpages = {7},
keywords = {Euclidean traveling salesman problem, inequalities, long edges, squared edgelengths}
}

@article{10.1137/S0097539792225583,
author = {Ganz, Jurg},
title = {Evaluation of Polynomials Using the Structure of the Coefficients},
year = {1995},
issue_date = {June 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792225583},
doi = {10.1137/S0097539792225583},
abstract = {A new algorithm to evaluate polynomials that exploits the structure of their coefficients is proposed. This algorithm is an extension  of one due  to Savage with the advantage that it is not restricted to coefficients from a set whose cardinality is small compared to the  degree of the polynomial. The new algorithm is shown to be asymptotically optimum  for evaluating arbitrary functions in finite fields and for evaluating polynomials with real coefficients in a binary fixed-point representation.  To illustrate that it is nonasymptotically useful as well, the new algorithm is shown to reduce the time for syndrome calculation for binary Bose-Chaudhuri-Hocquenghem (BCH) codes  of practical interest.},
journal = {SIAM J. Comput.},
month = jun,
pages = {473–483},
numpages = {11},
keywords = {straight-line algorithm, polynomial evaluation, binary fixed-point representations, finite fields, decoding BCH codes}
}

@article{10.1137/S0097539793245015,
author = {Grigoriev, Dima and Singer, Michael and Yao, Andrew},
title = {On Computing Algebraic Functions Using Logarithms AndExponentials},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793245015},
doi = {10.1137/S0097539793245015},
abstract = {Let $rho$ be a set of algebraic expressions constructed with radicals and arithmetic operations, and which generate the splitting field $F$ of some polynomial. Let $N_{beta}(rho)$ be the minimum total number of root-takings and exponentiations used in any straightline program for computing the functions in $rho$ by taking roots, exponentials, logarithms, and performing arithmetic operations. In this paper it is proved that $N_{beta}(rho) = nu(G)$, where $nu(G)$ is the minimum length of any cyclic Jordan--Holder tower for the Galois group $G$ of $F$. This generalizes a result of Ja'Ja' [Proceedings of the 22nd IEEE Symposium on Foundations of Computer Science, 1981, pp. 95--100], and shows that the inclusion of certain new primitives, such as taking exponentials and logarithms, does not improve the cost of computing such expressions as compared with programs that use only root-takings.},
journal = {SIAM J. Comput.},
month = apr,
pages = {242–246},
numpages = {5},
keywords = {Galois group, differential algebra, logarithms, exponentials, complexity, Jordan--Holder tower, algebraic expressions}
}

@article{10.1137/S009753979324485X,
author = {Li, Ming and Vitanyi, Paul},
title = {A New Approach to Formal Language Theory by Kolmogorov Complexity},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979324485X},
doi = {10.1137/S009753979324485X},
abstract = {We present a new approach to formal language theory using Kolmogorov complexity. The main results presented here are an alternative for pumping lemma(s), a new characterization for regular languages, and a new method to separate deterministic context-free languages and nondeterministic context-free languages. The use of the new "incompressibility arguments" is illustrated by many examples. The approach is also successful at the high end of the Chomsky hierarchy since one can quantify nonrecursiveness in terms of Kolmogorov complexity.},
journal = {SIAM J. Comput.},
month = apr,
pages = {398–410},
numpages = {13},
keywords = {finite automata, formal language theory, pumping lemmas, regular languages, Kolmogorov complexity, deterministic context-free languages}
}

@article{10.1137/S0097539793243314,
author = {Wang, Qingzhou and Leiss, Ernst L.},
title = {A Heuristic Scheduling of Independent Tasks with BottleneckResource Constraints},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793243314},
doi = {10.1137/S0097539793243314},
abstract = {In this paper, the problem of scheduling independent tasks with bottleneck resource constraints is investigated. There is a set of independent tasks ${cal T} = {T_1, ldots, T_n}$ and a set of resources ${cal R} = {R_1, ldots, R_m}$. The available amount of resource $R_j$, for $j = 1, ldots, m$, is (normalized to) 1. Each task $T_i$'s execution requires at least $lambda_{(i,j)} leq 1$ units of resource $R_j in {cal R}$, and with these minimal resources, the execution time of $T_i$ is $tau_i$. If there is a resource $R_{beta(i)}$ so that $T_i$ can use $xi$ units $(xi geq lambda_{(i, beta(j))})$ and reduce the execution time to $frac{lambda_{(i, beta(i))}}{xi} tau_{i}$, we say that $T_i$ can achieve  linear speed-up  with respect to $R_{beta(i)}$. It is assumed that for each $T_i$, there is one, and only one, resource $R_{beta(i)}$ that is $T_i$'s  bottleneck  resource: $T_i$ can use $xi$ units of $R_{(i, beta(i))}$ and achieve linear speed-up, where $xi$ is between $lambda_{(i, beta(i))}$ and $Lambda_{(i, beta(i))} leq 1$. The problem is to find a feasible schedule for all the tasks in ${cal T}$ that has a shortest overall makespan.  This problem is a combination of two previously studied problems---scheduling tasks with resource constraints [  SIAM J. Comput ., 4 (1975), pp.~187--200.] scheduling parallel tasks [  SIAM J. Comput ., 21 (1992), pp.~281--294]. A variant of this problem was studied in [  J. Combin. Theory , 21 (1976), pp.~257--298]. Because the problem is NP-hard, we propose the ECT (  earliest completion time ) algorithm as a heuristic solution and show that the performance ratio of the ECT makespan $M_{{scriptsize ECT}}$ to the optimal makespan $M_{{scriptsize OPT}}$ is bounded by $2l+m+1$, where $l$ is the number of the bottleneck resources in ${cal R}$. When $l=0$, this is exactly the performance bound shown by Garey and Graham in [  SIAM J. Comput ., 4 (1975), pp.~187--200]. },
journal = {SIAM J. Comput.},
month = apr,
pages = {235–241},
numpages = {7},
keywords = {and independent task scheduling, bottleneck resource, heuristic}
}

@article{10.1137/S0097539793242618,
author = {Goemans, Michel X. and Williamson, David P.},
title = {A General Approximation Technique for Constrained Forest Problems},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793242618},
doi = {10.1137/S0097539793242618},
abstract = {We present a general approximation technique for a large class of graph problems. Our technique mostly applies to problems of covering, at minimum cost, the vertices of a graph with trees, cycles or paths satisfying certain requirements. In particular, many basic combinatorial optimization problems fit in this framework, including the shortest path, minimum-cost spanning tree, minimum-weight perfect matching, traveling salesman and Steiner tree problems.  Our technique produces approximation algorithms that run in $O(n^2log n)$ time and come within a factor of 2 of optimal for most of these problems. For instance, we obtain a 2-approximation algorithm for the minimum-weight perfect matching problem under the triangle inequality. Our running time of $O(n^2log n)$ time compares favorably with the best strongly polynomial exact algorithms running in $O(n^3)$ time for dense graphs. A similar result is obtained for the 2-matching problem and its variants. We also derive the first approximation algorithms for many NP-complete problems, including the non-fixed point-to-point connection problem, the exact path partitioning problem and complex location-design problems. Moreover, for the prize-collecting traveling salesman or Steiner tree problems, we obtain 2-approximation algorithms, therefore improving the previously best-known performance guarantees of 2.5 and 3, respectively [  Math. Programming , 59 (1993), pp. 413--420]. },
journal = {SIAM J. Comput.},
month = apr,
pages = {296–317},
numpages = {22},
keywords = {traveling salesman problem, matching, combinatorial optimization, approximation algorithms, T-joins, Steiner tree problem}
}

@article{10.1137/S009753979225030X,
author = {Kapoor, Sanjiv and Ramesh, H.},
title = {Algorithms for Enumerating All Spanning Trees OfUndirected and Weighted Graphs},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979225030X},
doi = {10.1137/S009753979225030X},
abstract = {In this paper, we present algorithms for enumeration of spanning trees in undirected graphs, with and without weights.  The algorithms use a search tree technique to construct a computation tree. The computation tree can be used to output all spanning trees by outputting only relative changes between spanning trees rather than the entire spanning trees themselves. Both the construction of the computation tree and the listing of the trees is shown to require $O(N+V+E)$ operations for the case of undirected graphs without weights. The basic algorithm is based on swapping edges in a fundamental cycle. For the case of weighted graphs (undirected), we show that the nodes of the computation tree of spanning trees can be sorted in increasing order of weight, in $O(Nlog V+VE)$ time. The spanning trees themselves can be listed in $O(NV)$ time. Here $N$, $V$, and $E$ refer respectively to the number of spanning trees, vertices, and edges of the graph. },
journal = {SIAM J. Comput.},
month = apr,
pages = {247–265},
numpages = {19},
keywords = {undirected graph, spanning tree, enumeration, weighted graph}
}

@article{10.1137/S0097539792240406,
author = {Natarajan, B. K.},
title = {Sparse Approximate Solutions to Linear Systems},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240406},
doi = {10.1137/S0097539792240406},
abstract = {The following problem is considered: given a matrix $A$ in ${bf R}^{m times n}$, ($m$ rows and $n$ columns), a vector $b$ in ${bf R}^m$, and ${bf epsilon} &gt; 0$, compute a vector $x$ satisfying $| Ax - b |_2 leq {bf epsilon}$ if such exists, such that $x$ has the fewest number of non-zero entries over all such vectors. It is shown that the problem is NP-hard, but that the well-known greedy heuristic is good in that it computes a solution with at most $leftlceil 18  mbox{ Opt} ({bf epsilon}/2) |{bf A}^+|^2_2 ln(|b|_2/{bf epsilon}) rightrceil$ non-zero entries, where $mbox{Opt}({bf epsilon}/2)$ is the optimum number of nonzero entries at error ${bf epsilon}/2$, ${bf A}$ is the matrix obtained by normalizing each column of $A$ with respect to the $L_2$ norm, and ${bf A}^+$ is its pseudo-inverse.},
journal = {SIAM J. Comput.},
month = apr,
pages = {227–234},
numpages = {8},
keywords = {sparse solutions, linear systems}
}

@article{10.1137/S0097539792239291,
author = {Mansour, Yishay},
title = {Randomized Interpolation and Approximationof Sparse Polynomials},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792239291},
doi = {10.1137/S0097539792239291},
abstract = {We present a randomized algorithm that interpolates a sparse polynomial in polynomial time in the bit complexity model. The algorithm can be also applied to approximate polynomials that can be approximated by sparse polynomials (the approximation is in the $L_2$ norm).},
journal = {SIAM J. Comput.},
month = apr,
pages = {357–368},
numpages = {12},
keywords = {randomized algorithms, approximation, polynomial interpolation, harmonic analysis}
}

@article{10.1137/S0097539792238649,
author = {Fich, Faith E. and Munro, J. Ian and Poblete, Patricio V.},
title = {Permuting In Place},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792238649},
doi = {10.1137/S0097539792238649},
abstract = {This paper addresses the fundamental problem of permuting the elements of an array of $n$ elements according to some given permutation. Our goal is to perform the permutation quickly using only a polylogarithmic number of bits of extra storage. The main result is an algorithm whose worst case running time is $O(n log n)$ and that uses $O(log n )$ additional $log n$-bit words of memory. A simpler method is presented for the case in which both the permutation and its inverse can be computed at (amortised) unit cost. This algorithm requires $O(n log n)$ time and $O(1)$ words in the worst case. These results are extended to the situation in which we are to apply a power of the permutation. A linear time, $O(1)$ word method is presented for the special case in which the data values are all distinct and are either initially in sorted order or will be when permuted.},
journal = {SIAM J. Comput.},
month = apr,
pages = {266–278},
numpages = {13},
keywords = {space, in place, permutation, reordering}
}

@article{10.1137/S0097539792238133,
author = {Juedes, David W. and Lutz, Jack H.},
title = {The Complexity and Distribution of Hard Problems},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792238133},
doi = {10.1137/S0097539792238133},
abstract = {Measure-theoretic aspects of the $leq^{rm P}_{rm m}$-reducibility structure of the exponential time complexity classes E=DTIME($2^{rm linear}$) and $E_{2}={rm DTIME}(2^{rm polynomial})$ are investigated. Particular attention is given to the  complexity  (measured by the size of complexity cores) and  distribution  (abundance in the sense of measure) of languages that are $leq^{rm P}_{rm m}$-hard for E and other complexity classes.  Tight upper and lower bounds on the size of complexity cores of hard languages are derived. The upper bound says that the $leq^{rm P}_{rm m}$-hard languages for E are  unusually simple , in the sense that they have smaller complexity cores than most languages in E. It follows that the $leq^{rm P}_{rm m}$-complete languages for E form a measure 0 subset of E (and similarly in $E_2$).  This latter fact is seen to be a special case of a more general theorem, namely, that {it every} pmr-degree (e.g., the degree of all pmr-complete languages for NP) has measure 0 in E and in Ep. },
journal = {SIAM J. Comput.},
month = apr,
pages = {279–295},
numpages = {17},
keywords = {complexity classes, computational complexity, complexitycores, complete problems, polynomial reducibilities, resource-bounded measure}
}

@article{10.1137/S0097539792237784,
author = {Lakshman, Y. N. and Saunders, B. David},
title = {Sparse Polynomial Interpolation in Nonstandard Bases},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792237784},
doi = {10.1137/S0097539792237784},
abstract = {In this paper, we consider the  problem of interpolating univariate polynomials over a field of characteristic zero that are sparse  in (a) the  Pochhammer basis or, (b) the Chebyshev basis.  The polynomials are assumed to be given by black boxes, i.e., one can obtain the value of a polynomial at any point by querying its black box. We describe efficient new algorithms for these problems. Our algorithms may be regarded as generalizations of Ben-Or and Tiwari's (1988) algorithm (based on the BCH decoding algorithm) for interpolating polynomials  that are sparse in the standard basis. The arithmetic complexity of the algorithms is $O(t^2 + tlog d)$ which is also the complexity of the  univariate version of the Ben-Or and Tiwari algorithm.  That algorithm and  those presented here also share the requirement of $2t$ evaluation points.},
journal = {SIAM J. Comput.},
month = apr,
pages = {387–397},
numpages = {11},
keywords = {BCH codes, Pochhamer basis, Chebyshev polynomial, polynomial interpolation, sparsity}
}

@article{10.1137/S0097539792236882,
author = {Koren, Gilad and Shasha, Dennis},
title = {D<sup>over</sup>: An Optimal On-Line Scheduling Algorithm for Overloaded Uniprocessor Real-Time Systems},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792236882},
doi = {10.1137/S0097539792236882},
abstract = {Consider a real-time system in which every task has a value that it obtains only if it completes by its deadline. The problem is to design an on-line scheduling algorithm (i.e., the scheduler has no knowledge of a task until it is released) that maximizes the guaranteed value obtained by the system.  When such a system is underloaded (i.e., there exists a schedule for which all tasks meet their deadlines), Dertouzos [Proceedings IFIF Congress, 1974, pp. 807--813] showed that the earliest deadline first algorithm will achieve 100% of the possible value. Locke [Ph. D. thesis, Computer Science Dept., Carnegie-Mellon Univ., Pittsburgh, PA] showed that earliest deadline first performs very badly, however, when the system is overloaded, and he proposed heuristics to deal with overload.  This paper presents an optimal on-line scheduling algorithm for overloaded uniprocessor systems. It is optimal in the sense that it gives the best competitive ratio possible relative to an off-line scheduler. },
journal = {SIAM J. Comput.},
month = apr,
pages = {318–339},
numpages = {22},
keywords = {competitive, deadline, worst-case guarantee}
}

@article{10.1137/S0097539792226278,
author = {Delcher, A. L. and Kosaraju, S. Rao},
title = {An $\cal NC$ Algorithm for Evaluating Monotone Planar Circuits},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792226278},
doi = {10.1137/S0097539792226278},
abstract = {Goldschlager first established that a special case of the   monotone planar circuit problem can be solved by a Turing   machine in $O(log^2 n)$ space.  Subsequently, Dymond and Cook   refined the argument and proved that the same class can be   evaluated in $O(log^2 n)$ time with a polynomial number of   processors.  In this paper, we prove that the general monotone   planar circuit value problem can be evaluated in $O(log^4 n)$   time with a polynomial number of processors, settling an open   problem posed by Goldschlager and Parberry.},
journal = {SIAM J. Comput.},
month = apr,
pages = {369–375},
numpages = {7},
keywords = {monotone circuits, parallel algorithms, planar circuits}
}

@article{10.1137/S0097539791221529,
author = {Cheriyan, Joseph and Hagerup, Torben},
title = {A Randomized Maximum-Flow Algorithm},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791221529},
doi = {10.1137/S0097539791221529},
abstract = {A randomized algorithm for computing a maximum flow is presented. For an $n$-vertex $m$-edge network, the running time is $O(nm + n^2(log n)^2)$ with probability at least $1 - 2^{-sqrt{nm}}$. The algorithm is always correct, and in the worst case runs in $O(nm log n)$ time. The only use of randomization is to randomly permute the adjacency lists of the network vertices at the start of the execution.  The analysis introduces the notion of premature target relabeling (PTR) events and shows that each PTR event contributes $O(log n)$ amortized time to the overall running time. The number of PTR events is always $O(nm)$; however, it is shown that when the adjacency lists are randomly permuted, then this quantity is $O(n^{3/2}m^{1/2} + n^2 log n)$ with high probability. },
journal = {SIAM J. Comput.},
month = apr,
pages = {203–226},
numpages = {24},
keywords = {Fibonacci heap, maximum flow, dynamic tree, randomized algorithm, random permutations, scaling}
}

@article{10.1137/S0097539791218202,
author = {Kilpelainen, Pekka and Mannila, Heikki},
title = {Ordered and Unordered Tree Inclusion},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791218202},
doi = {10.1137/S0097539791218202},
abstract = {The following tree-matching problem is considered: Given labeled trees $P$ and $T$, can $P$ be obtained from  $T$ by deleting nodes? Deleting a node $u$ entails removing all edges incident to $u$ and, if $u$ has a parent $v$, replacing the  edge from $v$ to $u$ by edges from $v$ to the children of $u$. The problem is motivated by the study of query languages for structured text databases. Simple solutions to this problem require exponential time. For ordered trees an algorithm is presented that requires $O(|P| |T|)$ time and space. The corresponding problem for unordered trees is also  considered and a proof of its NP-completeness is given. An algorithm is presented for the unordered problem. This algorithm works in $O(|P| |T|)$ time if  the out-degrees of the nodes in $P$ are bounded by a constant, and in polynomial time if they are $O(log |T|)$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {340–356},
numpages = {17},
keywords = {pattern matching, trees, NP-completeness, dynamic programming}
}

@article{10.1137/S0097539791194999,
author = {Chor, Benny and Gereb-Graus, Mihaly and Kushilevitz, Eyal},
title = {Private Computations Over the Integers},
year = {1995},
issue_date = {April 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791194999},
doi = {10.1137/S0097539791194999},
abstract = {The subject of this work is the possibility of private distributed computations of $n$-argument functions defined over the integers. A function $f$ is $t$-private if there exists a protocol for computing $f$, so that no coalition of at most $t$ participants can infer any additional information from the execution of the protocol. It is known that over  finite  domains, every function can be computed $leftlfloor{(n-1)/2}rightrfloor$-privately. Some functions, like addition, are even $n$-private.  We prove that this result cannot be extended to infinite domains. The possibility of privately computing $f$ is shown to be closely related to the  communication complexity  of $f$. Using this relation, we show, for example, that $n$-argument addition is $leftlfloor{(n-1)/2}rightrfloor$-private over the nonnegative integers, but not even $1$-private over all the integers.  Finally, a complete characterization of $t$-private  Boolean  functions over countable domains is given. A Boolean function is $1$-private if and only if its communication complexity is  bounded . This characterization enables us to prove that every Boolean function falls into one of the following three categories: It is either $n$-private, $leftlfloor{(n-1)/2}rightrfloor$-private but not $leftlceil{n/2}rightrceil $-private, or not $1$-private. },
journal = {SIAM J. Comput.},
month = apr,
pages = {376–386},
numpages = {11},
keywords = {communication complexity, private distributed computations}
}

@article{10.1137/S0097539793245829,
author = {Cole, Richard and Hariharan, Ramesh and Paterson, Mike and Zwick, Uri},
title = {Tighter Lower Bounds on the Exact Complexity of String Matching},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793245829},
doi = {10.1137/S0097539793245829},
abstract = {This paper considers the exact number of character comparisons needed to  find all occurrences of a pattern of length $m$ in a text of length $n$ using on-line and general algorithms. For on-line algorithms, a lower bound of about  $(1+frac{9}{4(m+1)})cdot n$ character comparisons is obtained. For general algorithms, a lower bound of about $(1+frac{2}{m+3})cdot n$ character comparisons is obtained. These lower bounds complement an on-line upper bound  of about $(1+frac{8}{3(m+1)})cdot n$ comparisons obtained recently by Cole and Hariharan.  The lower bounds are obtained by finding patterns with interesting combinatorial properties. It is also shown that for some patterns off-line algorithms can be more efficient than on-line algorithms.},
journal = {SIAM J. Comput.},
month = feb,
pages = {30–45},
numpages = {16},
keywords = {string matching, pattern matching, lower bounds, complexity, comparisons}
}

@article{10.1137/S0097539792251730,
author = {Saran, Huzur and Vazirani, Vijay V.},
title = {Finding $k$ Cuts within Twice the Optimal},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792251730},
doi = {10.1137/S0097539792251730},
abstract = {Two simple approximation algorithms for the minimum $k$-cut problem are presented.  Each algorithm finds a $k$ cut having weight within a factor of $(2-2/k)$ of the optimal. One of our algorithms is particularly efficient---it requires a total of  only $n-1$ maximum flow computations for finding a set of near-optimal $k$ cuts, one for each value of $k$ between 2 and $n$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {101–108},
numpages = {8},
keywords = {approximation algorithms, minimum cuts, graph partitioning}
}

@article{10.1137/S0097539792240625,
author = {Ibarra, Oscar H. and Jiang, Tao and Tran, Nicholas and Wang, Hui},
title = {New Decidability Results Concerning Two-Way Counter Machines},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240625},
doi = {10.1137/S0097539792240625},
abstract = {The authors study some decision questions concerning two-way counter machines and obtain the strongest decidable results to date concerning these machines.  In particular, it is shown that the emptiness, containment, and equivalence (ECE, for short) problems are  decidable for two-way counter machines whose counter is reversal-bounded (i.e., the counter alternates between increasing and decreasing modes at most a fixed number of times). This result is used to give a simpler proof of a recent result in which the ECE problems for two-way reversal-bounded pushdown automata accepting  bounded languages (i.e., subsets of $w_1^*ldots w_k^*$ for some nonnull words $w_1,ldots,w_k$) are decidable. Other applications concern decision questions about simple programs. Finally, it is shown that nondeterministic two-way reversal-bounded multicounter machines are effectively equivalent to finite automata on unary languages, and hence their ECE problems are decidable also.},
journal = {SIAM J. Comput.},
month = feb,
pages = {123–137},
numpages = {15},
keywords = {emptiness problem, simple programs, pushdown automata, decidability, counter machines}
}

@article{10.1137/S0097539792237462,
author = {Naor, Moni and Roth, Ron M.},
title = {Optimal File Sharing in Distributed Networks},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792237462},
doi = {10.1137/S0097539792237462},
abstract = {The following file distribution problem is considered: Given  a network of processors represented by an undirected graph  $G=(V,E)$ and a file size $k$, an arbitrary file w  of $k$ bits is to be distributed among all nodes of $G$. To  this end, each node is assigned a memory device such that by  accessing the memory of its own and of its adjacent nodes,  the node can reconstruct the contents of w. The  objective is to minimize the total size of memory in the  network. This paper presents a file distribution scheme  which realizes this objective for $k gg log Delta_G$,  where $Delta_G$ stands for the maximum degree in $G$: For  this range of $k$, the total memory size required by the  suggested scheme approaches an integer programming lower  bound on that size. The scheme is also constructive in the  sense that given $G$ and $k$, the memory size at each node  in $G$, as well as the mapping of any file w into the  node memory devices, can be computed in time complexity  which is polynomial in $k$ and $|V|$. Furthermore, each node  can reconstruct the contents of such a file w in  $O(k^2)$ bit operations. Finally, it is shown that the  requirement of $k$ being much larger than $log Delta_G$ is  necessary in order to have total memory size close to the  integer programming lower bound.},
journal = {SIAM J. Comput.},
month = feb,
pages = {158–183},
numpages = {26},
keywords = {linear programming, distributed networks, probabilistic algorithms, file assignment, resource sharing, integer programming, set cover, linear codes, derandomization}
}

@article{10.1137/S0097539792232070,
author = {Blass, Andreas and Gurevich, Yuri},
title = {Matrix Transformation is Complete for the Average Case},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792232070},
doi = {10.1137/S0097539792232070},
abstract = {In the theory of worst case complexity, NP completeness is used to establish that, for all practical purposes, the given NP problem is not decidable in polynomial time.  In the theory of average case complexity, average case completeness is supposed to play the role of NP completeness.  However, the average case reduction theory is still at an early stage, and only a few average case complete problems are known.  We present the first algebraic problem complete for the average case under a natural probability distribution.  The problem is this: Given a unimodular matrix $X$ of integers, a set $S$ of linear transformations of such unimodular matrices and a natural number $n$, decide if there is a product of $leq n$ (not necessarily different) members of $S$ that takes $X$ to the identity matrix.},
journal = {SIAM J. Comput.},
month = feb,
pages = {3–29},
numpages = {27},
keywords = {average case, reduction, decision problems, unimodular matrices, randomization.}
}

@article{10.1137/S009753979223037X,
author = {Zhang, Yanjun},
title = {On the Optimality of Randomized $\alpha$-$\beta$ Search},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223037X},
doi = {10.1137/S009753979223037X},
abstract = {It was shown that the expected number  of leaves evaluated by randomized $alpha - beta$ search for evaluating uniform  game trees of degree $d$ and height $h$ is $O((B_d)^h)$ where $B_d = d/2+ln d+O(1)$.  It was shown by Saks and  Wigderson [Proceedings of  27th Annual Symposium on Foundations of Computer Science (1986), pp. 29-38] that  the optimal branching factor of randomized algorithms for evaluating uniform trees of degree $d$ is $B^{ast}_d= (d-1+sqrt{d^2+14d+1},)/4= d/2+O(1)$.  As $B_d/B^{ast}_d=1+O(ln d/d)$, randomized $alpha$-$beta$ search is asymptotically optimal for evaluating uniform game trees as the degree of tree increases.},
journal = {SIAM J. Comput.},
month = feb,
pages = {138–147},
numpages = {10},
keywords = {randomized algorithms, $alpha$-$beta$ search, game-tree evaluation}
}

@article{10.1137/S0097539792227077,
author = {Kao, Ming-Yang},
title = {Planar Strong Connectivity Helps in Parallel Depth-First Search},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792227077},
doi = {10.1137/S0097539792227077},
abstract = {This paper proves that for a strongly connected planar directed graph of size $n$, a depth-first search tree rooted at a specified vertex can be computed in $O(log^{5}n)$ time with $n/log{n}$ processors.  Previously, for planar directed graphs that may not be strongly connected, the best depth-first search algorithm runs in $O(log^{10}n)$ time with $n$ processors.  Both algorithms run on a parallel random access machine that allows concurrent reads and concurrent writes in its shared memory, and in case of a write conflict, permits an arbitrary processor to succeed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {46–62},
numpages = {17},
keywords = {planar directed graphs, depth-first search, linear-processor NC algorithms, bubblegraphs, strong connectivity, $s$-$t$ graphs, graph separators}
}

@article{10.1137/S0097539792225303,
author = {Bonet, Maria Luisa and Buss, Samuel R.},
title = {The Serial Transitive Closure Problem for Trees},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792225303},
doi = {10.1137/S0097539792225303},
abstract = {The serial transitive closure problem is the problem of, given a directed graph $G$ and a list of  edges, called closure edges, which are in the transitive closure of the graph, to generate all the closure edges from edges in $G$.   A nearly linear upper bound is given on the number of steps in optimal solutions to the serial transitive closure problem for the case of  graphs which are trees.  "Nearly linear" means $O(ncdot alpha(n))$ where $alpha$ is the inverse Ackermann function.  This upper bound is optimal to within a constant factor.},
journal = {SIAM J. Comput.},
month = feb,
pages = {109–122},
numpages = {14},
keywords = {graph algorithm, inverse Ackermannfunction, weak superconcentrators, transitive closure}
}

@article{10.1137/S0097539792224474,
author = {Alon, Noga and Karp, Richard M. and Peleg, David and West, Douglas},
title = {A Graph-Theoretic Game and Its Application to the $k$-Server Problem},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792224474},
doi = {10.1137/S0097539792224474},
abstract = {This paper investigates a zero-sum game played on a weighted connected graph $G$ between two players, the  tree player  and the  edge player . At each play, the tree player chooses a spanning tree $T$ and the edge player chooses an edge $e$. The payoff to the edge player is $cost(T,e)$, defined as follows: If $e$ lies in the tree $T$ then $cost(T,e)=0$; if $e$ does not lie in the tree then $cost(T,e) = cycle(T,e)/w(e)$, where $w(e)$ is the weight of edge $e$ and $cycle(T,e)$ is the weight of the unique cycle formed when edge $e$ is added to the tree $T$. The main result is that the value of the game on any $n$-vertex graph is bounded above by $exp(O(sqrt{log n loglog n}))$. It is conjectured that the value of the game is $O(log n)$.  The game arises in connection with the $k$-server problem on a  road network ; i.e., a metric space that can be represented as a multigraph $G$ in which each edge $e$ represents a road of length $w(e)$. It is shown that, if the value of the game on $G$ is $Val(G,w)$, then there is a randomized strategy that achieves a competitive ratio of $k(1 + Val(G,w))$ against any oblivious adversary. Thus, on any $n$-vertex road network, there is a randomized algorithm for the $k$-server problem that is $kcdotexp(O(sqrt{log n loglog n}))$ competitive against oblivious adversaries.  At the heart of the analysis of the game is an algorithm that provides an approximate solution for the  simple network design problem . Specifically, for any $n$-vertex weighted, connected multigraph, the algorithm constructs a spanning tree $T$ such that the average, over all edges $e$, of $cost(T,e)$ is less than or equal to $exp(O(sqrt{log n loglog n}))$. This result has potential application to the design of communication networks. It also improves substantially known estimates concerning the existence of a sparse basis for the cycle space of a graph. },
journal = {SIAM J. Comput.},
month = feb,
pages = {78–100},
numpages = {23},
keywords = {spanners, servers, spanning trees, average stretch}
}

@article{10.1137/S0097539791221505,
author = {Heffernan, Paul J. and Mitchell, Joseph S. B.},
title = {An Optimal Algorithm for Computing Visibility in the Plane},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791221505},
doi = {10.1137/S0097539791221505},
abstract = {The authors give an algorithm to compute the visibility polygon from a point among a set of $h$ pairwise-disjoint polygonal obstacles with a total of $n$ vertices.  Our algorithm uses $O(n)$ space and runs in optimal time $Theta(n+hlog h)$, improving the previous upper bound of $O(nlog n)$.  A direct consequence of the algorithm is an $O(n+hlog h)$ time algorithm for computing the convex hull of $h$ disjoint simple polygons.},
journal = {SIAM J. Comput.},
month = feb,
pages = {184–201},
numpages = {18},
keywords = {lower envelopes, computational geometry, visibility, hidden line elimination}
}

@article{10.1137/S0097539791217695,
author = {Cidon, Israel and Kutten, Shay and Mansour, Yishay and Peleg, David},
title = {Greedy Packet Scheduling},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791217695},
doi = {10.1137/S0097539791217695},
abstract = {Scheduling packets to be forwarded over a link is an important subtask of the routing process in  both parallel computing and in communication networks. This paper investigates the simple class of greedy scheduling algorithms, namely, algorithms that always forward a packet if they can. It is first proved that for various "natural" classes of routes, the time required to complete the transmission of a set of packets is bounded by the number of packets, $k$, and the maximal route length, $d$, for any greedy algorithm (including the arbitrary scheduling policy). Next, tight time bounds of $d+k-1$ are proved for a specific greedy algorithm on the class of shortest paths in $n$-vertex networks. Finally, it is shown that when the routes are arbitrary, the time achieved by various "natural" greedy algorithms can be as bad as $Omega(d sqrt{k} + k)$, for any $k$, and even for $d=Omega(n)$.},
journal = {SIAM J. Comput.},
month = feb,
pages = {148–157},
numpages = {10},
keywords = {parallel computing, shortest paths, communication networks, routing}
}

@article{10.1137/S0097539791201903,
author = {Bini, Dario and Gemignani, Luca},
title = {Fast Parallel Computation of the Polynomial Remainder Sequence Via Bezout and Hankel Matrices},
year = {1995},
issue_date = {Feb. 1995},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {24},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791201903},
doi = {10.1137/S0097539791201903},
abstract = {If $u(x)$ and $v(x)$ are polynomials of degree $n$ and $m$, respectively, $m &lt; n$, all the coefficients of the polynomials generated by the Euclidean scheme applied to $u(x)$ and $v(x)$ can be computed by using $O(log^3 n)$ parallel arithmetic steps and $n^2/log n$ processors over any field  of characteristic 0 supporting FFT (Fast Fourier Transform). If the field does not support FFT the number of processors is increased by a factor of $loglog n$; if the field does not allow division by $n!$  the number of processors is increased by a factor of $n$.  This result is obtained by reducing the Euclidean scheme to computing the block triangular factorization of the Bezout matrix associated with  $u(x)$ and $v(x)$. This approach is also extended to the evaluation of polynomial gcd (greatest common divisor) over any field of constants in $O(log^2 n)$ steps with the same number of processors.},
journal = {SIAM J. Comput.},
month = feb,
pages = {63–77},
numpages = {15},
keywords = {computational complexity, Euclidean scheme, parallel algorithms, greatest common divisor, Hankel and Bezout matrices}
}

@article{10.1137/S0097539793251876,
author = {Hochbaum, Dorit S.},
title = {Simple and Fast Algorithms for Linear and Integer Programs with Two Variables Per Inequality},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793251876},
doi = {10.1137/S0097539793251876},
abstract = {The authors present an $O(mn^2 log m)$ algorithm for  solving feasibility in linear programs with up to two  variables per inequality which is derived directly from the  Fourier--Motzkin elimination method. (The number of  variables and inequalities are denoted by $n$ and $m$,  respectively.) The running time of the algorithm dominates that of the best known algorithm for the problem, and is far  simpler. Integer programming on monotone inequalities, i.e.,  inequalities where the coefficients are of opposite sign, is then considered. This problem includes as a special case the simultaneous approximation of a rational vector with  specified accuracy, which is known to be NP-complete.  However, it is shown that both a feasible solution and an  optimal solution with respect to an arbitrary objective  function can be computed in pseudo-polynomial time.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1179–1192},
numpages = {14},
keywords = {integer programming, linear programming}
}

@article{10.1137/S0097539793244587,
author = {Agarwala, Richa and Fernandez-Baca, David},
title = {A Polynomial-Time Algorithm for the Perfect Phylogeny Problem When the Number of Character States is Fixed},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793244587},
doi = {10.1137/S0097539793244587},
abstract = {This paper presents a polynomial-time algorithm for determining whether a set of species, described by the characters they exhibit, has a perfect phylogeny, assuming the maximum number of possible states for a character is fixed. This solves a longstanding open problem. This result should be contrasted with the proof by Steel [J. Classification, 9(1992), pp. 91--116] and Bodlaender, Fellows, and Warnow [Proceedings of the19th International Colloquium on Automata, Languages, and Programming, Lecture Notes in Computer Science, 1992, pp. 273--283] that the perfect phylogeny problem is NP complete in general.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1216–1224},
numpages = {9},
keywords = {perfect phylogeny, evolution, algorithms, character compatibility}
}

@article{10.1137/S0097539793238140,
author = {Book, Ronald V.},
title = {On Languages Reducible to Algorithmically RandomLanguages},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793238140},
doi = {10.1137/S0097539793238140},
abstract = {In this paper languages "bounded reducible" to  algorithmically random languages  are studied; these are the languages whose characteristic sequences are algorithmically random (as defined by Martin-L\"{o}f [  Inform. and Control , 9 (1966), pp. 602--619]); here RAND denotes the class of algorithmically random languages. The reducibilities $le^{cal R}$ are very general but are defined so that if $AinR(B)$, then there is a machine $M$ with the properties that $L(M,B)=A$ and every computation of $M$ relative to any oracle halts.  Book, Lutz, and Wagner [  Math. Systems Theory , 27 (1994), pp.~201--209] studied {sf ALMOST}-$R$, defined to be ${Amid$ for almost every $B, Ale_{cal R} B}$. They showed that {sf ALMOST}-$R=R(RAND)caprec$, where $rec$ denotes the class of recursive languages, so that {sf ALMOST}-$R$ is the "recursive part" of $R(RAND)$. In this paper this characterization is strengthened by showing that for  every  $Bin RAND$, {sf ALMOST}-$R=R(B)caprec$. A pair $(A,B)$ of languages is an  independent pair  of algorithmically random languages if $Aoplus Bin RAND$. In this paper it is shown that for every $R$ and for every independent pair $(A,B)$, {sf ALMOST}-$R=R(A)capR(B)$. },
journal = {SIAM J. Comput.},
month = dec,
pages = {1275–1282},
numpages = {8},
keywords = {reducibilities, complexity classes, algorithmically random oracles, characterization theorems, independent pairs}
}

@article{10.1137/S0097539792240893,
author = {SIAM Staff},
title = {Priority Queues and Permutations},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792240893},
doi = {10.1137/S0097539792240893},
abstract = {A priority queue transforms an input permutation $sigma$ of some set of size $n$ into an output permutation $tau$.  The set $R_n$ of such related pairs $(sigma,tau)$ is studied.  Efficient algorithms for determining $s(tau)=|{sigma:(sigma,tau)in R_n}|$ and $t(sigma)=|{tau:(sigma,tau)in R_n}|$ are given, a new proof that $|R_n|=(n+1)^{n-1}$ is given, and the transitive closure of $R_n$ is found.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1225–1230},
numpages = {6},
keywords = {priority queue, permutation, enumeration}
}

@article{10.1137/S009753979223277X,
author = {Afek, Yehuda and Gafni, Eli},
title = {Distributed Algorithms for Unidirectional Networks},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223277X},
doi = {10.1137/S009753979223277X},
abstract = {This paper addresses the question of distributively computing over a strongly connected unidirectional data communication network. In unidirectional networks the existence of a communication link from one node to another does not imply the existence of a link in the opposite direction. The strong connectivity means that from every node there is a directed path to any other node. The authors assume an arbitrary topology network in which the strong connectivity is the only restriction. Four models are considered, synchronous and asynchronous, and for each node space availability, which grows as either $O(1)$ bits or $O(log n)$ bits per incident link, where $n$ is the total number of nodes in the network, is considered.  First algorithms for two basic problems in distributed computing in data communication networks,  traversal , and  election , are provided. Each of these basic protocols produces two directed spanning trees rooted at a distinguished node in the network, one called  in-tree , leading to the root, and the other,  out-tree , leading from the root. Given these trees, the authors efficiently transform bidirectional algorithms to run on unidirectional networks, and in particular solve other problems such as the broadcast and echo [E. J. Chang],  Decentralized Algorithms in Distributed Systems , Ph. D. thesis, University of Toronto, October 1979] in a way that is more efficient ($O(n^2)$ messages) than direct transformation (which yields $O(nm)$ messages algorithm). The communication cost of the traversal and election algorithms is $O(nm+ n^2 log n)$ bits ($O(nm)$ messages and time), where $m$ is the total number of links in the network. The traversal algorithms for unidirectional networks of finite automata achieve the same cost ($O(nm+n^2 log n)$ bits) in the asynchronous case, while in the synchronous case the communication cost of the algorithm is $O(mn)$ bits. },
journal = {SIAM J. Comput.},
month = dec,
pages = {1152–1178},
numpages = {27},
keywords = {traversal, distributed algorithms, election, unidirectional}
}

@article{10.1137/S0097539792231830,
author = {Cypher, Robert and Gravano, Luis},
title = {Requirements for Deadlock-Free, Adaptive PacketRouting},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792231830},
doi = {10.1137/S0097539792231830},
abstract = {This paper studies the problem of deadlock-free packet routing in parallel and distributed architectures.  Three main results are presented. First, it is shown that the standard technique of ordering the buffers so that every packet always has the possibility of moving to a higher-ordered buffer is not necessary for deadlock freedom. Second, it is shown that every deadlock-free, adaptive packet routing  algorithm can be restricted, by limiting the adaptivity available, to obtain  an oblivious algorithm which is also deadlock-free. Third, it is shown that any packet routing algorithm for a cycle or torus network which is free of deadlock and which uses only minimal length paths must require at least three buffers in some node. This matches the known upper bound of three buffers per node for  deadlock-free, minimal packet routing on cycle and torus networks.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1266–1274},
numpages = {9},
keywords = {parallel algorithms, networks, deadlock, packet routing, lower bounds, store-and-forward routing, buffer requirements, adaptive routing}
}

@article{10.1137/S0097539792231167,
author = {Larmore, Lawrence L. and Przytycka, Teresa M.},
title = {A Fast Algorithm for Optimum Height-Limited Alphabetic Binary Trees},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792231167},
doi = {10.1137/S0097539792231167},
abstract = {In this paper, an $O(nLlog n)$-time algorithm is presented for construction of an optimal alphabetic binary tree with height restricted to $L$. This algorithm is an alphabetic version of the Package Merge algorithm, and yields an $O(nLlog n)$-time algorithm for the alphabetic Huffman coding problem. The Alphabetic Package Merge algorithm is quite simple to describe, but appears hard to prove correct.  Garey [  SIAM J. Comput ., 3 (1974), pp. 101--110] gives an $O(n^3log n)$-time algorithm for the height-limited alphabetic binary tree problem. Itai [  SIAM J. Comput ., 5 (1976), pp. 9--18] and Wessner [  Inform. Process. Lett ., 4 (1976), pp. 90--94] independently reduce this time to $O(n^2L)$ for the alphabetic problem. In [  SIAM J. Comput ., 16 (1987), pp. 1115--1123], a rather complex $O(n^{3/2}Llog ^{1/2}n)$-time "hybrid" algorithm is given for length-limited Huffman coding. The Package Merge algorithm, discussed in this paper, first appeared in [  Tech. Report , 88-01, ICS Dept. Univ. of California, Irvine, CA], but without proof of correctness. },
journal = {SIAM J. Comput.},
month = dec,
pages = {1283–1312},
numpages = {30},
keywords = {optimal tree, weighted binary tree}
}

@article{10.1137/S0097539792230277,
author = {Chaudhuri, Shiva},
title = {Tight Bounds on Oblivious Chaining},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792230277},
doi = {10.1137/S0097539792230277},
abstract = {The chaining problem is defined as follows. Given values $a_{1},ldots,a_{n},,a_{i} = 0$ or 1, $1 leq i leq n$, compute  $b_{1},ldots,b_{n}$ such that $b_{i} = max{j mid a_{j} = 1,, j &lt; i }$. (Define $max{} = 0.$) The chaining problem appears as a subproblem in many contexts. There are known algorithms that solve the chaining problem on CRCW PRAMs in $O(alpha(n))$ time, where $alpha(n)$ is the inverse of Ackerman's function, and is a very slowly growing function. The author studies a  class of algorithms (called oblivious algorithms) for this problem.  A simple oblivious chaining algorithm running in $O(alpha(n))$ time is presented. More importantly, the optimality of the algorithm is demonstrated by showing a matching lower  bound for oblivious algorithms using $n$ processors. The first  steps toward a lower bound for all chaining algorithms  are also provided by showing that any chaining algorithm that  runs in two steps must use a superlinear number of processors.  The proofs use prefix graphs and  weak superconcentrators.  An interesting connection  between the two is demonstrated and this idea is used to obtain improved bounds on the size of prefix graphs.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1253–1265},
numpages = {13},
keywords = {superconcentrators, parallel, lower bound, prefix graphs, Ackerman's function, chaining}
}

@article{10.1137/S0097539791256325,
author = {Cohen, Edith and Megiddo, Nimrod},
title = {Improved Algorithms for Linear Inequalities with Two Variables per Inequality},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791256325},
doi = {10.1137/S0097539791256325},
abstract = {The authors show that a system of $m$ linear inequalities with $n$ variables, where each inequality involves at most two variables, can be solved in $tilde{O}(mn^2)$ time (we denote $tilde{O}(f)=O(fpolylog npolylog m))$   deterministically, and in $tilde{O}(n^3+mn)$ expected time using randomization. Parallel implementations of these algorithms run in $tilde{O}(n)$ time, where the deterministic algorithm uses $tilde{O}(mn)$ processors and the randomized algorithm uses  $tilde{O}(n^2+m)$ processors. The bounds significantly improve over previous algorithms.  The randomized algorithm is based on novel insights into the structure of the problem.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1313–1350},
numpages = {38},
keywords = {linear inequalities, linear programming, strongly polynomial algorithms, two-variables inequalities, linear systems}
}

@article{10.1137/S0097539791219670,
author = {Nishimura, Naomi},
title = {A Model for Asynchronous Shared Memory Parallel Computation},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791219670},
doi = {10.1137/S0097539791219670},
abstract = {Traditional theoretical shared memory parallel models have been based on a number of assumptions which simultaneously simplify solutions to problems and distance the models from actual parallel machines.  One such assumption is that processors work together in a synchronous fashion.  Recent work has focused on finding a model that captures the essence of computation by processors communicating asynchronously through shared memory.  In this paper, a general framework and set of criteria used to analyze these models, including the complexity analysis of several fundamental algorithmic paradigms,  are considered. A general asynchronous model is introduced and how it   satisfies these criteria is demonstrated.  In this model, $O(log p)$ algorithms are demonstrated for solving $p$-input versions of the  problems of AND, OR, parity, maximum, minimum, and list ranking.   To handle list ranking, a technique of analyzing algorithms is  developed in which the set of tasks that are to be executed depends  on the processor schedules.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1231–1252},
numpages = {22},
keywords = {models of parallel computation, parallel algorithms, asynchrony, parallel computation, computational complexity}
}

@article{10.1137/S0097539791216987,
author = {Kim, Sam M. and McNaughton, Robert},
title = {Computing the Order of a Locally Testable Automaton},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791216987},
doi = {10.1137/S0097539791216987},
abstract = {A locally testable language is a language with the property  that, for some positive integer $j$, whether or not a string  $x$ is in the language depends on (1) the prefix and suffix  of $x$ of length $j - 1$, and (2) the set of substrings of x  of length $j$, without regard to the order in which these  substrings occur or the number of times each substring  occurs. For any $j$ for which this is true, it is said that  the language is $j$-testable. For a given locally  testable language, the smallest such number $j$ is called  the order of the language. Locally testable  languages are regular and therefore these concepts apply to  the finite automata that recognize the languages. The  authors show that computing the order of a given locally  testable deterministic automaton is NP-hard and present  a polynomial-time $epsilon$-approximation algorithm for  computing it. In addition, an upper bound of $2n^2 +1$ on  the order of a locally testable automaton of $n$ states is  obtained, and the co-NP-completeness of the problem of  whether, for a given $j$, a given deterministic automaton is  $j$-testable is proven.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1193–1215},
numpages = {23},
keywords = {regular language, local testability, algorithm, NP-hard, finite state automaton}
}

@article{10.1137/S0097539790188168,
author = {Gyssens, Marc and Paredaens, Jan and Van Gucht, Dirk},
title = {A Grammar-Based Approach Towards Unifying Hierarchical Data Models},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790188168},
doi = {10.1137/S0097539790188168},
abstract = {A simple model for representing the hierarchical structure of information is proposed. This model, called the grammatical model, is based on trees that are generated by grammars; the grammars describe the hierarchy of the information represented by the trees. Two methods for querying in this data model are given. The first, called the grammatical algebra, is based on a set of primitive grammar-oriented operators, the second, called the grammatical calculus, on local transformations on the trees. The semantics of both is formally defined. Decidability issues regarding the grammatical calculus are investigated. Finally, the two querying methods are proved to be equally expressive.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1093–1137},
numpages = {45},
keywords = {information base, trees, algebra, grammars, transformations, calculusendkeywords}
}

@article{10.1137/S0097539790179919,
author = {Chazelle, Bernard and Edelsbrunner, Herbert and Guibas, Leonidas J. and Hershberger, John E. and Seidel, Raimund and Sharir, Micha},
title = {Selecting Heavily Covered Points},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790179919},
doi = {10.1137/S0097539790179919},
abstract = {A collection of geometric selection lemmas is proved, such as the following: For any set $P$ of $n$ points in  three-dimensional space and any set ${cal S}$ of $m$ spheres, where each sphere passes through a distinct point pair in  $P$, there exists a point $x$, not necessarily in $P$, that  is enclosed by $Omega (m^2/(n^2 log^6 {n^2 over m}))$ of  the spheres in ${cal S}$. Similar results apply in  arbitrary fixed dimensions, and for geometric bodies other  than spheres. The results have applications in reducing the  size of geometric structures, such as three-dimensional  Delaunay triangulations and Gabriel graphs, by adding extra  points to their defining sets.},
journal = {SIAM J. Comput.},
month = dec,
pages = {1138–1151},
numpages = {14},
keywords = {covering, Gabriel graphs, Delaunay triangulations, intervals, finite-element meshes, computational geometry, selecting points, boxes, spheres, discrete geometry}
}

@article{10.1137/S0097539793246690,
author = {Du, Ding-Zhu and Park, Haesun},
title = {On Competitive Group Testing},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793246690},
doi = {10.1137/S0097539793246690},
abstract = {In many fault detection problems, the goal is to identify defective items from a set of items with a minimum number of tests. Each test is on a subset of items, which tells whether the subset contains a defective item or not.  The concept of competitive algorithm has been developed to relate the properties of the group testing algorithms that assume that the number of defective items $d$ is known, to those without any a priori knowledge on $d$.  A new concept of strongly competitive algorithm is defined that relates different characteristics of these two classes of algorithms and present an interesting relationship between the two concepts competitive and strongly competitive. A strongly competitive algorithm is also presented.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1019–1025},
numpages = {7},
keywords = {group testing, competitive algorithm, strongly competitive algorithm, fault detection}
}

@article{10.1137/S0097539792235712,
author = {Pan, V. Y.},
title = {New Resultant Inequalities and Complex Polynomial Factorization},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235712},
doi = {10.1137/S0097539792235712},
abstract = {The author deduces some new probabilistic estimates on the distances between the zeros of a polynomial $p(x)$ by using some properties of the discriminant of $p(x)$ and applies these estimates to improve the fastest deterministic algorithm for approximating polynomial factorization over the complex field. Namely, given a natural $n$, positive $epsilon$, such that $log (1/epsilon) = O(nlog n)$, and the complex coefficients of a polynomial $p(x)=sum^n_{i=0} p_ix^i$, such that $p_nne 0$, $sum _i |p_i| le 1$, a factorization of $p(x)$ (within the error norm $epsilon$) is computed as a product of factors of degrees at most $n/2$, by using $O(log^2n)$ time and $n^3$ processors under the PRAM arithmetic model of parallel computing or by using $O(n^2log^2 n)$ arithmetic operations. The algorithm is randomized, of Las Vegas type, allowing a failure with a probability at most $delta$, for any positive $delta &lt; 1$ such that $log (1/delta) = O(log n)$.  Except for a narrow class of polynomials $p(x)$, these results can be also obtained for $epsilon$ such that $log(1/epsilon) =O(n^2log n)$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {934–950},
numpages = {17},
keywords = {randomized algorithms, complex polynomial factorization, computational complexity, resultant}
}

@article{10.1137/S009753979223455X,
author = {Blum, Avrim L.},
title = {Separating Distribution-Free and Mistake-Bound Learning Models over the Boolean Domain},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223455X},
doi = {10.1137/S009753979223455X},
abstract = {Two of the most commonly used models in computational learning theory are the distribution-free model in which examples are chosen from a fixed but arbitrary distribution, and the absolute mistake-bound model in which examples are presented in an arbitrary order. Over the Boolean domain ${0,1}^n$, it is known that if the learner is allowed unlimited computational resources then any concept class learnable in one model is also learnable in the other. In addition, any polynomial-time learning algorithm for a concept class in the mistake-bound model can be transformed into one that learns the class in the distribution-free model.  This paper shows that if one-way functions exist, then the mistake-bound model is strictly harder than the distribution-free model for polynomial-time learning. Specifically, given a one-way function, it is shown how to create a concept class over ${0,1}^n$ that is learnable in polynomial time in the distribution-free model, but not in the absolute mistake-bound model. In addition, the concept class remains hard to learn in the mistake-bound model even if the learner is allowed a polynomial number of membership queries.  The concepts considered are based upon the Goldreich, Goldwasser, and Micali random function construction [Goldreich, Goldwasser, and Micali,  Journal ACM , 33 (1986), pp. 792--807] and involve creating the following new cryptographic object: an exponentially long sequence of strings $sigma_1, sigma_2, ldots, sigma_r$ over ${0,1}^n$ that is hard to compute in one direction (given $sigma_i$ one cannot compute $sigma_j$ for $j &lt; i$) but is easy to compute and even make random-access jumps in the other direction (given $sigma_i$ and $j&gt;i$ one can compute $sigma_j$, even if $j$ is exponentially larger than $i$). Similar sequences considered previously [Blum, Blum, and Shub,  SIAM J. Comput. , 15 (1986), pp. 364--383], [Blum and Micali,  SIAM J. Comput. , 13 (1984), pp. 850--863] did not allow random-access jumps forward without knowledge of a seed allowing one to compute backwards as well. },
journal = {SIAM J. Comput.},
month = oct,
pages = {990–1000},
numpages = {11},
keywords = {learning models, machine learning theory, one-way functions}
}

@article{10.1137/S0097539792233907,
author = {Allender, Eric and Gore, Vivek},
title = {A Uniform Circuit Lower Bound For the Permanent},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792233907},
doi = {10.1137/S0097539792233907},
abstract = {The authors show that uniform families of ACC circuits of subexponential size cannot compute the permanent function.  This also implies similar lower bounds for certain sets in PP. This is one of the very few examples of a lower bound in circuit complexity whose proof hinges on the uniformity condition; it is still unknown if there is any set in Ntime ($2^{n^{O(1)}}$) that does not have nonuniform ACC circuits.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1026–1049},
numpages = {24},
keywords = {lower bounds, circuit complexity, permanent, complexity classes, uniformity}
}

@article{10.1137/S0097539792232021,
author = {Broder, Andrei Z. and Frieze, Alan M. and Upfal, Eli},
title = {Existence and Construction of Edge-Disjoint Pathson Expander Graphs},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792232021},
doi = {10.1137/S0097539792232021},
abstract = {Given an expander graph $G=(V,E)$ and a set of $q$ disjoint pairs of vertices in $V$, the authors are interested in finding for each pair $(a_i, b_i)$ a path connecting $a_i$ to $b_i$ such that the set of $q$ paths so found is edge disjoint. (For general graphs the related decision problem is NP complete.)  The authors prove sufficient conditions for the existence of edge-disjoint paths connecting any set of $qleq n/(log n)^kappa$ disjoint pairs of vertices on any $n$ vertex bounded degree expander, where $kappa$ depends only on the expansion properties of the input graph, and not on $n$. Furthermore, a randomized $o(n^3)$ time algorithm, and a random $cal NC$ algorithm for constructing these paths is presented. (Previous existence proofs and construction algorithms allowed only up to $n^epsilon$ pairs, for some $epsilonll frac{1}{3}$, and strong expanders [D. Peleg and E. Upfal,  Combinatorica , 9 (1989), pp.~289--313.].)  In passing, an algorithm is developed for splitting a sufficiently strong expander into two edge-disjoint spanning expanders. },
journal = {SIAM J. Comput.},
month = oct,
pages = {976–989},
numpages = {14},
keywords = {edge-disjoint paths, expanders}
}

@article{10.1137/S009753979223023X,
author = {Lew, William and Mahmoud, Hosam M.},
title = {The Joint Distribution of Elastic Buckets in Multiway Search Trees},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979223023X},
doi = {10.1137/S009753979223023X},
abstract = {Random search trees are studied when they grow under a general computer memory management scheme. In a general scheme, the space is released in buckets of certain predesignated sizes. For a search tree with branch factor $m$, the nodes may hold up to $m-1$ keys. Suppose the buckets of the memory management scheme that can hold less than $m$ keys have key capacities $c_1, ldots,c_p$. The search tree must then be  implemented with multitype nodes of  these capacities. After $n$ insertions, let $X_n^{(i)}$ be  the number of buckets of type $i$ (i.e., of capacity $c_i$,  $1{leq}i{leq}p$). The multivariate structure of the tree  is investigated. For the vector {bf X}$_n =  (X_n^{(1)}, ldots, X_n^{(p)})^T$, the asymptotic mean and  covariance matrix are determined. Under practical memory  management schemes, all variances and covariances experience  a phase transition: For $3 leq m leq 26$, all variances  and covariances are asymptotically linear in $n$; for higher  branch factors the variances and covariances become a  superlinear (but subquadratic) function of $n$. The joint  distribution of {bf X}$_n$ is shown to be  multivariate normal in a range of $m$. While the tree is  growing, conversions between types are necessary. A  multivariate problem concerning these conversions with an  asymptotic multivariate normal distribution is also studied.  The fixed bucket, exact fit, and buddy system allocation  schemes will serve as illustrating examples.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1050–1074},
numpages = {25},
keywords = {multivariate statistics, random trees, searching}
}

@article{10.1137/S0097539791199796,
author = {Westbrook, Jeffery},
title = {Randomized Algorithms for Multiprocessor Page Migration},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791199796},
doi = {10.1137/S0097539791199796},
abstract = {The  page migration  problem is to manage a globally addressed shared memory in a multiprocessor system. Each physical page of memory is located at a given processor, and memory references to that page by other processors incur a cost proportional to the network distance. At times the page may migrate between processors at cost proportional to the distance times $D$, a page size factor. The problem is to schedule movements on-line so that the total cost of memory references is within a constant factor $c$ of the best off-line schedule. An algorithm that does so is called c-competitive. Black and Sleator gave 3-competitive deterministic on-line algorithms for uniform networks (complete graphs with unit edge lengths) and for trees with arbitrary edge lengths. No good deterministic algorithm is known for general networks with arbitrary edge lengths.  Randomized algorithms are presented for the migration problem that are both simple and better than 3-competitive against an oblivious adversary. An algorithm for uniform graphs is given. It is approximately 2.28-competitive as $D$ grows large. A second, more powerful algorithm that works on graphs with arbitrary edge distances is also given. This algorithm is approximately 2.62-competitive (or, 1 plus the golden ratio) for large $D$. Both these algorithms use random bits only during an initialization phase, and from then on run deterministically. The competitiveness of a very simple coin-flipping algorithm is also examined. },
journal = {SIAM J. Comput.},
month = oct,
pages = {951–966},
numpages = {16},
keywords = {on-line algorithms, competitive analysis, memory management, page migration, multiprocessors}
}

@article{10.1137/S0097539791199334,
author = {Ahuja, Ravindra K. and Orlin, James B. and Stein, Clifford},
title = {Improved Algorithms for Bipartite Network Flow},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791199334},
doi = {10.1137/S0097539791199334},
abstract = {In this paper, network flow algorithms for bipartite networks are studied.  A network $G=(V,E)$ is called bipartite if its vertex set $V$ can be partitioned into two subsets $V_1$ and $V_2$ such that all edges have one endpoint in $V_1$ and the other in $V_2$.  Let $n=|V|$, $n_1 = |V_1|$, $n_2 = |V_2|$, $m=|E|$ and assume without loss of generality that $n_1 leq n_2$.   A bipartite network is called unbalanced if $n_1 ll n_2$ and balanced otherwise. (This notion is necessarily imprecise.) It is shown that several maximum flow algorithms can be substantially sped up when applied to unbalanced networks. The basic idea in these improvements is a two-edge push rule that allows one to "charge" most computation to vertices in $V_1$, and hence develop algorithms whose running times depend on $n_1$ rather than $n$. For example, it is shown that the two-edge push version of Goldberg and Tarjan's FIFO preflow-push algorithm runs in $O(n_1 m + n_1^3)$ time and that the analogous version of Ahuja and Orlin's excess scaling algorithm runs in  $O(n_1 m + n_1^2 log U)$ time, where $U$ is the largest edge capacity. These ideas are also extended to dynamic tree implementations, parametric maximum flows, and minimum-cost flows.},
journal = {SIAM J. Comput.},
month = oct,
pages = {906–933},
numpages = {28},
keywords = {parallel algorithms, bipartite graphs, network flow, minimum-cost flow, maximum flow, parametric maximum flow}
}

@article{10.1137/S0097539791195877,
author = {Feige, Uriel and Raghavan, Prabhakar and Peleg, David and Upfal, Eli},
title = {Computing with Noisy Information},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791195877},
doi = {10.1137/S0097539791195877},
abstract = {This paper studies the depth of noisy decision trees in which each node gives the wrong answer with some constant probability. In the noisy Boolean decision tree model, tight bounds are given on the number of queries to input variables required to compute threshold functions, the parity function and symmetric functions.  In the noisy comparison tree model, tight bounds are given on the number of noisy comparisons for searching, sorting, selection and merging.  The paper also studies parallel selection and sorting with noisy comparisons, giving tight bounds for several problems.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1001–1018},
numpages = {18},
keywords = {error-correction, fault-tolerance, sorting and searching, reliability, noisy computation}
}

@article{10.1137/S0097539791195543,
author = {Cole, Richard},
title = {Tight Bounds on the Complexity of the Boyer--Moore String Matching Algorithm},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791195543},
doi = {10.1137/S0097539791195543},
abstract = {The problem of finding all occurrences of a pattern of length $m$ in a text of length $n$ is considered.  It is shown that the Boyer--Moore string matching algorithm performs roughly $3n$ comparisons and that this bound is tight up to $O(n/m)$; more precisely, an upper bound of $3n - 3(n-m+1)/(m+2)$ comparisons is shown, as is a lower bound of $3n(1-o(1))$ comparisons, as $frac{n}{m}rightarrowinfty$ and $mrightarrowinfty$.  While the upper bound is somewhat involved, its main elements provide a simple proof of a $4n$ upper bound for the same algorithm.},
journal = {SIAM J. Comput.},
month = oct,
pages = {1075–1091},
numpages = {17},
keywords = {string matching, character comparisons, Boyer--Moore algorithm, amortized analysis}
}

@article{10.1137/S0097539790187539,
author = {Das, A. and Thulasiraman, K. and Agarwal, V. K.},
title = {Diagnosis of <i>t/(t +1)</i>-Diagnosable Systems},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790187539},
doi = {10.1137/S0097539790187539},
abstract = {A classic PMC (Preparata, Metze, and Chien) multiprocessor system [F. P.  Preparata, G. Metze, and R. T. Chien, IEEE Trans. Electr. Comput., EC-16 (1967), pp. 848--854] composed of $n$ units is said to be $t/(t+1)$ diagnosable [A. D. Friedman, A new measure of digital system diagnosis, in Dig. 1975 Int. Symp. Fault-Tolerant Comput., 1975, pp. 167--170] if, given a syndrome (complete collection of test results), the set of faulty units can be isolated to within a set of at most $t+1$ units, assuming that at most $t$ units in the system are faulty. This paper presents a methodology for determining when a unit $v$ can belong to an allowable fault set of cardinality at most $t$.  Based on this methodology, for a given syndrome in a $t/(t+1)$-diagnosable system, the authors establish a necessary and sufficient condition for a vertex $v$ to belong to an allowable fault set of cardinality at most $t$ and certain properties of $t/(t+1)$-diagnosable systems. This condition leads to an $O(n^{3.5}) t/(t+1)$-diagnosis algorithm. This $t/(t+1)$-diagnosis algorithm complements the $t/(t+1)$-diagnosability algorithm of Sullivan [The complexity of system-level fault diagnosis and diagnosability, Ph. D. thesis, Yale University, New Haven, CT, 1986].},
journal = {SIAM J. Comput.},
month = oct,
pages = {895–905},
numpages = {11},
keywords = {test assignment, fault isolation, fault diagnosis, PMC models, vertex cover sets, graph algorithms}
}

@article{10.1137/S0097539788148959,
author = {Yao, Andrew Chi-Chih},
title = {Near-Optimal Time-Space Tradeoff for Element Distinctness},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539788148959},
doi = {10.1137/S0097539788148959},
abstract = {It was conjectured in Borodin et al. [J. Comput. System Sci., 22 (1981), pp. 351--364] that to solve the element distinctness problem requires $TS = Omega(n^2)$ on a comparison-based branching program using space $S$ and time $T$, which, if true, would be close to optimal since $TS = O((n log n)^2)$ is achievable. Recently, Borodin et al. [SIAM J. Comput., 16 (1987), pp. 97--99] showed that $TS = Omega (n^{3/2}(log n)^{1/2})$. This paper presents a near-optimal tradeoff $TS = Omega(n^{2-epsilon(n)})$, where $epsilon(n) = O(1/(log  n)^{1/2})$.},
journal = {SIAM J. Comput.},
month = oct,
pages = {966–975},
numpages = {10},
keywords = {element distinctness, lower bounds, branching programs, comparisons, linear ordering, time-space tradeoff}
}

@article{10.1137/S0097539793243600,
author = {Aceto, Luca},
title = {On "Axiomatising Finite Concurrent Processes"},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539793243600},
doi = {10.1137/S0097539793243600},
abstract = {In his pioneering paper [Axiomatising finite concurrent processes, SIAM J. Comput., 17 (1988), pp. 997--1017], Hennessy gave complete axiomatizations of Milner's observational congruence and of t-observational congruence which made use of an auxiliary operation to axiomatize parallel composition. Unfortunately, those axiomatizations turn out to be flawed due to the subtle interplay between Hennessy's auxiliary parallel operator and synchronization.  The aim of this paper is to present correct versions of the equational characterizations given in Hennessy's paper. Some of the problems which arise in giving operational semantics to the auxiliary operators used by Bergstra and Klop and Hennessy in the theory of congruences like Milner's observational congruence are also discussed.},
journal = {SIAM J. Comput.},
month = aug,
pages = {852–863},
numpages = {12},
keywords = {observational congruence, t-observational congruence, concurrent processes, equational logic}
}

@article{10.1137/S0097539792237498,
author = {Lutz, Jack H. and Mayordomo, Elvira},
title = {Measure, Stochasticity, and the Density of Hard Languages},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792237498},
doi = {10.1137/S0097539792237498},
abstract = {The main theorem of this paper is that, for every real number $alpha&lt;1$ (e.g., $alpha=0.99$), only a measure 0 subset of the languages decidable in exponential time are $leq^{P}_{n^{alpha} - tt}$-reducible to languages that are not exponentially dense.  Thus every  $leq^{P}_{n^{alpha} - tt}$-  hard language for  E  is exponentially dense . This strengthens Watanabe's 1987 result, that every $leq^{P}_{(O log n)-tt}$-hard language for E is exponentially dense. The combinatorial technique used here, the  sequentially most frequent query selection , also gives a new, simpler proof of Watanabe's result.  The main theorem also has implications for the structure of NP under strong hypotheses. Ogiwara and Watanabe (1991) have shown that the hypothesis $pneNP$ implies that every $leq^{P}_{btt}$-hard language for NP is nonsparse (i.e., not polynomially sparse). Their technique does not appear to allow significant relaxation of either the query bound or the sparseness criterion. It is shown here that a stronger hypothesis---namely, that NP does not have measure 0 in exponential time---implies the stronger conclusion that, for every real $alpha&lt;1$, every $leq^{P}_{n^{alpha} - tt}$-hard language for NP is exponentially dense. Evidence is presented that this stronger hypothesis is reasonable.  The proof of the main theorem uses a new, very general  weak stochasticity theorem , ensuring that almost every language in E is statistically unpredictable by feasible deterministic algorithms, even with linear nonuniform advice. },
journal = {SIAM J. Comput.},
month = aug,
pages = {762–779},
numpages = {18},
keywords = {sparse languages, weak stochasticity, computational complexity, complexity classes, dense languages, polynomial reductions, resource-bounded measure}
}

@article{10.1137/S0097539792225297,
author = {Dahlhaus, E. and Johnson, D. S. and Papadimitriou, C. H. and Seymour, P. D. and Yannakakis, M.},
title = {The Complexity of Multiterminal Cuts},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792225297},
doi = {10.1137/S0097539792225297},
abstract = {In the multiterminal cut problem one is given an edge-weighted graph and a subset of the vertices called terminals, and is asked for a minimum weight set of edges that separates each terminal from all the others.  When the number $k$ of terminals is two, this is simply the mincut, max-flow problem, and can be solved in polynomial time. It is shown that the problem becomes NP-hard as soon as $k=3$, but can be solved in polynomial time for planar graphs for any fixed $k$. The planar problem is NP-hard, however, if $k$ is not fixed. A simple approximation algorithm for arbitrary graphs that is guaranteed to come within a factor of $2-2/k$ of the optimal cut weight is also described.},
journal = {SIAM J. Comput.},
month = aug,
pages = {864–894},
numpages = {31},
keywords = {network flow, planar graphs, NP-completeness, partitioning}
}

@article{10.1137/S0097539792224061,
author = {Schrijver, Alexander},
title = {Finding $k$ Disjoint Paths in a Directed Planar Graph},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792224061},
doi = {10.1137/S0097539792224061},
abstract = {It is shown that, for each fixed $k$, the problem of finding $k$ pairwise vertex-disjoint directed paths between given pairs of terminals in a directed planar graph is solvable in polynomial time.},
journal = {SIAM J. Comput.},
month = aug,
pages = {780–788},
numpages = {9},
keywords = {cohomologous, graph, directed, homologous, disjoint, free group, polynomial-time, algorithm, path, planar}
}

@article{10.1137/S0097539791224893,
author = {Culik, Karel and Karhumaki, Juhani},
title = {Finite Automata Computing Real Functions},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791224893},
doi = {10.1137/S0097539791224893},
abstract = {A new application of finite automata as computers of real functions is introduced. It is shown that even automata with a restricted structure compute all polynomials, many fractal-like and other functions.  Among the results shown, the authors give necessary and sufficient conditions for continuity, show that continuity and equivalence are decidable properties, and show how to compute integrals of functions in the automata representation.},
journal = {SIAM J. Comput.},
month = aug,
pages = {789–814},
numpages = {26},
keywords = {weighted finite automata, image generation, fractals, data compression}
}

@article{10.1137/S0097539791222171,
author = {Kannan, Sampath K. and Warnow, Tandy J.},
title = {Inferring Evolutionary History from DNA Sequences},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791222171},
doi = {10.1137/S0097539791222171},
abstract = {One of the longstanding problems in computational molecular biology is the Character Compatibility Problem, which is concerned with the construction of phylogenetic trees for species sets, where the species are defined by characters. The character compatibility problem is NP-Complete in general. In this paper an $O(n^2 k)$ time algorithm is described for the case where the species are described by quaternary characters. This algorithm can be used to construct phylogenetic trees from DNA sequences.},
journal = {SIAM J. Comput.},
month = aug,
pages = {713–737},
numpages = {25},
keywords = {evolutionary trees, algorithms, graphs, evolution}
}

@article{10.1137/S0097539791194094,
author = {Dietzfelbinger, Martin and Karlin, Anna and Mehlhorn, Kurt and Meyer auf der Heide, Friedhelm and Rohnert, Hans and Tarjan, Robert E.},
title = {Dynamic Perfect Hashing: Upper and Lower Bounds},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791194094},
doi = {10.1137/S0097539791194094},
abstract = {The dynamic dictionary problem is considered: provide an algorithm for storing a dynamic set, allowing the operations insert, delete, and lookup.  A dynamic perfect hashing strategy is given: a randomized algorithm for the dynamic dictionary problem that takes $O(1)$ worst-case time for lookups and $O(1)$ amortized expected time for insertions and deletions; it uses space proportional to the size of the set stored.  Furthermore, lower bounds for the time complexity of a class of deterministic algorithms for the dictionary problem are proved.  This class encompasses realistic hashing-based schemes that use linear space.  Such algorithms have amortized worst-case time complexity $Omega(log n)$ for a sequence of $n$ insertions and lookups; if the worst-case lookup time is restricted to $k$, then the lower bound becomes $Omega(kcdot n^{1/k})$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {738–761},
numpages = {24},
keywords = {hashing, data structures, lower bound, dictionary problem, randomized algorithm, universal hashing}
}

@article{10.1137/S0097539790192696,
author = {Bshouty, Nader H.},
title = {On the Complexity of Bilinear Forms Over Associative Algebras},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790192696},
doi = {10.1137/S0097539790192696},
abstract = {Let $F$ be a field, and let $q(alpha)=q_1^{d_1}(alpha)cdots q_k^{d_k}(alpha)in F[alpha]$ be a polynomial of degree $n$, where $q_1(alpha),ldots,q_k(alpha)$ are distinct irreducible polynomials. Let $y(alpha),y_1(alpha),ldots,y_r(alpha)$, $x_1(alpha),ldots,x_s(alpha)$ be $(n-1)$-degree polynomials with distinct nonscalar coefficients. The authors show the following: the number of nonscalar multiplications/divisions required to compute the coefficients of $x_i(alpha)y(alpha) mbox{mod}  q(alpha)$ for $i=1,ldots,s$ by straight line algorithms is $s(2n-k)$. If $H$ is a $stimes r$- matrix with entries from $F$, then the number of nonscalar multiplications/ divisions required to compute the coefficients of $(x_1(alpha),ldots,x_s(alpha)) $ $ H (y_1(alpha),ldots,$ $y_r(alpha))^T mbox{ mod } q(alpha) $ by straight line algorithms is equal to $(2n-k)$rank$(H)$. All the above systems satisfy the direct sum conjecture strongly. The above results also hold for some other algebras that are direct sums of local algebras, such as commutative algebras and division algebras.},
journal = {SIAM J. Comput.},
month = aug,
pages = {815–833},
numpages = {19},
keywords = {multiplicative complexity, associative algebras, direct sum, bilinear forms}
}

@article{10.1137/S0097539790192635,
author = {Chor, Benny and Israeli, Amos and Li, Ming},
title = {Wait-Free Consensus Using Asynchronous Hardware},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790192635},
doi = {10.1137/S0097539790192635},
abstract = {This paper studies the wait-free consensus problem in the asynchronous shared memory model. In this model, processors communicate by shared registers that allow atomic read and write operations (but do not support atomic test-and-set).  It is known that the wait-free consensus problem cannot be solved by deterministic protocols. A randomized solution is presented. This protocol is simple, constructive, tolerates up to $n-1$ processors crashes (where $n$ is the number of processors), and its expected run-time is $O(n^2)$.},
journal = {SIAM J. Comput.},
month = aug,
pages = {701–712},
numpages = {12},
keywords = {consensus, wait-free protocols, asynchronous distributed systems, randomized algorithms, fault tolerance}
}

@article{10.1137/S0097539790190077,
author = {Ramanan, Prakash},
title = {A New Lower Bound Technique and Its Application: Tight Lower Bound for a Polygon Triangulation},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790190077},
doi = {10.1137/S0097539790190077},
abstract = {A new technique for obtaining lower bounds on the worst-case time-complexity of optimization problems in the linear decision tree model of computation is presented. This technique is then used to obtain a tight $Omega(n log n)$ lower bound for a problem of finding a minimum cost triangulation of a convex polygon with weighted vertices. This problem is similar to the problem of finding an optimal order of computing a matrix chain product. If the lower bound technique could be extended to bounded degree algebraic decision trees, a tight  $Omega(n log n)$ lower bound for this latter problem  would be obtained.},
journal = {SIAM J. Comput.},
month = aug,
pages = {834–851},
numpages = {18},
keywords = {algebraic decisiontree model, polygon triangulation, time-complexity, matrix chain product, optimization problem, lower bound}
}

@article{10.1137/S0097539789169483,
author = {Subramanian, Ashok},
title = {A New Approach to Stable Matching Problems},
year = {1994},
issue_date = {Aug. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789169483},
doi = {10.1137/S0097539789169483},
abstract = {It is shown that Stable Matching problems are the same as problems about stable configurations of X-networks. Consequences include easy proofs of old theorems, a new simple algorithm for finding a stable matching, an understanding of the difference between Stable Marriage and Stable Roommates, NP-completeness of Three-party Stable Marriage, CC-completeness of several Stable Matching problems, and a fast parallel reduction from the Stable Marriage problem to the Assignment problem.},
journal = {SIAM J. Comput.},
month = aug,
pages = {671–701},
numpages = {31},
keywords = {comparator, stable configuration, stable matching, CC, weighted matching, circuit value, parallel complexity, scatter, network stability, stable marriage, assignment problem, stable roommates}
}

@article{10.1137/S0097539792241175,
author = {Klein, Philip and Plotkin, Serge and Stein, Clifford and Tardos, Eva},
title = {Faster Approximation Algorithms for the Unit Capacity Concurrent Flow Problem with Applications to Routing and Finding Sparse Cuts},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792241175},
doi = {10.1137/S0097539792241175},
abstract = {This paper describes new algorithms for approximately solving the concurrent multicommodity flow problem with uniform capacities. These algorithms are much faster than algorithms discovered previously. Besides being an important problem in its own right, the uniform-capacity concurrent flow problem has many interesting applications.  Leighton and Rao used uniform-capacity concurrent flow to find an approximately "sparsest cut" in a graph and thereby approximately solve a wide variety of graph problems, including minimum feedback arc set, minimum cut linear arrangement, and minimum area layout. However, their method appeared to be impractical as it required solving a large linear program. This paper shows that their method might be practical by giving an $O(m^2 log m)$ expected-time randomized algorithm for their concurrent flow problem on an $m$-edge graph.  Raghavan and Thompson used uniform-capacity concurrent flow to solve approximately a channel width minimization problem in very large scale integration.  An $O(k^{3/2} (m + n log n))$ expected-time randomized algorithm and an $O(kmin{n,k} (m+nlog n)log k)$ deterministic algorithm is given for this problem when the channel width is $Omega(log n)$, where $k$ denotes the number of wires to be routed in an $n$-node, $m$-edge network.},
journal = {SIAM J. Comput.},
month = jun,
pages = {466–487},
numpages = {22},
keywords = {concurrent flow, approximation, multicommodity flow, graph separators, VLSI routing}
}

@article{10.1137/S0097539792231143,
author = {Johnson, Donald B. and Raab, Larry},
title = {Complexity of Network Reliability and Optimal Resource Placement Problems},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792231143},
doi = {10.1137/S0097539792231143},
abstract = {A fundamental problem of distributed system design in an existing network where components can fail is finding an optimal location at which to place a resource. This paper proves exactly how hard this placement problem is under the measure of data availability.  Specifically, it shows that the optimal placement problem for availability is #$P$-complete, a measure of intractability at least as severe as NP-completeness.  To obtain these results, the environment in which a distributed system operates is modelled by a probabilistic graph, which is a set of fully reliable vertices representing sites and a set of edges representing communication links, each operational with a rational probability. Finding the optimal placement in a probabilistic graph is proved to be  #$P$-complete by giving a sequence of Turing reductions from #Satisfiability. This result is generalized to networks in  which each site and each link has an independent, rational operational probability and to networks in which all the sites or all the links have fixed, uniform operational probabilities. Given the anticipated computational difficulty of finding an exact solution, the requirements for effective, practical approximation methods are discussed.},
journal = {SIAM J. Comput.},
month = jun,
pages = {510–519},
numpages = {10},
keywords = {reliability graph, resource placement, database, simulation, networks, #$P$ complexity class}
}

@article{10.1137/S009753979222676X,
author = {Shmoys, David B. and Stein, Clifford and Wein, Joel},
title = {Improved Approximation Algorithms for Shop Scheduling Problems},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979222676X},
doi = {10.1137/S009753979222676X},
abstract = {In the job shop scheduling problem, there are $m$ machines and $n$ jobs.  A job consists of a sequence of operations, each of which must be processed on a specified machine, and the aim is to complete all jobs as quickly as possible.  This problem is strongly ${cal NP}$-hard even for very restrictive special cases.  The authors give the first randomized and deterministic polynomial-time algorithms that yield polylogarithmic approximations to the optimal length schedule. These algorithms also extend to the more general case where a job is given not by a linear ordering of the machines on which it must be processed but by an arbitrary partial order.  Comparable bounds can also be obtained when there are $m'$ types of machines, a specified number of machines of each type, and each operation must be processed on one of the machines of a specified type, as well as for the problem of scheduling unrelated parallel machines subject to chain precedence constraints.},
journal = {SIAM J. Comput.},
month = jun,
pages = {617–632},
numpages = {16},
keywords = {scheduling, approximation algorithms}
}

@article{10.1137/S0097539791223206,
author = {Grandjean, Etienne},
title = {Linear Time Algorithms and NP-Complete Problems},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791223206},
doi = {10.1137/S0097539791223206},
abstract = {This paper defines and studies a computational model (a random access machine with powerful input/output instructions), and shows that the classes DLINEAR and NLINEAR of problems computable in deterministic (respectively, nondeterministic) linear time in this model of computation are robust and powerful. In particular, DLINEAR includes most of the concrete problems commonly regarded as computable in linear time (such as graph problems, topological sorting, strong connectivity, etc.). Most combinatorial NP-complete problems are in NLINEAR. The  interest of NLINEAR class is enhanced by the fact that some  natural NP-complete problems, for example, "reduction of  incompletely specified automata" (RISA), are  NLINEAR-complete (consequently, NLINEAR $neq$ DLINEAR if  and only if RISA $notin$ DLINEAR). This notion strengthens  NP-completeness, as this paper argues that propositional  satisfiability is not NLINEAR complete.},
journal = {SIAM J. Comput.},
month = jun,
pages = {573–597},
numpages = {25},
keywords = {sorting, random access machine, model of computation, linear time, NP-completeness, input/output process, determinism, nondeterminism, uniform cost measure, algorithms on graphs, Turing machine, simulation, reduction}
}

@article{10.1137/S0097539791218640,
author = {Sheu, Ming-Jye and Long, Timothy J.},
title = {The Extended Low Hierarchy Is an Infinite Hierarchy},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791218640},
doi = {10.1137/S0097539791218640},
abstract = {Balcazar, Book, and Schoning introduced the extended low hierarchy based on the $Sigma$-levels of the polynomial-time hierarchy as follows: for $k geq 1$, level $k$ of the extended low hierarchy is the set $elow{k} = { A mid sgm{k}(A) subseteq sgm{k-1}(AoplusSAT)}$. Allender and Hemachandra and Long and Sheu introduced refinements of the extended low hierarchy based on the $Delta$- and $Theta$-levels, respectively, of the polynomial-time hierarchy: for $k geq 2$, $edlow{k} = { A mid dlt{k}(A) subseteq dlt{k-1}(AoplusSAT)}$ and $etlow{k} = { A mid tht{k}(A) subseteq tht{k-1}(AoplusSAT)}$. This paper shows that the extended low hierarchy is properly infinite by showing, for $k geq 2$, that $elow{k} subsetneq etlow{k+1} subsetneq edlow{k+1}  subsetneq elow{k+1}$. The proofs use the circuit lower bound techniques of Haa stad and Ko.  As corollaries to the constructions, for $k geq 2$, oracle sets $B_k$, $C_k$, and $D_k$, such that $PH(B_k) = sgm{k}(B_k) supsetneq dlt{k}(B_k)$,  $PH(C_k) = dlt{k}(C_k) supsetneq tht{k}(C_k)$, and  $PH(D_k) = tht{k}(D_k) supsetneq  sgm{k-1}(D_k)$ are obtained.},
journal = {SIAM J. Comput.},
month = jun,
pages = {488–509},
numpages = {22},
keywords = {polynomial-time hierarchy, extended low hierarchy, circuit lower bounds, relativizations}
}

@article{10.1137/S0097539791218275,
author = {Berkman, Omer and Jaja, Joseph and Krishnamurthy, Sridhar and Thurimella, Ramakrishna and Vishkin, Uzi},
title = {Top-Bottom Routing Around a Rectangle Is as Easyas Computing Prefix Minima},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791218275},
doi = {10.1137/S0097539791218275},
abstract = {A new parallel algorithm for the prefix minima problem is presented for inputs drawn from the range of integers $[1..s]$. For an input of size $n$, it runs in $O(logloglog s)$ time and $O(n)$ work (which is optimal). A faster algorithm is presented for the special case $s=n$; it runs in $O(log ^*n)$ time with optimal work. Both algorithms are for the Priority concurrent-read concurrent-write parallel random access machine (CRCW PRAM). A possibly surprising outcome of this work is that, whenever the range of the input is restricted, the prefix minima problem can be solved significantly faster than the $Omega( loglog n )$ time lower bound in a decision model of parallel computation, as described by Valiant [  SIAM J. Comput. , 4 (1975), pp. 348--355].  The top-bottom routing problem, which is an important subproblem of routing wires around a rectangle in two layers, is also considered. It is established that, for parallel (and hence for serial) computation, the problem of top-bottom routing is no harder than the prefix minima problem with $s=n$, thus giving an $O(log ^*n)$ time optimal parallel algorithm for the top-bottom routing problem. This is one of the first nontrivial problems to be given an optimal parallel algorithm that runs in sublogarithmic time. },
journal = {SIAM J. Comput.},
month = jun,
pages = {449–465},
numpages = {17},
keywords = {prefix minima, VLSI routing, parallel algorithms, PRAM algorithms}
}

@article{10.1137/S0097539791200375,
author = {Deogun, Jitender S. and Steiner, George},
title = {Polynomial Algorithms for  Hamiltonian Cycle in Cocomparability Graphs},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791200375},
doi = {10.1137/S0097539791200375},
abstract = {Finding a Hamiltonian cycle in a graph is one of the classical NP-complete problems.  Complexity of the Hamiltonian problem in permutation graphs has been a well-known open problem. In this paper the authors settle the complexity of the Hamiltonian problem in the more general class of cocomparability graphs.  It is shown that the Hamiltonian cycle existence problem for cocomparability graphs is in $P$. A polynomial time algorithm for constructing a Hamiltonian path and cycle is also presented. The approach is based on exploiting the relationship between the Hamiltonian problem in a cocomparability graph and the bump number problem in a partial order corresponding to the transitive orientation of its complementary graph.},
journal = {SIAM J. Comput.},
month = jun,
pages = {520–552},
numpages = {33},
keywords = {bump number, partial order, Hamiltonian path, cocomparability graphs, Hamiltonian cycle}
}

@article{10.1137/S0097539791196883,
author = {Beame, Paul and Tompa, Martin and Yan, Peiyuan},
title = {Communication-Space Tradeoffs for UnrestrictedProtocols},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791196883},
doi = {10.1137/S0097539791196883},
abstract = {This paper introduces communicating branching programs and develops a general technique for demonstrating communication-space tradeoffs for pairs of communicating branching programs.  This technique is then used to prove communication-space tradeoffs for any pair of communicating branching programs that hashes according to a universal family of hash functions.  Other tradeoffs follow from this result.  As an example, any pair of communicating Boolean branching programs that computes matrix-vector products over GF(2) requires communication-space product (Omega(n^2)), provided the space used is (o(n/log n)).  These are the first examples of communication-space tradeoffs on a completely general model of communicating processes.},
journal = {SIAM J. Comput.},
month = jun,
pages = {652–661},
numpages = {10},
keywords = {branching program, lower bound, universal family of hash functions, communication complexity, tradeoff}
}

@article{10.1137/S0097539790189368,
author = {Kirschenhofer, Peter and Prodinger, Helmut and Szpankowski, Wojciech},
title = {Digital Search Trees Again Revisited: The Internal Path Length Perspective},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790189368},
doi = {10.1137/S0097539790189368},
abstract = {This paper studies the asymptotics of the variance for the internal path length in a symmetric digital search tree under the Bernoulli model. This problem has been open until now. It is proved that the variance is asymptotically equal to $Ncdot0.26600 +Ncdotdelta(log_2 N),$ where $N$ is the number of stored records and $delta(x)$ is a periodic function of mean zero and a very small amplitude.  This result completes a series of studies devoted to the asymptotic analysis of the variances of digital tree parameters in the symmetric case.  In order to prove the previous result a number of nontrivial problems concerning analytic continuations and some others of a numerical nature had to be solved. In fact, some of these techniques are motivated by the methodology introduced in an influential paper by Flajolet and Sedgewick.},
journal = {SIAM J. Comput.},
month = jun,
pages = {598–616},
numpages = {19},
keywords = {digital search trees, algorithm analysis}
}

@article{10.1137/S0097539790184298,
author = {Reif, John H. and Sen, Sandeep},
title = {Randomized Algorithms for Binary Search and Load Balancing on Fixed Connection Networks with Geometric Applications},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790184298},
doi = {10.1137/S0097539790184298},
abstract = {There are now a number of fundamental problems in computational geometry that have optimal algorithms on PRAM models. This paper presents randomized parallel algorithms that execute on an $n$-processor butterfly interconnection network in $O(log n)$ time for the following problems of input size $n$: trapezoidal decomposition, visibility, triangulation, and two-dimensional convex hull. These algorithms involve tackling some of the very basic problems, like binary search and load balancing, that are taken for granted in PRAM models.  Apart from a two-dimensional convex hull algorithm, these are the first nontrivial geometric algorithms that attain this performance on fixed connection networks. These techniques use a number of ideas from Flashsort that have to be modified to handle more difficult situations; it seems likely that they will have wider applications.},
journal = {SIAM J. Comput.},
month = jun,
pages = {633–651},
numpages = {19},
keywords = {parallel algorithms, randomization, butterfly network, computational geometry}
}

@article{10.1137/S0097539790181889,
author = {Braschi, Bertrand and Trystram, Denis},
title = {A New Insight into the Coffman-Graham Algorithm},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790181889},
doi = {10.1137/S0097539790181889},
abstract = {The approximate solution of the $m$-machine problem is addressed. The Lam--Sethi worst-case analysis of the Coffman--Graham algorithm is set up to be partly incorrect. A slightly different context is set up to correct and complete this analysis. It is shown that the makespan of a schedule computed by an extended Coffman--Graham algorithm is lower than or at worst equal to $(2 - 2/m) omega_{opt} - (m - 3)/m$, where $omega_{opt}$ is the minimal makespan of a schedule.},
journal = {SIAM J. Comput.},
month = jun,
pages = {662–669},
numpages = {8},
keywords = {scheduling theory, list scheduling, worst-case analysis}
}

@article{10.1137/S0097539790181336,
author = {Cai, Jin-Yi and Lipton, Richard J.},
title = {Subquadratic Simulations of Balanced Formulae by Branching Programs},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790181336},
doi = {10.1137/S0097539790181336},
abstract = {This paper considers Boolean formulae and their simulations  by bounded width branching programs. It is shown that every  balanced Boolean formula of size $s$ can be simulated by a  constant width (width 5) branching program of length  $s^{1.811ldots}$. A lower bound for the translational cost  from formulae to permutation branching programs is also  presented.},
journal = {SIAM J. Comput.},
month = jun,
pages = {563–572},
numpages = {10},
keywords = {Boolean formulae, Boolean circuits, group theory, branching programs}
}

@article{10.1137/S0097539789168283,
author = {Pestien, Victor and Ramakrishnan, S. and Sarkar, Dilip},
title = {Packet Transmission in a Noisy-Channel Ring Network},
year = {1994},
issue_date = {June 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789168283},
doi = {10.1137/S0097539789168283},
abstract = {Assume that $n$ stations, each with a buffer to hold only one packet at a time, are connected as a ring and that data packets are transmitted counterclockwise. A station will attempt to transmit a packet to the next station only if (i) it has a packet to send and (ii) the next station's buffer is empty. The communication channels connecting the stations are noisy, and there is a fixed probability $p$ ($0 An exact expression for the long-run average time for a packet to go around the ring is derived. (A special case of this answers a question raised by Berman and Simon in [  Proc. 20th ACM Symp. on Theory of Computing , ACM Press, 1988, pp. 66--77].) For fixed $n$ and $p$, the throughput of the system is maximum when the number of packets is an integer closest to $n/2$. },
journal = {SIAM J. Comput.},
month = jun,
pages = {553–562},
numpages = {10},
keywords = {Markov chain, equilibrium distribution, packet communication, ring network}
}

@article{10.1137/S0097539792235487,
author = {Swaminathan, R. and Wagner, Donald K.},
title = {On the Consecutive-Retrieval Problem},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792235487},
doi = {10.1137/S0097539792235487},
abstract = {A ${0,1}$-matrix $M$ has the consecutive-retrieval property if there exists a tree $T$ such that the vertices of $T$ are indexed on the rows of $M$ and the columns of $M$ are the incidence vectors of the vertex sets of paths of $T$. If such a $T$ exists, then $T$ is a realization for $M$. In this paper, an $O(r^2c)$ algorithm is presented to determine whether a given standard, $r times c$ matrix has the consecutive-retrieval property and, if so, to construct a realization.},
journal = {SIAM J. Comput.},
month = apr,
pages = {398–414},
numpages = {17},
keywords = {polynomial-time algorithm, matrix decomposition, tree realization, consecutive-retrieval property}
}

@article{10.1137/S0097539792226321,
author = {Amir, Amihood and Benson, Gary and Farach, Martin},
title = {An Alphabet Independent Approach to Two-Dimensional Pattern Matching},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792226321},
doi = {10.1137/S0097539792226321},
abstract = {There are many solutions to the string matching problem that are strictly linear in the input size and independent of alphabet size. Furthermore, the model of computation for these algorithms is very weak: they allow only simple arithmetic and comparisons of equality between characters of the input. In contrast, algorithms for two-dimensional matching have needed stronger models of computation, most notably assuming a totally ordered alphabet. The fastest algorithms for two-dimensional matching have therefore had a logarithmic dependence on the alphabet size. In the worst case, this gives an algorithm that runs in $O(n^2 log{m})$ with $O(m^2 log m)$ preprocessing.  The authors show an algorithm for two-dimensional matching with an $O(n^2)$ text-scanning phase. Furthermore, the text scan requires no special assumptions about the alphabet, i.e., it runs on the same model as the standard linear-time string-matching algorithm. The pattern preprocessing requires an ordered alphabet and runs with the same alphabet dependency as the previously known algorithms. },
journal = {SIAM J. Comput.},
month = apr,
pages = {313–323},
numpages = {11},
keywords = {period, multidimensional matching, string}
}

@article{10.1137/S0097539792225935,
author = {Fu, Bin and Li, Hong-zhou},
title = {Closeness of NP-Hard Sets to Other Complexity Classes},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792225935},
doi = {10.1137/S0097539792225935},
abstract = {Let $A$ be a language and $C$ be a class of languages. $A$ is said to be s-C-close (s-C-outside-close) if there exists $B in C$ such that $parallel (A bigtriangleup B)^{leq n}parallel leq s(n)$ (and $A subseteq B $). If $A$ is q-C-close (q-C-outside-close) for some polynomial $q$ then it is simply said that $A$ is C-close (C-outside-close). The following results are shown in this paper.  (1) No NP-hard set can be coNP-close unless NP $=$ coNP.  (2) No NP-hard set can be R-close unless NP $=$ R.  (3) No NP-hard set can be $O(log n)$ -UP-close unless NP $=$ FewP.  (4) No NP-hard set can be $O(log n)$-$C_=P$-close unless NP $ subseteq C_=P$.  (5) No NP-hard set can be UP-outside-close unless NP $ = $ FewP.  (6) No NP-hard set can be $C_=P$-outside-close unless NP $ subseteq C_=P$. },
journal = {SIAM J. Comput.},
month = apr,
pages = {255–260},
numpages = {6},
keywords = {NP-hard sets, sparse sets, symmetric difference}
}

@article{10.1137/S0097539792224838,
author = {Karloff, Howard and Rabani, Yuval and Ravid, Yiftach},
title = {Lower Bounds for Randomized $k$-Serverand Motion-Planning Algorithms},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792224838},
doi = {10.1137/S0097539792224838},
abstract = {In this paper, the authors prove lower bounds on the competitive ratio of randomized algorithms for two on-line problems: the $k$-server problem, suggested by Manasse, McGeoch, and Sleator [Competitive algorithms for on-line problems, J. Algorithms, 11 (1990), pp. 208--230], and an on-line motion-planning problem due to Papadimitriou and Yannakakis [Shortest paths without a map, Lecture Notes in Comput. Sci. 372, Springer-Verlag, New York, 1989, pp. 610--620]. The authors prove, against an oblivious adversary, an $Omega(log k)$ lower bound on the competitive ratio of any randomized on-line $k$-server algorithm in any sufficiently large metric space, an $Omega(loglog k)$ lower bound on the competitive ratio of any randomized on-line $k$-server algorithm in any metric space with at least $k+1$ points, and an $Omega(loglog n)$ lower bound on the competitive ratio of any on-line motion-planning algorithm for a scene with $n$ obstacles. Previously, no superconstant lower bound on the competitive ratio of randomized on-line algorithms was known for any of these problems.},
journal = {SIAM J. Comput.},
month = apr,
pages = {293–312},
numpages = {20},
keywords = {$k$-server problem, competitive analysis, on-line algorithm, motion planning}
}

@article{10.1137/S0097539791223747,
author = {Berg, Mark de and Overmars, Mark and Schwarzkopf, Otfried},
title = {Computing and Verifying Depth Orders},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791223747},
doi = {10.1137/S0097539791223747},
abstract = {A depth order on a set of line segments in 3-space is an order such that line segment $a$ comes before line segment $a'$ in the order when $a$ lies below $a'$ or, in other words, when there is a vertical ray that first intersects $a'$ and then intersects $a$. Efficient algorithms for the computation and verification of depth orders of sets of $n$ line segments in 3-space are presented.  The algorithms run in time $O(n^{4/3+varepsilon})$, for any fixed $varepsilon &gt; 0$. If all line segments are axis-parallel or, more generally, have only a constant number of different orientations, then the sorting algorithm runs in $O(nlog^3 n)$ time and the verification takes $O(nlog^2 n)$ time. The algorithms can be generalized to handle triangles and other polygons instead of line segments.  They are based on a general framework for computing and verifying linear orders extending implicitly defined binary relations.},
journal = {SIAM J. Comput.},
month = apr,
pages = {437–446},
numpages = {10},
keywords = {linear extensions of partial orders, three dimensions, computational geometry, depth orders}
}

@article{10.1137/S0097539791202647,
author = {Pruesse, Gara and Ruskey, Frank},
title = {Generating Linear Extensions Fast},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791202647},
doi = {10.1137/S0097539791202647},
abstract = {One of the most important sets associated with a poset  ${cal P}$ is its set of linear extensions, $E({cal P})$. This paper presents an algorithm to generate all of the linear extensions of a poset in constant amortized time, that is, in time $O(e(cP))$, where $e(cP) = |E(cP)|$.  The fastest previously known algorithm for generating the linear extensions of a poset runs in time $O(n ! cdot ! e(cP))$, where $n$ is the number of elements of the poset. The algorithm presented here is the first constant amortized time algorithm for generating a "naturally defined" class of combinatorial objects for which the corresponding counting problem is #P-complete. Furthermore, it is shown that linear extensions can be generated in constant amortized time where each extension differs from its predecessor by one or two adjacent transpositions. The algorithm is practical and can be modified to count linear extensions efficiently and to compute $P (x &lt; y)$, for all pairs $x,y$, in time $O(n^2 + e({cal P}))$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {373–386},
numpages = {14},
keywords = {combinatorial Gray code, poset, linear extension, transposition}
}

@article{10.1137/S0097539791201587,
author = {Kim, Myong-Hi and Sutherland, Scott},
title = {Polynomial Root-Finding Algorithmsand Branched Covers},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791201587},
doi = {10.1137/S0097539791201587},
abstract = {A family of root-finding algorithms is constructed that combines knowledge of the branched covering structure of a polynomial with a path-lifting algorithm for finding individual roots.  In particular, the family includes an algorithm that computes an $epsilon$-factorization of a polynomial of degree $d$ that has an arithmetic complexity of  $Order{d(log d)^2|logepsilon| +d^2(log d)^2}$.   At the present time, this complexity is the best known in terms  of the degree.},
journal = {SIAM J. Comput.},
month = apr,
pages = {415–436},
numpages = {22},
keywords = {arithmetic complexity, approximate zeros, branched covering, path-lifting method, Newton's method}
}

@article{10.1137/S0097539791200351,
author = {Kobler, Johannes and Thierauf, Thomas},
title = {Complexity-Restricted Advice Functions},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791200351},
doi = {10.1137/S0097539791200351},
abstract = {The authors consider uniform subclasses of the nonuniform complexity classes defined by Karp and Lipton [  L'Enseign. Math. , 28 (1982)] via the notion of advice functions. These subclasses are obtained by restricting the complexity of computing correct advice. Also, the effect of allowing advice functions of limited complexity to depend on the input rather than on the input's length is investigated. Among other results, using the notions described above, new characterizations of (a) $NP^{NPcap SPARSE}$, (b) $NP$ with a restricted access to an $NP$ oracle, and (c) the odd levels of the boolean hierarchy are given.  As a consequence, it is shown that every set that is nondeterministically truth-table reducible to SAT in the sense of Rich [  J. Comput. System Sci. , 38 (1989), pp. 511--523] is already deterministically truth-table reducible to SAT. Furthermore, it turns out that the $NP$ reduction classes of bounded versions of this reducibility coincide with the odd levels of the boolean hierarchy. },
journal = {SIAM J. Comput.},
month = apr,
pages = {261–275},
numpages = {15},
keywords = {advice classes, optimization functions, restricted oracle access, nonuniform complexity classes, relativization, truth-table reducibility, sparse NP sets, boolean hierarchy}
}

@article{10.1137/S0097539791195245,
author = {Narayanan, H. and Saran, Huzur and Vazirani, Vijay V.},
title = {Randomized Parallel Algorithms for Matroid Union and Intersection, with Applications to Arboresences and Edge-Disjoint Spanning Trees},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791195245},
doi = {10.1137/S0097539791195245},
abstract = {The strong link between matroids and matching is used to extend the ideas that resulted in the design of random $NC$ $(RNC)$ algorithms for matching to obtain $RNC$ algorithms for the matroid union, intersection, and matching problems, and for linearly representable matroids. As a consequence, $RNC$ algorithms for the well-known problems of finding an arboresence and a maximum cardinality set of edge-disjoint spanning trees in a graph are obtained. The key tools used are linear algebra and randomization.},
journal = {SIAM J. Comput.},
month = apr,
pages = {387–397},
numpages = {11},
keywords = {randomized algorithms, parallel algorithms, matroids, graph algorithms}
}

@article{10.1137/S009753979119415X,
author = {Triesch, Eberhard},
title = {Some Results on Elusive Graph Properties},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979119415X},
doi = {10.1137/S009753979119415X},
abstract = {This article proves several graph properties to be elusive. Two of the main results are If ${cal P}$ is a decreasing graph property containing no graph of girth smaller than 5, then ${cal P}$ is elusive. The property of having matching number at most $k$, $k &lt; lfloor | V |2 rfloor$, is elusive. The proofs are all based on a topological method developed by Kahn, Saks, and Sturtevant.},
journal = {SIAM J. Comput.},
month = apr,
pages = {247–254},
numpages = {8},
keywords = {matching, elusive, recognition complexity, girth, monotone graph property}
}

@article{10.1137/S0097539790192672,
author = {Bagchi, A. and Schmeichel, E. F. and Hakimi, S. L.},
title = {Parallel Information Dissemination by Packets},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790192672},
doi = {10.1137/S0097539790192672},
abstract = {Each vertex of an undirected graph possesses a piece of information that must be sent to every other vertex. They communicate by sending bounded size packets of messages from one vertex to another. The authors describe parallel algorithms, which accomplish the desired tasks for six prominent architectures. The algorithms are optimal, or nearly so, in every case.},
journal = {SIAM J. Comput.},
month = apr,
pages = {355–372},
numpages = {18},
keywords = {interprocessor communication, parallel gossiping, algorithms for parallel communication on networks}
}

@article{10.1137/S0097539790190971,
author = {Chaudhuri, Soma and Welch, Jennifer L.},
title = {Bounds on the Costs of Multivalued RegisterImplementations},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790190971},
doi = {10.1137/S0097539790190971},
abstract = {A fundamental aspect of any concurrent system is how processes communicate with each other.  Ultimately, all communication involves concurrent reads and writes of shared memory cells, or registers.  The stronger the guarantees provided by a register, the more useful it is to the user, but the harder it may be to implement in practice. This paper considers the problem of implementing a $k$-ary regular (respectively, safe) register out of binary regular (respectively, safe) registers, assuming a single writer. While algorithms have been developed previously for these problems, no nontrivial lower bounds were known.  The cost measures considered here are the number of physical registers and the number of reads and writes on the physical registers required to implement the logical register. Tight bounds are obtained on the cost measures in many cases, and interesting trade-offs between the cost measures are identified. The lower bounds are shown using information-theoretic techniques. Two new algorithms are presented that improve on the costs of previously known algorithms: the hypercube algorithm implements a $k$-ary safe register out of binary safe registers, requiring only one physical write per logical write; and the tree algorithm implements a $k$-ary regular register out of binary regular registers, requiring only $lceil log k rceil$ physical operations per logical operation.  Both algorithms use novel combinatorial techniques.},
journal = {SIAM J. Comput.},
month = apr,
pages = {335–354},
numpages = {20},
keywords = {shared memory registers, concurrent distributed system, time and space complexity, registers, concurrent computation}
}

@article{10.1137/S0097539790190144,
author = {Broder, Andrei Z. and Karlin, Anna R. and Raghavan, Prabhakar},
title = {Trading Space for Time in Undirected $s-T$ Connectivity},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790190144},
doi = {10.1137/S0097539790190144},
abstract = {Aleliunas et al. [20th Annual Symposium on Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1979, pp. 218--223] posed the following question: "The reachability problem for undirected graphs can be solved in log space and $O(mn)$ time [$m$ is the number of edges and $n$ is the number of vertices] by a probabilistic algorithm that simulates a random walk, or in linear time and space by a conventional deterministic graph traversal algorithm.  Is there a spectrum of time-space trade-offs between these extremes?" This question is answered in the affirmative for sparse graphs by presentation of an algorithm that is faster than the random walk by a factor essentially proportional to the size of its workspace.  For denser graphs, this algorithm is faster than the random walk but the speed-up factor is smaller.},
journal = {SIAM J. Comput.},
month = apr,
pages = {324–334},
numpages = {11},
keywords = {parallel random walks, connectivity testing, space-time tradeoff}
}

@article{10.1137/S0097539789164765,
author = {Herley, Kieran T. and Bilardi, Gianfranco},
title = {Deterministic Simulations of Prams on Bounded Degree Networks},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789164765},
doi = {10.1137/S0097539789164765},
abstract = {The problem of simulating a PRAM with $n$ processors and memory size $m geq n$ on an $n$-node bounded degree network is considered. A deterministic algorithm is presented that simulates an arbitrary PRAM step in $O((log n log m)/log log n)$  time in the worst case on an expander-based network. By extending a previously established lower bound, it is shown that the proposed simulation is optimal whenever  $Omega(n^{1 + epsilon}) leq m leq O(2^{(log n)^{alpha}})$  for some positive real constants $epsilon$ and $alpha$.},
journal = {SIAM J. Comput.},
month = apr,
pages = {276–292},
numpages = {17},
keywords = {expander graphs, shared memory machines, networks of processors, parallel computation, simulations}
}

@article{10.1137/S0097539789162109,
author = {Kaufmann, Michael and Mehlhorn, Kurt},
title = {A Linear-Time Algorithm for the Homotopic Routing Problem in Grid Graphs},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789162109},
doi = {10.1137/S0097539789162109},
abstract = {The paper considers the problem of finding edge-disjoint paths between pairs of vertices in a finite grid graph. The homotopy class for each path to be routed is prespecified. A very fast algorithm that guarantees to find a solution for any solvable homotopic routing problem is given.},
journal = {SIAM J. Comput.},
month = apr,
pages = {227–246},
numpages = {20},
keywords = {algorithms, VLSI-theory, homotopic routing, edge-disjoint paths}
}

@article{10.1137/0223030,
author = {Reif, John H. and Sen, Sandeep},
title = {Optimal Parallel Randomized Algorithms for Three-Dimensional Convex Hulls and Related Problems},
year = {1994},
issue_date = {April 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0223030},
doi = {10.1137/0223030},
journal = {SIAM J. Comput.},
month = apr,
pages = {447–448},
numpages = {2}
}

@article{10.1137/S0097539792229404,
author = {Pellegrini, Marco},
title = {On Collision-Free Placements of Simplices and the Closest Pair of Lines in 3-Space},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792229404},
doi = {10.1137/S0097539792229404},
abstract = {The problem of detecting efficiently whether a query simplex is  collision-free  among polyhedral obstacles is considered. If $n$ is the number of vertices, edges, and faces of the polyhedral obstacles, and $m$ is the amount of storage allocated for the data structure $(n^{1 + epsilon} leq m leq n^{4 + epsilon})$, it is possible to solve collision-free placements queries for simplices in time $O(n^{1 + epsilon}/m^{1/4})$ for any $epsilon &gt; 0$, where the constants depend on $epsilon$. In order to solve this problem the authors develop data structures to detect on-line intersections of query half planes with sets of lines and segments.  Some nearest-neighbor problems for objects in 3-space are also considered. Given a set of $n$ lines in 3-space, the shortest vertical segment between any pair of lines is found in randomized expected time $O(n^{8/5 + epsilon})$ for every $epsilon &gt; 0$. The longest connecting vertical segment is found in time $O(n^{4/3 + epsilon})$. The shortest connecting segment is found in time $O(n^{5/3 + epsilon})$. },
journal = {SIAM J. Comput.},
month = feb,
pages = {133–153},
numpages = {21},
keywords = {proximity, point location, three-dimensional space, collision-free placements, half-space range searching, arrangements, Pl\"{u}, parametric search}
}

@article{10.1137/S0097539792228629,
author = {Boros, E. and Crama, Y. and Hammer, P. L. and Saks, M.},
title = {A Complexity Index for Satisfiability Problems},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792228629},
doi = {10.1137/S0097539792228629},
abstract = {This paper associates a linear programming problem (LP) to any conjunctive normal form $gf$, and shows that the optimum value $Z(gf)$ of this LP measures the complexity of the corresponding  SAT  (Boolean satisfiability) problem. More precisely, there is an algorithm for  SAT  that runs in polynomial time on the class of satisfiability problems satisfying $Z(gf)leq 1+frac{clog n}{n}$ for a fixed constant $c$, where $n$ is the number of variables. In contrast, for any fixed $beta&lt;1$,  SAT  is still NP complete when restricted to the class of CNFs for which $Z(gf)leq 1+(1/n^{beta})$. },
journal = {SIAM J. Comput.},
month = feb,
pages = {45–49},
numpages = {5},
keywords = {Boolean satisfiability, polynomial algorithms, NP completeness}
}

@article{10.1137/S0097539792228289,
author = {Bellare, Mihir and Goldwasser, Shafi},
title = {The Complexity of Decision Versus Search},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792228289},
doi = {10.1137/S0097539792228289},
abstract = {A basic question about NP is whether or not search reduces in polynomial time to decision. This paper indicates that the answer is negative: Under a complexity assumption (that deterministic and nondeterministic double-exponential time are unequal) a language in NP for which search does not reduce to decision is constructed.  These ideas extend in a natural way to interactive proofs and program checking. Under similar assumptions, the authors present languages in NP for which it is harder to prove membership interactively than it is to decide this membership, and languages in NP that are not checkable. },
journal = {SIAM J. Comput.},
month = feb,
pages = {97–119},
numpages = {23},
keywords = {quadratic residuosity, sparse sets, NP-completeness, self-reducibility, interactive proofs, program checking}
}

@article{10.1137/S0097539792227612,
author = {Du, D.-Z. and Xue, G.-L. and Sun, S.-Z. and Cheng, S.-W.},
title = {Modifications of Competitive Group Testing},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539792227612},
doi = {10.1137/S0097539792227612},
abstract = {Many fault-detection problems fall into the following model:  There is a set of $n$ items, some of which are defective.  The goal is to identify the defective items by using the  minimum number of tests. Each test is on a subset of items  and tells whether the subset contains a defective item or  not. Let $M_{alpha}(d, n) (M_{alpha}(d,|,n))$ denote the  maximum number of tests for an algorithm $alpha$ to  identify $d$ defectives from a set of $n$ items provided  that $d$, the number of defective items, is known (unknown)  before the testing. Let $M(d, n) = min_{alpha}  M_{alpha}(d, n)$. An algorithm $alpha$ is called a {it  competitive algorithm/} if there exist constants $c$ and  $a$ such that for all $n &gt; d &gt; 0$, $M_{alpha}(d,|,n) leq  cM(d, n) + a$. This paper confirms a recent conjecture that  there exists a bisecting algorithm $A$ such that  $M_A(d,|,n) leq 2M(d, n) + 1$. Also, an algorithm $B$  such that $M_B(d,|,n) leq 1.65M(d, n) + 10$ is presented.},
journal = {SIAM J. Comput.},
month = feb,
pages = {82–96},
numpages = {15},
keywords = {group testing, competitive algorithm}
}

@article{10.1137/S0097539791198900,
author = {Shawe-Taylor, John and Pisanski, Tomaz},
title = {Homeomorphism of 2-Complexes is Graph Isomorphism Complete},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791198900},
doi = {10.1137/S0097539791198900},
abstract = {It is shown that the problem of determining whether two 2-complexes  are homeomorphic is isomorphism-complete.},
journal = {SIAM J. Comput.},
month = feb,
pages = {120–132},
numpages = {13},
keywords = {simplicial complex, isomorphism, homeomorphism, graph, computational complexity, triangulation, 2-complex}
}

@article{10.1137/S0097539791197852,
author = {Bermond, Jean-Claude and Fraigniaud, Pierre},
title = {Broadcasting and Gossiping in de Bruijn Networks},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791197852},
doi = {10.1137/S0097539791197852},
abstract = {Communication schemes based on store and forward routing, in which a processor can communicate simultaneously  with all its neighbors (in parallel) are considered.  Moreover, the authors assume that sending a message of  length $L$ from a node to a neighbor takes time $beta + L  tau$. The authors give efficient broadcasting and  gossiping protocols for the de Bruijn networks. To do  this, arc-disjoint spanning trees of small depth  rooted at a given vertex in de Bruijn digraphs are  constructed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {212–225},
numpages = {14},
keywords = {de Bruijn graphs, broadcasting, gossiping, disjoint spanning trees, interconnection networks}
}

@article{10.1137/S0097539791197323,
author = {Santis, Alfredo De and Persiano, Giuseppe},
title = {Tight Upper and Lower Bounds on the Path Length of Binary Trees},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791197323},
doi = {10.1137/S0097539791197323},
abstract = {The  external path length  of a tree $T$ is the sum of the lengths of the paths from the root to each external node. The  maximal path length difference , $Delta$, is the difference between the lengths of the longest and shortest such paths.  Tight lower and upper bounds are proved on the external path length of binary trees with $N$ external nodes and maximal path length difference $Delta$ is prescribed.  In particular, an upper bound is given that, for each value of $Delta$, can be exactly achieved for infinitely many values of $N$. This improves on the previously known upper bound that could only be achieved up to a factor proportional to $N$. An elementary proof of the known upper bound is also presented as a preliminary result.  Moreover, a lower bound is proved that can be exactly achieved for each value of $N$ and $Deltaleq N/2$. },
journal = {SIAM J. Comput.},
month = feb,
pages = {12–24},
numpages = {13},
keywords = {binary search trees, path length}
}

@article{10.1137/S009753979119607X,
author = {Kuo, David and Chang, Gerard J.},
title = {The Profile Minimization Problem in Trees},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979119607X},
doi = {10.1137/S009753979119607X},
abstract = {The profile minimization problem is to find a one-to-one  function $f$ from the vertex set $V(G)$ of a graph $G$ to  the set of all positive integers such that $sum_{x in  V(G)} {f(x) - min_{y in N[x]} f(y)}$ is as small as  possible, where $N[x] = {x} cup { y:y mbox{ is adjacent  to } x}$ is the closed neighborhood of $x$ in $G$. This paper gives an $O(n^{1.722})$ time algorithm for the problem  in a tree of $n$ vertices.},
journal = {SIAM J. Comput.},
month = feb,
pages = {71–81},
numpages = {11},
keywords = {basic path, labeling, algorithm, centroid, profile, leaf, tree, sparse matrix}
}

@article{10.1137/S0097539791194069,
author = {Grigoriev, Dima and Karpinski, Marek and Singer, Michael F.},
title = {Computational Complexity of Sparse Rational Interpolation},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539791194069},
doi = {10.1137/S0097539791194069},
abstract = {The authors analyze the computational complexity of sparse rational interpolation, and give the first deterministic algorithm for this problem with singly exponential bounds on the number of arithmetic  operations.},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–12},
numpages = {12},
keywords = {sparse rational functions, interpolation, arithmetic operations, computational complexity}
}

@article{10.1137/S0097539790191010,
author = {Irving, Robert W. and Jerrum, Mark R.},
title = {Three-Dimensional Statistical Data Security Problems},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790191010},
doi = {10.1137/S0097539790191010},
abstract = {Suppose there is a three-dimensional table of cross-tabulated nonnegative integer statistics, and suppose that all of the row, column, and "file" sums are revealed together with the values in some of the individual cells in the table. The question arises as to whether, as a consequence, the values contained in some of the other (suppressed) cells can be deduced from the information revealed.  The corresponding problem in two dimensions has been comprehensively studied by Gusfield [  SIAM J. Comput. , 17 (1988), pp. 552--571], who derived elegant polynomial-time algorithms for the identification of any such "compromised" cells, and for calculating the tightest bounds on the values contained in all cells that follow from the information revealed. In this note it is shown, by contrast, that the three-dimensional version of the problem is NP-complete.  It is also shown that if the suggested row, column, and file sums for an unknown three-dimensional table are given, with or without the values in some of the cells, the problem of determining whether there exists any table with the given sums is NP-complete. In the course of proving these results, the NP-completeness of some constrained Latin square construction problems, which are of some interest in their own right, is established. },
journal = {SIAM J. Comput.},
month = feb,
pages = {170–184},
numpages = {15},
keywords = {data security, NP-complete problems, Latin squares}
}

@article{10.1137/S0097539790189733,
author = {Sundar, Rajamani and Tarjan, Robert E.},
title = {Unique Binary-Search-Tree Representations and Equality Testing of Sets and Sequences},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790189733},
doi = {10.1137/S0097539790189733},
abstract = {This paper studies the problem of representing sets over an  ordered universe by unique binary search trees, so that  dictionary operations can be performed efficiently on any  set.  Although efficient randomized solutions to the problem  are known, its deterministic complexity has been open.  The  paper exhibits representations that permit the execution of  dictionary operations in optimal deterministic time when the  dictionary is sufficiently sparse or sufficiently dense.   The results demonstrate an exponential separation between  the deterministic and randomized complexities of the  problem. Unique representations are applied to obtain efficient data  structures for maintaining  a dynamic collection of  sets/sequences under queries that test the equality of a  pair of objects.  The data structure for set equality  testing tests equality of sets in constant time and  processes set updates in $O(log m)$ amortized time and  $O(log m)$ space, where $m$ denotes the total number of  updates performed.  It is based on an efficient  implementation of cascades of C{vipt ONS} operations on  uniquely stored S-expressions.  The data structure for  sequence equality testing tests  equality of sequences in  constant time and processes updates in $O(sqrt{n log m},  + log m)$ amortized time and $O(sqrt{n})$ amortized space where $n$ denotes the length of the sequence that is updated  and $m$ denotes the total number of updates performed.},
journal = {SIAM J. Comput.},
month = feb,
pages = {24–44},
numpages = {21},
keywords = {dictionary, S-expressions, sequences, unique representation, programming languages, sets, data structures, equality testing, binary search tree}
}

@article{10.1137/S0097539790186716,
author = {Frederickson, Greg N. and Rodger, Susan H.},
title = {An NC Algorithm for Scheduling Unit-Time Jobs with Arbitrary Release Times and Deadlines},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539790186716},
doi = {10.1137/S0097539790186716},
abstract = {The problem of scheduling $n$ unit-time jobs with real-valued release times and deadlines is shown to be in NC. The solution is based on characterizations of a canonical schedule and best subset of jobs to be scheduled in a given time interval. The algorithm runs on a CREW PRAM in $O((log n)^2)$ time and uses $O(n^4/ log n)$ processors.},
journal = {SIAM J. Comput.},
month = feb,
pages = {185–211},
numpages = {27},
keywords = {scheduling, deadline, parallel algorithm, release time}
}

@article{10.1137/S009753979018330X,
author = {Matousek, Jiri and Pach, Janos and Sharir, Micha and Sifrony, Shmuel and Welzl, Emo},
title = {Fat Triangles Determine Linearly Many Holes},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S009753979018330X},
doi = {10.1137/S009753979018330X},
abstract = {The authors show that for every fixed $delta&gt;0$ the following holds: If $F$ is a union of $n$ triangles, all of whose angles are at least $delta$, then the complement of $F$ has $O(n)$ connected components  and the boundary of $F$ consists of $O(n log log n)$ straight segments (where the constants of proportionality depend on $delta$).  This latter complexity becomes linear if all triangles are of roughly the same size or if they are all infinite wedges.},
journal = {SIAM J. Comput.},
month = feb,
pages = {154–169},
numpages = {16},
keywords = {Davenport Schinzel sequences, combinatorial geometry, union of geometric figures, fat triangles, computational geometry}
}

@article{10.1137/S0097539789173597,
author = {Apostolico, Alberto and Italiano, Giuseppe F. and Gambosi, Giorgio and Talamo, Maurizio},
title = {The Set Union Problem with Unlimited Backtracking},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {23},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/S0097539789173597},
doi = {10.1137/S0097539789173597},
abstract = {An extension of the disjoint set union problem is considered, where the extra primitive backtrack($i$) can undo the last $i$ unions not yet undone. Let $n$ be the total number of elements in all the sets. A data structure is presented that supports each union and find in $O(log n/log log n)$ worst-case time and each backtrack($i$) in $O(1)$ worst-case time, irrespective of $i$.  The total space required by the data structure is $O(n)$.  A byproduct of this construction is a partially persistent data structure for the standard set union problem, capable of supporting union, find, and find-in-the-past operations, each in $O(log n/log log n)$ worst-case time.  All these upper bounds are tight for the class of  separable-pointer algorithms as well as in the cell probe model of  computation.},
journal = {SIAM J. Comput.},
month = feb,
pages = {50–70},
numpages = {21},
keywords = {deunion, disjoint set union, unlimited backtrack, design and analysis of algorithms}
}

@article{10.1137/0222080,
author = {Kushilevitz, Eyal and Mansour, Yishay},
title = {Learning Decision Trees Using the Fourier Spectrum},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222080},
doi = {10.1137/0222080},
journal = {SIAM J. Comput.},
month = dec,
pages = {1331–1348},
numpages = {18},
keywords = {decision trees, machine learning, Fourier transform}
}

@article{10.1137/0222079,
author = {Chu, Jiang-Hsing and Knott, Gary D.},
title = {A New Method for Computing Page-Fault Rates},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222079},
doi = {10.1137/0222079},
journal = {SIAM J. Comput.},
month = dec,
pages = {1319–1330},
numpages = {12},
keywords = {order-k programs, regular expressions, page-fault rate, analysis of algorithms, caching}
}

@article{10.1137/0222078,
author = {Chen, Bo},
title = {A Better Heuristic for Preemptive Parallel Machine Scheduling with Batch Setup Times},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222078},
doi = {10.1137/0222078},
journal = {SIAM J. Comput.},
month = dec,
pages = {1303–1318},
numpages = {16},
keywords = {heuristics, preemptive scheduling, identical parallel machines, batch setup times, worst-case performance}
}

@article{10.1137/0222077,
author = {Chazelle, Bernard and Edelsbrunner, Herbert and Guibas, Leonidas and Sharir, Micha and Snoeyink, Jack},
title = {Computing a Face in an Arrangement of Line Segments and Related Problems},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222077},
doi = {10.1137/0222077},
journal = {SIAM J. Comput.},
month = dec,
pages = {1286–1302},
numpages = {17},
keywords = {probabilistic backwards analysis, computational geometry, Davenport-Schinzel sequences, arrangements, randomized incremental algorithms}
}

@article{10.1137/0222076,
author = {Karpinski, Marek and Werther, Throsten},
title = {VC Dimension and Uniform Learnability of Sparse Polynomials and Rational Functions},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222076},
doi = {10.1137/0222076},
journal = {SIAM J. Comput.},
month = dec,
pages = {1276–1285},
numpages = {10},
keywords = {computational learning theory, VC dimension, sparse polynomials, regression function}
}

@article{10.1137/0222075,
author = {Gavald\`{a}, Ricard and Watanabe, Osamu},
title = {On the Computational Complexity of Small Descriptions},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222075},
doi = {10.1137/0222075},
journal = {SIAM J. Comput.},
month = dec,
pages = {1257–1275},
numpages = {19},
keywords = {polynomial-time reducibility, polynomial-time equivalence, tally sets, computational complexity, sparse sets, Kolmogorov complexity}
}

@article{10.1137/0222074,
author = {Rhee, Wansoo T. and Talagrand, Michel},
title = {On-Line Bin Packing of Items of Random Sizes, II},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222074},
doi = {10.1137/0222074},
journal = {SIAM J. Comput.},
month = dec,
pages = {1251–1256},
numpages = {6},
keywords = {bin packing, on-line algorithm, stochastic}
}

@article{10.1137/0222073,
author = {Pan, Victor and Reif, John},
title = {Fast and Efficient Parallel Solution of Sparse Linear Systems},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222073},
doi = {10.1137/0222073},
journal = {SIAM J. Comput.},
month = dec,
pages = {1227–1250},
numpages = {24},
keywords = {parallel algorithms, nested dissection, graph separators, parallel complexity, sparse linear systems}
}

@article{10.1137/0222072,
author = {He, Xin},
title = {On Finding the Rectangular Duals of Planar Triangular Graphs},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222072},
doi = {10.1137/0222072},
journal = {SIAM J. Comput.},
month = dec,
pages = {1218–1226},
numpages = {9},
keywords = {planar graph, rectangular dual}
}

@article{10.1137/0222071,
author = {Karger, David R. and Koller, Daphne and Phillips, Steven J.},
title = {Finding the Hidden Path: Time Bounds for All-Pairs Shortest Paths},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222071},
doi = {10.1137/0222071},
journal = {SIAM J. Comput.},
month = dec,
pages = {1199–1217},
numpages = {19},
keywords = {weighted graphs, lower bound, random graphs, all-pairs shortest paths, path comparison}
}

@article{10.1137/0222070,
author = {Szpankowski, Wojciech},
title = {A Generalized Suffix Tree and Its (Un)Expected Asymptotic Behaviors},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222070},
doi = {10.1137/0222070},
journal = {SIAM J. Comput.},
month = dec,
pages = {1176–1198},
numpages = {23},
keywords = {height, mixing condition, probabilistic models, shortest path, Re´nyi's entropy, typical depth and depth of insertion, algorithms on words, generalized suffix trees, data compression}
}

@article{10.1137/0222069,
author = {Goldreich, Oded and Krawczyk, Hugo and Luby, Michael},
title = {On the Existence of Pseudorandom Generators},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222069},
doi = {10.1137/0222069},
journal = {SIAM J. Comput.},
month = dec,
pages = {1163–1175},
numpages = {13},
keywords = {complexity theory, cryptography, pseudorandom generators, one-way functions, randomness}
}

@article{10.1137/0222068,
author = {Cai, Jiazhen and Han, Xiaofeng and Tarjan, Robert E.},
title = {An <i>O(m</i> Log <i>n)</i>-Time Algorithm for the Maximal Planar Subgraph Problem},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222068},
doi = {10.1137/0222068},
journal = {SIAM J. Comput.},
month = dec,
pages = {1142–1162},
numpages = {21},
keywords = {planar graph, embedding, selection tree, depth-first search, complexity}
}

@article{10.1137/0222067,
author = {Jiang, Tao and Ravikumar, B.},
title = {Minimal NFA Problems Are Hard},
year = {1993},
issue_date = {Dec. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222067},
doi = {10.1137/0222067},
journal = {SIAM J. Comput.},
month = dec,
pages = {1117–1141},
numpages = {25},
keywords = {finite automaton, PSPACE-complete, minimization, Np-complete}
}

@article{10.1137/0222066,
author = {Jerrum, Mark and Sinclair, Alistair},
title = {Polynomial-Time Approximation Algorithms for the Ising Model},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222066},
doi = {10.1137/0222066},
journal = {SIAM J. Comput.},
month = oct,
pages = {1087–1116},
numpages = {30},
keywords = {ferromagnetism, #P-completeness, spin-glasses, Markov chains, approximation algorithms, Ising model, Monte Carlo simulation, rapid mixing, statistical physics, partition function}
}

@article{10.1137/0222065,
author = {Lutz, Jack H.},
title = {A Pseudorandom Oracle Characterization of BPP},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222065},
doi = {10.1137/0222065},
journal = {SIAM J. Comput.},
month = oct,
pages = {1075–1086},
numpages = {12},
keywords = {BPP, pseudorandom oracles, pseudorandom generators, probabilistic complexity, resource-bounded measure, random oracles}
}

@article{10.1137/0222064,
author = {Bollob\'{a}s, B\'{e}la and Simon, Istvan},
title = {Probabilistic Analysis of Disjoint Set Union Algorithms},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222064},
doi = {10.1137/0222064},
journal = {SIAM J. Comput.},
month = oct,
pages = {1053–1074},
numpages = {22},
keywords = {equivalence algorithms, expected time bounds, Quick-Find algorithms, analysis of algorithms, probabilistic method, Union-Find problem, disjoint set union, random graphs}
}

@article{10.1137/0222063,
author = {Formann, M. and Hagerup, T. and Haralambides, J. and Kaufmann, M. and Leighton, F. T. and Symvonis, A. and Welzl, E. and Woeginger, G.},
title = {Drawing Graphs in the Plane with High Resolution},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222063},
doi = {10.1137/0222063},
journal = {SIAM J. Comput.},
month = oct,
pages = {1035–1052},
numpages = {18},
keywords = {square graph, graph layout, coloring, resolution}
}

@article{10.1137/0222062,
author = {Goldman, Sally A. and Rivest, Ronald L. and Schapire, Robert E.},
title = {Learning Binary Relations and Total Orders},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222062},
doi = {10.1137/0222062},
journal = {SIAM J. Comput.},
month = oct,
pages = {1006–1034},
numpages = {29},
keywords = {on-line learning, fully polynomial randomized approximation schemes, computational learning theory, mistake-bounded learning, machine learning, binary relations, total orders}
}

@article{10.1137/0222061,
author = {Feigenbaum, Joan and Fortnow, Lance},
title = {Random-Self-Reducibility of Complete Sets},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222061},
doi = {10.1137/0222061},
journal = {SIAM J. Comput.},
month = oct,
pages = {994–1005},
numpages = {12},
keywords = {random-self-reductions, program checkers, interactive proof systems, complexity classes}
}

@article{10.1137/0222060,
author = {Lou, Ruey-der and Sarrafzadeh, Majid},
title = {An Optimal Algorithm for the Maximum Three-Chain Problem},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222060},
doi = {10.1137/0222060},
journal = {SIAM J. Comput.},
month = oct,
pages = {976–993},
numpages = {18},
keywords = {chains, point dominance, lower bound, optimal algorithm, computational geometry}
}

@article{10.1137/0222059,
author = {Blass, Andreas and Gurevich, Yuri},
title = {Randomizing Reductions of Search Problems},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222059},
doi = {10.1137/0222059},
journal = {SIAM J. Comput.},
month = oct,
pages = {949–975},
numpages = {27},
keywords = {reduction, randomization, search problems, average case}
}

@article{10.1137/0222058,
author = {Manber, Udi and Myers, Gene},
title = {Suffix Arrays: A New Method for on-Line String Searches},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222058},
doi = {10.1137/0222058},
journal = {SIAM J. Comput.},
month = oct,
pages = {935–948},
numpages = {14},
keywords = {text indexing, suffix trees, string matching, pattern matching, string searching, inverted indices}
}

@article{10.1137/0222057,
author = {Halstenberg, Bernd and Reischuk, R\"{u}diger},
title = {Different Modes of Communication},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222057},
doi = {10.1137/0222057},
journal = {SIAM J. Comput.},
month = oct,
pages = {913–934},
numpages = {22},
keywords = {k-round protocols, communication complexity, probabilistic protocols}
}

@article{10.1137/0222056,
author = {Hsu, Tsan-Sheng and Ramachandran, Vijaya},
title = {Finding a Smallest Augmentation to Biconnect a Graph},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222056},
doi = {10.1137/0222056},
journal = {SIAM J. Comput.},
month = oct,
pages = {889–912},
numpages = {24},
keywords = {EREW PRAM, parallel computation, linear time, graph augmentation, biconnected graph, poly-log time}
}

@article{10.1137/0222055,
author = {Bar-Yehuda, Reuven and Israeli, Amos and Itai, Alon},
title = {Multiple Communication Im Multihop Radio Networks},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222055},
doi = {10.1137/0222055},
journal = {SIAM J. Comput.},
month = aug,
pages = {875–887},
numpages = {13},
keywords = {point-to-point routing, radio networks, distributed algorithms, average case analysis, randomized algorithms, queueing theory, broadcast}
}

@article{10.1137/0222054,
author = {Harel, David and Raz, Danny},
title = {Deciding Properties of Nonregular Programs},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222054},
doi = {10.1137/0222054},
journal = {SIAM J. Comput.},
month = aug,
pages = {857–874},
numpages = {18},
keywords = {propositional dynamic logic (PDL), stack automata, context-free languages, decidability}
}

@article{10.1137/0222053,
author = {Naor, Joseph (Seffi) and Naor, Moni},
title = {Small-Bias Probability Spaces: Efficient Constructions and Applications},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222053},
doi = {10.1137/0222053},
journal = {SIAM J. Comput.},
month = aug,
pages = {838–856},
numpages = {19},
keywords = {discrepancy, derandomization, randomized algorithms, VLSI circuit testing}
}

@article{10.1137/0222052,
author = {Kearns, Michael and Li, Ming},
title = {Learning in the Presence of Malicious Errors},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222052},
doi = {10.1137/0222052},
journal = {SIAM J. Comput.},
month = aug,
pages = {807–837},
numpages = {31}
}

@article{10.1137/0222051,
author = {Agarwal, Pankaj K. and Matou\v{s}ek, Ji\v{r}\'{\i}},
title = {Ray Shooting and Parametric Search},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222051},
doi = {10.1137/0222051},
journal = {SIAM J. Comput.},
month = aug,
pages = {794–806},
numpages = {13},
keywords = {range searching, ray shooting, arrangements, convex polytope, parametric search}
}

@article{10.1137/0222050,
author = {Agarwal, Pankaj K. and Pellegrini, Marco and Sharir, Micha},
title = {Counting Circular Arc Intersections},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222050},
doi = {10.1137/0222050},
journal = {SIAM J. Comput.},
month = aug,
pages = {778–793},
numpages = {16},
keywords = {point location, random sampling, arrangements, partition tree}
}

@article{10.1137/0222049,
author = {Goldstein, Arthur S. and Reingold, Edward M.},
title = {A Fibonacci Version of Kraft's Inequality Applied Discrete Unimodal Search},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222049},
doi = {10.1137/0222049},
journal = {SIAM J. Comput.},
month = aug,
pages = {751–777},
numpages = {27},
keywords = {optimal algorithms, Ackermann's function, unbounded search, inverse Ackermann's function, unimodal search, Kraft's inequality, Fibonacci numbers, Fibonacci search, unimodal functions}
}

@article{10.1137/0222048,
author = {Moser, Louise E. and Melliar-Smith, P. M. and Agrawala, Vivek},
title = {Asynchronous Fault-Tolerant Total Ordering Algorithms},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222048},
doi = {10.1137/0222048},
journal = {SIAM J. Comput.},
month = aug,
pages = {727–750},
numpages = {24},
keywords = {total order, partial order, distributed computing, fault tolerance, probabilistic algorithm, asynchronism}
}

@article{10.1137/0222047,
author = {Goldman, Sally A. and Kearns, Michael J. and Schapire, Robert E.},
title = {Exact Identification of Read-Once Formulas Using Fixed Points of Amplification Functions},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222047},
doi = {10.1137/0222047},
journal = {SIAM J. Comput.},
month = aug,
pages = {705–726},
numpages = {22},
keywords = {amplification functions, learning with noise, Boolean formulas, read-once formulas, computational learning theory, machine learning, learning with queries}
}

@article{10.1137/0222046,
author = {D\"{u}r, A. and Grabmeier, J.},
title = {Applying Coding Theory to Sparse Interpolation},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222046},
doi = {10.1137/0222046},
journal = {SIAM J. Comput.},
month = aug,
pages = {695–704},
numpages = {10},
keywords = {interpolation, sparse multivariate polynomials, Reed-Muller codes, Boolean polynomials, Reed-Solomon codes, coding theory}
}

@article{10.1137/0222045,
author = {Niederreiter, H. and Schnorr, C. P.},
title = {Local Randomness in Polynomial Random Number and Random Function Generators},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222045},
doi = {10.1137/0222045},
journal = {SIAM J. Comput.},
month = aug,
pages = {684–694},
numpages = {11},
keywords = {random function generator, local randomness, random number generator, one-way functions, polynomial random number generator, families of hash functions}
}

@article{10.1137/0222044,
author = {Goerdt, Andreas},
title = {Regular Resolution versus Unrestricted Resolution},
year = {1993},
issue_date = {Aug. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222044},
doi = {10.1137/0222044},
journal = {SIAM J. Comput.},
month = aug,
pages = {661–683},
numpages = {23},
keywords = {resolution theorem proving, propositional logic, regular resolution}
}

@article{10.1137/0222043,
author = {Coffman, E. G. and Flatto, Leopold and Wright, Paul E.},
title = {A Stochastic Checkpoint Optimization Problem},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222043},
doi = {10.1137/0222043},
journal = {SIAM J. Comput.},
month = jun,
pages = {650–659},
numpages = {10},
keywords = {online algorithms, checkpoints, moving-servers, stochastic optimization}
}

@article{10.1137/0222042,
author = {Rosenkrantz, Daniel J. and Hunt, Harry B.},
title = {The Complexity of Processing Hierarchical Specifications},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222042},
doi = {10.1137/0222042},
journal = {SIAM J. Comput.},
month = jun,
pages = {627–649},
numpages = {23},
keywords = {computational complexity, hierarchical specification, acyclic circuits, CAD systems, combinational circuits, sequential circuits, cyclic circuits}
}

@article{10.1137/0222041,
author = {Bini, Dario and Pan, Victor},
title = {Improved Parallel Polynomial Division},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222041},
doi = {10.1137/0222041},
journal = {SIAM J. Comput.},
month = jun,
pages = {617–626},
numpages = {10},
keywords = {parallel algorithms, triangular Toeplitz matrices, computational complexity, polynomial division}
}

@article{10.1137/0222040,
author = {Fussell, Donald and Ramachandran, Vijaya and Thurimella, Ramakrishna},
title = {Finding Triconnected Components by Local Replacement},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222040},
doi = {10.1137/0222040},
journal = {SIAM J. Comput.},
month = jun,
pages = {587–616},
numpages = {30},
keywords = {triconnectivity, parallel algorithm, PRAM, graph, vertex connectivity}
}

@article{10.1137/0222039,
author = {Kirousis, Lefteris M. and Serna, Maria and Spirakis, Paul},
title = {Parallel Complexity of the Connected Subgraph Problem},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222039},
doi = {10.1137/0222039},
journal = {SIAM J. Comput.},
month = jun,
pages = {573–586},
numpages = {14},
keywords = {algorithms in NC, connected subgraphs, parallel algorithms, P-complete problems, connectivity, graphs}
}

@article{10.1137/0222038,
author = {Buss, Jonathan F. and Goldsmith, Judy},
title = {Nondeterminism within <i>P</i>},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222038},
doi = {10.1137/0222038},
journal = {SIAM J. Comput.},
month = jun,
pages = {560–572},
numpages = {13},
keywords = {nondeterminism, quasilinear time, computational complexity}
}

@article{10.1137/0222037,
author = {Kalorkoti, K.},
title = {Inverting Polynomials and Formal Power Series},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222037},
doi = {10.1137/0222037},
journal = {SIAM J. Comput.},
month = jun,
pages = {552–559},
numpages = {8},
keywords = {formal power series, inverse, algebraic complexity, polynomials}
}

@article{10.1137/0222036,
author = {Edelsbrunner, Herbert and Tan, Tiow-Seng},
title = {A Quadratic Time Algorithm for the Minmax Length Triangulation},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222036},
doi = {10.1137/0222036},
journal = {SIAM J. Comput.},
month = jun,
pages = {527–551},
numpages = {25},
keywords = {two dimensions, computational geometry, minmax edge length, normed metrics, point sets, triangulations}
}

@article{10.1137/0222035,
author = {Yeap, Kok-Hoo and Sarrafzadeh, Majid},
title = {Floor-Planning by Graph Dualization: 2-Concave Rectilinear Modules},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222035},
doi = {10.1137/0222035},
journal = {SIAM J. Comput.},
month = jun,
pages = {500–526},
numpages = {27},
keywords = {planar graphs, graph dualization, floor-planning, CRM}
}

@article{10.1137/0222034,
author = {Bienstock, Daniel and Diaz, Nicole},
title = {Blocking Small Cuts in a Network, and Related Problems},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222034},
doi = {10.1137/0222034},
journal = {SIAM J. Comput.},
month = jun,
pages = {482–499},
numpages = {18},
keywords = {connectivity, complexity, graph algorithms}
}

@article{10.1137/0222033,
author = {Kao, Ming-Yang and Shannon, Gregory E.},
title = {Linear-Processor NC Algorithms for Planar Directed Graphs II: Directed Spanning Trees},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222033},
doi = {10.1137/0222033},
journal = {SIAM J. Comput.},
month = jun,
pages = {460–481},
numpages = {22},
keywords = {duplicate removal, planar directed graphs, tree rerooting, planar orientation, vertex contraction, edge cutting, strong connectivity, directed spanning trees, linear-processor NC algorithms, vertex expansion}
}

@article{10.1137/0222032,
author = {Kao, Ming-Yang},
title = {Linear-Processor NC Algorithms for Planar Directed Graphs I: Strongly Connected Components},
year = {1993},
issue_date = {June 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222032},
doi = {10.1137/0222032},
journal = {SIAM J. Comput.},
month = jun,
pages = {431–459},
numpages = {29},
keywords = {vertex contraction, strongly connected components, planar topology, planar orientation, vertex expansion, planar directed graphs, linear-processor NC algorithms, edge cutting}
}

@article{10.1137/0222031,
author = {Edelsbrunner, Herbert and Seidel, Raimund and Sharir, Micha},
title = {On the Zone Theorem for Hyperplane Arrangements},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222031},
doi = {10.1137/0222031},
journal = {SIAM J. Comput.},
month = apr,
pages = {418–429},
numpages = {12},
keywords = {induction, sweep, discrete and computational geometry, hyperplanes, counting faces, zones, arrangements}
}

@article{10.1137/0222030,
author = {Alon, Noga and Naor, Moni},
title = {Coin-Flipping Games Immune against Linear-Sized Coalitions},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222030},
doi = {10.1137/0222030},
journal = {SIAM J. Comput.},
month = apr,
pages = {403–417},
numpages = {15},
keywords = {leader election, distributed computing, fault tolerance, perfect information games, coin-flipping}
}

@article{10.1137/0222029,
author = {Book, Ronald V. and Lutz, Jack H.},
title = {On Languages with Very High Space-Bounded Kolmogorov Complexity},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222029},
doi = {10.1137/0222029},
journal = {SIAM J. Comput.},
month = apr,
pages = {395–402},
numpages = {8},
keywords = {bounded truth-table reducibility, Kolmogorov complexity, sparse sets, exponential space}
}

@article{10.1137/0222028,
author = {Moran, Shlomo and Warmuth, Manfred K.},
title = {Gap Theorems for Distributed Computation},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222028},
doi = {10.1137/0222028},
journal = {SIAM J. Comput.},
month = apr,
pages = {379–394},
numpages = {16},
keywords = {distributed algorithms, gap theorem, lower bounds, asynchronous, message complexity, ring of processors, bit complexity}
}

@article{10.1137/0222027,
author = {Cypher, Robert},
title = {Theoretical Aspects of VLSI Pin Limitations},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222027},
doi = {10.1137/0222027},
journal = {SIAM J. Comput.},
month = apr,
pages = {356–378},
numpages = {23},
keywords = {pin limitations, VLSI theory, parallel sorting}
}

@article{10.1137/0222026,
author = {Galambos, G\'{a}bor and Woeginger, Gerhard J.},
title = {An On-Line Scheduling Heuristic with Better Worst Case Ratio than Graham's List Scheduling},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222026},
doi = {10.1137/0222026},
journal = {SIAM J. Comput.},
month = apr,
pages = {349–355},
numpages = {7},
keywords = {scheduling, worst case bounds, combinatorial problems, online algorithms}
}

@article{10.1137/0222025,
author = {Coffman, E. G. and Flatto, Leopold and Wright, Paul E.},
title = {Optimal Stochastic Allocation of Machines under Waiting-Time Constraints},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222025},
doi = {10.1137/0222025},
journal = {SIAM J. Comput.},
month = apr,
pages = {332–348},
numpages = {17},
keywords = {optimal scheduling, Markovian decision process, Bellman equation}
}

@article{10.1137/0222024,
author = {Bajaj, Chanderjit and Canny, John and Garrity, Thomas and Warren, Joe},
title = {Factoring Rational Polynomials over the Complex Numbers},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222024},
doi = {10.1137/0222024},
journal = {SIAM J. Comput.},
month = apr,
pages = {318–331},
numpages = {14},
keywords = {algebraic geometry, polynomials, NC, factoring}
}

@article{10.1137/0222023,
author = {Bugrara, Khaled M. and Purdom, Paul Walton},
title = {Average Time Analysis of Clause Order Backtracking},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222023},
doi = {10.1137/0222023},
journal = {SIAM J. Comput.},
month = apr,
pages = {303–317},
numpages = {15},
keywords = {average time, NP-complete, Davis-Putnam, backtracking, searching, satisfiability, combinatorial search, pure literal rule}
}

@article{10.1137/0222022,
author = {Santha, Miklos and Wilson, Christopher},
title = {Limiting Negations in Constant Depth Circuits},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222022},
doi = {10.1137/0222022},
journal = {SIAM J. Comput.},
month = apr,
pages = {294–302},
numpages = {9},
keywords = {circuit complexity, negation gates, monotone circuits}
}

@article{10.1137/0222021,
author = {Karmarkar, N. and Karp, R. and Lipton, R. and Lov\'{a}sz, L. and Luby, M.},
title = {A Monte-Carlo Algorithm for Estimating the Permanent},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222021},
doi = {10.1137/0222021},
journal = {SIAM J. Comput.},
month = apr,
pages = {284–293},
numpages = {10},
keywords = {bipartite graph, permanent, Monte-Carlo algorithm, matching, determinant}
}

@article{10.1137/0222020,
author = {Goddard, Wayne and Kenyon, Claire and King, Valerie and Schulman, Leonard J.},
title = {Optimal Randomized Algorithms for Local Sorting and Set-Maxima},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222020},
doi = {10.1137/0222020},
journal = {SIAM J. Comput.},
month = apr,
pages = {272–283},
numpages = {12},
keywords = {randomized algorithms, graph algorithms, comparison model, sorting, partial order}
}

@article{10.1137/0222019,
author = {de la Vega, Wenceslas Fernandez and Kannan, Sampath and Santha, Miklos},
title = {Two Probabilistic Results on Merging},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222019},
doi = {10.1137/0222019},
journal = {SIAM J. Comput.},
month = apr,
pages = {261–271},
numpages = {11},
keywords = {randomized algorithm, lower bound, merging, information theory}
}

@article{10.1137/0222018,
author = {Tarhio, Jorma and Ukkonen, Esko},
title = {Approximate Boyer-Moore String Matching},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222018},
doi = {10.1137/0222018},
journal = {SIAM J. Comput.},
month = apr,
pages = {243–260},
numpages = {18},
keywords = {k differences problem, edit distance, k mismatches problem, string matching, Boyer-Moore algorithm}
}

@article{10.1137/0222017,
author = {Berkman, Omer and Vishkin, Uzi},
title = {Recursive Star-Tree Parallel Data Structure},
year = {1993},
issue_date = {April 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222017},
doi = {10.1137/0222017},
journal = {SIAM J. Comput.},
month = apr,
pages = {221–242},
numpages = {22},
keywords = {parallel data structures, lowest common ancestors, parallel algorithms}
}

@article{10.1137/0222016,
author = {Nisan, Noam and Wigderson, Avi},
title = {Rounds in Communication Complexity Revisited},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222016},
doi = {10.1137/0222016},
journal = {SIAM J. Comput.},
month = feb,
pages = {211–219},
numpages = {9},
keywords = {monotone circuits, information, communication complexity, rounds}
}

@article{10.1137/0222015,
author = {Kratochv\'{\i}l, Jan and Savick\'{y}, Petr and Tuza, Zsolt},
title = {One More Occurrence of Variables Makes Satisfiability Jump from Trivial to NP-Complete},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222015},
doi = {10.1137/0222015},
journal = {SIAM J. Comput.},
month = feb,
pages = {203–210},
numpages = {8},
keywords = {conjunctive normal form, Boolean formula, satisfiability, NP-completeness}
}

@article{10.1137/0222014,
author = {Weber, Andreas},
title = {Decomposing Finite-Valued Transducers and Deciding Their Equivalence},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222014},
doi = {10.1137/0222014},
journal = {SIAM J. Comput.},
month = feb,
pages = {175–202},
numpages = {28},
keywords = {valuedness, finite valued, equivalence problem, finite transducer}
}

@article{10.1137/0222013,
author = {Cheriyan, Joseph and Kao, Ming-Yang and Thurimella, Ramakrishna},
title = {Scan-First Search and Sparse Certificates: An Improved Parallel Algorithm for <i>k</i>-Vertex Connectivity},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222013},
doi = {10.1137/0222013},
journal = {SIAM J. Comput.},
month = feb,
pages = {157–174},
numpages = {18},
keywords = {graphs, vertex connectivity, PRAM, parallel algorithms}
}

@article{10.1137/0222012,
author = {Miltersen, Peter Bro},
title = {The Complexity of Malign Measures},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222012},
doi = {10.1137/0222012},
journal = {SIAM J. Comput.},
month = feb,
pages = {147–156},
numpages = {10},
keywords = {malignness, average case complexity}
}

@article{10.1137/0222011,
author = {Iwama, Kazuo},
title = {ASPACE(<i>o</i>(Log Log <i>n</i>)) is Regular},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222011},
doi = {10.1137/0222011},
journal = {SIAM J. Comput.},
month = feb,
pages = {136–146},
numpages = {11},
keywords = {alternating Turing machines, space lower bounds}
}

@article{10.1137/0222010,
author = {Oyamaguchi, Michio},
title = {NV-Sequentiality: A Decidable Condition for Call-by-Need Computations in Term-Rewriting Systems},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222010},
doi = {10.1137/0222010},
journal = {SIAM J. Comput.},
month = feb,
pages = {114–135},
numpages = {22},
keywords = {left-linear system, term-rewriting system, call-by-need computation, strong sequentiality, sequentiality}
}

@article{10.1137/0222009,
author = {Geffert, Viliam},
title = {Tally Versions of the Savitch and Immerman-Szelepcse´Nyi Theorems for Sublogarithmic Space},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222009},
doi = {10.1137/0222009},
journal = {SIAM J. Comput.},
month = feb,
pages = {102–113},
numpages = {12},
keywords = {tally sets, space bounded computation, nondeterministic space, nondeterministic Turing machine}
}

@article{10.1137/0222008,
author = {Kundu, Sukhamay},
title = {An <i>O(n)</i> Algorithm for Determining the Subregion-Tree Representation of a Rectangular Dissection},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222008},
doi = {10.1137/0222008},
journal = {SIAM J. Comput.},
month = feb,
pages = {79–101},
numpages = {23},
keywords = {transitive reduction, rectangular dissection, wall representation, subregion representation, acyclic digraph, depth-first search}
}

@article{10.1137/0222007,
author = {Friedman, Joel},
title = {A Note on Poset Geometries},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222007},
doi = {10.1137/0222007},
journal = {SIAM J. Comput.},
month = feb,
pages = {72–78},
numpages = {7},
keywords = {poset balancing, partial order, linear extension}
}

@article{10.1137/0222006,
author = {Cypher, Robert},
title = {A Lower Bound on the Size of Shellsort Sorting Networks},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222006},
doi = {10.1137/0222006},
journal = {SIAM J. Comput.},
month = feb,
pages = {62–71},
numpages = {10},
keywords = {lower bounds, shellsort, parallel sorting, sorting networks}
}

@article{10.1137/0222005,
author = {Frederickson, Greg N.},
title = {A Note on the Complexity of a Simple Transportation Problem},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222005},
doi = {10.1137/0222005},
journal = {SIAM J. Comput.},
month = feb,
pages = {57–61},
numpages = {5},
keywords = {circular track, graph augmentation, transportation problems, robot arm motion}
}

@article{10.1137/0222004,
author = {Mao, Weizhen},
title = {Tight Worst-Case Performance Bounds for next-<i>k</i>-Fit Bin Packing},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222004},
doi = {10.1137/0222004},
journal = {SIAM J. Comput.},
month = feb,
pages = {46–56},
numpages = {11},
keywords = {worst-case performance, bin packing, approximation algorithm}
}

@article{10.1137/0222003,
author = {Hern\'{a}ndez, H\'{e}ctor J. and Wang, Ke},
title = {On the Boundedness of Constant-Time-Maintainable Database Schemes},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222003},
doi = {10.1137/0222003},
journal = {SIAM J. Comput.},
month = feb,
pages = {29–45},
numpages = {17},
keywords = {database, representative instance, constraint enforcement, query processing, boundedness, dependencies}
}

@article{10.1137/0222002,
author = {Galil, Zvi and Italiano, Giuseppe F.},
title = {Maintaining the 3-Edge-Connected Components of a Graph on-Line},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222002},
doi = {10.1137/0222002},
journal = {SIAM J. Comput.},
month = feb,
pages = {11–28},
numpages = {18},
keywords = {vertex connectivity, dynamic data structures, edge connectivity, analysis of algorithms}
}

@article{10.1137/0222001,
author = {Fiat, Amos and Naor, Moni},
title = {Implicit <i>O</i>(1) Probe Search},
year = {1993},
issue_date = {Feb. 1993},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {22},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0222001},
doi = {10.1137/0222001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–10},
numpages = {10},
keywords = {spatial complexity, hashing, perfect hashing, Ramsey theory, randomness in computation}
}

@article{10.1137/0221071,
author = {Shokrollahi, Mohammad Amin},
title = {Optimal Algorithms for Multiplication in Certain Finite Fields Using Elliptic Curves},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221071},
doi = {10.1137/0221071},
journal = {SIAM J. Comput.},
month = dec,
pages = {1193–1198},
numpages = {6},
keywords = {elliptic curves, finite fields, bilinear complexity}
}

@article{10.1137/0221070,
author = {Dixon, Brandon and Rauch, Monika and Tarjan, Robert E.},
title = {Verification and Sensitivity Analysis of Minimum Spanning Trees in Linear Time},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221070},
doi = {10.1137/0221070},
journal = {SIAM J. Comput.},
month = dec,
pages = {1184–1192},
numpages = {9},
keywords = {network optimization, divide and conquer, program checking, minimum spanning tree, sensitivity analysis}
}

@article{10.1137/0221069,
author = {Prodinger, Helmut},
title = {External Internal Nodes in Digital Search Trees via Mellin Transforms},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221069},
doi = {10.1137/0221069},
journal = {SIAM J. Comput.},
month = dec,
pages = {1180–1183},
numpages = {4},
keywords = {Mellin transform, digital search trees}
}

@article{10.1137/0221068,
author = {Bellantoni, Stephen and Pitassi, Toniann and Urquhart, Alasdair},
title = {Approximation and Small-Depth Frege Proofs},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221068},
doi = {10.1137/0221068},
journal = {SIAM J. Comput.},
month = dec,
pages = {1161–1179},
numpages = {19},
keywords = {proof theory, lower bounds, complexity of propositional proof systems}
}

@article{10.1137/0221067,
author = {Tompa, Martin},
title = {Lower Bounds on Universal Traversal Sequences for Cycles and Other Low Degree Graphs},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221067},
doi = {10.1137/0221067},
journal = {SIAM J. Comput.},
month = dec,
pages = {1153–1160},
numpages = {8},
keywords = {lower bound, circumnavigation, universal traversal sequence, reflecting sequence, cycle, graph traversal}
}

@article{10.1137/0221066,
author = {Frederickson, Greg N. and Guan, D. J.},
title = {Preemptive Ensemble Motion Planning on a Tree},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221066},
doi = {10.1137/0221066},
journal = {SIAM J. Comput.},
month = dec,
pages = {1130–1152},
numpages = {23}
}

@article{10.1137/0221065,
author = {Bein, Wolfgang W. and Kamburowski, Jerzy and Stallmann, Matthias F. M.},
title = {Optimal Reduction of Two-Terminal Directed Acyclic Graphs},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221065},
doi = {10.1137/0221065},
journal = {SIAM J. Comput.},
month = dec,
pages = {1112–1129},
numpages = {18}
}

@article{10.1137/0221064,
author = {Wang, Jie},
title = {Polynomial Time Productivity, Approximations, and Levelability},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221064},
doi = {10.1137/0221064},
journal = {SIAM J. Comput.},
month = dec,
pages = {1100–1111},
numpages = {12}
}

@article{10.1137/0221063,
author = {Martel, Charles and Park, Arvin and Subramonian, Ramesh},
title = {Work-Optimal Asynchronous Algorithms for Shared Memory Parallel Computers},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221063},
doi = {10.1137/0221063},
journal = {SIAM J. Comput.},
month = dec,
pages = {1070–1099},
numpages = {30},
keywords = {primary 68Q22, 68R05, secondary 68Q25}
}

@article{10.1137/0221062,
author = {Galil, Zvi and Italiano, Giuseppe F.},
title = {Fully Dynamic Algorithms for 2-Edge Connectivity},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221062},
doi = {10.1137/0221062},
journal = {SIAM J. Comput.},
month = dec,
pages = {1047–1069},
numpages = {23}
}

@article{10.1137/0221061,
author = {Shih, Wei-Kuan and Chern, T. C. and Hsu, Wen-Lian},
title = {An <i>O</i>(<i>n</i><sup>2</sup> Log <i>n</i>) Algorithm for the Hamiltonian Cycle Problem on Circular-Arc Graphs},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221061},
doi = {10.1137/0221061},
journal = {SIAM J. Comput.},
month = dec,
pages = {1026–1046},
numpages = {21}
}

@article{10.1137/0221060,
author = {Renegar, James},
title = {On the Computational Complexity of Approximating Solutions for Real Algebraic Formulae},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221060},
doi = {10.1137/0221060},
journal = {SIAM J. Comput.},
month = dec,
pages = {1008–1025},
numpages = {18},
keywords = {roots, decision methods, polynomials}
}

@article{10.1137/0221059,
author = {Du, D. Z. and Hwang, F. K.},
title = {Reducing the Steiner Problem in a Normal Space},
year = {1992},
issue_date = {Dec. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221059},
doi = {10.1137/0221059},
journal = {SIAM J. Comput.},
month = dec,
pages = {1001–1007},
numpages = {7}
}

@article{10.1137/0221058,
author = {Balas, Egon and Xue, Jue},
title = {Addendum: Minimum Weighted Coloring of Triangulated Graphs, with Application to Maximum Weight Vertex Packing and Clique Finding in Arbitrary Graphs},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221058},
doi = {10.1137/0221058},
journal = {SIAM J. Comput.},
month = oct,
pages = {1000},
numpages = {1}
}

@article{10.1137/0221057,
author = {Cheng, Siu Wing and Janardan, Ravi},
title = {New Results on Dynamic Planar Point Location},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221057},
doi = {10.1137/0221057},
journal = {SIAM J. Comput.},
month = oct,
pages = {972–999},
numpages = {28},
keywords = {trees of bounded balance, dynamic data structure, priority search trees, computational geometry, point location, planar subdivision}
}

@article{10.1137/0221056,
author = {Loui, Michael C. and Luginbuhl, David R.},
title = {Optimal On-Line Simulations of Tree Machines by Random Access Machines},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221056},
doi = {10.1137/0221056},
journal = {SIAM J. Comput.},
month = oct,
pages = {959–971},
numpages = {13},
keywords = {Kolmogorov complexity, random access machine, on-line simulation, real-time simulation, tree machine, time complexity}
}

@article{10.1137/0221055,
author = {Heath, Lenwood S. and Rosenberg, Arnold L.},
title = {Laying out Graphs Using Queues},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221055},
doi = {10.1137/0221055},
journal = {SIAM J. Comput.},
month = oct,
pages = {927–958},
numpages = {32},
keywords = {graph embedding, separators, stack layout, bandwidth, book embedding, NP-completeness, queue layout, scheduling parallel processors, fault-tolerant computing}
}

@article{10.1137/0221054,
author = {Just, Bettina},
title = {Generalizing the Continued Fraction Algorithm to Arbitrary Dimensions},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221054},
doi = {10.1137/0221054},
journal = {SIAM J. Comput.},
month = oct,
pages = {909–926},
numpages = {18},
keywords = {integer relation, continued fraction algorithm, diophantine approximation}
}

@article{10.1137/0221053,
author = {Reif, John H. and Tate, Stephen R.},
title = {On Threshold Circuits and Polynomial Computation},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221053},
doi = {10.1137/0221053},
journal = {SIAM J. Comput.},
month = oct,
pages = {896–908},
numpages = {13},
keywords = {circuit complexity, finite field circuits, threshold circuits}
}

@article{10.1137/0221052,
author = {Dolev, Danny and Feder, Tom\'{a}s},
title = {Determinism vs. Nondeterminism in Multiparty Communication Complexity},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221052},
doi = {10.1137/0221052},
journal = {SIAM J. Comput.},
month = oct,
pages = {889–895},
numpages = {7},
keywords = {multiparty communication, communication complexity}
}

@article{10.1137/0221051,
author = {Suzuki, Ichiro and Yamashita, Masafumi},
title = {Searching for a Mobile Intruder in a Polygonal Region},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221051},
doi = {10.1137/0221051},
journal = {SIAM J. Comput.},
month = oct,
pages = {863–888},
numpages = {26},
keywords = {geometry visibility}
}

@article{10.1137/0221050,
author = {Breslauer, Danny and Galil, Zvi},
title = {A Lower Bound for Parallel String Matching},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221050},
doi = {10.1137/0221050},
journal = {SIAM J. Comput.},
month = oct,
pages = {856–862},
numpages = {7},
keywords = {parallel algorithms, period, lower bounds, string}
}

@article{10.1137/0221049,
author = {Yu, Lin and Rosenkrantz, Daniel J.},
title = {Representability of Design Objects by Ancestor-Controlled Hierarchical Specifications},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221049},
doi = {10.1137/0221049},
journal = {SIAM J. Comput.},
month = oct,
pages = {824–855},
numpages = {32},
keywords = {databases, configuration control, hierarchical modules, versions, module alternatives, conditional expansion, design objects}
}

@article{10.1137/0221048,
author = {Koch, Richard},
title = {Increasing the Size of a Network by a Constant Factor Can Increase Performance by More than a Constant Factor},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221048},
doi = {10.1137/0221048},
journal = {SIAM J. Comput.},
month = oct,
pages = {801–823},
numpages = {23},
keywords = {performance analysis, difference equations, parallel computation, interconnection network, parallel computer architecture}
}

@article{10.1137/0221047,
author = {Bini, Dario and Gemignani, Luca},
title = {On the Complexity of Polynomial Zeros},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221047},
doi = {10.1137/0221047},
journal = {SIAM J. Comput.},
month = aug,
pages = {781–799},
numpages = {19},
keywords = {Euclidean scheme, polynomial zeros, parallel complexity}
}

@article{10.1137/0221046,
author = {Buss, S. and Cook, S. and Gupta, A. and Ramachandran, V.},
title = {An Optimal Parallel Algorithm for Formula Evaluation},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221046},
doi = {10.1137/0221046},
journal = {SIAM J. Comput.},
month = aug,
pages = {755–780},
numpages = {26},
keywords = {log-time hierarchy, Boolean formulas, formula evaluation, parallel algorithms, circuit complexity}
}

@article{10.1137/0221045,
author = {Chang, Richard},
title = {On the Structure of Bounded Queries to Arbitrary NP Sets},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221045},
doi = {10.1137/0221045},
journal = {SIAM J. Comput.},
month = aug,
pages = {743–754},
numpages = {12},
keywords = {nonuniform computation, bounded queries, Boolean hierarchy, sparse sets, polynomial-time hierarchy}
}

@article{10.1137/0221044,
author = {Ganesan, K. and Homer, Steven},
title = {Complete Problems and Strong Polynomial Reducibilities},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221044},
doi = {10.1137/0221044},
journal = {SIAM J. Comput.},
month = aug,
pages = {733–742},
numpages = {10},
keywords = {complexity classes, polynomial reductions, completeness}
}

@article{10.1137/0221043,
author = {Aldous, David and Hofri, Micha and Szpankowski, Wojciech},
title = {Maximum Size of a Dynamic Data Structure: Hashing with Lazy Deletion Revisited},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221043},
doi = {10.1137/0221043},
journal = {SIAM J. Comput.},
month = aug,
pages = {713–732},
numpages = {20}
}

@article{10.1137/0221042,
author = {Li, Ming and Longpr\'{e}, Luc and Vit\'{a}nyi, Paul},
title = {The Power of the Queue},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221042},
doi = {10.1137/0221042},
journal = {SIAM J. Comput.},
month = aug,
pages = {697–712},
numpages = {16},
keywords = {upper bounds, Kolmogorov complexity, lower bounds, multi-queue machines, on-line simulation, multi-tape machines, abstract storage unit}
}

@article{10.1137/0221041,
author = {Chazelle, Bernard},
title = {An Optimal Algorithm for Intersecting Three-Dimensional Convex Polyhedra},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221041},
doi = {10.1137/0221041},
journal = {SIAM J. Comput.},
month = aug,
pages = {671–696},
numpages = {26},
keywords = {convex polyhedra, computational geometry}
}

@article{10.1137/0221040,
author = {Venkateswaran, H.},
title = {Circuit Definitions of Nondeterministic Complexity Classes},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221040},
doi = {10.1137/0221040},
journal = {SIAM J. Comput.},
month = aug,
pages = {655–670},
numpages = {16},
keywords = {Boolean circuits, arithmetic circuits, NP, skew circuits, semi-unboundedness, P}
}

@article{10.1137/0221039,
author = {Leighton, F. T. and Newman, Mark J. and Ranade, Abhiram G. and Schwabe, Eric J.},
title = {Dynamic Tree Embeddings in Butterflies and Hypercubes},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221039},
doi = {10.1137/0221039},
journal = {SIAM J. Comput.},
month = aug,
pages = {639–654},
numpages = {16},
keywords = {dynamic embeddings, butterfly network, binary trees, hypercube}
}

@article{10.1137/0221038,
author = {Melissaratos, Elefterios A. and Souvaine, Diane L.},
title = {Shortest Paths Help Solve Geometric Optimization Problems in Planar Regions},
year = {1992},
issue_date = {Aug. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221038},
doi = {10.1137/0221038},
journal = {SIAM J. Comput.},
month = aug,
pages = {601–638},
numpages = {38},
keywords = {visibility, simple polygons, stock-cutting, shortest paths, computational geometry, separators, splinegons, geometric optimization, robotics, enclosure problems, inclusion problems}
}

@article{10.1137/0221037,
author = {Gu, Qian Ping and Maruoka, Akira},
title = {Learning Monotone Boolean Functions by Uniformly Distributed Examples},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221037},
doi = {10.1137/0221037},
journal = {SIAM J. Comput.},
month = jun,
pages = {587–599},
numpages = {13},
keywords = {learning by examples, monotone Boolean formula, computational complexity, concept learning, Boolean function}
}

@article{10.1137/0221036,
author = {Kari, Jarko},
title = {The Nilpotency Problem of One-Dimensional Cellular Automata},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221036},
doi = {10.1137/0221036},
journal = {SIAM J. Comput.},
month = jun,
pages = {571–586},
numpages = {16},
keywords = {decidability, tiling, limit set, nilpotent, cellular automaton}
}

@article{10.1137/0221035,
author = {Agarwal, Pankaj K.},
title = {Ray Shooting and Other Applications of Spanning Trees with Low Stabbing Number},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221035},
doi = {10.1137/0221035},
journal = {SIAM J. Comput.},
month = jun,
pages = {540–570},
numpages = {31},
keywords = {point location, arrangements, stabbing number, ray shooting, zone, fractional cascading, spanning tree}
}

@article{10.1137/0221034,
author = {Allender, Eric and Hemachandra, Lane A. and Ogiwara, Mitsunori and Watanabe, Osamu},
title = {Relating Equivalence and Reducibility to Sparse Sets},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221034},
doi = {10.1137/0221034},
journal = {SIAM J. Comput.},
month = jun,
pages = {521–539},
numpages = {19}
}

@article{10.1137/0221033,
author = {Gatterdam, R. W.},
title = {Algorithms for Splicing Systems},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221033},
doi = {10.1137/0221033},
journal = {SIAM J. Comput.},
month = jun,
pages = {507–520},
numpages = {14},
keywords = {strictly locally testable, finite automata, DNA, splicing system}
}

@article{10.1137/0221032,
author = {Khuller, Samir and Mitchell, Stephen G. and Vazirani, Vijay V.},
title = {Processor Efficient Parallel Algorithms for the Two Disjoint Paths Problem and for Finding a Kuratowski Homeomorph},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221032},
doi = {10.1137/0221032},
journal = {SIAM J. Comput.},
month = jun,
pages = {486–506},
numpages = {21},
keywords = {graph theory, parallel algorithms, disjoint paths, Kuratowski homeomorphs}
}

@article{10.1137/0221031,
author = {Reif, John H. and Sen, Sandeep},
title = {Optimal Parallel Randomized Algorithms for Three-Dimensional Convex Hulls and Related Problems},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221031},
doi = {10.1137/0221031},
journal = {SIAM J. Comput.},
month = jun,
pages = {466–485},
numpages = {20},
keywords = {randomization, convex-hulls, computational geometry, parallel algorithms}
}

@article{10.1137/0221030,
author = {Papadimitriou, Christos H.},
title = {The Complexity of the Lin-Kernighan Heuristic for the Traveling Salesman Problem},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221030},
doi = {10.1137/0221030},
journal = {SIAM J. Comput.},
month = jun,
pages = {450–465},
numpages = {16},
keywords = {local search, PLS-complete, traveling salesman problem}
}

@article{10.1137/0221029,
author = {Natarajan, B. K.},
title = {Probably Approximate Learning over Classes of Distributions},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221029},
doi = {10.1137/0221029},
journal = {SIAM J. Comput.},
month = jun,
pages = {438–449},
numpages = {12},
keywords = {functions, sets, probabilistic learning, classes of distributions}
}

@article{10.1137/0221028,
author = {Galil, Zvi and Giancarlo, Raffaele},
title = {On the Exact Complexity of String Matching: Upper Bounds},
year = {1992},
issue_date = {June 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221028},
doi = {10.1137/0221028},
journal = {SIAM J. Comput.},
month = jun,
pages = {407–437},
numpages = {31},
keywords = {string matching, worst case behavior, computational complexity, text editing, string searching}
}

@article{10.1137/0221027,
author = {Jamison, Beverly and Olariu, Stephan},
title = {Recognizing P<sub>4</sub>-Sparse Graphs in Linear Time},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221027},
doi = {10.1137/0221027},
journal = {SIAM J. Comput.},
month = apr,
pages = {381–406},
numpages = {26},
keywords = {optimal algorithms, cographs, P4-sparse graphs, linear-time algorithms}
}

@article{10.1137/0221026,
author = {Krumme, David W.},
title = {Fast Gossiping for the Hypercube},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221026},
doi = {10.1137/0221026},
journal = {SIAM J. Comput.},
month = apr,
pages = {365–380},
numpages = {16},
keywords = {hypercube, broadcasting, gossiping}
}

@article{10.1137/0221025,
author = {Bajaj, Chanderjit L. and Dey, Tamal K.},
title = {Convex Decomposition of Polyhedra and Robustness},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221025},
doi = {10.1137/0221025},
journal = {SIAM J. Comput.},
month = apr,
pages = {339–364},
numpages = {26},
keywords = {geometric modeling, computational geometry, computational complexity, robust computations, finite element analysis}
}

@article{10.1137/0221024,
author = {Azar, Yossi},
title = {Lower Bounds for Threshold and Symmetric Functions in Parallel Computation},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221024},
doi = {10.1137/0221024},
journal = {SIAM J. Comput.},
month = apr,
pages = {329–338},
numpages = {10},
keywords = {symmetric functions, PRAM, lower bounds, threshold, parallel computation}
}

@article{10.1137/0221023,
author = {Toda, Seinosuke and Ogiwara, Mitsunori},
title = {Counting Classes Are at Least as Hard as the Polynomial-Time Hierarchy},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221023},
doi = {10.1137/0221023},
journal = {SIAM J. Comput.},
month = apr,
pages = {316–328},
numpages = {13},
keywords = {randomized reducibility, polynomial-time hierarchy, counting complexity classes, computational complexity theory}
}

@article{10.1137/0221022,
author = {Chen, Pang C.},
title = {Heuristic Sampling: A Method for Predicting the Performance of Tree Searching Programs},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221022},
doi = {10.1137/0221022},
journal = {SIAM J. Comput.},
month = apr,
pages = {295–315},
numpages = {21},
keywords = {feasibility testing, stratified sampling, cost estimation, search tree, analysis of algorithms, heuristics, Monte Carlo method}
}

@article{10.1137/0221021,
author = {Wang, Qingzhou and Cheng, Kam Hoi},
title = {A Heuristic of Scheduling Parallel Tasks and Its Analysis},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221021},
doi = {10.1137/0221021},
journal = {SIAM J. Comput.},
month = apr,
pages = {281–294},
numpages = {14},
keywords = {task precedence graph, scheduling, heuristic, NP-hard, parallel task}
}

@article{10.1137/0221020,
author = {Preparata, Franco P. and Tamassia, Roberto},
title = {Efficient Point Location in a Convex Spatial Cell-Complex},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221020},
doi = {10.1137/0221020},
journal = {SIAM J. Comput.},
month = apr,
pages = {267–280},
numpages = {14},
keywords = {analysis of algorithms, point location, computational geometry, convex cell complex}
}

@article{10.1137/0221019,
author = {Helmbold, David and Sloan, Robert and Warmuth, Manfred K.},
title = {Learning Integer Lattices},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221019},
doi = {10.1137/0221019},
journal = {SIAM J. Comput.},
month = apr,
pages = {240–266},
numpages = {27},
keywords = {lattices, concept learning, mistake bounds}
}

@article{10.1137/0221018,
author = {Menezes, A. J. and Van Oorschot, P. C. and Vanstone, S. A.},
title = {Subgroup Refinement Algorithms for Root Finding in GF(q)<sup>*</sup>},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221018},
doi = {10.1137/0221018},
journal = {SIAM J. Comput.},
month = apr,
pages = {228–239},
numpages = {12},
keywords = {root finding, finite fields, polynomial factorization}
}

@article{10.1137/0221017,
author = {Tzeng, Wen-Guey},
title = {A Polynomial-Time Algorithm for the Equivalence of Probabilistic Automata},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221017},
doi = {10.1137/0221017},
journal = {SIAM J. Comput.},
month = apr,
pages = {216–227},
numpages = {12},
keywords = {path equivalence, probabilistic automata, unambiguous finite automata, approximate equivalence, equivalence, nondeterministic finite automata}
}

@article{10.1137/0221016,
author = {Bui, Thang Nguyen and Peck, Andrew},
title = {Partitioning Planar Graphs},
year = {1992},
issue_date = {April 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221016},
doi = {10.1137/0221016},
journal = {SIAM J. Comput.},
month = apr,
pages = {203–215},
numpages = {13},
keywords = {edge separators, planar graphs, graph partitioning, graph algorithms, graph bisection, k-outerplanar graphs}
}

@article{10.1137/0221015,
author = {Linial, Nathan},
title = {Locality in Distributed Graph Algorithms},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221015},
doi = {10.1137/0221015},
journal = {SIAM J. Comput.},
month = feb,
pages = {193–201},
numpages = {9},
keywords = {distributed algorithms, locality, lower bounds, graph theory}
}

@article{10.1137/0221014,
author = {Fischer, Paul and Simon, Hans Ulrich},
title = {On Learning Ring-Sum-Expansions},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221014},
doi = {10.1137/0221014},
journal = {SIAM J. Comput.},
month = feb,
pages = {181–192},
numpages = {12},
keywords = {Vapnik-Chervonenkis-dimension, pac-learning, mistake bounds, worst case, Boolean functions}
}

@article{10.1137/0221013,
author = {Snyder, Timothy Law},
title = {On the Exact Location of Steiner Points in General Dimension},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221013},
doi = {10.1137/0221013},
journal = {SIAM J. Comput.},
month = feb,
pages = {163–180},
numpages = {18},
keywords = {Hanan's Theorem, L1 Metric, rectilinear Steiner trees}
}

@article{10.1137/0221012,
author = {Bhatt, Sandeep N. and Chung, Fan R. K. and Leighton, F. Thomson and Rosenberg, Arnold L.},
title = {Efficient Embeddings of Trees in Hypercubes},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221012},
doi = {10.1137/0221012},
journal = {SIAM J. Comput.},
month = feb,
pages = {151–162},
numpages = {12},
keywords = {graph embedding, binary trees, tree decomposition, boolean hypercube, congestion, dilation, expansion}
}

@article{10.1137/0221011,
author = {Goldberg, Andrew V. and Plotkin, Serge A. and Shmoys, David B. and Tardos, \'{E}va},
title = {Using Interior-Point Methods for Fast Parallel Algorithms for Bipartite Matching and Related Problems},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221011},
doi = {10.1137/0221011},
journal = {SIAM J. Comput.},
month = feb,
pages = {140–150},
numpages = {11},
keywords = {parallel algorithms, linear programming, matching, interior-point methods}
}

@article{10.1137/0221010,
author = {Krumme, David W. and Cybenko, George and Venkataraman, K. N.},
title = {Gossiping in Minimal Time},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221010},
doi = {10.1137/0221010},
journal = {SIAM J. Comput.},
month = feb,
pages = {111–139},
numpages = {29},
keywords = {broadcasting, gossiping}
}

@article{10.1137/0221009,
author = {Landau, Susan},
title = {Simplification of Nested Radicals},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221009},
doi = {10.1137/0221009},
journal = {SIAM J. Comput.},
month = feb,
pages = {85–110},
numpages = {26},
keywords = {nested radicals, denesting, Galois theory, radical simplification}
}

@article{10.1137/0221008,
author = {Hendrickson, Bruce},
title = {Conditions for Unique Graph Realizations},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221008},
doi = {10.1137/0221008},
journal = {SIAM J. Comput.},
month = feb,
pages = {65–84},
numpages = {20}
}

@article{10.1137/0221007,
author = {Tsai, Li-Hui},
title = {Asymptotic Analysis of an Algorithm for Balanced Parallel Processor Scheduling},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221007},
doi = {10.1137/0221007},
journal = {SIAM J. Comput.},
month = feb,
pages = {59–64},
numpages = {6},
keywords = {probabilistic algorithm analysis, makespan scheduling}
}

@article{10.1137/0221006,
author = {Ben-or, Michael and Cleve, Richard},
title = {Computing Algebraic Formulas Using a Constant Number of Registers},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221006},
doi = {10.1137/0221006},
journal = {SIAM J. Comput.},
month = feb,
pages = {54–58},
numpages = {5},
keywords = {complexity classes, algebraic computing, straight-line programs}
}

@article{10.1137/0221005,
author = {Devroye, Luc and Szpankowski, Wojciech and Rais, Bonita},
title = {A Note on the Height of Suffix Trees},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221005},
doi = {10.1137/0221005},
journal = {SIAM J. Comput.},
month = feb,
pages = {48–53},
numpages = {6},
keywords = {suffix tree, strong convergence algorithms on words, trie hashing, height, analysis of algorithms}
}

@article{10.1137/0221004,
author = {Ger\'{e}b-Graus, Mih\'{a}ly and Krizanc, Danny},
title = {The Average Complexity of Parallel Comparison Merging},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221004},
doi = {10.1137/0221004},
journal = {SIAM J. Comput.},
month = feb,
pages = {43–47},
numpages = {5},
keywords = {average case complexity, merging, parallel comparison tree}
}

@article{10.1137/0221003,
author = {Bruck, Jehoshua and Smolensky, Roman},
title = {Polynomial Threshold Functions, <i>AC</i><sup>0</sup> Functions, and Spectral Norms},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221003},
doi = {10.1137/0221003},
journal = {SIAM J. Comput.},
month = feb,
pages = {33–42},
numpages = {10},
keywords = {harmonic analysis, Boolean functions, threshold functions, complexity, AC0 functions}
}

@article{10.1137/0221002,
author = {Baeza-Yates, R. and Casas, R. and D\'{\i}az, J. and Mart\'{\i}nez, C.},
title = {On the Average Size of the Intersection of Binary Trees},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221002},
doi = {10.1137/0221002},
journal = {SIAM J. Comput.},
month = feb,
pages = {24–32},
numpages = {9},
keywords = {generating functions, average complexity, binary search trees}
}

@article{10.1137/0221001,
author = {Halperin, Dan and Overmars, Mark H. and Sharir, Micha},
title = {Efficient Motion Planning for an <i>L</i>-Shaped Object},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {21},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0221001},
doi = {10.1137/0221001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–23},
numpages = {23},
keywords = {motion planning, arrangements, computational geometry, robotics, configuration space, data structures, dynamic segment trees}
}

@article{10.1137/0220072,
author = {Galil, Zvi and Margalit, Oded},
title = {An Almost Linear-Time Algorithm for the Dense Subset-Sum Problem},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220072},
doi = {10.1137/0220072},
journal = {SIAM J. Comput.},
month = dec,
pages = {1157–1189},
numpages = {33}
}

@article{10.1137/0220071,
author = {Hemachandra, Lane A. and Hoene, Albrecht},
title = {On Sets with Efficient Implicit Membership Tests},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220071},
doi = {10.1137/0220071},
journal = {SIAM J. Comput.},
month = dec,
pages = {1148–1156},
numpages = {9}
}

@article{10.1137/0220070,
author = {Miller, Gary L. and Reif, John H.},
title = {Parallel Tree Contraction Part 2: Further Applications},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220070},
doi = {10.1137/0220070},
journal = {SIAM J. Comput.},
month = dec,
pages = {1128–1147},
numpages = {20}
}

@article{10.1137/0220069,
author = {Franco, John},
title = {Elimination of Infrequent Variables Improves Average Case Performance of Satisfiability Algorithms},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220069},
doi = {10.1137/0220069},
journal = {SIAM J. Comput.},
month = dec,
pages = {1119–1127},
numpages = {9}
}

@article{10.1137/0220068,
author = {Blum, Manuel and De Santis, Alfredo and Micali, Silvio and Persiano, Giuseppe},
title = {Noninteractive Zero-Knowledge},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220068},
doi = {10.1137/0220068},
journal = {SIAM J. Comput.},
month = dec,
pages = {1084–1118},
numpages = {35}
}

@article{10.1137/0220067,
author = {Hafner, James L. and McCurley, Kevin S.},
title = {Asymptotically Fast Triangularization of Matrices over Rings},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220067},
doi = {10.1137/0220067},
journal = {SIAM J. Comput.},
month = dec,
pages = {1068–1083},
numpages = {16}
}

@article{10.1137/0220066,
author = {Gazit, Hillel},
title = {An Optimal Randomized Parallel Algorithm for Finding Connected Components in a Graph},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220066},
doi = {10.1137/0220066},
journal = {SIAM J. Comput.},
month = dec,
pages = {1046–1067},
numpages = {22}
}

@article{10.1137/0220065,
author = {Overmars, Mark H. and Yap, Chee-Keng},
title = {New Upper Bounds in Klee's Measure Problem},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220065},
doi = {10.1137/0220065},
journal = {SIAM J. Comput.},
month = dec,
pages = {1034–1045},
numpages = {12}
}

@article{10.1137/0220064,
author = {Rubinstein, Roy S.},
title = {Self-P-Printability and Polynomial Time Turing Equivalence to a Tally Set},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220064},
doi = {10.1137/0220064},
journal = {SIAM J. Comput.},
month = dec,
pages = {1021–1033},
numpages = {13}
}

@article{10.1137/0220063,
author = {Galil, Zvi and Giancarlo, Raffaele},
title = {On the Exact Complexity of String Matching: Lower Bounds},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220063},
doi = {10.1137/0220063},
journal = {SIAM J. Comput.},
month = dec,
pages = {1008–1020},
numpages = {13}
}

@article{10.1137/0220062,
author = {Nisan, Noam},
title = {CREW PRAMs and Decision Trees},
year = {1991},
issue_date = {Dec. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220062},
doi = {10.1137/0220062},
journal = {SIAM J. Comput.},
month = dec,
pages = {999–1007},
numpages = {9}
}

@article{10.1137/0220060,
author = {Ho, Jan-Ming and Lee, D. T. and Chang, Chia-Hsiang and Wong, C. K.},
title = {Minimum Diameter Spanning Trees and Related Problems},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220060},
doi = {10.1137/0220060},
journal = {SIAM J. Comput.},
month = oct,
pages = {987–997},
numpages = {11}
}

@article{10.1137/0220059,
author = {Ko, Ker-I},
title = {On the Complexity of Learning Minimum Time-Bounded Turing Machines},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220059},
doi = {10.1137/0220059},
journal = {SIAM J. Comput.},
month = oct,
pages = {962–986},
numpages = {25}
}

@article{10.1137/0220058,
author = {Friedman, Joel},
title = {The Spectra of Infinite Hypertrees},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220058},
doi = {10.1137/0220058},
abstract = {A model of regular infinite hypertrees is developed to mimic for hypergraphs what infinite trees do for graphs. Two notions of spectra, or “first eigenvalue,” are then examined for the infinite tree, obtaining a precise value for the first notion and obtaining some estimates for the second. The results indicate agreement of the first eigenvalue of the infinite hypertree with the “second eigenvalue” of a random hypergraph of the same degree, to within logarithmic factors, at least for the first notion of first eigenvalue. — Authors Abstract},
journal = {SIAM J. Comput.},
month = oct,
pages = {951–961},
numpages = {11}
}

@article{10.1137/0220057,
author = {Luo, Zhi-Quan and Tsitsiklis, John N.},
title = {On the Communication Complexity of Solving a Polynomial Equation},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220057},
doi = {10.1137/0220057},
journal = {SIAM J. Comput.},
month = oct,
pages = {936–950},
numpages = {15}
}

@article{10.1137/0220056,
author = {Li, Ming and Vit\'{a}nyi, Paul M. B.},
title = {Learning Simple Concepts under Simple Distributions},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220056},
doi = {10.1137/0220056},
journal = {SIAM J. Comput.},
month = oct,
pages = {911–935},
numpages = {25}
}

@article{10.1137/0220055,
author = {Ghosh, Subir Kumar and Mount, David M.},
title = {An Output-Sensitive Algorithm for Computing Visibility},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220055},
doi = {10.1137/0220055},
journal = {SIAM J. Comput.},
month = oct,
pages = {888–910},
numpages = {23}
}

@article{10.1137/0220054,
author = {Pippenger, Nicholas},
title = {Selection Networks},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220054},
doi = {10.1137/0220054},
journal = {SIAM J. Comput.},
month = oct,
pages = {878–887},
numpages = {10}
}

@article{10.1137/0220053,
author = {Toda, Seinosuke},
title = {PP is as Hard as the Polynomial-Time Hierarchy},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220053},
doi = {10.1137/0220053},
journal = {SIAM J. Comput.},
month = oct,
pages = {865–877},
numpages = {13}
}

@article{10.1137/0220052,
author = {Chan, Mee Yee},
title = {Embedding of Grids into Optimal Hypercubes},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220052},
doi = {10.1137/0220052},
journal = {SIAM J. Comput.},
month = oct,
pages = {834–864},
numpages = {31}
}

@article{10.1137/0220051,
author = {Kutylowski, Miroslaw},
title = {Time Complexity of Boolean Functions on CREW PRAMs},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220051},
doi = {10.1137/0220051},
journal = {SIAM J. Comput.},
month = oct,
pages = {824–853},
numpages = {30}
}

@article{10.1137/0220050,
author = {Kenyon-Mathieu, Claire M. and Vitter, Jeffrey Scott},
title = {The Maximum Size of Dynamic Data Structures},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220050},
doi = {10.1137/0220050},
journal = {SIAM J. Comput.},
month = oct,
pages = {807–823},
numpages = {17}
}

@article{10.1137/0220049,
author = {Pigozzi, Don},
title = {Equality-Test and If-Then-Else Algebras: Axiomatization and Specification},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220049},
doi = {10.1137/0220049},
journal = {SIAM J. Comput.},
month = aug,
pages = {766–805},
numpages = {40},
keywords = {initial algebra, equational logic, specification, quasi variety, if-then-else, conditional equations, quasi equations, semicomputable, variety, equality test, final algebra, computable}
}

@article{10.1137/0220048,
author = {Davida, George I. and Litow, Bruce},
title = {Fast Parallel Arithmetic via Modular Representation},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220048},
doi = {10.1137/0220048},
journal = {SIAM J. Comput.},
month = aug,
pages = {756–765},
numpages = {10},
keywords = {modular, circuit, combinational, uniform, almost uniform, division, parallelism, comparison}
}

@article{10.1137/0220047,
author = {Goodrich, Michael T.},
title = {Intersecting Line Segments in Parallel with an Output-Sensitive Number of Processors},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220047},
doi = {10.1137/0220047},
journal = {SIAM J. Comput.},
month = aug,
pages = {737–755},
numpages = {19},
keywords = {PRAM model, line-segment intersection, computational geometry, parallel data structures, parallel algorithms}
}

@article{10.1137/0220046,
author = {Chung, Shun-Ping and Ross, Keith W.},
title = {On Nonblocking Multirate Interconnection Networks},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220046},
doi = {10.1137/0220046},
journal = {SIAM J. Comput.},
month = aug,
pages = {726–736},
numpages = {11}
}

@article{10.1137/0220045,
author = {Tamassia, Roberto and Vitter, Jeffrey S.},
title = {Parallel Transitive Closure and Point Location in Planar Structures},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220045},
doi = {10.1137/0220045},
journal = {SIAM J. Comput.},
month = aug,
pages = {708–725},
numpages = {18},
keywords = {parallel computation, parallel algorithms, transitive closure, planar point location, reachability, fractional cascading, computational geometry, planar st-graphs, graph drawing, visibility, graph algorithms}
}

@article{10.1137/0220044,
author = {Dyer, Martin},
title = {On Counting Lattice Points in Polyhedra},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220044},
doi = {10.1137/0220044},
journal = {SIAM J. Comput.},
month = aug,
pages = {695–707},
numpages = {13},
keywords = {polynomial time, Dedekind sums, lattice points, convex polyhedron}
}

@article{10.1137/0220043,
author = {Sutter, Erich E.},
title = {The Fast M-Transform: A Fast Computation of Cross-Correlations with Binary m-Sequences},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220043},
doi = {10.1137/0220043},
journal = {SIAM J. Comput.},
month = aug,
pages = {686–694},
numpages = {9},
keywords = {fast cross-correlation, Walsh-Hadamard transforms, m-sequences, Hadamard transforms, nonlinear systems analysis}
}

@article{10.1137/0220042,
author = {Reutenauer, Christophe and Schutzenberger, Marcel-Paul},
title = {Minimization of Rational Word Functions},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220042},
doi = {10.1137/0220042},
journal = {SIAM J. Comput.},
month = aug,
pages = {669–685},
numpages = {17},
keywords = {rational function, sequential bimachine}
}

@article{10.1137/0220041,
author = {Yao, Andrew Chi-Chih},
title = {Lower Bounds for Algebraic Computation Trees with Integer Inputs},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220041},
doi = {10.1137/0220041},
journal = {SIAM J. Comput.},
month = aug,
pages = {655–668},
numpages = {14},
keywords = {algebraic computation trees, topological approach, closest pair, integer element distinctness, lower bounds}
}

@article{10.1137/0220040,
author = {Gusfield, Dan},
title = {Computing the Strength of a Graph},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220040},
doi = {10.1137/0220040},
journal = {SIAM J. Comput.},
month = aug,
pages = {639–654},
numpages = {16},
keywords = {polymatroids, graph vulnerability, bipartite flow, parametric network flow}
}

@article{10.1137/0220039,
author = {Chen, Jian-er and Yap, Chee-Keng},
title = {Reversal Complexity},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220039},
doi = {10.1137/0220039},
journal = {SIAM J. Comput.},
month = aug,
pages = {622–638},
numpages = {17},
keywords = {reversal, tape reduction theorem, parallel complexity, complete languages, reversal hierarchies, space}
}

@article{10.1137/0220038,
author = {Mehlhorn, Kurt and Yap, Chee-Keng},
title = {Constructive Whitney-Graustein Theorem: Or How to Untangle Closed Planar Curves},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220038},
doi = {10.1137/0220038},
journal = {SIAM J. Comput.},
month = aug,
pages = {603–621},
numpages = {19},
keywords = {Whitney-Graustein theorem, polygons, computational algebraic topology, winding number, computational geometry}
}

@article{10.1137/0220037,
author = {von zur Gathen, Joachim},
title = {Tests for Permutation Polynomials},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220037},
doi = {10.1137/0220037},
journal = {SIAM J. Comput.},
month = apr,
pages = {591–602},
numpages = {12},
keywords = {finite fields, values of polynomials, Euclidean remainder sequence, subresultant, permutation polynomials, probabilistic algorithm}
}

@article{10.1137/0220036,
author = {Clote, Peter and Kranakis, Evangelos},
title = {Boolean Functions, Invariance Groups, and Parallel Complexity},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220036},
doi = {10.1137/0220036},
journal = {SIAM J. Comput.},
month = apr,
pages = {553–590},
numpages = {38},
keywords = {Abelian group, Boolean function, index of a group, representable group, pumping lemma, cyclic, Po´lya cycle index, permutation group, NC, invariance group of Boolean function, symmetric Boolean function, regular group, circuit, wreath product, parallel complexity, diheral-hyperoctahedral groups, regular language, classification theory}
}

@article{10.1137/0220035,
author = {Shih, Wei-Kuan and Liu, Jane W. S. and Chung, Jen-Yao},
title = {Algorithms for Scheduling Imprecise Computations with Timing Constraints},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220035},
doi = {10.1137/0220035},
journal = {SIAM J. Comput.},
month = apr,
pages = {537–552},
numpages = {16},
keywords = {scheduling to meet deadlines, deterministic scheduling, real-time systems}
}

@article{10.1137/0220034,
author = {Goldberg, Andrew V. and Sipser, Michael},
title = {Compression and Ranking},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220034},
doi = {10.1137/0220034},
journal = {SIAM J. Comput.},
month = apr,
pages = {524–536},
numpages = {13},
keywords = {Kolmogorov complexity, data compression, computational complexity}
}

@article{10.1137/0220033,
author = {Goldsmith, Judy and Hemachandra, Lane A. and Joseph, Deborah and Young, Paul},
title = {Near-Testable Sets},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220033},
doi = {10.1137/0220033},
journal = {SIAM J. Comput.},
month = apr,
pages = {506–523},
numpages = {18}
}

@article{10.1137/0220032,
author = {Zwick, Uri},
title = {A 4<i>n</i> Lower Bound on the Combinational Complexity of Certain Symmetric Boolean Functions over the Basis of Unate Dyadic Boolean Functions},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220032},
doi = {10.1137/0220032},
journal = {SIAM J. Comput.},
month = apr,
pages = {499–505},
numpages = {7}
}

@article{10.1137/0220031,
author = {Geffert, Viliam},
title = {Nondeterministic Computations in Sublogarithmic Space and Space Constructibility},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220031},
doi = {10.1137/0220031},
journal = {SIAM J. Comput.},
month = apr,
pages = {484–498},
numpages = {15},
keywords = {nondeterministic space, nondeterministic turing machine, space constructibility, space-bounded computation}
}

@article{10.1137/0220030,
author = {Ogiwara, Mitsunori and Watanabe, Osamu},
title = {On Polynomial-Time Bounded Truth-Table Reducibility of NP Sets to Sparse Sets},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220030},
doi = {10.1137/0220030},
journal = {SIAM J. Comput.},
month = apr,
pages = {471–483},
numpages = {13}
}

@article{10.1137/0220029,
author = {Pach, J\'{a}nos and Sharir, Micha},
title = {On Vertical Visibility in Arrangements of Segments and the Queue Size in the Bentley-Ottmann Line Sweeping Algorithm},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220029},
doi = {10.1137/0220029},
journal = {SIAM J. Comput.},
month = apr,
pages = {460–470},
numpages = {11}
}

@article{10.1137/0220028,
author = {Baum, Ulrich and Clausen, Michael},
title = {Some Lower and Upper Complexity Bounds for Generalized Fourier Transforms and Their Inverses},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220028},
doi = {10.1137/0220028},
journal = {SIAM J. Comput.},
month = apr,
pages = {451–459},
numpages = {9},
keywords = {linear complexity, Frobenius groups, extra-special 2-groups, fast fourier transforms, fast inverse fourier transforms, group algebras}
}

@article{10.1137/0220027,
author = {Wolfson, Ouri and Segall, Adrain},
title = {The Communication Complexity of Atomic Commitment and of Gossiping},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220027},
doi = {10.1137/0220027},
journal = {SIAM J. Comput.},
month = apr,
pages = {423–450},
numpages = {28},
keywords = {transaction management, gossiping, database consistency, distributed databases optimal protocols, commit protocols}
}

@article{10.1137/0220026,
author = {Marcotte, Odile and Suri, Subhash},
title = {Fast Matching Algorithms for Points on a Polygon},
year = {1991},
issue_date = {June 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220026},
doi = {10.1137/0220026},
journal = {SIAM J. Comput.},
month = apr,
pages = {405–422},
numpages = {18},
keywords = {geometric matching, nearest neighbors, divide and conquer, computational geometry, shortest paths, matrix searching}
}

@article{10.1137/0220025,
author = {Kadin, Jim},
title = {ERRATUM: The Polynomial Time Hierarchy Collapses If the Boolean Hierarchy Collapses},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220025},
doi = {10.1137/0220025},
journal = {SIAM J. Comput.},
month = mar,
pages = {404},
numpages = {1}
}

@article{10.1137/0220024,
author = {Gritzmann, Peter and Habsieger, Laurent and Klee, Victor},
title = {Good and Bad Radii of Convex Polygons},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220024},
doi = {10.1137/0220024},
journal = {SIAM J. Comput.},
month = mar,
pages = {395–403},
numpages = {9},
keywords = {diameter, polarity, inradius, algebraic number, implicit computation, width, rationalizing polynomial, convex lattice polygon, circumradius}
}

@article{10.1137/0220023,
author = {Afek, Yehuda and Gafni, Eli},
title = {Time and Message Bounds for Election in Synchronous and Asynchronous Complete Networks},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220023},
doi = {10.1137/0220023},
journal = {SIAM J. Comput.},
month = mar,
pages = {376–394},
numpages = {19}
}

@article{10.1137/0220022,
author = {Khuller, Samir and Schieber, Baruch},
title = {Efficient Parallel Algorithms for Testing <i>k</i>-Connectivity and Finding Disjoint s-t Paths in Graphs},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220022},
doi = {10.1137/0220022},
journal = {SIAM J. Comput.},
month = mar,
pages = {352–375},
numpages = {24}
}

@article{10.1137/0220021,
author = {Natarajan, B. K.},
title = {Probably Approximate Learning of Sets and Functions},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220021},
doi = {10.1137/0220021},
journal = {SIAM J. Comput.},
month = mar,
pages = {328–351},
numpages = {24},
keywords = {probabilistic inference, sets functions}
}

@article{10.1137/0220020,
author = {Mansour, Yishay and Schieber, Baruch and Tiwari, Prasoon},
title = {Lower Bounds for Computations with the Floor Operation},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220020},
doi = {10.1137/0220020},
journal = {SIAM J. Comput.},
month = mar,
pages = {315–327},
numpages = {13},
keywords = {square-root, floor operation, Newton iteration, lower bound, mod operation, truncation}
}

@article{10.1137/0220019,
author = {Roth, Ron M. and Benedek, Gyora M.},
title = {Interpolation and Approximation of Sparse Multivariate Polynomials over GF(2)},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220019},
doi = {10.1137/0220019},
journal = {SIAM J. Comput.},
month = mar,
pages = {291–314},
numpages = {24},
keywords = {learning of boolean functions, approximation of sparse polynomials, interpolation of sparse polynomials, Reed-Muller codes}
}

@article{10.1137/0220018,
author = {Ibarra, Oscar H. and Jiang, Tao},
title = {The Power of Alternating One-Reversal Counters and Stacks},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220018},
doi = {10.1137/0220018},
journal = {SIAM J. Comput.},
month = mar,
pages = {278–290},
numpages = {13},
keywords = {reversal, recursively enumerable set, computational complexity, turing machine, alternation, pushdown automata, counter machine}
}

@article{10.1137/0220017,
author = {Beame, Paul},
title = {A General Sequential Time-Space Tradeoff for Finding Unique Elements},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220017},
doi = {10.1137/0220017},
journal = {SIAM J. Comput.},
month = mar,
pages = {270–277},
numpages = {8},
keywords = {recursively enumerable set, counter machine, reversal, alternation, Turing machine, pushdown automata, computational complexity}
}

@article{10.1137/0220016,
author = {Edelsbrunner, Herbert and Shi, Weiping},
title = {An O(<i>n</i> Log<sup>2</sup><i>h</i>) Time Algorithm for the Three-Dimensional Convex Hull Problem},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220016},
doi = {10.1137/0220016},
journal = {SIAM J. Comput.},
month = mar,
pages = {259–269},
numpages = {11},
keywords = {three dimensions, computational geometry, convex hull, output sensitive}
}

@article{10.1137/0220015,
author = {Book, Ronald V.},
title = {Some Observations on Separating Complexity Classes},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220015},
doi = {10.1137/0220015},
journal = {SIAM J. Comput.},
month = mar,
pages = {246–258},
numpages = {13},
keywords = {the polynomial-time hierarchy, complexity classes, uniform witnesses, relativizations, the BP-operator, NP, PSPACE, P, polynomial space, polynomial time, AM, BPP}
}

@article{10.1137/0220014,
author = {J\'{a}J\'{a}, Joseph and Chang, Shing-Chong},
title = {Parallel Algorithms for Channel Routing in the Knock-Knee Model},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220014},
doi = {10.1137/0220014},
journal = {SIAM J. Comput.},
month = mar,
pages = {228–245},
numpages = {18},
keywords = {VLSI design, channel routing, left-edge algorithm, layout, parallel algorithms, line packing}
}

@article{10.1137/0220013,
author = {Matou\v{s}ek, Ji\v{r}\'{\i}},
title = {Approximate Levels in Line Arrangements},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220013},
doi = {10.1137/0220013},
journal = {SIAM J. Comput.},
month = mar,
pages = {222–227},
numpages = {6},
keywords = {computational geometry, approximate level, line arrangement, deterministic algorithm, range counting}
}

@article{10.1137/0220012,
author = {Balas, Egon and Xue, Jue},
title = {Minimum Weighted Coloring of Triangulated Graphs, with Application to Maximum Weight Vertex Packing and Clique Finding in Arbitrary Graphs},
year = {1991},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220012},
doi = {10.1137/0220012},
journal = {SIAM J. Comput.},
month = mar,
pages = {209–221},
numpages = {13},
keywords = {maximum clique finding, graph coloring, vertex packing, triangulated graphs}
}

@article{10.1137/0220011,
author = {Reingold, Edward M. and Shen, Xiaojun},
title = {More Nearly Optimal Algorithms for Unbounded Searching, Part II: The Transfinite Case},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220011},
doi = {10.1137/0220011},
journal = {SIAM J. Comput.},
month = feb,
pages = {184–208},
numpages = {25}
}

@article{10.1137/0220010,
author = {Reingold, Edward M. and Shen, Xiaojun},
title = {More Nearly Optimal Algorithms for Unbounded Searching, Part I: The Finite Case},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220010},
doi = {10.1137/0220010},
journal = {SIAM J. Comput.},
month = feb,
pages = {156–183},
numpages = {28}
}

@article{10.1137/0220009,
author = {Sutner, K. and Satyanarayana, A. and Suffel, C.},
title = {The Complexity of the Residual Node Connectedness Reliability Problem},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220009},
doi = {10.1137/0220009},
journal = {SIAM J. Comput.},
month = feb,
pages = {149–155},
numpages = {7}
}

@article{10.1137/0220008,
author = {Chrobak, Marek and Larmore, Lawrence L.},
title = {An Optimal On-Line Algorithm for K-Servers on Trees},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220008},
doi = {10.1137/0220008},
journal = {SIAM J. Comput.},
month = feb,
pages = {144–148},
numpages = {5}
}

@article{10.1137/0220007,
author = {Tung, Shih Ping},
title = {Complexity of Sentences over Number Rings},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220007},
doi = {10.1137/0220007},
journal = {SIAM J. Comput.},
month = feb,
pages = {126–143},
numpages = {18}
}

@article{10.1137/0220006,
author = {Ullman, Jeffrey D. and Yannakakis, Mihalis},
title = {High Probability Parallel Transitive-Closure Algorithms},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220006},
doi = {10.1137/0220006},
journal = {SIAM J. Comput.},
month = feb,
pages = {100–125},
numpages = {26}
}

@article{10.1137/0220005,
author = {Parberry, Ian and Yan, Pei Yuan},
title = {Improved Upper and Lower Time Bounds for Parallel Random Access Machines without Simultaneous Writes},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220005},
doi = {10.1137/0220005},
journal = {SIAM J. Comput.},
month = feb,
pages = {88–99},
numpages = {12}
}

@article{10.1137/0220004,
author = {Sch\"{a}ffer, Alejandro A. and Yannakakis, Mihalis},
title = {Simple Local Search Problems That Are Hard to Solve},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220004},
doi = {10.1137/0220004},
journal = {SIAM J. Comput.},
month = feb,
pages = {56–87},
numpages = {32}
}

@article{10.1137/0220003,
author = {Gu, Qian Ping and Maruoka, Akira},
title = {Amplification of Bounded Depth Monotone Read-Once Boolean Formulae},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220003},
doi = {10.1137/0220003},
journal = {SIAM J. Comput.},
month = feb,
pages = {41–55},
numpages = {15}
}

@article{10.1137/0220002,
author = {Vishkin, Uzi},
title = {Deterministic Sampling: A New Technique for Fast Pattern Matching},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220002},
doi = {10.1137/0220002},
journal = {SIAM J. Comput.},
month = feb,
pages = {22–40},
numpages = {19}
}

@article{10.1137/0220001,
author = {Duval, Dominique},
title = {Absolute Factorization of Polynomials: A Geometric Approach},
year = {1991},
issue_date = {Feb. 1991},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {20},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0220001},
doi = {10.1137/0220001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–21},
numpages = {21}
}

@article{10.1137/0219077,
author = {Murota, Kazuo},
title = {Computing Puiseux-Series Solutions to Determinantal Equations via Combinatorial Relaxation},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219077},
doi = {10.1137/0219077},
journal = {SIAM J. Comput.},
month = nov,
pages = {1132–1161},
numpages = {30}
}

@article{10.1137/0219076,
author = {Lutz, Jack H.},
title = {Category and Measure in Complexity Classes},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219076},
doi = {10.1137/0219076},
journal = {SIAM J. Comput.},
month = nov,
pages = {1100–1131},
numpages = {32}
}

@article{10.1137/0219075,
author = {Friedman, Joel},
title = {Random Polynomials and Approximate Zeros of Newton's Method},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219075},
doi = {10.1137/0219075},
journal = {SIAM J. Comput.},
month = nov,
pages = {1068–1099},
numpages = {32}
}

@article{10.1137/0219074,
author = {Alon, Noga and Karchmer, Mauricio and Wigderson, Avi},
title = {Linear Circuits over GF(2)},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219074},
doi = {10.1137/0219074},
journal = {SIAM J. Comput.},
month = nov,
pages = {1064–1067},
numpages = {4}
}

@article{10.1137/0219073,
author = {Grigoriev, Dima Yu and Karpinski, Marek and Singer, Michael F.},
title = {Fast Parallel Algorithms for Sparse Multivariate Polynomial Interpolation over Finite Fields},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219073},
doi = {10.1137/0219073},
journal = {SIAM J. Comput.},
month = nov,
pages = {1059–1063},
numpages = {5}
}

@article{10.1137/0219072,
author = {Breslauer, Dany and Galil, Zvi},
title = {An Optimal <i>O</i>(Log <i>n</i>)Time Parallel String Matching Algorithm},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219072},
doi = {10.1137/0219072},
journal = {SIAM J. Comput.},
month = nov,
pages = {1051–1058},
numpages = {8}
}

@article{10.1137/0219071,
author = {Lee, D. T. and Sarrafzadeh, M. and Wu, Y. F.},
title = {Minimum Cuts for Circular-Arc Graphs},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219071},
doi = {10.1137/0219071},
journal = {SIAM J. Comput.},
month = nov,
pages = {1041–1050},
numpages = {10}
}

@article{10.1137/0219070,
author = {Sugihara, Kazuo and Suzuki, Ichiro and Yamashita, Masafumi},
title = {The Searchlight Scheduling Problem},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219070},
doi = {10.1137/0219070},
journal = {SIAM J. Comput.},
month = nov,
pages = {1024–1040},
numpages = {17}
}

@article{10.1137/0219069,
author = {Dwork, Cynthia and Stockmeyer, Larry},
title = {A Time Complexity Gap for Two-Way Probabilistic Finite-State Automata},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219069},
doi = {10.1137/0219069},
journal = {SIAM J. Comput.},
month = nov,
pages = {1011–1123},
numpages = {113}
}

@article{10.1137/0219068,
author = {Lueker, George S. and Megiddo, Nimrod and Ramachandran, Vijaya},
title = {Linear Programming with Two Variables per Inequality in Poly-Log Time},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219068},
doi = {10.1137/0219068},
journal = {SIAM J. Comput.},
month = nov,
pages = {1000–1010},
numpages = {11}
}

@article{10.1137/0219067,
author = {Galil, Zvi and Park, Kunsoo},
title = {An Improved Algorithm for Approximate String Matching},
year = {1990},
issue_date = {Dec. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219067},
doi = {10.1137/0219067},
journal = {SIAM J. Comput.},
month = nov,
pages = {989–999},
numpages = {11}
}

@article{10.1137/0219066,
author = {Apostolico, Alberto and Atallah, Mikhail J. and Larmore, Lawrence L. and McFaddin, Scott},
title = {Efficient Parallel Algorithms for String Editing and Related Problems},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219066},
doi = {10.1137/0219066},
journal = {SIAM J. Comput.},
month = sep,
pages = {968–988},
numpages = {21}
}

@article{10.1137/0219065,
author = {Johnstone, John K. and Bajaj, Chanderjit L.},
title = {Sorting Points along an Algebraic Curve},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219065},
doi = {10.1137/0219065},
journal = {SIAM J. Comput.},
month = sep,
pages = {925–967},
numpages = {43}
}

@article{10.1137/0219064,
author = {Reif, John H. and Tate, Stephen R.},
title = {Optimal Size Integer Division Circuits},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219064},
doi = {10.1137/0219064},
journal = {SIAM J. Comput.},
month = sep,
pages = {912–924},
numpages = {13}
}

@article{10.1137/0219063,
author = {Bienstock, D.},
title = {Linear-Time Test for Small Face Covers in Any Fixed Surface},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219063},
doi = {10.1137/0219063},
journal = {SIAM J. Comput.},
month = sep,
pages = {907–911},
numpages = {5}
}

@article{10.1137/0219062,
author = {Mehlhorn, K. and N\"{a}her, St. and Rauch, M.},
title = {On the Complexity of a Game Related to the Dictionary Problem},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219062},
doi = {10.1137/0219062},
journal = {SIAM J. Comput.},
month = sep,
pages = {902–906},
numpages = {5}
}

@article{10.1137/0219061,
author = {Iwano, Kazuo and Steiglitz, Kenneth},
title = {A Semiring on Convex Polygons and Zero-Sum Cycle Problems},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219061},
doi = {10.1137/0219061},
journal = {SIAM J. Comput.},
month = sep,
pages = {883–901},
numpages = {19}
}

@article{10.1137/0219060,
author = {Lucas, Joan M.},
title = {Postorder Disjoint Set Union is Linear},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219060},
doi = {10.1137/0219060},
journal = {SIAM J. Comput.},
month = sep,
pages = {868–882},
numpages = {15}
}

@article{10.1137/0219059,
author = {Li, Keqin and Cheng, Kam-Hoi},
title = {On Three-Dimensional Packing},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219059},
doi = {10.1137/0219059},
journal = {SIAM J. Comput.},
month = sep,
pages = {847–867},
numpages = {21}
}

@article{10.1137/0219058,
author = {Wagner, Klaus W.},
title = {Bounded Query Classes},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219058},
doi = {10.1137/0219058},
journal = {SIAM J. Comput.},
month = sep,
pages = {833–846},
numpages = {14}
}

@article{10.1137/0219057,
author = {Devroye, Luc and Laforest, Louise},
title = {An Analysis of Random <i>d</i>-Dimensional Quad Trees},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219057},
doi = {10.1137/0219057},
journal = {SIAM J. Comput.},
month = sep,
pages = {821–832},
numpages = {12}
}

@article{10.1137/0219056,
author = {Cypher, R. E. and Sanz, J. L. and Snyder, L.},
title = {The Hough Transform Has <i>O(N)</i> Complexity on <i>N\texttimes{}-N</i> Mesh Connected Computers},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219056},
doi = {10.1137/0219056},
journal = {SIAM J. Comput.},
month = sep,
pages = {805–820},
numpages = {16}
}

@article{10.1137/0219055,
author = {Gr\"{a}del, Erich and Schiller, Friedrich},
title = {Domino Games and Complexity},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219055},
doi = {10.1137/0219055},
journal = {SIAM J. Comput.},
month = sep,
pages = {787–804},
numpages = {18}
}

@article{10.1137/0219054,
author = {Schmidt, Jeanette P. and Siegel, Alan},
title = {The Spatial Complexity of Oblivious <i>k</i>-Probe Hash Functions},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219054},
doi = {10.1137/0219054},
journal = {SIAM J. Comput.},
month = sep,
pages = {775–786},
numpages = {12}
}

@article{10.1137/0219053,
author = {Dub\'{e}, Thomas W.},
title = {The Structure of Polynomial Ideals and Grobner Bases},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219053},
doi = {10.1137/0219053},
journal = {SIAM J. Comput.},
month = jun,
pages = {750–773},
numpages = {24}
}

@article{10.1137/0219052,
author = {Krentel, Mark W.},
title = {On Finding and Verifying Locally Optimal Solutions},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219052},
doi = {10.1137/0219052},
journal = {SIAM J. Comput.},
month = jun,
pages = {742–749},
numpages = {8}
}

@article{10.1137/0219051,
author = {Munshi, Ashfag A. and Simons, Barbara},
title = {Scheduling Sequential Loops on Parallel Processors},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219051},
doi = {10.1137/0219051},
journal = {SIAM J. Comput.},
month = jun,
pages = {728–741},
numpages = {14}
}

@article{10.1137/0219050,
author = {Fich, Faith E. and Wigderson, Avi},
title = {Toward Understanding Exclusive Read},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219050},
doi = {10.1137/0219050},
journal = {SIAM J. Comput.},
month = jun,
pages = {718–727},
numpages = {10}
}

@article{10.1137/0219049,
author = {Stinson, D. R.},
title = {Some Observations on Parallel Algorithms for Fast Exponentiation in GF(2<sup><i>n</i></sup>)},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219049},
doi = {10.1137/0219049},
journal = {SIAM J. Comput.},
month = jun,
pages = {711–717},
numpages = {7}
}

@article{10.1137/0219048,
author = {Rhee, Wansoo T.},
title = {A Note for Optimal Bin Packing and Optimal Bin Covering with Items of Random Size},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219048},
doi = {10.1137/0219048},
journal = {SIAM J. Comput.},
month = jun,
pages = {705–710},
numpages = {6}
}

@article{10.1137/0219047,
author = {Hagerup, Torben},
title = {Planar Depth-First Search in <i>O</i>(Log <i>n</i>) Parallel Time},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219047},
doi = {10.1137/0219047},
journal = {SIAM J. Comput.},
month = jun,
pages = {678–704},
numpages = {27}
}

@article{10.1137/0219046,
author = {Levine, Robert Y. and Sherman, Alan T.},
title = {A Note on Bennett's Time Space Tradeoff for Reversible Computation},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219046},
doi = {10.1137/0219046},
journal = {SIAM J. Comput.},
month = jun,
pages = {673–677},
numpages = {5}
}

@article{10.1137/0219045,
author = {Frieze, Alan and McDiarmid, Colin and Reed, Bruce},
title = {Greedy Matching on the Line},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219045},
doi = {10.1137/0219045},
journal = {SIAM J. Comput.},
month = jun,
pages = {666–672},
numpages = {7}
}

@article{10.1137/0219044,
author = {Jackson, Bill},
title = {Shortest Circuit Covers and Postman Tours in Graphs with a Nowhere Zero 4-Flow},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219044},
doi = {10.1137/0219044},
journal = {SIAM J. Comput.},
month = jun,
pages = {659–665},
numpages = {7}
}

@article{10.1137/0219043,
author = {Dezani-Ciancaglini, M. and Venneri, B.},
title = {Partial Types and Intervals},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219043},
doi = {10.1137/0219043},
journal = {SIAM J. Comput.},
month = jun,
pages = {644–658},
numpages = {15}
}

@article{10.1137/0219042,
author = {Joyer, J. M. and Kailath, T. and Lev-Ari, H. and Bao, S. K.},
title = {On the Analysis of Synchronous Computing Systems},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219042},
doi = {10.1137/0219042},
journal = {SIAM J. Comput.},
month = jun,
pages = {627–643},
numpages = {17}
}

@article{10.1137/0219041,
author = {Chin, F. and Ting, H. F.},
title = {Improving the Time Complexity of Massage Optimal Distributed Algorithms for Minimum-Weight Spanning Trees},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219041},
doi = {10.1137/0219041},
journal = {SIAM J. Comput.},
month = jun,
pages = {612–626},
numpages = {15}
}

@article{10.1137/0219040,
author = {Mount, David M.},
title = {The Number of Shortest Paths on the Surface of a Polyhedron},
year = {1990},
issue_date = {Aug. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219040},
doi = {10.1137/0219040},
journal = {SIAM J. Comput.},
month = jun,
pages = {593–611},
numpages = {19}
}

@article{10.1137/0219038,
author = {Wagner, A. and Corneil, D. G.},
title = {Embedding Trees in a Hypercube is NP-Complete},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219038},
doi = {10.1137/0219038},
journal = {SIAM J. Comput.},
month = jun,
pages = {570–590},
numpages = {21}
}

@article{10.1137/0219037,
author = {Annexstein, Fred and Baumslag, Marc and Rosenberg, Arnold L.},
title = {Group Action Graphs and Parallel Architectures},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219037},
doi = {10.1137/0219037},
journal = {SIAM J. Comput.},
month = jun,
pages = {544–569},
numpages = {26}
}

@article{10.1137/0219036,
author = {Sakkalis, Takis},
title = {The Euclidean Algorithm and the Degree of the Gauss Map},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219036},
doi = {10.1137/0219036},
journal = {SIAM J. Comput.},
month = jun,
pages = {538–543},
numpages = {6}
}

@article{10.1137/0219035,
author = {Beigel, Richard},
title = {Unbounded Searching Algorithms},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219035},
doi = {10.1137/0219035},
journal = {SIAM J. Comput.},
month = jun,
pages = {522–537},
numpages = {16}
}

@article{10.1137/0219034,
author = {Liundefinedkiewicz, Maciej and Loryundefined, Krzysztof},
title = {Fast Simulations of Time-Bounded One-Tape Turing Machines by Space-Bounded Ones},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219034},
doi = {10.1137/0219034},
journal = {SIAM J. Comput.},
month = jun,
pages = {511–521},
numpages = {11}
}

@article{10.1137/0219033,
author = {Eppstein, David},
title = {Reset Sequences for Monotonic Automata},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219033},
doi = {10.1137/0219033},
journal = {SIAM J. Comput.},
month = jun,
pages = {500–510},
numpages = {11}
}

@article{10.1137/0219032,
author = {Dwork, Cynthia and Stockmeyer, Larry},
title = {Flipping Persuasively in Constant Time},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219032},
doi = {10.1137/0219032},
journal = {SIAM J. Comput.},
month = jun,
pages = {472–499},
numpages = {28}
}

@article{10.1137/0219031,
author = {Bshouty, Nader H.},
title = {Maximal Rank of <i>m</i> x <i>n</i> x (<i>Mn</i> - <i>k</i>) Tensors},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219031},
doi = {10.1137/0219031},
journal = {SIAM J. Comput.},
month = jun,
pages = {467–471},
numpages = {5}
}

@article{10.1137/0219030,
author = {Ye, Yinyu},
title = {A Class of Projective Transformations for Linear Programming},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219030},
doi = {10.1137/0219030},
journal = {SIAM J. Comput.},
month = jun,
pages = {457–466},
numpages = {10}
}

@article{10.1137/0219029,
author = {Bshouty, Nader H. and Kaminski, Michael},
title = {Multiplication of Polynomials over Finite Fields},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219029},
doi = {10.1137/0219029},
journal = {SIAM J. Comput.},
month = jun,
pages = {452–456},
numpages = {5}
}

@article{10.1137/0219028,
author = {Grandjean, Etienne},
title = {A Nontrivial Lower Bound for an NP Problem on Automata},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219028},
doi = {10.1137/0219028},
journal = {SIAM J. Comput.},
month = jun,
pages = {438–451},
numpages = {14}
}

@article{10.1137/0219027,
author = {Seidl, Helmut},
title = {Deciding Equivalence of Finite Tree Automata},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219027},
doi = {10.1137/0219027},
journal = {SIAM J. Comput.},
month = jun,
pages = {424–437},
numpages = {14}
}

@article{10.1137/0219026,
author = {Molzan, B.},
title = {Expressibility and Nonuniform Complexity Classes},
year = {1990},
issue_date = {June 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219026},
doi = {10.1137/0219026},
journal = {SIAM J. Comput.},
month = jun,
pages = {411–423},
numpages = {13}
}

@article{10.1137/0219025,
author = {Aggarwal, Alok and Anderson, Richard J. and Kao, Ming-Yang},
title = {Parallel Depth-First Search in General Directed Graphs},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219025},
doi = {10.1137/0219025},
journal = {SIAM J. Comput.},
month = apr,
pages = {397–409},
numpages = {13}
}

@article{10.1137/0219024,
author = {Wilson, Christopher B.},
title = {On the Decomposability of <i>NC</i> and <i>AC</i>},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219024},
doi = {10.1137/0219024},
journal = {SIAM J. Comput.},
month = apr,
pages = {384–396},
numpages = {13}
}

@article{10.1137/0219023,
author = {Rutten, J. J. M.},
title = {Semantic Correctness for a Parallel Object-Oriented Language},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219023},
doi = {10.1137/0219023},
journal = {SIAM J. Comput.},
month = apr,
pages = {341–383},
numpages = {43}
}

@article{10.1137/0219022,
author = {Floyd, Robert W. and Knuth, Donald E.},
title = {Addition Machines},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219022},
doi = {10.1137/0219022},
journal = {SIAM J. Comput.},
month = apr,
pages = {329–340},
numpages = {12}
}

@article{10.1137/0219021,
author = {Papadimitriou, Christos H. and Yannakakis, Mihalis},
title = {Towards an Architecture-Independent Analysis of Parallel Algorithms},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219021},
doi = {10.1137/0219021},
journal = {SIAM J. Comput.},
month = apr,
pages = {322–328},
numpages = {7}
}

@article{10.1137/0219020,
author = {Agarwal, Pankaj K. and Sharir, Micha},
title = {Red-Blue Intersection Detection Algorithms, with Applications to Motion Planning and Collision Detection},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219020},
doi = {10.1137/0219020},
journal = {SIAM J. Comput.},
month = apr,
pages = {297–321},
numpages = {25}
}

@article{10.1137/0219019,
author = {Sanchis, Laura A. and Fulk, Mark A.},
title = {On the Efficient Generation of Language Instances},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219019},
doi = {10.1137/0219019},
journal = {SIAM J. Comput.},
month = apr,
pages = {281–296},
numpages = {16}
}

@article{10.1137/0219018,
author = {Plaisted, David A.},
title = {A Heuristic Algorithm for Small Separators in Arbitrary Graphs},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219018},
doi = {10.1137/0219018},
journal = {SIAM J. Comput.},
month = apr,
pages = {267–280},
numpages = {14}
}

@article{10.1137/0219017,
author = {Peleg, David and Upfal, Eli},
title = {A Time-Randomness Trade-off for Oblivious Routing},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219017},
doi = {10.1137/0219017},
journal = {SIAM J. Comput.},
month = apr,
pages = {256–266},
numpages = {11}
}

@article{10.1137/0219016,
author = {Bilardi, G. and Preparata, F. P.},
title = {Characterization of Associative Operations with Prefix Circuits of Constant Depth and Linear Size},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219016},
doi = {10.1137/0219016},
journal = {SIAM J. Comput.},
month = apr,
pages = {246–255},
numpages = {10}
}

@article{10.1137/0219015,
author = {Whitehead, Jennifer},
title = {The Complexity of File Transfer Scheduling with Forwarding},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219015},
doi = {10.1137/0219015},
journal = {SIAM J. Comput.},
month = apr,
pages = {222–245},
numpages = {24}
}

@article{10.1137/0219014,
author = {Kutylowski, Miroslaw and Liundefinedkiewicz, Maciej and Loryundefined, Krzysztof},
title = {Reversal Complexity Classes for Alternating Turing Machines},
year = {1990},
issue_date = {April 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219014},
doi = {10.1137/0219014},
journal = {SIAM J. Comput.},
month = apr,
pages = {207–221},
numpages = {15}
}

@article{10.1137/0219013,
author = {Frederickson, Greg N. and Johnson, Donald B.},
title = {Erratum: Generalized Selection and Ranking: Sorted Matrices},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219013},
doi = {10.1137/0219013},
journal = {SIAM J. Comput.},
month = feb,
pages = {205–206},
numpages = {2}
}

@article{10.1137/0219012,
author = {Hoover, H. J.},
title = {Feasible Real Functions and Arithmetic Circuits},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219012},
doi = {10.1137/0219012},
journal = {SIAM J. Comput.},
month = feb,
pages = {182–204},
numpages = {23}
}

@article{10.1137/0219011,
author = {Frederickson, Greg N. and Janardan, Ravi},
title = {Space-Efficient Message Routing in <i>c</i>-Decomposable Networks},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219011},
doi = {10.1137/0219011},
journal = {SIAM J. Comput.},
month = feb,
pages = {164–181},
numpages = {18}
}

@article{10.1137/0219010,
author = {Scheinerman, Edward R.},
title = {On the Expected Capacity of Binomial and Random Concentrators},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219010},
doi = {10.1137/0219010},
journal = {SIAM J. Comput.},
month = feb,
pages = {156–163},
numpages = {8}
}

@article{10.1137/0219009,
author = {Gusfield, Dan},
title = {Very Simple Methods for All Pairs Network Flow Analysis},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219009},
doi = {10.1137/0219009},
journal = {SIAM J. Comput.},
month = feb,
pages = {143–155},
numpages = {13}
}

@article{10.1137/0219008,
author = {Dowling, Michael L.},
title = {A Fast Parallel Horner Algorithm},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219008},
doi = {10.1137/0219008},
journal = {SIAM J. Comput.},
month = feb,
pages = {133–142},
numpages = {10}
}

@article{10.1137/0219007,
author = {Friedman, Joel},
title = {A Density Theorem for Purely Iterative Zero Finding Methods},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219007},
doi = {10.1137/0219007},
journal = {SIAM J. Comput.},
month = feb,
pages = {124–132},
numpages = {9}
}

@article{10.1137/0219006,
author = {Labahn, George and Chio, Dong Koo and Cabay, Stan},
title = {The Inverses of Block Hankel and Block Toeplitz Matrices},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219006},
doi = {10.1137/0219006},
journal = {SIAM J. Comput.},
month = feb,
pages = {98–123},
numpages = {26}
}

@article{10.1137/0219005,
author = {Yokouchi, Hirofumi and Hikita, Teruo},
title = {A Rewriting System for Categorical Combinators with Multiple Arguments},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219005},
doi = {10.1137/0219005},
journal = {SIAM J. Comput.},
month = feb,
pages = {78–97},
numpages = {20}
}

@article{10.1137/0219004,
author = {Ng, Cheng and Hirschberg, Daniel S.},
title = {Lower Bounds for the Stable Marriage Problem and Its Variants},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219004},
doi = {10.1137/0219004},
journal = {SIAM J. Comput.},
month = feb,
pages = {71–77},
numpages = {7}
}

@article{10.1137/0219003,
author = {Hunt, H. B. and Stearns, R. E.},
title = {The Complexity of Very Simple Boolean Formulas with Applications},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219003},
doi = {10.1137/0219003},
journal = {SIAM J. Comput.},
month = feb,
pages = {44–70},
numpages = {27}
}

@article{10.1137/0219002,
author = {Hentzel, I. R. and Jacobs, D. Porkrass},
title = {Complexity and Unsolvability Properties of Nilpotency},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219002},
doi = {10.1137/0219002},
journal = {SIAM J. Comput.},
month = feb,
pages = {32–43},
numpages = {12}
}

@article{10.1137/0219001,
author = {Palis, Michael A. and Shende, Sunil and Wei, David S. L.},
title = {An Optimal Linear-Time Parallel Parser for Tree Adjoining Languages},
year = {1990},
issue_date = {Feb. 1990},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {19},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0219001},
doi = {10.1137/0219001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–31},
numpages = {31}
}

@article{10.1137/0218083,
author = {Ravikumar, B. and Ibarra, O. H.},
title = {Relating the Type of Ambiguity of Finite Automata to the Succinctness of Their Representation},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218083},
doi = {10.1137/0218083},
journal = {SIAM J. Comput.},
month = dec,
pages = {1263–1282},
numpages = {20}
}

@article{10.1137/0218082,
author = {Zhang, K. and Shasha, D.},
title = {Simple Fast Algorithms for the Editing Distance between Trees and Related Problems},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218082},
doi = {10.1137/0218082},
journal = {SIAM J. Comput.},
month = dec,
pages = {1245–1262},
numpages = {18}
}

@article{10.1137/0218081,
author = {Chen, M.-S. and Shin, K. G.},
title = {On Relaxed Squashed Embedding of Graphs into a Hypercube},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218081},
doi = {10.1137/0218081},
journal = {SIAM J. Comput.},
month = dec,
pages = {1226–1244},
numpages = {19}
}

@article{10.1137/0218080,
author = {Vaidya, P. M.},
title = {Geometry Helps in Matching},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218080},
doi = {10.1137/0218080},
journal = {SIAM J. Comput.},
month = dec,
pages = {1201–1225},
numpages = {25}
}

@article{10.1137/0218079,
author = {Li, Z. and Reingold, E. M.},
title = {Solution of a Divide-and-Conquer Maximin Recurrence},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218079},
doi = {10.1137/0218079},
journal = {SIAM J. Comput.},
month = dec,
pages = {1188–1200},
numpages = {13}
}

@article{10.1137/0218078,
author = {Schimmler, M. and Starke, C.},
title = {A Correction Network for <i>N</i>-Sorters},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218078},
doi = {10.1137/0218078},
journal = {SIAM J. Comput.},
month = dec,
pages = {1179–1187},
numpages = {9}
}

@article{10.1137/0218077,
author = {Jerrum, M. and Sinclair, Alistair},
title = {Approximating the Permanent},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218077},
doi = {10.1137/0218077},
journal = {SIAM J. Comput.},
month = dec,
pages = {1149–1178},
numpages = {30}
}

@article{10.1137/0218076,
author = {Vazirani, U. V. and Vazirani, V. V.},
title = {The Two-Processor Scheduling Problem is in Random NC},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218076},
doi = {10.1137/0218076},
journal = {SIAM J. Comput.},
month = dec,
pages = {1140–1148},
numpages = {9}
}

@article{10.1137/0218075,
author = {Rappaport, D.},
title = {Computing Simple Circuits from a Set of Line Segments is NP-Complete},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218075},
doi = {10.1137/0218075},
journal = {SIAM J. Comput.},
month = dec,
pages = {1128–1139},
numpages = {12}
}

@article{10.1137/0218074,
author = {Bernstein, D. and Jaffe, J. M. and Rodeh, M.},
title = {Scheduling Arithmetic and Load Operations in Parallel with No Spilling},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218074},
doi = {10.1137/0218074},
journal = {SIAM J. Comput.},
month = dec,
pages = {1098–1127},
numpages = {30}
}

@article{10.1137/0218073,
author = {Ladner, Richard E.},
title = {Polynomial Space Counting Problems},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218073},
doi = {10.1137/0218073},
journal = {SIAM J. Comput.},
month = dec,
pages = {1087–1097},
numpages = {11}
}

@article{10.1137/0218072,
author = {Cheriyan, J. and Maheshwari, S. N.},
title = {Analysis of Preflow Push Algorithms for Maximum Network Flow},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218072},
doi = {10.1137/0218072},
journal = {SIAM J. Comput.},
month = dec,
pages = {1057–1086},
numpages = {30}
}

@article{10.1137/0218071,
author = {Humenik, K.},
title = {Ratio Estimators Are Maximum-Likelihood Estimators for Non-Context-Free Grammars},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218071},
doi = {10.1137/0218071},
journal = {SIAM J. Comput.},
month = oct,
pages = {1048–1055},
numpages = {8}
}

@article{10.1137/0218070,
author = {Brown, C. A. and Finkelstein, L. and Purdom, P. W.},
title = {A New Base Change Algorithm for Permutation Groups},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218070},
doi = {10.1137/0218070},
journal = {SIAM J. Comput.},
month = oct,
pages = {1037–1047},
numpages = {11}
}

@article{10.1137/0218069,
author = {Gabow, H. N. and Tarjan, R. E.},
title = {Faster Scaling Algorithms for Network Problems},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218069},
doi = {10.1137/0218069},
journal = {SIAM J. Comput.},
month = oct,
pages = {1013–1036},
numpages = {24}
}

@article{10.1137/0218068,
author = {Coan, B. A. and Dolev, D. and Dwork, C. and Stockmeyer, L.},
title = {The Distributed Firing Squad Problem},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218068},
doi = {10.1137/0218068},
journal = {SIAM J. Comput.},
month = oct,
pages = {990–1012},
numpages = {23}
}

@article{10.1137/0218067,
author = {Doberkat, E. E.},
title = {Topological Completeness in an Ideal Model for Polymorphic Types},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218067},
doi = {10.1137/0218067},
journal = {SIAM J. Comput.},
month = oct,
pages = {977–989},
numpages = {13}
}

@article{10.1137/0218066,
author = {Eberly, W.},
title = {Very Fast Parallel Polynomial Arithmetic},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218066},
doi = {10.1137/0218066},
journal = {SIAM J. Comput.},
month = oct,
pages = {955–976},
numpages = {22}
}

@article{10.1137/0218065,
author = {Ahuja, R. K. and Orlin, J. B. and Tarjan, R. E.},
title = {Improved Time Bounds for the Maximum Flow Problem},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218065},
doi = {10.1137/0218065},
journal = {SIAM J. Comput.},
month = oct,
pages = {939–954},
numpages = {16}
}

@article{10.1137/0218064,
author = {Rhee, W. T. and Talagrand, M.},
title = {The Complete Convergence of First Fit Decreasing},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218064},
doi = {10.1137/0218064},
journal = {SIAM J. Comput.},
month = oct,
pages = {919–938},
numpages = {20}
}

@article{10.1137/0218063,
author = {Rhee, W. T. and Talagrand, M.},
title = {The Complete Convergence of Best Fit Decreasing},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218063},
doi = {10.1137/0218063},
journal = {SIAM J. Comput.},
month = oct,
pages = {909–918},
numpages = {10}
}

@article{10.1137/0218062,
author = {Verma, R. M. and Reyner, S. W.},
title = {An Analysis of a Good Algorithm for the Subtree Problem, Correlated},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218062},
doi = {10.1137/0218062},
journal = {SIAM J. Comput.},
month = oct,
pages = {906–908},
numpages = {3}
}

@article{10.1137/0218061,
author = {Cherry, G. W.},
title = {An Analysis of the Rational Exponential Integral},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218061},
doi = {10.1137/0218061},
journal = {SIAM J. Comput.},
month = oct,
pages = {893–905},
numpages = {13}
}

@article{10.1137/0218060,
author = {Anily, S. and Hassin, R.},
title = {Ranking the Best Binary Trees},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218060},
doi = {10.1137/0218060},
journal = {SIAM J. Comput.},
month = oct,
pages = {882–892},
numpages = {11}
}

@article{10.1137/0218059,
author = {H\r{a}stad, J. and Just, B. and Lagarias, J. C. and Schnorr, C. P.},
title = {Polynomial Time Algorithms for Finding Integer Relations among Real Numbers},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218059},
doi = {10.1137/0218059},
journal = {SIAM J. Comput.},
month = oct,
pages = {859–881},
numpages = {23}
}

@article{10.1137/0218058,
author = {Frederickson, Greg N. and Janardan, Ravi},
title = {Efficient Message Routing in Planar Networks},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218058},
doi = {10.1137/0218058},
journal = {SIAM J. Comput.},
month = aug,
pages = {843–857},
numpages = {15}
}

@article{10.1137/0218057,
author = {Culik, Karel and Pachl, Jan K. and Yu, Sheng},
title = {On the Limit Sets of Cellular Automata},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218057},
doi = {10.1137/0218057},
journal = {SIAM J. Comput.},
month = aug,
pages = {831–842},
numpages = {12}
}

@article{10.1137/0218056,
author = {Preparata, Franco P. and Tamassia, Roberto},
title = {Fully Dynamic Point Location in a Monotone Subdivision},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218056},
doi = {10.1137/0218056},
journal = {SIAM J. Comput.},
month = aug,
pages = {811–830},
numpages = {20}
}

@article{10.1137/0218055,
author = {Cole, Richard and Salowe, Jeffrey S. and Steiger, W. L. and Szemer\'{e}di, Endre},
title = {An Optimal-Time Algorithm for Slope Selection},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218055},
doi = {10.1137/0218055},
journal = {SIAM J. Comput.},
month = aug,
pages = {792–810},
numpages = {19}
}

@article{10.1137/0218054,
author = {Jacquet, Philippe and Szpankowski, Wojciech},
title = {Ultimate Characterizations of the Burst Response of an Interval Searching Algorithm: A Study of a Functional Equation},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218054},
doi = {10.1137/0218054},
journal = {SIAM J. Comput.},
month = aug,
pages = {777–791},
numpages = {15}
}

@article{10.1137/0218053,
author = {Bennett, Charles H.},
title = {Time/Space Trade-Offs for Reversible Computation},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218053},
doi = {10.1137/0218053},
journal = {SIAM J. Comput.},
month = aug,
pages = {766–776},
numpages = {11}
}

@article{10.1137/0218052,
author = {Bshouty, Nader H.},
title = {A Lower Bound for Matrix Multiplication},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218052},
doi = {10.1137/0218052},
journal = {SIAM J. Comput.},
month = aug,
pages = {759–765},
numpages = {7}
}

@article{10.1137/0218051,
author = {Vaidya, Pravin M.},
title = {Space-Time Trade-Offs for Orthogonal Range Queries},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218051},
doi = {10.1137/0218051},
journal = {SIAM J. Comput.},
month = aug,
pages = {748–758},
numpages = {11}
}

@article{10.1137/0218050,
author = {Peleg, David and Ullman, Jeffrey D.},
title = {An Optimal Synchronizer for the Hypercube},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218050},
doi = {10.1137/0218050},
journal = {SIAM J. Comput.},
month = aug,
pages = {740–747},
numpages = {8}
}

@article{10.1137/0218049,
author = {Galil, Zvi and Haber, Stuart and Yung, Moti},
title = {Minimum-Knowledge Interactive Proofs for Decision Problems},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218049},
doi = {10.1137/0218049},
journal = {SIAM J. Comput.},
month = aug,
pages = {711–739},
numpages = {29}
}

@article{10.1137/0218048,
author = {Simons, Barbara B. and Warmuth, Manfred K.},
title = {A Fast Algorithm for Multiprocessor Scheduling of Unit-Length Jobs},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218048},
doi = {10.1137/0218048},
journal = {SIAM J. Comput.},
month = aug,
pages = {690–710},
numpages = {21}
}

@article{10.1137/0218047,
author = {Yao, Andrew Chi-Chih},
title = {On the Complexity of Partial Order Productions},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218047},
doi = {10.1137/0218047},
journal = {SIAM J. Comput.},
month = aug,
pages = {679–689},
numpages = {11}
}

@article{10.1137/0218046,
author = {Iliopoulos, Costas S.},
title = {Worst-Case Complexity Bounds on Algorithms for Computing the Canonical Structure of Infinite Abelian Groups and Solving Systems of Linear Diophantine Equations},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218046},
doi = {10.1137/0218046},
journal = {SIAM J. Comput.},
month = aug,
pages = {670–678},
numpages = {9}
}

@article{10.1137/0218045,
author = {Iliopoulos, Costas S.},
title = {Worst-Case Complexity Bounds on Algorithms for Computing the Canonical Structure of Finite Abelian Groups and the Hermite and Smith Normal Forms of an Integer Matrix},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218045},
doi = {10.1137/0218045},
journal = {SIAM J. Comput.},
month = aug,
pages = {658–669},
numpages = {12}
}

@article{10.1137/0218044,
author = {Labahn, George and Cabay, Stan},
title = {Matrix Pade´ Fractions and Their Computation},
year = {1989},
issue_date = {Aug. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218044},
doi = {10.1137/0218044},
journal = {SIAM J. Comput.},
month = aug,
pages = {639–657},
numpages = {19}
}

@article{10.1137/0218043,
author = {Immerman, Neil},
title = {Expressibility and Parallel Complexity},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218043},
doi = {10.1137/0218043},
journal = {SIAM J. Comput.},
month = jun,
pages = {625–638},
numpages = {14}
}

@article{10.1137/0218042,
author = {Norton, G. H.},
title = {Precise Analyses of the Right- and Left-Shift Greatest Common Divisor Algorithms for <i>GF</i>(<i>q</i>)U<i>x</i>e},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218042},
doi = {10.1137/0218042},
journal = {SIAM J. Comput.},
month = jun,
pages = {608–624},
numpages = {17}
}

@article{10.1137/0218041,
author = {Rajasekaran, S. and Reif, J. H.},
title = {Optimal and Sublogarithmic Time Randomized Parallel Sorting Algorithms},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218041},
doi = {10.1137/0218041},
journal = {SIAM J. Comput.},
month = jun,
pages = {594–607},
numpages = {14}
}

@article{10.1137/0218040,
author = {Clausen, M.},
title = {Fast Fourier Transforms for Metabelian Groups},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218040},
doi = {10.1137/0218040},
journal = {SIAM J. Comput.},
month = jun,
pages = {584–593},
numpages = {10}
}

@article{10.1137/0218039,
author = {Barahona, R. and Tardos, E.},
title = {Note on Weintraub's Minimum-Cost Circulation Algorithm},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218039},
doi = {10.1137/0218039},
journal = {SIAM J. Comput.},
month = jun,
pages = {579–583},
numpages = {5}
}

@article{10.1137/0218038,
author = {Borodin, A. and Cook, S. A. and Dymond, P. W. and Ruzzo, W. L. and Tompa, M.},
title = {Two Applications of Inductive Counting for Complementation Problems},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218038},
doi = {10.1137/0218038},
journal = {SIAM J. Comput.},
month = jun,
pages = {559–578},
numpages = {20}
}

@article{10.1137/0218037,
author = {Furst, M. L. and Kannan, R.},
title = {Succinct Certificates for Almost All Subset Sum Problems},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218037},
doi = {10.1137/0218037},
journal = {SIAM J. Comput.},
month = jun,
pages = {550–558},
numpages = {9}
}

@article{10.1137/0218036,
author = {Venkateswaran, H. and Tompa, M.},
title = {A New Pebble Game That Characterizes Parallel Complexity Classes},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218036},
doi = {10.1137/0218036},
journal = {SIAM J. Comput.},
month = jun,
pages = {533–549},
numpages = {17}
}

@article{10.1137/0218035,
author = {Atallah, M. J. and Cole, R. and Goodrich, M. T.},
title = {Cascading Divide-and-Conquer: A Technique for Designing Parallel Algorithms},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218035},
doi = {10.1137/0218035},
journal = {SIAM J. Comput.},
month = jun,
pages = {499–532},
numpages = {34}
}

@article{10.1137/0218034,
author = {Rhee, W. T. and Talagrand, M.},
title = {Optimal Bin Covering with Items of Random Size},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218034},
doi = {10.1137/0218034},
journal = {SIAM J. Comput.},
month = jun,
pages = {487–498},
numpages = {12}
}

@article{10.1137/0218033,
author = {Rhee, Wansoo T. and Talagrand, Michel},
title = {Optimal Bin Packing with Items of Random Sizes III},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218033},
doi = {10.1137/0218033},
journal = {SIAM J. Comput.},
month = jun,
pages = {473–486},
numpages = {14}
}

@article{10.1137/0218032,
author = {Li, S.-Y. R.},
title = {Dynamic Programming by Exchangeability},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218032},
doi = {10.1137/0218032},
journal = {SIAM J. Comput.},
month = jun,
pages = {463–472},
numpages = {10}
}

@article{10.1137/0218031,
author = {Tang, S. and Watanabe, O.},
title = {On Tally Relativizations of <i>BP</i>-Complexity Classes},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218031},
doi = {10.1137/0218031},
journal = {SIAM J. Comput.},
month = jun,
pages = {449–462},
numpages = {14}
}

@article{10.1137/0218030,
author = {Chan, E P},
title = {A Design Theory for Solving the Anomalies Problem},
year = {1989},
issue_date = {June 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218030},
doi = {10.1137/0218030},
journal = {SIAM J. Comput.},
month = jun,
pages = {429–448},
numpages = {20}
}

@article{10.1137/0218029,
author = {Goldberg, Mark and Spencer, Thomas},
title = {A New Parallel Algorithm for the Maximal Independent Set Problem},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218029},
doi = {10.1137/0218029},
journal = {SIAM J. Comput.},
month = apr,
pages = {419–427},
numpages = {9}
}

@article{10.1137/0218028,
author = {Bugrara, Khaled M. and Pan, Youfang and Purdom, Paul Walton},
title = {Exponential Average Time for the Pure Literal Rule},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218028},
doi = {10.1137/0218028},
journal = {SIAM J. Comput.},
month = apr,
pages = {409–418},
numpages = {10}
}

@article{10.1137/0218027,
author = {Ko, Ker-I},
title = {Relativized Polynomial Time Hierarchies Having Exactly K Levels},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218027},
doi = {10.1137/0218027},
journal = {SIAM J. Comput.},
month = apr,
pages = {392–408},
numpages = {17}
}

@article{10.1137/0218026,
author = {Iwama, Kazuo},
title = {CNF Satisfiability Test by Counting and Polynomial Average Time},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218026},
doi = {10.1137/0218026},
journal = {SIAM J. Comput.},
month = apr,
pages = {385–391},
numpages = {7}
}

@article{10.1137/0218025,
author = {Yao, F. Frances and Dobkin, David P. and Edelsbrunner, Herbert and Paterson, Michael S.},
title = {Partitioning Space for Range Queries},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218025},
doi = {10.1137/0218025},
journal = {SIAM J. Comput.},
month = apr,
pages = {371–384},
numpages = {14}
}

@article{10.1137/0218024,
author = {Renegar, James},
title = {On the Worst-Case Arithmetic Complexity of Approximating Zeros of Systems of Polynomials},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218024},
doi = {10.1137/0218024},
journal = {SIAM J. Comput.},
month = apr,
pages = {350–370},
numpages = {21}
}

@article{10.1137/0218023,
author = {Naor, Joseph (Seffi) and Naor, Moni and Sch\"{a}ffer, Alejandro A.},
title = {Fast Parallel Algorithms for Chordal Graphs},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218023},
doi = {10.1137/0218023},
journal = {SIAM J. Comput.},
month = apr,
pages = {327–349},
numpages = {23}
}

@article{10.1137/0218022,
author = {Leung, Joseph Y.-T. and Young, Gilbert H.},
title = {Minimizing Schedule Length Subject to Minimum Flow Time},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218022},
doi = {10.1137/0218022},
journal = {SIAM J. Comput.},
month = apr,
pages = {314–326},
numpages = {13}
}

@article{10.1137/0218021,
author = {Melen, Riccardo and Turner, Jonathan S.},
title = {Nonblocking Multirate Networks},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218021},
doi = {10.1137/0218021},
journal = {SIAM J. Comput.},
month = apr,
pages = {301–313},
numpages = {13}
}

@article{10.1137/0218020,
author = {Hagerup, Torben and Chrobak, Marek and Diks, Krzysztof},
title = {Optimal Parallel 5-Colouring of Planar Graphs},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218020},
doi = {10.1137/0218020},
journal = {SIAM J. Comput.},
month = apr,
pages = {288–300},
numpages = {13}
}

@article{10.1137/0218019,
author = {Steele, J. Michael and Snyder, Timothy Law},
title = {Worst-Case Growth Rates of Some Classical Problems of Combinatorial Optimization},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218019},
doi = {10.1137/0218019},
journal = {SIAM J. Comput.},
month = apr,
pages = {278–287},
numpages = {10}
}

@article{10.1137/0218018,
author = {Bar-Noy, Amotz and Borodin, Allen and Karchmer, Mauricio and Linial, Nathan and Werman, Michael},
title = {Bounds on Universal Sequences},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218018},
doi = {10.1137/0218018},
journal = {SIAM J. Comput.},
month = apr,
pages = {268–277},
numpages = {10}
}

@article{10.1137/0218017,
author = {Alon, N. and Azar, Y.},
title = {Finding an Approximate Maximum},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218017},
doi = {10.1137/0218017},
journal = {SIAM J. Comput.},
month = apr,
pages = {258–267},
numpages = {10}
}

@article{10.1137/0218016,
author = {Hwang, Jing-Jang and Chow, Yuan-Chieh and Anger, Frank D. and Lee, Chung-Yee},
title = {Scheduling Precedence Graphs in Systems with Interprocessor Communication Times},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218016},
doi = {10.1137/0218016},
journal = {SIAM J. Comput.},
month = apr,
pages = {244–257},
numpages = {14}
}

@article{10.1137/0218015,
author = {Peleg, David and Upfal, Eli},
title = {The Token Distribution Problem},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218015},
doi = {10.1137/0218015},
journal = {SIAM J. Comput.},
month = apr,
pages = {229–243},
numpages = {15}
}

@article{10.1137/0218014,
author = {Bilardi, Gianfranco and Nicolau, Alexandru},
title = {Adaptive Bitonic Sorting: An Optimal Parallel Algorithm for Shared-Memory Machines},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218014},
doi = {10.1137/0218014},
journal = {SIAM J. Comput.},
month = apr,
pages = {216–228},
numpages = {13}
}

@article{10.1137/0218013,
author = {Lickteig, Thomas},
title = {A Lower Bound on the Complexity of Division in Finite Extension Fields and Inversion in Quadratic Alternative Algebras},
year = {1989},
issue_date = {April 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218013},
doi = {10.1137/0218013},
journal = {SIAM J. Comput.},
month = apr,
pages = {209–215},
numpages = {7}
}

@article{10.1137/0218012,
author = {Goldwasser, S. and Micali, S. and Rackoff, C.},
title = {The Knowledge Complexity of Interactive Proof Systems},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218012},
doi = {10.1137/0218012},
journal = {SIAM J. Comput.},
month = feb,
pages = {186–208},
numpages = {23}
}

@article{10.1137/0218011,
author = {Coffman, E. G. and Lagarias, J. C.},
title = {Algorithms for Packing Squares: A Probabilistic Analysis},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218011},
doi = {10.1137/0218011},
journal = {SIAM J. Comput.},
month = feb,
pages = {166–185},
numpages = {20}
}

@article{10.1137/0218010,
author = {Ordman, E. T.},
title = {Minimal Threshold Separators and Memory Requirements for Synchronization},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218010},
doi = {10.1137/0218010},
journal = {SIAM J. Comput.},
month = feb,
pages = {152–165},
numpages = {14}
}

@article{10.1137/0218009,
author = {Rhee, Wansoo T. and Talagrand, M.},
title = {Optimal Bin Packing with Items of Random Sizes II},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218009},
doi = {10.1137/0218009},
journal = {SIAM J. Comput.},
month = feb,
pages = {139–151},
numpages = {13}
}

@article{10.1137/0218008,
author = {Frederickson, Greg N. and Srinivas, Mandayam A.},
title = {Algorithms and Data Structures for an Expanded Family of Matroid Intersection Problems},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218008},
doi = {10.1137/0218008},
journal = {SIAM J. Comput.},
month = feb,
pages = {112–138},
numpages = {27}
}

@article{10.1137/0218007,
author = {Cai, J.-Y. and Gundermann, T. and Wechsung, G. and Hartmanis, J. and Hemachandra, Lane A. and Sewelson, V. and Wagner, K.},
title = {The Boolean Hierarchy II: Applications},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218007},
doi = {10.1137/0218007},
journal = {SIAM J. Comput.},
month = feb,
pages = {95–111},
numpages = {17}
}

@article{10.1137/0218006,
author = {Larmore, L. L.},
title = {Minimum Delay Codes},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218006},
doi = {10.1137/0218006},
journal = {SIAM J. Comput.},
month = feb,
pages = {82–94},
numpages = {13}
}

@article{10.1137/0218005,
author = {Korte, Norbert and M\"{o}hring, Rolf H.},
title = {An Incremental Linear-Time Algorithm for Recognizing Interval Graphs},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218005},
doi = {10.1137/0218005},
journal = {SIAM J. Comput.},
month = feb,
pages = {68–81},
numpages = {14}
}

@article{10.1137/0218004,
author = {Wilber, R.},
title = {Lower Bounds for Accessing Binary Search Trees with Rotations},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218004},
doi = {10.1137/0218004},
journal = {SIAM J. Comput.},
month = feb,
pages = {56–67},
numpages = {12}
}

@article{10.1137/0218003,
author = {Gallo, G. and Grigoriadis, M. D. and Tarjan, R. E.},
title = {A Fast Parametric Maximum Flow Algorithm and Applications},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218003},
doi = {10.1137/0218003},
journal = {SIAM J. Comput.},
month = feb,
pages = {30–55},
numpages = {26}
}

@article{10.1137/0218002,
author = {Abrahamson, K. and Adler, A. and Gelbart, R. and Higham, L. and Kirkpatrick, D.},
title = {The Bit Complexity of Randomized Leader Election on a Ring},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218002},
doi = {10.1137/0218002},
journal = {SIAM J. Comput.},
month = feb,
pages = {12–29},
numpages = {18}
}

@article{10.1137/0218001,
author = {Westbrook, J. and Tarjan, R. E.},
title = {Amortized Analysis of Algorithms for Set Union with Backtracking},
year = {1989},
issue_date = {Feb. 1989},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {18},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0218001},
doi = {10.1137/0218001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–11},
numpages = {11}
}

@article{10.1137/0217080,
author = {Kadin, Jim},
title = {The Polynomial Time Hierarchy Collapses If the Boolean Hierarchy Collapses},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217080},
doi = {10.1137/0217080},
journal = {SIAM J. Comput.},
month = dec,
pages = {1263–1282},
numpages = {20}
}

@article{10.1137/0217079,
author = {Schieber, Baruch and Vishkin, Uzi},
title = {On Finding Lowest Common Ancestors: Simplification and Parallelization},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217079},
doi = {10.1137/0217079},
journal = {SIAM J. Comput.},
month = dec,
pages = {1253–1262},
numpages = {10}
}

@article{10.1137/0217078,
author = {Cai, Jin-Yi and Gundermann, Thomas and Hartmanis, Juris and Hemachandra, Lane A. and Sewelson, Vivian and Wagner, Klaus and Wechsung, Gerd},
title = {The Boolean Hierarchy I: Structural Properties},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217078},
doi = {10.1137/0217078},
journal = {SIAM J. Comput.},
month = dec,
pages = {1232–1252},
numpages = {21}
}

@article{10.1137/0217077,
author = {Kong, T. Y. and Mount, David M. and Roscoe, A. W.},
title = {The Decomposition of a Rectangle into Rectangles of Minimal Perimeter},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217077},
doi = {10.1137/0217077},
journal = {SIAM J. Comput.},
month = dec,
pages = {1215–1231},
numpages = {17}
}

@article{10.1137/0217076,
author = {Knight, William J.},
title = {Search in an Ordered Array Having Variable Probe Cost},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217076},
doi = {10.1137/0217076},
journal = {SIAM J. Comput.},
month = dec,
pages = {1203–1214},
numpages = {12}
}

@article{10.1137/0217075,
author = {Allender, Eric W. and Rubinstein, Roy S.},
title = {P-Printable Sets},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217075},
doi = {10.1137/0217075},
journal = {SIAM J. Comput.},
month = dec,
pages = {1193–1202},
numpages = {10}
}

@article{10.1137/0217074,
author = {Alon, N. and Azar, Z.},
title = {The Average Complexity of Deterministic and Randomized Parallel Comparison-Sorting Algorithms},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217074},
doi = {10.1137/0217074},
journal = {SIAM J. Comput.},
month = dec,
pages = {1178–1192},
numpages = {15}
}

@article{10.1137/0217073,
author = {Bergstra, J. A. and Klop, J. W. and Olderrog, E.-R.},
title = {Readies and Failures in the Algebra of Communicating Processes},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217073},
doi = {10.1137/0217073},
journal = {SIAM J. Comput.},
month = dec,
pages = {1134–1177},
numpages = {44}
}

@article{10.1137/0217072,
author = {Bollob\'{a}s, B\'{e}la and Brightwell, Graham},
title = {Transitive Orientations of Graphs},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217072},
doi = {10.1137/0217072},
journal = {SIAM J. Comput.},
month = dec,
pages = {1119–1133},
numpages = {15}
}

@article{10.1137/0217071,
author = {Morris, Robert J. T. and Wong, Wing Shing},
title = {A Short-Term Neural Network Memory},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217071},
doi = {10.1137/0217071},
journal = {SIAM J. Comput.},
month = dec,
pages = {1103–1118},
numpages = {16}
}

@article{10.1137/0217070,
author = {Mehlhorn, Kurt and N\"{a}her, Stefan and Alt, Helmut},
title = {A Lower Bound on the Complexity of the Union-Split-Find Problem},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217070},
doi = {10.1137/0217070},
journal = {SIAM J. Comput.},
month = dec,
pages = {1093–1102},
numpages = {10}
}

@article{10.1137/0217069,
author = {Ben-Or, Michael and Feig, Ephraim and Kozen, Dexter and Tiwari, Prasoon},
title = {A Fast Parallel Algorithm for Determining All Roots of a Polynomial with Real Roots},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217069},
doi = {10.1137/0217069},
journal = {SIAM J. Comput.},
month = dec,
pages = {1081–1092},
numpages = {12}
}

@article{10.1137/0217068,
author = {Lengaujer, Thomas and Wanke, Egon},
title = {Efficient Solution to Connectivity Problems on Hierarchically Defined Graphs},
year = {1988},
issue_date = {Dec. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217068},
doi = {10.1137/0217068},
journal = {SIAM J. Comput.},
month = dec,
pages = {1063–1080},
numpages = {18}
}

@article{10.1137/0217067,
author = {Tarjan, Robert E. and VanWyk, Christopher J.},
title = {Erratum: An <i>O</i> (<i>n</i> Log Log <i>n</i>)-Time Algorithm for Triangulating a Simple Polygon},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217067},
doi = {10.1137/0217067},
journal = {SIAM J. Comput.},
month = oct,
pages = {1061},
numpages = {1}
}

@article{10.1137/0217066,
author = {McDiarmid, Colin},
title = {Average-Case Lower Bounds for Searching},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217066},
doi = {10.1137/0217066},
journal = {SIAM J. Comput.},
month = oct,
pages = {1044–1060},
numpages = {17}
}

@article{10.1137/0217065,
author = {Zellini, Paolo},
title = {Optimal Bounds for Solving Tridiagonal Systems with Preconditioning},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217065},
doi = {10.1137/0217065},
journal = {SIAM J. Comput.},
month = oct,
pages = {1036–1043},
numpages = {8}
}

@article{10.1137/0217064,
author = {Miller, Zevi},
title = {A Linear Algorithm for Topological Bandwidth in Degree-Three Trees},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217064},
doi = {10.1137/0217064},
journal = {SIAM J. Comput.},
month = oct,
pages = {1018–1035},
numpages = {18}
}

@article{10.1137/0217063,
author = {Hennessy, Matthew},
title = {Axiomatising Finite Concurrent Processes},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217063},
doi = {10.1137/0217063},
journal = {SIAM J. Comput.},
month = oct,
pages = {997–1017},
numpages = {21}
}

@article{10.1137/0217062,
author = {Selman, Alan L.},
title = {Natural Self-Reducible Sets},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217062},
doi = {10.1137/0217062},
journal = {SIAM J. Comput.},
month = oct,
pages = {989–996},
numpages = {8}
}

@article{10.1137/0217061,
author = {Dwork, Cynthia and Peleg, David and Upfal, Eli},
title = {Fault Tolerance in Networks of Bounded Degree},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217061},
doi = {10.1137/0217061},
journal = {SIAM J. Comput.},
month = oct,
pages = {975–988},
numpages = {14}
}

@article{10.1137/0217060,
author = {Dyer, M. E. and Frieze, A. M.},
title = {On the Complexity of Computing the Volume of a Polyhedron},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217060},
doi = {10.1137/0217060},
journal = {SIAM J. Comput.},
month = oct,
pages = {967–974},
numpages = {8}
}

@article{10.1137/0217059,
author = {Bloom, Stephen L. and Esik, Zoltan},
title = {Varieties of Iteration Theories},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217059},
doi = {10.1137/0217059},
journal = {SIAM J. Comput.},
month = oct,
pages = {939–966},
numpages = {28}
}

@article{10.1137/0217058,
author = {Immerman, Neil},
title = {Nondeterministic Space is Closed under Complementation},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217058},
doi = {10.1137/0217058},
journal = {SIAM J. Comput.},
month = oct,
pages = {935–938},
numpages = {4}
}

@article{10.1137/0217057,
author = {Provan, J. Scott},
title = {An Approximation Scheme for Finding Steiner Trees with Obstacles},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217057},
doi = {10.1137/0217057},
journal = {SIAM J. Comput.},
month = oct,
pages = {920–934},
numpages = {15}
}

@article{10.1137/0217056,
author = {Book, Ronald V. and Ko, Ker-l},
title = {On Sets Truth-Table Reducible to Sparse Sets},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217056},
doi = {10.1137/0217056},
journal = {SIAM J. Comput.},
month = oct,
pages = {903–919},
numpages = {17}
}

@article{10.1137/0217055,
author = {Karp, Richard M. and Motwani, Rajeev and Raghavan, Prabhakar},
title = {Deferred Data Structuring},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217055},
doi = {10.1137/0217055},
journal = {SIAM J. Comput.},
month = oct,
pages = {883–902},
numpages = {20}
}

@article{10.1137/0217054,
author = {Edelsbrunner, Herbert and Skiena, Steven S.},
title = {Probing Convex Polygons with X-Rays},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217054},
doi = {10.1137/0217054},
journal = {SIAM J. Comput.},
month = oct,
pages = {870–882},
numpages = {13}
}

@article{10.1137/0217053,
author = {Atallah, Mikhail J. and Kosaraju, S. Rao},
title = {Efficient Solutions to Some Transportation Problems with Applications to Minimizing Robot Arm Travel},
year = {1988},
issue_date = {October 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217053},
doi = {10.1137/0217053},
journal = {SIAM J. Comput.},
month = oct,
pages = {849–869},
numpages = {21}
}

@article{10.1137/0217052,
author = {Clarkson, Kenneth L.},
title = {A Randomized Algorithm for Closest-Point Queries},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217052},
doi = {10.1137/0217052},
journal = {SIAM J. Comput.},
month = aug,
pages = {830–847},
numpages = {18}
}

@article{10.1137/0217051,
author = {Gabow, Harold N.},
title = {Scheduling Uet Systems on Two Uniform Processors and Length Two Pipelines},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217051},
doi = {10.1137/0217051},
journal = {SIAM J. Comput.},
month = aug,
pages = {810–829},
numpages = {20}
}

@article{10.1137/0217050,
author = {Grandjean, Etienne},
title = {A Natural Np-Complete Problem with a Nontrivial Lower Bound},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217050},
doi = {10.1137/0217050},
journal = {SIAM J. Comput.},
month = aug,
pages = {786–809},
numpages = {24}
}

@article{10.1137/0217049,
author = {Cole, Richard},
title = {Parallel Merge Sort},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217049},
doi = {10.1137/0217049},
journal = {SIAM J. Comput.},
month = aug,
pages = {770–785},
numpages = {16}
}

@article{10.1137/0217048,
author = {Gusfield, Dan},
title = {The Structure of the Stable Roomate Problem: Efficient Representation and Enumeration of All Stable Assignments},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217048},
doi = {10.1137/0217048},
journal = {SIAM J. Comput.},
month = aug,
pages = {742–769},
numpages = {28}
}

@article{10.1137/0217047,
author = {Avis, David and Lai, C. W.},
title = {The Probabilistic Analysis of a Heuristic for the Assignment Problem},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217047},
doi = {10.1137/0217047},
journal = {SIAM J. Comput.},
month = aug,
pages = {732–741},
numpages = {10}
}

@article{10.1137/0217046,
author = {Dwork, Cynthia and Kanellakis, Paris C. and Stockmeyer, Larry},
title = {Parallel Algorithms for Term Matching},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217046},
doi = {10.1137/0217046},
journal = {SIAM J. Comput.},
month = aug,
pages = {711–731},
numpages = {21}
}

@article{10.1137/0217045,
author = {Ravi, S. S. and Lloyd, Errol L.},
title = {The Complexity of Near-Optimal Programmable Logic Array Folding},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217045},
doi = {10.1137/0217045},
journal = {SIAM J. Comput.},
month = aug,
pages = {696–710},
numpages = {15}
}

@article{10.1137/0217044,
author = {Miller, Gary L. and Ramachandran, Vijaya and Kaltofen, Erich},
title = {Efficient Parallel Evaluation of Straight-Line Code and Arithmetic Circuits},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217044},
doi = {10.1137/0217044},
journal = {SIAM J. Comput.},
month = aug,
pages = {687–695},
numpages = {9}
}

@article{10.1137/0217043,
author = {Ku\v{c}era, Lud\v{e}k and Trnkov\u{a}, V\v{e}ra},
title = {Isomorphism Testing of Unary Algebras},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217043},
doi = {10.1137/0217043},
journal = {SIAM J. Comput.},
month = aug,
pages = {673–686},
numpages = {14}
}

@article{10.1137/0217042,
author = {Vit\'{a}nyi, Paul M. B.},
title = {Locality, Communication, and Interconnect Length in Multicomputers},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217042},
doi = {10.1137/0217042},
journal = {SIAM J. Comput.},
month = aug,
pages = {659–672},
numpages = {14}
}

@article{10.1137/0217041,
author = {Schaback, R.},
title = {On the Expected Sublinearity of the Boyer-Moore Algorithm},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217041},
doi = {10.1137/0217041},
journal = {SIAM J. Comput.},
month = aug,
pages = {648–658},
numpages = {11}
}

@article{10.1137/0217040,
author = {John, John Welliaveetil},
title = {A New Lower Bound for the Set-Partitioning Problem},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217040},
doi = {10.1137/0217040},
journal = {SIAM J. Comput.},
month = aug,
pages = {640–647},
numpages = {8}
}

@article{10.1137/0217039,
author = {Dershowitz, Nachum and Marcus, Leo and Tarlecki, Andrzej},
title = {Existence, Uniqueness, and Construction of Rewrite Systems},
year = {1988},
issue_date = {August 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217039},
doi = {10.1137/0217039},
journal = {SIAM J. Comput.},
month = aug,
pages = {629–639},
numpages = {11}
}

@article{10.1137/0217038,
author = {Long, Timothy J.},
title = {Erratum: On Restricting the Size of Oracles Compared with Restricting Access to Oracles},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217038},
doi = {10.1137/0217038},
journal = {SIAM J. Comput.},
month = jun,
pages = {628},
numpages = {1}
}

@article{10.1137/0217037,
author = {Fich, Faith E. and Ragde, Prabhakar and Wigderson, Avi},
title = {Relations between Concurrent-Write Models of Parallel Computation},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217037},
doi = {10.1137/0217037},
journal = {SIAM J. Comput.},
month = jun,
pages = {606–627},
numpages = {22}
}

@article{10.1137/0217036,
author = {Siegel, Alan and Dolev, Danny},
title = {Some Geometry for General River Routing},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217036},
doi = {10.1137/0217036},
journal = {SIAM J. Comput.},
month = jun,
pages = {583–605},
numpages = {23}
}

@article{10.1137/0217035,
author = {Vaidya, Pravin M.},
title = {Minimum Spanning Trees in <i>k</i>-Dimensional Space},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217035},
doi = {10.1137/0217035},
journal = {SIAM J. Comput.},
month = jun,
pages = {572–582},
numpages = {11}
}

@article{10.1137/0217034,
author = {Gusfield, Dan},
title = {A Graph Theoretic Approach to Statistical Data Security},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217034},
doi = {10.1137/0217034},
journal = {SIAM J. Comput.},
month = jun,
pages = {552–571},
numpages = {20}
}

@article{10.1137/0217033,
author = {Hochbaum, Dorit s. and Shmoys, David B.},
title = {A Polynomial Approximation Scheme for Scheduling on Uniform Processors: Using the Dual Approximation Approach},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217033},
doi = {10.1137/0217033},
journal = {SIAM J. Comput.},
month = jun,
pages = {539–551},
numpages = {13}
}

@article{10.1137/0217032,
author = {D'Atri, Alessandro and Moscarini, Marina},
title = {Distance-Hereditary Graphs, Steiner Trees, and Connected Domination},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217032},
doi = {10.1137/0217032},
journal = {SIAM J. Comput.},
month = jun,
pages = {521–538},
numpages = {18}
}

@article{10.1137/0217031,
author = {Yao, Andrew Chi-Chih},
title = {Monotone Bipartite Graph Properties Are Evasive},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217031},
doi = {10.1137/0217031},
journal = {SIAM J. Comput.},
month = jun,
pages = {517–520},
numpages = {4}
}

@article{10.1137/0217030,
author = {Book, R. and Orponen, P. and Russo, D. and Watanabe, O.},
title = {Lowness Properties of Sets in the Exponential-Time Hierarchy},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217030},
doi = {10.1137/0217030},
journal = {SIAM J. Comput.},
month = jun,
pages = {504–516},
numpages = {13}
}

@article{10.1137/0217029,
author = {Pittel, Boris and Yu, Jenn-Hwa},
title = {On Search Times for Early-Insertion Coalesced Hashing},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217029},
doi = {10.1137/0217029},
journal = {SIAM J. Comput.},
month = jun,
pages = {492–503},
numpages = {12}
}

@article{10.1137/0217028,
author = {He, Xin and Yesha, Yaacov},
title = {A Nearly Optimal Parallel Algorithm for Constructing Depth First Spanning Trees in Planar Graphs},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217028},
doi = {10.1137/0217028},
journal = {SIAM J. Comput.},
month = jun,
pages = {486–491},
numpages = {6}
}

@article{10.1137/0217027,
author = {Klein, Philip N. and Reif, John H.},
title = {Parallel Time <i>O</i>(Log <i>n</i>) Acceptance of Deterministic CFLs on an Exclusive-Write P-RAM},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217027},
doi = {10.1137/0217027},
journal = {SIAM J. Comput.},
month = jun,
pages = {463–485},
numpages = {23}
}

@article{10.1137/0217026,
author = {Chazelle, Bernard},
title = {Functional Approach to Data Structures and Its Use in Multidimensional Searching},
year = {1988},
issue_date = {June 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217026},
doi = {10.1137/0217026},
journal = {SIAM J. Comput.},
month = jun,
pages = {427–462},
numpages = {36}
}

@article{10.1137/0213009,
author = {Chiu, Dah-Ming and Bernstein, Philip A. and Ho, Yu-Chi},
title = {Optimizing Chain Queries in a Distributed Database System.},
year = {1984},
issue_date = {Feb. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213009},
doi = {10.1137/0213009},
journal = {SIAM J. Comput.},
month = feb,
pages = {116–134},
numpages = {19}
}

@article{10.1137/0213008,
author = {Manber, Udi and Tompa, Martin},
title = {The Effect of Number of Hamiltonian Paths on the Complexity of a Vertex-Coloring Problem},
year = {1984},
issue_date = {Feb. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213008},
doi = {10.1137/0213008},
journal = {SIAM J. Comput.},
month = feb,
pages = {109–115},
numpages = {7}
}

@article{10.1137/0213004,
author = {Reif, John H.},
title = {On Synchronous Parallel Computations with Independent Probabilistic Choice},
year = {1984},
issue_date = {Feb. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213004},
doi = {10.1137/0213004},
journal = {SIAM J. Comput.},
month = feb,
pages = {46–56},
numpages = {11}
}

@article{10.1137/0213026,
author = {Cartwright, Robert},
title = {Recursive Programs as Definitions in First Order Logic},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213026},
doi = {10.1137/0213026},
journal = {SIAM J. Comput.},
month = may,
pages = {374–408},
numpages = {35}
}

@article{10.1137/0213024,
author = {Harel, Dov and Tarjan, Robert Endre},
title = {Fast Algorithms for Finding Nearest Common Ancestors},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213024},
doi = {10.1137/0213024},
journal = {SIAM J. Comput.},
month = may,
pages = {338–355},
numpages = {18}
}

@article{10.1137/0213023,
author = {Schoning, Uwe and Book, Ronald V.},
title = {Immunity, Relativizations, and Nondeterminism},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213023},
doi = {10.1137/0213023},
journal = {SIAM J. Comput.},
month = may,
pages = {329–337},
numpages = {9}
}

@article{10.1137/0213022,
author = {Agarwal, Sunita and Mittal, A K. and Sharma, P},
title = {Constrained Optimum Communication Trees and Sensitivity Analysis},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213022},
doi = {10.1137/0213022},
journal = {SIAM J. Comput.},
month = may,
pages = {315–328},
numpages = {14}
}

@article{10.1137/0213021,
author = {Sharir, Micha and Pnueli, Amir and Harts, Sergiu},
title = {Verification of Probabilistic Programs},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213021},
doi = {10.1137/0213021},
journal = {SIAM J. Comput.},
month = may,
pages = {292–314},
numpages = {23}
}

@article{10.1137/0213020,
author = {Frederickson, Greg N.},
title = {Self-Organizing Heuristics for Implicit Data Structures},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213020},
doi = {10.1137/0213020},
journal = {SIAM J. Comput.},
month = may,
pages = {277–291},
numpages = {15}
}

@article{10.1137/0213019,
author = {Bini, Dario},
title = {Parallel Solution of Certain Toeplitz Linear Systems},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213019},
doi = {10.1137/0213019},
journal = {SIAM J. Comput.},
month = may,
pages = {268–276},
numpages = {9}
}

@article{10.1137/0213017,
author = {Hu, T C. and Shing, M T.},
title = {Computation of Matrix Chain Products.  Part II},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213017},
doi = {10.1137/0213017},
journal = {SIAM J. Comput.},
month = may,
pages = {228–251},
numpages = {24}
}

@article{10.1137/0213016,
author = {Duris, Pavol and Galil, Zvi},
title = {Two Tapes Are Better than One for Nondeterministic Machines},
year = {1984},
issue_date = {May 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213016},
doi = {10.1137/0213016},
journal = {SIAM J. Comput.},
month = may,
pages = {219–227},
numpages = {9}
}

@article{10.1137/0213040,
author = {Leung, Joseph Y-T. and Vornberger, Oliver and Witthoff, James D.},
title = {On Some Variants of the Bandwidth Minimization Problem},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213040},
doi = {10.1137/0213040},
journal = {SIAM J. Comput.},
month = jul,
pages = {650–667},
numpages = {18}
}

@article{10.1137/0213039,
author = {Toueg, Sam and Babao\u{g}lu, \"{O}zalp},
title = {On the Optimum Checkpoint Selection Problem},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213039},
doi = {10.1137/0213039},
journal = {SIAM J. Comput.},
month = jul,
pages = {630–649},
numpages = {20}
}

@article{10.1137/0213038,
author = {Hopcroft, John and Joseph, Deborah and Whitesides, Sue},
title = {Movement Problems for 2-Dimensional Linkages},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213038},
doi = {10.1137/0213038},
journal = {SIAM J. Comput.},
month = jul,
pages = {610–629},
numpages = {20}
}

@article{10.1137/0213037,
author = {Baker, B S. and Coffman, E G.},
title = {Insertion and Compaction Algorithms in Sequentially Allocated Storage},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213037},
doi = {10.1137/0213037},
journal = {SIAM J. Comput.},
month = jul,
pages = {600–609},
numpages = {10}
}

@article{10.1137/0213036,
author = {Tsin, Yung H. and Chin, Francis Y.},
title = {Efficient Parallel Algorithms for a Class of Graph Theoretic Problems},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213036},
doi = {10.1137/0213036},
journal = {SIAM J. Comput.},
month = jul,
pages = {580–599},
numpages = {20}
}

@article{10.1137/0213035,
author = {Tarjan, Robert E. and Yannakakis, Mihalis},
title = {Simple Linear-Time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs, and Selectively Reduce Acyclic Hypergraphs},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213035},
doi = {10.1137/0213035},
journal = {SIAM J. Comput.},
month = jul,
pages = {566–579},
numpages = {14}
}

@article{10.1137/0213034,
author = {Melhem, Rami G. and Rheinboldt, Werner C.},
title = {A Mathematical Model for the Verification of Systolic Networks},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213034},
doi = {10.1137/0213034},
journal = {SIAM J. Comput.},
month = jul,
pages = {541–565},
numpages = {25}
}

@article{10.1137/0213032,
author = {Rosenkrantz, D J. and Stearns, R E. and Lewis, P M.},
title = {Consistency and Serializability in Concurrent Database Systems},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213032},
doi = {10.1137/0213032},
journal = {SIAM J. Comput.},
month = jul,
pages = {508–530},
numpages = {23}
}

@article{10.1137/0213031,
author = {Chazelle, Bernard},
title = {Convex Partitions of Polyhedra:  A Lower Bound and Worst-Case Optimal Algorithm},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213031},
doi = {10.1137/0213031},
journal = {SIAM J. Comput.},
month = jul,
pages = {488–507},
numpages = {20}
}

@article{10.1137/0213030,
author = {Book, Ronald V. and Long, Timothy J. and Selman, Alan L.},
title = {Quantitative Relativizations of Complexity Classes},
year = {1984},
issue_date = {August 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213030},
doi = {10.1137/0213030},
journal = {SIAM J. Comput.},
month = jul,
pages = {461–487},
numpages = {27}
}

@article{10.1137/0213055,
author = {Arnon, Dennis S. and Collins, George E. and McCallum, Scott},
title = {Cylindrical Algebraic Decomposition II:  An Adjacency Algorithm for the Plane},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213055},
doi = {10.1137/0213055},
journal = {SIAM J. Comput.},
month = nov,
pages = {878–889},
numpages = {12}
}

@article{10.1137/0213054,
author = {Arnon, Dennis S. and Collins, George E. and McCallum, Scott},
title = {Cylindrical Algebraic Decomposition I:  The Basic Algorithm},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213054},
doi = {10.1137/0213054},
journal = {SIAM J. Comput.},
month = nov,
pages = {865–877},
numpages = {13}
}

@article{10.1137/0213053,
author = {Blum, Manuel and Micali, Silvio},
title = {How to Generate Cryptographically Strong Sequences of Pseudo-Random Bits},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213053},
doi = {10.1137/0213053},
journal = {SIAM J. Comput.},
month = nov,
pages = {850–864},
numpages = {15}
}

@article{10.1137/0213052,
author = {Ja'Ja', J. and Kumar, V. K. P. and Simon, J.},
title = {Information Transfer under Different Sets of Protocols},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213052},
doi = {10.1137/0213052},
journal = {SIAM J. Comput.},
month = nov,
pages = {840–849},
numpages = {10}
}

@article{10.1137/0213051,
author = {Sherman, R and Pnueli, A and Harel, D},
title = {Is the Interesting Part of Process Logic Uninteresting? A Translation from PL to PDL},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213051},
doi = {10.1137/0213051},
journal = {SIAM J. Comput.},
month = nov,
pages = {825–839},
numpages = {15}
}

@article{10.1137/0213050,
author = {von zur Gathen, Joachim},
title = {Parallel Algorithms for Algebraic Problems},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213050},
doi = {10.1137/0213050},
journal = {SIAM J. Comput.},
month = nov,
pages = {802–824},
numpages = {23}
}

@article{10.1137/0213048,
author = {Gallier, Jean H.},
title = {N-Rational Algebras II.  Varieties and Logic of Inequalities},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213048},
doi = {10.1137/0213048},
journal = {SIAM J. Comput.},
month = nov,
pages = {776–794},
numpages = {19}
}

@article{10.1137/0213046,
author = {Barz, H W.},
title = {The Power of Synchronization Mechanisms},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213046},
doi = {10.1137/0213046},
journal = {SIAM J. Comput.},
month = nov,
pages = {726–749},
numpages = {24}
}

@article{10.1137/0213045,
author = {Heller, Hans},
title = {On Relativized Polynomial and Exponential Computations},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213045},
doi = {10.1137/0213045},
journal = {SIAM J. Comput.},
month = nov,
pages = {717–725},
numpages = {9}
}

@article{10.1137/0213044,
author = {Dobson, Gregory},
title = {Scheduling Independent Tasks on Uniform Processors},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213044},
doi = {10.1137/0213044},
journal = {SIAM J. Comput.},
month = nov,
pages = {705–716},
numpages = {12}
}

@article{10.1137/0213043,
author = {Lai, Ten-Hwang and Sahni, Sartaj},
title = {Preemptive Scheduling of a Multiprocessor System with Memories to Minimize Maximum Lateness},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213043},
doi = {10.1137/0213043},
journal = {SIAM J. Comput.},
month = nov,
pages = {690–704},
numpages = {15}
}

@article{10.1137/0213042,
author = {Blass, Andreas and Gurevich, Yuri},
title = {Equivalence Relations, Invariants, and Normal Forms},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213042},
doi = {10.1137/0213042},
journal = {SIAM J. Comput.},
month = nov,
pages = {682–689},
numpages = {8}
}

@article{10.1137/0213041,
author = {Heyman, D P. and Tsur, S},
title = {Disk Performance in a Transaction-Oriented System},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {13},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0213041},
doi = {10.1137/0213041},
journal = {SIAM J. Comput.},
month = nov,
pages = {669–681},
numpages = {13}
}

@article{10.1137/0214019,
author = {Willard, Dan E.},
title = {New Data Structures for Orthogonal Range Queries},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214019},
doi = {10.1137/0214019},
journal = {SIAM J. Comput.},
month = feb,
pages = {232–253},
numpages = {22}
}

@article{10.1137/0214018,
author = {Hsu, Wen-Lian},
title = {Maximum Weight Clique Algorithms for Circular-Arc Graphs and Circle Graphs},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214018},
doi = {10.1137/0214018},
journal = {SIAM J. Comput.},
month = feb,
pages = {224–231},
numpages = {8}
}

@article{10.1137/0214017,
author = {Chiba, Norishige and Nishizeki, Takao},
title = {Arboricity and Subgraph Listing Algorithms},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214017},
doi = {10.1137/0214017},
journal = {SIAM J. Comput.},
month = feb,
pages = {210–223},
numpages = {14}
}

@article{10.1137/0214016,
author = {Lagarias, J. C.},
title = {The Computational Complexity of Simultaneous Diophantine Approximation Problems},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214016},
doi = {10.1137/0214016},
journal = {SIAM J. Comput.},
month = feb,
pages = {196–209},
numpages = {14}
}

@article{10.1137/0214013,
author = {Chung, Moon-Jung and Makedon, Fillia and Sudborough, Ivan H. and Turner, Jonathan},
title = {Polynomial Time Algorithms for the Min Cut Problem on Degree Restricted Trees},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214013},
doi = {10.1137/0214013},
journal = {SIAM J. Comput.},
month = feb,
pages = {158–177},
numpages = {20}
}

@article{10.1137/0214012,
author = {Balc\'{a}zar, Jos\'{e} L.},
title = {Simplicity, Relativizations and Nondeterminism},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214012},
doi = {10.1137/0214012},
journal = {SIAM J. Comput.},
month = feb,
pages = {148–157},
numpages = {10}
}

@article{10.1137/0214011,
author = {Boyce, James E. and Dobkin, David P. and Drysdale, Robert L. and Guibas, Leo J.},
title = {Finding Extremal Polygons},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214011},
doi = {10.1137/0214011},
journal = {SIAM J. Comput.},
month = feb,
pages = {134–147},
numpages = {14}
}

@article{10.1137/0214010,
author = {Yao, Andrew C.},
title = {On the Expected Performance of Path Compression Algorithms},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214010},
doi = {10.1137/0214010},
journal = {SIAM J. Comput.},
month = feb,
pages = {129–133},
numpages = {5}
}

@article{10.1137/0214008,
author = {Kurtz, Stuart A.},
title = {Sparse Sets in NP-P: Relativizations},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214008},
doi = {10.1137/0214008},
journal = {SIAM J. Comput.},
month = feb,
pages = {113–119},
numpages = {7}
}

@article{10.1137/0214007,
author = {Fiduccia, Charles M.},
title = {An Efficient Formula for Linear Recurrences},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214007},
doi = {10.1137/0214007},
journal = {SIAM J. Comput.},
month = feb,
pages = {106–112},
numpages = {7}
}

@article{10.1137/0214004,
author = {Kanellakis, Paris C. and Papadimitriou, Christos H.},
title = {The Complexity of Distributed Concurrency Control},
year = {1985},
issue_date = {Feb. 1985},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {14},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0214004},
doi = {10.1137/0214004},
journal = {SIAM J. Comput.},
month = feb,
pages = {52–74},
numpages = {23}
}

@article{10.1137/0215022,
author = {Chazelle, B and Drysdale, R L and Lee, D T},
title = {Computing the Largest Empty Rectangle},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215022},
doi = {10.1137/0215022},
journal = {SIAM J. Comput.},
month = feb,
pages = {300–315},
numpages = {16}
}

@article{10.1137/0215021,
author = {Kirkpatrick, David G and Seidel, Raimund},
title = {The Ultimate Planar Convex Hull Algorithm},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215021},
doi = {10.1137/0215021},
journal = {SIAM J. Comput.},
month = feb,
pages = {287–299},
numpages = {13}
}

@article{10.1137/0215020,
author = {Levin, Leonid A},
title = {Average Case Complete Problems},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215020},
doi = {10.1137/0215020},
journal = {SIAM J. Comput.},
month = feb,
pages = {285–286},
numpages = {2}
}

@article{10.1137/0215018,
author = {Cabay, Stanley and Choi, Dong Koo},
title = {Algebraic Computations of Scaled Pade´ Fractions},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215018},
doi = {10.1137/0215018},
journal = {SIAM J. Comput.},
month = feb,
pages = {243–270},
numpages = {28}
}

@article{10.1137/0215017,
author = {Reif, John H},
title = {Logarithmic Depth Circuits for Algebraic Functions},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215017},
doi = {10.1137/0215017},
journal = {SIAM J. Comput.},
month = feb,
pages = {231–242},
numpages = {12}
}

@article{10.1137/0215016,
author = {Friesen, D K and Langston, M A},
title = {Variable Sized Bin Packing},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215016},
doi = {10.1137/0215016},
journal = {SIAM J. Comput.},
month = feb,
pages = {222–230},
numpages = {9}
}

@article{10.1137/0215015,
author = {Etzion, T and Lempel, A},
title = {An Efficient Algorithm for Generating Linear Transformations in a Shuffle Exchange Network},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215015},
doi = {10.1137/0215015},
journal = {SIAM J. Comput.},
month = feb,
pages = {216–221},
numpages = {6}
}

@article{10.1137/0215014,
author = {Sharir, Micha and Schorr, Amir},
title = {On Shortest Paths in Polyhedral Spaces},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215014},
doi = {10.1137/0215014},
journal = {SIAM J. Comput.},
month = feb,
pages = {193–215},
numpages = {23}
}

@article{10.1137/0215013,
author = {Coppersmith, D and Klawe, M M and Pippenger, N J},
title = {Alphabetic Minimax Trees of Degree Atmost <i>t</i>},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215013},
doi = {10.1137/0215013},
journal = {SIAM J. Comput.},
month = feb,
pages = {189–192},
numpages = {4}
}

@article{10.1137/0215012,
author = {Baker, Brenda S},
title = {A Provably Good Algorithm for the Two Module Routing Problem},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215012},
doi = {10.1137/0215012},
journal = {SIAM J. Comput.},
month = feb,
pages = {162–188},
numpages = {27}
}

@article{10.1137/0215011,
author = {Shub, M and Smale, S},
title = {<i>Computational Complexity</i>: On the Geometry of Polynomials and a Theory of Cost: II},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215011},
doi = {10.1137/0215011},
journal = {SIAM J. Comput.},
month = feb,
pages = {145–161},
numpages = {17}
}

@article{10.1137/0215010,
author = {Chin, Francis and Ramarao, K V S},
title = {Optimal Termination Protocols for Network Partitioning},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215010},
doi = {10.1137/0215010},
journal = {SIAM J. Comput.},
month = feb,
pages = {131–144},
numpages = {14}
}

@article{10.1137/0215009,
author = {Galil, Zvi and Micali, Silvio and Gabow, Harold},
title = {An <i>O</i>(EV Log V) Algorithm for Finding a Maximal Weighted Matching in General Graphs},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215009},
doi = {10.1137/0215009},
journal = {SIAM J. Comput.},
month = feb,
pages = {120–130},
numpages = {11}
}

@article{10.1137/0215008,
author = {Meyer auf der Heide, Friedhelm},
title = {Efficient Simulations among Several Models of Parallel Computers},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215008},
doi = {10.1137/0215008},
journal = {SIAM J. Comput.},
month = feb,
pages = {106–119},
numpages = {14}
}

@article{10.1137/0215007,
author = {Apostolico, Alberto and Giancarlo, Raffaele},
title = {The Boyer Moore Galil String Searching Strategies Revisited},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215007},
doi = {10.1137/0215007},
journal = {SIAM J. Comput.},
month = feb,
pages = {98–105},
numpages = {8}
}

@article{10.1137/0215006,
author = {Cook, Stephen and Dwork, Cynthia and Reischuk, Rudger},
title = {Upper and Lower Time Bounds for Parallel Random Access Machines without Simultaneous Writes},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215006},
doi = {10.1137/0215006},
journal = {SIAM J. Comput.},
month = feb,
pages = {87–97},
numpages = {11}
}

@article{10.1137/0215005,
author = {Englfriet, Joost},
title = {The Complexity of Languages Generated by Attribute Grammars},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215005},
doi = {10.1137/0215005},
journal = {SIAM J. Comput.},
month = feb,
pages = {70–86},
numpages = {17}
}

@article{10.1137/0215004,
author = {Sleator, Daniel Dominic and Tarjan, Robert Endre},
title = {Self Adjusting Heaps},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215004},
doi = {10.1137/0215004},
journal = {SIAM J. Comput.},
month = feb,
pages = {52–69},
numpages = {18}
}

@article{10.1137/0215003,
author = {O'Rourke, Joseph},
title = {The Signature of a Plane Curve},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215003},
doi = {10.1137/0215003},
journal = {SIAM J. Comput.},
month = feb,
pages = {34–51},
numpages = {18}
}

@article{10.1137/0215002,
author = {Mehlhorn, Kurt and Tsakalidis, Athanasios},
title = {An Amortized Analysis of Insertions into AVL Trees},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215002},
doi = {10.1137/0215002},
journal = {SIAM J. Comput.},
month = feb,
pages = {22–33},
numpages = {12}
}

@article{10.1137/0215001,
author = {Cherry, G W},
title = {Integration in Finite Terms with Special Functions: The Logarithmic Integral},
year = {1986},
issue_date = {Feb. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215001},
doi = {10.1137/0215001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–21},
numpages = {21}
}

@article{10.1137/0215045,
author = {Feigenbaum, Joan and Sch\"{a}ffer, Alejandro A},
title = {Recognizing Composite Graphs is Equivalent to Testing Graph Isomorphism},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215045},
doi = {10.1137/0215045},
journal = {SIAM J. Comput.},
month = may,
pages = {619–627},
numpages = {9}
}

@article{10.1137/0215044,
author = {Berman, Francine and Bock, Mary Ellen and Dittert, Eric and O'Donnell, Michael J},
title = {Collections of Functions for Perfect Hashing},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215044},
doi = {10.1137/0215044},
journal = {SIAM J. Comput.},
month = may,
pages = {604–618},
numpages = {15}
}

@article{10.1137/0215043,
author = {Johnson, Rodney W and McLoughlin, Aileen M},
title = {Noncomutative Bilinear Algorithms for 3x3 Matrix Multiplication},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215043},
doi = {10.1137/0215043},
journal = {SIAM J. Comput.},
month = may,
pages = {595–603},
numpages = {9}
}

@article{10.1137/0215042,
author = {Huynh, Dung T},
title = {The Complexity of the Membership Problem for Two Subclasses of Polynomial Ideal s},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215042},
doi = {10.1137/0215042},
journal = {SIAM J. Comput.},
month = may,
pages = {581–594},
numpages = {14}
}

@article{10.1137/0215041,
author = {Turner, Jonathan S},
title = {On the Probable Performance of Heuristics for Bandwidth Minimization},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215041},
doi = {10.1137/0215041},
journal = {SIAM J. Comput.},
month = may,
pages = {561–580},
numpages = {20}
}

@article{10.1137/0215040,
author = {Borodin, Allan and Dolev, Danny and Fich, Faith E and Paul, Wolfgang},
title = {Bounds for Width Two Branching Programs},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215040},
doi = {10.1137/0215040},
journal = {SIAM J. Comput.},
month = may,
pages = {549–560},
numpages = {12}
}

@article{10.1137/0215039,
author = {Richmond, Bruce and Odlyzko, Andrew and McKay, Brendan D},
title = {Constant Time Generation of Free Trees},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215039},
doi = {10.1137/0215039},
journal = {SIAM J. Comput.},
month = may,
pages = {540–548},
numpages = {9}
}

@article{10.1137/0215038,
author = {Frieze, A M},
title = {On the Lagarias-Odlyzko Algorithm for the Subset Sum Problem},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215038},
doi = {10.1137/0215038},
journal = {SIAM J. Comput.},
month = may,
pages = {536–539},
numpages = {4}
}

@article{10.1137/0215037,
author = {Valiant, L G},
title = {Negation is Powerless for Boolean Slice Functions},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215037},
doi = {10.1137/0215037},
journal = {SIAM J. Comput.},
month = may,
pages = {531–535},
numpages = {5}
}

@article{10.1137/0215036,
author = {Langnhop, Carl E and Wright, William E},
title = {Probablitiec Related to Father Son Distances in Binary Search Trees},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215036},
doi = {10.1137/0215036},
journal = {SIAM J. Comput.},
month = may,
pages = {520–530},
numpages = {11}
}

@article{10.1137/0215035,
author = {Geske, John and Grollmann, Joachim},
title = {Relativizations of Unambiguous and Random Polynomial Time Classes},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215035},
doi = {10.1137/0215035},
journal = {SIAM J. Comput.},
month = may,
pages = {511–519},
numpages = {9}
}

@article{10.1137/0215034,
author = {Matsumoto, Kazuhiko and Nishizeki, Takao and Saito, Nobuji},
title = {Planar Multicommodity Flows, Maximum Matchings and Negative Cycles},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215034},
doi = {10.1137/0215034},
journal = {SIAM J. Comput.},
month = may,
pages = {495–510},
numpages = {16}
}

@article{10.1137/0215033,
author = {Imai, Hiroshi and Asano, Takao},
title = {Efficient Algorithms for Geometric Graph Search Problems},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215033},
doi = {10.1137/0215033},
journal = {SIAM J. Comput.},
month = may,
pages = {478–494},
numpages = {17}
}

@article{10.1137/0215032,
author = {Willard, Dan E},
title = {Log-Logarithmic Selection Resolution Protocols in a Multiple Access Channel},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215032},
doi = {10.1137/0215032},
journal = {SIAM J. Comput.},
month = may,
pages = {468–477},
numpages = {10}
}

@article{10.1137/0215031,
author = {Maass, Wolfgang},
title = {On the Complexity of Nonconvex Covering},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215031},
doi = {10.1137/0215031},
journal = {SIAM J. Comput.},
month = may,
pages = {453–467},
numpages = {15}
}

@article{10.1137/0215030,
author = {von zur Gathen, Joachim},
title = {Representations and Parallel Computations for Rational Functions},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215030},
doi = {10.1137/0215030},
journal = {SIAM J. Comput.},
month = may,
pages = {432–452},
numpages = {21}
}

@article{10.1137/0215029,
author = {Ausiello, G and D'Atri, A and Sacc\'{a}, D},
title = {Minimal Representation of Directed Hypergraphs},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215029},
doi = {10.1137/0215029},
journal = {SIAM J. Comput.},
month = may,
pages = {418–431},
numpages = {14}
}

@article{10.1137/0215028,
author = {Bruno, John L and Downey, Peter J},
title = {Probabilistic Bounds on the Performance of List Scheduling},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215028},
doi = {10.1137/0215028},
journal = {SIAM J. Comput.},
month = may,
pages = {409–417},
numpages = {9}
}

@article{10.1137/0215027,
author = {Orponen, Pekka and Russo, David A and Sch\"{o}ning, Uwe},
title = {Optimal Approximations and Polynomially Levelable Sets},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215027},
doi = {10.1137/0215027},
journal = {SIAM J. Comput.},
month = may,
pages = {399–408},
numpages = {10}
}

@article{10.1137/0215026,
author = {Blum, Lenore and Shub, Michael},
title = {Evaluating Rational Functions: Infinite Precision is Finite Cost and Tractable on Average},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215026},
doi = {10.1137/0215026},
journal = {SIAM J. Comput.},
month = may,
pages = {384–398},
numpages = {15}
}

@article{10.1137/0215025,
author = {Blum, L and Blum, M and Shub, M},
title = {A Simple Unpredictable Pseudo Random Number Generator},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215025},
doi = {10.1137/0215025},
journal = {SIAM J. Comput.},
month = may,
pages = {364–383},
numpages = {20}
}

@article{10.1137/0215024,
author = {Edelsbrunner, H and O'Rouke, J and Seidel, R},
title = {Constructing Arrangements of Lines and Hyperplanes with Applications},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215024},
doi = {10.1137/0215024},
journal = {SIAM J. Comput.},
month = may,
pages = {341–363},
numpages = {23}
}

@article{10.1137/0215023,
author = {Edelsbrunner, Herbert and Guibas, Lionidas J and Stolfi, Jorge},
title = {Optimal Point Location in a Monotone Subdivision},
year = {1986},
issue_date = {May 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215023},
doi = {10.1137/0215023},
journal = {SIAM J. Comput.},
month = may,
pages = {317–340},
numpages = {24}
}

@article{10.1137/0215062,
author = {Kingston, Jeffrey H},
title = {Analysis of Henriksen's Algorithm for the Simulation Event Set},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215062},
doi = {10.1137/0215062},
journal = {SIAM J. Comput.},
month = aug,
pages = {887–902},
numpages = {16}
}

@article{10.1137/0215061,
author = {Hull, Richard},
title = {Relative Information Capacity of Simple Relational Database Schemata},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215061},
doi = {10.1137/0215061},
journal = {SIAM J. Comput.},
month = aug,
pages = {856–886},
numpages = {31}
}

@article{10.1137/0215060,
author = {Arazi, Benjamin},
title = {A Binary Search with a Parallel Recovery of the Bits},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215060},
doi = {10.1137/0215060},
journal = {SIAM J. Comput.},
month = aug,
pages = {851–855},
numpages = {5}
}

@article{10.1137/0215059,
author = {Hunt, H B and Rosenkrantz, D J},
title = {Recursion Schemes and Recursive Programs Are Exponentially Hard to Analyze},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215059},
doi = {10.1137/0215059},
journal = {SIAM J. Comput.},
month = aug,
pages = {831–850},
numpages = {20}
}

@article{10.1137/0215058,
author = {Smith, Justin R},
title = {Parallel Algorithms for Depth-First Searches I. Planar Graphs},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215058},
doi = {10.1137/0215058},
journal = {SIAM J. Comput.},
month = aug,
pages = {814–830},
numpages = {17}
}

@article{10.1137/0215057,
author = {Thomson Leighton, Frank and Rosenberg, Arnold L},
title = {Three Dimensional Circuit Layouts},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215057},
doi = {10.1137/0215057},
journal = {SIAM J. Comput.},
month = aug,
pages = {793–813},
numpages = {21}
}

@article{10.1137/0215056,
author = {Otto, Friedrich},
title = {Church-Rosser Thue Systems That Present Free Monoids},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215056},
doi = {10.1137/0215056},
journal = {SIAM J. Comput.},
month = aug,
pages = {786–792},
numpages = {7}
}

@article{10.1137/0215055,
author = {Hopcroft, J E and Wolfong, G T},
title = {Reducing Multiple Object Motion Planning to Graph Searching},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215055},
doi = {10.1137/0215055},
journal = {SIAM J. Comput.},
month = aug,
pages = {768–785},
numpages = {18}
}

@article{10.1137/0215054,
author = {Flajolet, Philippe and Sedgewick, Robert},
title = {Digital Search Trees Revisited},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215054},
doi = {10.1137/0215054},
journal = {SIAM J. Comput.},
month = aug,
pages = {748–767},
numpages = {20}
}

@article{10.1137/0215053,
author = {Balc\'{a}zar, Jos\'{e} and Book, Ronald V and Sch\"{o}ning, Uwe},
title = {Sparse Sets Lowness and Highness},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215053},
doi = {10.1137/0215053},
journal = {SIAM J. Comput.},
month = aug,
pages = {739–747},
numpages = {9}
}

@article{10.1137/0215052,
author = {Dyer, M E},
title = {On a Multidimensional Search Technique and Its Application to the Euclidean One Centre Problem},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215052},
doi = {10.1137/0215052},
journal = {SIAM J. Comput.},
month = aug,
pages = {725–738},
numpages = {14}
}

@article{10.1137/0215051,
author = {Chazelle, Bernard},
title = {Filtering Search: A New Approach to Query Answering},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215051},
doi = {10.1137/0215051},
journal = {SIAM J. Comput.},
month = aug,
pages = {703–724},
numpages = {22}
}

@article{10.1137/0215050,
author = {Scott Provan, J},
title = {The Complexity of Reliability Computations in Planar and Acyclic Graphs},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215050},
doi = {10.1137/0215050},
journal = {SIAM J. Comput.},
month = aug,
pages = {694–702},
numpages = {9}
}

@article{10.1137/0215049,
author = {Citrini, Claudio and Crespi Reghizzi, Stefano and Mandrioli, Dino},
title = {On Deterministic Multi Pass Analysis},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215049},
doi = {10.1137/0215049},
journal = {SIAM J. Comput.},
month = aug,
pages = {668–693},
numpages = {26}
}

@article{10.1137/0215048,
author = {Irving, Robert W and Leather, Paul},
title = {The Complexity of Counting Stable Marriages},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215048},
doi = {10.1137/0215048},
journal = {SIAM J. Comput.},
month = aug,
pages = {655–667},
numpages = {13}
}

@article{10.1137/0215047,
author = {Friedman, Joel},
title = {Constructing <i>O</i>(<i>n</i>Log<i>n</i>) Size Monotone Formulae for the <i>k</i>Th Threshold Function of <i>n</i> Boolean Variables},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215047},
doi = {10.1137/0215047},
journal = {SIAM J. Comput.},
month = aug,
pages = {641–654},
numpages = {14}
}

@article{10.1137/0215046,
author = {Flajolet, P. and Prodinger, H.},
title = {Register Allocation for Unary Binary Trees},
year = {1986},
issue_date = {August 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215046},
doi = {10.1137/0215046},
journal = {SIAM J. Comput.},
month = aug,
pages = {629–640},
numpages = {12}
}

@article{10.1137/0215084,
author = {Jouannaud, Jean-Pierre and Kirchner, H\'{e}l\`{e}ne},
title = {Completion of a Set of Rules modulo a Set of Equations},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215084},
doi = {10.1137/0215084},
journal = {SIAM J. Comput.},
month = nov,
pages = {1155–1194},
numpages = {40}
}

@article{10.1137/0215083,
author = {Bach, Eric and Miller, Gary and Shallit, Jeffrey},
title = {Sums of Divisors, Perfect Numbers and Factoring},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215083},
doi = {10.1137/0215083},
journal = {SIAM J. Comput.},
month = nov,
pages = {1143–1154},
numpages = {12}
}

@article{10.1137/0215082,
author = {Manber, Udi},
title = {On Maintaining Dynamic Information in a Concurrent Environment},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215082},
doi = {10.1137/0215082},
journal = {SIAM J. Comput.},
month = nov,
pages = {1130–1142},
numpages = {13}
}

@article{10.1137/0215081,
author = {Kawaguchi, Tsuyoshi and Kyan, Seiki},
title = {Worst Case Bound of an LRF Schedule for the Mean Weighted Flow-Time Problem},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215081},
doi = {10.1137/0215081},
journal = {SIAM J. Comput.},
month = nov,
pages = {1119–1129},
numpages = {11}
}

@article{10.1137/0215080,
author = {Chao, Ming-Te and Franco, John},
title = {Probabilistic Analysis of Two Heuristics for the 3-Satisfiability Problem},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215080},
doi = {10.1137/0215080},
journal = {SIAM J. Comput.},
month = nov,
pages = {1106–1118},
numpages = {13}
}

@article{10.1137/0215079,
author = {Huynh, Dung T},
title = {Some Observations about the Randomness of Hard Problems},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215079},
doi = {10.1137/0215079},
journal = {SIAM J. Comput.},
month = nov,
pages = {1101–1105},
numpages = {5}
}

@article{10.1137/0215078,
author = {Gaver, Donald P and Jacobs, Patricia A},
title = {Processor-Shared Time-Sharing Models in Heavy Traffic},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215078},
doi = {10.1137/0215078},
journal = {SIAM J. Comput.},
month = nov,
pages = {1085–1100},
numpages = {16}
}

@article{10.1137/0215077,
author = {Faigle, U and Lov\'{a}sz, L and Schrader, R and Tur\'{a}n, Gy},
title = {Searching in Trees, Series-Parallel and Interval Orders},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215077},
doi = {10.1137/0215077},
journal = {SIAM J. Comput.},
month = nov,
pages = {1075–1084},
numpages = {10}
}

@article{10.1137/0215076,
author = {Hirschberg, D S and Larmore, L L},
title = {Average Case Analysis of Marking Algorithms},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215076},
doi = {10.1137/0215076},
journal = {SIAM J. Comput.},
month = nov,
pages = {1069–1074},
numpages = {6}
}

@article{10.1137/0215075,
author = {Balas, Egon and Yu, Chang Sung},
title = {Finding a Maximum Clique in an Arbitrary Graph},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215075},
doi = {10.1137/0215075},
journal = {SIAM J. Comput.},
month = nov,
pages = {1054–1068},
numpages = {15}
}

@article{10.1137/0215074,
author = {Luby, Michael},
title = {A Simple Parallel Algorithm for the Maximal Independent Set Problem},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215074},
doi = {10.1137/0215074},
journal = {SIAM J. Comput.},
month = nov,
pages = {1036–1055},
numpages = {20}
}

@article{10.1137/0215073,
author = {Li, Liwu},
title = {Ranking and Unranking of AVL-Trees},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215073},
doi = {10.1137/0215073},
journal = {SIAM J. Comput.},
month = nov,
pages = {1025–1035},
numpages = {11}
}

@article{10.1137/0215072,
author = {Blum, Norbert},
title = {On the Single-Operation Worst-Case Time Complexity of the Disjoint Set Union Problem},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215072},
doi = {10.1137/0215072},
journal = {SIAM J. Comput.},
month = nov,
pages = {1021–1024},
numpages = {4}
}

@article{10.1137/0215071,
author = {Ja'Ja, Joseph and Takche, Jean},
title = {On the Validity of the Direct Sum Conjecture},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215071},
doi = {10.1137/0215071},
journal = {SIAM J. Comput.},
month = nov,
pages = {1004–1020},
numpages = {17}
}

@article{10.1137/0215070,
author = {Beame, Paul W and Cook, Stephen A and Hoover, H James},
title = {Log Depth Circuits for Division and Related Problems},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215070},
doi = {10.1137/0215070},
journal = {SIAM J. Comput.},
month = nov,
pages = {994–1003},
numpages = {10}
}

@article{10.1137/0215069,
author = {Prill, David},
title = {On Approximations and Incidence in Cylindrical Algebraic Decompositions},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215069},
doi = {10.1137/0215069},
journal = {SIAM J. Comput.},
month = nov,
pages = {972–993},
numpages = {22}
}

@article{10.1137/0215068,
author = {Gonnet, Gaston H and Munro, J Ian},
title = {Heaps on Heaps},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215068},
doi = {10.1137/0215068},
journal = {SIAM J. Comput.},
month = nov,
pages = {964–971},
numpages = {8}
}

@article{10.1137/0215067,
author = {Ambos-Spies, Klaus},
title = {An Inhomogeneity in the Structure of Karp Degrees},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215067},
doi = {10.1137/0215067},
journal = {SIAM J. Comput.},
month = nov,
pages = {958–963},
numpages = {6}
}

@article{10.1137/0215066,
author = {Cunningham, William H},
title = {Improved Bounds for Matroid Partition and Intersection Algorithms},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215066},
doi = {10.1137/0215066},
journal = {SIAM J. Comput.},
month = nov,
pages = {948–957},
numpages = {10}
}

@article{10.1137/0215065,
author = {Pang, King F and Gamal, Abbas El},
title = {Communication Complexity of Computing the Hamming Distance},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215065},
doi = {10.1137/0215065},
journal = {SIAM J. Comput.},
month = nov,
pages = {932–947},
numpages = {16}
}

@article{10.1137/0215064,
author = {Katz, Martin David and Volper, Dennis J},
title = {Data Structures for Retrieval on Square Grids},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215064},
doi = {10.1137/0215064},
journal = {SIAM J. Comput.},
month = nov,
pages = {919–931},
numpages = {13}
}

@article{10.1137/0215063,
author = {Davenport, J H},
title = {The Risch Differential Equation Problem},
year = {1986},
issue_date = {Nov. 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {15},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0215063},
doi = {10.1137/0215063},
journal = {SIAM J. Comput.},
month = nov,
pages = {903–918},
numpages = {16}
}

@article{10.1137/0216017,
author = {Soulie, Francoise F. and Weisbuch, G\'{e}rard},
title = {Random Iterations of Threshold Networks and Associative Memory},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216017},
doi = {10.1137/0216017},
journal = {SIAM J. Comput.},
month = feb,
pages = {203–220},
numpages = {18}
}

@article{10.1137/0216016,
author = {Maass, Wolfgang and Schorr, Amir},
title = {Speed-up of Turing Machines with One Work Tape and a Two-Way Input Tape},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216016},
doi = {10.1137/0216016},
journal = {SIAM J. Comput.},
month = feb,
pages = {195–202},
numpages = {8}
}

@article{10.1137/0216015,
author = {Mosses, Peter D. and Plotkin, Gordon D.},
title = {On Proving Limiting Completeness},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216015},
doi = {10.1137/0216015},
journal = {SIAM J. Comput.},
month = feb,
pages = {179–194},
numpages = {16}
}

@article{10.1137/0216014,
author = {Courcoubetis, C. A. and Reiman, M. I. and Simon, B.},
title = {Stability of a Queueing System with Concurrent Service and Locking},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216014},
doi = {10.1137/0216014},
journal = {SIAM J. Comput.},
month = feb,
pages = {169–178},
numpages = {10}
}

@article{10.1137/0216013,
author = {Choi, Hyeong-Ah and Hakimi, S. Louis},
title = {Scheduling File Transfers for Trees and Odd Cycles},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216013},
doi = {10.1137/0216013},
journal = {SIAM J. Comput.},
month = feb,
pages = {162–168},
numpages = {7}
}

@article{10.1137/0216012,
author = {Murgolo, Frank D.},
title = {An Efficient Approximation Scheme for Variable-Sized Bin Packing},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216012},
doi = {10.1137/0216012},
journal = {SIAM J. Comput.},
month = feb,
pages = {149–161},
numpages = {13}
}

@article{10.1137/0216011,
author = {Hunt, H. B. and Rosenkrantz, D. J. and Bloniarz, P. A.},
title = {On the Computational Complexity of Algebra on Lattices},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216011},
doi = {10.1137/0216011},
journal = {SIAM J. Comput.},
month = feb,
pages = {129–148},
numpages = {20}
}

@article{10.1137/0216010,
author = {Gusfield, Dan},
title = {Three Fast Algorithms for Four Problems in Stable Marriage},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216010},
doi = {10.1137/0216010},
journal = {SIAM J. Comput.},
month = feb,
pages = {111–128},
numpages = {18}
}

@article{10.1137/0216009,
author = {Jones, Douglas W.},
title = {A Note on Bottom-up Skew Heaps},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216009},
doi = {10.1137/0216009},
journal = {SIAM J. Comput.},
month = feb,
pages = {108–110},
numpages = {3}
}

@article{10.1137/0216008,
author = {Meyer auf der Heide, Friedhelm M. and Wigderson, Avi},
title = {The Complexity of Parallel Sorting},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216008},
doi = {10.1137/0216008},
journal = {SIAM J. Comput.},
month = feb,
pages = {100–107},
numpages = {8}
}

@article{10.1137/0216007,
author = {Borodin, A. and Fich, F. and Meyer auf der Heide, F. and Upfal, E. and Wigderson, A.},
title = {A Time-Space Tradeoff for Element Distinctness},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216007},
doi = {10.1137/0216007},
journal = {SIAM J. Comput.},
month = feb,
pages = {97–99},
numpages = {3}
}

@article{10.1137/0216006,
author = {Aurenhammer, F},
title = {Power Diagrams: Properties, Algorithms and Applications},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216006},
doi = {10.1137/0216006},
journal = {SIAM J. Comput.},
month = feb,
pages = {78–96},
numpages = {19}
}

@article{10.1137/0216005,
author = {Cole, Richard and Sharir, Micha and Yap, Chee K},
title = {On <i>k</i>-Hulls and Related Problems},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216005},
doi = {10.1137/0216005},
journal = {SIAM J. Comput.},
month = feb,
pages = {61–77},
numpages = {17}
}

@article{10.1137/0216004,
author = {Miller, Russ and Stout, Quentin},
title = {Data Movement Techniques for the Pyramid Computer},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216004},
doi = {10.1137/0216004},
journal = {SIAM J. Comput.},
month = feb,
pages = {38–60},
numpages = {23}
}

@article{10.1137/0216003,
author = {Schmueli, Oded and Itai, Alon},
title = {Complexity of View: Tree and Cyclic Schemas},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216003},
doi = {10.1137/0216003},
journal = {SIAM J. Comput.},
month = feb,
pages = {17–37},
numpages = {21}
}

@article{10.1137/0216002,
author = {Kannan, Ravindran and Miller, Gary and Rudolph, Larry},
title = {Sublinear Parallel Algorithm for Computing the Greatest Common Divisor of Two Integers},
year = {1987},
issue_date = {Feb. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216002},
doi = {10.1137/0216002},
journal = {SIAM J. Comput.},
month = feb,
pages = {7–16},
numpages = {10}
}

@article{10.1137/0216029,
author = {Hofri, Micha and Ross, Keith W.},
title = {On the Optimal Control of Two Queues with Server Setup Times and Its Analysis},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216029},
doi = {10.1137/0216029},
journal = {SIAM J. Comput.},
month = apr,
pages = {399–420},
numpages = {22}
}

@article{10.1137/0216028,
author = {Knessl, C. and Matkowsky, B. J. and Schuss, Z. and Tier, C.},
title = {Asymptotic Expansions for a Closed Multiple Access System},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216028},
doi = {10.1137/0216028},
journal = {SIAM J. Comput.},
month = apr,
pages = {378–398},
numpages = {21}
}

@article{10.1137/0216027,
author = {Ibarra, Oscar H. and Palis, Michael A.},
title = {On Efficient Simulations of Systolic Arrays by Random-Access Machines},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216027},
doi = {10.1137/0216027},
journal = {SIAM J. Comput.},
month = apr,
pages = {367–377},
numpages = {11}
}

@article{10.1137/0216026,
author = {Horton, J. D.},
title = {A Polynomial-Time Algorithm to Find the Shortest Cycle Basis of a Graph},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216026},
doi = {10.1137/0216026},
journal = {SIAM J. Comput.},
month = apr,
pages = {358–366},
numpages = {9}
}

@article{10.1137/0216025,
author = {Guessarian, Ir\`{e}ne and Meseguer, Jos\'{e}},
title = {On the Axiomatization of “If-Then-Else”},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216025},
doi = {10.1137/0216025},
journal = {SIAM J. Comput.},
month = apr,
pages = {332–357},
numpages = {26}
}

@article{10.1137/0216024,
author = {Asano, Takao},
title = {An Application of Duality to Edge-Deletion Problems},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216024},
doi = {10.1137/0216024},
journal = {SIAM J. Comput.},
month = apr,
pages = {312–331},
numpages = {20}
}

@article{10.1137/0216023,
author = {Lickteig, Thomas},
title = {The Computational Complexity of Division in Quadratic Extension Fields},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216023},
doi = {10.1137/0216023},
journal = {SIAM J. Comput.},
month = apr,
pages = {278–311},
numpages = {34}
}

@article{10.1137/0216022,
author = {Cai, Jin-yi and Meyer, Gabriele E.},
title = {Graph Minimal Uncolorability is D<sup>P</sup>-Complete},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216022},
doi = {10.1137/0216022},
journal = {SIAM J. Comput.},
month = apr,
pages = {259–277},
numpages = {19}
}

@article{10.1137/0216021,
author = {Bini, D. and Capovani, M.},
title = {Tensor Rank and Border Rank of Band Toeplitz Matrices},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216021},
doi = {10.1137/0216021},
journal = {SIAM J. Comput.},
month = apr,
pages = {252–258},
numpages = {7}
}

@article{10.1137/0216020,
author = {Gusfield, Dan and Martel, Charles and Fernandez-Baca, David},
title = {Fast Algorithms for Bipartite Network Flow},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216020},
doi = {10.1137/0216020},
journal = {SIAM J. Comput.},
month = apr,
pages = {237–251},
numpages = {15}
}

@article{10.1137/0216019,
author = {Korach, E. and Moran, S. and Zaks, S.},
title = {The Optimality of Distributive Constructions of Minimum Weight and Degree Restricted Spanning Trees in a Complete Network of Processors},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216019},
doi = {10.1137/0216019},
journal = {SIAM J. Comput.},
month = apr,
pages = {231–236},
numpages = {6}
}

@article{10.1137/0216018,
author = {Culik, Karel and Karhum\"{a}ki, Juhani},
title = {The Equivalence Problem for Single-Valued Two-Way Transducers (on NPDTOL Languages) is Decidable},
year = {1987},
issue_date = {April 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216018},
doi = {10.1137/0216018},
journal = {SIAM J. Comput.},
month = apr,
pages = {221–230},
numpages = {10}
}

@article{10.1137/0216040,
author = {Lenstra, Arjen K.},
title = {Factoring Multivariate Polynomials over Algebraic Number Fields},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216040},
doi = {10.1137/0216040},
journal = {SIAM J. Comput.},
month = jun,
pages = {591–598},
numpages = {8}
}

@article{10.1137/0216039,
author = {Hu, T. C. and Wachs, Michelle L.},
title = {Binary Search on a Tape},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216039},
doi = {10.1137/0216039},
journal = {SIAM J. Comput.},
month = jun,
pages = {573–590},
numpages = {18}
}

@article{10.1137/0216038,
author = {Sharir, Micha},
title = {On Shortest Paths amidst Convex Polyhedra},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216038},
doi = {10.1137/0216038},
journal = {SIAM J. Comput.},
month = jun,
pages = {561–572},
numpages = {12}
}

@article{10.1137/0216037,
author = {Friesen, Donald K.},
title = {Tighter Bounds for LPT Scheduling on Uniform Processors},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216037},
doi = {10.1137/0216037},
journal = {SIAM J. Comput.},
month = jun,
pages = {554–560},
numpages = {7}
}

@article{10.1137/0216036,
author = {Papadimitriou, Christos H. and Yannakakis, Mihalis},
title = {The Complexity of Reliable Concurrency Control},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216036},
doi = {10.1137/0216036},
journal = {SIAM J. Comput.},
month = jun,
pages = {538–553},
numpages = {16}
}

@article{10.1137/0216035,
author = {Vaishnavi, Vijay K.},
title = {Weighted Leaf AVL-Trees},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216035},
doi = {10.1137/0216035},
journal = {SIAM J. Comput.},
month = jun,
pages = {503–537},
numpages = {35}
}

@article{10.1137/0216034,
author = {Gurevich, Yuri and Shelah, Saharon},
title = {Expected Computation Time for Hamiltonian Path Problem},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216034},
doi = {10.1137/0216034},
journal = {SIAM J. Comput.},
month = jun,
pages = {486–502},
numpages = {17}
}

@article{10.1137/0216033,
author = {Mekler, Alan H. and Nelson, Evelyn M.},
title = {Equational Bases for If-Then-Else},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216033},
doi = {10.1137/0216033},
journal = {SIAM J. Comput.},
month = jun,
pages = {465–485},
numpages = {21}
}

@article{10.1137/0216032,
author = {Azar, Yossi and Vishkin, Uzi},
title = {Tight Comparison Bounds on the Complexity of Parallel Sorting},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216032},
doi = {10.1137/0216032},
journal = {SIAM J. Comput.},
month = jun,
pages = {458–464},
numpages = {7}
}

@article{10.1137/0216031,
author = {Toueg, Sam and Perry, Kenneth J. and Srikanth, T. K.},
title = {Fast Distributed Agreement},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216031},
doi = {10.1137/0216031},
journal = {SIAM J. Comput.},
month = jun,
pages = {445–457},
numpages = {13}
}

@article{10.1137/0216030,
author = {Tamassia, Roberto},
title = {On Embedding a Graph in the Grid with the Minimum Number of Bends},
year = {1987},
issue_date = {June 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {3},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216030},
doi = {10.1137/0216030},
journal = {SIAM J. Comput.},
month = jun,
pages = {421–444},
numpages = {24}
}

@article{10.1137/0216051,
author = {Immerman, Neil},
title = {Languages That Capture Complexity Classes},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216051},
doi = {10.1137/0216051},
journal = {SIAM J. Comput.},
month = aug,
pages = {760–778},
numpages = {19}
}

@article{10.1137/0216050,
author = {Helmbold, David and Mayr, Ernst},
title = {Two Processor Scheduling is in NC},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216050},
doi = {10.1137/0216050},
journal = {SIAM J. Comput.},
month = aug,
pages = {747–759},
numpages = {13}
}

@article{10.1137/0216049,
author = {Widmayer, P. and Wu, Y. F. and Wong, C. K.},
title = {On Some Distance Problems in Fixed Orientations},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216049},
doi = {10.1137/0216049},
journal = {SIAM J. Comput.},
month = aug,
pages = {728–746},
numpages = {19}
}

@article{10.1137/0216048,
author = {Wormald, Nicholas C.},
title = {Generating Random Unlabelled Graphs},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216048},
doi = {10.1137/0216048},
journal = {SIAM J. Comput.},
month = aug,
pages = {717–727},
numpages = {11}
}

@article{10.1137/0216047,
author = {Oommen, B. John and Hansen, E. R.},
title = {List Organizing Strategies Using Stochastic Move-to-Front and Stochastic Move-to-Rear Operations},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216047},
doi = {10.1137/0216047},
journal = {SIAM J. Comput.},
month = aug,
pages = {705–716},
numpages = {12}
}

@article{10.1137/0216046,
author = {Gonzalez, Teofilo F. and Lee, Sing-Ling},
title = {A 1.6 Approximation Algorithm for Routing Multiterminal Nets},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216046},
doi = {10.1137/0216046},
journal = {SIAM J. Comput.},
month = aug,
pages = {669–704},
numpages = {36}
}

@article{10.1137/0216045,
author = {Mitchell, Joseph S. B. and Mount, David M. and Papadimitriou, Christos H.},
title = {The Discrete Geodesic Problem},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216045},
doi = {10.1137/0216045},
journal = {SIAM J. Comput.},
month = aug,
pages = {647–668},
numpages = {22}
}

@article{10.1137/0216044,
author = {Papadimitriou, Christos H. and Ullman, Jeffrey D.},
title = {A Communication-Time Tradeoff},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216044},
doi = {10.1137/0216044},
journal = {SIAM J. Comput.},
month = aug,
pages = {639–646},
numpages = {8}
}

@article{10.1137/0216043,
author = {Hirschberg, D. S. and Larmore, L. L.},
title = {The Least Weight Subsequence Problem},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216043},
doi = {10.1137/0216043},
journal = {SIAM J. Comput.},
month = aug,
pages = {628–638},
numpages = {11}
}

@article{10.1137/0216042,
author = {Gasarch, William},
title = {Oracles for Deterministic versus Alternating Classes},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216042},
doi = {10.1137/0216042},
journal = {SIAM J. Comput.},
month = aug,
pages = {613–627},
numpages = {15}
}

@article{10.1137/0216041,
author = {Gusfield, Dan},
title = {Optimal Mixed Graph Augmentation},
year = {1987},
issue_date = {Aug. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {4},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216041},
doi = {10.1137/0216041},
journal = {SIAM J. Comput.},
month = aug,
pages = {599–612},
numpages = {14}
}

@article{10.1137/0216061,
author = {Becker, B. and Hotz, G.},
title = {On the Optimal Layout of Planar Graphs with Fixed Boundary},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216061},
doi = {10.1137/0216061},
journal = {SIAM J. Comput.},
month = oct,
pages = {946–972},
numpages = {27}
}

@article{10.1137/0216060,
author = {von zur Gathen, Joachim},
title = {Computing Powers in Parallel},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216060},
doi = {10.1137/0216060},
journal = {SIAM J. Comput.},
month = oct,
pages = {930–945},
numpages = {16}
}

@article{10.1137/0216059,
author = {Hunt, H. B. and Stearns, R. E.},
title = {Nonlinear Algebra and Optimization on Rings Are “Hard”},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216059},
doi = {10.1137/0216059},
journal = {SIAM J. Comput.},
month = oct,
pages = {910–929},
numpages = {20}
}

@article{10.1137/0216058,
author = {McKenzie, Pierre and Cook, Stephen A.},
title = {The Parallel Complexity of Abelian Permutation Group Problems},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216058},
doi = {10.1137/0216058},
journal = {SIAM J. Comput.},
month = oct,
pages = {880–909},
numpages = {30}
}

@article{10.1137/0216057,
author = {Lubiw, Anna},
title = {Doubly Lexical Orderings of Matrices},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216057},
doi = {10.1137/0216057},
journal = {SIAM J. Comput.},
month = oct,
pages = {854–879},
numpages = {26}
}

@article{10.1137/0216056,
author = {Kurtz, Stuart A.},
title = {A Note on Randomized Polynomial Time},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216056},
doi = {10.1137/0216056},
journal = {SIAM J. Comput.},
month = oct,
pages = {852–853},
numpages = {2}
}

@article{10.1137/0216055,
author = {Chan, Edward P. F. and Mendelzon, Alberto O.},
title = {Independent and Separable Database Schemes},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216055},
doi = {10.1137/0216055},
journal = {SIAM J. Comput.},
month = oct,
pages = {841–851},
numpages = {11}
}

@article{10.1137/0216054,
author = {Huang, Wenqi and Yu, Xiangdong},
title = {A DNF without Regular Shortest Consensus Path},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216054},
doi = {10.1137/0216054},
journal = {SIAM J. Comput.},
month = oct,
pages = {836–840},
numpages = {5}
}

@article{10.1137/0216053,
author = {Alt, Helmut and Hagerup, Torben and Mehlhorn, Kurt and Perparata, Franco P.},
title = {Deterministic Simulation of Idealized Parallel Computers on More Realistic Ones},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216053},
doi = {10.1137/0216053},
journal = {SIAM J. Comput.},
month = oct,
pages = {808–835},
numpages = {28}
}

@article{10.1137/0216052,
author = {Rosier, Louis E. and Yen, Hsu-Chun},
title = {Logspace Hierarchies, Polynomial Time and the Complexity of Fairness Problems Concerning Ω-Machines},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {5},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216052},
doi = {10.1137/0216052},
journal = {SIAM J. Comput.},
month = oct,
pages = {779–807},
numpages = {29}
}

@article{10.1137/0216073,
author = {Morrison, John A. and Shepp, Larry A. and van Wyk, Christopher J.},
title = {A Queueing Analysis of Hashing with Lazy Deletion},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216073},
doi = {10.1137/0216073},
journal = {SIAM J. Comput.},
month = dec,
pages = {1155–1164},
numpages = {10}
}

@article{10.1137/0216072,
author = {Ibarra, Oscar H. and Jiang, Tao},
title = {On One-Way Cellular Arrays},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216072},
doi = {10.1137/0216072},
journal = {SIAM J. Comput.},
month = dec,
pages = {1135–1154},
numpages = {20}
}

@article{10.1137/0216071,
author = {Scheinerman, Edward R.},
title = {Almost Sure Fault Tolerance in Random Graphs},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216071},
doi = {10.1137/0216071},
journal = {SIAM J. Comput.},
month = dec,
pages = {1124–1134},
numpages = {11}
}

@article{10.1137/0216070,
author = {Larmore, Lawrence L.},
title = {Height Restricted Optimal Binary Trees},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216070},
doi = {10.1137/0216070},
journal = {SIAM J. Comput.},
month = dec,
pages = {1115–1123},
numpages = {9}
}

@article{10.1137/0216069,
author = {Hofri, Micha and Konheim, Alan G.},
title = {Padded Lists Revisited},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216069},
doi = {10.1137/0216069},
journal = {SIAM J. Comput.},
month = dec,
pages = {1073–1114},
numpages = {42}
}

@article{10.1137/0216068,
author = {Frieze, A. M.},
title = {On the Exact Solution of Random Travelling Salesman Problems with Medium Size Integer Coefficients},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216068},
doi = {10.1137/0216068},
journal = {SIAM J. Comput.},
month = dec,
pages = {1052–1072},
numpages = {21}
}

@article{10.1137/0216067,
author = {Abrahamson, Karl},
title = {Generalized String Matching},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216067},
doi = {10.1137/0216067},
journal = {SIAM J. Comput.},
month = dec,
pages = {1039–1051},
numpages = {13}
}

@article{10.1137/0216066,
author = {Pippenger, Nicholas},
title = {Sorting and Selecting in Rounds},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216066},
doi = {10.1137/0216066},
journal = {SIAM J. Comput.},
month = dec,
pages = {1032–1038},
numpages = {7}
}

@article{10.1137/0216065,
author = {Moffat, Alistair and Takaoka, Tadao},
title = {An All Pairs Shortest Path Algorithm with Expected Time <i>O</i>(<i>n<sup>2</sup></i>Log<i>n</i>)},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216065},
doi = {10.1137/0216065},
journal = {SIAM J. Comput.},
month = dec,
pages = {1023–1031},
numpages = {9}
}

@article{10.1137/0216064,
author = {Frederickson, Greg N.},
title = {Fast Algorithms for Shortest Paths in Planar Graphs, with Applications},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216064},
doi = {10.1137/0216064},
journal = {SIAM J. Comput.},
month = dec,
pages = {1004–1022},
numpages = {19}
}

@article{10.1137/0216063,
author = {Yang, Mark C. K. and Huang, Jun S. and Chow, Yuan-Chieh},
title = {Optimal Parallel Sorting Scheme by Order Statistics},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216063},
doi = {10.1137/0216063},
journal = {SIAM J. Comput.},
month = dec,
pages = {990–1003},
numpages = {14}
}

@article{10.1137/0216062,
author = {Paige, Robert and Tarjan, Robert E.},
title = {Three Partition Refinement Algorithms},
year = {1987},
issue_date = {December 1, 1987},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {16},
number = {6},
issn = {0097-5397},
url = {https://doi.org/10.1137/0216062},
doi = {10.1137/0216062},
journal = {SIAM J. Comput.},
month = dec,
pages = {973–989},
numpages = {17}
}

@article{10.1137/0217010,
author = {Tarjan, Robert E. and van Wyk, Christopher},
title = {An <i>O</i> (<i>n</i> Log Log <i>n</i>)-Time Algorithm for Triangulating a Simple Polygon},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217010},
doi = {10.1137/0217010},
journal = {SIAM J. Comput.},
month = feb,
pages = {143–178},
numpages = {36}
}

@article{10.1137/0217009,
author = {Cole, Richard and Vishkin, Uzi},
title = {Approximate Parallel Scheduling. Part I: The Basic Technique with Applications to Optimal Parallel List Ranking in Logarithmic Time},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217009},
doi = {10.1137/0217009},
journal = {SIAM J. Comput.},
month = feb,
pages = {128–142},
numpages = {15}
}

@article{10.1137/0217008,
author = {Nicol, David M.},
title = {Expected Performance of <i>m</i>-Solution Backtracking},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217008},
doi = {10.1137/0217008},
journal = {SIAM J. Comput.},
month = feb,
pages = {114–127},
numpages = {14}
}

@article{10.1137/0217007,
author = {Faigle, U. and Tur\'{a}n, G.},
title = {Sorting and Recognition Problems for Ordered Sets},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217007},
doi = {10.1137/0217007},
journal = {SIAM J. Comput.},
month = feb,
pages = {100–113},
numpages = {14}
}

@article{10.1137/0217006,
author = {Fushimi, Masanori},
title = {Designing a Uniform Random Number Generator Whose Subsequences Are <i>k</i>-Distributed},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217006},
doi = {10.1137/0217006},
journal = {SIAM J. Comput.},
month = feb,
pages = {89–99},
numpages = {11}
}

@article{10.1137/0217005,
author = {Katajainen, Jyrki and van Leeuwen, Jan and Penttonen, Martti},
title = {Fast Simulation of Turing Machines by Random Access Machines},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217005},
doi = {10.1137/0217005},
journal = {SIAM J. Comput.},
month = feb,
pages = {77–88},
numpages = {12}
}

@article{10.1137/0217004,
author = {Bienstock, Daniel and Monma, Clyde L.},
title = {On the Complexity of Covering Vertices by Faces in a Planar Graph},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217004},
doi = {10.1137/0217004},
journal = {SIAM J. Comput.},
month = feb,
pages = {53–76},
numpages = {24}
}

@article{10.1137/0217003,
author = {Masuda, Sumio and Nakajima, Kazuo},
title = {An Optimal Algorithm for Finding a Maximum Independent Set of a Circular-Arc Graph},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217003},
doi = {10.1137/0217003},
journal = {SIAM J. Comput.},
month = feb,
pages = {41–52},
numpages = {12}
}

@article{10.1137/0217002,
author = {Friesen, D. K. and Kuhl, F. S.},
title = {Analysis of a Hybrid Algorithm for Packing Unequal Bins},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217002},
doi = {10.1137/0217002},
journal = {SIAM J. Comput.},
month = feb,
pages = {23–40},
numpages = {18}
}

@article{10.1137/0217001,
author = {Sagiv, Yehoshua},
title = {On Bounded Database Schemes and Bounded Horn-Clause Programs},
year = {1988},
issue_date = {Feb. 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {1},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217001},
doi = {10.1137/0217001},
journal = {SIAM J. Comput.},
month = feb,
pages = {1–12},
numpages = {12}
}

@article{10.1137/0217025,
author = {Micali, Silvio and Rackoff, Charles and Sloan, Bob},
title = {The Notion of Security for Probabilistic Cryptosystems},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217025},
doi = {10.1137/0217025},
journal = {SIAM J. Comput.},
month = apr,
pages = {412–426},
numpages = {15}
}

@article{10.1137/0217024,
author = {Reif, J. H. and Tygar, J. D.},
title = {Efficient Parallel Pseudorandom Number Generation},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217024},
doi = {10.1137/0217024},
journal = {SIAM J. Comput.},
month = apr,
pages = {404–411},
numpages = {8}
}

@article{10.1137/0217023,
author = {Pomerance, Carl and Smith, J. W. and Tuler, Randy},
title = {A Pipeline Architecture for Factoring Large Integers with the Quadratic Sieve Algorithm},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217023},
doi = {10.1137/0217023},
journal = {SIAM J. Comput.},
month = apr,
pages = {387–403},
numpages = {17}
}

@article{10.1137/0217022,
author = {Luby, Michael and Rackoff, Charles},
title = {How to Construct Pseudorandom Permutations from Pseudorandom Functions},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217022},
doi = {10.1137/0217022},
journal = {SIAM J. Comput.},
month = apr,
pages = {373–386},
numpages = {14}
}

@article{10.1137/0217021,
author = {Long, Douglas L. and Wigderson, Avi},
title = {The Discrete Logarithm Hides <i>O</i>(Log <i>n</i>) Bits},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217021},
doi = {10.1137/0217021},
journal = {SIAM J. Comput.},
month = apr,
pages = {363–372},
numpages = {10}
}

@article{10.1137/0217020,
author = {Lagarias, Jeffrey C. and Reeds, James A.},
title = {Unique Extrapolation of Polynomial Recurrences},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217020},
doi = {10.1137/0217020},
journal = {SIAM J. Comput.},
month = apr,
pages = {342–362},
numpages = {21}
}

@article{10.1137/0217019,
author = {Hastad, Johan},
title = {Solving Simultaneous Modular Equations of Low Degree},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217019},
doi = {10.1137/0217019},
journal = {SIAM J. Comput.},
month = apr,
pages = {336–341},
numpages = {6}
}

@article{10.1137/0217018,
author = {Grollmann, Joachim and Selman, Alan L.},
title = {Complexity Measures for Public-Key Cryptosystems},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217018},
doi = {10.1137/0217018},
journal = {SIAM J. Comput.},
month = apr,
pages = {309–335},
numpages = {27}
}

@article{10.1137/0217017,
author = {Goldwasser, Shafi and Micali, Silvio and Rivest, Ronald L.},
title = {A Digital Signature Scheme Secure against Adaptive Chosen-Message Attacks},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217017},
doi = {10.1137/0217017},
journal = {SIAM J. Comput.},
month = apr,
pages = {281–308},
numpages = {28}
}

@article{10.1137/0217016,
author = {Frieze, Alan M. and Hastad, Johan and Kannan, Ravi and Lagarias, Jeffrey C. and Shamir, Adi},
title = {Reconstructing Truncated Integer Variables Satisfying Linear Congruences},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217016},
doi = {10.1137/0217016},
journal = {SIAM J. Comput.},
month = apr,
pages = {262–280},
numpages = {19}
}

@article{10.1137/0217015,
author = {Chor, Benny and Goldreich, Oded},
title = {Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217015},
doi = {10.1137/0217015},
journal = {SIAM J. Comput.},
month = apr,
pages = {230–261},
numpages = {32}
}

@article{10.1137/0217014,
author = {Bennett, Charles H. and Brassard, Gilles and Robert, Jean-Marc},
title = {Privacy Amplification by Public Discussion},
year = {1988},
issue_date = {April 1988},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {17},
number = {2},
issn = {0097-5397},
url = {https://doi.org/10.1137/0217014},
doi = {10.1137/0217014},
journal = {SIAM J. Comput.},
month = apr,
pages = {210–229},
numpages = {20}
}

