@article{10.1561/1500000062,
author = {Hoogeveen, Doris and Wang, Li and Baldwin, Timothy and Verspoor, Karin M.},
title = {Web Forum Retrieval and Text Analytics: A Survey},
year = {2018},
issue_date = {3 1 2018},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {12},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000062},
doi = {10.1561/1500000062},
abstract = {This survey presents an overview of information retrieval, natural languageprocessing and machine learning research that makes use of forumdata, including both discussion forums and community questionansweringcQA archives. The focus is on automated analysis, withthe goal of gaining a better understanding of the data and its users.We discuss the different strategies used for both retrieval taskspost retrieval, question retrieval, and answer retrieval and classificationtasks post type classification, question classification, post qualityassessment, subjectivity, and viewpoint classification at the postlevel, as well as at the thread level thread retrieval, solvedness andtask orientation, discourse structure recovery and dialogue act tagging,QA-pair extraction, and thread summarisation. We also review workon forum users, including user satisfaction, expert finding, questionrecommendation and routing, and community analysis.The survey includes a brief history of forums, an overview of thedifferent kinds of forums, a summary of publicly available datasets forforum research, and a short discussion on the evaluation of retrievaltasks using forum data.The aim is to give a broad overview of the different kinds of forumresearch, a summary of the methods that have been applied, some insightsinto successful strategies, and potential areas for future research.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–163},
numpages = {163}
}

@article{10.1561/1500000052,
author = {Arguello, Jaime},
title = {Aggregated Search},
year = {2017},
issue_date = {6 3 2017},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {10},
number = {5},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000052},
doi = {10.1561/1500000052},
abstract = {The goal of aggregated search is to provide integrated search acrossmultiple heterogeneous search services in a unified interface-a singlequery box and a common presentation of results. In the web searchdomain, aggregated search systems are responsible for integrating resultsfrom specialized search services, or verticals, alongside the coreweb results. For example, search portals such as Google, Bing, andYahoo! provide access to vertical search engines that focus on differenttypes of media images and video, different types of search taskssearch for local businesses and online products, and even applicationsthat can help users complete certain tasks language translation andmath calculations.Aggregated search systems perform two mains tasks. The first taskvertical selection is to predict which verticals if any to present inresponse to a user's query. The second task vertical presentation is topredict where and how to present each selected vertical alongside thecore web results.The goal of this work is to provide a comprehensive summary of previousresearch in aggregated search. We first describe why aggregatedsearch requires unique solutions. Then, we discuss different sources ofevidence that are likely to be available to an aggregated search system,as well as different techniques for integrating evidence in order to makevertical selection and presentation decisions. Next, we survey differentevaluation methodologies for aggregated search and discuss prioruser studies that have aimed to better understand how users behavewith aggregated search interfaces. Finally, we review different advancedtopics in aggregated search.},
journal = {Found. Trends Inf. Retr.},
month = mar,
pages = {365–502},
numpages = {138}
}

@article{10.1561/1500000055,
author = {Cai, Fei and de Rijke, Maarten},
title = {A Survey of Query Auto Completion in Information Retrieval},
year = {2016},
issue_date = {19 9 2016},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {10},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000055},
doi = {10.1561/1500000055},
abstract = {AbstractIn information retrieval, query auto completion QAC, also known as type-ahead [Xiao et al., 2013, Cai et al., 2014b] and auto-complete suggestion [Jain and Mishne, 2010], refers to the following functionality: given a pre\"{\i} undefinedx consisting of a number of characters entered into a search box, the user interface proposes alternative ways of extending the pre\"{\i} undefinedx to a full query. Ranking query completions is a challenging task due to the limited length of pre\"{\i} undefinedxes entered by users, the large volume of possible query completions matching a pre\"{\i} undefinedx, and the broad range of possible search intents. In recent years, a large number of query auto completion approaches have been proposed that produce ranked lists of alternative query completions by mining query logs.In this survey, we review work on query auto completion that has been published before 2016. We focus mainly on web search and provide a formal de\"{\i} undefinednition of the query auto completion problem. We describe two dominant families of approaches to the query auto completion problem, one based on heuristic models and the other based on learning to rank. We also identify dominant trends in published work on query auto completion, viz. the use of time-sensitive signals and the use of user-speci\"{\i} undefinedc signals. We describe the datasets and metrics that are used to evaluate algorithms for query auto completion. We also devote a chapter to ef\"{\i} undefinedciency and a chapter to presentation and interaction aspects of query auto completion. We end by discussing related tasks as well as potential research directions to further the area.},
journal = {Found. Trends Inf. Retr.},
month = sep,
pages = {273–363},
numpages = {91}
}

@article{10.1561/1500000051,
author = {Hofmann, Katja and Li, Lihong and Radlinski, Filip},
title = {Online Evaluation for Information Retrieval},
year = {2016},
issue_date = {6 2016},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {10},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000051},
doi = {10.1561/1500000051},
abstract = {Online evaluation is one of the most common approaches to measure the effectiveness of an information retrieval system. It involves fielding the information retrieval system to real users, and observing these users' interactions in-situ while they engage with the system. This allows actual users with real world information needs to play an important part in assessing retrieval quality. As such, online evaluation complements the common alternative offline evaluation approaches which may provide more easily interpretable outcomes, yet are often less realistic when measuring of quality and actual user experience.In this survey, we provide an overview of online evaluation techniques for information retrieval. We show how online evaluation is used for controlled experiments, segmenting them into experiment designs that allow absolute or relative quality assessments. Our presentation of different metrics further partitions online evaluation based on different sized experimental units commonly of interest: documents, lists and sessions. Additionally, we include an extensive discussion of recent work on data re-use, and experiment estimation based on historical data.A substantial part of this work focuses on practical issues: How to run evaluations in practice, how to select experimental parameters, how to take into account ethical considerations inherent in online evaluations, and limitations that experimenters should be aware of. While most published work on online experimentation today is at large scale in systems with millions of users, we also emphasize that the same techniques can be applied at small scale. To this end, we emphasize recent work that makes it easier to use at smaller scales and encourage studying real-world information seeking in a wide range of scenarios. Finally, we present a summary of the most recent work in the area, and describe open problems, as well as postulating future directions.},
journal = {Found. Trends Inf. Retr.},
month = jun,
pages = {1–117},
numpages = {117}
}

@article{10.1561/1500000032,
author = {Bast, Hannah and Bj\"{o}rn, Buchhold and Haussmann, Elmar},
title = {Semantic Search on Text and Knowledge Bases},
year = {2016},
issue_date = {6 2016},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {10},
number = {2–3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000032},
doi = {10.1561/1500000032},
abstract = {This article provides a comprehensive overview of the broad area of semantic search on text and knowledge bases. In a nutshell, semantic search is "search with meaning". This "meaning" can refer to various parts of the search process: understanding the query instead of just finding matches of its components in the data, understanding the data instead of just searching it for such matches, or representing knowledge in a way suitable for meaningful retrieval.Semantic search is studied in a variety of different communities with a variety of different views of the problem. In this survey, we classify this work according to two dimensions: the type of data text, knowledge bases, combinations of these and the kind of search keyword, structured, natural language. We consider all nine combinations. The focus is on fundamental techniques, concrete systems, and benchmarks. The survey also considers advanced issues: ranking, indexing, ontology matching and merging, and inference. It also provides a succinct overview of fundamental natural language processing techniques: POS-tagging, named-entity recognition and disambiguation, sentence parsing, and distributional semantics.The survey is as self-contained as possible, and should thus also serve as a good tutorial for newcomers to this fascinating and highly topical field.},
journal = {Found. Trends Inf. Retr.},
month = jun,
pages = {119–271},
numpages = {153}
}

@article{10.1561/1500000046,
author = {Ginsca, Alexandru L. and Popescu, Adrian and Lupu, Mihai},
title = {Credibility in Information Retrieval},
year = {2015},
issue_date = {12 2015},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {9},
number = {5},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000046},
doi = {10.1561/1500000046},
abstract = {Credibility, as the general concept covering trustworthiness and expertise, but also quality and reliability, is strongly debated in philosophy, psychology, and sociology, and its adoption in computer science is therefore fraught with difficulties. Yet its importance has grown in the information access community because of two complementing factors: on one hand, it is relatively difficult to precisely point to the source of a piece of information, and on the other hand, complex algorithms, statistical machine learning, artificial intelligence, make decisions on behalf of the users, with little oversight from the users themselves.This survey presents a detailed analysis of existing credibility models from different information seeking research areas, with focus on the Web and its pervasive social component. It shows that there is a very rich body of work pertaining to different aspects and interpretations of credibility, particularly for different types of textual content e.g., Web sites, blogs, tweets, but also to other modalities videos, images, audio and topics e.g., health care. After an introduction placing credibility in the context of other sciences and relating it to trust, we argue for a quartic decomposition of credibility: expertise and trustworthiness, well documented in the literature and predominantly related to information source, and quality and reliability, raised to the status of equal partners because the source is often impossible to detect, and predominantly related to the content.The second half of the survey provides the reader with access points to the literature, grouped by research interests. Section 3 reviews general research directions: the factors that contribute to credibility assessment in human consumers of information; the models used to combine these factors; the methods to predict credibility. A smaller section is dedicated to informing users about the credibility learned from the data. Sections 4, 5, and 6 go further into details, with domain-specific credibility, social media credibility, and multimedia credibility, respectively. While each of them is best understood in the context of Sections 1 and 2, they can be read independently of each other.The last section of this survey addresses a topic not commonly considered under "credibility": the credibility of the system itself, independent of the data creators. This is a topic of particular importance in domains where the user is professionally motivated and where there are no concerns about the credibility of the data e.g. e-discovery and patent search. While there is little explicit work in this direction, we argue that this is an open research direction that is worthy of future exploration.Finally, as an additional help to the reader, an appendix lists the existing test collections that cater specifically to some aspect of credibility.Overall, this review will provide the reader with an organised and comprehensive reference guide to the state of the art and the problems at hand, rather than a final answer to the question of what credibility is for computer science. Even within the relatively limited scope of an exact science, such an answer is not possible for a concept that is itself widely debated in philosophy and social sciences.},
journal = {Found. Trends Inf. Retr.},
month = dec,
pages = {355–475},
numpages = {121}
}

@article{10.1561/1500000043,
author = {Kanhabua, Nattiya and Blanco, Roi and N\o{}rv\r{a}g, Kjetil},
title = {Temporal Information Retrieval},
year = {2015},
issue_date = {7 2015},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {9},
number = {2},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000043},
doi = {10.1561/1500000043},
abstract = {Temporal dynamics and how they impact upon various components of information retrieval IR systems have received a large share of attention in the last decade. In particular, the study of relevance in information retrieval can now be framed within the so-called temporal IR approaches, which explain how user behavior, document content and scale vary with time, and how we can use them in our favor in order to improve retrieval effectiveness. This survey provides a comprehensive overview of temporal IR approaches, centered on the following questions: what are temporal dynamics, why do they occur, and when and how to leverage temporal information throughout the search cycle and architecture. We first explain the general and wide aspects associated to temporal dynamics by focusing on the web domain, from content and structural changes to variations of user behavior and interactions. Next, we pinpoint several research issues and the impact of such temporal characteristics on search, essentially regarding processing dynamic content, temporal query analysis and time-aware ranking. We also address particular aspects of temporal information extraction for instance, how to timestamp documents and generate temporal profiles of text. To this end, we present existing temporal search engines and applications in related research areas, e.g., exploration, summarization, and clustering of search results, as well as future event retrieval and prediction, where the time dimension also plays an important role.},
journal = {Found. Trends Inf. Retr.},
month = jul,
pages = {91–208},
numpages = {118}
}

@article{10.1561/1500000040,
author = {Santos, Rodrygo L. T. and Macdonald, Craig and Ounis, Iadh},
title = {Search Result Diversification},
year = {2015},
issue_date = {3 2015},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {9},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000040},
doi = {10.1561/1500000040},
abstract = {Ranking in information retrieval has been traditionally approachedas a pursuit of relevant information, under the assumption that theusers' information needs are unambiguously conveyed by their submittedqueries. Nevertheless, as an inherently limited representation of amore complex information need, every query can arguably be consideredambiguous to some extent. In order to tackle query ambiguity,search result diversification approaches have recently been proposed toproduce rankings aimed to satisfy the multiple possible informationneeds underlying a query. In this survey, we review the published literatureon search result diversification. In particular, we discuss themotivations for diversifying the search results for an ambiguous queryand provide a formal definition of the search result diversification problem.In addition, we describe the most successful approaches in theliterature for producing and evaluating diversity in multiple search domains.Finally, we also discuss recent advances as well as open researchdirections in the field of search result diversification.},
journal = {Found. Trends Inf. Retr.},
month = mar,
pages = {1–90},
numpages = {90}
}

@article{10.1561/1500000045,
author = {Dave, Kushal and Varma, Vasudeva},
title = {Computational Advertising: Techniques for Targeting Relevant Ads},
year = {2014},
issue_date = {October 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {8},
number = {4–5},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000045},
doi = {10.1561/1500000045},
abstract = {Computational Advertising, popularly known as online advertising or Web advertising, refers to finding the most relevant ads matching a particular context on the Web. The context depends on the type of advertising and could mean — content where the ad is shown, the user who is viewing the ad or the social network of the user. Computational Advertising (CA) is a scientific sub-discipline at the intersection of information retrieval, statistical modeling, machine learning, optimization, large scale search and text analysis. The core problem addressed in Computational Advertising is of match-making between the ads and the context.CA is prevalent in three major forms on the Web. One of the forms involves showing textual ads relevant to a query on the search page, known as Sponsored Search. On the other hand, showing textual ads relevant to a third party webpage content is known as Contextual Advertising. The third form of advertising also deals with the placement of ads on third party Web pages, but the ads in this form are rich multimedia ads — image, video, audio, flash. The business model with rich media ads is slightly different from the ones with textual ads. These ads are also called banner ads, and this form of advertising is known as Display Advertising.Both Sponsored Search and Contextual Advertising involve retrieving relevant ads for different types of content (query and Web page). As ads are short and are mainly written to attract the user, retrieval of ads pose challenges like vocabulary mismatch between the query/content and the ad. Also, as the user's probability of examining an ad decreases with the position of the ad in the ranked list, it is imperative to keep the best ads at the top positions. Display Advertising poses several challenges including modeling user behaviour and noisy page content and bid optimization on the advertiser's side. Additionally, online advertising faces challenges like false bidding, click spam and ad spam. These challenges are prevalent in all forms of advertising. There has been a lot of research work published in different areas of CA in the last one and a half decade. The focus of this survey is to discuss the problems and solutions pertaining to the information retrieval, machine learning and statistics domain of CA. This survey covers techniques and approaches that deal with several issues mentioned above.Research in Computational Advertising has evolved over time and currently continues both in traditional areas (vocabulary mismatch, query rewriting, click prediction) and recently identified areas (user targeting, mobile advertising, social advertising). In this study, we predominantly focus on the problems and solutions proposed in traditional areas in detail and briefly cover the emerging areas in the latter half of the survey. To facilitate future research, a discussion of available resources, list of public benchmark datasets and future directions of work is also provided in the end.},
journal = {Found. Trends Inf. Retr.},
month = oct,
pages = {263–418},
numpages = {156}
}

@article{10.1561/1500000042,
author = {Schedl, Markus and G\'{o}mez, Emilia and Urbano, Juli\'{a}n},
title = {Music Information Retrieval: Recent Developments and Applications},
year = {2014},
issue_date = {September 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {8},
number = {2–3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000042},
doi = {10.1561/1500000042},
abstract = {We provide a survey of the field of Music Information Retrieval (MIR), in particular paying attention to latest developments, such as semantic auto-tagging and user-centric retrieval and recommendation approaches. We first elaborate on well-established and proven methods for feature extraction and music indexing, from both the audio signal and contextual data sources about music items, such as web pages or collaborative tags. These in turn enable a wide variety of music retrieval tasks, such as semantic music search or music identification ("query by example"). Subsequently, we review current work on user analysis and modeling in the context of music recommendation and retrieval, addressing the recent trend towards user-centric and adaptive approaches and systems. A discussion follows about the important aspect of how various MIR approaches to different problems are evaluated and compared. Eventually, a discussion about the major open challenges concludes the survey.},
journal = {Found. Trends Inf. Retr.},
month = sep,
pages = {127–261},
numpages = {135}
}

@article{10.1561/1500000033,
author = {Gurrin, Cathal and Smeaton, Alan F. and Doherty, Aiden R.},
title = {LifeLogging: Personal Big Data},
year = {2014},
issue_date = {June 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {8},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000033},
doi = {10.1561/1500000033},
abstract = {We have recently observed a convergence of technologies to foster the emergence of lifelogging as a mainstream activity. Computer storage has become significantly cheaper, and advancements in sensing technology allows for the efficient sensing of personal activities, locations and the environment. This is best seen in the growing popularity of the quantified self movement, in which life activities are tracked using wearable sensors in the hope of better understanding human performance in a variety of tasks. This review aims to provide a comprehensive summary of lifelogging, to cover its research history, current technologies, and applications. Thus far, most of the lifelogging research has focused predominantly on visual lifelogging, hence we maintain this focus in this review. However, we also reflect on the challenges lifelogging poses for information access and retrieval in general. This review is a suitable reference for those seeking an information retrieval scientist's perspective on lifelogging and the quantified self.},
journal = {Found. Trends Inf. Retr.},
month = jun,
pages = {1–125},
numpages = {125}
}

@article{10.1561/1500000035,
author = {Li, Hang and Xu, Jun},
title = {Semantic Matching in Search},
year = {2014},
issue_date = {June 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {7},
number = {5},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000035},
doi = {10.1561/1500000035},
abstract = {Relevance is the most important factor to assure users' satisfaction in search and the success of a search engine heavily depends on its performance on relevance. It has been observed that most of the dissatisfaction cases in relevance are due to term mismatch between queries and documents (e.g., query "NY times" does not match well with a document only containing "New York Times"), because term matching, i.e., the bag-of-words approach, still functions as the main mechanism of modern search engines. It is not exaggerated to say, therefore, that mismatch between query and document poses the most critical challenge in search. Ideally, one would like to see query and document match with each other, if they are topically relevant. Recently, researchers have expended significant effort to address the problem. The major approach is to conduct semantic matching, i.e., to perform more query and document understanding to represent the meanings of them, and perform better matching between the enriched query and document representations. With the availability of large amounts of log data and advanced machine learning techniques, this becomes more feasible and significant progress has been made recently. This survey gives a systematic and detailed introduction to newly developed machine learning technologies for query document matching (semantic matching) in search, particularly web search. It focuses on the fundamental problems, as well as the state-of-the-art solutions of query document matching on form aspect, phrase aspect, word sense aspect, topic aspect, and structure aspect. The ideas and solutions explained may motivate industrial practitioners to turn the research results into products. The methods introduced and the discussions made may also stimulate academic researchers to find new research directions and approaches. Matching between query and document is not limited to search and similar problems can be found in question answering, online advertising, cross-language information retrieval, machine translation, recommender systems, link prediction, image annotation, drug design, and other applications, as the general task of matching between objects from two different spaces. The technologies introduced can be generalized into more general machine learning techniques, which is referred to as learning to match in this survey.},
journal = {Found. Trends Inf. Retr.},
month = jun,
pages = {343–469},
numpages = {127}
}

@article{10.1561/1500000031,
author = {Darwish, Kareem and Magdy, Walid},
title = {Arabic Information Retrieval},
year = {2014},
issue_date = {February 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {7},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000031},
doi = {10.1561/1500000031},
abstract = {In the past several years, Arabic Information Retrieval (IR) has garnered significant attention. The main research interests have focused on retrieval of formal language, mostly in the news domain, with ad hoc retrieval, OCR document retrieval, and cross-language retrieval. The literature on other aspects of retrieval continues to be sparse or non-existent, though some of these aspects have been investigated by industry. Others aspects of Arabic retrieval that have received attention include document image retrieval, speech search, social media and web search, and filtering. However, efforts on different aspects of Arabic retrieval continue to be deficient and severely lacking behind efforts in other languages. The survey covers: 1) general properties of the Arabic language; 2) some of the aspects of Arabic that affect retrieval; 3) Arabic processing necessary for effective Arabic retrieval; 4) Arabic retrieval in public IR evaluations; 5) specialized retrieval problems, namely Arabic-English CLIR, Arabic Document Image Retrieval, Arabic Social Search, Arabic Web Search, Question Answering, Image retrieval, and Arabic Speech Search; 6) Arabic IR and NLP resources; and 7) open IR problems that require further attention.},
journal = {Found. Trends Inf. Retr.},
month = feb,
pages = {239–342},
numpages = {104},
keywords = {Arabic IR, Arabic NLP}
}

@article{10.1561/1500000027,
author = {Lupu, Mihai and Hanbury, Allan},
title = {Patent Retrieval},
year = {2013},
issue_date = {February 2013},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {7},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000027},
doi = {10.1561/1500000027},
abstract = {Intellectual property and the patent system in particular have been extremely present in research and discussion, even in the public media, in the last few years. Without going into any controversial issues regarding the patent system, we approach a very real and growing problem: searching for innovation. The target collection for this task does not consist of patent documents only, but it is in these documents that the main difference is found compared to web or news information retrieval. In addition, the issue of patent search implies a particular user model and search process model. This review is concerned with how research and technology in the field of Information Retrieval assists or even changes the processes of patent search. It is a survey of work done on patent data in relation to Information Retrieval in the last 20–25 years. It explains the sources of difficulty and the existing document processing and retrieval methods of the domain, and provides a motivation for further research in the area.},
journal = {Found. Trends Inf. Retr.},
month = feb,
pages = {1–97},
numpages = {97},
keywords = {Machine Learning, Ra, Rd, Databases/Information Retrieval}
}

@article{10.1561/1500000020,
author = {Larson, Martha and Jones, Gareth J. F.},
title = {Spoken Content Retrieval: A Survey of Techniques and Technologies},
year = {2012},
issue_date = {April 2012},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {5},
number = {4—5},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000020},
doi = {10.1561/1500000020},
abstract = {Speech media, that is, digital audio and video containing spoken content, has blossomed in recent years. Large collections are accruing on the Internet as well as in private and enterprise settings. This growth has motivated extensive research on techniques and technologies that facilitate reliable indexing and retrieval. Spoken content retrieval (SCR) requires the combination of audio and speech processing technologies with methods from information retrieval (IR). SCR research initially investigated planned speech structured in document-like units, but has subsequently shifted focus to more informal spoken content produced spontaneously, outside of the studio and in conversational settings. This survey provides an overview of the field of SCR encompassing component technologies, the relationship of SCR to text IR and automatic speech recognition and user interaction issues. It is aimed at researchers with backgrounds in speech technology or IR who are seeking deeper insight on how these fields are integrated to support research and development, thus addressing the core challenges of SCR.},
journal = {Found. Trends Inf. Retr.},
month = apr,
pages = {235–422},
numpages = {188}
}

@article{10.1561/1500000024,
author = {Balog, Krisztian and Fang, Yi and de Rijke, Maarten and Serdyukov, Pavel and Si, Luo},
title = {Expertise Retrieval},
year = {2012},
issue_date = {February 2012},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {6},
number = {2–3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000024},
doi = {10.1561/1500000024},
abstract = {People have looked for experts since before the advent of computers. With advances in information retrieval technology and the large-scale availability of digital traces of knowledge-related activities, computer systems that can fully automate the process of locating expertise have become a reality. The past decade has witnessed tremendous interest, and a wealth of results, in expertise retrieval as an emerging subdiscipline in information retrieval. This survey highlights advances in models and algorithms relevant to this field. We draw connections among methods proposed in the literature and summarize them in five groups of basic approaches. These serve as the building blocks for more advanced models that arise when we consider a range of content-based factors that may impact the strength of association between a topic and a person. We also discuss practical aspects of building an expert search system and present applications of the technology in other domains, such as blog distillation and entity retrieval. The limitations of current approaches are also pointed out. We end our survey with a set of conjectures on what the future may hold for expertise retrieval research.},
journal = {Found. Trends Inf. Retr.},
month = feb,
pages = {127–256},
numpages = {130}
}

@article{10.1561/1500000026,
author = {Santos, Rodrygo L. T. and Macdonald, Craig and McCreadie, Richard and Ounis, Iadh and Soboroff, Ian},
title = {Information Retrieval on the Blogosphere},
year = {2012},
issue_date = {January 2012},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {6},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000026},
doi = {10.1561/1500000026},
abstract = {Blogs have recently emerged as a new open, rapidly evolving and reactive publishing medium on the Web. Rather than managed by a central entity, the content on the blogosphere — the collection of all blogs on the Web — is produced by millions of independent bloggers, who can write about virtually anything. This open publishing paradigm has led to a growing mass of user-generated content on the Web, which can vary tremendously both in format and quality when looked at in isolation, but which can also reveal interesting patterns when observed in aggregation. One field particularly interested in studying how information is produced, consumed, and searched in the blogosphere is information retrieval. In this survey, we review the published literature on searching the blogosphere. In particular, we describe the phenomenon of blogging and the motivations for searching for information on blogs. We cover both the search tasks underlying blog searchers' information needs and the most successful approaches to these tasks. These include blog post and full blog search tasks, as well as blog-aided search tasks, such as trend and market analysis. Finally, we also describe the publicly available resources that support research on searching the blogosphere.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–125},
numpages = {125}
}

@article{10.1561/1500000021,
author = {Castillo, Carlos and Davison, Brian D.},
title = {Adversarial Web Search},
year = {2011},
issue_date = {May 2011},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {4},
number = {5},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000021},
doi = {10.1561/1500000021},
abstract = {Web search engines have become indispensable tools for finding content. As the popularity of the Web has increased, the efforts to exploit the Web for commercial, social, or political advantage have grown, making it harder for search engines to discriminate between truthful signals of content quality and deceptive attempts to game search engines' rankings. This problem is further complicated by the open nature of the Web, which allows anyone to write and publish anything, and by the fact that search engines must analyze ever-growing numbers of Web pages. Moreover, increasing expectations of users, who over time rely on Web search for information needs related to more aspects of their lives, further deepen the need for search engines to develop effective counter-measures against deception.In this monograph, we consider the effects of the adversarial relationship between search systems and those who wish to manipulate them, a field known as "Adversarial Information Retrieval". We show that search engine spammers create false content and misleading links to lure unsuspecting visitors to pages filled with advertisements or malware. We also examine work over the past decade or so that aims to discover such spamming activities to get spam pages removed or their effect on the quality of the results reduced.Research in Adversarial Information Retrieval has been evolving over time, and currently continues both in traditional areas (e.g., link spam) and newer areas, such as click fraud and spam in social media, demonstrating that this conflict is far from over.},
journal = {Found. Trends Inf. Retr.},
month = may,
pages = {377–486},
numpages = {110}
}

@article{10.1561/1500000010,
author = {Shokouhi, Milad and Si, Luo},
title = {Federated Search},
year = {2011},
issue_date = {January 2011},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {5},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000010},
doi = {10.1561/1500000010},
abstract = {Federated search (federated information retrieval or distributed information retrieval) is a technique for searching multiple text collections simultaneously. Queries are submitted to a subset of collections that are most likely to return relevant answers. The results returned by selected collections are integrated and merged into a single list. Federated search is preferred over centralized search alternatives in many environments. For example, commercial search engines such as Google cannot easily index uncrawlable hidden web collections while federated search systems can search the contents of hidden web collections without crawling. In enterprise environments, where each organization maintains an independent search engine, federated search techniques can provide parallel search over multiple collections.There are three major challenges in federated search. For each query, a subset of collections that are most likely to return relevant documents are selected. This creates the collection selection problem. To be able to select suitable collections, federated search systems need to acquire some knowledge about the contents of each collection, creating the collection representation problem. The results returned from the selected collections are merged before the final presentation to the user. This final step is the result merging problem.The goal of this work, is to provide a comprehensive summary of the previous research on the federated search challenges described above.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–102},
numpages = {102}
}

@article{10.1561/1500000017,
author = {Olston, Christopher and Najork, Marc},
title = {Web Crawling},
year = {2010},
issue_date = {March 2010},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {4},
number = {3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000017},
doi = {10.1561/1500000017},
abstract = {This is a survey of the science and practice of web crawling. While at first glance web crawling may appear to be merely an application of breadth-first-search, the truth is that there are many challenges ranging from systems concerns such as managing very large data structures to theoretical questions such as how often to revisit evolving content sources. This survey outlines the fundamental challenges and describes the state-of-the-art models and solutions. It also highlights avenues for future work.},
journal = {Found. Trends Inf. Retr.},
month = mar,
pages = {175–246},
numpages = {72}
}

@article{10.1561/1500000013,
author = {Silvestri, Fabrizio},
title = {Mining Query Logs: Turning Search Usage Data into Knowledge},
year = {2010},
issue_date = {January 2010},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {4},
number = {1—2},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000013},
doi = {10.1561/1500000013},
abstract = {Web search engines have stored in their logs information about users since they started to operate. This information often serves many purposes. The primary focus of this survey is on introducing to the discipline of query mining by showing its foundations and by analyzing the basic algorithms and techniques that are used to extract useful knowledge from this (potentially) infinite source of information. We show how search applications may benefit from this kind of analysis by analyzing popular applications of query log mining and their influence on user experience. We conclude the paper by, briefly, presenting some of the most challenging current open problems in this field.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–174},
numpages = {174}
}

@article{10.1561/1500000019,
author = {Robertson, Stephen and Zaragoza, Hugo},
title = {The Probabilistic Relevance Framework: BM25 and Beyond},
year = {2009},
issue_date = {April 2009},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {3},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000019},
doi = {10.1561/1500000019},
abstract = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970—1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the different ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
journal = {Found. Trends Inf. Retr.},
month = apr,
pages = {333–389},
numpages = {57}
}

@article{10.1561/1500000014,
author = {Snoek, Cees G. M. and Worring, Marcel},
title = {Concept-Based Video Retrieval},
year = {2009},
issue_date = {April 2008},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {2},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000014},
doi = {10.1561/1500000014},
abstract = {In this paper, we review 300 references on video retrieval, indicating when text-only solutions are unsatisfactory and showing the promising alternatives which are in majority concept-based. Therefore, central to our discussion is the notion of a semantic concept: an objective linguistic description of an observable entity. Specifically, we present our view on how its automated detection, selection under uncertainty, and interactive usage might solve the major scientific problem for video retrieval: the semantic gap. To bridge the gap, we lay down the anatomy of a concept-based video search engine. We present a component-wise decomposition of such an interdisciplinary multimedia system, covering influences from information retrieval, computer vision, machine learning, and human–computer interaction. For each of the components we review state-of-the-art solutions in the literature, each having different characteristics and merits. Because of these differences, we cannot understand the progress in video retrieval without serious evaluation efforts such as carried out in the NIST TRECVID benchmark. We discuss its data, tasks, results, and the many derived community initiatives in creating annotations and baselines for repeatable experiments. We conclude with our perspective on future challenges and opportunities.},
journal = {Found. Trends Inf. Retr.},
month = apr,
pages = {215–322},
numpages = {108}
}

@article{10.1561/1500000016,
author = {Liu, Tie-Yan},
title = {Learning to Rank for Information Retrieval},
year = {2009},
issue_date = {March 2009},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {3},
number = {3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000016},
doi = {10.1561/1500000016},
abstract = {Learning to rank for Information Retrieval (IR) is a task to automatically construct a ranking model using training data, such that the model can sort new objects according to their degrees of relevance, preference, or importance. Many IR problems are by nature ranking problems, and many IR technologies can be potentially enhanced by using learning-to-rank techniques. The objective of this tutorial is to give an introduction to this research direction. Specifically, the existing learning-to-rank algorithms are reviewed and categorized into three approaches: the pointwise, pairwise, and listwise approaches. The advantages and disadvantages with each approach are analyzed, and the relationships between the loss functions used in these approaches and IR evaluation measures are discussed. Then the empirical evaluations on typical learning-to-rank methods are shown, with the LETOR collection as a benchmark dataset, which seems to suggest that the listwise approach be the most effective one among all the approaches. After that, a statistical ranking theory is introduced, which can describe different learning-to-rank algorithms, and be used to analyze their query-level generalization abilities. At the end of the tutorial, we provide a summary and discuss potential future work on learning to rank.},
journal = {Found. Trends Inf. Retr.},
month = mar,
pages = {225–331},
numpages = {107}
}

@article{10.1561/1500000012,
author = {Kelly, Diane},
title = {Methods for Evaluating Interactive Information Retrieval Systems with Users},
year = {2009},
issue_date = {January 2009},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {3},
number = {1—2},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000012},
doi = {10.1561/1500000012},
abstract = {This paper provides overview and instruction regarding the evaluation of interactive information retrieval systems with users. The primary goal of this article is to catalog and compile material related to this topic into a single source. This article (1) provides historical background on the development of user-centered approaches to the evaluation of interactive information retrieval systems; (2) describes the major components of interactive information retrieval system evaluation; (3) describes different experimental designs and sampling strategies; (4) presents core instruments and data collection techniques and measures; (5) explains basic data analysis techniques; and (4) reviews and discusses previous studies. This article also discusses validity and reliability issues with respect to both measures and methods, presents background information on research ethics and discusses some ethical issues which are specific to studies of interactive information retrieval (IIR). Finally, this article concludes with a discussion of outstanding challenges and future research directions.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–224},
numpages = {224}
}

@article{10.1561/1500000006,
author = {Cormack, Gordon V.},
title = {Email Spam Filtering: A Systematic Review},
year = {2008},
issue_date = {April 2007},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {1},
number = {4},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000006},
doi = {10.1561/1500000006},
abstract = {Spam is information crafted to be delivered to a large number of recipients, in spite of their wishes. A spam filter is an automated tool to recognize spam so as to prevent its delivery. The purposes of spam and spam filters are diametrically opposed: spam is effective if it evades filters, while a filter is effective if it recognizes spam. The circular nature of these definitions, along with their appeal to the intent of sender and recipient make them difficult to formalize. A typical email user has a working definition no more formal than "I know it when I see it." Yet, current spam filters are remarkably effective, more effective than might be expected given the level of uncertainty and debate over a formal definition of spam, more effective than might be expected given the state-of-the-art information retrieval and machine learning methods for seemingly similar problems. But are they effective enough? Which are better? How might they be improved? Will their effectiveness be compromised by more cleverly crafted spam?We survey current and proposed spam filtering techniques with particular emphasis on how well they work. Our primary focus is spam filtering in email; Similarities and differences with spam filtering in other communication and storage media — such as instant messaging and the Web — are addressed peripherally. In doing so we examine the definition of spam, the user's information requirements and the role of the spam filter as one component of a large and complex information universe. Well-known methods are detailed sufficiently to make the exposition self-contained, however, the focus is on considerations unique to spam. Comparisons, wherever possible, use common evaluation measures, and control for differences in experimental setup. Such comparisons are not easy, as benchmarks, measures, and methods for evaluating spam filters are still evolving. We survey these efforts, their results and their limitations. In spite of recent advances in evaluation methodology, many uncertainties (including widely held but unsubstantiated beliefs) remain as to the effectiveness of spam filtering techniques and as to the validity of spam filter evaluation methods. We outline several uncertainties and propose experimental methods to address them.},
journal = {Found. Trends Inf. Retr.},
month = apr,
pages = {335–455},
numpages = {121}
}

@article{10.1561/1500000008,
author = {Zhai, ChengXiang},
title = {Statistical Language Models for Information Retrieval A Critical Review},
year = {2008},
issue_date = {March 2008},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {2},
number = {3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000008},
doi = {10.1561/1500000008},
abstract = {Statistical language models have recently been successfully applied to many information retrieval problems. A great deal of recent work has shown that statistical language models not only lead to superior empirical performance, but also facilitate parameter tuning and open up possibilities for modeling nontraditional retrieval problems. In general, statistical language models provide a principled way of modeling various kinds of retrieval problems. The purpose of this survey is to systematically and critically review the existing work in applying statistical language models to information retrieval, summarize their contributions, and point out outstanding challenges.},
journal = {Found. Trends Inf. Retr.},
month = mar,
pages = {137–213},
numpages = {77}
}

@article{10.1561/1500000011,
author = {Pang, Bo and Lee, Lillian},
title = {Opinion Mining and Sentiment Analysis},
year = {2008},
issue_date = {January 2008},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {2},
number = {1–2},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000011},
doi = {10.1561/1500000011},
abstract = {An important part of our information-gathering behavior has always been to find out what other people think. With the growing availability and popularity of opinion-rich resources such as online review sites and personal blogs, new opportunities and challenges arise as people now can, and do, actively use information technologies to seek out and understand the opinions of others. The sudden eruption of activity in the area of opinion mining and sentiment analysis, which deals with the computational treatment of opinion, sentiment, and subjectivity in text, has thus occurred at least in part as a direct response to the surge of interest in new systems that deal directly with opinions as a first-class object.This survey covers techniques and approaches that promise to directly enable opinion-oriented information-seeking systems. Our focus is on methods that seek to address the new challenges raised by sentiment-aware applications, as compared to those that are already present in more traditional fact-based analysis. We include material on summarization of evaluative text and on broader issues regarding privacy, manipulation, and economic impact that the development of opinion-oriented information-access services gives rise to. To facilitate future work, a discussion of available resources, benchmark datasets, and evaluation campaigns is also provided.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–135},
numpages = {135}
}

@article{10.1561/1500000005,
author = {Juola, Patrick},
title = {Authorship Attribution},
year = {2006},
issue_date = {December 2006},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {1},
number = {3},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000005},
doi = {10.1561/1500000005},
abstract = {Authorship attribution, the science of inferring characteristics of the author from the characteristics of documents written by that author, is a problem with a long history and a wide range of application. Recent work in "non-traditional" authorship attribution demonstrates the practicality of automatically analyzing documents based on authorial style, but the state of the art is confusing. Analyses are difficult to apply, little is known about type or rate of errors, and few "best practices" are available. In part because of this confusion, the field has perhaps had less uptake and general acceptance than is its due.This review surveys the history and present state of the discipline, presenting some comparative results when available. It shows, first, that the discipline is quite successful, even in difficult cases involving small documents in unfamiliar and less studied languages; it further analyzes the types of analysis and features used and tries to determine characteristics of well-performing systems, finally formulating these in a set of recommendations for best practices.},
journal = {Found. Trends Inf. Retr.},
month = dec,
pages = {233–334},
numpages = {102}
}

@article{10.1561/1500000001,
author = {Prager, John},
title = {Open-Domain Question: Answering},
year = {2006},
issue_date = {January 2006},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {1},
number = {2},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000001},
doi = {10.1561/1500000001},
abstract = {The top-performing Question-Answering (QA) systems have been of two types: consistent, solid, well-established and multi-faceted systems that do well year after year, and ones that come out of nowhere employing totally innovative approaches and which out-perform almost everybody else. This article examines both types of system in depth. We establish what a "typical" QA-system looks like, and cover the commonly used approaches by the component modules. Understanding this will enable any proficient system developer to build his own QA-system. Fortunately there are many components available for free from their developers to make this a reasonable expectation for a graduate-level project. We also look at particular systems that have performed well and which employ interesting and innovative approaches.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {91–231},
numpages = {141}
}

@article{10.1561/1500000002,
author = {Orio, Nicola},
title = {Music Retrieval: A Tutorial and Review},
year = {2006},
issue_date = {January 2006},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {1},
number = {1},
issn = {1554-0669},
url = {https://doi.org/10.1561/1500000002},
doi = {10.1561/1500000002},
abstract = {The increasing availability of music in digital format needs to be matched by the development of tools for music accessing, filtering, classification, and retrieval. The research area of Music Information Retrieval (MIR) covers many of these aspects. The aim of this paper is to present an overview of this vast and new field. A number of issues, which are peculiar to the music language, are described--including forms, formats, and dimensions of music--together with the typologies of users and their information needs. To fulfil these needs a number of approaches are discussed, from direct search to information filtering and clustering of music documents. An overview of the techniques for music processing, which are commonly exploited in many approaches, is also presented. Evaluation and comparisons of the approaches on a common benchmark are other important issues. To this end, a description of the initial efforts and evaluation campaigns for MIR is provided.},
journal = {Found. Trends Inf. Retr.},
month = jan,
pages = {1–96},
numpages = {96}
}

