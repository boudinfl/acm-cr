@article{10.1007/s10791-019-09354-z,
author = {Dietz, Laura and Xiong, Chenyan and Dalton, Jeff and Meij, Edgar},
title = {Special Issue on Knowledge Graphs and Semantics in Text Analysis and Retrieval},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-019-09354-z},
doi = {10.1007/s10791-019-09354-z},
journal = {Inf. Retr.},
month = aug,
pages = {229–231},
numpages = {3}
}

@article{10.1007/s10791-018-9348-8,
author = {Sawant, Uma and Garg, Saurabh and Chakrabarti, Soumen and Ramakrishnan, Ganesh},
title = {Neural Architecture for Question Answering Using a Knowledge Graph and Web Corpus},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9348-8},
doi = {10.1007/s10791-018-9348-8},
abstract = {In Web search, entity-seeking queries often trigger a special question answering (QA) system. It may use a parser to interpret the question to a structured query, execute that on a knowledge graph (KG), and return direct entity responses. QA systems based on precise parsing tend to be brittle: minor syntax variations may dramatically change the response. Moreover, KG coverage is patchy. At the other extreme, a large corpus may provide broader coverage, but in an unstructured, unreliable form. We present AQQUCN, a QA system that gracefully combines KG and corpus evidence. AQQUCN accepts a broad spectrum of query syntax, between well-formed questions to short "telegraphic" keyword sequences. In the face of inherent query ambiguities, AQQUCN aggregates signals from KGs and large corpora to directly rank KG entities, rather than commit to one semantic interpretation of the query. AQQUCN models the ideal interpretation as an unobservable or latent variable. Interpretations and candidate entity responses are scored as pairs, by combining signals from multiple convolutional networks that operate collectively on the query, KG and corpus. On four public query workloads, amounting to over 8000 queries with diverse query syntax, we see 5---16% absolute improvement in mean average precision (MAP), compared to the entity ranking performance of recent systems. Our system is also competitive at entity set retrieval, almost doubling F1 scores for challenging short queries.},
journal = {Inf. Retr.},
month = aug,
pages = {324–349},
numpages = {26},
keywords = {Entity ranking, Convolutional network, Question answering, Knowledge graph, Neural network}
}

@article{10.1007/s10791-018-9346-x,
author = {Garigliotti, Dar\'{\i}o and Hasibi, Faegheh and Balog, Krisztian},
title = {Identifying and Exploiting Target Entity Type Information for Ad Hoc Entity Retrieval},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9346-x},
doi = {10.1007/s10791-018-9346-x},
abstract = {Today, the practice of returning entities from a knowledge base in response to search queries has become widespread. One of the distinctive characteristics of entities is that they are typed, i.e., assigned to some hierarchically organized type system (type taxonomy). The primary objective of this paper is to gain a better understanding of how entity type information can be utilized in entity retrieval. We perform this investigation in two settings: firstly, in an idealized "oracle" setting, assuming that we know the distribution of target types of the relevant entities for a given query; and secondly, in a realistic scenario, where target entity types are identified automatically based on the keyword query. We perform a thorough analysis of three main aspects: (i) the choice of type taxonomy, (ii) the representation of hierarchical type information, and (iii) the combination of type-based and term-based similarity in the retrieval model. Using a standard entity search test collection based on DBpedia, we show that type information can significantly and substantially improve retrieval performance, yielding up to 67% relative improvement in terms of NDCG@10 over a strong text-only baseline in an oracle setting. We further show that using automatic target type detection, we can outperform the text-only baseline by 44% in terms of NDCG@10. This is as good as, and sometimes even better than, what is attainable by using explicit target type information provided by humans. These results indicate that identifying target entity types of queries is challenging even for humans and attests to the effectiveness of our proposed automatic approach.},
journal = {Inf. Retr.},
month = aug,
pages = {285–323},
numpages = {39},
keywords = {Entity retrieval, Query understanding, Entity types, Semantic search}
}

@article{10.1007/s10791-018-9345-y,
author = {Nayak, Guruprasad and Dutta, Sourav and Ajwani, Deepak and Nicholson, Patrick and Sala, Alessandra},
title = {Automated Assessment of Knowledge Hierarchy Evolution: Comparing Directed Acyclic Graphs},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9345-y},
doi = {10.1007/s10791-018-9345-y},
abstract = {Automated construction of knowledge hierarchies from huge data corpora is gaining increasing attention in recent years, in order to tackle the infeasibility of manually extracting and semantically linking millions of concepts. As a knowledge hierarchy evolves with these automated techniques, there is a need for measures to assess its temporal evolution, quantifying the similarities between different versions and identifying the relative growth of different subgraphs in the knowledge hierarchy. In this paper, we focus on measures that leverage structural properties of the knowledge hierarchy graph to assess the temporal changes. We propose a principled and scalable similarity measure, based on Katz similarity between concept nodes, for comparing different versions of a knowledge hierarchy, modeled as a generic directed acyclic graph. We present theoretical analysis to depict that the proposed measure accurately captures the salient properties of taxonomic hierarchies, assesses changes in the ordering of nodes, along with the logical subsumption of relationships among concepts. We also present a linear time variant of the measure, and show that our measures, unlike previous approaches, are tunable to cater to diverse application needs. We further show that our measure provides interpretability, thereby identifying the key structural and logical difference in the hierarchies. Experiments on a real DBpedia and biological knowledge hierarchy showcase that our measures accurately capture structural similarity, while providing enhanced scalability and tunability. Also, we demonstrate that the temporal evolution of different subgraphs in this knowledge hierarchy, as captured purely by our structural measure, corresponds well with the known disruptions in the related subject areas.},
journal = {Inf. Retr.},
month = aug,
pages = {256–284},
numpages = {29},
keywords = {Knowledge hierarchy matching, Semantic subsumption, DAG similarity, Taxonomy evaluation, Concept tracking}
}

@article{10.1007/s10791-018-9344-z,
author = {Jimmy and Zuccon, Guido and Koopman, Bevan},
title = {Payoffs and Pitfalls in Using Knowledge-Bases for Consumer Health Search},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9344-z},
doi = {10.1007/s10791-018-9344-z},
abstract = {Consumer health search (CHS) is a challenging domain with vocabulary mismatch and considerable domain expertise hampering peoples' ability to formulate effective queries. We posit that using knowledge bases for query reformulation may help alleviate this problem. How to exploit knowledge bases for effective CHS is nontrivial, involving a swathe of key choices and design decisions (many of which are not explored in the literature). Here we rigorously empirically evaluate the impact these different choices have on retrieval effectiveness.
 A state-of-the-art knowledge-base retrieval model--the Entity Query Feature Expansion model--was used to evaluate these choices, which include: which knowledge base to use (specialised vs. general purpose), how to construct the knowledge base, how to extract entities from queries and map them to entities in the knowledge base, what part of the knowledge base to use for query expansion, and if to augment the knowledge base search process with relevance feedback.
 While knowledge base retrieval has been proposed as a solution for CHS, this paper delves into the finer details of doing this effectively, highlighting both payoffs and pitfalls. It aims to provide some lessons to others in advancing the state-of-the-art in CHS.},
journal = {Inf. Retr.},
month = aug,
pages = {350–394},
numpages = {45},
keywords = {Consumer health search, Query expansion, Knowledge graph, Knowledge base}
}

@article{10.1007/s10791-018-9343-0,
author = {Macavaney, Sean and Yates, Andrew and Cohan, Arman and Soldaini, Luca and Hui, Kai and Goharian, Nazli and Frieder, Ophir},
title = {Overcoming Low-Utility Facets for Complex Answer Retrieval},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9343-0},
doi = {10.1007/s10791-018-9343-0},
abstract = {Many questions cannot be answered simply; their answers must include numerous nuanced details and context. Complex Answer Retrieval (CAR) is the retrieval of answers to such questions. These questions can be constructed from a topic entity (e.g., `cheese') and a facet (e.g., `health effects'). While topic matching has been thoroughly explored, we observe that some facets use general language that is unlikely to appear verbatim in answers, exhibiting low utility. In this work, we present an approach to CAR that identifies and addresses low-utility facets. First, we propose two estimators of facet utility: the hierarchical structure of CAR queries, and facet frequency information from training data. Then, to improve the retrieval performance on low-utility headings, we include entity similarity scores using embeddings trained from a CAR knowledge graph, which captures the context of facets. We show that our methods are effective by applying them to two leading neural ranking techniques, and evaluating them on the TREC CAR dataset. We find that our approach perform significantly better than the unmodified neural ranker and other leading CAR techniques, yielding state-of-the-art results. We also provide a detailed analysis of our results, verify that low-utility facets are indeed difficult to match, and that our approach improves the performance for these difficult queries.},
journal = {Inf. Retr.},
month = aug,
pages = {395–418},
numpages = {24},
keywords = {Reranking, Neural information retrieval, Complex answer retrieval, Knowledge graphs}
}

@article{10.1007/s10791-018-9342-1,
author = {Rastogi, Pushpendre and Poliak, Adam and Lyzinski, Vince and Durme, Benjamin},
title = {Neural Variational Entity Set Expansion for Automatically Populated Knowledge Graphs},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9342-1},
doi = {10.1007/s10791-018-9342-1},
abstract = {We propose Neural variational set expansion to extract actionable information from a noisy knowledge graph (KG) and propose a general approach for increasing the interpretability of recommendation systems. We demonstrate the usefulness of applying a variational autoencoder to the Entity set expansion task based on a realistic automatically generated KG.},
journal = {Inf. Retr.},
month = aug,
pages = {232–255},
numpages = {24},
keywords = {Unsupervised learning, Variational autoencoder, Product of experts (POE), Set expansion, Cold start recommendation, Content based recommendation}
}

@article{10.1007/s10791-019-09352-1,
author = {Boratto, Ludovico and Kaltenbrunner, Andreas and Stilo, Giovanni},
title = {Guest Editorial: Social Media for Personalization and Search},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-019-09352-1},
doi = {10.1007/s10791-019-09352-1},
journal = {Inf. Retr.},
month = apr,
pages = {1–3},
numpages = {3}
}

@article{10.1007/s10791-018-9341-2,
author = {Kulshrestha, Juhi and Eslami, Motahhare and Messias, Johnnatan and Zafar, Muhammad Bilal and Ghosh, Saptarshi and Gummadi, Krishna P. and Karahalios, Karrie},
title = {Search Bias Quantification: Investigating Political Bias in Social Media and Web Search},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9341-2},
doi = {10.1007/s10791-018-9341-2},
abstract = {Users frequently use search systems on the Web as well as online social media to learn about ongoing events and public opinion on personalities. Prior studies have shown that the top-ranked results returned by these search engines can shape user opinion about the topic (e.g., event or person) being searched. In case of polarizing topics like politics, where multiple competing perspectives exist, the political bias in the top search results can play a significant role in shaping public opinion towards (or away from) certain perspectives. Given the considerable impact that search bias can have on the user, we propose a generalizable search bias quantification framework that not only measures the political bias in ranked list output by the search system but also decouples the bias introduced by the different sources--input data and ranking system. We apply our framework to study the political bias in searches related to 2016 US Presidential primaries in Twitter social media search and find that both input data and ranking system matter in determining the final search output bias seen by the users. And finally, we use the framework to compare the relative bias for two popular search systems--Twitter social media search and Google web search--for queries related to politicians and political events. We end by discussing some potential solutions to signal the bias in the search results to make the users more aware of them.},
journal = {Inf. Retr.},
month = apr,
pages = {188–227},
numpages = {40},
keywords = {Search bias, Web search, Social media search, Sources of search bias, Search bias quantification, Political bias inference}
}

@article{10.1007/s10791-018-9339-9,
author = {Naini, Kaweh Djafari and Kawase, Ricardo and Kanhabua, Nattiya and Nieder\'{e}e, Claudia and Altingovde, Ismail Sengor},
title = {Those Were the Days: Learning to Rank Social Media Posts for Reminiscence},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9339-9},
doi = {10.1007/s10791-018-9339-9},
abstract = {Social media posts are a great source for life summaries aggregating activities, events, interactions and thoughts of the last months or years. 
They can be used for personal reminiscence as well as for keeping track with developments in the lives of not-so-close friends. One of the core challenges of automatically creating such summaries is to decide which posts are memorable, i.e., should be considered for retention and which ones to forget. To address this challenge, we design and conduct user evaluation studies and construct a corpus that captures human expectations towards content retention. We analyze this corpus to identify a small set of seed features that are most likely to characterize memorable posts. Next, we compile a broader set of features that are leveraged to build general and personalized machine-learning models to rank posts for retention. By applying feature selection, we identify a compact yet effective subset of these features. The models trained with the presented feature sets outperform the baseline models exploiting an intuitive set of temporal and social features.},
journal = {Inf. Retr.},
month = apr,
pages = {159–187},
numpages = {29},
keywords = {Personalized ranking, Letor, Social features, Personalization, Feature selection, Learning to rank, Content retention, Social media, Facebook}
}

@article{10.1007/s10791-018-9338-x,
author = {Bennacer Seghouani, Nac\'{e}ra and Jipmo, Coriane Nana and Quercini, Gianluca},
title = {Determining the Interests of Social Media Users: Two Approaches},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9338-x},
doi = {10.1007/s10791-018-9338-x},
abstract = {Although social media platforms serve diverse purposes, from social and professional networking to photo sharing and blogging, people frequently use them to share the thoughts and opinions and most importantly, their interests (e.g., politics, economy, sports). Understanding the interests of social media users is key to many applications that need to characterize them to recommend some services and find other individuals with similar interests. In this paper, we propose two approaches to the automatic determination of the interests of social media users. The first, that we named Frisk, is an unsupervised multilingual approach that determines the interests of a user from the explicit meaning of the words that occur in the user's posts. The second, that we termed Ascertain, is a supervised approach that resorts to the hidden dimensions of the words that several studies indicated to be capable of revealing some of the psychological processes and personality traits of a person. In our evaluation, that we performed on two datasets obtained from Twitter, we show that Frisk is capable of inferring the interests in a multilingual context with good accuracy and that the psychological dimensions used by Ascertain are also good predictors of a user's interests.},
journal = {Inf. Retr.},
month = apr,
pages = {129–158},
numpages = {30},
keywords = {Interest classification, Twitter user profile, Personality}
}

@article{10.1007/s10791-018-9337-y,
author = {Zarrinkalam, Fattane and Kahani, Mohsen and Bagheri, Ebrahim},
title = {User Interest Prediction over Future Unobserved Topics on Social Networks},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9337-y},
doi = {10.1007/s10791-018-9337-y},
abstract = {The accurate prediction of users' future interests on social networks allows one to perform future planning by studying how users will react if certain topics emerge in the future. It can improve areas such as targeted advertising and the efficient delivery of services. Despite the importance of predicting user future interests on social networks, existing works mainly focus on identifying user current interests and little work has been done on the prediction of user potential interests in the future. There have been work that attempt to identify a user future interests, however they cannot predict user interests with regard to new topics since these topics have never received any feedback from users in the past. In this paper, we propose a framework that works on the basis of temporal evolution of user interests and utilizes semantic information from knowledge bases such as Wikipedia to predict user future interests and overcome the cold item problem. Through extensive experiments on a real-world Twitter dataset, we demonstrate the effectiveness of our approach in predicting future interests of users compared to state-of-the-art baselines. Moreover, we further show that the impact of our work is especially meaningful when considered in case of cold items.},
journal = {Inf. Retr.},
month = apr,
pages = {93–128},
numpages = {36},
keywords = {User modeling, Twitter, Wikipedia category hierarchy, User interest prediction}
}

@article{10.1007/s10791-018-9336-z,
author = {Eberhard, Lukas and Trattner, Christoph and Atzmueller, Martin},
title = {Predicting Trading Interactions in an Online Marketplace through Location-Based and Online Social Networks},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9336-z},
doi = {10.1007/s10791-018-9336-z},
abstract = {Link prediction is a prominent research direction e.g., for inferring upcoming interactions to be used in recommender systems. Although this problem of predicting links between users has been extensively studied in the past, research investigating this issue simultaneously in multiplex networks is rather rare so far. This is the focus of this paper. We investigate the extent to which trading interactions between sellers and buyers within an online marketplace platform can be predicted based on three different but overlapping networks--an online social network, a location-based social network and a trading network. In particular, we conducted the study in the context of the virtual world Second Life. For that, we crawled according data of the online social network, user information of the location-based social network obtained by specialized bots, and we extracted purchases of the trading network. Overall, we generated and used 57 topological and homophilic features in different constellations to predict trading interactions between user pairs. We focused on both unsupervised as well as supervised learning methods. For supervised learning, we achieved accuracy values up to $$92.5%$$92.5%, for unsupervised learning we obtained nDCG values up to over $$97%$$97% and MAP values up to $$75%$$75%.},
journal = {Inf. Retr.},
month = apr,
pages = {55–92},
numpages = {38},
keywords = {Location-based and online social networks, Seller, Buyer, Link prediction, Second life, Supervised and unsupervised learning}
}

@article{10.1007/s10791-018-9335-0,
author = {Monteserin, Ariel and Armentano, Marcelo G.},
title = {Influence Me! Predicting Links to Influential Users},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9335-0},
doi = {10.1007/s10791-018-9335-0},
abstract = {In addition to being in contact with friends, online social networks are commonly used as a source of information, suggestions and recommendations from members of the community. Whenever we accept a suggestion or perform any action because it was recommended by a "friend", we are being influenced by him/her. For this reason, it is useful for users seeking for interesting information to identify and connect to this kind of influential users.
 In this context, we propose an approach to predict links to influential users. Compared to approaches that identify general influential users in a network, our approach seeks to identify users who might have some kind of influence to individual (target) users. To carry out this goal, we adapted an influence maximization algorithm to find new influential users from the set of current influential users of the target user. Moreover, we compared the results obtained with different metrics for link prediction and analyzed in which context these metrics obtained better results.
},
journal = {Inf. Retr.},
month = apr,
pages = {32–54},
numpages = {23},
keywords = {Social influence, Link prediction, Social networks}
}

@article{10.1007/s10791-018-9333-2,
author = {Cucchiarelli, Alessandro and Morbidoni, Christian and Stilo, Giovanni and Velardi, Paola},
title = {A Topic Recommender for Journalists},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9333-2},
doi = {10.1007/s10791-018-9333-2},
abstract = {The way in which people gather information about events and form their own opinion on them has changed dramatically with the advent of social media. For many readers, the news gathered from online sources has become an opportunity to share points of view and information within micro-blogging platforms such as Twitter, mainly aimed at satisfying their communication needs. Furthermore, the need to deepen the aspects related to news stimulates a demand for additional information which is often met through online encyclopedias, such as Wikipedia. This behaviour has also influenced the way in which journalists write their articles, requiring a careful assessment of what actually interests the readers. The goal of this paper is to present a recommender system, What to Write and Why, capable of suggesting to a journalist, for a given event, the aspects still uncovered in news articles on which the readers focus their interest. The basic idea is to characterize an event according to the echo it receives in online news sources and associate it with the corresponding readers' communicative and informative patterns, detected through the analysis of Twitter and Wikipedia, respectively. Our methodology temporally aligns the results of this analysis and recommends the concepts that emerge as topics of interest from Twitter and Wikipedia, either not covered or poorly covered in the published news articles.},
journal = {Inf. Retr.},
month = apr,
pages = {4–31},
numpages = {28},
keywords = {Event detection, Wikipedia, Temporal mining, Online News, Twitter, Recommender systems}
}

@article{10.1007/s10791-018-9329-y,
author = {Ganguly, Debasis and Jones, Gareth J.},
title = {A Non-Parametric Topical Relevance Model},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9329-y},
doi = {10.1007/s10791-018-9329-y},
abstract = {An information retrieval (IR) system can often fail to retrieve relevant documents due to the incomplete specification of information need in the user's query. Pseudo-relevance feedback (PRF) aims to improve IR effectiveness by exploiting potentially relevant aspects of the information need present in the documents retrieved in an initial search. Standard PRF approaches utilize the information contained in these top ranked documents from the initial search with the assumption that documents as a whole are relevant to the information need. However, in practice, documents are often multi-topical where only a portion of the documents may be relevant to the query. In this situation, exploitation of the topical composition of the top ranked documents, estimated with statistical topic modeling based approaches, can potentially be a useful cue to improve PRF effectiveness. The key idea behind our PRF method is to use the term-topic and the document-topic distributions obtained from topic modeling over the set of top ranked documents to re-rank the initially retrieved documents. The objective is to improve the ranks of documents that are primarily composed of the relevant topics expressed in the information need of the query. Our RF model can further be improved by making use of non-parametric topic modeling, where the number of topics can grow according to the document contents, thus giving the RF model the capability to adjust the number of topics based on the content of the top ranked documents. We empirically validate our topic model based RF approach on two document collections of diverse length and topical composition characteristics: (1) ad-hoc retrieval using the TREC 6-8 and the TREC Robust '04 dataset, and (2) tweet retrieval using the TREC Microblog '11 dataset. Results indicate that our proposed approach increases MAP by up to 9% in comparison to the results obtained with an LDA based language model (for initial retrieval) coupled with the relevance model (for feedback). Moreover, the non-parametric version of our proposed approach is shown to be more effective than its parametric counterpart due to its advantage of adapting the number of topics, improving results by up to 5.6% of MAP compared to the parametric version.},
journal = {Inf. Retr.},
month = oct,
pages = {449–479},
numpages = {31},
keywords = {Latent Dirichlet allocation, Non-parametric topic modeling, Pseudo-relevance feedback, Query-likelihood model, Relevance model}
}

@article{10.1007/s10791-018-9328-z,
author = {Foka, Amalia F.},
title = {An Artist Ranking System Based on Social Media Mining},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9328-z},
doi = {10.1007/s10791-018-9328-z},
abstract = {Currently users on social media post their opinion and feelings about almost everything. This online behavior has led to numerous applications where social media data are used to measure public opinion in a similar way as a poll or a survey. In this paper, we will present an application of social media mining for the art market. To the best of our knowledge, this will be the first attempt to mine social media to extract quantitative and qualitative data for the art market. Although there are previous works on analyzing and predicting other markets, these methodologies cannot be applied directly to the art market. In our proposed methodology, artists will be treated as brands. That is, we will mine Twitter posts that mention specific artists' names and attempt to rank artists in a similar manner as brand equity and awareness would be measured. The particularities of the art market are considered mainly in the construction of a topic-specific user network where user expertise and influence is evaluated and later used to rank artists. The proposed ranking system is evaluated against two other available systems to identify the advantages it can offer.},
journal = {Inf. Retr.},
month = oct,
pages = {410–448},
numpages = {39},
keywords = {User influence, Art market, Social media mining, Social media user network, Topic identification, User expertise}
}

@article{10.1007/s10791-018-9327-0,
author = {Zamani, Hamed and Shakery, Azadeh},
title = {A Language Model-Based Framework for Multi-Publisher Content-Based Recommender Systems},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-018-9327-0},
doi = {10.1007/s10791-018-9327-0},
abstract = {The rapid growth of the Web has increased the difficulty of finding the information that can address the users' information needs. A number of recommendation approaches have been developed to tackle this problem. The increase in the number of data providers has necessitated the development of multi-publisher recommender systems; systems that include more than one item/data provider. In such environments, preserving the privacy of both publishers and subscribers is a key and challenging point. In this paper, we propose a multi-publisher framework for recommender systems based on a client---server architecture, which preserves the privacy of both data providers and subscribers. We develop our framework as a content-based filtering system using the statistical language modeling framework. We also introduce AUTO, a simple yet effective threshold optimization algorithm, to find a dissemination threshold for making acceptance and rejection decisions for new published documents. We further propose a language model sketching technique to reduce the network traffic between servers and clients in the proposed framework. Extensive experiments using the TREC-9 Filtering Track and the CLEF 2008-09 INFILE Track collections indicate the effectiveness of the proposed models in both single- and multi-publisher settings.},
journal = {Inf. Retr.},
month = oct,
pages = {369–409},
numpages = {41},
keywords = {Language models, Threshold optimization, Privacy preservation, Content-based recommender system, Multi-publisher recommendation, Adaptive filtering}
}

@article{10.1007/s10791-017-9326-6,
author = {Zingla, Meriem Amina and Latiri, Chiraz and Mulhem, Philippe and Berrut, Catherine and Slimani, Yahya},
title = {Hybrid Query Expansion Model for Text and Microblog Information Retrieval},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9326-6},
doi = {10.1007/s10791-017-9326-6},
abstract = {Query expansion (QE) is an important process in information retrieval applications that improves the user query and helps in retrieving relevant results. In this paper, we introduce a hybrid query expansion model (HQE) that investigates how external resources can be combined to association rules mining and used to enhance expansion terms generation and selection. The HQE model can be processed in different configurations, starting from methods based on association rules and combining it with external knowledge. The HQE model handles the two main phases of a QE process, namely: the candidate terms generation phase and the selection phase. We propose for the first phase, statistical, semantic and conceptual methods to generate new related terms for a given query. For the second phase, we introduce a similarity measure, ESAC, based on the Explicit Semantic Analysis that computes the relatedness between a query and the set of candidate terms. The performance of the proposed HQE model is evaluated within two experimental validations. The first one addresses the tweet search task proposed by TREC Microblog Track 2011 and an ad-hoc IR task related to the hard topics of the TREC Robust 2004. The second experimental validation concerns the tweet contextualization task organized by INEX 2014. Global results highlighted the effectiveness of our HQE model and of association rules mining for QE combined with external resources.},
journal = {Inf. Retr.},
month = aug,
pages = {337–367},
numpages = {31},
keywords = {dbpedia, Tweets search, Query expansion, Tweet contextualization, Ad-hoc IR task, Information retrieval, Association rules, Explicit Semantic Analysis, wikipedia}
}

@article{10.1007/s10791-017-9325-7,
author = {Hasanain, Maram and Suwaileh, Reem and Elsayed, Tamer and Kutlu, Mucahid and Almerekhi, Hind},
title = {EveTAR: Building a Large-Scale Multi-Task Test Collection over Arabic Tweets},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9325-7},
doi = {10.1007/s10791-017-9325-7},
abstract = {This article introduces a new language-independent approach for creating a large-scale high-quality test collection of tweets that supports multiple information retrieval (IR) tasks without running a shared-task campaign. The adopted approach (demonstrated over Arabic tweets) designs the collection around significant (i.e., popular) events, which enables the development of topics that represent frequent information needs of Twitter users for which rich content exists. That inherently facilitates the support of multiple tasks that generally revolve around events, namely event detection, ad-hoc search, timeline generation, and real-time summarization. The key highlights of the approach include diversifying the judgment pool via interactive search and multiple manually-crafted queries per topic, collecting high-quality annotations via crowd-workers for relevancy and in-house annotators for novelty, filtering out low-agreement topics and inaccessible tweets, and providing multiple subsets of the collection for better availability. Applying our methodology on Arabic tweets resulted in EveTAR, the first freely-available tweet test collection for multiple IR tasks. EveTAR includes a crawl of 355M Arabic tweets and covers 50 significant events for which about 62K tweets were judged with substantial average inter-annotator agreement (Kappa value of 0.71). We demonstrate the usability of EveTAR by evaluating existing algorithms in the respective tasks. Results indicate that the new collection can support reliable ranking of IR systems that is comparable to similar TREC collections, while providing strong baseline results for future studies over Arabic tweets.},
journal = {Inf. Retr.},
month = aug,
pages = {307–336},
numpages = {30},
keywords = {Microblogs, Dialects, Real-time summarization, Evaluation, Ad-hoc search, Timeline generation, Event detection, Twitter}
}

@article{10.1007/s10791-017-9324-8,
author = {Kotlerman, Lili and Dagan, Ido and Kurland, Oren},
title = {Clustering Small-Sized Collections of Short Texts},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9324-8},
doi = {10.1007/s10791-017-9324-8},
abstract = {The need to cluster small text corpora composed of a few hundreds of short texts rises in various applications; e.g., clustering top-retrieved documents based on their snippets. This clustering task is challenging due to the vocabulary mismatch between short texts and the insufficient corpus-based statistics (e.g., term co-occurrence statistics) due to the corpus size. We address this clustering challenge using a framework that utilizes a set of external knowledge resources that provide information about term relations. Specifically, we use information induced from the resources to estimate similarity between terms and produce term clusters. We also utilize the resources to expand the vocabulary used in the given corpus and thus enhance term clustering. We then project the texts in the corpus onto the term clusters to cluster the texts. We evaluate various instantiations of the proposed framework by varying the term clustering method used, the approach of projecting the texts onto the term clusters, and the way of applying external knowledge resources. Extensive empirical evaluation demonstrates the merits of our approach with respect to applying clustering algorithms directly on the text corpus, and using state-of-the-art co-clustering and topic modeling methods.},
journal = {Inf. Retr.},
month = aug,
pages = {273–306},
numpages = {34},
keywords = {Clustering, Short text similarities, Clustering short texts}
}

@article{10.1007/s10791-017-9320-z,
author = {Carvalho, Cristiano and Moura, Edleno Silva and Veloso, Adriano and Ziviani, Nivio},
title = {Website Replica Detection with Distant Supervision},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9320-z},
doi = {10.1007/s10791-017-9320-z},
abstract = {Duplicate content on the Web occurs within the same website or across multiple websites. The latter is mainly associated with the existence of website replicas--sites that are perceptibly similar. Replication may be accidental, intentional or malicious, but no matter the reason, search engines suffer greatly either from unnecessarily storing and moving duplicate data, or from providing search results that do not offer real value to the users. In this paper, we model the detection of website replicas as a pairwise classification problem with distant supervision. That is, (heuristically) finding obvious replica and non-replica cases is trivial, but learning effective classifiers requires a representative set of non-obvious labeled examples, which are hard to obtain. We employ efficient Expectation-Maximization (EM) algorithms in order to find non-obvious examples from obvious ones, enlarging the training-set and improving the classifiers iteratively. Our classifiers employ association rules, being thus incrementally updated as the EM process iterates, making our algorithms time-efficient. Experiments show that: (1) replicas are fully eliminated at a false-positive rate lower than 0.005, incurring in + 19% reduction in the number of duplicate URLs, (2) reduction increases to + 21% by using our site-level algorithms in conjunction with existing URL-level algorithms, and (3) our classifiers are more than two orders of magnitude faster than semi-supervised alternative solutions.},
journal = {Inf. Retr.},
month = aug,
pages = {253–272},
numpages = {20},
keywords = {Replica detection, Expectation-Maximization, Distant Supervision}
}

@article{10.1007/s10791-017-9323-9,
author = {Craswell, Nick and Croft, W. Bruce and Rijke, Maarten and Guo, Jiafeng and Mitra, Bhaskar},
title = {Neural Information Retrieval: Introduction to the Special Issue},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9323-9},
doi = {10.1007/s10791-017-9323-9},
journal = {Inf. Retr.},
month = jun,
pages = {107–110},
numpages = {4}
}

@article{10.1007/s10791-017-9321-y,
author = {Onal, Kezban Dilek and Zhang, Ye and Altingovde, Ismail Sengor and Rahman, Md Mustafizur and Karagoz, Pinar and Braylan, Alex and Dang, Brandon and Chang, Heng-Lu and Kim, Henna and Mcnamara, Quinten and Angert, Aaron and Banner, Edward and Khetan, Vivek and Mcdonnell, Tyler and Nguyen, An Thanh and Xu, Dan and Wallace, Byron C. and Rijke, Maarten and Lease, Matthew},
title = {Neural Information Retrieval: At the End of the Early Years},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9321-y},
doi = {10.1007/s10791-017-9321-y},
abstract = {A recent "third wave" of neural network (NN) approaches now delivers state-of-the-art performance in many machine learning tasks, spanning speech recognition, computer vision, and natural language processing. Because these modern NNs often comprise multiple interconnected layers, work in this area is often referred to as deep learning. Recent years have witnessed an explosive growth of research into NN-based approaches to information retrieval (IR). A significant body of work has now been created. In this paper, we survey the current landscape of Neural IR research, paying special attention to the use of learned distributed representations of textual units. We highlight the successes of neural IR thus far, catalog obstacles to its wider adoption, and suggest potentially promising directions for future research.},
journal = {Inf. Retr.},
month = jun,
pages = {111–182},
numpages = {72},
keywords = {Semantic compositionality, Semantic matching, Recurrent neural network, Deep learning, Word embedding, Search engine, Neural network, Distributed representation}
}

@article{10.1007/s10791-017-9319-5,
author = {Yang, Xiao and Macdonald, Craig and Ounis, Iadh},
title = {Using Word Embeddings in Twitter Election Classification},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9319-5},
doi = {10.1007/s10791-017-9319-5},
abstract = {Word embeddings and convolutional neural networks (CNN) have attracted extensive attention in various classification tasks for Twitter, e.g. sentiment classification. However, the effect of the configuration used to generate the word embeddings on the classification performance has not been studied in the existing literature. In this paper, using a Twitter election classification task that aims to detect election-related tweets, we investigate the impact of the background dataset used to train the embedding models, as well as the parameters of the word embedding training process, namely the context window size, the dimensionality and the number of negative samples, on the attained classification performance. By comparing the classification results of word embedding models that have been trained using different background corpora (e.g. Wikipedia articles and Twitter microposts), we show that the background data should align with the Twitter classification dataset both in data type and time period to achieve significantly better performance compared to baselines such as SVM with TF-IDF. Moreover, by evaluating the results of word embedding models trained using various context window sizes and dimensionalities, we find that large context window and dimension sizes are preferable to improve the performance. However, the number of negative samples parameter does not significantly affect the performance of the CNN classifiers. Our experimental results also show that choosing the correct word embedding model for use with CNN leads to statistically significant improvements over various baselines such as random, SVM with TF-IDF and SVM with word embeddings. Finally, for out-of-vocabulary (OOV) words that are not available in the learned word embedding models, we show that a simple OOV strategy to randomly initialise the OOV words without any prior knowledge is sufficient to attain a good classification performance among the current OOV strategies (e.g. a random initialisation using statistics of the pre-trained word embedding models).},
journal = {Inf. Retr.},
month = jun,
pages = {183–207},
numpages = {25},
keywords = {Word2vec, CNN, Election classification, Word embedding, Twitter}
}

@article{10.1007/s10791-017-9318-6,
author = {Carrara, Fabio and Esuli, Andrea and Fagni, Tiziano and Falchi, Fabrizio and Moreo Fern\'{a}ndez, Alejandro},
title = {Picture It in Your Mind: Generating High Level Visual Representations from Textual Descriptions},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9318-6},
doi = {10.1007/s10791-017-9318-6},
abstract = {In this paper we tackle the problem of image search when the query is a short textual description of the image the user is looking for. We choose to implement the actual search process as a similarity search in a visual feature space, by learning to translate a textual query into a visual representation. Searching in the visual feature space has the advantage that any update to the translation model does not require to reprocess the (typically huge) image collection on which the search is performed. We propose various neural network models of increasing complexity that learn to generate, from a short descriptive text, a high level visual representation in a visual feature space such as the pool5 layer of the ResNet-152 or the fc6---fc7 layers of an AlexNet trained on ILSVRC12 and Places databases. The Text2Vis models we explore include (1) a relatively simple regressor network relying on a bag-of-words representation for the textual descriptors, (2) a deep recurrent network that is sensible to word order, and (3) a wide and deep model that combines a stacked LSTM deep network with a wide regressor network. We compare the models we propose with other search strategies, also including textual search methods that exploit state-of-the-art caption generation models to index the image collection.},
journal = {Inf. Retr.},
month = jun,
pages = {208–229},
numpages = {22},
keywords = {Image retrieval, Text representation, Cross-media retrieval}
}

@article{10.1007/s10791-017-9317-7,
author = {Wang, Dongjing and Deng, Shuiguang and Xu, Guandong},
title = {Sequence-Based Context-Aware Music Recommendation},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9317-7},
doi = {10.1007/s10791-017-9317-7},
abstract = {Contextual factors greatly affect users' preferences for music, so they can benefit music recommendation and music retrieval. However, how to acquire and utilize the contextual information is still facing challenges. This paper proposes a novel approach for context-aware music recommendation, which infers users' preferences for music, and then recommends music pieces that fit their real-time requirements. Specifically, the proposed approach first learns the low dimensional representations of music pieces from users' music listening sequences using neural network models. Based on the learned representations, it then infers and models users' general and contextual preferences for music from users' historical listening records. Finally, music pieces in accordance with user's preferences are recommended to the target user. Extensive experiments are conducted on real world datasets to compare the proposed method with other state-of-the-art recommendation methods. The results demonstrate that the proposed method significantly outperforms those baselines, especially on sparse data.},
journal = {Inf. Retr.},
month = jun,
pages = {230–252},
numpages = {23},
keywords = {Recommender systems, Context-aware, Embedding, Sequence-based, Neural network}
}

@article{10.1007/s10791-017-9322-x,
author = {Imhof, Melanie and Braschler, Martin},
title = {A Study of Untrained Models for Multimodal Information Retrieval},
year = {2018},
issue_date = {February  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9322-x},
doi = {10.1007/s10791-017-9322-x},
abstract = {Operational multimodal information retrieval systems have to deal with increasingly complex document collections and queries that are composed of a large set of textual and non-textual modalities such as ratings, prices, timestamps, geographical coordinates, etc. The resulting combinatorial explosion of modality combinations makes it intractable to treat each modality individually and to obtain suitable training data. As a consequence, instead of finding and training new models for each individual modality or combination of modalities, it is crucial to establish unified models, and fuse their outputs in a robust way. Since the most popular weighting schemes for textual retrieval have in the past generalized well to many retrieval tasks, we demonstrate how they can be adapted to be used with non-textual modalities, which is a first step towards finding such a unified model. We demonstrate that the popular weighting scheme BM25 is suitable to be used for multimodal IR systems and analyze the underlying assumptions of the BM25 formula with respect to merging modalities under the so-called raw-score merging hypothesis, which requires no training. We establish a multimodal baseline for two multimodal test collections, show how modalities differ with respect to their contribution to relevance and the difficulty of treating modalities with overlapping information. Our experiments demonstrate that our multimodal baseline with no training achieves a significantly higher retrieval effectiveness than using just the textual modality for the social book search 2016 collection and lies in the range of a trained multimodal approach using the optimal linear combination of the modality scores.},
journal = {Inf. Retr.},
month = feb,
pages = {81–106},
numpages = {26},
keywords = {BM25, Multimodal information retrieval, Raw-score merging hypothesis}
}

@article{10.1007/s10791-017-9316-8,
author = {Yang, Grace Hui and Dong, Xuchu and Luo, Jiyun and Zhang, Sicong},
title = {Session Search Modeling by Partially Observable Markov Decision Process},
year = {2018},
issue_date = {February  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9316-8},
doi = {10.1007/s10791-017-9316-8},
abstract = {Session search, the task of document retrieval for a series of queries in a session, has been receiving increasing attention from the information retrieval research community. Session search exhibits the properties of rich user-system interactions and temporal dependency. These properties lead to our proposal of using partially observable Markov decision process to model session search. On the basis of a design choice schema for states, actions and rewards, we evaluate different combinations of these choices over the TREC 2012 and 2013 session track datasets. According to the experimental results, practical design recommendations for using PODMP in session search are discussed.},
journal = {Inf. Retr.},
month = feb,
pages = {56–80},
numpages = {25},
keywords = {Session search, Dynamic IR modeling, POMDP}
}

@article{10.1007/s10791-017-9314-x,
author = {Costa, Gianni and Ortale, Riccardo},
title = {Machine Learning Techniques for XML (Co-)Clustering by Structure-Constrained Phrases},
year = {2018},
issue_date = {February  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9314-x},
doi = {10.1007/s10791-017-9314-x},
abstract = {A new method is proposed for clustering XML documents by structure-constrained phrases. It is implemented by three machine-learning approaches previously unexplored in the XML domain, namely non-negative matrix (tri-)factorization, co-clustering and automatic transactional clustering. A novel class of XML features approximately captures structure-constrained phrases as n-grams contextualized by root-to-leaf paths. Experiments over real-world benchmark XML corpora show that the effectiveness of the three approaches improves with contextualized n-grams of suitable length. This confirms the validity of the devised method from multiple clustering perspectives. Two approaches overcome in effectiveness several state-of-the-art competitors. The scalability of the three approaches is investigated, too.},
journal = {Inf. Retr.},
month = feb,
pages = {24–55},
numpages = {32},
keywords = {Semi-structured data analysis, XML (co-)clustering by structure and nested text, Structure-constrained phrases, XML, Contextualized n-grams}
}

@article{10.1007/s10791-017-9313-y,
author = {Ganguly, Debasis and Jones, Gareth J. and Ram\'{\i}rez-De-La-Cruz, Aar\'{o}n and Ram\'{\i}rez-De-La-Rosa, Gabriela and Villatoro-Tello, Esa\'{u}},
title = {Retrieving and Classifying Instances of Source Code Plagiarism},
year = {2018},
issue_date = {February  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9313-y},
doi = {10.1007/s10791-017-9313-y},
abstract = {Automatic detection of source code plagiarism is an important research field for both the commercial software industry and within the research community. Existing methods of plagiarism detection primarily involve exhaustive pairwise document comparison, which does not scale well for large software collections. To achieve scalability, we approach the problem from an information retrieval (IR) perspective. We retrieve a ranked list of candidate documents in response to a pseudo-query representation constructed from each source code document in the collection. The challenge in source code document retrieval is that the standard bag-of-words (BoW) representation model for such documents is likely to result in many false positives being retrieved, because of the use of identical programming language specific constructs and keywords. To address this problem, we make use of an abstract syntax tree (AST) representation of the source code documents. While the IR approach is efficient, it is essentially unsupervised in nature. To further improve its effectiveness, we apply a supervised classifier (pre-trained with features extracted from sample plagiarized source code pairs) on the top ranked retrieved documents. We report experiments on the SOCO-2014 dataset comprising 12K Java source files with almost 1M lines of code. Our experiments confirm that the AST based approach produces significantly better retrieval effectiveness than a standard BoW representation, i.e., the AST based approach is able to identify a higher number of plagiarized source code documents at top ranks in response to a query source code document. The supervised classifier, trained on features extracted from sample plagiarized source code pairs, is shown to effectively filter and thus further improve the ranked list of retrieved candidate plagiarized documents.},
journal = {Inf. Retr.},
month = feb,
pages = {1–23},
numpages = {23},
keywords = {Source code plagiarism detection, Lexical, Field based indexing and retrieval, Document representation, Structural and stylistic features}
}

@article{10.1007/s10791-017-9312-z,
author = {Bellog\'{\i}n, Alejandro and Castells, Pablo and Cantador, Iv\'{a}n},
title = {Statistical Biases in Information Retrieval Metrics for Recommender Systems},
year = {2017},
issue_date = {December  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9312-z},
doi = {10.1007/s10791-017-9312-z},
abstract = {There is an increasing consensus in the Recommender Systems community that the dominant error-based evaluation metrics are insufficient, and mostly inadequate, to properly assess the practical effectiveness of recommendations. Seeking to evaluate recommendation rankings--which largely determine the effective accuracy in matching user needs--rather than predicted rating values, Information Retrieval metrics have started to be applied for the evaluation of recommender systems. In this paper we analyse the main issues and potential divergences in the application of Information Retrieval methodologies to recommender system evaluation, and provide a systematic characterisation of experimental design alternatives for this adaptation. We lay out an experimental configuration framework upon which we identify and analyse specific statistical biases arising in the adaptation of Information Retrieval metrics to recommendation tasks, namely sparsity and popularity biases. These biases considerably distort the empirical measurements, hindering the interpretation and comparison of results across experiments. We develop a formal characterisation and analysis of the biases upon which we analyse their causes and main factors, as well as their impact on evaluation metrics under different experimental configurations, illustrating the theoretical findings with empirical evidence. We propose two experimental design approaches that effectively neutralise such biases to a large extent. We report experiments validating our proposed experimental variants, and comparing them to alternative approaches and metrics that have been defined in the literature with similar or related purposes.},
journal = {Inf. Retr.},
month = dec,
pages = {606–634},
numpages = {29},
keywords = {Popularity bias, Sparsity bias, Cranfield, Evaluation, Recommender systems}
}

@article{10.1007/s10791-017-9311-0,
author = {Liu, Mengwen and Fang, Yi and Choulos, Alexander G. and Park, Dae Hoon and Hu, Xiaohua},
title = {Product Review Summarization through Question Retrieval and Diversification},
year = {2017},
issue_date = {December  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9311-0},
doi = {10.1007/s10791-017-9311-0},
abstract = {Product reviews have become an important resource for customers before they make purchase decisions. However, the abundance of reviews makes it difficult for customers to digest them and make informed choices. In our study, we aim to help customers who want to quickly capture the main idea of a lengthy product review before they read the details. In contrast with existing work on review analysis and document summarization, we aim to retrieve a set of real-world user questions to summarize a review. In this way, users would know what questions a given review can address and they may further read the review only if they have similar questions about the product. Specifically, we design a two-stage approach which consists of question selection and question diversification. For question selection phase, we first employ probabilistic retrieval models to locate candidate questions that are relevant to a given review. A Recurrent Neural Network Encoder---Decoder is utilized to measure the "answerability" of questions to a review. We then design a set function to re-rank the questions with the goal of rewarding diversity in the final question set. The set function satisfies submodularity and monotonicity, which results in an efficient greedy algorithm of submodular optimization. Evaluation on product reviews from two categories shows that the proposed approach is effective for discovering meaningful questions that are representative of individual reviews.},
journal = {Inf. Retr.},
month = dec,
pages = {575–605},
numpages = {31},
keywords = {Sequence-to-sequence learning, Diversity, Review summarization, Question retrieval}
}

@article{10.1007/s10791-017-9307-9,
author = {Zhuang, Xu and Zhu, Yan and Chang, Chin-Chen and Peng, Qiang and Khurshid, Faisal},
title = {A Unified Score Propagation Model for Web Spam Demotion Algorithm},
year = {2017},
issue_date = {December  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9307-9},
doi = {10.1007/s10791-017-9307-9},
abstract = {Web spam pages exploit the biases of search engine algorithms to get higher than their deserved rankings in search results by using several types of spamming techniques. Many web spam demotion algorithms have been developed to combat spam via the use of the web link structure, from which the goodness or badness score of each web page is evaluated. Those scores are then used to identify spam pages or punish their rankings in search engine results. However, most of the published spam demotion algorithms differ from their base models by only very limited improvements and still suffer from some common score manipulation methods. The lack of a general framework for this field makes the task of designing high-performance spam demotion algorithms very inefficient. In this paper, we propose a unified score propagation model for web spam demotion algorithms by abstracting the score propagation process of relevant models with a forward score propagation function and a backward score propagation function, each of which can further be expressed as three sub-functions: a splitting function, an accepting function and a combination function. On the basis of the proposed model, we develop two new web spam demotion algorithms named Supervised Forward and Backward score Ranking (SFBR) and Unsupervised Forward and Backward score Ranking (UFBR). Our experiments, conducted on three large-scale public datasets, show that (1) SFBR is very robust and apparently outperforms other algorithms and (2) UFBR can obtain results comparable to some well-known supervised algorithms in the spam demotion task even if the UFBR is unsupervised.},
journal = {Inf. Retr.},
month = dec,
pages = {547–574},
numpages = {28},
keywords = {Spam detection, Web ranking algorithms, Web scoring system, Web spam demotion}
}

@article{10.1007/s10791-017-9315-9,
author = {Eickhoff, Carsten and Gwizdka, Jacek and Hauff, Claudia and He, Jiyin},
title = {Introduction to the Special Issue on Search as Learning},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9315-9},
doi = {10.1007/s10791-017-9315-9},
journal = {Inf. Retr.},
month = oct,
pages = {399–402},
numpages = {4}
}

@article{10.1007/s10791-017-9310-1,
author = {Azpiazu, Ion Madrazo and Dragovic, Nevena and Pera, Maria Soledad and Fails, Jerry Alan},
title = {Online Searching and Learning: YUM and Other Search Tools for Children and Teachers},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9310-1},
doi = {10.1007/s10791-017-9310-1},
abstract = {Information discovery tasks using online search tools are performed on a regular basis by school-age children. However, these tools are not necessarily designed to both explicitly facilitate the retrieval of resources these young users can comprehend and aid low-literacy searchers. This is of particular concern for educational environments, as there is an inherent expectation that these tools facilitate effective learning. In this manuscript we present an initial assessment conducted over (1) children-oriented search tools based on queries generated by K-9 students, analyzing features such as readability and adequacy of retrieved results, and (2) tools used by teachers in their classrooms, analyzing their main purpose and target audience's age range. Among the examined tools, we include YouUnderstood.Me, an enhanced search environment, which is the result of our ongoing efforts on the development of a search environment tailored to 5-15 year-olds that can foster learning through the retrieval of materials that not only satisfy the information needs of these users but also match their reading abilities. The results of these studies highlight the fact that search results presented to children have average reading levels that do not match the target audience. In addition, tools oriented to teachers do not go beyond showing the progress of their students, and seldomly provide a simple way of retrieving class contents that fit current needs of students. These facts further showcase the need for developing a dual environment oriented to both teachers and students.},
journal = {Inf. Retr.},
month = oct,
pages = {524–545},
numpages = {22},
keywords = {Children, Personalization, Teachers, Search as learning}
}

@article{10.1007/s10791-017-9308-8,
author = {Karanam, Saraschandra and Jorge-Botana, Guillermo and Olmos, Ricardo and Oostendorp, Herre},
title = {The Role of Domain Knowledge in Cognitive Modeling of Information Search},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9308-8},
doi = {10.1007/s10791-017-9308-8},
abstract = {Computational cognitive models developed so far do not incorporate individual differences in domain knowledge in predicting user clicks on search result pages. We address this problem using a cognitive model of information search which enables us to use two semantic spaces having a low (non-expert semantic space) and a high (expert semantic space) amount of medical and health related information to represent respectively low and high knowledge of users in this domain. We also investigated two different processes along which one can gain a larger amount of knowledge in a domain: an evolutionary and a common core process. Simulations of model click behavior on difficult information search tasks and subsequent matching with actual behavioral data from users (divided into low and high domain knowledge groups based on a domain knowledge test) were conducted. Results showed that the efficacy of modeling for high domain knowledge participants (in terms of the number of matches between the model predictions and the actual user clicks on search result pages) was higher with the expert semantic space compared to the non-expert semantic space while for low domain knowledge participants it was the other way around. When the process of knowledge acquisition was taken into account, the effect of using a semantic space based on high domain knowledge was significant only for high domain knowledge participants, irrespective of the knowledge acquisition process. The implications of these outcomes for support tools that can be built based on these models are discussed.},
journal = {Inf. Retr.},
month = oct,
pages = {456–479},
numpages = {24},
keywords = {Domain knowledge, Knowledge acquisition, Corpus, Information search, Semantic space, Cognitive modeling}
}

@article{10.1007/s10791-017-9306-x,
author = {Kodama, Christie and St. Jean, Beth and Subramaniam, Mega and Taylor, Natalie Greene},
title = {There's a Creepy Guy on the Other End at Google! Engaging Middle School Students in a Drawing Activity to Elicit Their Mental Models of Google},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9306-x},
doi = {10.1007/s10791-017-9306-x},
abstract = {Although youth are increasingly going online to fulfill their needs for information, many youth struggle with information and digital literacy skills, such as the abilities to conduct a search and assess the credibility of online information. Ideally, these skills encompass an accurate and comprehensive understanding of the ways in which a system, such as a Web search engine, functions. In order to investigate youths' conceptions of the Google search engine, a drawing activity was conducted with 26 HackHealth after-school program participants to elicit their mental models of Google. The findings revealed that many participants personified Google and emphasized anthropomorphic elements, computing equipment, and/or connections (such as cables, satellites and antennas) in their drawings. Far fewer participants focused their drawings on the actual Google interface or on computer code. Overall, their drawings suggest a limited understanding of Google and the ways in which it actually works. However, an understanding of youths' conceptions of Google can enable educators to better tailor their digital literacy instruction efforts and can inform search engine developers and search engine interface designers in making the inner workings of the engine more transparent and their output more trustworthy to young users. With a better understanding of how Google works, young users will be better able to construct effective queries, assess search results, and ultimately find relevant and trustworthy information that will be of use to them.},
journal = {Inf. Retr.},
month = oct,
pages = {403–432},
numpages = {30},
keywords = {Information retrieval, Digital youth, Youth information seeking, Internet searching, Mental models, Adolescents}
}

@article{10.1007/s10791-017-9305-y,
author = {Lu, Yihan and Hsiao, I-Han},
title = {Personalized Information Seeking Assistant (PiSA): From Programming Information Seeking to Learning},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9305-y},
doi = {10.1007/s10791-017-9305-y},
abstract = {Online programming discussion forums have grown increasingly and formed sizable repositories of problem-solving solutions. In this paper, we investigate programming learners' information seeking behaviors in online discussion forums, and provide visual navigational support to facilitate information seeking. We design engines to collect students' information seeking behaviors, and model these behaviors with sequence pattern mining techniques. The results show that programming learners indeed seek for information from discussion forums by actively search and read progressively according to course schedule topics. Advanced students consistently perform query refinements, examine search results and commit to read, however, novices do not. Finally, according to the lessons learned, we propose, design and evaluate Personalized Information Seeking Assistant system to help query refinement by summarizing the search results and to provide social-based browsing history. Findings suggest that paying attention to the query history may lead to further reading events, which subsequently resulting in potential learning activities.},
journal = {Inf. Retr.},
month = oct,
pages = {433–455},
numpages = {23},
keywords = {Computing education, Novice programming learning, Behavior modeling, Information seeking behavior}
}

@article{10.1007/s10791-017-9304-z,
author = {Knight, Simon and Rienties, Bart and Littleton, Karen and Tempelaar, Dirk and Mitsui, Matthew and Shah, Chirag},
title = {The Orchestration of a Collaborative Information Seeking Learning Task},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9304-z},
doi = {10.1007/s10791-017-9304-z},
abstract = {The paper describes our novel perspective on `searching to learn' through collaborative information seeking (CIS). We describe this perspective, which motivated empirical work to `orchestrate' a CIS searching to learn session. The work is described through the lens of orchestration, an approach which brings to the fore the ways in which: background context--including practical classroom constraints, and theoretical perspective; actors--including the educators, researchers, and technologies; and activities that are to be completed, are brought into alignment. The orchestration is exemplified through the description of research work designed to explore a pedagogically salient construct (epistemic cognition), in a particular institutional setting. Evaluation of the session indicated satisfaction with the orchestration from students, with written feedback indicating reflection from them on features of the orchestration. We foreground this approach to demonstrate the potential of orchestration as a design approach for researching and implementing CIS as a `searching to learn' context.},
journal = {Inf. Retr.},
month = oct,
pages = {480–505},
numpages = {26},
keywords = {Searching to learn, Educational technology, Computer supported collaborative learning, Collaborative information seeking}
}

@article{10.1007/s10791-017-9303-0,
author = {Syed, Rohail and Collins-Thompson, Kevyn},
title = {Optimizing Search Results for Human Learning Goals},
year = {2017},
issue_date = {October   2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9303-0},
doi = {10.1007/s10791-017-9303-0},
abstract = {While past research has shown that learning outcomes can be influenced by the amount of effort students invest during the learning process, there has been little research into this question for scenarios where people use search engines to learn. In fact, learning-related tasks represent a significant fraction of the time users spend using Web search, so methods for evaluating and optimizing search engines to maximize learning are likely to have broad impact. Thus, we introduce and evaluate a retrieval algorithm designed to maximize educational utility for a vocabulary learning task, in which users learn a set of important keywords for a given topic by reading representative documents on diverse aspects of the topic. Using a crowdsourced pilot study, we compare the learning outcomes of users across four conditions corresponding to rankings that optimize for different levels of keyword density. We find that adding keyword density to the retrieval objective gave significant learning gains on some topics, with higher levels of keyword density generally corresponding to more time spent reading per word, and stronger learning gains per word read. We conclude that our approach to optimizing search ranking for educational utility leads to retrieved document sets that ultimately may result in more efficient learning of important concepts.},
journal = {Inf. Retr.},
month = oct,
pages = {506–523},
numpages = {18},
keywords = {Intrinsic diversity, Assessment of learning in search, Retrieval models and ranking}
}

@article{10.1007/s10791-017-9302-1,
author = {Campos, Ricardo and Dias, Ga\"{e}l and Jorge, Al\'{\i}pio M\'{a}rio and Nunes, C\'{e}lia},
title = {Identifying Top Relevant Dates for Implicit Time Sensitive Queries},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9302-1},
doi = {10.1007/s10791-017-9302-1},
abstract = {Despite a clear improvement of search and retrieval temporal applications, current search engines are still mostly unaware of the temporal dimension. Indeed, in most cases, systems are limited to offering the user the chance to restrict the search to a particular time period or to simply rely on an explicitly specified time span. If the user is not explicit in his/her search intents (e.g., "philip seymour hoffman") search engines may likely fail to present an overall historic perspective of the topic. In most such cases, they are limited to retrieving the most recent results. One possible solution to this shortcoming is to understand the different time periods of the query. In this context, most state-of-the-art methodologies consider any occurrence of temporal expressions in web documents and other web data as equally relevant to an implicit time sensitive query. To approach this problem in a more adequate manner, we propose in this paper the detection of relevant temporal expressions to the query. Unlike previous metadata and query log-based approaches, we show how to achieve this goal based on information extracted from document content. However, instead of simply focusing on the detection of the most obvious date we are also interested in retrieving the set of dates that are relevant to the query. Towards this goal, we define a general similarity measure that makes use of co-occurrences of words and years based on corpus statistics and a classification methodology that is able to identify the set of top relevant dates for a given implicit time sensitive query, while filtering out the non-relevant ones. Through extensive experimental evaluation, we mean to demonstrate that our approach offers promising results in the field of temporal information retrieval (T-IR), as demonstrated by the experiments conducted over several baselines on web corpora collections.},
journal = {Inf. Retr.},
month = aug,
pages = {363–398},
numpages = {36},
keywords = {Relevant temporal expressions, Temporal query understanding, Implicit time sensitive queries, Temporal information retrieval}
}

@article{10.1007/s10791-017-9301-2,
author = {P\"{a}\"{a}kk\"{o}nen, Teemu and Kek\"{a}l\"{a}inen, Jaana and Keskustalo, Heikki and Azzopardi, Leif and Maxwell, David and J\"{a}rvelin, Kalervo},
title = {Validating Simulated Interaction for Retrieval Evaluation},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9301-2},
doi = {10.1007/s10791-017-9301-2},
abstract = {
A searcher's interaction with a retrieval system consists of actions such as query formulation, search result list interaction and document interaction. The simulation of searcher interaction has recently gained momentum in the analysis and evaluation of interactive information retrieval (IIR). However, a key issue that has not yet been adequately addressed is the validity of such IIR simulations and whether they reliably predict the performance obtained by a searcher across the session. The aim of this paper is to determine the validity of the common interaction model (CIM) typically used for simulating multi-query sessions. We focus on search result interactions, i.e., inspecting snippets, examining documents and deciding when to stop examining the results of a single query, or when to stop the whole session. To this end, we run a series of simulations grounded by real world behavioral data to show how accurate and responsive the model is to various experimental conditions under which the data were produced.
 We then validate on a second real world data set derived under similar experimental conditions. We seek to predict cumulated gain across the session. We find that the interaction model with a query-level stopping strategy based on consecutive non-relevant snippets leads to the highest prediction accuracy, and lowest deviation from ground truth, around 9 to 15% depending on the experimental conditions. To our knowledge, the present study is the first validation effort of the CIM that shows that the model's acceptance and use is justified within IIR evaluations. We also identify and discuss ways to further improve the CIM and its behavioral parameters for more accurate simulations.},
journal = {Inf. Retr.},
month = aug,
pages = {338–362},
numpages = {25},
keywords = {Session-based evaluation, IR interaction, Simulation}
}

@article{10.1007/s10791-017-9300-3,
author = {Zhou, Xing and Ding, Lixin and Li, Zhaokui and Wan, Runze},
title = {Collaborator Recommendation in Heterogeneous Bibliographic Networks Using Random Walks},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9300-3},
doi = {10.1007/s10791-017-9300-3},
abstract = {The increasingly growing popularity of the collaboration among researchers and the increasing information overload in big scholarly data make it imperative to develop a collaborator recommendation system for researchers to find potential partners. Existing works always study this task as a link prediction problem in a homogeneous network with a single object type (i.e., author) and a single link type (i.e., co-authorship). However, a real-world academic social network often involves several object types, e.g., papers, terms, and venues, as well as multiple relationships among different objects. This paper proposes a RWR-CR (standing for random walk with restart-based collaborator recommendation) algorithm in a heterogeneous bibliographic network towards this problem. First, we construct a heterogeneous network with multiple types of nodes and links with a simplified network structure by removing the citing paper nodes. Then, two importance measures are used to weight edges in the network, which will bias a random walker's behaviors. Finally, we employ a random walk with restart to retrieve relevant authors and output an ordered recommendation list in terms of ranking scores.
 Experimental results on DBLP and hep-th datasets demonstrate the effectiveness of our methodology and its promising performance in collaborator prediction.},
journal = {Inf. Retr.},
month = aug,
pages = {317–337},
numpages = {21},
keywords = {Collaborator recommendation, Random walk with restart, Link prediction, Heterogeneous bibliographic network, Importance measure}
}

@article{10.1007/s10791-017-9309-7,
author = {Hawking, David and Moffat, Alistair and Trotman, Andrew},
title = {Efficiency in Information Retrieval: Introduction to Special Issue},
year = {2017},
issue_date = {June      2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9309-7},
doi = {10.1007/s10791-017-9309-7},
journal = {Inf. Retr.},
month = jun,
pages = {169–171},
numpages = {3}
}

@article{10.1007/s10791-017-9299-5,
author = {Tolosa, Gabriel and Feuerstein, Esteban and Becchetti, Luca and Marchetti-Spaccamela, Alberto},
title = {Performance Improvements for Search Systems Using an Integrated Cache of Lists + Intersections},
year = {2017},
issue_date = {June      2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9299-5},
doi = {10.1007/s10791-017-9299-5},
abstract = {Modern information retrieval systems use several levels of caching to speedup computation by exploiting frequent, recent or costly data used in the past. Previous studies show that the use of caching techniques is crucial in search engines, as it helps reducing query response times and processing workloads on search servers. In this work we propose and evaluate a static cache that acts simultaneously as list and intersection cache, offering a more efficient way of handling cache space. We also use a query resolution strategy that takes advantage of the existence of this cache to reorder the query execution sequence. In addition, we propose effective strategies to select the term pairs that should populate the cache. We also represent the data in cache in both raw and compressed forms and evaluate the differences between them using different configurations of cache sizes. The results show that the proposed Integrated Cache outperforms the standard posting lists cache in most of the cases, taking advantage not only of the intersection cache but also the query resolution strategy.},
journal = {Inf. Retr.},
month = jun,
pages = {172–198},
numpages = {27},
keywords = {Caching, Information retrieval systems, Integrated cache, Performance improvement}
}

@article{10.1007/s10791-017-9298-6,
author = {Daoud, Caio Moura and Moura, Edleno Silva and Fernandes, David and Silva, Altigran Soares and Rossi, Cristian and Carvalho, Andre},
title = {Waves: A Fast Multi-Tier Top-k Query Processing Algorithm},
year = {2017},
issue_date = {June      2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9298-6},
doi = {10.1007/s10791-017-9298-6},
abstract = {In this paper, we present Waves, a novel document-at-a-time algorithm for fast computing of top-k query results in search systems. The Waves algorithm uses multi-tier indexes for processing queries. It performs successive tentative evaluations of results which we call waves. Each wave traverses the index, starting from a specific tier level i. Each wave i may insert only those documents that occur in that tier level into the answer. After processing a wave, the algorithm checks whether the answer achieved might be changed by successive waves or not. A new wave is started only if it has a chance of changing the top-k scores. We show through experiments that such lazy query processing strategy results in smaller query processing times when compared to previous approaches proposed in the literature. We present experiments to compare Waves' performance to the state-of-the-art document-at-a-time query processing methods that preserve top-k results and show scenarios where the method can be a good alternative algorithm for computing top-k results.},
journal = {Inf. Retr.},
month = jun,
pages = {292–316},
numpages = {25},
keywords = {Query processing, Information retrieval, Search system}
}

@article{10.1007/s10791-017-9297-7,
author = {Gagie, Travis and Hartikainen, Aleksi and Karhu, Kalle and K\"{a}rkk\"{a}inen, Juha and Navarro, Gonzalo and Puglisi, Simon J. and Sir\'{e}n, Jouni},
title = {Document Retrieval on Repetitive String Collections},
year = {2017},
issue_date = {June      2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9297-7},
doi = {10.1007/s10791-017-9297-7},
abstract = {Most of the fastest-growing string collections today are repetitive, that is, most of the constituent documents are similar to many others. As these collections keep growing, a key approach to handling them is to exploit their repetitiveness, which can reduce their space usage by orders of magnitude. We study the problem of indexing repetitive string collections in order to perform efficient document retrieval operations on them. Document retrieval problems are routinely solved by search engines on large natural language collections, but the techniques are less developed on generic string collections. The case of repetitive string collections is even less understood, and there are very few existing solutions. We develop two novel ideas, interleaved LCPs and precomputed document lists, that yield highly compressed indexes solving the problem of document listing (find all the documents where a string appears), top-k document retrieval (find the k documents where a string appears most often), and document counting (count the number of documents where a string appears). We also show that a classical data structure supporting the latter query becomes highly compressible on repetitive data. Finally, we show how the tools we developed can be combined to solve ranked conjunctive and disjunctive multi-term queries under the simple $${textsf{tf}}{textsf{-}}{textsf{idf}}$$tf-idf model of relevance. We thoroughly evaluate the resulting techniques in various real-life repetitiveness scenarios, and recommend the best choices for each case.},
journal = {Inf. Retr.},
month = jun,
pages = {253–291},
numpages = {39},
keywords = {Document retrieval on strings, Suffix trees and arrays, Repetitive string collections}
}

@article{10.1007/s10791-016-9291-5,
author = {Lin, Jimmy and Trotman, Andrew},
title = {The Role of Index Compression in Score-at-a-Time Query Evaluation},
year = {2017},
issue_date = {June      2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9291-5},
doi = {10.1007/s10791-016-9291-5},
abstract = {This paper explores the performance of top k document retrieval with score-at-a-time query evaluation on impact-ordered indexes in main memory. To better understand execution efficiency in the context of modern processor architectures, we examine the role of index compression on query evaluation latency. Experiments include compressing postings with variable byte encoding, Simple-8b, variants of the QMX compression scheme, as well as a condition that is less often considered--no compression. Across four web test collections, we find that the highest query evaluation speed is achieved by simply leaving the postings lists uncompressed, although the performance advantage over a state-of-the-art compression scheme is relatively small and the index is considerably larger. We explain this finding in terms of the design of modern processor architectures: Index segments with high impact scores are usually short and inherently benefit from cache locality. Index segments with lower impact scores may be quite long, but modern architectures have sufficient memory bandwidth (coupled with prefetching) to "keep up" with the processor. Our results highlight the importance of "architecture affinity" when designing high-performance search engines.},
journal = {Inf. Retr.},
month = jun,
pages = {199–220},
numpages = {22}
}

@article{10.1007/s10791-016-9290-6,
author = {Kim, Yubin and Callan, Jamie and Culpepper, J. Shane and Moffat, Alistair},
title = {Efficient Distributed Selective Search},
year = {2017},
issue_date = {June      2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9290-6},
doi = {10.1007/s10791-016-9290-6},
abstract = {Simulation and analysis have shown that selective search can reduce the cost of large-scale distributed information retrieval. 
By partitioning the collection into small topical shards, and then using a resource ranking algorithm to choose a subset of shards to search for each query, fewer postings are evaluated. 
In this paper we extend the study of selective search into new areas using a fine-grained simulation, examining the difference in efficiency when term-based and sample-based resource selection algorithms are used; measuring the effect of two policies for assigning index shards to machines; and exploring the benefits of index-spreading and mirroring as the number of deployed machines is varied. Results obtained for two large datasets and four large query logs confirm that selective search is significantly more efficient than conventional distributed search architectures and can handle higher query rates. Furthermore, we demonstrate that selective search can be tuned to avoid bottlenecks, and thus maximize usage of the underlying computer hardware.},
journal = {Inf. Retr.},
month = jun,
pages = {221–252},
numpages = {32},
keywords = {Selective search, Load balancing, Efficiency, Distributed search}
}

@article{10.1007/s10791-017-9296-8,
author = {Kristianto, Giovanni Yoko and Topi\'{c}, Goran and Aizawa, Akiko},
title = {Utilizing Dependency Relationships between Math Expressions in Math IR},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9296-8},
doi = {10.1007/s10791-017-9296-8},
abstract = {Current mathematical search systems allow math expressions within a document to be queried using math expressions and keywords. To accept such queries, math search systems must index both math expressions and textual information in documents. Each indexed math expression is usually associated with all the words in its surrounding context within a given window size. However, we found that this context is often ineffective for explaining math expressions in scientific papers. The meaning of an expression is usually defined in the early part of a document, and the meaning of each symbol contained in the expression can be useful for explaining the entire expression. This explanation may not be captured within the context of a math expression, unless we set the context to have a very wide window size. However, widening the window size also increases the proportion of words that are unrelated to the expression. This paper proposes the use of dependency relationships between math expressions to enrich the textual information of each expression. We examine the influence of this enrichment in a math search system. The experimental results show that significantly better precision can be obtained using the enriched textual information rather than the math expressions' own textual information. This indicates that the enrichment of textual information for each math expression using dependency relationships enhances the math search system.},
journal = {Inf. Retr.},
month = apr,
pages = {132–167},
numpages = {36},
keywords = {Dependency graph, Mathematical information retrieval, Mathematical expression encoding, Contextual information}
}

@article{10.1007/s10791-017-9295-9,
author = {Ebesu, Travis and Fang, Yi},
title = {Neural Semantic Personalized Ranking for Item Cold-Start Recommendation},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9295-9},
doi = {10.1007/s10791-017-9295-9},
abstract = {Recommender systems help users deal with information overload and enjoy a personalized experience on the Web. One of the main challenges in these systems is the item cold-start problem which is very common in practice since modern online platforms have thousands of new items published every day. Furthermore, in many real-world scenarios, the item recommendation tasks are based on users' implicit preference feedback such as whether a user has interacted with an item. To address the above challenges, we propose a probabilistic modeling approach called Neural Semantic Personalized Ranking (NSPR) to unify the strengths of deep neural network and pairwise learning. Specifically, NSPR tightly couples a latent factor model with a deep neural network to learn a robust feature representation from both implicit feedback and item content, consequently allowing our model to generalize to unseen items. We demonstrate NSPR's versatility to integrate various pairwise probability functions and propose two variants based on the Logistic and Probit functions. We conduct a comprehensive set of experiments on two real-world public datasets and demonstrate that NSPR significantly outperforms the state-of-the-art baselines.},
journal = {Inf. Retr.},
month = apr,
pages = {109–131},
numpages = {23},
keywords = {Pairwise learning, Recommender systems, Implicit feedback, Deep neural network}
}

@article{10.1007/s10791-017-9293-y,
author = {Liu, Mengwen and Ding, Wanying and Park, Dae Hoon and Fang, Yi and Yan, Rui and Hu, Xiaohua},
title = {Which Used Product is More Sellable? A Time-Aware Approach},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9293-y},
doi = {10.1007/s10791-017-9293-y},
abstract = {A number of online marketplaces enable customers to buy or sell used products, which raises the need for ranking tools to help them find desirable items among a huge pool of choices. To the best of our knowledge, no prior work in the literature has investigated the task of used product ranking which has its unique characteristics compared with regular product ranking. While there exist a few ranking metrics (e.g., price, conversion probability) that measure the "goodness" of a product, they do not consider the time factor, which is crucial in used product trading due to the fact that each used product is often unique while new products are usually abundant in supply or quantity. In this paper, we introduce a novel time-aware metric--"sellability", which is defined as the time duration for a used item to be traded, to quantify the value of it. In order to estimate the "sellability" values for newly generated used products and to present users with a ranked list of the most relevant results, we propose a combined Poisson regression and listwise ranking model. The model has a good property in fitting the distribution of "sellability". In addition, the model is designed to optimize loss functions for regression and ranking simultaneously, which is different from previous approaches that are conventionally learned with a single cost function, i.e., regression or ranking. We evaluate our approach in the domain of used vehicles. Experimental results show that the proposed model can improve both regression and ranking performance compared with non-machine learning and machine learning baselines.},
journal = {Inf. Retr.},
month = apr,
pages = {81–108},
numpages = {28},
keywords = {Used product ranking, Learning to rank, Implicit feedback}
}

@article{10.1007/s10791-017-9294-x,
author = {Liu, Yiqun and Nie, Jian-Yun and Chang, Yi},
title = {Constructing Click Models for Search Users},
year = {2017},
issue_date = {February  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9294-x},
doi = {10.1007/s10791-017-9294-x},
journal = {Inf. Retr.},
month = feb,
pages = {1–3},
numpages = {3}
}

@article{10.1007/s10791-016-9292-4,
author = {Liu, Zeyang and Mao, Jiaxin and Wang, Chao and Ai, Qingyao and Liu, Yiqun and Nie, Jian-Yun},
title = {Enhancing Click Models with Mouse Movement Information},
year = {2017},
issue_date = {February  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9292-4},
doi = {10.1007/s10791-016-9292-4},
abstract = {User interactions in Web search, in particular, clicks, provide valuable hints on document relevance; but the signals are very noisy. In order to better understand user click behaviors and to infer the implied relevance, various click models have been proposed, each relying on some hypotheses and involving different hidden events (e.g. examination).
 In almost all the existing click models, it is assumed that clicks are the only observable evidence and the examinations of documents are deduced from it. However, with an increasing number of embedded heterogeneous components (e.g. verticals) on Search Engine Result Pages, click information is not sufficient to draw a complete picture of process of user examination, especially in federated search scenario. In practice, we can also collect mouse movement information, which has proven to have a strong correlation with examination. In this paper, we propose to incorporate mouse movement information into existing click models to enhance the estimation of examination. The enhanced click models are shown to have a better ability to predict both user clicks and document relevance, than the original models. The collection of mouse movement information has been implemented in a commercial search engine, showing the feasibility of the approach in practice.
},
journal = {Inf. Retr.},
month = feb,
pages = {53–80},
numpages = {28},
keywords = {Federated search, Search engine, Click model, Mouse movement}
}

@article{10.1007/s10791-016-9289-z,
author = {Yu, Hai-Tao and Jatowt, Adam and Blanco, Roi and Joho, Hideo and Jose, Joemon M.},
title = {Decoding Multi-Click Search Behavior Based on Marginal Utility},
year = {2017},
issue_date = {February  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9289-z},
doi = {10.1007/s10791-016-9289-z},
abstract = {Query logs contain rich feedback information from users interacting with search engines. Therefore, various click models have been developed to interpret users' search behavior and to extract useful knowledge from query logs. However, most existing models are not designed to consider novelty bias in click behavior. The underlying hypothesis behind this paper is that given the previously clicked documents, a user tends to choose documents which provide novel relevant information to satisfy her information need, rather than redundant relevant information. Moreover, the prior click models have been mainly tested on frequently occurring queries, hence, leaving a large proportion of sparse queries uncovered. In this paper, we propose to predict users' click behavior from the perspective of utility theory (i.e., utility and marginal utility). In particular, as a complement to the examination hypothesis, we introduce a new hypothesis called marginal utility hypothesis to characterize the effect of novelty bias on users' click behavior by exploring the semantic divergence among documents in a result list. Moreover, to cope with sparse or unseen queries that have not been observed in the training set, we use a set of descriptive features to quantify the probability of a document being relevant and probability of a document providing marginally (novel) useful information. Finally, a series of experiments are conducted on a real-world data set to validate the effectiveness of the proposed methods. The experimental results verify the effectiveness of interpreting users' click behavior based on the marginal utility hypothesis, especially when query sessions contain sparse queries or unseen query-document pairs.},
journal = {Inf. Retr.},
month = feb,
pages = {25–52},
numpages = {28},
keywords = {Query session, Click model, Novelty bias, Marginal utility}
}

@article{10.1007/s10791-016-9287-1,
author = {Guo, Jiafeng and Zhu, Xiaofei and Lan, Yanyan and Cheng, Xueqi},
title = {Modeling Users' Search Sessions for High Utility Query Recommendation},
year = {2017},
issue_date = {February  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9287-1},
doi = {10.1007/s10791-016-9287-1},
abstract = {Query recommendation has long been considered a key feature of search engines, which can improve users' search experience by providing useful query suggestions for their search tasks. Most existing approaches on query recommendation aim to recommend relevant queries, i.e., alternative queries similar to a user's initial query. However, the ultimate goal of query recommendation is to assist users to reformulate queries so that they can accomplish their search task successfully and quickly. Only considering relevance in query recommendation is apparently not directly toward this goal. In this paper, we argue that it is more important to directly recommend queries with high utility, i.e., queries that can better satisfy users' information needs. For this purpose, we attempt to infer query utility from users' sequential search behaviors recorded in their search sessions. Specifically, we propose a dynamic Bayesian network, referred as Query Utility Model (QUM), to capture query utility by simultaneously modeling users' reformulation and click behaviors. We then recommend queries with high utility to help users better accomplish their search tasks. We empirically evaluated the performance of our approach on a publicly released query log by comparing with the state-of-the-art methods. The experimental results show that, by recommending high utility queries, our approach is far more effective in helping users find relevant search results and thus satisfying their information needs.},
journal = {Inf. Retr.},
month = feb,
pages = {4–24},
numpages = {21},
keywords = {Query recommendation, Query utility, Search behavior, Dynamic Bayesian network}
}

@article{10.1007/s10791-016-9288-0,
author = {Song, Ruihua and Wang, Dingquan and Nie, Jian-Yun and Wen, Ji-Rong and Yu, Yong},
title = {Enhancing Web Search with Queries of Equivalent Intents},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9288-0},
doi = {10.1007/s10791-016-9288-0},
abstract = {Users often issue all kinds of queries to look for the same target due to the intrinsic ambiguity and flexibility of natural languages. Some previous work clusters queries based on co-clicks; however, the intents of queries in one cluster are not that similar but roughly related. It is desirable to conduct automatic mining of queries with equivalent intents from a large scale search logs. In this paper, we take account of similarities between query strings. There are two issues associated with such similarities: it is too costly to compare any pair of queries in large scale search logs, and two queries with a similar formulation, such as "SVN" (Apache Subversion) and support vector machine (SVM), are not necessarily similar in their intents. To address these issues, we propose using the similarities of query strings above the co-click based clustering results. Our method improves precision over the co-click based clustering method (lifting precision from 0.37 to 0.62), and outperforms a commercial search engine's query alteration (lifting $$F_1$$F1 measure from 0.42 to 0.56). As an application, we consider web document retrieval. We aggregate similar queries' click-throughs with the query's click-throughs and evaluate them on a large scale dataset. Experimental results indicate that our proposed method significantly outperforms the baseline method of using a query's own click-throughs in all metrics.},
journal = {Inf. Retr.},
month = dec,
pages = {573–593},
numpages = {21},
keywords = {Mining similar queries, Query intent, Web search}
}

@article{10.1007/s10791-016-9284-4,
author = {Gunes, Ihsan and Polat, Huseyin},
title = {Detecting Shilling Attacks in Private Environments},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9284-4},
doi = {10.1007/s10791-016-9284-4},
abstract = {Privacy-preserving collaborative filtering algorithms are successful approaches. However, they are susceptible to shilling attacks. Recent research has increasingly focused on collaborative filtering to protect against both privacy and shilling attacks. Malicious users may add fake profiles to manipulate the output of privacy-preserving collaborative filtering systems, which reduces the accuracy of these systems. Thus, it is imperative to detect fake profiles for overall success. Many methods have been developed for detecting attack profiles to keep them outside of the system. However, these techniques have all been established for non-private collaborative filtering schemes. The detection of shilling attacks in privacy-preserving recommendation systems has not been deeply examined. In this study, we examine the detection of shilling attacks in privacy-preserving collaborative filtering systems. We utilize four attack-detection methods to filter out fake profiles produced by six well-known shilling attacks on perturbed data. We evaluate these detection methods with respect to their ability to identify bogus profiles. Real data-based experiments are performed. Empirical outcomes demonstrate that some of the detection methods are very successful at filtering out fake profiles in privacy-preserving collaborating filtering schemes.},
journal = {Inf. Retr.},
month = dec,
pages = {547–572},
numpages = {26},
keywords = {Detection, Privacy, Shilling attack, Collaborative filtering, Recommendation}
}

@article{10.1007/s10791-016-9286-2,
author = {Verberne, Suzan and Sappelli, Maya and Hiemstra, Djoerd and Kraaij, Wessel},
title = {Evaluation and Analysis of Term Scoring Methods for Term Extraction},
year = {2016},
issue_date = {October   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9286-2},
doi = {10.1007/s10791-016-9286-2},
abstract = {We evaluate five term scoring methods for automatic term extraction on four different types of text collections: personal document collections, news articles, scientific articles and medical discharge summaries. Each collection has its own use case: author profiling, boolean query term suggestion, personalized query suggestion and patient query expansion. The methods for term scoring that have been proposed in the literature were designed with a specific goal in mind. However, it is as yet unclear how these methods perform on collections with characteristics different than what they were designed for, and which method is the most suitable for a given (new) collection. In a series of experiments, we evaluate, compare and analyse the output of six term scoring methods for the collections at hand. We found that the most important factors in the success of a term scoring method are the size of the collection and the importance of multi-word terms in the domain. Larger collections lead to better terms; all methods are hindered by small collection sizes (below 1000 words). The most flexible method for the extraction of single-word and multi-word terms is pointwise Kullback---Leibler divergence for informativeness and phraseness. Overall, we have shown that extracting relevant terms using unsupervised term scoring methods is possible in diverse use cases, and that the methods are applicable in more contexts than their original design purpose.},
journal = {Inf. Retr.},
month = oct,
pages = {510–545},
numpages = {36},
keywords = {Query suggestion, Evaluation, Term scoring, Query expansion, Author profiling, Term extraction}
}

@article{10.1007/s10791-016-9285-3,
author = {B\"{o}hm, Thilo and Klas, Claus-Peter and Hemmje, Matthias},
title = {Towards a Probabilistic Model for Supporting Collaborative Information Access},
year = {2016},
issue_date = {October   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9285-3},
doi = {10.1007/s10791-016-9285-3},
abstract = {In information retrieval research, models and systems traditionally assume that a single person is querying and reviewing the results. However, several empirical studies of professional practice identified collaboration during IR as everyday work patterns in order to solve a shared information need and to benefit from the diverse expertise and experience of the team members. Moreover, most IR systems that are employed in professional work routines are designed for individual use and prototype collaborative systems are too limited to support use in todays work practice. To bridge this gap, this papers develops and formalizes a decision theoretic approach towards supporting a team of people that explicitly set out together to resolve a shared information need. We develop a formal cost model for collaborative IR that considers the trade-off between estimated relevance of a document as well as estimated document redundancy. From this cost model, we use a decision theoretic approach to derive the notion of activity suggestions, that is, a formal optimum criterion that describes optimum collaboration strategies in IR as the solution of an integer linear program. Those collaboration strategies are suggested to team members with the aim to facilitate the collaborative performance of information retrieval tasks. We demonstrate the application of our model by means of search result division in two collaborative search tasks. In the conducted experiments, we study the effects of different domain knowledge and resulting relevance assessments of team members in four different conditions. The gathered results indicate that our approach can improve the retrieval effectiveness of teams in recall-oriented tasks.},
journal = {Inf. Retr.},
month = oct,
pages = {487–509},
numpages = {23},
keywords = {Task division, Integer linear programming, Information retrieval, Decision theory, Probabilistic ranking, Collaboration}
}

@article{10.1007/s10791-016-9283-5,
author = {Bordino, Ilaria and Lalmas, Mounia and Mejova, Yelena and Laere, Olivier},
title = {Beyond Entities: Promoting Explorative Search with Bundles},
year = {2016},
issue_date = {October   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9283-5},
doi = {10.1007/s10791-016-9283-5},
abstract = {Search engines are increasingly going beyond the pure relevance of search results to entertain users with information items that are interesting and even surprising, albeit sometimes not fully related to their search intent. In this paper, we study this serendipitous search space in the context of entity search, which has recently emerged as a powerful paradigm for building semantically rich answers. Specifically, our work proposes to enhance an explorative search system that represents a large sample of Yahoo Answers as an entity network, with a result structuring that goes beyond ranked lists, using composite entity retrieval, which requires a bundling of the results. We propose and compare six bundling methods, which exploit topical categories, entity specializations, and sentiment, and go beyond simple entity clustering. Two large-scale crowd-sourced studies show that users find a bundled organization--especially based on the topical categories of the query entity--to be better at revealing the most useful results, as well as at organizing the results, helping to discover novel and interesting information, and promoting exploration. Finally, a third study of 30 simulated search tasks reveals the bundled search experience to be less frustrating and more rewarding, with more users willing to recommend it to others.},
journal = {Inf. Retr.},
month = oct,
pages = {447–486},
numpages = {40},
keywords = {Composite eetrieval, Entity search, Explorative aearch, Entity networks, Topical bundles, Bundles}
}

@article{10.1007/s10791-016-9282-6,
author = {Lu, Xiaolu and Moffat, Alistair and Culpepper, J. Shane},
title = {The Effect of Pooling and Evaluation Depth on IR Metrics},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9282-6},
doi = {10.1007/s10791-016-9282-6},
abstract = {Batch IR evaluations are usually performed in a framework that consists of a document collection, a set of queries, a set of relevance judgments, and one or more effectiveness metrics. A large number of evaluation metrics have been proposed, with two primary families having emerged: recall-based metrics, and utility-based metrics. In both families, the pragmatics of forming judgments mean that it is usual to evaluate the metric to some chosen depth such as $$k=20$$k=20 or $$k=100$$k=100, without necessarily fully considering the ramifications associated with that choice. Our aim is this paper is to explore the relative risks arising with fixed-depth evaluation in the two families, and document the complex interplay between metric evaluation depth and judgment pooling depth. Using a range of TREC resources including NewsWire data and the ClueWeb collection, we: (1) examine the implications of finite pooling on the subsequent usefulness of different test collections, including specifying options for truncated evaluation; and (2) determine the extent to which various metrics correlate with themselves when computed to different evaluation depths using those judgments. We demonstrate that the judgment pools constructed for the ClueWeb collections lack resilience, and are suited primarily to the application of top-heavy utility-based metrics rather than recall-based metrics; and that on the majority of the established test collections, and across a range of evaluation depths, recall-based metrics tend to be more volatile in the system rankings they generate than are utility-based metrics. That is, experimentation using utility-based metrics is more robust to choices such as the evaluation depth employed than is experimentation using recall-based metrics. This distinction should be noted by researchers as they plan and execute system-versus-system retrieval experiments.},
journal = {Inf. Retr.},
month = aug,
pages = {416–445},
numpages = {30},
keywords = {Evaluation metrics comparison, Pooling and evaluation depth, Experimentation}
}

@article{10.1007/s10791-016-9280-8,
author = {Manzato, Marcelo G. and Domingues, Marcos A. and Fortes, Arthur C. and Sundermann, Camila V. and D'addio, Rafael M. and Conrado, Merley S. and Rezende, Solange O. and Pimentel, Maria G.},
title = {Mining Unstructured Content for Recommender Systems: An Ensemble Approach},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9280-8},
doi = {10.1007/s10791-016-9280-8},
abstract = {Recommendation of textual documents requires indexing mechanisms to extract structured metadata for attribute-aware recommender systems. Applying a variety of text mining algorithms has the advantage of capturing different aspects of unstructured content, resulting in richer descriptions. However, it is difficult to integrate them into a unique model so that these descriptions can efficiently improve recommendation accuracy. This article proposes a generic model based on ensemble learning that combines simple text mining methods in a post-processing approach. After executing each text mining technique, each set of metadata of a particular type is applied to the recommender module, which generates attribute-specific rankings. Then, the resulting recommendations are ensembled to generate a final personalized ranking to the user. We evaluated our ensemble technique with two attribute-aware collaborative recommenders (k-Nearest Neighbors and BPR-Mapping) and we demonstrate its generality by means of comparisons among different types of ensembles. We used two datasets from different domains, the first is from the Brazilian Embrapa Agency of Technology Information website, whose documents are written in Portuguese language, and the second is the HetRec MovieLens 2k, published by the GroupLens Research Group, whose movies' storylines are written in English. The experiments show that, particularly to the k-NN recommender, better accuracy can be obtained when multiple metadata types are combined. The proposed approach is extensible and flexible to new indexing and recommendation techniques.},
journal = {Inf. Retr.},
month = aug,
pages = {378–415},
numpages = {38},
keywords = {Ensemble learning, Metadata awareness, Recommender systems, Personalized ranking, Unstructured content}
}

@article{10.1007/s10791-016-9279-1,
author = {Clarke, Charles L. and Culpepper, J. Shane and Moffat, Alistair},
title = {Assessing Efficiency---Effectiveness Tradeoffs in Multi-Stage Retrieval Systems without Using Relevance Judgments},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9279-1},
doi = {10.1007/s10791-016-9279-1},
abstract = {Large-scale retrieval systems are often implemented as a cascading sequence of phases--a first filtering step, in which a large set of candidate documents are extracted using a simple technique such as Boolean matching and/or static document scores; and then one or more ranking steps, in which the pool of documents retrieved by the filter is scored more precisely using dozens or perhaps hundreds of different features. The documents returned to the user are then taken from the head of the final ranked list. Here we examine methods for measuring the quality of filtering and preliminary ranking stages, and show how to use these measurements to tune the overall performance of the system. Standard top-weighted metrics used for overall system evaluation are not appropriate for assessing filtering stages, since the output is a set of documents, rather than an ordered sequence of documents. Instead, we use an approach in which a quality score is computed based on the discrepancy between filtered and full evaluation. Unlike previous approaches, our methods do not require relevance judgments, and thus can be used with virtually any query set. We show that this quality score directly correlates with actual differences in measured effectiveness when relevance judgments are available. Since the quality score does not require relevance judgments, it can be used to identify queries that perform particularly poorly for a given filter. Using these methods, we explore a wide range of filtering options using thousands of queries, categorize the relative merits of the different approaches, and identify useful parameter combinations.},
journal = {Inf. Retr.},
month = aug,
pages = {351–377},
numpages = {27},
keywords = {Experimentation, Effectiveness, Measurement, Search, Efficiency}
}

@article{10.1007/s10791-016-9281-7,
author = {Scholer, Falk and Kelly, Diane and Carterette, Ben},
title = {Information Retrieval Evaluation Using Test Collections},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-016-9281-7},
doi = {10.1007/s10791-016-9281-7},
journal = {Inf. Retr.},
month = jun,
pages = {225–229},
numpages = {5}
}

@article{10.1007/s10791-015-9276-9,
author = {Samar, Thaer and Bellog\'{\i}n, Alejandro and Vries, Arjen P.},
title = {The Strange Case of Reproducibility versus Representativeness in Contextual Suggestion Test Collections},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9276-9},
doi = {10.1007/s10791-015-9276-9},
abstract = {The most common approach to measuring the effectiveness of Information Retrieval systems is by using test collections. The Contextual Suggestion (CS) TREC track provides an evaluation framework for systems that recommend items to users given their geographical context. The specific nature of this track allows the participating teams to identify candidate documents either from the Open Web or from the ClueWeb12 collection, a static version of the web. In the judging pool, the documents from the Open Web and ClueWeb12 collection are distinguished. Hence, each system submission should be based only on one resource, either Open Web (identified by URLs) or ClueWeb12 (identified by ids). To achieve reproducibility, ranking web pages from ClueWeb12 should be the preferred method for scientific evaluation of CS systems, but it has been found that the systems that build their suggestion algorithms on top of input taken from the Open Web achieve consistently a higher effectiveness. Because most of the systems take a rather similar approach to making CSs, this raises the question whether systems built by researchers on top of ClueWeb12 are still representative of those that would work directly on industry-strength web search engines. Do we need to sacrifice reproducibility for the sake of representativeness? We study the difference in effectiveness between Open Web systems and ClueWeb12 systems through analyzing the relevance assessments of documents identified from both the Open Web and ClueWeb12. Then, we identify documents that overlap between the relevance assessments of the Open Web and ClueWeb12, observing a dependency between relevance assessments and the source of the document being taken from the Open Web or from ClueWeb12. After that, we identify documents from the relevance assessments of the Open Web which exist in the ClueWeb12 collection but do not exist in the ClueWeb12 relevance assessments. We use these documents to expand the ClueWeb12 relevance assessments. Our main findings are twofold. First, our empirical analysis of the relevance assessments of 2 years of CS track shows that Open Web documents receive better ratings than ClueWeb12 documents, especially if we look at the documents in the overlap. Second, our approach for selecting candidate documents from ClueWeb12 collection based on information obtained from the Open Web makes an improvement step towards partially bridging the gap in effectiveness between Open Web and ClueWeb12 systems, while at the same time we achieve reproducible results on well-known representative sample of the web.},
journal = {Inf. Retr.},
month = jun,
pages = {230–255},
numpages = {26},
keywords = {Contextual suggestion, Test collections evaluation, Filtering and recommendation, Web IR and social media search, Open vs archived web, Reproducibility}
}

@article{10.1007/s10791-015-9275-x,
author = {Demeester, Thomas and Aly, Robin and Hiemstra, Djoerd and Nguyen, Dong and Develder, Chris},
title = {Predicting Relevance Based on Assessor Disagreement: Analysis and Practical Applications for Search Evaluation},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9275-x},
doi = {10.1007/s10791-015-9275-x},
abstract = {Evaluation of search engines relies on assessments of search results for selected test queries, from which we would ideally like to draw conclusions in terms of relevance of the results for general (e.g., future, unknown) users. In practice however, most evaluation scenarios only allow us to conclusively determine the relevance towards the particular assessor that provided the judgments. A factor that cannot be ignored when extending conclusions made from assessors towards users, is the possible disagreement on relevance, assuming that a single gold truth label does not exist. This paper presents and analyzes the predicted relevance model (PRM), which allows predicting a particular result's relevance for a random user, based on an observed assessment and knowledge on the average disagreement between assessors. With the PRM, existing evaluation metrics designed to measure binary assessor relevance, can be transformed into more robust and effectively graded measures that evaluate relevance towards a random user. It also leads to a principled way of quantifying multiple graded or categorical relevance levels for use as gains in established graded relevance measures, such as normalized discounted cumulative gain, which nowadays often use heuristic and data-independent gain values. Given a set of test topics with graded relevance judgments, the PRM allows evaluating systems on different scenarios, such as their capability of retrieving top results, or how well they are able to filter out non-relevant ones. Its use in actual evaluation scenarios is illustrated on several information retrieval test collections.},
journal = {Inf. Retr.},
month = jun,
pages = {284–312},
numpages = {29},
keywords = {Graded relevance assessments for information retrieval, Information retrieval evaluation, Test collections, Assessor disagreement}
}

@article{10.1007/s10791-015-9274-y,
author = {Urbano, Juli\'{a}n},
title = {Test Collection Reliability: A Study of Bias and Robustness to Statistical Assumptions via Stochastic Simulation},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9274-y},
doi = {10.1007/s10791-015-9274-y},
abstract = {The number of topics that a test collection contains has a direct impact on how well the evaluation results reflect the true performance of systems. However, large collections can be prohibitively expensive, so researchers are bound to balance reliability and cost. This issue arises when researchers have an existing collection and they would like to know how much they can trust their results, and also when they are building a new collection and they would like to know how many topics it should contain before they can trust the results. Several measures have been proposed in the literature to quantify the accuracy of a collection to estimate the true scores, as well as different ways to estimate the expected accuracy of hypothetical collections with a certain number of topics. We can find ad-hoc measures such as Kendall tau correlation and swap rates, and statistical measures such as statistical power and indexes from generalizability theory. Each measure focuses on different aspects of evaluation, has a different theoretical basis, and makes a number of assumptions that are not met in practice, such as normality of distributions, homoscedasticity, uncorrelated effects and random sampling. However, how good these estimates are in practice remains a largely open question. In this paper we first compare measures and estimators of test collection accuracy and propose unbiased statistical estimators of the Kendall tau and tau AP correlation coefficients. Second, we detail a method for stochastic simulation of evaluation results under different statistical assumptions, which can be used for a variety of evaluation research where we need to know the true scores of systems. Third, through large-scale simulation from TREC data, we analyze the bias of a range of estimators of test collection accuracy. Fourth, we analyze the robustness to statistical assumptions of these estimators, in order to understand what aspects of an evaluation are affected by what assumptions and guide in the development of new collections and new measures. All the results in this paper are fully reproducible with data and code available online.},
journal = {Inf. Retr.},
month = jun,
pages = {313–350},
numpages = {38},
keywords = {Information retrieval, Evaluation, Test collection, Simulation, Reliability}
}

@article{10.1007/s10791-015-9273-z,
author = {Sakai, Tetsuya},
title = {Topic Set Size Design},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9273-z},
doi = {10.1007/s10791-015-9273-z},
abstract = {Traditional pooling-based information retrieval (IR) test collections typically have $$n= 50$$n=50---100 topics, but it is difficult for an IR researcher to say why the topic set size should really be n.
 The present study provides details on principled ways to determine the number of topics for a test collection to be built, based on a specific set of statistical requirements. We employ Nagata's three sample size design techniques, which are based on the paired t test, one-way ANOVA, and confidence intervals, respectively. These topic set size design methods require topic-by-run score matrices from past test collections for the purpose of estimating the within-system population variance for a particular evaluation measure. While the previous work of Sakai incorrectly used estimates of the total variances, here we use the correct estimates of the within-system variances, which yield slightly smaller topic set sizes than those reported previously by Sakai. Moreover, this study provides a comparison across the three methods. Our conclusions nevertheless echo those of Sakai: as different evaluation measures can have vastly different within-system variances, they require substantially different topic set sizes under the same set of statistical requirements; by analysing the tradeoff between the topic set size and the pool depth for a particular evaluation measure in advance, researchers can build statistically reliable yet highly economical test collections.},
journal = {Inf. Retr.},
month = jun,
pages = {256–283},
numpages = {28}
}

@article{10.1007/s10791-015-9277-8,
author = {Goeuriot, Lorraine and Jones, Gareth J. and Kelly, Liadh and M\"{u}ller, Henning and Zobel, Justin},
title = {Medical Information Retrieval: Introduction to the Special Issue},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9277-8},
doi = {10.1007/s10791-015-9277-8},
journal = {Inf. Retr.},
month = apr,
pages = {1–5},
numpages = {5}
}

@article{10.1007/s10791-015-9269-8,
author = {Palotti, Jo\~{a}o and Hanbury, Allan and M\"{u}ller, Henning and Kahn, Charles E.},
title = {How Users Search and What They Search for in the Medical Domain},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9269-8},
doi = {10.1007/s10791-015-9269-8},
abstract = {The internet is an important source of medical knowledge for everyone, from laypeople to medical professionals. We investigate how these two extremes, in terms of user groups, have distinct needs and exhibit significantly different search behaviour. We make use of query logs in order to study various aspects of these two kinds of users. The logs from America Online, Health on the Net, Turning Research Into Practice and American Roentgen Ray Society (ARRS) GoldMiner were divided into three sets: (1) laypeople, (2) medical professionals (such as physicians or nurses) searching for health content and (3) users not seeking health advice. Several analyses are made focusing on discovering how users search and what they are most interested in. One possible outcome of our analysis is a classifier to infer user expertise, which was built. We show the results and analyse the feature set used to infer expertise. We conclude that medical experts are more persistent, interacting more with the search engine. Also, our study reveals that, conversely to what is stated in much of the literature, the main focus of users, both laypeople and professionals, is on disease rather than symptoms. The results of this article, especially through the classifier built, could be used to detect specific user groups and then adapt search results to the user group.},
journal = {Inf. Retr.},
month = apr,
pages = {189–224},
numpages = {36},
keywords = {User behavior, Query log analysis, Health search}
}

@article{10.1007/s10791-015-9268-9,
author = {Koopman, Bevan and Zuccon, Guido and Bruza, Peter and Sitbon, Laurianne and Lawley, Michael},
title = {Information Retrieval as Semantic Inference: A Graph Inference Model Applied to Medical Search},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9268-9},
doi = {10.1007/s10791-015-9268-9},
abstract = {This paper presents a Graph Inference retrieval model that integrates structured knowledge resources, statistical information retrieval methods and inference in a unified framework. Key components of the model are a graph-based representation of the corpus and retrieval driven by an inference mechanism achieved as a traversal over the graph. The model is proposed to tackle the semantic gap problem--the mismatch between the raw data and the way a human being interprets it. We break down the semantic gap problem into five core issues, each requiring a specific type of inference in order to be overcome. Our model and evaluation is applied to the medical domain because search within this domain is particularly challenging and, as we show, often requires inference. In addition, this domain features both structured knowledge resources as well as unstructured text. Our evaluation shows that inference can be effective, retrieving many new relevant documents that are not retrieved by state-of-the-art information retrieval models. We show that many retrieved documents were not pooled by keyword-based search methods, prompting us to perform additional relevance assessment on these new documents. A third of the newly retrieved documents judged were found to be relevant. Our analysis provides a thorough understanding of when and how to apply inference for retrieval, including a categorisation of queries according to the effect of inference. The inference mechanism promoted recall by retrieving new relevant documents not found by previous keyword-based approaches. In addition, it promoted precision by an effective reranking of documents. When inference is used, performance gains can generally be expected on hard queries. However, inference should not be applied universally: for easy, unambiguous queries and queries with few relevant documents, inference did adversely affect effectiveness. These conclusions reflect the fact that for retrieval as inference to be effective, a careful balancing act is involved. Finally, although the Graph Inference model is developed and applied to medical search, it is a general retrieval model applicable to other areas such as web search, where an emerging research trend is to utilise structured knowledge resources for more effective semantic search.},
journal = {Inf. Retr.},
month = apr,
pages = {6–37},
numpages = {32},
keywords = {Medical information retrieval, Semantic inference, Health informatics}
}

@article{10.1007/s10791-015-9265-z,
author = {Kovacs, William and Weisenthal, Samuel and Folio, Les and Li, Qiaoyi and Summers, Ronald M. and Yao, Jianhua},
title = {Retrieval, Visualization, and Mining of Large Radiation Dosage Data},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9265-z},
doi = {10.1007/s10791-015-9265-z},
abstract = {Radiation dose monitoring has become an essential service that hospitals must perform. Depending on the system in place, this can result in the collection of large quantities of data, ripe for analysis. These data should include a wide variety of variables for each study because assessment of the propriety of the patient's dose is dependent on many factors, including patient age and size, as well as the body section that is being scanned. Moreover, the scanners themselves have many properties that affect patient dose, such as model, pitch and kVp. In this paper, we propose an engine that seamlessly integrated with a clinical PACS to retrieve radiation dosage data. We devised several schemes to analyze these data through visualization and mining techniques that examine it at different scopes. We demonstrate the utility of such visual methods at examining large, noisy, and multi-dimensional data, which is embodied in the collected radiation data.},
journal = {Inf. Retr.},
month = apr,
pages = {38–58},
numpages = {21},
keywords = {Radiation dose, Clinical PACS, Data retrieval, Data visualization}
}

@article{10.1007/s10791-015-9263-1,
author = {Zheng, Jiaping and Yu, Hong},
title = {Methods for Linking EHR Notes to Education Materials},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9263-1},
doi = {10.1007/s10791-015-9263-1},
abstract = {It has been shown that accessing the patients' own electronic health records (EHR) can enhance their medical understanding and provide clinically relevant benefits. However, languages that are difficult for non-medical professionals to comprehend are prevalent in the EHR notes. The valuable and authoritative information contained in the EHR is thus less accessible to the patients, who ultimately stand to benefit the most from the information. To address this challenge, we are developing a system to retrieve EHR note-specific online consumer-oriented health education materials. We explored several query generation methods to convert long EHR notes to effective queries, including topic models and key concept identification. Our experiments show that queries using key concepts identified by a learning based model with pseudo-relevance feedback significantly outperform the baseline system of using the full text note.},
journal = {Inf. Retr.},
month = apr,
pages = {174–188},
numpages = {15},
keywords = {EHR note, Patient education, Information retrieval}
}

@article{10.1007/s10791-015-9262-2,
author = {Lossio-Ventura, Juan Antonio and Jonquet, Clement and Roche, Mathieu and Teisseire, Maguelonne},
title = {Biomedical Term Extraction: Overview and a New Methodology},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9262-2},
doi = {10.1007/s10791-015-9262-2},
abstract = {Terminology
 extraction is an essential task in domain knowledge acquisition, as well as for information retrieval. It is also a mandatory first step aimed at building/enriching terminologies and ontologies. As often proposed in the literature, existing terminology extraction methods feature linguistic and statistical aspects and solve some problems related (but not completely) to term extraction, e.g. noise, silence, low frequency, large-corpora, complexity of the multi-word term extraction process. In contrast, we propose a cutting edge methodology to extract and to rank biomedical terms, covering all the mentioned problems. This methodology offers several measures based on linguistic, statistical, graphic and web aspects.
 These measures extract and rank candidate terms with excellent precision: we demonstrate that they outperform previously reported precision results for automatic term extraction, and work with different languages (English, French, and Spanish). We also demonstrate how the use of graphs and the web to assess the significance of a term candidate, enables us to outperform precision results. We evaluated our methodology on the biomedical GENIA and LabTestsOnline corpora and compared it with previously reported measures.},
journal = {Inf. Retr.},
month = apr,
pages = {59–99},
numpages = {41},
keywords = {Graphs, Automatic term extraction, Web mining, Natural language processing, Biomedical terminology extraction, BioNLP, Text mining}
}

@article{10.1007/s10791-015-9260-4,
author = {Markonis, Dimitrios and Schaer, Roger and M\"{u}ller, Henning},
title = {Evaluating Multimodal Relevance Feedback Techniques for Medical Image Retrieval},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9260-4},
doi = {10.1007/s10791-015-9260-4},
abstract = {Medical image retrieval can assist physicians in finding information supporting their diagnosis and fulfilling information needs. Systems that allow searching for medical images need to provide tools for quick and easy navigation and query refinement as the time available for information search is often short. Relevance feedback is a powerful tool in information retrieval. This study evaluates relevance feedback techniques with regard to the content they use. A novel relevance feedback technique that uses both text and visual information of the results is proposed. The two information modalities from the image examples are fused either at the feature level using the Rocchio algorithm or at the query list fusion step using a common late fusion rule. Results using the ImageCLEF 2012 benchmark database for medical image retrieval show the potential of relevance feedback techniques in medical image retrieval. The mean average precision (mAP) is used as the evaluation metric and the proposed method outperforms commonly-used methods. The baseline without feedback reached 16 % whereas the relevance feedback with 20 images reached up to 26.35 % with three steps and when using 100 images up to 34.87 % in four steps. Most improvements occur in the first two steps of relevance feedback and then results start to become relatively flat. This might also be due to only using positive feedback as negative feeback often also improves results after more steps. The effect of relevance feedback in automatically spelling corrected and translated queries is investigated as well. Results without mistakes were better than spell-corrected results but the spelling correction more than double results over non-corrected retrieval. Multimodal relevance feedback has shown to be able to help visual medical information retrieval. Next steps include integrating semantics into relevance feedback techniques to benefit from the structured knowledge of ontologies and experimenting on the fusion of text and visual information.},
journal = {Inf. Retr.},
month = apr,
pages = {100–112},
numpages = {13},
keywords = {Content-based image retrieval, Medical image retrieval, Relevance feedback}
}

@article{10.1007/s10791-015-9259-x,
author = {Roberts, Kirk and Simpson, Matthew and Demner-Fushman, Dina and Voorhees, Ellen and Hersh, William},
title = {State-of-the-Art in Biomedical Literature Retrieval for Clinical Cases: A Survey of the TREC 2014 CDS Track},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9259-x},
doi = {10.1007/s10791-015-9259-x},
abstract = {Providing access to relevant biomedical literature in a clinical setting has the potential to bridge a critical gap in evidence-based medicine. Here, our goal is specifically to provide relevant articles to clinicians to improve their decision-making in diagnosing, treating, and testing patients. To this end, the TREC 2014 Clinical Decision Support Track evaluated a system's ability to retrieve relevant articles in one of three categories (Diagnosis, Treatment, Test) using an idealized form of a patient medical record
. Over 100 submissions from over 25 participants were evaluated on 30 topics, resulting in over 37k relevance judgments. In this article, we provide an overview of the task, a survey of the information retrieval methods employed by the participants, an analysis of the results, and a discussion on the future directions for this challenging yet important task.},
journal = {Inf. Retr.},
month = apr,
pages = {113–148},
numpages = {36},
keywords = {Clinical decision support, Information retrieval evaluation, Biomedical information retrieval}
}

@article{10.1007/s10791-015-9258-y,
author = {Soldaini, Luca and Yates, Andrew and Yom-Tov, Elad and Frieder, Ophir and Goharian, Nazli},
title = {Enhancing Web Search in the Medical Domain via Query Clarification},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9258-y},
doi = {10.1007/s10791-015-9258-y},
abstract = {The majority of Internet users search for medical information online; however, many do not have an adequate medical vocabulary. Users might have difficulties finding the most authoritative and useful information because they are unfamiliar with the appropriate medical expressions describing their condition; consequently, they are unable to adequately satisfy their information need. We investigate the utility of bridging the gap between layperson and expert vocabularies; our approach adds the most appropriate expert expression to queries submitted by users, a task we call query clarification. We evaluated the impact of query clarification. Using three different synonym mappings and conducting two task-based retrieval studies, users were asked to answer medically-related questions using interleaved results from a major search engine. Our results show that the proposed system was preferred by users and helped them answer medical concerns correctly more often, with up to a 7 % increase in correct answers over an unmodified query. Finally, we introduce a supervised classifier to select the most appropriate synonym mapping for each query, which further increased the fraction of correct answers (12 %).},
journal = {Inf. Retr.},
month = apr,
pages = {149–173},
numpages = {25},
keywords = {Medical informatics, Health search, Query clarification, Personalized search}
}

@article{10.1007/s10791-015-9278-7,
author = {Yang, Peilin and Wang, Hongning and Fang, Hui and Cai, Deng},
title = {Opinions Matter: A General Approach to User Profile Modeling for Contextual Suggestion},
year = {2015},
issue_date = {December  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9278-7},
doi = {10.1007/s10791-015-9278-7},
abstract = {
The increasing use of mobile devices enables an information retrieval (IR) system to capitalize on various types of contexts (e.g., temporal and geographical information) about its users. Combined with the user preference history recorded in the system, a better understanding of users' information need can be achieved and it thus leads to improved user satisfaction. More importantly, such a system could proactively recommend suggestions based on the contexts. User profiling is essential in contextual suggestion. However, given most users' observed behaviors are sparse and their preferences are latent in an IR system, constructing accurate user profiles is generally difficult. In this paper, we focus on location-based contextual suggestion and propose to leverage users' opinions to construct the profiles. Instead of simply recording "what places a user likes or dislikes" in the past (i.e., description-based profile), we want to construct a profile to identify "why a user likes or dislikes a place" so as to better predict whether the user would like a new candidate suggestion of place. By assuming users would like or dislike a place with similar reasons, we construct the opinion-based user profile in a collaborative way: opinions from the other users are leveraged to estimate a profile for the target user. Candidate suggestions are represented in the same fashion and ranked based on their similarities with respect to the user profiles. Moreover, we also develop a novel summary generation method that utilizes the opinion-based user profiles to generate personalized and high-quality summaries for the suggestions. Experiments are conducted over three standard TREC contextual suggestion collections and a Yelp data set. Extensive experiment comparisons confirm that the proposed opinion-based user modeling outperforms the existing description-based methods. In particular, the systems developed based on the proposed methods have been ranked as top 1 in both TREC 2013 and 2014 contextual suggestion tracks.
},
journal = {Inf. Retr.},
month = dec,
pages = {586–610},
numpages = {25},
keywords = {Opinions, Contextual suggestions, User modeling, Recommendation}
}

@article{10.1007/s10791-015-9272-0,
author = {Ganesan, Kavita and Zhai, Chengxiang},
title = {OpinoFetch: A Practical and Efficient Approach to Collecting Opinions on Arbitrary Entities},
year = {2015},
issue_date = {December  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9272-0},
doi = {10.1007/s10791-015-9272-0},
abstract = {The abundance of opinions on the Web is now becoming a critical source of information in a variety of application areas such as business intelligence, market research and online shopping. Unfortunately, due to the rapid growth of online content, there is no one source to obtain a comprehensive set of opinions about a specific entity or a topic, making access to such content severely limited. While previous works have been focused on mining and summarizing online opinions, there is limited work on exploring the automatic collection of opinion content on the Web. In this paper, we propose a lightweight and practical approach to collecting opinion containing pages, namely review pages on the Web for arbitrary entities. We leverage existing Web search engines and use a novel information network called the FetchGraph to efficiently obtain review pages for entities of interest. Our experiments in three different domains show that our method is more effective than plain search engine results and we are able to collect entity specific review pages efficiently with reasonable precision and accuracy.
},
journal = {Inf. Retr.},
month = dec,
pages = {530–558},
numpages = {29},
keywords = {Opinion crawling, Review aggregation, Review crawling, Opinion analysis, Opinion aggregation, Opinion collection}
}

@article{10.1007/s10791-015-9271-1,
author = {Ren, Pengjie and Chen, Zhumin and Ma, Jun and Wang, Shuaiqiang and Zhang, Zhiwei and Ren, Zhaochun},
title = {Mining and Ranking Users' Intents behind Queries},
year = {2015},
issue_date = {December  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9271-1},
doi = {10.1007/s10791-015-9271-1},
abstract = {
How to understand intents behind user queries is crucial towards improving the performance of Web search systems. NTCIR-11 IMine task focuses on this problem. In this paper, we address the NTCIR-11 IMine task with two phases referred to as Query Intent Mining (QIM) and Query Intent Ranking (QIR). (I) QIM is intended to mine users' potential intents by clustering short text fragments related to the given query. (II) QIR focuses on ranking those mined intents in a proper way. Two challenges exist in handling these tasks. (II) How to precisely estimate the intent similarity between user queries which only consist of a few words. (2) How to properly rank intents in terms of multiple factors, e.g. relevance, diversity, intent drift and so on. For the first challenge, we first investigate two interesting phenomena by analyzing query logs and document datasets, namely "Same-Intent-Co-Click" (SICC) and "Same-Intent-Similar-Rank" (SISR). SICC means that when users issue different queries, these queries represent the same intent if they click on the same URL. SISR means that if two queries denote the same intent, we should get similar search results when issuing them to a search engine. Then, we propose similarity functions for QIM based on the two phenomena. For the second challenge, we propose a novel intent ranking model which considers multiple factors as a whole. We perform extensive experiments and an interesting case study on the Chinese dataset of NTCIR-11 IMine task. Experimental results demonstrate the effectiveness of our proposed approaches in terms of both QIM and QIR.
},
journal = {Inf. Retr.},
month = dec,
pages = {504–529},
numpages = {26},
keywords = {Intent mining, Information retrieval, Query understanding, NTCIR-11 IMine task, Intent ranking}
}

@article{10.1007/s10791-015-9270-2,
author = {Giachanou, Anastasia and Salampasis, Michail and Paltoglou, Georgios},
title = {Multilayer Source Selection as a Tool for Supporting Patent Search and Classification},
year = {2015},
issue_date = {December  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9270-2},
doi = {10.1007/s10791-015-9270-2},
abstract = {In this paper we present a method that can be used to attain specific objectives in a typical prior art search process. The objectives are first to assist patent searchers in understanding the underlying technical concepts of a patent by identifying relevant international patent classification (IPC) codes and second to help them conduct a filtered search based on automatically selected IPCs. We view the automated selection of IPCs as a collection selection problem from the domain of distributed information retrieval (DIR) that can be addressed using existing DIR methods, which we extend and adapt for the patent domain. Our work exploits the intellectually assigned classifications codes that are used to categorize patents and to facilitate patent searches. In our method, manually assigned IPC codes of patent documents are used to cluster, distribute and index patents through hundreds or thousands of sub-collections. We propose a new multilayer collection selection method that effectively suggests classification codes exploiting the hierarchical classification schemes such as IPC/CPC. The new method in addition to utilizing the topical relevance of IPCs at a particular level of interest exploits the topical relevance of their ancestors in the IPC hierarchy and aggregates those multiple estimations of relevance to a single estimation. Experimental results on the CLEF-IP 2011 dataset show that the proposed approach outperforms state-of-art methods from the DIR domain not only in identifying relevant IPC codes but also in retrieving relevant patent documents given a patent query.},
journal = {Inf. Retr.},
month = dec,
pages = {559–585},
numpages = {27},
keywords = {Patent classification, IPC suggestion, Distributed information retrieval, IPC, Patent search}
}

@article{10.1007/s10791-015-9267-x,
author = {Liu, Xitong and Fang, Hui},
title = {Latent Entity Space: A Novel Retrieval Approach for Entity-Bearing Queries},
year = {2015},
issue_date = {December  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9267-x},
doi = {10.1007/s10791-015-9267-x},
abstract = {Analysis on Web search query logs has revealed that there is a large portion of entity-bearing queries, reflecting the increasing demand of users on retrieving relevant information about entities such as persons, organizations, products, etc. In the meantime, significant progress has been made in Web-scale information extraction, which enables efficient entity extraction from free text. Since an entity is expected to capture the semantic content of documents and queries more accurately than a term, it would be interesting to study whether leveraging the information about entities can improve the retrieval accuracy for entity-bearing queries. In this paper, we propose a novel retrieval approach, i.e., latent entity space (LES), which models the relevance by leveraging entity profiles to represent semantic content of documents and queries. In the LES, each entity corresponds to one dimension, representing one semantic relevance aspect. We propose a formal probabilistic framework to model the relevance in the high-dimensional entity space. Experimental results over TREC collections show that the proposed LES approach is effective in capturing latent semantic content and can significantly improve the search accuracy of several state-of-the-art retrieval models for entity-bearing queries.},
journal = {Inf. Retr.},
month = dec,
pages = {473–503},
numpages = {31},
keywords = {Entity profile, Document retrieval, Latent entity space}
}

@article{10.1007/s10791-015-9266-y,
author = {Tonon, Alberto and Demartini, Gianluca and Cudr\'{e}-Mauroux, Philippe},
title = {Pooling-Based Continuous Evaluation of Information Retrieval Systems},
year = {2015},
issue_date = {October   2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9266-y},
doi = {10.1007/s10791-015-9266-y},
abstract = {The dominant approach to evaluate the effectiveness of information retrieval (IR) systems is by means of reusable test collections built following the Cranfield paradigm. In this paper, we propose a new IR evaluation methodology based on pooled test-collections and on the continuous use of either crowdsourcing or professional editors to obtain relevance judgements. Instead of building a static collection for a finite set of systems known a priori, we propose an IR evaluation paradigm where retrieval approaches are evaluated iteratively on the same collection. Each new retrieval technique takes care of obtaining its missing relevance judgements and hence contributes to augmenting the overall set of relevance judgements of the collection. We also propose two metrics: Fairness Score, and opportunistic number of relevant documents, which we then use to define new pooling strategies. The goal of this work is to study the behavior of standard IR metrics, IR system ranking, and of several pooling techniques in a continuous evaluation context by comparing continuous and non-continuous evaluation results on classic test collections. We both use standard and crowdsourced relevance judgements, and we actually run a continuous evaluation campaign over several existing IR systems.},
journal = {Inf. Retr.},
month = oct,
pages = {445–472},
numpages = {28},
keywords = {Continuous evaluation, Pooling techniques, Crowdsourcing, Information retrieval evaluation}
}

@article{10.1007/s10791-015-9264-0,
author = {Mao, Jin and Lu, Kun and Mu, Xiangming and Li, Gang},
title = {Mining Document, Concept, and Term Associations for Effective Biomedical Retrieval: Introducing MeSH-Enhanced Retrieval Models},
year = {2015},
issue_date = {October   2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9264-0},
doi = {10.1007/s10791-015-9264-0},
abstract = {Manually assigned subject terms, such as Medical Subject Headings (MeSH) in the health domain, describe the concepts or topics of a document. Existing information retrieval models do not take full advantage of such information. In this paper, we propose two MeSH-enhanced (ME) retrieval models that integrate the concept layer (i.e. MeSH) into the language modeling framework to improve retrieval performance. The new models quantify associations between documents and their assigned concepts to construct conceptual representations for the documents, and mine associations between concepts and terms to construct generative concept models. The two ME models reconstruct two essential estimation processes of the relevance model (Lavrenko and Croft 2001) by incorporating the document-concept and the concept-term associations. More specifically, in Model 1, language models of the pseudo-feedback documents are enriched by their assigned concepts. In Model 2, concepts that are related to users' queries are first identified, and then used to reweight the pseudo-feedback documents according to the document-concept associations. Experiments carried out on two standard test collections show that the ME models outperformed the query likelihood model, the relevance model (RM3), and an earlier ME model. A detailed case analysis provides insight into how and why the new models improve/worsen retrieval performance. Implications and limitations of the study are discussed. This study provides new ways to formally incorporate semantic annotations, such as subject terms, into retrieval models. The findings of this study suggest that integrating the concept layer into retrieval models can further improve the performance over the current state-of-the-art models.},
journal = {Inf. Retr.},
month = oct,
pages = {413–444},
numpages = {32},
keywords = {MeSH-enhanced retrieval models, Relevance model, Concept, Health information retrieval}
}

@article{10.1007/s10791-015-9261-3,
author = {Qian, Yanan and Zheng, Qinghua and Sakai, Tetsuya and Ye, Junting and Liu, Jun},
title = {Dynamic Author Name Disambiguation for Growing Digital Libraries},
year = {2015},
issue_date = {October   2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9261-3},
doi = {10.1007/s10791-015-9261-3},
abstract = {When a digital library user searches for publications by an author name, she often sees a mixture of publications by different authors who have the same name. With the growth of digital libraries and involvement of more authors, 
this author ambiguity problem is becoming critical. Author disambiguation (AD) often tries to solve this problem by leveraging metadata such as coauthors, research topics, publication venues and citation information, since more personal information such as the contact details is often restricted or missing. In this paper, we study the problem of how to efficiently disambiguate author names given an incessant stream of published papers. To this end, we propose a "BatchAD+IncAD" framework for dynamic author disambiguation. First, we perform batch author disambiguation (BatchAD) to disambiguate all author names at a given time by grouping all records (each record refers to a paper with one of its author names) into disjoint clusters. This establishes a one-to-one mapping between the clusters and real-world authors. Then, for newly added papers, we periodically perform incremental author disambiguation (IncAD), which determines whether each new record can be assigned to an existing cluster, or to a new cluster not yet included in the previous data. Based on the new data, IncAD also tries to correct previous AD results. Our main contributions are: (1) We demonstrate with real data that a small number of new papers often have overlapping author names with a large portion of existing papers, so it is challenging for IncAD to effectively leverage previous AD results. (2) We propose a novel IncAD model which aggregates metadata from a cluster of records to estimate the author's profile such as her coauthor distributions and keyword distributions, in order to predict how likely it is that a new record is "produced" by the author. (3) Using two labeled datasets and one large-scale raw dataset, we show that the proposed method is much more efficient than state-of-the-art methods while ensuring high accuracy.},
journal = {Inf. Retr.},
month = oct,
pages = {379–412},
numpages = {34},
keywords = {Multi-classification, Data stream, Digital library, Clustering, Author disambiguation}
}

@article{10.1007/s10791-015-9257-z,
author = {Lv, Yuanhua and Zhai, Chengxiang},
title = {Negative Query Generation: Bridging the Gap between Query Likelihood Retrieval Models and Relevance},
year = {2015},
issue_date = {August    2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9257-z},
doi = {10.1007/s10791-015-9257-z},
abstract = {The language modeling approach to information retrieval has recently attracted much attention. In the language modeling retrieval models, we can score and rank documents based on the query likelihood method. From the theoretical perspective, however, the justification of the existing (standard) query likelihood method based on the probability ranking principle requires an unrealistic assumption about the generation of a "negative query" from a document, which states that the probability that a user who dislikes a document would use a query does not depend on the particular document. This assumption enables ignoring the negative query generation so as to justify using the basic query likelihood method as a retrieval function. In reality, however, this assumption does not hold because a user who dislikes a document would more likely avoid using words in the document when posing a query. This suggests that the standard query likelihood function is a potentially non-optimal retrieval function. In this paper, we attempt to improve the standard language modeling retrieval models by bringing back the component of negative query generation. Specifically, we propose a general and efficient approach to estimate document-dependent probabilities of negative query generation based on the principle of maximum entropy, and derive a more complete query likelihood retrieval function that also contains the negative query generation component. In addition, we further develop a more general probabilistic distance retrieval method to naturally incorporate query language models, which covers the proposed query likelihood with negative query generation as its special case. The proposed approaches not only bridge the theoretic gap between the standard language modeling retrieval models and the notion of relevance, but also improves the retrieval effectiveness with (almost) no additional computational cost.
},
journal = {Inf. Retr.},
month = aug,
pages = {359–378},
numpages = {20},
keywords = {Relevance, Query likelihood, Principle of maximum entropy, Probability ranking principle, Language model, Negative query generation}
}

@article{10.1007/s10791-015-9256-0,
author = {Arampatzis, Avi and Drosatos, George and Efraimidis, Pavlos S.},
title = {Versatile Query Scrambling for Private Web Search},
year = {2015},
issue_date = {August    2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9256-0},
doi = {10.1007/s10791-015-9256-0},
abstract = {We 
consider the problem of privacy leaks suffered by Internet users when they perform web searches, and propose a framework to mitigate them. In brief, given a `sensitive' search query, the objective of our work is to retrieve the target documents from a search engine without disclosing the actual query. Our approach, which builds upon and improves recent work on search privacy, approximates the target search results by replacing the private user query with a set of blurred or scrambled queries. The results of the scrambled queries are then used to cover the private user interest. We model the problem theoretically, define a set of privacy objectives with respect to web search and investigate the effectiveness of the proposed solution with a set of queries with privacy issues on a large web collection. Experiments show great improvements in retrieval effectiveness over a previously reported baseline in the literature. Furthermore, the methods are more versatile, predictably-behaved, applicable to a wider range of information needs, and the privacy they provide is more comprehensible to the end-user. Additionally, we investigate the perceived privacy via a user study, as well as, measure the system's usefulness taking into account the trade off between retrieval effectiveness and privacy. The practical feasibility of the methods is demonstrated in a field experiment, scrambling queries against a popular web search engine. The findings may have implications for other IR research areas, such as query expansion, query decomposition, and distributed retrieval.},
journal = {Inf. Retr.},
month = aug,
pages = {331–358},
numpages = {28},
keywords = {Inter-user agreement, Set covering, Query-based document sampling, Search privacy, Query scrambler, Mutual information}
}

@article{10.1007/s10791-015-9254-2,
author = {Jameel, Shoaib and Lam, Wai and Bing, Lidong},
title = {Supervised Topic Models with Word Order Structure for Document Classification and Retrieval Learning},
year = {2015},
issue_date = {August    2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9254-2},
doi = {10.1007/s10791-015-9254-2},
abstract = {One limitation of most existing probabilistic latent topic models for document classification is that the topic model itself does not consider useful side-information, namely, class labels of documents. Topic models, which in turn consider the side-information, popularly known as supervised topic models, do not consider the word order structure in documents. One of the motivations behind considering the word order structure is to capture the semantic fabric of the document. We investigate a low-dimensional latent topic model for document classification. Class label information and word order structure are integrated into a supervised topic model enabling a more effective interaction among such information for solving document classification. We derive a collapsed Gibbs sampler for our model. Likewise, supervised topic models with word order structure have not been explored in document retrieval learning. We propose a novel supervised topic model for document retrieval learning which can be regarded as a pointwise model for tackling the learning-to-rank task. Available relevance assessments and word order structure are integrated into the topic model itself.
 We conduct extensive experiments on several publicly available benchmark datasets, and show that our model improves upon the state-of-the-art models.},
journal = {Inf. Retr.},
month = aug,
pages = {283–330},
numpages = {48},
keywords = {Learning-to-rank, Structured topic model, Document classification, Maximum-margin, Topic modeling}
}

@article{10.1007/s10791-015-9255-1,
author = {Rahimi, Razieh and Shakery, Azadeh and King, Irwin},
title = {Multilingual Information Retrieval in the Language Modeling Framework},
year = {2015},
issue_date = {June      2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9255-1},
doi = {10.1007/s10791-015-9255-1},
abstract = {Multilingual information retrieval (MLIR) provides results that are more comprehensive than those of mono- and cross-lingual retrieval. Methods for MLIR are categorized as: (1) Fusion-based methods that merge results from multiple retrieval runs, and (2) Direct methods that build a unique index for the entire collection. Merging results of individual runs reduces the overall effectiveness, while more effective direct methods suffer from either time complexity and memory overhead, or over-weighting of index terms. In this paper, we propose a direct MLIR approach by using the language modeling framework that includes a novel multilingual language model estimation for documents, and a new way to globally estimate word statistics. These contributions enable ranking documents in multiple languages in one retrieval phase without having the problems of the previous direct methods. Moreover, our approach has the advantage of accommodating multilingual feedback information which helps to prevent query drift, and consequently to improve the performance. Finally, we effectively address the common case of incomplete coverage of translation resources in our proposed estimation methods. Experimental results show that the proposed approach outperforms the previous MLIR approaches.},
journal = {Inf. Retr.},
month = jun,
pages = {246–281},
numpages = {36},
keywords = {Multilingual language models, Multilingual feedback, Language modeling framework, KL-divergence framework, Multilingual information retrieval}
}

@article{10.1007/s10791-015-9253-3,
author = {Niu, Shuzi and Lan, Yanyan and Guo, Jiafeng and Wan, Shengxian and Cheng, Xueqi},
title = {Which Noise Affects Algorithm Robustness for Learning to Rank},
year = {2015},
issue_date = {June      2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9253-3},
doi = {10.1007/s10791-015-9253-3},
abstract = {When applying learning to rank algorithms in real search applications, noise in human labeled training data becomes an inevitable problem which will affect the performance of the algorithms. Previous work mainly focused on studying how noise affects ranking algorithms and how to design robust ranking algorithms. In our work, we investigate what inherent characteristics make training data robust to label noise and how to utilize them to guide labeling. The motivation of our work comes from an interesting observation that a same ranking algorithm may show very different sensitivities to label noise over different data sets. We thus investigate the underlying reason for this observation based on three typical kinds of learning to rank algorithms (i.e. pointwise, pairwise and listwise methods) and three public data sets (i.e. OHSUMED, TD2003 and MSLR-WEB10K) with different properties. We find that when label noise increases in training data, it is the document pair noise ratio (referred to as pNoise) rather than document noise ratio (referred to as dNoise) that can well explain the performance degradation of a ranking algorithm. We further identify two inherent characteristics of the training data, namely relevance levels and label balance, that have great impact on the variation of pNoise with respect to label noise (i.e. dNoise). According to these above results, we further discuss some guidelines on the labeling strategy to construct robust training data for learning to rank algorithms in practice.},
journal = {Inf. Retr.},
month = jun,
pages = {215–245},
numpages = {31},
keywords = {Learning to rank, Label noise, Robust data}
}

@article{10.1007/s10791-015-9252-4,
author = {Forsati, Rana and Moayedikia, Alireza and Shamsfard, Mehrnoush},
title = {An Effective Web Page Recommender Using Binary Data Clustering},
year = {2015},
issue_date = {June      2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9252-4},
doi = {10.1007/s10791-015-9252-4},
abstract = {Through growth of the Web, the amount of data on the net is growing in an uncontrolled way, that makes it hard for the users to find the relevant and required information- an issue which is usually referred to as information overload. Recommender systems are among the appealing methods that can handle this problem effectively. Theses systems are either based on collaborative filtering and content based approaches, or rely on rating of items and the behavior of the users to generate customized recommendations. In this paper we propose an efficient Web page recommender by exploiting session data of users. To this end, we propose a novel clustering algorithm to partition the binary session data into a fixed number of clusters and utilize the partitioned sessions to make recommendations. The proposed binary clustering algorithm is scalable and employs a novel method to find the representative of a set of binary vectors to represent the center of clusters--that might be interesting in its own right. In addition, the proposed clustering algorithm is integrated with the $$k$$k-means algorithm to achieve better clustering quality by combining its explorative power with fine-tuning power of the $$k$$k-means algorithm. We have performed extensive experiments on a real dataset to demonstrate the advantages of proposed binary data clustering methods and Web page recommendation algorithm. In particular, the proposed recommender system is compared to previously published works in terms of minimum frequency and based on the number of recommended pages to show its superiority in terms of accuracy, coverage and F-measure.},
journal = {Inf. Retr.},
month = jun,
pages = {167–214},
numpages = {48},
keywords = {Recommender systems, k-Means, Binary data clustering, Harmony search optimization}
}

@article{10.1007/s10791-015-9251-5,
author = {Sloan, Marc and Yang, Hui and Wang, Jun},
title = {A Term-Based Methodology for Query Reformulation Understanding},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9251-5},
doi = {10.1007/s10791-015-9251-5},
abstract = {Key to any research involving session search is the understanding of how a user's queries evolve throughout the session. When a user creates a query reformulation, he or she is consciously retaining terms from their original query, removing others and adding new terms. By measuring the similarity between queries we can make inferences on the user's information need and how successful their new query is likely to be. By identifying the origins of added terms we can infer the user's motivations and gain an understanding of their interactions. In this paper we present a novel term-based methodology for understanding and interpreting query reformulation actions. We use TREC Session Track data to demonstrate how our technique is able to learn from query logs and we make use of click data to test user interaction behavior when reformulating queries. We identify and evaluate a range of term-based query reformulation strategies and show that our methods provide valuable insight into understanding query reformulation in session search.
},
journal = {Inf. Retr.},
month = apr,
pages = {145–165},
numpages = {21},
keywords = {Query reformulation, Click model, Term model}
}

@article{10.1007/s10791-015-9250-6,
author = {Cai, Wenbin and Zhang, Muhan and Zhang, Ya},
title = {Active Learning for Ranking with Sample Density},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-015-9250-6},
doi = {10.1007/s10791-015-9250-6},
abstract = {While ranking is widely used in many online domains such as search engines and recommendation systems, it is non-trivial to label enough data examples to build a high performance machine-learned ranking model. To relieve this problem, active learning has been proposed, which selectively labels the most informative examples. However, data density, which has been proven helpful for data sampling in general, is ignored by most of the existing active learning for ranking studies. In this paper, we propose a novel active learning for ranking framework, generalization error minimization (GEM), which incorporates data density in minimizing generalization error. Concentrating on active learning for search ranking, we employ classical kernel density estimation to infer data density. Considering the unique query---document structure in ranking data, we estimate sample density at both query level and document level. Under the GEM framework, we propose new active learning algorithms at both query level and document level. Experimental results on the LETOR 4.0 data set and a real-world Web search ranking data set from a commercial search engine have demonstrated the effectiveness of the proposed active learning algorithms.},
journal = {Inf. Retr.},
month = apr,
pages = {123–144},
numpages = {22},
keywords = {Density, Learning to rank, Active learning}
}

@article{10.1007/s10791-014-9249-4,
author = {Lacerda, Anisio and Santos, Rodrygo L. and Veloso, Adriano and Ziviani, Nivio},
title = {Improving Daily Deals Recommendation Using Explore-Then-Exploit Strategies},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9249-4},
doi = {10.1007/s10791-014-9249-4},
abstract = {Daily-Deals Sites (DDSs) enable local businesses, such as restaurants and stores, to promote their products and services and to increase their sales by offering customers significantly reduced prices. If a customer finds a relevant deal in the catalog of electronic coupons, she can purchase it and the DDS receives a commission. Thus, offering relevant deals to customers maximizes the profitability of the DDS. An immediate strategy, therefore, would be to apply existing recommendation algorithms to suggest deals that are potentially relevant to specific customers, enabling more appealing, effective and personalized catalogs. However, this strategy may be innocuous because (1) most of the customers are sporadic bargain hunters, and thus past preference data is extremely sparse, (2) deals have a short living period, and thus data is extremely volatile, and (3) customers' taste and interest may undergo temporal drifts. In order to address such a particularly challenging scenario, we propose a new algorithm for daily deals recommendation based on an explore-then-exploit strategy. Basically, we choose a fraction of the customers to gather feedback on the current catalog in the exploration phase, and the remaining customers to receive improved recommendations based on the previously gathered feedback in a posterior exploitation phase. During exploration, a co-purchase network structure is updated with customer feedback (i.e., the purchases of the day), and during exploitation the updated network is used to enrich the recommendation algorithm. An advantage of our approach is that it is agnostic to the underlying recommender algorithm. Using real data obtained from a large DDS in Brazil, we show that the way in which we split customers into exploration and exploitation impacts by large the effectiveness of the recommendations. We evaluate different splitting strategies based on network centrality metrics and show that our approach offers gains in mean average precision and mean reciprocal rank ranging from 14 to 34 % when applied on top of state-of-the-art recommendation algorithms.},
journal = {Inf. Retr.},
month = apr,
pages = {95–122},
numpages = {28},
keywords = {Recommender systems, Armed bandit setting, Daily-deals sites}
}

@article{10.1007/s10791-014-9248-5,
author = {Santos, A\'{e}cio S. and Carvalho, Cristiano R. and Almeida, Jussara M. and Moura, Edleno S. and Silva, Altigran S. and Ziviani, Nivio},
title = {A Genetic Programming Framework to Schedule Webpage Updates},
year = {2015},
issue_date = {February  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9248-5},
doi = {10.1007/s10791-014-9248-5},
abstract = {The quality of a Web search engine is influenced by several factors, including coverage and the freshness of the content gathered by the web crawler. Focusing particularly on freshness, one key challenge is to estimate the likelihood of a previously crawled webpage being modified. 
Such estimates are used to define the order in which those pages should be visited, and thus, can be exploited to reduce the cost of monitoring crawled webpages for keeping updated versions. We here present a Genetic Programming framework, called $$ GP4C $$GP4C--Genetic Programming for Crawling, to generate score functions that produce accurate rankings of pages regarding their probabilities of having been modified. We compare $$ GP4C $$GP4C with state-of-the-art methods using a large dataset of webpages crawled from the Brazilian Web. Our evaluation includes multiple performance metrics and several variations of our framework, built from exploring different sets of terminals and fitness functions. In particular, we evaluate $$ GP4C $$GP4C using the ChangeRate and Normalized Discounted Cumulative Gain (NDCG) metrics as both objective function and evaluation metric. We show that, in comparison with ChangeRate, NDCG has the ability of better evaluating the effectiveness of scheduling strategies, since it is able to take the ranking produced by the scheduling into account.},
journal = {Inf. Retr.},
month = feb,
pages = {73–94},
numpages = {22},
keywords = {Scheduling functions, Web crawling, Genetic Programming}
}

@article{10.1007/s10791-014-9247-6,
author = {Dohnal, Vlastislav and Homola, Tomas and Zezula, Pavel},
title = {MDPV: Metric Distance Permutation Vocabulary},
year = {2015},
issue_date = {February  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9247-6},
doi = {10.1007/s10791-014-9247-6},
abstract = {Sub-image content-based similarity search forms an important operation in current image archives since it provides users with images that contain a query image as their part. Such a search can conveniently be implemented using the bag-of-features model. Its integral part is a construction of visual vocabulary. Most existing algorithms to create a visual vocabulary suffer from high computational (e.g. k-means) or supervisor-guidance (e.g. visual-bit classifier, or sparse coding) requirements. In this paper, we propose a novel approach to visual vocabulary construction called metric distance permutation vocabulary. It is based on permutations of metric distances to create compact visual words. Its major advantage over prior techniques is time and space efficiency of vocabulary construction and quantization process during querying, while achieving comparable or even better effectiveness (query result quality). Moreover, this basic concept is extended to combine more independent permutations. Both the proposals are experimented on well-known real-world data-sets and compared to other state-of-the-art techniques.},
journal = {Inf. Retr.},
month = feb,
pages = {51–72},
numpages = {22},
keywords = {Feature quantization, Metric distance permutation vocabulary, Visual vocabulary, k-Means clustering, Bag-of-features model}
}

@article{10.1007/s10791-014-9246-7,
author = {Wu, Haocheng and Hu, Yunhua and Li, Hang and Chen, Enhong},
title = {A New Approach to Query Segmentation for Relevance Ranking in Web Search},
year = {2015},
issue_date = {February  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9246-7},
doi = {10.1007/s10791-014-9246-7},
abstract = {In this paper, we try to determine how best to improve state-of-the-art methods for relevance ranking in web searching by query segmentation. Query segmentation is meant to separate the input query into segments, typically natural language phrases. We propose employing the re-ranking approach in query segmentation, which first employs a generative model to create the top k candidates and then employs a discriminative model to re-rank the candidates to obtain the final segmentation result. The method has been widely utilized for structure prediction in natural language processing, but has not been applied to query segmentation, as far as we know. Furthermore, we propose a new method for using the results of query segmentation in relevance ranking, which takes both the original query words and the segmented query phrases as units of query representation. We investigate whether our method can improve three relevance models, namely n-gram BM25, key n-gram model and term dependency model, within the framework of learning to rank. Our experimental results on large scale web search datasets show that our method can indeed significantly improve relevance ranking in all three cases.},
journal = {Inf. Retr.},
month = feb,
pages = {26–50},
numpages = {25},
keywords = {Web search, Re-ranking, BM25, Query processing, Term dependency model, Query segmentation, Key n-gram extraction, Relevance ranking}
}

@article{10.1007/s10791-014-9244-9,
author = {Li, Ximing and Ouyang, Jihong and Lu, You and Zhou, Xiaotang and Tian, Tian},
title = {Group Topic Model: Organizing Topics into Groups},
year = {2015},
issue_date = {February  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9244-9},
doi = {10.1007/s10791-014-9244-9},
abstract = {
Latent Dirichlet allocation defines hidden topics to capture latent semantics in text documents. However, it assumes that all the documents are represented by the same topics, resulting in the "forced topic" problem. To solve this problem, we developed a group latent Dirichlet allocation (GLDA). GLDA uses two kinds of topics: local topics and global topics. The highly related local topics are organized into groups to describe the local semantics, whereas the global topics are shared by all the documents to describe the background semantics. GLDA uses variational inference algorithms for both offline and online data. We evaluated the proposed model for topic modeling and document clustering. Our experimental results indicated that GLDA can achieve a competitive performance when compared with state-of-the-art approaches.
},
journal = {Inf. Retr.},
month = feb,
pages = {1–25},
numpages = {25},
keywords = {Document clustering, Topic modeling, Online learning, Group, Latent Dirichlet allocation, Variational inference}
}

@article{10.1007/s10791-014-9245-8,
author = {Hanbury, Allan and Lupu, Mihai and Kando, Noriko and Diallo, Barrou and Adams, Stephen},
title = {Guest Editorial: Special Issue on Information Retrieval in the Intellectual Property Domain},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9245-8},
doi = {10.1007/s10791-014-9245-8},
journal = {Inf. Retr.},
month = oct,
pages = {407–411},
numpages = {5}
}

@article{10.1007/s10791-014-9239-6,
author = {D'hondt, Eva and Verberne, Suzan and Oostdijk, Nelleke and Beney, Jean and Koster, Cornelius and Boves, Lou},
title = {Dealing with Temporal Variation in Patent Categorization},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9239-6},
doi = {10.1007/s10791-014-9239-6},
abstract = {
In this paper, we quantify the existence of concept drift in patent data, and examine its impact on classification accuracy. When developing algorithms for classifying incoming patent applications with respect to their category in the International Patent Classification (IPC) hierarchy, a temporal mismatch between training data and incoming documents may deteriorate classification results. We measure the effect of this temporal mismatch and aim to tackle it by optimal selection of training data. To illustrate the various aspects of concept drift on IPC class level, we first perform quantitative analyses on a subset of English abstracts extracted from patent documents in the CLEF-IP 2011 patent corpus. In a series of classification experiments, we then show the impact of temporal variation on the classification accuracy of incoming applications. We further examine what training data selection method, combined with our classification approach yields the best classifier; and how combining different text representations may improve patent classification. We found that using the most recent data is a better strategy than static sampling but that extending a set of recent training data with older documents does not harm classification performance. In addition, we confirm previous findings that using 2-skip-2-grams on top of the bag of unigrams structurally improves patent classification. Our work is an important contribution to the research into concept drift for text classification, and to the practice of classifying incoming patent applications.},
journal = {Inf. Retr.},
month = oct,
pages = {520–544},
numpages = {25},
keywords = {Concept drift, Text representation, Patent classification}
}

@article{10.1007/s10791-014-9238-7,
author = {Tannebaum, Wolfgang and Rauber, Andreas},
title = {Using Query Logs of USPTO Patent Examiners for Automatic Query Expansion in Patent Searching},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9238-7},
doi = {10.1007/s10791-014-9238-7},
abstract = {In the patent domain significant efforts are invested to assist researchers in formulating better queries, preferably via automated query expansion. Currently, automatic query expansion in patent search is mostly limited to computing co-occurring terms for the searchable features of the invention. Additional query terms are extracted automatically from patent documents based on entropy measures. Learning synonyms in the patent domain for automatic query expansion has been a difficult task. No dedicated sources providing synonyms for the patent domain, such as patent domain specific lexica or thesauri, are available. In this paper we focus on the highly professional search setting of patent examiners. In particular, we use query logs to learn synonyms for the patent domain. For automatic query expansion, we create term networks based on the query logs specifically for several USPTO patent classes. Experiments show good performance in automatic query expansion using these automatically generated term networks. Specifically, with a larger number of query logs for a specific patent US class available the performance of the learned term networks increases.},
journal = {Inf. Retr.},
month = oct,
pages = {452–470},
numpages = {19},
keywords = {Patent searching, Query expansion, Query log analysis}
}

@article{10.1007/s10791-013-9236-1,
author = {Zhou, Dong and Truran, Mark and Liu, Jianxun and Zhang, Sanrong},
title = {Using Multiple Query Representations in Patent Prior-Art Search},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9236-1},
doi = {10.1007/s10791-013-9236-1},
abstract = {
Before a patent application is made, it is important to search the appropriate databases for prior-art (i.e., pre-existing patents that may affect the validity of the application). Previous work on prior-art search has concentrated on single query representations of the patent application. In the following paper, we describe an approach which uses multiple query representations. We evaluate our technique using a well-known test collection (CLEF-IP 2011). Our results suggest that multiple query representations significantly outperform single query representations.},
journal = {Inf. Retr.},
month = oct,
pages = {471–491},
numpages = {21},
keywords = {Prior-art, Patent search, Collaborative filtering}
}

@article{10.1007/s10791-013-9234-3,
author = {Rusi\~{n}ol, Mar\c{c}al and Heras, Llu\'{\i}s-Pere and Terrades, Oriol Ramos},
title = {Flowchart Recognition for Non-Textual Information Retrieval in Patent Search},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9234-3},
doi = {10.1007/s10791-013-9234-3},
abstract = {Relatively little research has been done on the topic of patent image retrieval and in general in most of the approaches the retrieval is performed in terms of a similarity measure between the query image and the images in the corpus. However, systems aimed at overcoming the semantic gap between the visual description of patent images and their conveyed concepts would be very helpful for patent professionals. In this paper we present a flowchart recognition method aimed at achieving a structured representation of flowchart images that can be further queried semantically. The proposed method was submitted to the CLEF-IP 2012 flowchart recognition task. We report the obtained results on this dataset.},
journal = {Inf. Retr.},
month = oct,
pages = {545–562},
numpages = {18},
keywords = {Flowchart recognition, Raster-to-vector conversion, Patent documents, Text/graphics separation, Symbol recognition}
}

@article{10.1007/s10791-013-9233-4,
author = {Al-Shboul, Bashar and Myaeng, Sung-Hyon},
title = {Wikipedia-Based Query Phrase Expansion in Patent Class Search},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9233-4},
doi = {10.1007/s10791-013-9233-4},
abstract = {Relevance feedback methods generally suffer from topic drift caused by word ambiguities and synonymous uses of words. Topic drift is an important issue in patent information retrieval as people tend to use different expressions describing similar concepts causing low precision and recall at the same time. Furthermore, failing to retrieve relevant patents to an application during the examination process may cause legal problems caused by granting an existing invention. A possible cause of topic drift is utilizing a relevance feedback-based search method. As a way to alleviate the inherent problem, we propose a novel query phrase expansion approach utilizing semantic annotations in Wikipedia pages, trying to enrich queries with phrases disambiguating the original query words. The idea was implemented for patent search where patents are classified into a hierarchy of categories, and the analyses of the experimental results showed not only the positive roles of phrases and words in retrieving additional relevant documents through query expansion but also their contributions to alleviating the query drift problem. More specifically, our query expansion method was compared against relevance-based language model, a state-of-the-art query expansion method, to show its superiority in terms of MAP on all levels of the classification hierarchy.},
journal = {Inf. Retr.},
month = oct,
pages = {430–451},
numpages = {22},
keywords = {Phrase-based query expansion, Patent search, Clarity, Retrievability, Wikipedia categories}
}

@article{10.1007/s10791-013-9232-5,
author = {Mahdabi, Parvaz and Crestani, Fabio},
title = {The Effect of Citation Analysis on Query Expansion for Patent Retrieval},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9232-5},
doi = {10.1007/s10791-013-9232-5},
abstract = {Patent prior art search is a type of search in the patent domain where documents are searched for that describe the work previously carried out related to a patent application. The goal of this search is to check whether the idea in the patent application is novel. Vocabulary mismatch is one of the main problems of patent retrieval which results in low retrievability of similar documents for a given patent application. In this paper we show how the term distribution of the cited documents in an initially retrieved ranked list can be used to address the vocabulary mismatch. We propose a method for query modeling estimation which utilizes the citation links in a pseudo relevance feedback set. We first build a topic dependent citation graph, starting from the initially retrieved set of feedback documents and utilizing citation links of feedback documents to expand the set. We identify the important documents in the topic dependent citation graph using a citation analysis measure. We then use the term distribution of the documents in the citation graph to estimate a query model by identifying the distinguishing terms and their respective weights. We then use these terms to expand our original query. We use CLEF-IP 2011 collection to evaluate the effectiveness of our query modeling approach for prior art search. We also study the influence of different parameters on the performance of the proposed method. The experimental results demonstrate that the proposed approach significantly improves the recall over a state-of-the-art baseline which uses the link-based structure of the citation graph but not the term distribution of the cited documents.},
journal = {Inf. Retr.},
month = oct,
pages = {412–429},
numpages = {18},
keywords = {Query expansion, Citation analysis, Patent retrieval}
}

@article{10.1007/s10791-013-9231-6,
author = {Magdy, Walid and Jones, Gareth J.},
title = {Studying Machine Translation Technologies for Large-Data CLIR Tasks: A Patent Prior-Art Search Case Study},
year = {2014},
issue_date = {October   2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {5–6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9231-6},
doi = {10.1007/s10791-013-9231-6},
abstract = {Prior-art search in patent retrieval is concerned with finding all existing patents relevant to a patent application. Since patents often appear in different languages, cross-language information retrieval (CLIR) is an essential component of effective patent search. In recent years machine translation (MT) has become the dominant approach to translation in CLIR. Standard MT systems focus on generating proper translations that are morphologically and syntactically correct. Development of effective MT systems of this type requires large training resources and high computational power for training and translation. This is an important issue for patent CLIR where queries are typically very long sometimes taking the form of a full patent application, meaning that query translation using MT systems can be very slow. However, in contrast to MT, the focus for information retrieval (IR) is on the conceptual meaning of the search words regardless of their surface form, or the linguistic structure of the output. Thus much of the complexity of MT is not required for effective CLIR. We present an adapted MT technique specifically designed for CLIR. In this method IR text pre-processing in the form of stop word removal and stemming are applied to the MT training corpus prior to the training phase. Applying this step leads to a significant decrease in the MT computational and training resources requirements. Experimental application of the new approach to the cross language patent retrieval task from CLEF-IP 2010 shows that the new technique to be up to 23 times faster than standard MT for query translations, while maintaining IR effectiveness statistically indistinguishable from standard MT when large training resources are used. Furthermore the new method is significantly better than standard MT when only limited translation training resources are available, which can be a significant issue for translation in specialized domains. The new MT technique also enables patent document translation in a practical amount of time with a resulting significant improvement in the retrieval effectiveness.},
journal = {Inf. Retr.},
month = oct,
pages = {492–519},
numpages = {28},
keywords = {Cross-language patent retrieval, Machine translation, Cross-language information retrieval, Large-data CLIR, Prior-art Patent search}
}

@article{10.1007/s10791-014-9243-x,
author = {Vuurens, Jeroen B. and Vries, Arjen P.},
title = {Distance Matters! Cumulative Proximity Expansions for Ranking Documents},
year = {2014},
issue_date = {August    2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9243-x},
doi = {10.1007/s10791-014-9243-x},
abstract = {In the information retrieval 
process, functions that rank documents according to their estimated relevance to a query typically regard query terms as being independent. However, it is often the joint presence of query terms that is of interest to the user, which is overlooked when matching independent terms. One feature that can be used to express the relatedness of co-occurring terms is their proximity in text. In past research, models that are trained on the proximity information in a collection have performed better than models that are not estimated on data. We analyzed how co-occurring query terms can be used to estimate the relevance of documents based on their distance in text, which is used to extend a unigram ranking function with a proximity model that accumulates the scores of all occurring term combinations. This proximity model is more practical than existing models, since it does not require any co-occurrence statistics, it obviates the need to tune additional parameters, and has a retrieval speed close to competing models. We show that this approach is more robust than existing models, on both Web and newswire corpora, and on average performs equal or better than existing proximity models across collections.},
journal = {Inf. Retr.},
month = aug,
pages = {380–406},
numpages = {27},
keywords = {Query expansion, Term dependency, Term proximity}
}

@article{10.1007/s10791-014-9242-y,
author = {Hall, Mark M. and Fernando, Samuel and Clough, Paul D. and Soroa, Aitor and Agirre, Eneko and Stevenson, Mark},
title = {Evaluating Hierarchical Organisation Structures for Exploring Digital Libraries},
year = {2014},
issue_date = {August    2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9242-y},
doi = {10.1007/s10791-014-9242-y},
abstract = {Search boxes providing simple keyword-based search are insufficient when users have complex information needs or are unfamiliar with a collection, for example in large digital libraries. Browsing hierarchies can support these richer interactions, but many collections do not have a suitable hierarchy available. In this paper we present a number of approaches for automatically creating hierarchies and mapping items into them, including a novel technique which automatically adapts a Wikipedia-based taxonomy to the target collection. These approaches are applied to a large collection of cultural heritage items which is formed through the aggregation of other collections and for which no unified hierarchy is available. We investigate a number of novel user-evaluated metrics to quantify the hierarchies' quality and performance, showing that the proposed technique is preferred by users. From this we draw a number of conclusions as to what makes a hierarchy useful to the user.},
journal = {Inf. Retr.},
month = aug,
pages = {351–379},
numpages = {29},
keywords = {Evaluation, Exploratory search, Browsing, Hierarchical structures, Interactive information retrieval}
}

@article{10.1007/s10791-014-9241-z,
author = {Lee, Yeha and Lee, Jong-Hyeok},
title = {Identifying Top News Stories Based on Their Popularity in the Blogosphere},
year = {2014},
issue_date = {August    2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9241-z},
doi = {10.1007/s10791-014-9241-z},
abstract = {A huge volume of news stories are reported by various news channels, on a daily basis. Subscribing to all the stories and keeping track of the important ones day after day is very time-consuming. This paper proposes several approaches to identify important news stories. To this end, we take advantage of the blogosphere as an information source to evaluate the importance of news stories. Blogs reflect the diverse opinions of bloggers about news stories, and the attention that these stories receive can help estimate the importance of the stories. In this paper, we define the popularity of a news story in the blogosphere as the attention it attracts from users. We measure popularity of the stories in the blogosphere from two viewpoints: content and a timeline. In terms of content, we suggest several approaches to estimate language models for a news story and blog posts, and we evaluate the importance of the story using these language models. Furthermore, we generate a temporal profile of a news story by exploring the timeline of blog posts related to the story, and evaluate its importance based on the temporal profile. We experimentally verify the effectiveness of the proposed approaches for identifying top news stories.},
journal = {Inf. Retr.},
month = aug,
pages = {326–350},
numpages = {25},
keywords = {Blog retrieval, Top news stories identification, Language model approach, Blogosphere}
}

@article{10.1007/s10791-014-9240-0,
author = {Roa-Valverde, Antonio J. and Sicilia, Miguel-Angel},
title = {A Survey of Approaches for Ranking on the Web of Data},
year = {2014},
issue_date = {August    2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-014-9240-0},
doi = {10.1007/s10791-014-9240-0},
abstract = {Ranking information resources is a task that usually happens within more complex workflows and that typically occurs in any form of information retrieval, being commonly implemented by Web search engines. By filtering and rating data, ranking strategies guide the navigation of users when exploring large volumes of information items. There exist a considerable number of ranking algorithms that follow different approaches focusing on different aspects of the complex nature of the problem, and reflecting the variety of strategies that are possible to apply. With the growth of the web of linked data, a new problem space for ranking algorithms has emerged, as the nature of the information items to be ranked is very different from the case of Web pages. As a consequence, existing ranking algorithms have been adapted to the case of Linked Data and some specific strategies have started to be proposed and implemented. Researchers and organizations deploying Linked Data solutions thus require an understanding of the applicability, characteristics and state of evaluation of ranking strategies and algorithms as applied to Linked Data. We present a classification that formalizes and contextualizes under a common terminology the problem of ranking Linked Data. In addition, an analysis and contrast of the similarities, differences and applicability of the different approaches is provided. We aim this work to be useful when comparing different approaches to ranking Linked Data and when implementing new algorithms.},
journal = {Inf. Retr.},
month = aug,
pages = {295–325},
numpages = {31},
keywords = {Semantic search, Semantic web data management, Information retrieval, Link analysis, Linked data, Ranking algorithms}
}

@article{10.1007/s10791-013-9229-0,
author = {Wolff, Daniel and Weyde, Tillman},
title = {Learning Music Similarity from Relative User Ratings},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9229-0},
doi = {10.1007/s10791-013-9229-0},
abstract = {Computational modelling of music similarity is an increasingly important part of personalisation and optimisation in music information retrieval and research in music perception and cognition. The use of relative similarity ratings is a new and promising approach to modelling similarity that avoids well known problems with absolute ratings. In this article, we use relative ratings from the MagnaTagATune dataset with new and existing variants of state-of-the-art algorithms and provide the first comprehensive and rigorous evaluation of this approach. We compare metric learning based on support vector machines (SVMs) and metric-learning-to-rank (MLR), including a diagonal and a novel weighted variant, and relative distance learning with neural networks (RDNN). We further evaluate the effectiveness of different high and low level audio features and genre data, as well as dimensionality reduction methods, weighting of similarity ratings, and different sampling methods. Our results show that music similarity measures learnt on relative ratings can be significantly better than a standard Euclidian metric, depending on the choice of learning algorithm, feature sets and application scenario. MLR and SVM outperform DMLR and RDNN, while MLR with weighted ratings leads to no further performance gain. Timbral and music-structural features are most effective, and all features jointly are significantly better than any other combination of feature sets. Sharing audio clips (but not the similarity ratings) between test and training sets improves performance, in particular for the SVM-based methods, which is useful for some applications scenarios. A testing framework has been implemented in Matlab and made publicly available http://mi.soi.city.ac.uk/datasets/ir2012framework so that these results are reproducible.},
journal = {Inf. Retr.},
month = apr,
pages = {109–136},
numpages = {28},
keywords = {Relative similarity ratings, Music similarity, Metric learning to rank, Support vector machines, Metric learning, Neural networks}
}

@article{10.1007/s10791-013-9226-3,
author = {Aly, Robin and Demeester, Thomas and Robertson, Stephen},
title = {Probabilistic Models in IR and Their Relationships},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9226-3},
doi = {10.1007/s10791-013-9226-3},
abstract = {A solid research path towards new information retrieval models is to further develop the theory behind existing models. A profound understanding of these models is therefore essential. In this paper, we revisit probability ranking principle (PRP)-based models, probability of relevance (PR) models, and language models, finding conceptual differences in their definition and interrelationships. The probabilistic model of the PRP has not been explicitly defined previously, but doing so leads to the formulation of two actual principles with different objectives. First, the belief probability ranking principle (BPRP), which considers uncertain relevance between known documents and the current query, and second, the popularity probability ranking principle (PPRP), which considers the probability of relevance of documents among multiple queries with the same features. Our analysis shows how some of the discussed PR models implement the BPRP or the PPRP while others do not. However, for some models the parameter estimation is challenging. Finally, language models are often presented as related to PR models. However, we find that language models differ from PR models in every aspect of a probabilistic model and the effectiveness of language models cannot be explained by the PRP.},
journal = {Inf. Retr.},
month = apr,
pages = {177–201},
numpages = {25},
keywords = {Probability ranking principle, Language models, Probability of relevance, Probabilistic models}
}

@article{10.1007/s10791-013-9225-4,
author = {Kocaba\c{s}, undefinedlker and Din\c{c}er, Bekir Taner and Karao\u{g}lan, Bahar},
title = {A Nonparametric Term Weighting Method for Information Retrieval Based on Measuring the Divergence from Independence},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9225-4},
doi = {10.1007/s10791-013-9225-4},
abstract = {In this article, we introduce an out-of-the-box automatic term weighting method for information retrieval. The method is based on measuring the degree of divergence from independence of terms from documents in terms of their frequency of occurrence. Divergence from independence has a well-establish underling statistical theory. It provides a plain, mathematically tractable, and nonparametric way of term weighting, and even more it requires no term frequency normalization. Besides its sound theoretical background, the results of the experiments performed on TREC test collections show that its performance is comparable to that of the state-of-the-art term weighting methods in general. It is a simple but powerful baseline alternative to the state-of-the-art methods with its theoretical and practical aspects.},
journal = {Inf. Retr.},
month = apr,
pages = {153–176},
numpages = {24},
keywords = {Statistical dependence, Nonparametric index term weighting, Pearson's Chi-Square statistics, Information retrieval}
}

@article{10.1007/s10791-013-9224-5,
author = {Morid, Mohammad Amin and Shajari, Mehdi and Hashemi, Ali Reza},
title = {Defending Recommender Systems by Influence Analysis},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9224-5},
doi = {10.1007/s10791-013-9224-5},
abstract = {Collaborative filtering (CF) is a popular method for personalizing product recommendations for e-commerce applications. In order to recommend a product to a user and predict that user's preference, CF utilizes product evaluation ratings of like-minded users. The process of finding like-minded users forms a social network among all users and each link between two users represents an implicit connection between them. Users having more connections with others are the most influential users. Attacking recommender systems is a new issue for these systems. Here, an attacker tries to manipulate a recommender system in order to change the recommendation output according to her wish. If an attacker succeeds, her profile is used over and over again by the recommender system, making her an influential user. In this study, we applied the established attack detection methods to the influential users, instead of the whole user set, to improve their attack detection performance. Experiments were conducted using the same settings previously used to test the established methods. The results showed that the proposed influence-based method had better detection performance and improved the stability of a recommender system for most attack scenarios. It performed considerably better than established detection methods for attacks that inserted low numbers of attack profiles (20---25 %).},
journal = {Inf. Retr.},
month = apr,
pages = {137–152},
numpages = {16},
keywords = {Social network, Attack detection, Data mining, Recommender system, Shilling attack}
}

@article{10.1007/s10791-013-9228-1,
author = {Zheng, Wei and Fang, Hui and Yao, Conglei and Wang, Min},
title = {Leveraging Integrated Information to Extract Query Subtopics for Search Result Diversification},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9228-1},
doi = {10.1007/s10791-013-9228-1},
abstract = {Search result diversification aims to diversify search results to cover different query subtopics, i.e., pieces of relevant information. The state of the art diversification methods often explicitly model the diversity based on query subtopics, and their performance is closely related to the quality of subtopics. Most existing studies extracted query subtopics only from the unstructured data such as document collections. However, there exists a huge amount of information from structured data, which complements the information from the unstructured data. The structured data can provide valuable information about domain knowledge, but is currently under-utilized. In this article, we study how to leverage the integrated information from both structured and unstructured data to extract high quality subtopics for search result diversification. We first discuss how to extract subtopics from structured data. We then propose three methods to integrate structured and unstructured data. Specifically, the first method uses the structured data to guide the subtopic extraction from unstructured data, the second one uses the unstructured data to guide the extraction, and the last one first extracts the subtopics separately from two data sources and then combines those subtopics. Experimental results in both Enterprise and Web search domains show that the proposed methods are effective in extracting high quality subtopics from the integrated information, which can lead to better diversification performance.},
journal = {Inf. Retr.},
month = feb,
pages = {52–73},
numpages = {22},
keywords = {Unstructured data, Enterprise search, Structured data, Web search, Diversification, Query subtopics}
}

@article{10.1007/s10791-013-9227-2,
author = {Peetz, Maria-Hendrike and Meij, Edgar and Rijke, Maarten},
title = {Using Temporal Bursts for Query Modeling},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9227-2},
doi = {10.1007/s10791-013-9227-2},
abstract = {We present an approach to query modeling that leverages the temporal distribution of documents in an initially retrieved set of documents. In news-related document collections such distributions tend to exhibit bursts. Here, we define a burst to be a time period where unusually many documents are published. In our approach we detect bursts in result lists returned for a query. We then model the term distributions of the bursts using a reduced result list and select its most descriptive terms. Finally, we merge the sets of terms obtained in this manner so as to arrive at a reformulation of the original query. For query sets that consist of both temporal and non-temporal queries, our query modeling approach incorporates an effective selection method of terms. We consistently and significantly improve over various baselines, such as relevance models, on both news collections and a collection of blog posts.},
journal = {Inf. Retr.},
month = feb,
pages = {74–108},
numpages = {35},
keywords = {Information retrieval, Query modeling, Temporal information retrieval}
}

@article{10.1007/s10791-013-9220-9,
author = {Brosseau-Villeneuve, Bernard and Nie, Jian-Yun and Kando, Noriko},
title = {Latent Word Context Model for Information Retrieval},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9220-9},
doi = {10.1007/s10791-013-9220-9},
abstract = {The application of word sense disambiguation (WSD) techniques to information retrieval (IR) has yet to provide convincing retrieval results. Major obstacles to effective WSD in IR include coverage and granularity problems of word sense inventories, sparsity of document context, and limited information provided by short queries. In this paper, to alleviate these issues, we propose the construction of latent context models for terms using latent Dirichlet allocation. We propose building one latent context per word, using a well principled representation of local context based on word features. In particular, context words are weighted using a decaying function according to their distance to the target word, which is learnt from data in an unsupervised manner. The resulting latent features are used to discriminate word contexts, so as to constrict query's semantic scope. Consistent and substantial improvements, including on difficult queries, are observed on TREC test collections, and the techniques combines well with blind relevance feedback. Compared to traditional topic modeling, WSD and positional indexing techniques, the proposed retrieval model is more effective and scales well on large-scale collections.},
journal = {Inf. Retr.},
month = feb,
pages = {21–51},
numpages = {31},
keywords = {Topic models, Retrieval models, Word sense disambiguation (WSD), Word context discrimination (WCD), Word context}
}

@article{10.1007/s10791-013-9219-2,
author = {Ruan, Yu-Xun and Lin, Hsuan-Tien and Tsai, Ming-Feng},
title = {Improving Ranking Performance with Cost-Sensitive Ordinal Classification via Regression},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9219-2},
doi = {10.1007/s10791-013-9219-2},
abstract = {This paper proposes a novel ranking approach, cost-sensitive ordinal classification via regression (COCR), which respects the discrete nature of ordinal ranks in real-world data sets. In particular, COCR applies a theoretically sound method for reducing an ordinal classification to binary and solves the binary classification sub-tasks with point-wise regression. Furthermore, COCR allows us to specify mis-ranking costs to further improve the ranking performance; this ability is exploited by deriving a corresponding cost for a popular ranking criterion, expected reciprocal rank (ERR). The resulting ERR-tuned COCR boosts the benefits of the efficiency of using point-wise regression and the accuracy of top-rank prediction from the ERR criterion. Evaluations on four large-scale benchmark data sets, i.e., "Yahoo! Learning to Rank Challenge" and "Microsoft Learning to Rank," verify the significant superiority of COCR over commonly used regression approaches.},
journal = {Inf. Retr.},
month = feb,
pages = {1–20},
numpages = {20},
keywords = {Regression, List-wise ranking, Reduction, Cost-sensitive}
}

@article{10.1007/s10791-012-9217-9,
author = {Asadi, Nima and Lin, Jimmy},
title = {Document Vector Representations for Feature Extraction in Multi-Stage Document Ranking},
year = {2013},
issue_date = {December  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9217-9},
doi = {10.1007/s10791-012-9217-9},
abstract = {We consider a multi-stage retrieval architecture consisting of a fast, "cheap" candidate generation stage, a feature extraction stage, and a more "expensive" reranking stage using machine-learned models. In this context, feature extraction can be accomplished using a document vector index, a mapping from document ids to document representations. We consider alternative organizations of such a data structure for efficient feature extraction: design choices include how document terms are organized, how complex term proximity features are computed, and how these structures are compressed. In particular, we propose a novel document-adaptive hashing scheme for compactly encoding term ids. The impact of alternative designs on both feature extraction speed and memory footprint is experimentally evaluated. Overall, results show that our architecture is comparable in speed to using a traditional positional inverted index but requires less memory overall, and offers additional advantages in terms of flexibility.},
journal = {Inf. Retr.},
month = dec,
pages = {747–768},
numpages = {22},
keywords = {Compression, Document stores, Learning to rank}
}

@article{10.1007/s10791-012-9216-x,
author = {Kato, Makoto P. and Sakai, Tetsuya and Tanaka, Katsumi},
title = {When Do People Use Query Suggestion? A Query Suggestion Log Analysis},
year = {2013},
issue_date = {December  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9216-x},
doi = {10.1007/s10791-012-9216-x},
abstract = {Query suggestion, which enables the user to revise a query with a single click, has become one of the most fundamental features of Web search engines. However, it has not been clear what circumstances cause the user to turn to query suggestion. In order to investigate when and how the user uses query suggestion, we analyzed three kinds of data sets obtained from a major commercial Web search engine, comprising approximately 126 million unique queries, 876 million query suggestions and 306 million action patterns of users. Our analysis shows that query suggestions are often used (1) when the original query is a rare query, (2) when the original query is a single-term query, (3) when query suggestions are unambiguous, (4) when query suggestions are generalizations or error corrections of the original query, and (5) after the user has clicked on several URLs in the first search result page. Our results suggest that search engines should provide better assistance especially when rare or single-term queries are input, and that they should dynamically provide query suggestions according to the searcher's current state.},
journal = {Inf. Retr.},
month = dec,
pages = {725–746},
numpages = {22},
keywords = {Query log analysis, Web search, Query suggestion}
}

@article{10.1007/s10791-012-9214-z,
author = {Bellog\'{\i}n, Alejandro and Wang, Jun and Castells, Pablo},
title = {Bridging Memory-Based Collaborative Filtering and Text Retrieval},
year = {2013},
issue_date = {December  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9214-z},
doi = {10.1007/s10791-012-9214-z},
abstract = {When speaking of information retrieval, we often mean text retrieval. But there exist many other forms of information retrieval applications. A typical example is collaborative filtering that suggests interesting items to a user by taking into account other users' preferences or tastes. Due to the uniqueness of the problem, it has been modeled and studied differently in the past, mainly drawing from the preference prediction and machine learning view point. A few attempts have yet been made to bring back collaborative filtering to information (text) retrieval modeling and subsequently new interesting collaborative filtering techniques have been thus derived. In this paper, we show that from the algorithmic view point, there is an even closer relationship between collaborative filtering and text retrieval. Specifically, major collaborative filtering algorithms, such as the memory-based, essentially calculate the dot product between the user vector (as the query vector in text retrieval) and the item rating vector (as the document vector in text retrieval). Thus, if we properly structure user preference data and employ the target user's ratings as query input, major text retrieval algorithms and systems can be directly used without any modification. In this regard, we propose a unified formulation under a common notational framework for memory-based collaborative filtering, and a technique to use any text retrieval weighting function with collaborative filtering preference data. Besides confirming the rationale of the framework, our preliminary experimental results have also demonstrated the effectiveness of the approach in using text retrieval models and systems to perform item ranking tasks in collaborative filtering.},
journal = {Inf. Retr.},
month = dec,
pages = {697–724},
numpages = {28},
keywords = {Text retrieval models, Collaborative filtering, Recommender systems}
}

@article{10.1007/s10791-012-9213-0,
author = {Formoso, Vreixo and Fern\'{a}ndez, Diego and Cacheda, Fidel and Carneiro, Victor},
title = {Using Rating Matrix Compression Techniques to Speed up Collaborative Recommendations},
year = {2013},
issue_date = {December  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9213-0},
doi = {10.1007/s10791-012-9213-0},
abstract = {Collaborative filtering is a popular recommendation technique. Although researchers have focused on the accuracy of the recommendations, real applications also need efficient algorithms. An index structure can be used to store the rating matrix and compute recommendations very fast. In this paper we study how compression techniques can reduce the size of this index structure and, at the same time, speed up recommendations. We show how coding techniques commonly used in Information Retrieval can be effectively applied to collaborative filtering, reducing the matrix size up to 75 %, and almost doubling the recommendation speed. Additionally, we propose a novel identifier reassignment technique, that achieves high compression rates, reducing by 40 % the size of an already compressed matrix. It is a very simple approach based on assigning the smallest identifiers to the items and users with the highest number of ratings, and it can be efficiently computed using a two pass indexing. The usage of the proposed compression techniques can significantly reduce the storage and time costs of recommender systems, which are two important factors in many real applications.},
journal = {Inf. Retr.},
month = dec,
pages = {680–696},
numpages = {17},
keywords = {Collaborative filtering, Recommender systems, Rating matrix compression, Identifier assignment}
}

@article{10.1007/s10791-012-9212-1,
author = {Arampatzis, Avi and Efraimidis, Pavlos S. and Drosatos, George},
title = {A Query Scrambler for Search Privacy on the Internet},
year = {2013},
issue_date = {December  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9212-1},
doi = {10.1007/s10791-012-9212-1},
abstract = {We propose a method for search privacy on the Internet, focusing on enhancing plausible deniability against search engine query-logs. The method approximates the target search results, without submitting the intended query and avoiding other exposing queries, by employing sets of queries representing more general concepts. We model the problem theoretically, and investigate the practical feasibility and effectiveness of the proposed solution with a set of real queries with privacy issues on a large web collection. The findings may have implications for other IR research areas, such as query expansion and fusion in meta-search. Finally, we discuss ideas for privacy, such as k-anonymity, and how these may be applied to search tasks.},
journal = {Inf. Retr.},
month = dec,
pages = {657–679},
numpages = {23},
keywords = {Search privacy, WordNet, Fusion, Query scrambler}
}

@article{10.1007/s10791-012-9210-3,
author = {Litvak, Marina and Last, Mark},
title = {Cross-Lingual Training of Summarization Systems Using Annotated Corpora in a Foreign Language},
year = {2013},
issue_date = {October   2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9210-3},
doi = {10.1007/s10791-012-9210-3},
abstract = {The increasing trend of cross-border globalization and acculturation requires text summarization techniques to work equally well for multiple languages. However, only some of the automated summarization methods can be defined as "language-independent," i.e., not based on any language-specific knowledge. Such methods can be used for multilingual summarization, defined in Mani (Automatic summarization. Natural language processing. John Benjamins Publishing Company, Amsterdam, 2001 ) as "processing several languages, with a summary in the same language as input", but, their performance is usually unsatisfactory due to the exclusion of language-specific knowledge. Moreover, supervised machine learning approaches need training corpora in multiple languages that are usually unavailable for rare languages, and their creation is a very expensive and labor-intensive process. In this article, we describe cross-lingual methods for training an extractive single-document text summarizer called MUSE (MUltilingual Sentence Extractor)--a supervised approach, based on the linear optimization of a rich set of sentence ranking measures using a Genetic Algorithm. We evaluated MUSE's performance on documents in three different languages: English, Hebrew, and Arabic using several training scenarios. The summarization quality was measured using ROUGE-1 and ROUGE-2 Recall metrics. The results of the extensive comparative analysis showed that the performance of MUSE was better than that of the best known multilingual approach (TextRank) in all three languages. Moreover, our experimental results suggest that using the same sentence ranking model across languages results in a reasonable summarization quality, while saving considerable annotation efforts for the end-user. On the other hand, using parallel corpora generated by machine translation tools may improve the performance of a MUSE model trained on a foreign language. Comparative evaluation of an alternative optimization technique--Multiple Linear Regression--justifies the use of a Genetic Algorithm.},
journal = {Inf. Retr.},
month = oct,
pages = {629–656},
numpages = {28},
keywords = {Cross-lingual training, Multilingual summarization, Genetic Algorithm}
}

@article{10.1007/s10791-012-9209-9,
author = {Macdonald, Craig and Santos, Rodrygo L. and Ounis, Iadh},
title = {The Whens and Hows of Learning to Rank for Web Search},
year = {2013},
issue_date = {October   2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9209-9},
doi = {10.1007/s10791-012-9209-9},
abstract = {Web search engines are increasingly deploying many features, combined using learning to rank techniques. However, various practical questions remain concerning the manner in which learning to rank should be deployed. For instance, a sample of documents with sufficient recall is used, such that re-ranking of the sample by the learned model brings the relevant documents to the top. However, the properties of the document sample such as when to stop ranking--i.e. its minimum effective size--remain unstudied. Similarly, effective listwise learning to rank techniques minimise a loss function corresponding to a standard information retrieval evaluation measure. However, the appropriate choice of how to calculate the loss function--i.e. the choice of the learning evaluation measure and the rank depth at which this measure should be calculated--are as yet unclear. In this paper, we address all of these issues by formulating various hypotheses and research questions, before performing exhaustive experiments using multiple learning to rank techniques and different types of information needs on the ClueWeb09 and LETOR corpora. Among many conclusions, we find, for instance, that the smallest effective sample for a given query set is dependent on the type of information need of the queries, the document representation used during sampling and the test evaluation measure. As the sample size is varied, the selected features markedly change--for instance, we find that the link analysis features are favoured for smaller document samples. Moreover, despite reflecting a more realistic user model, the recently proposed ERR measure is not as effective as the traditional NDCG as a learning loss function. Overall, our comprehensive experiments provide the first empirical derivation of best practices for learning to rank deployments.},
journal = {Inf. Retr.},
month = oct,
pages = {584–628},
numpages = {45},
keywords = {Web search, Evaluation, Learning to rank, Loss function, Sample size, Document representations}
}

@article{10.1007/s10791-012-9207-y,
author = {Aly, Robin and Doherty, Aiden and Hiemstra, Djoerd and Jong, Franciska and Smeaton, Alan F.},
title = {The Uncertain Representation Ranking Framework for Concept-Based Video Retrieval},
year = {2013},
issue_date = {October   2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9207-y},
doi = {10.1007/s10791-012-9207-y},
abstract = {Concept based video retrieval often relies on imperfect and uncertain concept detectors. We propose a general ranking framework to define effective and robust ranking functions, through explicitly addressing detector uncertainty. It can cope with multiple concept-based representations per video segment and it allows the re-use of effective text retrieval functions which are defined on similar representations. The final ranking status value is a weighted combination of two components: the expected score of the possible scores, which represents the risk-neutral choice, and the scores' standard deviation, which represents the risk or opportunity that the score for the actual representation is higher. The framework consistently improves the search performance in the shot retrieval task and the segment retrieval task over several baselines in five TRECVid collections and two collections which use simulated detectors of varying performance.},
journal = {Inf. Retr.},
month = oct,
pages = {557–583},
numpages = {27},
keywords = {Representation uncertainty, Concept-based representation, Video retrieval}
}

@article{10.1007/s10791-013-9223-6,
author = {Sakai, Tetsuya and Kando, Noriko and Macdonald, Craig and Soboroff, Ian},
title = {Introduction to the Special Issue on Search Intents and Diversification},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9223-6},
doi = {10.1007/s10791-013-9223-6},
journal = {Inf. Retr.},
month = aug,
pages = {427–428},
numpages = {2}
}

@article{10.1007/s10791-013-9221-8,
author = {Wang, Qinglei and Qian, Yanan and Song, Ruihua and Dou, Zhicheng and Zhang, Fan and Sakai, Tetsuya and Zheng, Qinghua},
title = {Mining Subtopics from Text Fragments for a Web Query},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9221-8},
doi = {10.1007/s10791-013-9221-8},
abstract = {Web search queries are often ambiguous or faceted, and the task of identifying the major underlying senses and facets of queries has received much attention in recent years. We refer to this task as query subtopic mining. In this paper, we propose to use surrounding text of query terms in top retrieved documents to mine subtopics and rank them. We first extract text fragments containing query terms from different parts of documents. Then we group similar text fragments into clusters and generate a readable subtopic for each cluster. Based on the cluster and the language model trained from a query log, we calculate three features and combine them into a relevance score for each subtopic. Subtopics are finally ranked by balancing relevance and novelty. Our evaluation experiments with the NTCIR-9 INTENT Chinese Subtopic Mining test collection show that our method significantly outperforms a query log based method proposed by Radlinski et al. (2010) and a search result clustering based method proposed by Zeng et al. (2004) in terms of precision, I-rec, D-nDCG and D#-nDCG, the official evaluation metrics used at the NTCIR-9 INTENT task. Moreover, our generated subtopics are significantly more readable than those generated by the search result clustering method.},
journal = {Inf. Retr.},
month = aug,
pages = {484–503},
numpages = {20},
keywords = {Query intent, Intents ranking, Intent mining}
}

@article{10.1007/s10791-012-9218-8,
author = {Golbus, Peter B. and Aslam, Javed A. and Clarke, Charles L.},
title = {Increasing Evaluation Sensitivity to Diversity},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9218-8},
doi = {10.1007/s10791-012-9218-8},
abstract = {Many queries have multiple interpretations; they are ambiguous or underspecified. This is especially true in the context of Web search. To account for this, much recent research has focused on creating systems that produce diverse ranked lists. In order to validate these systems, several new evaluation measures have been created to quantify diversity. Ideally, diversity evaluation measures would distinguish between systems by the amount of diversity in the ranked lists they produce. Unfortunately, diversity is also a function of the collection over which the system is run and a system's performance at ad-hoc retrieval. A ranked list built from a collection that does not cover multiple subtopics cannot be diversified; neither can a ranked list that contains no relevant documents. To ensure that we are assessing systems by their diversity, we develop (1) a family of evaluation measures that take into account the diversity of the collection and (2) a meta-evaluation measure that explicitly controls for performance. We demonstrate experimentally that our new measures can achieve substantial improvements in sensitivity to diversity without reducing discriminative power.},
journal = {Inf. Retr.},
month = aug,
pages = {530–555},
numpages = {26},
keywords = {Diversity, Diversity difficulty, Evaluation}
}

@article{10.1007/s10791-012-9215-y,
author = {Wang, Chieh-Jen and Lin, Yung-Wei and Tsai, Ming-Feng and Chen, Hsin-Hsi},
title = {Mining Subtopics from Different Aspects for Diversifying Search Results},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9215-y},
doi = {10.1007/s10791-012-9215-y},
abstract = {User queries to the Web tend to have more than one interpretation due to their ambiguity and other characteristics. How to diversify the ranking results to meet users' various potential information needs has attracted considerable attention recently. This paper is aimed at mining the subtopics of a query either indirectly from the returned results of retrieval systems or directly from the query itself to diversify the search results. For the indirect subtopic mining approach, clustering the retrieval results and summarizing the content of clusters is investigated. In addition, labeling topic categories and concept tags on each returned document is explored. For the direct subtopic mining approach, several external resources, such as Wikipedia, Open Directory Project, search query logs, and the related search services of search engines, are consulted. Furthermore, we propose a diversified retrieval model to rank documents with respect to the mined subtopics for balancing relevance and diversity. Experiments are conducted on the ClueWeb09 dataset with the topics of the TREC09 and TREC10 Web Track diversity tasks. Experimental results show that the proposed subtopic-based diversification algorithm significantly outperforms the state-of-the-art models in the TREC09 and TREC10 Web Track diversity tasks. The best performance our proposed algorithm achieves is -nDCG@5 0.307, IA-P@5 0.121, and #-nDCG@5 0.214 on the TREC09, as well as -nDCG@10 0.421, IA-P@10 0.201, and #-nDCG@10 0.311 on the TREC10. The results conclude that the subtopic mining technique with the up-to-date users' search query logs is the most effective way to generate the subtopics of a query, and the proposed subtopic-based diversification algorithm can select the documents covering various subtopics.},
journal = {Inf. Retr.},
month = aug,
pages = {452–483},
numpages = {32},
keywords = {Search result re-ranking, Subtopic mining, Diversified retrieval}
}

@article{10.1007/s10791-012-9211-2,
author = {Santos, Rodrygo L. and Macdonald, Craig and Ounis, Iadh},
title = {Learning to Rank Query Suggestions for Adhoc and Diversity Search},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9211-2},
doi = {10.1007/s10791-012-9211-2},
abstract = {Query suggestions have become pervasive in modern web search, as a mechanism to guide users towards a better representation of their information need. In this article, we propose a ranking approach for producing effective query suggestions. In particular, we devise a structured representation of candidate suggestions mined from a query log that leverages evidence from other queries with a common session or a common click. This enriched representation not only helps overcome data sparsity for long-tail queries, but also leads to multiple ranking criteria, which we integrate as features for learning to rank query suggestions. To validate our approach, we build upon existing efforts for web search evaluation and propose a novel framework for the quantitative assessment of query suggestion effectiveness. Thorough experiments using publicly available data from the TREC Web track show that our approach provides effective suggestions for adhoc and diversity search.},
journal = {Inf. Retr.},
month = aug,
pages = {429–451},
numpages = {23},
keywords = {Diversity, Learning to rank, Web search, Relevance, Query suggestions}
}

@article{10.1007/s10791-012-9208-x,
author = {Sakai, Tetsuya and Song, Ruihua},
title = {Diversified Search Evaluation: Lessons from the NTCIR-9 INTENT Task},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9208-x},
doi = {10.1007/s10791-012-9208-x},
abstract = {The evaluation of diversified web search results is a relatively new research topic and is not as well-understood as the time-honoured evaluation methodology of traditional IR based on precision and recall. In diversity evaluation, one topic may have more than one  intent , and systems are expected to balance relevance and diversity. The recent NTCIR-9 evaluation workshop launched a new task called INTENT which included a diversified web search subtask that differs from the TREC web diversity task in several aspects: the choice of evaluation metrics, the use of intent popularity and per-intent graded relevance, and the use of topic sets that are twice as large as those of TREC. The objective of this study is to examine whether these differences are useful, using the actual data recently obtained from the NTCIR-9 INTENT task. Our main experimental findings are: (1) The  $$hbox{D},sharp$$  evaluation framework used at NTCIR provides more "intuitive" and statistically reliable results than Intent-Aware Expected Reciprocal Rank; (2) Utilising both intent popularity and per-intent graded relevance as is done at NTCIR tends to improve discriminative power, particularly for  $$hbox{D},sharp$$ -nDCG; and (3) Reducing the topic set size, even by just 10 topics, can affect not only significance testing but also the entire system ranking; when 50 topics are used (as in TREC) instead of 100 (as in NTCIR), the system ranking can be substantially different from the original ranking and the discriminative power can be halved. These results suggest that the directions being explored at NTCIR are valuable.},
journal = {Inf. Retr.},
month = aug,
pages = {504–529},
numpages = {26},
keywords = {Intents, Test collections, Search result diversification, NTCIR, Diversity, Web search, TREC, Evaluation}
}

@article{10.1007/s10791-012-9202-3,
author = {Goyal, Pawan and Behera, Laxmidhar and Mcginnity, T. M.},
title = {A Novel Neighborhood Based Document Smoothing Model for Information Retrieval},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9202-3},
doi = {10.1007/s10791-012-9202-3},
abstract = {In this paper, a novel neighborhood based document smoothing  model for information retrieval  has been proposed. Lexical association between terms is used to provide a context sensitive indexing weight to the document terms, i.e. the term weights are redistributed based on the lexical association with the context words. A generalized retrieval framework has been presented and it has been shown that the vector space model (VSM), divergence from randomness (DFR), Okapi Best Matching 25 (BM25) and the language model (LM) based retrieval frameworks are special cases of this generalized framework. Being proposed in the generalized retrieval framework, the neighborhood based document smoothing model is applicable to all the indexing models that use the term-document frequency scheme. The proposed smoothing model is as efficient as the baseline retrieval frameworks at runtime. Experiments over the TREC datasets show that the neighborhood based document smoothing model consistently improves the retrieval performance of VSM, DFR, BM25 and LM and the improvements are statistically significant.},
journal = {Inf. Retr.},
month = jun,
pages = {391–425},
numpages = {35},
keywords = {Document smoothing, Information retrieval, Lexical association}
}

@article{10.1007/s10791-012-9201-4,
author = {Cetintas, Suleyman and Chen, Datong and Si, Luo},
title = {Forecasting User Visits for Online Display Advertising},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9201-4},
doi = {10.1007/s10791-012-9201-4},
abstract = {Online display advertising is a multi-billion dollar industry where advertisers promote their products to users by having publishers display their advertisements on popular Web pages. An important problem in online advertising is how to forecast the number of user visits for a Web page during a particular period of time. Prior research addressed the problem by using traditional time-series forecasting techniques on historical data of user visits; (e.g., via a single regression model built for forecasting based on historical data for all Web pages) and did not fully explore the fact that different types of Web pages and different time stamps have different patterns of user visits. In this paper, we propose a series of probabilistic latent class models to automatically learn the underlying user visit patterns among multiple Web pages and multiple time stamps. The last (and the most effective) proposed model identifies latent groups/classes of (i) Web pages and (ii) time stamps with similar user visit patterns, and learns a specialized forecast model for each latent Web page and time stamp class. Compared with a single regression model as well as several other baselines, the proposed latent class model approach has the capability of differentiating the importance of different types of information across different classes of Web pages and time stamps, and therefore has much better modeling flexibility. An extensive set of experiments along with detailed analysis carried out on real-world data from Yahoo! demonstrates the advantage of the proposed latent class models in forecasting online user visits in online display advertising.},
journal = {Inf. Retr.},
month = jun,
pages = {369–390},
numpages = {22},
keywords = {Display advertising, Forecasting, User visits}
}

@article{10.1007/s10791-012-9200-5,
author = {Vuli\'{c}, Ivan and Smet, Wim and Moens, Marie-Francine},
title = {Cross-Language Information Retrieval Models Based on Latent Topic Models Trained with Document-Aligned Comparable Corpora},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9200-5},
doi = {10.1007/s10791-012-9200-5},
abstract = {In this paper, we study different applications of cross-language latent topic models trained on comparable corpora. The first focus lies on the task of cross-language information retrieval (CLIR). The Bilingual Latent Dirichlet allocation model (BiLDA) allows us to create an interlingual, language-independent representation of both queries and documents. We construct several BiLDA-based document models for CLIR, where no additional translation resources are used. The second focus lies on the methods for extracting translation candidates and semantically related words using only per-topic word distributions of the cross-language latent topic model. As the main contribution, we combine the two former steps, blending the evidences from the per-document topic distributions and the per-topic word distributions of the topic model with the knowledge from the extracted lexicon. We design and evaluate the novel evidence-rich statistical model for CLIR, and prove that such a model, which combines various (only internal) evidences, obtains the best scores for experiments performed on the standard test collections of the CLEF 2001---2003 campaigns. We confirm these findings in an alternative evaluation, where we automatically generate queries and perform the known-item search on a test subset of Wikipedia articles. The main importance of this work lies in the fact that we train translation resources from comparable document-aligned corpora and provide novel CLIR statistical models that exhaustively exploit as many cross-lingual clues as possible in the quest for better CLIR results, without use of any additional external resources such as parallel corpora or machine-readable dictionaries.},
journal = {Inf. Retr.},
month = jun,
pages = {331–368},
numpages = {38},
keywords = {Cross-language information retrieval, Unsupervised cross-language lexicon extraction, Evidence-rich retrieval models, Probabilistic latent topic models}
}

@article{10.1007/s10791-012-9198-8,
author = {Karimzadehgan, Maryam and Zhai, Chengxiang},
title = {A Learning Approach to Optimizing Exploration---Exploitation Tradeoff in Relevance Feedback},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9198-8},
doi = {10.1007/s10791-012-9198-8},
abstract = {Relevance feedback is an effective technique for improving search accuracy in interactive information retrieval. In this paper, we study an interesting optimization problem in interactive feedback that aims at optimizing the tradeoff between presenting search results with the highest immediate utility to a user (but not necessarily most useful for collecting feedback information) and presenting search results with the best potential for collecting useful feedback information (but not necessarily the most useful documents from a user's perspective). Optimizing such an exploration---exploitation tradeoff is key to the optimization of the overall utility of relevance feedback to a user in the entire session of relevance feedback. We formally frame this tradeoff as a problem of optimizing the diversification of search results since relevance judgments on more diversified results have been shown to be more useful for relevance feedback. We propose a machine learning approach to adaptively optimizing the diversification of search results for each query so as to optimize the overall utility in an entire session. Experiment results on three representative retrieval test collections show that the proposed learning approach can effectively optimize the exploration---exploitation tradeoff and outperforms the traditional relevance feedback approach which only does exploitation without exploration.},
journal = {Inf. Retr.},
month = jun,
pages = {307–330},
numpages = {24},
keywords = {Feedback, Interactive retrieval models, Diversification, User modeling}
}

@article{10.1007/s10791-013-9222-7,
author = {Lease, Matthew and Yilmaz, Emine},
title = {Crowdsourcing for Information Retrieval: Introduction to the Special Issue},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-013-9222-7},
doi = {10.1007/s10791-013-9222-7},
abstract = {This introduction to the special issue summarizes and contextualizes six novel research contributions at the intersection of information retrieval (IR) and crowdsourcing (also overlapping crowdsourcing's closely-related sibling, human computation). Several of the papers included in this special issue represent deeper investigations into research topics for which earlier stages of the authors' research were disseminated at crowdsourcing workshops at SIGIR and WSDM conferences, as well as at the NIST TREC conference. Since the first proposed use of crowdsourcing for IR in 2008, interest in this area has quickly accelerated and led to three workshops, an ongoing NIST TREC track, and a great variety of published papers, talks, and tutorials. We briefly summarize the area in order to help situate the contributions appearing in this special issue. We also discuss some broader current trends and issues in crowdsourcing which bear upon its use in IR and other fields.},
journal = {Inf. Retr.},
month = apr,
pages = {91–100},
numpages = {10},
keywords = {Search evaluation, Human computation, Crowdsourcing}
}

@article{10.1007/s10791-012-9206-z,
author = {Zuccon, Guido and Leelanupab, Teerapong and Whiting, Stewart and Yilmaz, Emine and Jose, Joemon M. and Azzopardi, Leif},
title = {Crowdsourcing Interactions: Using Crowdsourcing for Evaluating Interactive Information Retrieval Systems},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9206-z},
doi = {10.1007/s10791-012-9206-z},
abstract = {In the field of information retrieval (IR), researchers and practitioners are often faced with a demand for valid approaches to evaluate the performance of retrieval systems. The Cranfield experiment paradigm has been dominant for the in-vitro evaluation of IR systems. Alternative to this paradigm, laboratory-based user studies have been widely used to evaluate interactive information retrieval (IIR) systems, and at the same time investigate users' information searching behaviours. Major drawbacks of laboratory-based user studies for evaluating IIR systems include the high monetary and temporal costs involved in setting up and running those experiments, the lack of heterogeneity amongst the user population and the limited scale of the experiments, which usually involve a relatively restricted set of users. In this paper, we propose an alternative experimental methodology to laboratory-based user studies. Our novel experimental methodology uses a crowdsourcing platform as a means of engaging study participants. Through crowdsourcing, our experimental methodology can capture user interactions and searching behaviours at a lower cost, with more data, and within a shorter period than traditional laboratory-based user studies, and therefore can be used to assess the performances of IIR systems. In this article, we show the characteristic differences of our approach with respect to traditional IIR experimental and evaluation procedures. We also perform a use case study comparing crowdsourcing-based evaluation with laboratory-based evaluation of IIR systems, which can serve as a tutorial for setting up crowdsourcing-based IIR evaluations.},
journal = {Inf. Retr.},
month = apr,
pages = {267–305},
numpages = {39},
keywords = {Interactive IR evaluation, Crowdsourcing evaluation, Interactions}
}

@article{10.1007/s10791-012-9205-0,
author = {Kazai, Gabriella and Kamps, Jaap and Milic-Frayling, Natasa},
title = {An Analysis of Human Factors and Label Accuracy in Crowdsourcing Relevance Judgments},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9205-0},
doi = {10.1007/s10791-012-9205-0},
abstract = {Crowdsourcing relevance judgments for the evaluation of search engines is used increasingly to overcome the issue of scalability that hinders traditional approaches relying on a fixed group of trusted expert judges. However, the benefits of crowdsourcing come with risks due to the engagement of a self-forming group of individuals--the crowd, motivated by different incentives, who complete the tasks with varying levels of attention and success. This increases the need for a careful design of crowdsourcing tasks that attracts the right crowd for the given task and promotes quality work. In this paper, we describe a series of experiments using Amazon's Mechanical Turk, conducted to explore the `human' characteristics of the crowds involved in a relevance assessment task. In the experiments, we vary the level of pay offered, the effort required to complete a task and the qualifications required of the workers. We observe the effects of these variables on the quality of the resulting relevance labels, measured based on agreement with a gold set, and correlate them with self-reported measures of various human factors. We elicit information from the workers about their motivations, interest and familiarity with the topic, perceived task difficulty, and satisfaction with the offered pay. We investigate how these factors combine with aspects of the task design and how they affect the accuracy of the resulting relevance labels. Based on the analysis of 960 HITs and 2,880 HIT assignments resulting in 19,200 relevance labels, we arrive at insights into the complex interaction of the observed factors and provide practical guidelines to crowdsourcing practitioners. In addition, we highlight challenges in the data analysis that stem from the peculiarity of the crowdsourcing environment where the sample of individuals engaged in specific work conditions are inherently influenced by the conditions themselves.},
journal = {Inf. Retr.},
month = apr,
pages = {138–178},
numpages = {41},
keywords = {Study of human factors, Crowdsourcing, Relevance judgments}
}

@article{10.1007/s10791-012-9204-1,
author = {Alonso, Omar},
title = {Implementing Crowdsourcing-Based Relevance Experimentation: An Industrial Perspective},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9204-1},
doi = {10.1007/s10791-012-9204-1},
abstract = {Crowdsourcing has emerged as a viable platform for conducting different types of relevance evaluation. The main reason behind this trend is that it makes possible to conduct experiments extremely fast, with good results at a low cost. However, like in any experiment, there are several implementation details that would make an experiment work or fail. To gather useful results, clear instructions, user interface guidelines, content quality, inter-rater agreement metrics, work quality, and worker feedback are important characteristics of a successful crowdsourcing experiment. Furthermore, designing and implementing experiments that require thousands or millions of labels is different than conducting small scale research investigations. In this paper we outline a framework for conducting continuous crowdsourcing experiments, emphasizing aspects that should be of importance for all sorts of tasks. We illustrate the value of characteristics that can impact the overall outcome using examples based on TREC, INEX, and Wikipedia data sets.},
journal = {Inf. Retr.},
month = apr,
pages = {101–120},
numpages = {20},
keywords = {Crowdsourcing, Experiment design, Methodology, Relevance assessment &amp; evaluation}
}

@article{10.1007/s10791-012-9203-2,
author = {Munro, Robert},
title = {Crowdsourcing and the Crisis-Affected Community},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9203-2},
doi = {10.1007/s10791-012-9203-2},
abstract = {This article reports on Mission 4636, a real-time humanitarian crowdsourcing initiative that processed 80,000 text messages (SMS) sent from within Haiti following the 2010 earthquake. It was the first time that crowdsourcing (microtasking) had been used for international relief efforts, and is the largest deployment of its kind to date. This article presents the first full report and analysis of the initiative looking at the accuracy and timeliness in creating structured data from the messages and the collaborative nature of the process. Contrary to all previous papers, studies and media reports about Mission 4636, which have typically chosen to exclude empirical analyses and the involvement of the Haitian population, it is found that the greatest volume, speed and accuracy in information processing was by Haitian nationals, the Haitian diaspora, and those working closest with them, and that no new technologies played a significant role. It is concluded that international humanitarian organizations have been wrongly credited for large-scale information processing initiatives (here and elsewhere) and that for the most part they were largely just witnesses to crisis-affected communities bootstrapping their own recovery through communications technologies. The particular focus is on the role of the diaspora, an important population that are increasingly able to contribute to response efforts thanks to their increased communication potential. It is recommended that future humanitarian deployments of crowdsourcing focus on information processing within the populations they serve, engaging those with crucial local knowledge wherever they happen to be in the world.},
journal = {Inf. Retr.},
month = apr,
pages = {210–266},
numpages = {57},
keywords = {Microtasking, Crowdsourcing, Haiti, SMS}
}

@article{10.1007/s10791-012-9186-z,
author = {Mccreadie, Richard and Macdonald, Craig and Ounis, Iadh},
title = {Identifying Top News Using Crowdsourcing},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9186-z},
doi = {10.1007/s10791-012-9186-z},
abstract = {The influential Text REtrieval Conference (TREC) retrieval conference has always relied upon specialist assessors or occasionally participating groups to create relevance judgements for the tracks that it runs. Recently however, crowdsourcing has been championed as a cheap, fast and effective alternative to traditional TREC-like assessments. In 2010, TREC tracks experimented with crowdsourcing for the very first time. In this paper, we report our successful experience in creating relevance assessments for the TREC Blog track 2010 top news stories task using crowdsourcing. In particular, we crowdsourced both real-time newsworthiness assessments for news stories as well as traditional relevance assessments for blog posts. We conclude that crowdsourcing not only appears to be a feasible, but also cheap and fast means to generate relevance assessments. Furthermore, we detail our experiences running the crowdsourced evaluation of the TREC Blog track, discuss the lessons learned, and provide best practices.},
journal = {Inf. Retr.},
month = apr,
pages = {179–209},
numpages = {31},
keywords = {Blog, Relevance assessment, TREC, Top news, Crowdsourcing}
}

@article{10.1007/s10791-011-9181-9,
author = {Eickhoff, Carsten and Vries, Arjen P.},
title = {Increasing Cheat Robustness of Crowdsourcing Tasks},
year = {2013},
issue_date = {April     2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9181-9},
doi = {10.1007/s10791-011-9181-9},
abstract = {Crowdsourcing successfully strives to become a widely used means of collecting large-scale scientific corpora. Many research fields, including Information Retrieval, rely on this novel way of data acquisition. However, it seems to be undermined by a significant share of workers that are primarily interested in producing quick generic answers rather than correct ones in order to optimise their time-efficiency and, in turn, earn more money. Recently, we have seen numerous sophisticated schemes of identifying such workers. Those, however, often require additional resources or introduce artificial limitations to the task. In this work, we take a different approach by investigating means of a priori making crowdsourced tasks more resistant against cheaters.},
journal = {Inf. Retr.},
month = apr,
pages = {121–137},
numpages = {17},
keywords = {Human factors, Crowdsourcing, User experiments, Stability}
}

@article{10.1007/s10791-012-9197-9,
author = {Hofmann, Katja and Whiteson, Shimon and Rijke, Maarten},
title = {Balancing Exploration and Exploitation in Listwise and Pairwise Online Learning to Rank for Information Retrieval},
year = {2013},
issue_date = {February  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9197-9},
doi = {10.1007/s10791-012-9197-9},
abstract = {As retrieval systems become more complex, learning to rank approaches are being developed to automatically tune their parameters. Using online learning to rank, retrieval systems can learn directly from implicit feedback inferred from user interactions. In such an online setting, algorithms must obtain feedback for effective learning while simultaneously utilizing what has already been learned to produce high quality results. We formulate this challenge as an exploration---exploitation dilemma and propose two methods for addressing it. By adding mechanisms for balancing exploration and exploitation during learning, each method extends a state-of-the-art learning to rank method, one based on listwise learning and the other on pairwise learning. Using a recently developed simulation framework that allows assessment of online performance, we empirically evaluate both methods. Our results show that balancing exploration and exploitation can substantially and significantly improve the online retrieval performance of both listwise and pairwise approaches. In addition, the results demonstrate that such a balance affects the two approaches in different ways, especially when user feedback is noisy, yielding new insights relevant to making online learning to rank effective in practice.},
journal = {Inf. Retr.},
month = feb,
pages = {63–90},
numpages = {28},
keywords = {Information retrieval, Implicit feedback, Learning to rank}
}

@article{10.1007/s10791-012-9195-y,
author = {O'Hare, Neil and Murdock, Vanessa},
title = {Modeling Locations with Social Media},
year = {2013},
issue_date = {February  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9195-y},
doi = {10.1007/s10791-012-9195-y},
abstract = {In this paper we focus on the locations explicit and implicit in users descriptions of their surroundings. We propose a statistical language modeling approach to identifying locations in arbitrary text, and investigate several ways to estimate the models, based on the term frequency and the user frequency. The geotagged public photos in Flickr serve as a convenient ground truth. Our results show that we can predict location within a one kilometer by one kilometer cell with 17 % accuracy, and within a three kilometer radius around such a one kilometer cell with 40 % accuracy, using only a photo's tags. This is significantly better than the state of the art. Further we examine several estimation strategies that leverage the physical proximity of places, and show that for sparsely represented locations, smoothing from the immediate neighborhood improves results. We also show that estimation strategies based on user frequency are much more reliable than approaches based on the raw term frequency.},
journal = {Inf. Retr.},
month = feb,
pages = {30–62},
numpages = {33},
keywords = {Geographic context, Geotagging, Flickr, User-generated content, Language models}
}

@article{10.1007/s10791-012-9194-z,
author = {Shakery, Azadeh and Zhai, Chengxiang},
title = {Leveraging Comparable Corpora for Cross-Lingual Information Retrieval in Resource-Lean Language Pairs},
year = {2013},
issue_date = {February  2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9194-z},
doi = {10.1007/s10791-012-9194-z},
abstract = {Cross-language information retrieval (CLIR) has so far been studied with the assumption that some rich linguistic resources such as bilingual dictionaries or parallel corpora are available. But creation of such high quality resources is labor-intensive and they are not always at hand. In this paper we investigate the feasibility of using only comparable corpora for CLIR, without relying on other linguistic resources. Comparable corpora are text documents in different languages that cover similar topics and are often naturally attainable (e.g., news articles published in different languages at the same time period). We adapt an existing cross-lingual word association mining method and incorporate it into a language modeling approach to cross-language retrieval. We investigate different strategies for estimating the target query language models. Our evaluation results on the TREC Arabic---English cross-lingual data show that the proposed method is effective for the CLIR task, demonstrating that it is feasible to perform cross-lingual information retrieval with just comparable corpora.},
journal = {Inf. Retr.},
month = feb,
pages = {1–29},
numpages = {29},
keywords = {Probabilistic propagation, Comparable corpora, Language models, Cross-language information retrieval}
}

@article{10.1007/s10791-012-9192-1,
author = {Ali, M. Sadek and Consens, Mariano and Lalmas, Mounia},
title = {Extended Structural Relevance Framework: A Framework for Evaluating Structured Document Retrieval},
year = {2012},
issue_date = {December  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9192-1},
doi = {10.1007/s10791-012-9192-1},
abstract = {A structured document retrieval (SDR) system aims to minimize the effort users spend to locate relevant information by retrieving parts of documents. To evaluate the range of SDR tasks, from element to passage to tree retrieval, numerous task-specific measures have been proposed. This has resulted in SDR evaluation measures that cannot easily be compared with respect to each other and across tasks. In previous work, we defined the SDR task of tree retrieval where passage and element are special cases. In this paper, we look in greater detail into tree retrieval to identify the main components of SDR evaluation: relevance, navigation, and redundancy. Our goal is to evaluate SDR within a single probabilistic framework based on these components. This framework, called Extended Structural Relevance (ESR), calculates user expected gain in relevant information depending on whether it is seen via hits (relevant results retrieved), unseen via misses (relevant results not retrieved), or possibly seen via near-misses (relevant results accessed via navigation). We use these expectations as parameters to formulate evaluation measures for tree retrieval. We then demonstrate how existing task-specific measures, if viewed as tree retrieval, can be formulated, computed and compared using our framework. Finally, we experimentally validate ESR across a range of SDR tasks.},
journal = {Inf. Retr.},
month = dec,
pages = {558–590},
numpages = {33},
keywords = {Redundancy, Evaluation, User navigation, XML retrieval, Effectiveness measures, Tree retrieval, Relevance}
}

@article{10.1007/s10791-012-9184-1,
author = {Brisaboa, Nieves R. and Fari\~{n}a, Antonio and Ladra, Susana and Navarro, Gonzalo},
title = {Implicit Indexing of Natural Language Text by Reorganizing Bytecodes},
year = {2012},
issue_date = {December  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9184-1},
doi = {10.1007/s10791-012-9184-1},
abstract = {Word-based byte-oriented compression has succeeded on large natural language text databases, by providing competitive compression ratios, fast random access, and direct sequential searching. We show that by just rearranging the target symbols of the compressed text into a tree-shaped structure, and using negligible additional space, we obtain a new implicitly indexed representation of the compressed text, where search times are drastically improved. The occurrences of a word can be listed directly, without any text scanning, and in general any inverted-index-like capability, such as efficient phrase searches, can be emulated without storing any inverted list information. We experimentally show that our proposal performs not only much more efficiently than sequential searches over compressed text, but also than explicit inverted indexes and other types of indexes, when using little extra space. Our representation is especially successful when searching for single words and short phrases.},
journal = {Inf. Retr.},
month = dec,
pages = {527–557},
numpages = {31},
keywords = {Word-based compression, Compressed indexing, Searching compressed text}
}

@article{10.1007/s10791-012-9183-2,
author = {Yu, Qing and Miao, Zhengke and Wu, Gang and Wei, Yimin},
title = {Lumping Algorithms for Computing Google's PageRank and Its Derivative, with Attention to Unreferenced Nodes},
year = {2012},
issue_date = {December  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9183-2},
doi = {10.1007/s10791-012-9183-2},
abstract = {In this paper, we introduce five type nodes for lumping the Web matrix, and give a unified presentation of some popular lumping methods for PageRank. We show that the PageRank problem can be reduced to solving the PageRank corresponding to the strongly non-dangling and referenced nodes, and the full PageRank vector can be easily derived by some recursion formulations. Our new lumping strategy can reduce the original PageRank problem to a much smaller one, and it is much cheaper than the recursively reordering scheme. Furthermore, we discuss sensitivity of the PageRank vector, and present a lumping algorithm for computing its first order derivative. Numerical experiments show that the new algorithms are favorable when the matrix is large and the damping factor is high.},
journal = {Inf. Retr.},
month = dec,
pages = {503–526},
numpages = {24},
keywords = {Google, PageRank, Unreferenced nodes, Web information retrieval, Dangling nodes}
}

@article{10.1007/s10791-011-9180-x,
author = {Santos, Rodrygo L. and Macdonald, Craig and Ounis, Iadh},
title = {On the Role of Novelty for Search Result Diversification},
year = {2012},
issue_date = {October   2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9180-x},
doi = {10.1007/s10791-011-9180-x},
abstract = {Re-ranking the search results in order to promote novel ones has traditionally been regarded as an intuitive diversification strategy. In this paper, we challenge this common intuition and thoroughly investigate the actual role of novelty for search result diversification, based upon the framework provided by the diversity task of the TREC 2009 and 2010 Web tracks. Our results show that existing diversification approaches based solely on novelty cannot consistently improve over a standard, non-diversified baseline ranking. Moreover, when deployed as an additional component by the current state-of-the-art diversification approaches, our results show that novelty does not bring significant improvements, while adding considerable efficiency overheads. Finally, through a comprehensive analysis with simulated rankings of various quality, we demonstrate that, although inherently limited by the performance of the initial ranking, novelty plays a role at breaking the tie between similarly diverse results.},
journal = {Inf. Retr.},
month = oct,
pages = {478–502},
numpages = {25},
keywords = {Relevance, Web search, Diversity}
}

@article{10.1007/s10791-011-9179-3,
author = {Krestel, Ralf and Fankhauser, Peter},
title = {Reranking Web Search Results for Diversity},
year = {2012},
issue_date = {October   2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9179-3},
doi = {10.1007/s10791-011-9179-3},
abstract = {Search engine results are often biased towards a certain aspect of a query or towards a certain meaning for ambiguous query terms. Diversification of search results offers a way to supply the user with a better balanced result set increasing the probability that a user finds at least one document suiting her information need. In this paper, we present a reranking approach based on minimizing variance of Web search results to improve topic coverage in the top-k results. We investigate two different document representations as the basis for reranking. Smoothed language models and topic models derived by Latent Dirichlet allocation. To evaluate our approach we selected 240 queries from Wikipedia disambiguation pages. This provides us with ambiguous queries together with a community generated balanced representation of their (sub)topics. For these queries we crawled two major commercial search engines. In addition, we present a new evaluation strategy based on Kullback-Leibler divergence and Wikipedia. We evaluate this method using the TREC sub-topic evaluation on the one hand, and manually annotated query results on the other hand. Our results show that minimizing variance in search results by reranking relevant pages significantly improves topic coverage in the top-  k  results with respect to Wikipedia, and gives a good overview of the overall search result. Moreover, latent topic models achieve competitive diversification with significantly less reranking. Finally, our evaluation reveals that our automatic evaluation strategy using Kullback-Leibler divergence correlates well with -nDCG scores used in manual evaluation efforts.},
journal = {Inf. Retr.},
month = oct,
pages = {458–477},
numpages = {20},
keywords = {Wikipedia, Diversity, Topic models, Language models, Web search, Reranking, Diversity evaluation, Variance}
}

@article{10.1007/s10791-011-9178-4,
author = {Zheng, Wei and Wang, Xuanhui and Fang, Hui and Cheng, Hong},
title = {Coverage-Based Search Result Diversification},
year = {2012},
issue_date = {October   2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9178-4},
doi = {10.1007/s10791-011-9178-4},
abstract = {Traditional retrieval models may provide users with less satisfactory search experience because documents are scored independently and the top ranked documents often contain excessively redundant information. Intuitively, it is more desirable to diversify search results so that the top-ranked documents can cover different query subtopics, i.e., different pieces of relevant information. In this paper, we study the problem of search result diversification in an optimization framework whose objective is to maximize a coverage-based diversity function. We first define the diversity score of a set of search results through measuring the coverage of query subtopics in the result set, and then discuss how to use them to derive diversification methods. The key challenge here is how to define an appropriate coverage function given a query and a set of search results. To address this challenge, we propose and systematically study three different strategies to define coverage functions. They are based on summations, loss functions and evaluation measures respectively. Each of these coverage functions leads to a result diversification method. We show that the proposed coverage based diversification methods not only cover several state-of-the-art methods but also allows us to derive new ones. We compare these methods both analytically and empirically. Experiment results on two standard TREC collections show that all the methods are effective for diversification and the new methods can outperform existing ones.},
journal = {Inf. Retr.},
month = oct,
pages = {433–457},
numpages = {25},
keywords = {Diversification, Subtopic, Coverage, Information retrieval}
}

@article{10.1007/s10791-011-9177-5,
author = {Garc\'{\i}a-Cumbreras, M. \'{A}. and Mart\'{\i}nez-Santiago, F. and Ure\~{n}a-L\'{o}pez, L. A.},
title = {Architecture and Evaluation of BRUJA, a Multilingual Question Answering System},
year = {2012},
issue_date = {October   2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9177-5},
doi = {10.1007/s10791-011-9177-5},
abstract = {Given a user question, the goal of a Question Answering (QA) system is to retrieve answers rather than full documents or even best-matching passages, as most Information Retrieval systems currently do. In this paper, we present BRUJA, a QA system for the management of multilingual collections. BRUJ rkstions (English, Spanish and French). The BRUJA architecture is not formed with three monolingual QA systems but instead uses English as Interlingua to make usual QA tasks such as question classifications and answer extractions. In addition, BRUJA uses Cross Language Information Retrieval (CLIR) techniques to retrieve relevant documents from a multilingual collection. On the one hand, we have more documents to find answers from but on the other hand, we are introducing noise into the system because of translations to the Interlingua (English) and the CLIR module. The question is whether the difficulty of managing three languages is worth it or whether a monolingual QA system delivers better results. We report on in-depth experimentation and demonstrate that our multilingual QA system gets better results than its monolingual counterpart whenever it uses good translation resources and, especially, CLIR techniques that are state-of-the-art.},
journal = {Inf. Retr.},
month = oct,
pages = {413–432},
numpages = {20},
keywords = {Cross Language Information Retrieval, Multilingual question answering, Question answering}
}

@article{10.1007/s10791-012-9199-7,
author = {Wang, Fei and Cui, Peng and Sun, Gordon and Chua, Tat-Seng and Yang, Shiqiang},
title = {Guest Editorial: Special Issue on Information Retrieval for Social Media},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9199-7},
doi = {10.1007/s10791-012-9199-7},
journal = {Inf. Retr.},
month = jun,
pages = {179–182},
numpages = {4}
}

@article{10.1007/s10791-012-9196-x,
author = {Zhang, Dan and Si, Luo and Rego, Vernon J.},
title = {Sentiment Detection with Auxiliary Data},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9196-x},
doi = {10.1007/s10791-012-9196-x},
abstract = {As an important application in text mining and social media, sentiment detection has aroused more and more research interests, due to the expanding volume of available online information such as microblogging messages and review comments. Many machine learning methods have been proposed for sentiment detection. As a branch of machine learning, transfer learning is an important technique that tries to transfer knowledge from one domain to another one. When applied to sentiment detection, existing transfer learning methods employ articles with human labeled sentiments from other domains to help the sentiment detection on a target domain. Although most existing transfer learning methods are devoted to handle the data distribution difference between different domains, they only resort to some approximation methods, which may introduce some unnecessary biases. Furthermore, the popular assumption of existing transfer learning techniques on conditional probability is often too strong for practical applications. In this paper, we propose a novel method to model the distribution difference between different domains in sentiment detection by directly modeling the underlying joint distributions for different domains. Some of the important properties of the proposed method, such as the convergence rate and time complexity, are analyzed. The experimental results on the product review dataset and the twitter dataset demonstrate the advantages of the proposed method over the state-of-the-art methods.},
journal = {Inf. Retr.},
month = jun,
pages = {373–390},
numpages = {18},
keywords = {Sentiment detection, Twitter, Social media, Transfer learning, Microblogging}
}

@article{10.1007/s10791-012-9193-0,
author = {Wang, Jingdong and Zhao, Zhe and Zhou, Jiazhen and Wang, Hao and Cui, Bin and Qi, Guojun},
title = {Recommending Flickr Groups with Social Topic Model},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9193-0},
doi = {10.1007/s10791-012-9193-0},
abstract = {The explosion of multimedia content in social media networks raises a great demand of developing tools to facilitate producing, sharing and viewing media content. Flickr groups, self-organized communities with declared common interests, are able to help users to conveniently participate in social media network. In this paper, we address the problem of automatically recommending groups to users. We propose to simultaneously exploit media contents and link structures between users and groups. To this end, we present a probabilistic latent topic model to model them in an integrated framework, expecting to jointly discover the latent interests for users and groups and simultaneously learn the recommendation function. We demonstrate the proposed approach on the dataset crawled from Flickr.com.},
journal = {Inf. Retr.},
month = jun,
pages = {278–295},
numpages = {18},
keywords = {Recommendation, Flickr group, Social topic model}
}

@article{10.1007/s10791-012-9191-2,
author = {Zhou, Dong and Lawless, S\'{e}amus and Wade, Vincent},
title = {Improving Search via Personalized Query Expansion Using Social Media},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9191-2},
doi = {10.1007/s10791-012-9191-2},
abstract = {Social tagging systems have gained increasing popularity as a method of annotating and categorizing a wide range of different web resources. Web search that utilizes social tagging data suffers from an extreme example of the vocabulary mismatch problem encountered in traditional information retrieval (IR). This is due to the personalized, unrestricted vocabulary that users choose to describe and tag each resource. Previous research has proposed the utilization of query expansion to deal with search in this rather complicated space. However, non-personalized approaches based on relevance feedback and personalized approaches based on co-occurrence statistics only showed limited improvements. This paper proposes a novel query expansion framework based on individual user profiles mined from the annotations and resources the user has marked. The underlying theory is to regularize the smoothness of word associations over a connected graph using a regularizer function on terms extracted from top-ranked documents. The intuition behind the model is the prior assumption of term consistency: the most appropriate expansion terms for a query are likely to be associated with, and influenced by terms extracted from the documents ranked highly for the initial query. The framework also simultaneously incorporates annotations and web documents through a Tag-Topic model in a latent graph. The experimental results suggest that the proposed personalized query expansion method can produce better results than both the classical non-personalized search approach and other personalized query expansion methods. Hence, the proposed approach significantly benefits personalized web search by leveraging users' social media data.},
journal = {Inf. Retr.},
month = jun,
pages = {218–242},
numpages = {25},
keywords = {Query expansion, Social media, Graph algorithm, Tag-Topic model, Personalization, Web search}
}

@article{10.1007/s10791-012-9190-3,
author = {Tong, Hanghang and Papadimitriou, Spiros and Faloutsos, Christos and Yu, Philip S. and Eliassi-Rad, Tina},
title = {Gateway Finder in Large Graphs: Problem Definitions and Fast Solutions},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9190-3},
doi = {10.1007/s10791-012-9190-3},
abstract = {Given a graph, how to find a small group of `gateways', that is a small subset of nodes that are crucial in connecting the source to the target? For instance, given a social network, who is the best person to introduce you to, say, Chris Ferguson, the poker champion? Or, given a network of people and skills, who is the best person to help you learn about, say, wavelets? We formally formulate this problem in two scenarios: Pair-Gateway and Group-Gateway. For each scenario, we show that it is sub-modular and thus it can be solved near-optimally. We further give fast, scalable algorithms to find such gateways. Extensive experimental evaluations on real data sets demonstrate the effectiveness and efficiency of the proposed methods.},
journal = {Inf. Retr.},
month = jun,
pages = {391–411},
numpages = {21},
keywords = {Sub-modularity, Scalability, Social network, Graph mining, Gateway}
}

@article{10.1007/s10791-012-9189-9,
author = {Magnani, Matteo and Montesi, Danilo and Rossi, Luca},
title = {Conversation Retrieval for Microblogging Sites},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9189-9},
doi = {10.1007/s10791-012-9189-9},
abstract = {In this article we introduce a novel search paradigm for microblogging sites resulting from the intersection of Information Retrieval and Social Network Analysis (SNA). This approach is based on a formal model of on-line conversations and a set of ranking measures including SNA centrality metrics, time-related conversational metrics and other specific features of current microblogging sites. The ranking approach has been compared to other methods and tested on two well known social network sites (Twitter and Friendfeed) showing that the inclusion of SNA metrics in the ranking function and the usage of a model of conversation can improve the results of search tasks.},
journal = {Inf. Retr.},
month = jun,
pages = {354–372},
numpages = {19},
keywords = {Monitoring, Conversation retrieval, Social network analysis metrics, Social media, Social network sites}
}

@article{10.1007/s10791-012-9188-x,
author = {Hao, Tianyong and Agichtein, Eugene},
title = {Finding Similar Questions in Collaborative Question Answering Archives: Toward Bootstrapping-Based Equivalent Pattern Learning},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9188-x},
doi = {10.1007/s10791-012-9188-x},
abstract = {Many questions submitted to Collaborative Question Answering (CQA) sites have similar questions answered before. We propose a precise approach of automatically finding an answer to such questions by automatically identifying "equivalent" questions submitted and answered, in the past. Our method is based on automatically generating equivalent question patterns by grouping together questions that have previously obtained the same answers. The generated patterns are used as seed patterns to match more questions to extract large number of equivalent patterns by a new bootstrapping-based learning method. The resulting patterns can be applied to match a new question to an equivalent one that has already been answered, and thus suggest potential answers automatically. We experimented with this approach over a large collection of more than 200,000 real questions drawn from the Yahoo! Answers archive, automatically acquiring over 16,991 groups of equivalent question patterns. These patterns allow our method to obtain over 57% recall and over 54% precision on suggesting an answer automatically to new questions, significantly improving over baseline methods.},
journal = {Inf. Retr.},
month = jun,
pages = {332–353},
numpages = {22},
keywords = {Collaborative question answering, Bootstrapping, Pattern extension, Equivalent pattern}
}

@article{10.1007/s10791-012-9187-y,
author = {Schedl, Markus},
title = {#nowplaying Madonna: A Large-Scale Evaluation on Estimating Similarities between Music Artists and between Movies from Microblogs},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9187-y},
doi = {10.1007/s10791-012-9187-y},
abstract = {Different term weighting techniques such as  $$TFcdot IDF$$  or  BM25  have been used intensely for manifold text-based information retrieval tasks. Their use for modeling term profiles for named entities and subsequent calculation of similarities between these named entities have been studied to a much smaller extent. The recent trend of microblogging made available massive amounts of information about almost every topic around the world. Therefore, microblogs represent a valuable source for text-based named entity modeling. In this paper, we present a systematic and comprehensive evaluation of different  term weighting measures ,  normalization techniques ,  query schemes ,  index term sets , and  similarity functions  for the task of inferring similarities between named entities, based on data extracted from  microblog posts . We analyze several thousand combinations of choices for the above mentioned dimensions, which influence the similarity calculation process, and we investigate in which way they impact the quality of the similarity estimates. Evaluation is performed using three real-world data sets: two collections of microblogs related to music artists and one related to movies. For the music collections, we present results of  genre classification experiments  using as benchmark genre information from  allmusic.com  . For the movie collection, we present results of  multi-class classification experiments  using as benchmark categories from  IMDb  . We show that microblogs can indeed be exploited to model named entity similarity with remarkable accuracy, provided the correct settings for the analyzed aspects are used. We further compare the results to those obtained when using Web pages as data source.},
journal = {Inf. Retr.},
month = jun,
pages = {183–217},
numpages = {35},
keywords = {Vector space model, Information extraction, Term weighting, Evaluation, Social media mining, Microblog analysis}
}

@article{10.1007/s10791-012-9185-0,
author = {Fleming, Simon and Chalmers, Dan and Wakeman, Ian},
title = {A Deniable and Efficient Question and Answer Service over Ad Hoc Social Networks},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-012-9185-0},
doi = {10.1007/s10791-012-9185-0},
abstract = {When people are connected together over ad hoc social networks, it is possible to ask questions and retrieve answers using the wisdom of the crowd. However, locating a suitable candidate for answering a specific unique question within larger ad hoc groups is non-trivial, especially if we wish to respect the privacy of users by providing deniability. All members of the network wish to source the best possible answers from the network, while at the same time controlling the levels of attention required to generate them by the collective group of individuals and/or the time taken to read all the answers. Conventional expert retrieval approaches rank users for a given query in a centralised indexing process, associating users with material they have previously published. Such an approach is antithetical to privacy, so we have looked to distribute the routing of questions and answers, converting the indexing process into one of building a forwarding table. Starting from the simple operation of flooding the question to everyone, we compare a number of different routing options, where decisions must be made based on past performance and exploitation of the knowledge of our immediate neighbours. We focus on fully decentralised protocols using ant-inspired tactics to route questions towards members of the network who may be able to answer them well. Simultaneously, privacy concerns are acknowledged by allowing both question asking and answering to be plausibly deniable. We have found that via our routing method, it is possible to improve answer quality and also reduce the total amount of user attention required to generate those answers.},
journal = {Inf. Retr.},
month = jun,
pages = {296–331},
numpages = {36},
keywords = {Expert search, Ad hoc social networks, Privacy via plausible deniability, Expert retrieval, Stigmergy, Real time Q&amp;A routing}
}

@article{10.1007/s10791-011-9182-8,
author = {Weerkamp, Wouter and Rijke, Maarten},
title = {Credibility-Inspired Ranking for Blog Post Retrieval},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9182-8},
doi = {10.1007/s10791-011-9182-8},
abstract = {Credibility of information refers to its believability or the believability of its sources. We explore the impact of credibility-inspired indicators on the task of blog post retrieval, following the intuition that more credible blog posts are preferred by searchers. Based on a previously introduced credibility framework for blogs, we define several credibility indicators, and divide them into post-level (e.g., spelling, timeliness, document length) and blog-level (e.g., regularity, expertise, comments) indicators. The retrieval task at hand is precision-oriented, and we hypothesize that the use of credibility-inspired indicators will positively impact precision. We propose to use ideas from the credibility framework in a reranking approach to the blog post retrieval problem: We introduce two simple ways of reranking the top n of an initial run. The first approach, Credibility-inspired reranking, simply reranks the top n of a baseline based on the credibility-inspired score. The second approach, Combined reranking, multiplies the credibility-inspired score of the top n results by their retrieval score, and reranks based on this score. Results show that Credibility-inspired reranking leads to larger improvements over the baseline than Combined reranking, but both approaches are capable of improving over an already strong baseline. For Credibility-inspired reranking the best performance is achieved using a combination of all post-level indicators. Combined reranking works best using the post-level indicators combined with comments and pronouns. The blog-level indicators expertise, regularity, and coherence do not contribute positively to the performance, although analysis shows that they can be useful for certain topics. Additional analysis shows that a relative small value of n (15---25) leads to the best results, and that posts that move up the ranking due to the integration of reranking based on credibility-inspired indicators do indeed appear to be more credible than the ones that go down.},
journal = {Inf. Retr.},
month = jun,
pages = {243–277},
numpages = {35},
keywords = {Reranking, Blog post retrieval, Credibility}
}

@article{10.1007/s10791-011-9176-6,
author = {Lee, Yeha and Na, Seung-Hoon and Lee, Jong-Hyeok},
title = {Utilizing Local Evidence for Blog Feed Search},
year = {2012},
issue_date = {April     2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9176-6},
doi = {10.1007/s10791-011-9176-6},
abstract = {Blog feed search aims to identify a blog feed of recurring interest to users on a given topic. A blog feed, the retrieval unit for blog feed search, comprises blog posts of diverse topics. This topical diversity of blog feeds often causes performance deterioration of blog feed search. To alleviate the problem, this paper proposes several approaches based on passage retrieval, widely regarded as effective to handle topical diversity at document level in ad-hoc retrieval. We define the global and local evidence for blog feed search, which correspond to the document-level and passage-level evidence for passage retrieval, respectively, and investigate their influence on blog feed search, in terms of both initial retrieval and pseudo-relevance feedback. For initial retrieval, we propose a retrieval framework to integrate global evidence with local evidence. For pseudo-relevance feedback, we gather feedback information from the local evidence of the top K ranked blog feeds to capture diverse and accurate information related to a given topic. Experimental results show that our approaches using local evidence consistently and significantly outperform traditional ones.},
journal = {Inf. Retr.},
month = apr,
pages = {157–177},
numpages = {21},
keywords = {Blog feed search, Pseudo-relevance feedback, Blog distillation, Passage-based retrieval}
}

@article{10.1007/s10791-011-9175-7,
author = {Krupka, Michal},
title = {On Complexity Reduction of Concept Lattices: Three Counterexamples},
year = {2012},
issue_date = {April     2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9175-7},
doi = {10.1007/s10791-011-9175-7},
abstract = {We discuss the paper by Cheung and Vogel, Inf Retr 8(2), pp 285---299 (2005). We introduce some counterexamples showing that the theoretical results, the paper is based upon, are incorrect.},
journal = {Inf. Retr.},
month = apr,
pages = {151–156},
numpages = {6},
keywords = {Information retrieval, Lattice theory, Complexity reduction, Concept lattice}
}

@article{10.1007/s10791-011-9174-8,
author = {Ganesan, Kavita and Zhai, Chengxiang},
title = {Opinion-Based Entity Ranking},
year = {2012},
issue_date = {April     2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9174-8},
doi = {10.1007/s10791-011-9174-8},
abstract = {The deployment of Web 2.0 technologies has led to rapid growth of various opinions and reviews on the web, such as reviews on products and opinions about people. Such content can be very useful to help people find interesting entities like products, businesses and people based on their individual preferences or tradeoffs. Most existing work on leveraging opinionated content has focused on integrating and summarizing opinions on entities to help users better digest all the opinions. In this paper, we propose a different way of leveraging opinionated content, by directly ranking entities based on a user's preferences. Our idea is to represent each entity with the text of all the reviews of that entity. Given a user's keyword query that expresses the desired features of an entity, we can then rank all the candidate entities based on how well opinions on these entities match the user's preferences. We study several methods for solving this problem, including both standard text retrieval models and some extensions of these models. Experiment results on ranking entities based on opinions in two different domains (hotels and cars) show that the proposed extensions are effective and lead to improvement of ranking accuracy over the standard text retrieval models for this task.},
journal = {Inf. Retr.},
month = apr,
pages = {116–150},
numpages = {35},
keywords = {Vertical search, Preference based entity search, Ad-hoc faceted navigation, Entity oriented search, Product search, Opinion matching}
}

@article{10.1007/s10791-011-9173-9,
author = {Fuhr, Norbert and Lechtenfeld, Marc and Stein, Benno and Gollub, Tim},
title = {The Optimum Clustering Framework: Implementing the Cluster Hypothesis},
year = {2012},
issue_date = {April     2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9173-9},
doi = {10.1007/s10791-011-9173-9},
abstract = {Document clustering offers the potential of supporting users in interactive retrieval, especially when users have problems in specifying their information need precisely. In this paper, we present a theoretic foundation for optimum document clustering. Key idea is to base cluster analysis and evalutation on a set of queries, by defining documents as being similar if they are relevant to the same queries. Three components are essential within our optimum clustering framework, OCF: (1) a set of queries, (2) a probabilistic retrieval method, and (3) a document similarity metric. After introducing an appropriate validity measure, we define optimum clustering with respect to the estimates of the relevance probability for the query-document pairs under consideration. Moreover, we show that well-known clustering methods are implicitly based on the three components, but that they use heuristic design decisions for some of them. We argue that with our framework more targeted research for developing better document clustering methods becomes possible. Experimental results demonstrate the potential of our considerations.},
journal = {Inf. Retr.},
month = apr,
pages = {93–115},
numpages = {23},
keywords = {Document clustering, Probability ranking principle, Cluster metric, Probabilistic retrieval}
}

@article{10.1007/s10791-011-9172-x,
author = {Blanco, Roi and Lioma, Christina},
title = {Graph-Based Term Weighting for Information Retrieval},
year = {2012},
issue_date = {February  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9172-x},
doi = {10.1007/s10791-011-9172-x},
abstract = {A standard approach to Information Retrieval (IR) is to model text as a bag of words. Alternatively, text can be modelled as a graph, whose vertices represent words, and whose edges represent relations between the words, defined on the basis of any meaningful statistical or linguistic relation. Given such a  text graph , graph theoretic computations can be applied to measure various properties of the graph, and hence of the text. This work explores the usefulness of such graph-based text representations for IR. Specifically, we propose a principled graph-theoretic approach of (1) computing term weights and (2) integrating discourse aspects into retrieval. Given a text graph, whose vertices denote terms linked by co-occurrence and grammatical modification, we use graph ranking computations (e.g. PageRank Page et al. in The pagerank citation ranking: Bringing order to the Web. Technical report, Stanford Digital Library Technologies Project, 1998) to derive weights for each vertex, i.e. term weights, which we use to rank documents against queries. We reason that our graph-based term weights do not necessarily need to be normalised by document length (unlike existing term weights) because they are already scaled by their graph-ranking computation. This is a departure from existing IR ranking functions, and we experimentally show that it performs comparably to a tuned ranking baseline, such as BM25 (Robertson et al. in NIST Special Publication 500-236: TREC-4, 1995). In addition, we integrate into ranking graph properties, such as the average path length, or clustering coefficient, which represent different aspects of the topology of the graph, and by extension of the document represented as a graph. Integrating such properties into ranking allows us to consider issues such as discourse coherence, flow and density during retrieval. We experimentally show that this type of ranking performs comparably to BM25, and can even outperform it, across different TREC (Voorhees and Harman in TREC: Experiment and evaluation in information retrieval, MIT Press, 2005) datasets and evaluation measures.},
journal = {Inf. Retr.},
month = feb,
pages = {54–92},
numpages = {39},
keywords = {Graph theory, Information retrieval, Natural language processing}
}

@article{10.1007/s10791-011-9171-y,
author = {Brahmi, Abderrezak and Ech-Cherif, Ahmed and Benyettou, Abdelkader},
title = {Arabic Texts Analysis for Topic Modeling Evaluation},
year = {2012},
issue_date = {February  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9171-y},
doi = {10.1007/s10791-011-9171-y},
abstract = {Significant progress has been made in information retrieval covering text semantic indexing and multilingual analysis. However, developments in Arabic information retrieval did not follow the extraordinary growth of Arabic usage in the Web during the ten last years. In the tasks relating to semantic analysis, it is preferable to directly deal with texts in their original language. Studies on topic models, which provide a good way to automatically deal with semantic embedded in texts, are not complete enough to assess the effectiveness of the approach on Arabic texts. This paper investigates several text stemming methods for Arabic topic modeling. A new lemma-based stemmer is described and applied to newspaper articles. The Latent Dirichlet Allocation model is used to extract latent topics from three Arabic real-world corpora. For supervised classification in the topics space, experiments show an improvement when comparing to classification in the full words space or with root-based stemming approach. In addition, topic modeling with lemma-based stemming allows us to discover interesting subjects in the press articles published during the 2007---2009 period.},
journal = {Inf. Retr.},
month = feb,
pages = {33–53},
numpages = {21},
keywords = {Classification, Topic model, Test collections, Arabic stemming, Linguistic analysis}
}

@article{10.1007/s10791-011-9170-z,
author = {Escalante, Hugo Jair and Montes, Manuel and Sucar, Enrique},
title = {Multimodal Indexing Based on Semantic Cohesion for Image Retrieval},
year = {2012},
issue_date = {February  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9170-z},
doi = {10.1007/s10791-011-9170-z},
abstract = {This paper introduces two novel strategies for representing multimodal images with application to multimedia image retrieval. We consider images that are composed of both text and labels: while text describes the image content at a very high semantic level (e.g., making reference to places, dates or events), labels provide a mid-level description of the image (i.e., in terms of the objects that can be seen in the image). Accordingly, the main assumption of this work is that by combining information from text and labels we can develop very effective retrieval methods. We study standard information fusion techniques for combining both sources of information. However, whereas the performance of such techniques is highly competitive, they cannot capture effectively the content of images. Therefore, we propose two novel representations for multimodal images that attempt to exploit the semantic cohesion among terms from different modalities. Such representations are based on distributional term representations widely used in computational linguistics. Under the considered representations the content of an image is modeled by a distribution of co-occurrences over terms or of occurrences over other images, in such a way that the representation can be considered an expansion of the multimodal terms in the image. We report experimental results using the SAIAPR TC12 benchmark on two sets of topics used in ImageCLEF competitions with manually and automatically generated labels. Experimental results show that the proposed representations outperform significantly both, standard multimodal techniques and unimodal methods. Results on manually assigned labels provide an upper bound in the retrieval performance that can be obtained, whereas results with automatically generated labels are encouraging. The novel representations are able to capture more effectively the content of multimodal images. We emphasize that although we have applied our representations to multimedia image retrieval the same formulation can be adopted for modeling other multimodal documents (e.g., videos).},
journal = {Inf. Retr.},
month = feb,
pages = {1–32},
numpages = {32},
keywords = {Image annotation, Semantic cohesion modeling, Distributional term representations, Multimedia image retrieval}
}

@article{10.5555/2070786.2070818,
author = {Bigot, Anthony and Chrisment, Claude and Dkaki, Taoufiq and Hubert, Gilles and Mothe, Josiane},
title = {Fusing Different Information Retrieval Systems According to Query-Topics: A Study Based on Correlation in Information Retrieval Systems and TREC Topics},
year = {2011},
issue_date = {December  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {6},
issn = {1386-4564},
abstract = {To evaluate Information Retrieval Systems on their effectiveness, evaluation programs such as TREC offer a rigorous methodology as well as benchmark collections. Whatever the evaluation collection used, effectiveness is generally considered globally, averaging the results over a set of information needs. As a result, the variability of system performance is hidden as the similarities and differences from one system to another are averaged. Moreover, the topics on which a given system succeeds or fails are left unknown. In this paper we propose an approach based on data analysis methods (correspondence analysis and clustering) to discover correlations between systems and to find trends in topic/system correlations. We show that it is possible to cluster topics and systems according to system performance on these topics, some system clusters being better on some topics. Finally, we propose a new method to consider complementary systems as based on their performances which can be applied for example in the case of repeated queries. We consider the system profile based on the similarity of the set of TREC topics on which systems achieve similar levels of performance. We show that this method is effective when using the TREC ad hoc collection.},
journal = {Inf. Retr.},
month = dec,
pages = {617–648},
numpages = {32},
keywords = {Clustering, Meta search, System clustering, Dimensionality reduction techniques, Hierarchical clustering, System/query correlation, Local analysis of results, Query clustering, Information retrieval, Correspondence analysis}
}

@article{10.5555/2070786.2070817,
author = {Chapelle, Olivier and Ji, Shihao and Liao, Ciya and Velipasaoglu, Emre and Lai, Larry and Wu, Su-Lin},
title = {Intent-Based Diversification of Web Search Results: Metrics and Algorithms},
year = {2011},
issue_date = {December  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {6},
issn = {1386-4564},
abstract = {We study the problem of web search result diversification in the case where intent based relevance scores are available. A diversified search result will hopefully satisfy the information need of user-L.s who may have different intents. In this context, we first analyze the properties of an intent-based metric, ERR-IA, to measure relevance and diversity altogether. We argue that this is a better metric than some previously proposed intent aware metrics and show that it has a better correlation with abandonment rate. We then propose an algorithm to rerank web search results based on optimizing an objective function corresponding to this metric and evaluate it on shopping related queries.},
journal = {Inf. Retr.},
month = dec,
pages = {572–592},
numpages = {21},
keywords = {Web search, Relevance, Ranking, Diversification}
}

@article{10.1007/s10791-011-9168-6,
author = {Krikon, Eyal and Kurland, Oren},
title = {A Study of the Integration of Passage-, Document-, and Cluster-Based Information for Re-Ranking Search Results},
year = {2011},
issue_date = {December  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9168-6},
doi = {10.1007/s10791-011-9168-6},
abstract = {Cluster-based and passage-based document retrieval paradigms were shown to be effective. While the former are based on utilizing query-related corpus context manifested in clusters of similar documents, the latter address the fact that a document can be relevant even if only a very small part of it contains query-pertaining information. Hence, cluster-based approaches could be viewed as based on "expanding" the document representation, while passage-based approaches can be thought of as utilizing a "contracted" document representation. We present a study of the relative benefits of using each of these two approaches, and of the potential merits of their integration. To that end, we devise two methods that integrate whole-document-based, cluster-based and passage-based information. The methods are applied for the re-ranking task, that is, re-ordering documents in an initially retrieved list so as to improve precision at the very top ranks. Extensive empirical evaluation attests to the potential merits of integrating these information types. Specifically, the resultant performance substantially transcends that of the initial ranking; and, is often better than that of a state-of-the-art pseudo-feedback-based query expansion approach.},
journal = {Inf. Retr.},
month = dec,
pages = {593–616},
numpages = {24},
keywords = {Ad hoc retrieval, Cluster-based language models, Clusters, Passage-based language models, Passages, Re-ranking}
}

@article{10.1007/s10791-011-9166-8,
author = {Seo, Jangwon and Bruce Croft, W. and Smith, David A.},
title = {Online Community Search Using Conversational Structures},
year = {2011},
issue_date = {December  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9166-8},
doi = {10.1007/s10791-011-9166-8},
abstract = {Online communities are valuable information sources where knowledge is accumulated by interactions between people. Search services provided by online community sites such as forums are often, however, quite poor. To address this, we investigate retrieval techniques that exploit the hierarchical thread structures in community sites. Since these structures are sometimes not explicit or accurately annotated, we introduce structure discovery techniques that use a variety of features to model relations between posts. We then make use of thread structures in retrieval experiments with two online forums and one email archive. Our results show that using thread structures that have been accurately annotated can lead to significant improvements in retrieval performance compared to strong baselines.},
journal = {Inf. Retr.},
month = dec,
pages = {547–571},
numpages = {25},
keywords = {Thread structure, Forum search, Online community}
}

@article{10.1007/s10791-011-9165-9,
author = {Weerkamp, Wouter and Balog, Krisztian and Rijke, Maarten},
title = {Blog Feed Search with a Post Index},
year = {2011},
issue_date = {October   2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9165-9},
doi = {10.1007/s10791-011-9165-9},
abstract = {User generated content forms an important domain for mining knowledge. In this paper, we address the task of blog feed search: to find blogs that are principally devoted to a given topic, as opposed to blogs that merely happen to mention the topic in passing. The large number of blogs makes the blogosphere a challenging domain, both in terms of effectiveness and of storage and retrieval efficiency. We examine the effectiveness of an approach to blog feed search that is based on individual posts as indexing units (instead of full blogs). Working in the setting of a probabilistic language modeling approach to information retrieval, we model the blog feed search task by aggregating over a blogger's posts to collect evidence of relevance to the topic and persistence of interest in the topic. This approach achieves state-of-the-art performance in terms of effectiveness. We then introduce a two-stage model where a pre-selection of candidate blogs is followed by a ranking step. The model integrates aggressive pruning techniques as well as very lean representations of the contents of blog posts, resulting in substantial gains in efficiency while maintaining effectiveness at a very competitive level.},
journal = {Inf. Retr.},
month = oct,
pages = {515–545},
numpages = {31},
keywords = {Post-level indexing, Associations, Generative language models, Blog feed search, Efficiency}
}

@article{10.1007/s10791-011-9164-x,
author = {Gao, Bin and Liu, Tie-Yan and Liu, Yuting and Wang, Taifeng and Ma, Zhi-Ming and Li, Hang},
title = {Page Importance Computation Based on Markov Processes},
year = {2011},
issue_date = {October   2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9164-x},
doi = {10.1007/s10791-011-9164-x},
abstract = {This paper is concerned with Markov processes for computing page importance. Page importance is a key factor in Web search. Many algorithms such as PageRank and its variations have been proposed for computing the quantity in different scenarios, using different data sources, and with different assumptions. Then a question arises, as to whether these algorithms can be explained in a unified way, and whether there is a general guideline to design new algorithms for new scenarios. In order to answer these questions, we introduce a General Markov Framework in this paper. Under the framework, a Web Markov Skeleton Process is used to model the random walk conducted by the web surfer on a given graph. Page importance is then defined as the product of two factors: page reachability, the average possibility that the surfer arrives at the page, and page utility, the average value that the page gives to the surfer in a single visit. These two factors can be computed as the stationary probability distribution of the corresponding embedded Markov chain and the mean staying time on each page of the Web Markov Skeleton Process respectively. We show that this general framework can cover many existing algorithms including PageRank, TrustRank, and BrowseRank as its special cases. We also show that the framework can help us design new algorithms to handle more complex problems, by constructing graphs from new data sources, employing new family members of the Web Markov Skeleton Process, and using new methods to estimate these two factors. In particular, we demonstrate the use of the framework with the exploitation of a new process, named Mirror Semi-Markov Process. In the new process, the staying time on a page, as a random variable, is assumed to be dependent on both the current page and its inlink pages. Our experimental results on both the user browsing graph and the mobile web graph validate that the Mirror Semi-Markov Process is more effective than previous models in several tasks, even when there are web spams and when the assumption on preferential attachment does not hold.},
journal = {Inf. Retr.},
month = oct,
pages = {488–514},
numpages = {27},
keywords = {Mirror semi-Markov process, PageRank, BrowseRank, Page importance, Web Markov skeleton process}
}

@article{10.1007/s10791-011-9163-y,
author = {Whissell, John S. and Clarke, Charles L.},
title = {Improving Document Clustering Using Okapi BM25 Feature Weighting},
year = {2011},
issue_date = {October   2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9163-y},
doi = {10.1007/s10791-011-9163-y},
abstract = {We investigate the effect of feature weighting on document clustering, including a novel investigation of Okapi BM25 feature weighting. Using eight document datasets and 17 well-established clustering algorithms we show that the benefit of tf-idf weighting over tf weighting is heavily dependent on both the dataset being clustered and the algorithm used. In addition, binary weighting is shown to be consistently inferior to both tf-idf weighting and tf weighting. We investigate clustering using both BM25 term saturation in isolation and BM25 term saturation with idf, confirming that both are superior to their non-BM25 counterparts under several common clustering quality measures. Finally, we investigate estimation of the k1 BM25 parameter when clustering. Our results indicate that typical values of k1 from other IR tasks are not appropriate for clustering; k1 needs to be higher.},
journal = {Inf. Retr.},
month = oct,
pages = {466–487},
numpages = {22},
keywords = {Okapi BM25, Document clustering, Feature weighting}
}

@article{10.1007/s10791-011-9162-z,
author = {Cormack, Gordon V. and Smucker, Mark D. and Clarke, Charles L.},
title = {Efficient and Effective Spam Filtering and Re-Ranking for Large Web Datasets},
year = {2011},
issue_date = {October   2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-011-9162-z},
doi = {10.1007/s10791-011-9162-z},
abstract = {The TREC 2009 web ad hoc and relevance feedback tasks used a new document collection, the ClueWeb09 dataset, which was crawled from the general web in early 2009. This dataset contains 1 billion web pages, a substantial fraction of which are spam--pages designed to deceive search engines so as to deliver an unwanted payload. We examine the effect of spam on the results of the TREC 2009 web ad hoc and relevance feedback tasks, which used the ClueWeb09 dataset. We show that a simple content-based classifier with minimal training is efficient enough to rank the "spamminess" of every page in the dataset using a standard personal computer in 48 hours, and effective enough to yield significant and substantive improvements in the fixed-cutoff precision (estP10) as well as rank measures (estR-Precision, StatMAP, MAP) of nearly all submitted runs. Moreover, using a set of "honeypot" queries the labeling of training data may be reduced to an entirely automatic process. The results of classical information retrieval methods are particularly enhanced by filtering--from among the worst to among the best.},
journal = {Inf. Retr.},
month = oct,
pages = {441–465},
numpages = {25},
keywords = {Evaluation, Spam, Web search, TREC, Web spam}
}

@article{10.1007/s10791-010-9159-z,
author = {Efron, Miles},
title = {Ay\c{s}e G\"{o}Ker, John Davies (Eds): Information Retrieval: Searching in the 21st Century},
year = {2011},
issue_date = {August    2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9159-z},
doi = {10.1007/s10791-010-9159-z},
journal = {Inf. Retr.},
month = aug,
pages = {438–440},
numpages = {3}
}

@article{10.1007/s10791-010-9150-8,
author = {Meister, Lior and Kurland, Oren and Gelfer Kalmanovich, Inna},
title = {Re-Ranking Search Results Using an Additional Retrieved List},
year = {2011},
issue_date = {August    2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9150-8},
doi = {10.1007/s10791-010-9150-8},
abstract = {We present a novel approach to re-ranking a document list that was retrieved in response to a query so as to improve precision at the very top ranks. The approach is based on utilizing a second list that was retrieved in response to the query by using, for example, a different retrieval method and/or query representation. In contrast to commonly-used methods for fusion of retrieved lists that rely solely on retrieval scores (ranks) of documents, our approach also exploits inter-document-similarities between the lists--a potentially rich source of additional information. Empirical evaluation shows that our methods are effective in re-ranking TREC runs; the resultant performance also favorably compares with that of a highly effective fusion method. Furthermore, we show that our methods can potentially help to tackle a long-standing challenge, namely, integration of document-based and cluster-based retrieved results.},
journal = {Inf. Retr.},
month = aug,
pages = {413–437},
numpages = {25},
keywords = {Inter-document-similarities, Similarity-based fusion, Cluster-based retrieval, Re-ranking, Ad hoc retrieval}
}

@article{10.1007/s10791-010-9147-3,
author = {Baillie, Mark and Carman, Mark and Crestani, Fabio},
title = {A Multi-Collection Latent Topic Model for Federated Search},
year = {2011},
issue_date = {August    2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9147-3},
doi = {10.1007/s10791-010-9147-3},
abstract = {Collection selection is a crucial function, central to the effectiveness and efficiency of a federated information retrieval system. A variety of solutions have been proposed for collection selection adapting proven techniques used in centralised retrieval. This paper defines a new approach to collection selection that models the topical distribution in each collection. We describe an extended version of latent Dirichlet allocation that uses a hierarchical hyperprior to enable the different topical distributions found in each collection to be modelled. Under the model, resources are ranked based on the topical relationship between query and collection. By modelling collections in a low dimensional topic space, we can implicitly smooth their term-based characterisation with appropriate terms from topically related samples, thereby dealing with the problem of missing vocabulary within the samples. An important advantage of adopting this hierarchical model over current approaches is that the model generalises well to unseen documents given small samples of each collection. The latent structure of each collection can therefore be estimated well despite imperfect information for each collection such as sampled documents obtained through query-based sampling. Experiments demonstrate that this new, fully integrated topical model is more robust than current state of the art collection selection algorithms.},
journal = {Inf. Retr.},
month = aug,
pages = {390–412},
numpages = {23},
keywords = {Collection selection, Distributed information retrieval, Topic models, Retrieval}
}

@article{10.1007/s10791-010-9146-4,
author = {Fern\'{a}ndez, Ronald T. and Losada, David E. and Azzopardi, Leif A.},
title = {Extending the Language Modeling Framework for Sentence Retrieval to Include Local Context},
year = {2011},
issue_date = {August    2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9146-4},
doi = {10.1007/s10791-010-9146-4},
abstract = {Employing effective methods of sentence retrieval is essential for many tasks in Information Retrieval, such as summarization, novelty detection and question answering. The best performing sentence retrieval techniques attempt to perform matching directly between the sentences and the query. However, in this paper, we posit that the local context of a sentence can provide crucial additional evidence to further improve sentence retrieval. Using a Language Modeling Framework, we propose a novel reformulation of the sentence retrieval problem that extends previous approaches so that the local context is seamlessly incorporated within the retrieval models. In a series of comprehensive experiments, we show that localized smoothing and the prior importance of a sentence can improve retrieval effectiveness. The proposed models significantly and substantially outperform the state of the art and other competitive sentence retrieval baselines on recall-oriented measures, while remaining competitive on precision-oriented measures. This research demonstrates that local context plays an important role in estimating the relevance of a sentence, and that existing sentence retrieval language models can be extended to utilize this evidence effectively.},
journal = {Inf. Retr.},
month = aug,
pages = {355–389},
numpages = {35},
keywords = {Context, Language models, Sentence retrieval, Information retrieval}
}

@article{10.1007/s10791-010-9161-5,
author = {Sarvabhotla, Kiran and Pingali, Prasad and Varma, Vasudeva},
title = {Sentiment Classification: A Lexical Similarity Based Approach for Extracting Subjectivity in Documents},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9161-5},
doi = {10.1007/s10791-010-9161-5},
abstract = {With the growth of social media, document sentiment classification has become an active area of research in this decade. It can be viewed as a special case of topical classification applied only to subjective portions of a document (sources of sentiment). Hence, the key task in document sentiment classification is extracting subjectivity. Existing approaches to extract subjectivity rely heavily on linguistic resources such as sentiment lexicons and complex supervised patterns based on part-of-speech (POS) information. This makes the task of subjective feature extraction complex and resource dependent. In this work, we try to minimize the dependency on linguistic resources in sentiment classification. We propose a simple and statistical methodology called review summary (RSUMM) and use it in combination with well-known feature selection methods to extract subjectivity. Our experimental results on a movie review dataset prove the effectiveness of the proposed methodology.},
journal = {Inf. Retr.},
month = jun,
pages = {337–353},
numpages = {17},
keywords = {Sentiment classification, RSUMM, Social media, Subjectivity, Linguistic resources}
}

@article{10.1007/s10791-010-9160-6,
author = {Diligenti, Michelangelo and Gori, Marco and Maggini, Marco},
title = {A Unified Representation of Web Logs for Mining Applications},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9160-6},
doi = {10.1007/s10791-010-9160-6},
abstract = {The collective feedback of the users of an Information Retrieval (IR) system has been shown to provide semantic information that, while hard to extract using standard IR techniques, can be useful in Web mining tasks. In the last few years, several approaches have been proposed to process the logs stored by Internet Service Providers (ISP), Intranet proxies or Web search engines. However, the solutions proposed in the literature only partially represent the information available in the Web logs. In this paper, we propose to use a richer data structure, which is able to preserve most of the information available in the Web logs. This data structure consists of three groups of entities: users, documents and queries, which are connected in a network of relations. Query refinements correspond to separate transitions between the corresponding query nodes in the graph, while users are linked to the queries they have issued and to the documents they have selected. The classical query/document transitions, which connect a query to the documents selected by the users' in the returned result page, are also considered. The resulting data structure is a complete representation of the collective search activity performed by the users of a search engine or of an Intranet. The experimental results show that this more powerful representation can be successfully used in several Web mining tasks like discovering semantically relevant query suggestions and Web page categorization by topic.},
journal = {Inf. Retr.},
month = jun,
pages = {215–236},
numpages = {22},
keywords = {Query recommendations, Query suggestions, User feedback, Query similarity, Text categorization for the web, Web logs}
}

@article{10.1007/s10791-010-9158-0,
author = {Baeza-Yates, Ricardo and Pasi, Gabriella},
title = {Special Issue of The Journal of Information Retrieval on Web Mining for Search},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9158-0},
doi = {10.1007/s10791-010-9158-0},
journal = {Inf. Retr.},
month = jun,
pages = {213–214},
numpages = {2}
}

@article{10.1007/s10791-010-9155-3,
author = {Boldi, Paolo and Bonchi, Francesco and Castillo, Carlos and Vigna, Sebastiano},
title = {Query Reformulation Mining: Models, Patterns, and Applications},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9155-3},
doi = {10.1007/s10791-010-9155-3},
abstract = {Understanding query reformulation patterns is a key task towards next generation web search engines. If we can do that, then we can build systems able to understand and possibly predict user intent, providing the needed assistance at the right time, and thus helping users locate information more effectively and improving their web-search experience. As a step in this direction, we build a very accurate model for classifying user query reformulations into broad classes (generalization, specialization, error correction or parallel move), achieving 92% accuracy. We then apply the model to automatically label two very large query logs sampled from different geographic areas, and containing a total of approximately 17 million query reformulations. We study the resulting reformulation patterns, matching some results from previous studies performed on smaller manually annotated datasets, and discovering new interesting reformulation patterns, including connections between reformulation types and topical categories. We annotate two large query-flow graphs with reformulation type information, and run several graph-characterization experiments on these graphs, extracting new insights about the relationships between the different query reformulation types. Finally we study query recommendations based on short random walks on the query-flow graphs. Our experiments show that these methods can match in precision, and often improve, recommendations based on query-click graphs, without the need of users' clicks. Our experiments also show that it is important to consider transition-type labels on edges for having recommendations of good quality.},
journal = {Inf. Retr.},
month = jun,
pages = {257–289},
numpages = {33},
keywords = {Query flow graph, Session segmentation, Query log mining, Query recommendation}
}

@article{10.1007/s10791-010-9154-4,
author = {Li, Yuefeng and Algarni, Abdulmohsen and Xu, Yue},
title = {A Pattern Mining Approach for Information Filtering Systems},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9154-4},
doi = {10.1007/s10791-010-9154-4},
abstract = {It is a big challenge to clearly identify the boundary between positive and negative streams for information filtering systems. Several attempts have used negative feedback to solve this challenge; however, there are two issues for using negative relevance feedback to improve the effectiveness of information filtering. The first one is how to select constructive negative samples in order to reduce the space of negative documents. The second issue is how to decide noisy extracted features that should be updated based on the selected negative samples. This paper proposes a pattern mining based approach to select some offenders from the negative documents, where an offender can be used to reduce the side effects of noisy features. It also classifies extracted features (i.e., terms) into three categories: positive specific terms, general terms, and negative specific terms. In this way, multiple revising strategies can be used to update extracted features. An iterative learning algorithm is also proposed to implement this approach on the RCV1 data collection, and substantial experiments show that the proposed approach achieves encouraging performance and the performance is also consistent for adaptive filtering as well.},
journal = {Inf. Retr.},
month = jun,
pages = {237–256},
numpages = {20},
keywords = {Relevance feedback, Information filtering, Pattern mining}
}

@article{10.1007/s10791-010-9152-6,
author = {Hillard, Dustin and Manavoglu, Eren and Raghavan, Hema and Leggetter, Chris and Cant\'{u}-Paz, Erick and Iyer, Rukmini},
title = {The Sum of Its Parts: Reducing Sparsity in Click Estimation with Query Segments},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9152-6},
doi = {10.1007/s10791-010-9152-6},
abstract = {The critical task of predicting clicks on search advertisements is typically addressed by learning from historical click data. When enough history is observed for a given query-ad pair, future clicks can be accurately modeled. However, based on the empirical distribution of queries, sufficient historical information is unavailable for many query-ad pairs. The sparsity of data for new and rare queries makes it difficult to accurately estimate clicks for a significant portion of typical search engine traffic. In this paper we provide analysis to motivate modeling approaches that can reduce the sparsity of the large space of user search queries. We then propose methods to improve click and relevance models for sponsored search by mining click behavior for partial user queries. We aggregate click history for individual query words, as well as for phrases extracted with a CRF model. The new models show significant improvement in clicks and revenue compared to state-of-the-art baselines trained on several months of query logs. Results are reported on live traffic of a commercial search engine, in addition to results from offline evaluation.},
journal = {Inf. Retr.},
month = jun,
pages = {315–336},
numpages = {22},
keywords = {Clicks, Query log mining, Advertising, Relevance}
}

@article{10.1007/s10791-010-9151-7,
author = {Zhou, Bo and Liu, Yiqun and Zhang, Min and Jin, Yijiang and Ma, Shaoping},
title = {Incorporating Web Browsing Activities into Anchor Texts for Web Search},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9151-7},
doi = {10.1007/s10791-010-9151-7},
abstract = {Anchor texts complement Web page content and have been used extensively in commercial Web search engines. Existing methods for anchor text weighting rely on the hyperlink information which is created by page content editors. Since anchor texts are created to help user browse the Web, browsing behavior of Web users may also provide useful or complementary information for anchor text weighting. In this paper, we discuss the possibility and effectiveness of incorporating browsing activities of Web users into anchor texts for Web search. We first make an analysis on the effectiveness of anchor texts with browsing activities. And then we propose two new anchor models which incorporate browsing activities. To deal with the data sparseness problem of user-clicked anchor texts, two features of user's browsing behavior are explored and analyzed. Based on these features, a smoothing method for the new anchor models is proposed. Experimental results show that by incorporating browsing activities the new anchor models outperform the state-of-art anchor models which use only the hyperlink information. This study demonstrates the benefits of Web browsing activities to affect anchor text weighting.},
journal = {Inf. Retr.},
month = jun,
pages = {290–314},
numpages = {25},
keywords = {Web browsing behavior, Web search, Document representation, Anchor text}
}

@article{10.1007/s10791-010-9153-5,
author = {Xiaojun, Zhang},
title = {Michael W. Berry and Jacob Kogan (Eds.): Text Mining: Applications and Theory},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9153-5},
doi = {10.1007/s10791-010-9153-5},
journal = {Inf. Retr.},
month = apr,
pages = {208–211},
numpages = {4}
}

@article{10.1007/s10791-010-9149-1,
author = {Joho, Hideo},
title = {Diane Kelly: Methods for Evaluating Interactive Information Retrieval Systems with Users},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9149-1},
doi = {10.1007/s10791-010-9149-1},
journal = {Inf. Retr.},
month = apr,
pages = {204–207},
numpages = {4}
}

@article{10.1007/s10791-010-9141-9,
author = {Lu, Yue and Mei, Qiaozhu and Zhai, Chengxiang},
title = {Investigating Task Performance of Probabilistic Topic Models: An Empirical Study of PLSA and LDA},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9141-9},
doi = {10.1007/s10791-010-9141-9},
abstract = {Probabilistic topic models have recently attracted much attention because of their successful applications in many text mining tasks such as retrieval, summarization, categorization, and clustering. Although many existing studies have reported promising performance of these topic models, none of the work has systematically investigated the task performance of topic models; as a result, some critical questions that may affect the performance of all applications of topic models are mostly unanswered, particularly how to choose between competing models, how multiple local maxima affect task performance, and how to set parameters in topic models. In this paper, we address these questions by conducting a systematic investigation of two representative probabilistic topic models, probabilistic latent semantic analysis (PLSA) and Latent Dirichlet Allocation (LDA), using three representative text mining tasks, including document clustering, text categorization, and ad-hoc retrieval. The analysis of our experimental results provides deeper understanding of topic models and many useful insights about how to optimize the performance of topic models for these typical tasks. The task-based evaluation framework is generalizable to other topic models in the family of either PLSA or LDA.},
journal = {Inf. Retr.},
month = apr,
pages = {178–203},
numpages = {26},
keywords = {LDA, Performance, PLSA, Experimentation, Evaluation, Topic models}
}

@article{10.1007/s10791-010-9139-3,
author = {Fang, Yi and Si, Luo and Mathur, Aditya P.},
title = {Discriminative Probabilistic Models for Expert Search in Heterogeneous Information Sources},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9139-3},
doi = {10.1007/s10791-010-9139-3},
abstract = {In many realistic settings of expert finding, the evidence for expertise often comes from heterogeneous knowledge sources. As some sources tend to be more reliable and indicative than the others, different information sources need to receive different weights to reflect their degrees of importance. However, most previous studies in expert finding did not differentiate data sources, which may lead to unsatisfactory performance in the settings where the heterogeneity of data sources is present. In this paper, we investigate how to merge and weight heterogeneous knowledge sources in the context of expert finding. A relevance-based supervised learning framework is presented to learn the combination weights from training data. Beyond just learning a fixed combination strategy for all the queries and experts, we propose a series of discriminative probabilistic models which have increasing capability to associate the combination weights with specific experts and queries. In the last (and also the most sophisticated) proposed model, the combination weights depend on both expert classes and query topics, and these classes/topics are derived from expert and query features. Compared with expert and query independent combination methods, the proposed combination strategy can better adjust to different types of experts and queries. In consequence, the model yields much flexibility of combining data sources when dealing with a broad range of expertise areas and a large variation in experts. To the best of our knowledge, this is the first work that designs discriminative learning models to rank experts. Empirical studies on two real world faculty expertise testbeds demonstrate the effectiveness and robustness of the proposed discriminative learning models.},
journal = {Inf. Retr.},
month = apr,
pages = {158–177},
numpages = {20},
keywords = {Expert finding, Learning to rank, Expert search}
}

@article{10.1007/s10791-010-9138-4,
author = {Manaskasemsak, Bundit and Rungsawang, Arnon and Yamana, Hayato},
title = {Time-Weighted Web Authoritative Ranking},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9138-4},
doi = {10.1007/s10791-010-9138-4},
abstract = {We investigate temporal factors in assessing the authoritativeness of web pages. We present three different metrics related to time: age, event, and trend. These metrics measure recentness, special event occurrence, and trend in revisions, respectively. An experimental dataset is created by crawling selected web pages for a period of several months. This data is used to compare page rankings by human users with rankings computed by the standard PageRank algorithm (which does not include temporal factors) and three algorithms that incorporate temporal factors, including the Time-Weighted PageRank (TWPR) algorithm introduced here. Analysis of the rankings shows that all three temporal-aware algorithms produce rankings more like those of human users than does the PageRank algorithm. Of these, the TWPR algorithm produces rankings most similar to human users', indicating that all three temporal factors are relevant in page ranking. In addition, analysis of parameter values used to weight the three temporal factors reveals that age factor has the most impact on page rankings, while trend and event factors have the second and the least impact. Proper weighting of the three factors in TWPR algorithm provides the best ranking results.},
journal = {Inf. Retr.},
month = apr,
pages = {133–157},
numpages = {25},
keywords = {PageRank, Web authoritativeness, Link analysis, Web ranking algorithm, Time-weighted ranking, Search engine}
}

@article{10.1007/s10791-010-9136-6,
author = {Verberne, Suzan and Halteren, Hans and Theijssen, Daphne and Raaijmakers, Stephan and Boves, Lou},
title = {Learning to Rank for Why-Question Answering},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9136-6},
doi = {10.1007/s10791-010-9136-6},
abstract = {In this paper, we evaluate a number of machine learning techniques for the task of ranking answers to why-questions. We use TF-IDF together with a set of 36 linguistically motivated features that characterize questions and answers. We experiment with a number of machine learning techniques (among which several classifiers and regression techniques, Ranking SVM and SVM
                        
                           map
                        ) in various settings. The purpose of the experiments is to assess how the different machine learning approaches can cope with our highly imbalanced binary relevance data, with and without hyperparameter tuning. We find that with all machine learning techniques, we can obtain an MRR score that is significantly above the TF-IDF baseline of 0.25 and not significantly lower than the best score of 0.35. We provide an in-depth analysis of the effect of data imbalance and hyperparameter tuning, and we relate our findings to previous research on learning to rank for Information Retrieval.},
journal = {Inf. Retr.},
month = apr,
pages = {107–132},
numpages = {26},
keywords = {Why-questions, Question answering, Learning to rank}
}

@article{10.1007/s10791-010-9157-1,
author = {Carterette, Ben},
title = {An Analysis of NP-Completeness in Novelty and Diversity Ranking},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9157-1},
doi = {10.1007/s10791-010-9157-1},
abstract = {A useful ability for search engines is to be able to rank objects with novelty and diversity: the top k documents retrieved should cover possible intents of a query with some distribution, or should contain a diverse set of subtopics related to the user's information need, or contain nuggets of information with little redundancy. Evaluation measures have been introduced to measure the effectiveness of systems at this task, but these measures have worst-case NP-hard computation time. The primary consequence of this is that there is no ranking principle akin to the Probability Ranking Principle for document relevance that provides uniform instruction on how to rank documents for novelty and diversity. We use simulation to investigate the practical implications of this for optimization and evaluation of retrieval systems.},
journal = {Inf. Retr.},
month = feb,
pages = {89–106},
numpages = {18},
keywords = {Evaluation, Diversity, Simulation, Novelty, Theory, Test collections}
}

@article{10.1007/s10791-010-9156-2,
author = {Dai, Keshi and Kanoulas, Evangelos and Pavlu, Virgil and Aslam, Javed A.},
title = {Variational Bayes for Modeling Score Distributions},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9156-2},
doi = {10.1007/s10791-010-9156-2},
abstract = {Empirical modeling of the score distributions associated with retrieved documents is an essential task for many retrieval applications. In this work, we propose modeling the relevant documents' scores by a mixture of Gaussians and the non-relevant scores by a Gamma distribution. Applying Variational Bayes we automatically trade-off the goodness-of-fit with the complexity of the model. We test our model on traditional retrieval functions and actual search engines submitted to TREC. We demonstrate the utility of our model in inferring precision-recall curves. In all experiments our model outperforms the dominant exponential-Gaussian model.},
journal = {Inf. Retr.},
month = feb,
pages = {47–67},
numpages = {21},
keywords = {Recall-precision curves, Score distributions, Gaussian mixtures, Variational inference}
}

@article{10.1007/s10791-010-9145-5,
author = {Arampatzis, Avi and Robertson, Stephen},
title = {Modeling Score Distributions in Information Retrieval},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9145-5},
doi = {10.1007/s10791-010-9145-5},
abstract = {We review the history of modeling score distributions, focusing on the mixture of normal-exponential by investigating the theoretical as well as the empirical evidence supporting its use. We discuss previously suggested conditions which valid binary mixture models should satisfy, such as the Recall-Fallout Convexity Hypothesis, and formulate two new hypotheses considering the component distributions, individually as well as in pairs, under some limiting conditions of parameter values. From all the mixtures suggested in the past, the current theoretical argument points to the two gamma as the most-likely universal model, with the normal-exponential being a usable approximation. Beyond the theoretical contribution, we provide new experimental evidence showing vector space or geometric models, and BM25, as being `friendly' to the normal-exponential, and that the non-convexity problem that the mixture possesses is practically not severe. Furthermore, we review recent non-binary mixture models, speculate on graded relevance, and consider methods such as logistic regression for score calibration.},
journal = {Inf. Retr.},
month = feb,
pages = {26–46},
numpages = {21},
keywords = {Distributed retrieval, Score distribution, Fusion, Normalization, Filtering}
}

@article{10.1007/s10791-010-9144-6,
author = {Blanke, Tobias and Lalmas, Mounia},
title = {Specificity Aboutness in XML Retrieval},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9144-6},
doi = {10.1007/s10791-010-9144-6},
abstract = {This paper presents a theoretical methodology to evaluate XML retrieval systems and their filters. Theoretical evaluation is concerned with the formal investigation of qualitative properties of retrieval models. XML retrieval deals with retrieving those document components that specifically answer a query, and filters are a method of delivering the most focussed answers. Our theoretical evaluation critically analyzes how filters achieve this.},
journal = {Inf. Retr.},
month = feb,
pages = {68–88},
numpages = {21},
keywords = {XML retrieval, Information retrieval theory, Theoretical evaluation}
}

@article{10.1007/s10791-010-9143-7,
author = {Clinchant, St\'{e}phane and Gaussier, Eric},
title = {Retrieval Constraints and Word Frequency Distributions a Log-Logistic Model for IR},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9143-7},
doi = {10.1007/s10791-010-9143-7},
abstract = {We first present in this paper an analytical view of heuristic retrieval constraints which yields simple tests to determine whether a retrieval function satisfies the constraints or not. We then review empirical findings on word frequency distributions and the central role played by burstiness in this context. This leads us to propose a formal definition of burstiness which can be used to characterize probability distributions with respect to this phenomenon. We then introduce the family of information-based IR models which naturally captures heuristic retrieval constraints when the underlying probability distribution is bursty and propose a new IR model within this family, based on the log-logistic distribution. The experiments we conduct on several collections illustrate the good behavior of the log-logistic IR model: It significantly outperforms the Jelinek-Mercer and Dirichlet prior language models on most collections we have used, with both short and long queries and for both the MAP and the precision at 10 documents. It also compares favorably to BM25 and has similar performance to classical DFR models such as InL2 and PL2.},
journal = {Inf. Retr.},
month = feb,
pages = {5–25},
numpages = {21},
keywords = {Log-logistic distribution, Information retrieval theory, Burstiness, Retrieval constraints}
}

@article{10.1007/s10791-010-9142-8,
author = {Azzopardi, Leif and Song, Dawei and Kazai, Gabriella and Robertson, Stephen and R\"{u}ger, Stefan and Shokouhi, Milad and Yilmaz, Emine},
title = {Introduction to Special Issue on the Second International Conference on the Theory of Information Retrieval},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9142-8},
doi = {10.1007/s10791-010-9142-8},
journal = {Inf. Retr.},
month = feb,
pages = {1–4},
numpages = {4}
}

@article{10.1007/s10791-010-9148-2,
author = {Bierig, Ralf},
title = {Iris Xie: Interactive Information Retrieval in Digital Environments},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9148-2},
doi = {10.1007/s10791-010-9148-2},
journal = {Inf. Retr.},
month = dec,
pages = {693–694},
numpages = {2}
}

@article{10.1007/s10791-010-9140-x,
author = {Diaz, Fernando},
title = {A Generative Theory of Relevance},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9140-x},
doi = {10.1007/s10791-010-9140-x},
journal = {Inf. Retr.},
month = dec,
pages = {689–692},
numpages = {4}
}

@article{10.1007/s10791-010-9134-8,
author = {He, Yin and Liu, Tie-Yan},
title = {Tendency Correlation Analysis for Direct Optimization of Evaluation Measures in Information Retrieval},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9134-8},
doi = {10.1007/s10791-010-9134-8},
abstract = {Direct optimization of evaluation measures has become an important branch of learning to rank for information retrieval (IR). Since IR evaluation measures are difficult to optimize due to their non-continuity and non-differentiability, most direct optimization methods optimize some surrogate functions instead, which we call surrogate measures. A critical issue regarding these methods is whether the optimization of the surrogate measures can really lead to the optimization of the original IR evaluation measures. In this work, we perform formal analysis on this issue. We propose a concept named "tendency correlation" to describe the relationship between a surrogate measure and its corresponding IR evaluation measure. We show that when a surrogate measure has arbitrarily strong tendency correlation with an IR evaluation measure, the optimization of it will lead to the effective optimization of the original IR evaluation measure. Then, we analyze the tendency correlations of the surrogate measures optimized in a number of direct optimization methods. We prove that the surrogate measures in SoftRank and ApproxRank can have arbitrarily strong tendency correlation with the original IR evaluation measures, regardless of the data distribution, when some parameters are appropriately set. However, the surrogate measures in SVM              MAP             , DORM              NDCG             , PermuRank              MAP             , and SVM              NDCG              cannot have arbitrarily strong tendency correlation with the original IR evaluation measures on certain distributions of data. Therefore SoftRank and ApproxRank are theoretically sounder than SVM              MAP             , DORM              NDCG             , PermuRank              MAP             , and SVM              NDCG             , and are expected to result in better ranking performances. Our theoretical findings can explain the experimental results observed on public benchmark datasets.},
journal = {Inf. Retr.},
month = dec,
pages = {657–688},
numpages = {32},
keywords = {Direct optimization, Information retrieval measures, Learning to rank, Tendency correlation}
}

@article{10.1007/s10791-010-9132-x,
author = {Penev, Alex and Wong, Raymond K.},
title = {Structure vs. Content in Hierarchical Corpora},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9132-x},
doi = {10.1007/s10791-010-9132-x},
abstract = {We propose and describe  Parameterized filesystem HITS  (PFH), a lightweight rearrangement algorithm that performs a re-ranking of existing content-only search results in tree-like hierarchical corpora, such as a filesystem. PFH does this by combining the content analysis of the results with structural analysis of how they are organized. An parameter is used to vary the structure-content bias, allowing us to observe changes in performance when we place more emphasis on structure or on content. Using real and simulated data, experiments are provided to show that = 0.8 (i.e, 20% structure and 80% content) can substantially boost Mean Reciprocal Rank while keeping other IR metrics steady. Such an algorithm may be useful for building retrieval systems over hierarchical content such as Desktop Search, technical documents and books.},
journal = {Inf. Retr.},
month = dec,
pages = {636–656},
numpages = {21},
keywords = {Desktop search, HITS, Information retrieval, Ranking}
}

@article{10.1007/s10791-010-9127-7,
author = {Fang, Yi and Si, Luo and Mathur, Aditya P.},
title = {Discriminative Graphical Models for Faculty Homepage Discovery},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9127-7},
doi = {10.1007/s10791-010-9127-7},
abstract = {Faculty homepage discovery is an important step toward building an academic portal. Although the general homepage finding tasks have been well studied (e.g., TREC-2001 Web Track), faculty homepage discovery has its own special characteristics and not much focused research has been conducted for this task. In this paper, we view faculty homepage discovery as text categorization problems by utilizing Yahoo BOSS API to generate a small list of high-quality candidate homepages. Because the labels of these pages are not independent, standard text categorization methods such as logistic regression, which classify each page separately, are not well suited for this task. By defining homepage dependence graph, we propose a conditional undirected graphical model to make joint predictions by capturing the dependence of the decisions on all the candidate pages. Three cases of dependencies among faculty candidate homepages are considered for constructing the graphical model. Our model utilizes a discriminative approach so that any informative features can be used conveniently. Learning and inference can be done relatively efficiently for the joint prediction model because the homepage dependence graphs resulting from the three cases of dependencies are not densely connected. An extensive set of experiments have been conducted on two testbeds to show the effectiveness of the proposed discriminative graphical model.},
journal = {Inf. Retr.},
month = dec,
pages = {618–635},
numpages = {18},
keywords = {Information retrieval, Homepage finding, Discriminative graphical models}
}

@article{10.1007/s10791-010-9126-8,
author = {Smith, Larry H. and Wilbur, W. John},
title = {Finding Related Sentence Pairs in MEDLINE},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9126-8},
doi = {10.1007/s10791-010-9126-8},
abstract = {We explore the feasibility of automatically identifying sentences in different MEDLINE abstracts that are related in meaning. We compared traditional vector space models with machine learning methods for detecting relatedness, and found that machine learning was superior. The Huber method, a variant of Support Vector Machines which minimizes the modified Huber loss function, achieves 73% precision when the score cutoff is set high enough to identify about one related sentence per abstract on average. We illustrate how an abstract viewed in PubMed might be modified to present the related sentences found in other abstracts by this automatic procedure.},
journal = {Inf. Retr.},
month = dec,
pages = {601–617},
numpages = {17},
keywords = {Related sentences, Machine learning}
}

@article{10.1007/s10791-010-9137-5,
author = {Trotman, Andrew and Geva, Shlomo and Kamps, Jaap and Lalmas, Mounia and Murdock, Vanessa},
title = {Current Research in Focused Retrieval and Result Aggregation},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9137-5},
doi = {10.1007/s10791-010-9137-5},
abstract = {Both focused retrieval and result aggregation provide the user with answers to their information needs, rather than just pointers to whole documents. Focused retrieval identifies not only relevant documents but also which parts of those documents are relevant, thus reducing the time it takes the user to navigate in a document. Result aggregation is used when the best way to fulfil the user's need is to draw from many different information sources (different collections, documents, or parts of the same document), and to aggregate these into a single result, thus reducing the time it takes the user to fulfil their information need. This special issue includes seven papers showing the breadth and depth of the current state of research in these two branches of information retrieval. They include descriptions of live result aggregation systems, and experimental focussed retrieval systems including sentence retrieval, question answering, and entity ranking; as well as metrics for passage retrieval. To introduce this special issue, we provide an overview of the work presented in these papers.},
journal = {Inf. Retr.},
month = oct,
pages = {407–411},
numpages = {5},
keywords = {Users, Metrics, Focused retrieval, Result aggregation}
}

@article{10.1007/s10791-010-9135-7,
author = {Demartini, Gianluca and Firan, Claudiu S. and Iofciu, Tereza and Krestel, Ralf and Nejdl, Wolfgang},
title = {Why Finding Entities in Wikipedia is Difficult, Sometimes},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9135-7},
doi = {10.1007/s10791-010-9135-7},
abstract = {Entity Retrieval (ER)--in comparison to classical search--aims at finding individual entities instead of relevant documents. Finding a list of entities requires therefore techniques different to classical search engines. In this paper, we present a model to describe entities more formally and how an ER system can be build on top of it. We compare different approaches designed for finding entities in Wikipedia and report on results using standard test collections. An analysis of entity-centric queries reveals different aspects and problems related to ER and shows limitations of current systems performing ER with Wikipedia. It also indicates which approaches are suitable for which kinds of queries.},
journal = {Inf. Retr.},
month = oct,
pages = {534–567},
numpages = {34},
keywords = {Model, Algorithms, Entity search, Evaluation, Experimentation}
}

@article{10.1007/s10791-010-9133-9,
author = {Arvola, Paavo and Kek\"{a}l\"{a}inen, Jaana and Junkkari, Marko},
title = {Expected Reading Effort in Focused Retrieval Evaluation},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9133-9},
doi = {10.1007/s10791-010-9133-9},
abstract = {This study introduces a novel framework for evaluating passage and XML retrieval. The framework focuses on a user's effort to localize relevant content in a result document. Measuring the effort is based on a system guided reading order of documents. The effort is calculated as the quantity of text the user is expected to browse through. More specifically, this study seeks evaluation metrics for retrieval methods following a specific fetch and browse approach, where in the fetch phase documents are ranked in decreasing order according to their document score, like in document retrieval. In the browse phase, for each retrieved document, a set of non-overlapping passages representing the relevant text within the document is retrieved. In other words, the passages of the document are re-organized, so that the best matching passages are read first in sequential order. We introduce an application scenario motivating the framework, and propose sample metrics based on the framework. These metrics give a basis for the comparison of effectiveness between traditional document retrieval and passage/XML retrieval and illuminate the benefit of passage/XML retrieval.},
journal = {Inf. Retr.},
month = oct,
pages = {460–484},
numpages = {25},
keywords = {Metrics, Evaluation, Small screen devices, Passage retrieval, XML retrieval}
}

@article{10.1007/s10791-010-9131-y,
author = {Moriceau, V\'{e}ronique and Tannier, Xavier},
title = {FIDJI: Using Syntax for Validating Answers in Multiple Documents},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9131-y},
doi = {10.1007/s10791-010-9131-y},
abstract = {This article presents FIDJI, a question-answering (QA) system for French. FIDJI combines syntactic information with traditional QA techniques such as named entity recognition and term weighting; it does not require any pre-processing other than classical search engine indexing. Among other uses of syntax, we experiment in this system the validation of answers through different documents, as well as specific techniques for answering different types of questions (e.g., yes/no or list questions). We present several experiments which show the benefits of syntactic analysis, as well as multi-document validation. Different types of questions and corpora are tested, and specificities are commented. Links with result aggregation are also discussed.},
journal = {Inf. Retr.},
month = oct,
pages = {507–533},
numpages = {27},
keywords = {Syntactic analysis, Result aggregation, Question answering, Multi-document validation, Focused retrieval}
}

@article{10.1007/s10791-010-9130-z,
author = {Kaptein, Rianne and Marx, Maarten},
title = {Focused Retrieval and Result Aggregation with Political Data},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9130-z},
doi = {10.1007/s10791-010-9130-z},
abstract = {This paper presents a case-study in which we use a large semi-structured data set consisting of official transcripts of meetings of the Dutch parliament for focused retrieval and result aggregation. Transcripts of meetings are a document genre characterized by a complex narrative structure. The essence is not only what is said, but also by who and to whom. We have notes of more than 40 years of Dutch parliamentary debates where this structure is exploited to automatically make semantic annotations. These annotations yield numerous new ways of searching, browsing, mining and summarizing these documents. Concerning result aggregation, we summarise and visualise the structure of meetings into tables of content and interruption graphs. The contents of meetings or parts of meetings are condensed into word clouds that are created using a parsimonious language model. Furthermore, we have developed a search engine that exploits the structure and annotations of our data making it possible to provide entry points, to group search results, and to use faceted search techniques for data-exploration. Evaluation shows that our content and structure summarization tools provide a good first impression of a debate. Users reported that, compared to a standard document retrieval system, our search engine gives a better overview of the data. Search tasks are performed faster and the users felt more certain of their answers.},
journal = {Inf. Retr.},
month = oct,
pages = {412–433},
numpages = {22},
keywords = {Result aggregation, Political data, Focused retrieval, Word clouds}
}

@article{10.1007/s10791-009-9125-9,
author = {Pehcevski, Jovan and Thom, James A. and Vercoustre, Anne-Marie and Naumovski, Vladimir},
title = {Entity Ranking in Wikipedia: Utilising Categories, Links and Topic Difficulty Prediction},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9125-9},
doi = {10.1007/s10791-009-9125-9},
abstract = {Entity ranking has recently emerged as a research field that aims at retrieving entities as answers to a query. Unlike entity extraction where the goal is to tag names of entities in documents, entity ranking is primarily focused on returning a ranked list of relevant entity names for the query. Many approaches to entity ranking have been proposed, and most of them were evaluated on the INEX Wikipedia test collection. In this paper, we describe a system we developed for ranking Wikipedia entities in answer to a query. The entity ranking approach implemented in our system utilises the known categories, the link structure of Wikipedia, as well as the link co-occurrences with the entity examples (when provided) to retrieve relevant entities as answers to the query. We also extend our entity ranking approach by utilising the knowledge of predicted classes of topic difficulty. To predict the topic difficulty, we generate a classifier that uses features extracted from an INEX topic definition to classify the topic into an experimentally pre-determined class. This knowledge is then utilised to dynamically set the optimal values for the retrieval parameters of our entity ranking system. Our experiments demonstrate that the use of categories and the link structure of Wikipedia can significantly improve entity ranking effectiveness, and that topic difficulty prediction is a promising approach that could also be exploited to further improve the entity ranking performance.},
journal = {Inf. Retr.},
month = oct,
pages = {568–600},
numpages = {33},
keywords = {Wikipedia, XML Retrieval, Entity ranking, INEX}
}

@article{10.1007/s10791-009-9122-z,
author = {Losada, David E.},
title = {Statistical Query Expansion for Sentence Retrieval and Its Effects on Weak and Strong Queries},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9122-z},
doi = {10.1007/s10791-009-9122-z},
abstract = {The retrieval of sentences that are relevant to a given information need is a challenging passage retrieval task. In this context, the well-known vocabulary mismatch problem arises severely because of the fine granularity of the task. Short queries, which are usually the rule rather than the exception, aggravate the problem. Consequently, effective sentence retrieval methods tend to apply some form of query expansion, usually based on pseudo-relevance feedback. Nevertheless, there are no extensive studies comparing different statistical expansion strategies for sentence retrieval. In this work we study thoroughly the effect of distinct statistical expansion methods on sentence retrieval. We start from a set of retrieved documents in which relevant sentences have to be found. In our experiments different term selection strategies are evaluated and we provide empirical evidence to show that expansion before sentence retrieval yields competitive performance. This is particularly novel because expansion for sentence retrieval is often done after sentence retrieval (i.e. expansion terms are mined from a ranked set of sentences) and there are no comparative results available between both types of expansion. Furthermore, this comparison is particularly valuable because there are important implications in time efficiency. We also carefully analyze expansion on weak and strong queries and demonstrate clearly that expanding queries before sentence retrieval is not only more convenient for efficiency purposes, but also more effective when handling poor queries.},
journal = {Inf. Retr.},
month = oct,
pages = {485–506},
numpages = {22},
keywords = {Sentence retrieval, Information retrieval, Query expansion}
}

@article{10.1007/s10791-009-9121-0,
author = {Paris, C\'{e}cile and Wan, Stephen and Thomas, Paul},
title = {Focused and Aggregated Search: A Perspective from Natural Language Generation},
year = {2010},
issue_date = {October   2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9121-0},
doi = {10.1007/s10791-009-9121-0},
abstract = {Users are often faced with complex information needs that are not easily represented as a single query. With current technology, the burden of issuing these individual queries, analysing retrieved documents for relevance, as well as aggregating results falls upon the time-poor and informationally overloaded user. Aggregated search techniques represent the new generation of search applications that endeavour to help users perform these complex tasks. However, the way in which different data types are combined in current aggregated search applications is often performed using static hard-coded structures. We suggest that a useful alternative is to marry techniques from natural language generation, such as text planning and summarisation, in order to dynamically determine the best organisation of retrieved information. These organisations can be motivated by linguistic theories that consider issues such as the role that the information plays to facilitate a task, and the relationships between different pieces of information. With reference to a discourse strategy, it is possible to draw on several data sources automatically to generate a useful, focused, and coherent answer. We focus on exploring the parallels between aggregated search and natural language generation in the hope that the fields can be mutually informed, leading to further advances in the way search technologies can better serve the user. These issues are discussed and presented with examples of existing systems across different domains.},
journal = {Inf. Retr.},
month = oct,
pages = {434–459},
numpages = {26},
keywords = {Orchestration, Discourse strategy, Linguistics}
}

@article{10.1007/s10791-010-9129-5,
author = {Vallet, David},
title = {John Davies, Marko Grobelnik and Dunja Mladenic: Semantic Knowledge Management},
year = {2010},
issue_date = {August    2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9129-5},
doi = {10.1007/s10791-010-9129-5},
journal = {Inf. Retr.},
month = aug,
pages = {403–406},
numpages = {4}
}

@article{10.1007/s10791-010-9128-6,
author = {Foley, Colum},
title = {David Gibbon, Zhu Liu: Introduction to Video Search Engines},
year = {2010},
issue_date = {August    2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-010-9128-6},
doi = {10.1007/s10791-010-9128-6},
journal = {Inf. Retr.},
month = aug,
pages = {398–402},
numpages = {5}
}

@article{10.1007/s10791-009-9124-x,
author = {Qin, Tao and Liu, Tie-Yan and Li, Hang},
title = {A General Approximation Framework for Direct Optimization of Information Retrieval Measures},
year = {2010},
issue_date = {August    2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9124-x},
doi = {10.1007/s10791-009-9124-x},
abstract = {Recently direct optimization of information retrieval (IR) measures has become a new trend in learning to rank. In this paper, we propose a general framework for direct optimization of IR measures, which enjoys several theoretical advantages. The general framework, which can be used to optimize most IR measures, addresses the task by approximating the IR measures and optimizing the approximated surrogate functions. Theoretical analysis shows that a high approximation accuracy can be achieved by the framework. We take average precision (AP) and normalized discounted cumulated gains (NDCG) as examples to demonstrate how to realize the proposed framework. Experiments on benchmark datasets show that the algorithms deduced from our framework are very effective when compared to existing methods. The empirical results also agree well with the theoretical results obtained in the paper.},
journal = {Inf. Retr.},
month = aug,
pages = {375–397},
numpages = {23},
keywords = {Position function approximation, Accuracy analysis, Truncation function approximation, Direct optimization of IR measures, Learning to rank}
}

@article{10.1007/s10791-009-9123-y,
author = {Qin, Tao and Liu, Tie-Yan and Xu, Jun and Li, Hang},
title = {LETOR: A Benchmark Collection for Research on Learning to Rank for Information Retrieval},
year = {2010},
issue_date = {August    2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9123-y},
doi = {10.1007/s10791-009-9123-y},
abstract = {LETOR is a benchmark collection for the research on learning to rank for information retrieval, released by Microsoft Research Asia. In this paper, we describe the details of the LETOR collection and show how it can be used in different kinds of researches. Specifically, we describe how the document corpora and query sets in LETOR are selected, how the documents are sampled, how the learning features and meta information are extracted, and how the datasets are partitioned for comprehensive evaluation. We then compare several state-of-the-art learning to rank algorithms on LETOR, report their ranking performances, and make discussions on the results. After that, we discuss possible new research topics that can be supported by LETOR, in addition to algorithm comparison. We hope that this paper can help people to gain deeper understanding of LETOR, and enable more interesting research projects on learning to rank and related topics.},
journal = {Inf. Retr.},
month = aug,
pages = {346–374},
numpages = {29},
keywords = {Feature extraction, Benchmark datasets, Information retrieval, Learning to rank}
}

@article{10.1007/s10791-009-9119-7,
author = {Couto, T. and Ziviani, N. and Calado, P. and Cristo, M. and Gon\c{c}alves, M. and Moura, E. S. and Brand\~{a}o, W.},
title = {Classifying Documents with Link-Based Bibliometric Measures},
year = {2010},
issue_date = {August    2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9119-7},
doi = {10.1007/s10791-009-9119-7},
abstract = {Automatic document classification can be used to organize documents in a digital library, construct on-line directories, improve the precision of web searching, or help the interactions between user and search engines. In this paper we explore how linkage information inherent to different document collections can be used to enhance the effectiveness of classification algorithms. We have experimented with three link-based bibliometric measures, co-citation, bibliographic coupling and Amsler, on three different document collections: a digital library of computer science papers, a web directory and an on-line encyclopedia. Results show that both hyperlink and citation information can be used to learn reliable and effective classifiers based on a kNN classifier. In one of the test collections used, we obtained improvements of up to 69.8% of macro-averaged F
                        1 over the traditional text-based kNN classifier, considered as the baseline measure in our experiments. We also present alternative ways of combining bibliometric based classifiers with text based classifiers. Finally, we conducted studies to analyze the situation in which the bibliometric-based classifiers failed and show that in such cases it is hard to reach consensus regarding the correct classes, even for human judges.},
journal = {Inf. Retr.},
month = aug,
pages = {315–345},
numpages = {31},
keywords = {Web directories, Digital libraries, Text classification, Links}
}

@article{10.1007/s10791-009-9120-1,
author = {Liu, Tie-Yan and Joachims, Thorsten and Li, Hang and Zhai, Chengxiang},
title = {Introduction to Special Issue on Learning to Rank for Information Retrieval},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9120-1},
doi = {10.1007/s10791-009-9120-1},
journal = {Inf. Retr.},
month = jun,
pages = {197–200},
numpages = {4}
}

@article{10.1007/s10791-009-9117-9,
author = {Bai, Bing and Weston, Jason and Grangier, David and Collobert, Ronan and Sadamasa, Kunihiko and Qi, Yanjun and Chapelle, Olivier and Weinberger, Kilian},
title = {Learning to Rank with (a Lot of) Word Features},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9117-9},
doi = {10.1007/s10791-009-9117-9},
abstract = {In this article we present Supervised Semantic Indexing which defines a class of nonlinear (quadratic) models that are discriminatively trained to directly map from the word content in a query-document or document-document pair to a ranking score. Like Latent Semantic Indexing (LSI), our models take account of correlations between words (synonymy, polysemy). However, unlike LSI our models are trained from a supervised signal directly on the ranking task of interest, which we argue is the reason for our superior results. As the query and target texts are modeled separately, our approach is easily generalized to different retrieval tasks, such as cross-language retrieval or online advertising placement. Dealing with models on all pairs of words features is computationally challenging. We propose several improvements to our basic model for addressing this issue, including low rank (but diagonal preserving) representations, correlated feature hashing and sparsification. We provide an empirical study of all these methods on retrieval tasks based on Wikipedia documents as well as an Internet advertisement task. We obtain state-of-the-art performance while providing realistically scalable methods.},
journal = {Inf. Retr.},
month = jun,
pages = {291–314},
numpages = {24},
keywords = {Content matching, Learning to rank, Feature hashing, Cross language retrieval, Semantic indexing}
}

@article{10.1007/s10791-009-9116-x,
author = {Yilmaz, Emine and Robertson, Stephen},
title = {On the Choice of Effectiveness Measures for Learning to Rank},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9116-x},
doi = {10.1007/s10791-009-9116-x},
abstract = {Most current machine learning methods for building search engines are based on the assumption that there is a target evaluation metric that evaluates the quality of the search engine with respect to an end user and the engine should be trained to optimize for that metric. Treating the target evaluation metric as a given, many different approaches (e.g. LambdaRank, SoftRank, RankingSVM, etc.) have been proposed to develop methods for optimizing for retrieval metrics. Target metrics used in optimization act as bottlenecks that summarize the training data and it is known that some evaluation metrics are more informative than others. In this paper, we consider the effect of the target evaluation metric on learning to rank. In particular, we question the current assumption that retrieval systems should be designed to directly optimize for a metric that is assumed to evaluate user satisfaction. We show that even if user satisfaction can be measured by a metric X, optimizing the engine on a training set for a more informative metric Y may result in a better test performance according to X (as compared to optimizing the engine directly for X on the training set). We analyze the situations as to when there is a significant difference in the two cases in terms of the amount of available training data and the number of dimensions of the feature space.},
journal = {Inf. Retr.},
month = jun,
pages = {271–290},
numpages = {20},
keywords = {Empirical risk minimization, Evaluation, Evaluation metrics, Learning to rank, Training}
}

@article{10.1007/s10791-009-9112-1,
author = {Wu, Qiang and Burges, Christopher J. and Svore, Krysta M. and Gao, Jianfeng},
title = {Adapting Boosting for Information Retrieval Measures},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9112-1},
doi = {10.1007/s10791-009-9112-1},
abstract = {We present a new ranking algorithm that combines the strengths of two previous methods: boosted tree classification, and LambdaRank, which has been shown to be empirically optimal for a widely used information retrieval measure. Our algorithm is based on boosted regression trees, although the ideas apply to any weak learners, and it is significantly faster in both train and test phases than the state of the art, for comparable accuracy. We also show how to find the optimal linear combination for any two rankers, and we use this method to solve the line search problem exactly during boosting. In addition, we show that starting with a previously trained model, and boosting using its residuals, furnishes an effective technique for model adaptation, and we give significantly improved results for a particularly pressing problem in web search--training rankers for markets for which only small amounts of labeled data are available, given a ranker trained on much more data from a larger market.},
journal = {Inf. Retr.},
month = jun,
pages = {254–270},
numpages = {17},
keywords = {Learning to rank, Boosting, Web search}
}

@article{10.1007/s10791-009-9111-2,
author = {Chen, Depin and Xiong, Yan and Yan, Jun and Xue, Gui-Rong and Wang, Gang and Chen, Zheng},
title = {Knowledge Transfer for Cross Domain Learning to Rank},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9111-2},
doi = {10.1007/s10791-009-9111-2},
abstract = {Recently, learning to rank technology is attracting increasing attention from both academia and industry in the areas of machine learning and information retrieval. A number of algorithms have been proposed to rank documents according to the user-given query using a human-labeled training dataset. A basic assumption behind general learning to rank algorithms is that the training and test data are drawn from the same data distribution. However, this assumption does not always hold true in real world applications. For example, it can be violated when the labeled training data become outdated or originally come from another domain different from its counterpart of test data. Such situations bring a new problem, which we define as cross domain learning to rank. In this paper, we aim at improving the learning of a ranking model in target domain by leveraging knowledge from the outdated or out-of-domain data (both are referred to as source domain data). We first give a formal definition of the cross domain learning to rank problem. Following this, two novel methods are proposed to conduct knowledge transfer at feature level and instance level, respectively. These two methods both utilize Ranking SVM as the basic learner. In the experiments, we evaluate these two methods using data from benchmark datasets for document retrieval. The results show that the feature-level transfer method performs better with steady improvements over baseline approaches across different datasets, while the instance-level transfer method comes out with varying performance depending on the dataset used.},
journal = {Inf. Retr.},
month = jun,
pages = {236–253},
numpages = {18},
keywords = {Knowledge transfer, Information retrieval, Ranking SVM, Learning to rank}
}

@article{10.1007/s10791-009-9110-3,
author = {Chapelle, Olivier and Wu, Mingrui},
title = {Gradient Descent Optimization of Smoothed Information Retrieval Metrics},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9110-3},
doi = {10.1007/s10791-009-9110-3},
abstract = {Most ranking algorithms are based on the optimization of some loss functions, such as the pairwise loss. However, these loss functions are often different from the criteria that are adopted to measure the quality of the web page ranking results. To overcome this problem, we propose an algorithm which aims at directly optimizing popular measures such as the Normalized Discounted Cumulative Gain and the Average Precision. The basic idea is to minimize a smooth approximation of these measures with gradient descent. Crucial to this kind of approach is the choice of the smoothing factor. We provide various theoretical analysis on that choice and propose an annealing algorithm to iteratively minimize a less and less smoothed approximation of the measure of interest. Results on the Letor benchmark datasets show that the proposed algorithm achieves state-of-the-art performances.},
journal = {Inf. Retr.},
month = jun,
pages = {216–235},
numpages = {20},
keywords = {Learning to rank, Annealing, Gradient descent}
}

@article{10.1007/s10791-009-9109-9,
author = {Chapelle, O. and Keerthi, S. S.},
title = {Efficient Algorithms for Ranking with SVMs},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9109-9},
doi = {10.1007/s10791-009-9109-9},
abstract = {RankSVM (Herbrich et al. in Advances in large margin classifiers. MIT Press, Cambridge, MA, 2000; Joachims in Proceedings of the ACM conference on knowledge discovery and data mining (KDD), 2002) is a pairwise method for designing ranking models. SVMLight is the only publicly available software for RankSVM. It is slow and, due to incomplete training with it, previous evaluations show RankSVM to have inferior ranking performance. We propose new methods based on primal Newton method to speed up RankSVM training and show that they are 5 orders of magnitude faster than SVMLight. Evaluation on the Letor benchmark datasets after complete training using such methods shows that the performance of RankSVM is excellent.},
journal = {Inf. Retr.},
month = jun,
pages = {201–215},
numpages = {15},
keywords = {AUC optimization, Support vector machines, Ranking}
}

@article{10.1007/s10791-009-9118-8,
author = {Bendersky, Michael and Kurland, Oren},
title = {Utilizing Passage-Based Language Models for Ad Hoc Document Retrieval},
year = {2010},
issue_date = {April     2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9118-8},
doi = {10.1007/s10791-009-9118-8},
abstract = {To cope with the fact that, in the ad hoc retrieval setting, documents relevant to a query could contain very few (short) parts (passages) with query-related information, researchers proposed passage-based document ranking approaches. We show that several of these retrieval methods can be understood, and new ones can be derived, using the same probabilistic model. We use language-model estimates to instantiate specific retrieval algorithms, and in doing so present a novel passage language model that integrates information from the containing document to an extent controlled by the estimated document homogeneity. Several document-homogeneity measures that we present yield passage language models that are more effective than the standard passage model for basic document retrieval and for constructing and utilizing passage-based relevance models; these relevance models also outperform a document-based relevance model. Finally, we demonstrate the merits in using the document-homogeneity measures for integrating document-query and passage-query similarity information for document retrieval.},
journal = {Inf. Retr.},
month = apr,
pages = {157–187},
numpages = {31},
keywords = {Ad hoc document retrieval, Passage-based relevance models, Document homogeneity, Relevance models, Passage-based language models}
}

@article{10.1007/s10791-009-9115-y,
author = {Mogotsi, I. C.},
title = {Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch\"{u}Tze: Introduction to Information Retrieval},
year = {2010},
issue_date = {April     2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9115-y},
doi = {10.1007/s10791-009-9115-y},
journal = {Inf. Retr.},
month = apr,
pages = {192–195},
numpages = {4}
}

@article{10.1007/s10791-009-9114-z,
author = {Buscher, Georg},
title = {Bernard J. Jansen, Amanda Spink, Isak Taksa: Handbook of Research on Web Log Analysis},
year = {2010},
issue_date = {April     2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9114-z},
doi = {10.1007/s10791-009-9114-z},
journal = {Inf. Retr.},
month = apr,
pages = {188–191},
numpages = {4}
}

@article{10.1007/s10791-009-9113-0,
author = {Naughton, M. and Stokes, N. and Carthy, J.},
title = {Sentence-Level Event Classification in Unstructured Texts},
year = {2010},
issue_date = {April     2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9113-0},
doi = {10.1007/s10791-009-9113-0},
abstract = {The ability to correctly classify sentences that describe events is an important task for many natural language applications such as Question Answering (QA) and Text Summarisation. In this paper, we treat event detection as a sentence level text classification problem. Overall, we compare the performance of discriminative versus generative approaches to this task: namely, a Support Vector Machine (SVM) classifier versus a Language Modeling (LM) approach. We also investigate a rule-based method that uses handcrafted lists of `trigger' terms derived from WordNet. Two datasets are used in our experiments to test each approach on six different event types, i.e., Die, Attack, Injure, Meet, Transport and Charge-Indict. Our experimental results show that the trained SVM classifier significantly outperforms the simple rule-based system and language modeling approach on both datasets: ACE (F1 66% vs. 45% and 38%, respectively) and IBC (F1 92% vs. 88% and 74%, respectively). A detailed error analysis framework for the task is also provided which separates errors into different types: semantic, inference, continuous and trigger-less.},
journal = {Inf. Retr.},
month = apr,
pages = {132–156},
numpages = {25},
keywords = {Machine learning, Language modeling, Information extraction, Event detection}
}

@article{10.1007/s10791-009-9108-x,
author = {Aljaber, Bader and Stokes, Nicola and Bailey, James and Pei, Jian},
title = {Document Clustering of Scientific Texts Using Citation Contexts},
year = {2010},
issue_date = {April     2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9108-x},
doi = {10.1007/s10791-009-9108-x},
abstract = {Document clustering has many important applications in the area of data mining and information retrieval. Many existing document clustering techniques use the "bag-of-words" model to represent the content of a document. However, this representation is only effective for grouping related documents when these documents share a large proportion of lexically equivalent terms. In other words, instances of synonymy between related documents are ignored, which can reduce the effectiveness of applications using a standard full-text document representation. To address this problem, we present a new approach for clustering scientific documents, based on the utilization of citation contexts. A citation context is essentially the text surrounding the reference markers used to refer to other scientific works. We hypothesize that citation contexts will provide relevant synonymous and related vocabulary which will help increase the effectiveness of the bag-of-words representation. In this paper, we investigate the power of these citation-specific word features, and compare them with the original document's textual representation in a document clustering task on two collections of labeled scientific journal papers from two distinct domains: High Energy Physics and Genomics. We also compare these text-based clustering techniques with a link-based clustering algorithm which determines the similarity between documents based on the number of co-citations, that is in-links represented by citing documents and out-links represented by cited documents. Our experimental results indicate that the use of citation contexts, when combined with the vocabulary in the full-text of the document, is a promising alternative means of capturing critical topics covered by journal articles. More specifically, this document representation strategy when used by the clustering algorithm investigated in this paper, outperforms both the full-text clustering approach and the link-based clustering technique on both scientific journal datasets.},
journal = {Inf. Retr.},
month = apr,
pages = {101–131},
numpages = {31},
keywords = {Document clustering, Text categorization, Citation contexts}
}

@article{10.1007/s10791-009-9107-y,
author = {Lu, Jianguo and Li, Dingding},
title = {Estimating Deep Web Data Source Size by Capture---Recapture Method},
year = {2010},
issue_date = {February  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9107-y},
doi = {10.1007/s10791-009-9107-y},
abstract = {This paper addresses the problem of estimating the size of a deep web data source that is accessible by queries only. Since most deep web data sources are non-cooperative, a data source size can only be estimated by sending queries and analyzing the returning results. We propose an efficient estimator based on the capture---recapture method. First we derive an equation between the overlapping rate and the percentage of the data examined when random samples are retrieved from a uniform distribution. This equation is conceptually simple and leads to the derivation of an estimator for samples obtained by random queries. Since random queries do not produce random documents, it is well known that the traditional methods by random queries underestimate the size, i.e., those estimators have negative bias. Based on the simple estimator for random samples, we adjust the equation so that it can handle the samples returned by random queries. We conduct both simulation studies and experiments on corpora including Gov2, Reuters, Newsgroups, and Wikipedia. The results show that our method has small bias and standard deviation.},
journal = {Inf. Retr.},
month = feb,
pages = {70–95},
numpages = {26},
keywords = {Deep web, Capture---recapture, Estimators}
}

@article{10.1007/s10791-009-9100-5,
author = {Stokes, Nicola},
title = {William Hersh: Information Retrieval: A Health and Biomedical Perspective, 3rd Ed},
year = {2010},
issue_date = {February  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9100-5},
doi = {10.1007/s10791-009-9100-5},
journal = {Inf. Retr.},
month = feb,
pages = {96–100},
numpages = {5}
}

@article{10.1007/s10791-009-9099-7,
author = {Zhang, Yuye and Park, Laurence A. and Moffat, Alistair},
title = {Click-Based Evidence for Decaying Weight Distributions in Search Effectiveness Metrics},
year = {2010},
issue_date = {February  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9099-7},
doi = {10.1007/s10791-009-9099-7},
abstract = {Search effectiveness metrics are used to evaluate the quality of the answer lists returned by search services, usually based on a set of relevance judgments. One plausible way of calculating an effectiveness score for a system run is to compute the inner-product of the run's relevance vector and a "utility" vector, where the ith element in the utility vector represents the relative benefit obtained by the user of the system if they encounter a relevant document at depth i in the ranking. This paper uses such a framework to examine the user behavior patterns--and hence utility weightings--that can be inferred from a web query log. We describe a process for extrapolating user observations from query log clickthroughs, and employ this user model to measure the quality of effectiveness weighting distributions. Our results show that for measures with static distributions (that is, utility weighting schemes for which the weight vector is independent of the relevance vector), the geometric weighting model employed in the rank-biased precision effectiveness metric offers the closest fit to the user observation model. In addition, using past TREC data as to indicate likelihood of relevance, we also show that the distributions employed in the BPref and MRR metrics are the best fit out of the measures for which static distributions do not exist.},
journal = {Inf. Retr.},
month = feb,
pages = {46–69},
numpages = {24},
keywords = {Clickthrough, Reciprocal rank, Query log, BPref, Rank-biased precision, Effectiveness metric, Average precision}
}

@article{10.1007/s10791-009-9098-8,
author = {Liu, Yuting and Liu, Tie-Yan and Gao, Bin and Ma, Zhiming and Li, Hang},
title = {A Framework to Compute Page Importance Based on User Behaviors},
year = {2010},
issue_date = {February  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9098-8},
doi = {10.1007/s10791-009-9098-8},
abstract = {This paper is concerned with a framework to compute the importance of webpages by using real browsing behaviors of Web users. In contrast, many previous approaches like PageRank compute page importance through the use of the hyperlink graph of the Web. Recently, people have realized that the hyperlink graph is incomplete and inaccurate as a data source for determining page importance, and proposed using the real behaviors of Web users instead. In this paper, we propose a formal framework to compute page importance from user behavior data (which covers some previous works as special cases). First, we use a stochastic process to model the browsing behaviors of Web users. According to the analysis on hundreds of millions of real records of user behaviors, we justify that the process is actually a continuous-time time-homogeneous Markov process, and its stationary probability distribution can be used as the measure of page importance. Second, we propose a number of ways to estimate parameters of the stochastic process from real data, which result in a group of algorithms for page importance computation (all referred to as BrowseRank). Our experimental results have shown that the proposed algorithms can outperform the baseline methods such as PageRank and TrustRank in several tasks, demonstrating the advantage of using our proposed framework.},
journal = {Inf. Retr.},
month = feb,
pages = {22–45},
numpages = {24},
keywords = {BrowseRank, Continuous-time time-homogeneous Markov process, Staying time, User browsing process}
}

@article{10.1007/s10791-009-9097-9,
author = {Lemstr\"{o}m, Kjell and Mikkil\"{a}, Niko and M\"{a}kinen, Veli},
title = {Filtering Methods for Content-Based Retrieval on Indexed Symbolic Music Databases},
year = {2010},
issue_date = {February  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9097-9},
doi = {10.1007/s10791-009-9097-9},
abstract = {We introduce fast filtering methods for content-based music retrieval problems, where the music is modeled as sets of points in the Euclidean plane, formed by the (on-set time, pitch) pairs. The filters exploit a precomputed index for the database, and run in time dependent on the query length and intermediate output sizes of the filters, being almost independent of the database size. With a quadratic size index, the filters are provably lossless for general point sets of this kind. In the context of music, the search space can be narrowed down, which enables the use of a linear sized index for effective and efficient lossless filtering. For the checking phase, which dominates the overall running time, we exploit previously designed algorithms suitable for local checking. In our experiments on a music database, our best filter-based methods performed several orders of a magnitude faster than the previously designed solutions.},
journal = {Inf. Retr.},
month = feb,
pages = {1–21},
numpages = {21},
keywords = {Indexing, Symbolically encoded polyphonic music, Filtering, Content-based retrieval}
}

@article{10.1007/s10791-009-9105-0,
author = {Clarke, Charles L. and Cormack, Gordon V. and Lynam, Thomas R. and Buckley, Chris and Harman, Donna},
title = {Swapping Documents and Terms},
year = {2009},
issue_date = {December  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9105-0},
doi = {10.1007/s10791-009-9105-0},
abstract = {Experiments were conducted to explore the impact of combining various components of eight leading information retrieval systems. Each system demonstrated improved effectiveness through the use of  blind feedback , also known as  pseudo-relevance feedback , a form of query expansion. Blind feedback uses the results of a preliminary retrieval step to augment the efficacy of a secondary retrieval step. The hybrid combination of primary and secondary retrieval steps from different systems in a number of cases yielded better effectiveness than either of the constituent systems alone. This positive combining effect was observed when entire documents were passed between the two retrieval steps, but not when only the expansion terms were passed. Several combinations of primary and secondary retrieval steps were fused using the CombMNZ algorithm; all yielded significant effectiveness improvement over the individual systems, with the best yielding an improvement of 13% (  p  = 10 6) over the best individual system and an improvement of 4% (  p  = 10 5) over a simple fusion of the eight systems.},
journal = {Inf. Retr.},
month = dec,
pages = {680–694},
numpages = {15},
keywords = {Fusion, Pseudo-relevance feedback, Blink feedback}
}

@article{10.1007/s10791-009-9104-1,
author = {Ogilvie, Paul and Voorhees, Ellen and Callan, Jamie},
title = {On the Number of Terms Used in Automatic Query Expansion},
year = {2009},
issue_date = {December  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9104-1},
doi = {10.1007/s10791-009-9104-1},
abstract = {This paper investigates the number of expansion terms to use in automatic query expansion by examining the behavior of eight retrieval systems participating in the NRRC Reliable Information Access Workshop. The results demonstrate that current systems are able to obtain nearly all of the benefit of using a fixed number of expansion terms per topic, but significant additional improvement is possible if systems were able to accurately select the best number of expansion terms on a per topic basis. When optimizing average effectiveness as measured by mean average precision, using a fixed number of terms increases the score a large amount for a small number of topics but has little effect for most topics. The analysis further suggests that when a topic is helped by automatic feedback, the increase is from a set of terms that reinforce each other rather than from the system finding a single excellent term.},
journal = {Inf. Retr.},
month = dec,
pages = {666–679},
numpages = {14},
keywords = {Automatic query expansion, Blind feedback, Pseudo relevance feedback}
}

@article{10.1007/s10791-009-9103-2,
author = {Buckley, Chris},
title = {Why Current IR Engines Fail},
year = {2009},
issue_date = {December  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9103-2},
doi = {10.1007/s10791-009-9103-2},
abstract = {Observations from a unique investigation of failure analysis of Information Retrieval research engines held in 2003 are presented. The Reliable Information Access Workshop invited seven leading IR research groups to supply both their systems and their experts to an effort to analyze why their systems fail on some topics and whether the failures are due to system flaws, approach flaws, or the topic itself. There were surprising results from this cross-system failure analysis. One is that despite systems retrieving very different documents, the major cause of failure for any particular topic was almost always the same across all systems. Another is that relationships between aspects of a topic are not especially important for state-of-the-art systems; the systems are failing at a much more basic level where the top-retrieved documents are not reflecting some aspect at all. The investigatory framework and the lessons learned can serve as a model for needed future research in this area.},
journal = {Inf. Retr.},
month = dec,
pages = {652–665},
numpages = {14},
keywords = {Comparative system analysis, Failure analysis, Information retrieval evaluation, Failure categorization}
}

@article{10.1007/s10791-009-9102-3,
author = {Soboroff, Ian},
title = {A Guide to the RIA Workshop Data Archive},
year = {2009},
issue_date = {December  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9102-3},
doi = {10.1007/s10791-009-9102-3},
abstract = {During the course of the Reliable Information Access (RIA) workshop, a data archive was created to hold the outputs of the many experiments being done. This archive was designed to serve both as an organizational structure to support the researchers at the workshop itself and as a public archive of experimental retrieval results. This article describes the structure of the data in the archive and the ways in which the data may be accessed.},
journal = {Inf. Retr.},
month = dec,
pages = {642–651},
numpages = {10},
keywords = {Archive, Experiment}
}

@article{10.1007/s10791-009-9101-4,
author = {Harman, Donna and Buckley, Chris},
title = {Overview of the Reliable Information Access Workshop},
year = {2009},
issue_date = {December  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9101-4},
doi = {10.1007/s10791-009-9101-4},
abstract = {The Reliable Information Access (RIA) Workshop was held in the summer of 2003, with a goal of improved understanding of information retrieval systems, in particular with regard to the variability of retrieval performance across topics. The workshop ran massive cross-system failure analysis on 45 of the TREC topics and also performed cross-system experiments on pseudo-relevance feedback. This paper presents an overview of that workshop, along with some preliminary conclusions from these experiments. Even if this workshop was held 6 years ago, the issues of improving system performance across all topics is still critical to the field and this paper, along with the others in this issue, are the first widely published full papers for the workshop.},
journal = {Inf. Retr.},
month = dec,
pages = {615–641},
numpages = {27},
keywords = {Relevance feedback, Information retrieval, Failure analysis}
}

@article{10.1007/s10791-009-9106-z,
author = {Amig\.{o}, Enrique and Gonzalo, Julio and Artiles, Javier and Verdejo, Felisa},
title = {A Comparison of Extrinsic Clustering Evaluation Metrics Based on Formal Constraints},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9106-z},
doi = {10.1007/s10791-009-9106-z},
journal = {Inf. Retr.},
month = oct,
pages = {613},
numpages = {1}
}

@article{10.1007/s10791-009-9096-x,
author = {Klampanos, Iraklis A.},
title = {Manning Christopher, Prabhakar Raghavan, Hinrich Sch\"{u}Tze: Introduction to Information Retrieval},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9096-x},
doi = {10.1007/s10791-009-9096-x},
journal = {Inf. Retr.},
month = oct,
pages = {609–612},
numpages = {4}
}

@article{10.1007/s10791-009-9095-y,
author = {O'Brien, Heather L.},
title = {D. Nahl, D. Bilal (Eds.): Information and Emotion: The Emergent Affective Paradigm in Information Behaviour Research and Theory},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9095-y},
doi = {10.1007/s10791-009-9095-y},
journal = {Inf. Retr.},
month = oct,
pages = {605–608},
numpages = {4}
}

@article{10.1007/s10791-009-9094-z,
author = {Thomas, Paul and Hawking, David},
title = {Server Selection Methods in Personal Metasearch: A Comparative Empirical Study},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9094-z},
doi = {10.1007/s10791-009-9094-z},
abstract = {Server selection is an important subproblem in distributed information retrieval (DIR) but has commonly been studied with collections of more or less uniform size and with more or less homogeneous content. In contrast, realistic DIR applications may feature much more varied collections. In particular, personal metasearch--a novel application of DIR which includes all of a user's online resources--may involve collections which vary in size by several orders of magnitude, and which have highly varied data. We describe a number of algorithms for server selection, and consider their effectiveness when collections vary widely in size and are represented by imperfect samples. We compare the algorithms on a personal metasearch testbed comprising calendar, email, mailing list and web collections, where collection sizes differ by three orders of magnitude. We then explore the effect of collection size variations using four partitionings of the TREC ad hoc data used in many other DIR experiments. Kullback-Leibler divergence, previously considered poorly effective, performs better than expected in this application; other techniques thought to be effective perform poorly and are not appropriate for this problem. A strong correlation with size-based rankings for many techniques may be responsible.},
journal = {Inf. Retr.},
month = oct,
pages = {581–604},
numpages = {24},
keywords = {Distributed information retrieval, Server selection}
}

@article{10.1007/s10791-008-9071-y,
author = {Aiolli, Fabio and Cardin, Riccardo and Sebastiani, Fabrizio and Sperduti, Alessandro},
title = {Preferential Text Classification: Learning Algorithms and Evaluation Measures},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9071-y},
doi = {10.1007/s10791-008-9071-y},
abstract = {In many applicative contexts in which textual documents are labelled with thematic categories, a distinction is made between the primary categories of a document, which represent the topics that are central to it, and its secondary categories, which represent topics that the document only touches upon. We contend that this distinction, so far neglected in text categorization research, is important and deserves to be explicitly tackled. The contribution of this paper is threefold. First, we propose an evaluation measure for this  preferential text categorization  task, whereby different kinds of misclassifications involving either primary or secondary categories have a different impact on effectiveness. Second, we establish several baseline results for this task on a well-known benchmark for patent classification in which the distinction between primary and secondary categories is present; these results are obtained by reformulating the preferential text categorization task in terms of well established classification problems, such as single and/or multi-label multiclass classification; state-of-the-art learning technology such as SVMs and kernel-based methods are used. Third, we improve on these results by using a recently proposed class of algorithms explicitly devised for learning from training data expressed in preferential form, i.e., in the form "for document  d    i  , category  c  is preferred to category  c  "; this allows us to distinguish between primary and secondary categories not only in the classification phase but also in the learning phase, thus differentiating their impact on the classifiers to be generated.},
journal = {Inf. Retr.},
month = oct,
pages = {559–580},
numpages = {22},
keywords = {Text classification, Primary and secondary categories, Supervised learning, Preferential learning, Text categorization}
}

@article{10.1007/s10791-008-9070-z,
author = {Boiy, Erik and Moens, Marie-Francine},
title = {A Machine Learning Approach to Sentiment Analysis in Multilingual Web Texts},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9070-z},
doi = {10.1007/s10791-008-9070-z},
abstract = {Sentiment analysis, also called opinion mining, is a form of information extraction from text of growing research and commercial interest. In this paper we present our machine learning experiments with regard to sentiment analysis in blog, review and forum texts found on the World Wide Web and written in English, Dutch and French. We train from a set of example sentences or statements that are manually annotated as positive, negative or neutral with regard to a certain entity. We are interested in the feelings that people express with regard to certain consumption products. We learn and evaluate several classification models that can be configured in a cascaded pipeline. We have to deal with several problems, being the noisy character of the input texts, the attribution of the sentiment to a particular entity and the small size of the training set. We succeed to identify positive, negative and neutral feelings to the entity under consideration with ca. 83% accuracy for English texts based on unigram features augmented with linguistic features. The accuracy results of processing the Dutch and French texts are ca. 70 and 68% respectively due to the larger variety of the linguistic expressions that more often diverge from standard language, thus demanding more training patterns. In addition, our experiments give us insights into the portability of the learned models across domains and languages. A substantial part of the article investigates the role of active learning techniques for reducing the number of examples to be manually annotated.},
journal = {Inf. Retr.},
month = oct,
pages = {526–558},
numpages = {33},
keywords = {Information tracking, Cross-language learning, Opinion mining, Active learning}
}

@article{10.1007/s10791-008-9069-5,
author = {Wilbur, W. John and Kim, Won},
title = {The Ineffectiveness of Within-Document Term Frequency in Text Classification},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9069-5},
doi = {10.1007/s10791-008-9069-5},
abstract = {For the purposes of classification it is common to represent a document as a bag of words. Such a representation consists of the individual terms making up the document together with the number of times each term appears in the document. All classification methods make use of the terms. It is common to also make use of the local term frequencies at the price of some added complication in the model. Examples are the na\"{\i}ve Bayes multinomial model (MM), the Dirichlet compound multinomial model (DCM) and the exponential-family approximation of the DCM (EDCM), as well as support vector machines (SVM). Although it is usually claimed that incorporating local word frequency in a document improves text classification performance, we here test whether such claims are true or not. In this paper we show experimentally that simplified forms of the MM, EDCM, and SVM models which ignore the frequency of each word in a document perform about at the same level as MM, DCM, EDCM and SVM models which incorporate local term frequency. We also present a new form of the na\"{\i}ve Bayes multivariate Bernoulli model (MBM) which is able to make use of local term frequency and show again that it offers no significant advantage over the plain MBM. We conclude that word burstiness is so strong that additional occurrences of a word essentially add no useful information to a classifier.},
journal = {Inf. Retr.},
month = oct,
pages = {509–525},
numpages = {17},
keywords = {Word burstiness, Within-document frequency, Bag-of-words}
}

@article{10.1007/s10791-008-9068-6,
author = {Amorim, Renato Cordeiro},
title = {Pascal Poncelet, Florent Masseglia, Maguelonne Teisseire: Successes and New Directions in Data Mining},
year = {2009},
issue_date = {August    2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9068-6},
doi = {10.1007/s10791-008-9068-6},
journal = {Inf. Retr.},
month = aug,
pages = {504–508},
numpages = {5}
}

@article{10.1007/s10791-008-9067-7,
author = {Lin, Jimmy and Wilbur, W. John},
title = {Modeling Actions of PubMed Users with N-Gram Language Models},
year = {2009},
issue_date = {August    2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9067-7},
doi = {10.1007/s10791-008-9067-7},
abstract = {Transaction logs from online search engines are valuable for two reasons: First, they provide insight into human information-seeking behavior. Second, log data can be used to train user models, which can then be applied to improve retrieval systems. This article presents a study of logs from PubMed®, the public gateway to the MEDLINE® database of bibliographic records from the medical and biomedical primary literature. Unlike most previous studies on general Web search, our work examines user activities with a highly-specialized search engine. We encode user actions as string sequences and model these sequences using n-gram language models. The models are evaluated in terms of perplexity and in a sequence prediction task. They help us better understand how PubMed users search for information and provide an enabler for improving users' search experience.},
journal = {Inf. Retr.},
month = aug,
pages = {487–503},
numpages = {17},
keywords = {Search behavior, Query log analysis}
}

@article{10.1007/s10791-008-9066-8,
author = {Amig\'{o}, Enrique and Gonzalo, Julio and Artiles, Javier and Verdejo, Felisa},
title = {A Comparison of Extrinsic Clustering Evaluation Metrics Based on Formal Constraints},
year = {2009},
issue_date = {August    2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9066-8},
doi = {10.1007/s10791-008-9066-8},
abstract = {There is a wide set of evaluation metrics available to compare the quality of text clustering algorithms. In this article, we define a few intuitive formal constraints on such metrics which shed light on which aspects of the quality of a clustering are captured by different metric families. These formal constraints are validated in an experiment involving human assessments, and compared with other constraints proposed in the literature. Our analysis of a wide range of metrics shows that only BCubed satisfies all formal constraints. We also extend the analysis to the problem of overlapping clustering, where items can simultaneously belong to more than one cluster. As Bcubed cannot be directly applied to this task, we propose a modified version of Bcubed that avoids the problems found with other metrics.},
journal = {Inf. Retr.},
month = aug,
pages = {461–486},
numpages = {26},
keywords = {Formal constraints, Clustering, Evaluation metrics}
}

@article{10.1007/s10791-008-9065-9,
author = {Kurland, Oren},
title = {Re-Ranking Search Results Using Language Models of Query-Specific Clusters},
year = {2009},
issue_date = {August    2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9065-9},
doi = {10.1007/s10791-008-9065-9},
abstract = {To obtain high precision at top ranks by a search performed in response to a query, researchers have proposed a cluster-based re-ranking paradigm: clustering an initial list of documents that are the most highly ranked by some initial search, and using information induced from these (often called) query-specific clusters for re-ranking the list. However, results concerning the effectiveness of various automatic cluster-based re-ranking methods have been inconclusive. We show that using query-specific clusters for automatic re-ranking of top-retrieved documents is effective with several methods in which clusters play different roles, among which is the smoothing of document language models. We do so by adapting previously-proposed cluster-based retrieval approaches, which are based on (static) query-independent clusters for ranking all documents in a corpus, to the re-ranking setting wherein clusters are query-specific. The best performing method that we develop outperforms both the initial document-based ranking and some previously proposed cluster-based re-ranking approaches; furthermore, this algorithm consistently outperforms a state-of-the-art pseudo-feedback-based approach. In further exploration we study the performance of cluster-based smoothing methods for re-ranking with various (soft and hard) clustering algorithms, and demonstrate the importance of clusters in providing context from the initial list through a comparison to using single documents to this end.},
journal = {Inf. Retr.},
month = aug,
pages = {437–460},
numpages = {24},
keywords = {Cluster-based re-ranking, Cluster-based smoothing, Cluster-based language models, Query-specific clusters}
}

@article{10.1007/s10791-009-9093-0,
author = {Lazarinis, Fotis and Vilares, Jes\'{u}s and Tait, John and Efthimiadis, Efthimis N.},
title = {Current Research Issues and Trends in Non-English Web Searching},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9093-0},
doi = {10.1007/s10791-009-9093-0},
abstract = {With increasingly higher numbers of non-English language web searchers the problems of efficient handling of non-English Web documents and user queries are becoming major issues for search engines. The main aim of this review paper is to make researchers aware of the existing problems in monolingual non-English Web retrieval by providing an overview of open issues. A significant number of papers are reviewed and the research issues investigated in these studies are categorized in order to identify the research questions and solutions proposed in these papers. Further research is proposed at the end of each section.},
journal = {Inf. Retr.},
month = jun,
pages = {230–250},
numpages = {21},
keywords = {Encoding handling, Non-English retrieval, Indexing, Query log analysis, Stopwords, Web searching, Segmentation, Stemming, Language identification, Lemmatization}
}

@article{10.1007/s10791-009-9092-1,
author = {Eguchi, Koji and Croft, W. Bruce},
title = {Query Structuring and Expansion with Two-Stage Term Dependence for Japanese Web Retrieval},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9092-1},
doi = {10.1007/s10791-009-9092-1},
abstract = {In this paper, we propose a new term dependence model for information retrieval, which is based on a theoretical framework using Markov random fields. We assume two types of dependencies of terms given in a query: (i) long-range dependencies that may appear for instance within a passage or a sentence in a target document, and (ii) short-range dependencies that may appear for instance within a compound word in a target document. Based on this assumption, our two-stage term dependence model captures both long-range and short-range term dependencies differently, when more than one compound word appear in a query. We also investigate how query structuring with term dependence can improve the performance of query expansion using a relevance model. The relevance model is constructed using the retrieval results of the structured query with term dependence to expand the query. We show that our term dependence model works well, particularly when using query structuring with compound words, through experiments using a 100-gigabyte test collection of web documents mostly written in Japanese. We also show that the performance of the relevance model can be significantly improved by using the structured query with our term dependence model.},
journal = {Inf. Retr.},
month = jun,
pages = {251–274},
numpages = {24},
keywords = {Term dependence, Japanese web retrieval, Structured queries}
}

@article{10.1007/s10791-009-9091-2,
author = {Lazarinis, Fotis and Vilares, Jesus and Tait, John and Efthimiadis, Efthimis N.},
title = {Introduction to the Special Issue on Non-English Web Retrieval},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9091-2},
doi = {10.1007/s10791-009-9091-2},
journal = {Inf. Retr.},
month = jun,
pages = {227–229},
numpages = {3}
}

@article{10.1007/s10791-008-9086-4,
author = {Berendt, Bettina and Kralisch, Anett},
title = {A User-Centric Approach to Identifying Best Deployment Strategies for Language Tools: The Impact of Content and Access Language on Web User Behaviour and Attitudes},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9086-4},
doi = {10.1007/s10791-008-9086-4},
abstract = {The number of Web users whose first language is not English continues to grow, as does the amount of content provided in languages other than English. This poses new challenges for actors on the Web, such as in which language(s) content should be offered, how search tools should deal with mono- and multilingual content, and how users can make the best use of navigation and search options, suited to their individual linguistic skills. How should these challenges be dealt with? Technological approaches to non-English (or in general, cross-language) Web search have made large progress; however, translation remains a hard problem. This precludes a low-cost but high-quality blanket all-language coverage of the whole Web. In this paper, we propose a user-centric approach to answering questions of where to best concentrate efforts and investments. Drawing on linguistic research, we describe data on the availability of content and access to it in first and second languages across the Web. We then present three studies that investigated the impact of the availability (or not) of first-language content and access forms on user behaviour and attitudes. The results indicate that non-English languages are under-represented on the Web and that this is partly due to content-creation, link-setting and link-following behaviour. They also show that user satisfaction is influenced both by the cognitive effort of searching and the availability of alternative information in that language. These findings suggest that more cross-language tools are desirable. However, they also indicate that context (such as user groups' domain expertise or site type) should be considered when tradeoffs between information quality and multilinguality need to be taken into account.},
journal = {Inf. Retr.},
month = jun,
pages = {380–399},
numpages = {20},
keywords = {Non-English, Non-native language, Web search, Information seeking, Native language, Web-site access}
}

@article{10.1007/s10791-008-9085-5,
author = {Piskorski, Jakub and Wieloch, Karol and Sydow, Marcin},
title = {On Knowledge-Poor Methods for Person Name Matching and Lemmatization for Highly Inflectional Languages},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9085-5},
doi = {10.1007/s10791-008-9085-5},
abstract = {Web person search is one of the most common activities of Internet users. Recently, a vast amount of work on applying various NLP techniques for person name disambiguation in large web document collections has been reported, where the main focus was on English and few other major languages. This article reports on knowledge-poor methods for tackling person name matching and lemmatization in Polish, a highly inflectional language with complex person name declension paradigm. These methods apply mainly well-established string distance metrics, some new variants thereof, automatically acquired simple suffix-based lemmatization patterns and some combinations of the aforementioned techniques. Furthermore, we also carried out some initial experiments on deploying techniques that utilize the context, in which person names appear. Results of numerous experiments are presented. The evaluation carried out on a data set extracted from a corpus of on-line news articles revealed that achieving lemmatization accuracy figures greater than 90% seems to be difficult, whereas combining string distance metrics with suffix-based patterns results in 97.6---99% accuracy for the name matching task. Interestingly, no significant additional gain could be achieved through integrating some basic techniques, which try to exploit the local context the names appear in. Although our explorations were focused on Polish, we believe that the work presented in this article constitutes practical guidelines for tackling the same problem for other highly inflectional languages with similar phenomena.},
journal = {Inf. Retr.},
month = jun,
pages = {275–299},
numpages = {25},
keywords = {Highly inflectional languages, Person name matching, String distance metrics, Lemmatization}
}

@article{10.1007/s10791-008-9084-6,
author = {Efthimiadis, Efthimis N. and Malevris, Nicos and Kousaridas, Apostolos and Lepeniotou, Alexandra and Loutas, Nikos},
title = {Non-English Web Search: An Evaluation of Indexing and Searching the Greek Web},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9084-6},
doi = {10.1007/s10791-008-9084-6},
abstract = {The study reports on a longitudinal and comparative evaluation of Greek language searching on the web. Ten engines, five global (A9, AltaVista, Google, MSN Search, and Yahoo!) and five Greek (Anazitisi, Ano-Kato, Phantis. Trinity, and Visto), were evaluated using (a) navigational queries in 2004 and 2006; and (b) by measuring the freshness of the search engine indices in 2005 and 2006. Homepage finding queries for known Greek organizations were created and searched. Queries included the name of the organization in its Greek and non-Greek, English or transliterated equivalent forms. The organizations represented ten categories: government departments, universities, colleges, travel agencies, museums, media (TV, radio, newspapers), transportation, and banks. The freshness of the indices was evaluated by examining the status of the returned URLs (live versus dead) from the navigational queries, and by identifying if the engines have indexed 32480 active (live) Greek domain URLs. Effectiveness measures included (a) qualitative assessment of how engines handle the Greek language; (b) precision at 10 documents (P@10); (c) mean reciprocal rank (MRR); (d) Navigational Query Discounted Cumulative Gain (NQ-DCG), a new heuristic evaluation measure; (e) response time; (f) the ratio of the dead URL links returned, (g) the presence or absence of URLs and the decay observed over the period of the study. The results report on which of the global and Greek search engines perform best; and if the performance achieved is good enough from a user's perspective.},
journal = {Inf. Retr.},
month = jun,
pages = {352–379},
numpages = {28},
keywords = {Evaluation, Search engines, Greek web, Homepage finding, Greek queries, Non-English web search, Navigational queries}
}

@article{10.1007/s10791-008-9083-7,
author = {Guzm\'{a}n-Cabrera, Rafael and Montes-Y-G\'{o}mez, Manuel and Rosso, Paolo and Villase\~{n}or-Pineda, Luis},
title = {Using the Web as Corpus for Self-Training Text Categorization},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9083-7},
doi = {10.1007/s10791-008-9083-7},
abstract = {Most current methods for automatic text categorization are based on supervised learning techniques and, therefore, they face the problem of requiring a great number of training instances to construct an accurate classifier. In order to tackle this problem, this paper proposes a new semi-supervised method for text categorization, which considers the automatic extraction of unlabeled examples from the Web and the application of an enriched self-training approach for the construction of the classifier. This method, even though language independent, is more pertinent for scenarios where large sets of labeled resources do not exist. That, for instance, could be the case of several application domains in different non-English languages such as Spanish. The experimental evaluation of the method was carried out in three different tasks and in two different languages. The achieved results demonstrate the applicability and usefulness of the proposed method.},
journal = {Inf. Retr.},
month = jun,
pages = {400–415},
numpages = {16},
keywords = {Semi-supervised learning, Authorship attribution, Self-training, Web as corpus, Text categorization}
}

@article{10.1007/s10791-008-9082-8,
author = {Blanco, Roi and Lioma, Christina},
title = {Mixed Monolingual Homepage Finding in 34 Languages: The Role of Language Script and Search Domain},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9082-8},
doi = {10.1007/s10791-008-9082-8},
abstract = {The information that is available or sought on the World Wide Web (Web) is increasingly multilingual. Information Retrieval systems, such as the freely available search engines on the Web, need to provide fair and equal access to this information, regardless of the language in which a query is written or where the query is posted from. In this work, we ask two questions: How do existing state of the art search engines deal with languages written in different alphabets (scripts)__ __ Do local language-based search domains actually facilitate access to information__ __ We conduct a thorough study on the effect of multilingual queries for homepage finding, where the aim of the retrieval system is to return only one document, namely the homepage described in the query. We evaluate the effect of multilingual queries in retrieval performance with regard to (i) the alphabet in which the queries are written (e.g., Latin, Russian, Arabic), and (ii) the language domain where the queries are posted (e.g., google.com, google.fr). We query four major freely available search engines with 764 queries in 34 different languages, and look for the correct homepage in the top retrieved results. In order to have fair multilingual experimental settings, we use an ontology that is comparable across languages and also representative of realistic Web searches: football premier leagues in different countries; the official team name represents our query, and the official team homepage represents the document to be retrieved. A series of thorough experiments involving over 10,000 runs, with queries both in their correct and in Latin characters, and also using both global-domain and local-domain searches, reveal that queries issued in the correct script of a language are more likely to be found and ranked in the top 3, while queries in non-Latin script languages which are however issued in Latin script are less likely to be found; also, queries issued to the correct local domain of a search engine, e.g., French queries to yahoo.fr, are likely to have better retrieval performance than queries issued to the global domain of a search engine. To our knowledge, this is the first Web retrieval study that uses such a wide range of languages.},
journal = {Inf. Retr.},
month = jun,
pages = {324–351},
numpages = {28},
keywords = {Web information retrieval, Multilingual information retrieval, Search engines and evaluation}
}

@article{10.1007/s10791-008-9081-9,
author = {Hammo, Bassam H.},
title = {Towards Enhancing Retrieval Effectiveness of Search Engines for Diacritisized Arabic Documents},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9081-9},
doi = {10.1007/s10791-008-9081-9},
abstract = {The majority of Arabic text available on the web is written without short vowels (diacritics). Diacritics are commonly used in religious scripts such as the holy Quran (the book of Islam), Al-Hadith (the teachings of Prophet Mohammad (PBUH)), children's literature, and in some words where ambiguity of articulation might arise. Internet Arabic users might lose credible sources of Arabic text to be retrieved if they could not match the correct diacritical marks attached to the words in the collection. However, typing the diacritical marks is very annoying and time consuming. The other way around, is to ignore these marks and fall into the problem of ambiguity. Previous work suggested pre-processing of Arabic text to remove these diacritical marks before indexing. Consequently, there are noticeable discrepancies when searching the web for Arabic text using international search engines such as Google and yahoo. In this article, we propose a framework to enhance the retrieval effectiveness of search engines to search for diacritic and diacritic-less Arabic text through query expansion techniques. We used a rule-based stemmer and a semantic relational database compiled in an experimental thesaurus to do the expansion. We tested our approach on the scripts of the Quran. We found that query expansion for searching Arabic text is promising and it is likely that the efficiency can be further improved by advanced natural language processing tools.},
journal = {Inf. Retr.},
month = jun,
pages = {300–323},
numpages = {24},
keywords = {Arabic stemming, Arabic information retrieval, Query expansion, Thesaurus, Diacritisized scripts}
}

@article{10.1007/s10791-008-9080-x,
author = {Asker, Lars and Argaw, Atelach Alemu and Gamb\"{a}ck, Bj\"{o}rn and Eyassu Asfeha, Samuel and Nigussie Habte, Lemma},
title = {Classifying Amharic Webnews},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9080-x},
doi = {10.1007/s10791-008-9080-x},
abstract = {We present work aimed at compiling an Amharic corpus from the Web and automatically categorizing the texts. Amharic is the second most spoken Semitic language in the World (after Arabic) and used for countrywide communication in Ethiopia. It is highly inflectional and quite dialectally diversified. We discuss the issues of compiling and annotating a corpus of Amharic news articles from the Web. This corpus was then used in three sets of text classification experiments. Working with a less-researched language highlights a number of practical issues that might otherwise receive less attention or go unnoticed. The purpose of the experiments has not primarily been to develop a cutting-edge text classification system for Amharic, but rather to put the spotlight on some of these issues. The first two sets of experiments investigated the use of Self-Organizing Maps (SOMs) for document classification. Testing on small datasets, we first looked at classifying unseen data into 10 predefined categories of news items, and then at clustering it around query content, when taking 16 queries as class labels. The second set of experiments investigated the effect of operations such as stemming and part-of-speech tagging on text classification performance. We compared three representations while constructing classification models based on bagging of decision trees for the 10 predefined news categories. The best accuracy was achieved using the full text as representation. A representation using only the nouns performed almost equally well, confirming the assumption that most of the information required for distinguishing between various categories actually is contained in the nouns, while stemming did not have much effect on the performance of the classifier.},
journal = {Inf. Retr.},
month = jun,
pages = {416–435},
numpages = {20},
keywords = {Text classification, Semitic languages, Web mining}
}

@article{10.1007/s10791-009-9090-3,
author = {Fern\'{a}ndez-Luna, Juan M. and Huete, Juan F. and Macfarlane, Andrew},
title = {Introduction to the Special Issue on Teaching and Learning in Information Retrieval},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9090-3},
doi = {10.1007/s10791-009-9090-3},
abstract = {We present an overview of the special issue in this paper. The main objective is to provide information for lecturers on how to improve the student experience, using current knowledge in the field. To this end we present an overview of six papers covering areas as diverse as tools and methods used to support teaching and learning, pedagogical challenges in teaching mathematics for search, etc.},
journal = {Inf. Retr.},
month = apr,
pages = {99–101},
numpages = {3},
keywords = {Learning, Educational assessment, Teaching, Curricula, Information retrieval}
}

@article{10.1007/s10791-009-9089-9,
author = {Fern\'{a}ndez-Luna, Juan M. and Huete, Juan F. and Macfarlane, Andrew and Efthimiadis, Efthimis N.},
title = {Teaching and Learning in Information Retrieval},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9089-9},
doi = {10.1007/s10791-009-9089-9},
abstract = {A literature review of pedagogical methods for teaching and learning information retrieval is presented. From the analysis of the literature a taxonomy was built and it is used to structure the paper. Information Retrieval (IR) is presented from different points of view: technical levels, educational goals, teaching and learning methods, assessment and curricula. The review is organized around two levels of abstraction which form a taxonomy that deals with the different aspects of pedagogy as applied to information retrieval. The first level looks at the technical level of delivering information retrieval concepts, and at the educational goals as articulated by the two main subject domains where IR is delivered: computer science (CS) and library and information science (LIS). The second level focuses on pedagogical issues, such as teaching and learning methods, delivery modes (classroom, online or e-learning), use of IR systems for teaching, assessment and feedback, and curricula design. The survey, and its bibliography, provides an overview of the pedagogical research carried out in the field of IR. It also provides a guide for educators on approaches that can be applied to improving the student learning experiences.},
journal = {Inf. Retr.},
month = apr,
pages = {201–226},
numpages = {26},
keywords = {Learning, Curricula, Teaching, Educational assessment, Information retrieval}
}

@article{10.1007/s10791-009-9088-x,
author = {Jones, Gareth J.},
title = {An Inquiry-Based Learning Approach to Teaching Information Retrieval},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9088-x},
doi = {10.1007/s10791-009-9088-x},
abstract = {The study of information retrieval (IR) has increased in interest and importance with the explosive growth of online information in recent years. Learning about IR within formal courses of study enables users of search engines to use them more knowledgeably and effectively, while providing the starting point for the explorations of new researchers into novel search technologies. Although IR can be taught in a traditional manner of formal classroom instruction with students being led through the details of the subject and expected to reproduce this in assessment, the nature of IR as a topic makes it an ideal subject for inquiry-based learning approaches to teaching. In an inquiry-based learning approach students are introduced to the principles of a subject and then encouraged to develop their understanding by solving structured or open problems. Working through solutions in subsequent class discussions enables students to appreciate the availability of alternative solutions as proposed by their classmates. Following this approach students not only learn the details of IR techniques, but significantly, naturally learn to apply them in solution of problems. In doing this they not only gain an appreciation of alternative solutions to a problem, but also how to assess their relative strengths and weaknesses. Developing confidence and skills in problem solving enables student assessment to be structured around solution of problems. Thus students can be assessed on the basis of their understanding and ability to apply techniques, rather simply their skill at reciting facts. This has the additional benefit of encouraging general problem solving skills which can be of benefit in other subjects. This approach to teaching IR was successfully implemented in an undergraduate module where students were assessed in a written examination exploring their knowledge and understanding of the principles of IR and their ability to apply them to solving problems, and a written assignment based on developing an individual research proposal.},
journal = {Inf. Retr.},
month = apr,
pages = {148–161},
numpages = {14},
keywords = {Teaching information retrieval, Inquiry-based learning, Language technology integration}
}

@article{10.1007/s10791-008-9087-3,
author = {Herrera-Viedma, E. and L\'{o}pez-Herrera, A. G. and Alonso, S. and Moreno, J. M. and Cabrerizo, F. J. and Porcel, C.},
title = {A Computer-Supported Learning System to Help Teachers to Teach Fuzzy Information Retrieval Systems},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9087-3},
doi = {10.1007/s10791-008-9087-3},
abstract = {This paper describes a computer-supported learning system to teach students the principles and concepts of Fuzzy Information Retrieval Systems based on weighted queries. This tool is used to support the teacher's activity in the degree course Information Retrieval Systems Based on Artificial Intelligence at the Faculty of Library and Information Sciences at the University of Granada. Learning of languages of weighted queries in Fuzzy Information Retrieval Systems is complex because it is very difficult to understand the different semantics that could be associated to the weights of queries together with their respective strategies of query evaluation. We have developed and implemented this computer-supported education system because it allows to support the teacher's activity in the classroom to teach the use of weighted queries in FIRSs and it helps students to develop self-learning processes on the use of such queries. We have evaluated the performance of its use in the learning process according to the students' perceptions and their results obtained in the course's exams. We have observed that using this software tool the students learn better the management of the weighted query languages and then their performance in the exams is improved.},
journal = {Inf. Retr.},
month = apr,
pages = {179–200},
numpages = {22},
keywords = {Fuzzy connectives, Education, Weighted queries, Fuzzy Information Retrieval, Teaching}
}

@article{10.1007/s10791-008-9079-3,
author = {Henrich, Andreas and Sieber, Stefanie},
title = {Blended Learning and Pure E-Learning Concepts for Information Retrieval: Experiences and Future Directions},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9079-3},
doi = {10.1007/s10791-008-9079-3},
abstract = {Today, teaching and learning are mostly supported by digital material and electronic communication ranging from the provision of slides or scripts in digital form to elaborate, interactive learning environments. This article describes the prospects and risks of blended learning and e-learning for information retrieval courses. It deals with adequate content presentation and representation, as well as with interaction concepts and didactic considerations concerning the cost-benefit ratio of animations, applets, and multimedia elements. We present lessons learnt from 6 years of teaching information retrieval in blended learning and pure e-learning scenarios, and derive graded concepts for basic and advanced topics based on a book-like content representation on the one side, and lecture-recordings on the other side. Each concept is complemented by a pragmatic and focussed use of auxiliary elements such as forums and self-tests. Examples for beneficial and misguided applets and animations are given, along with criteria for their differentiation. Finally, critical success factors for technology enhanced learning approaches in the information retrieval field are derived concerning the creation, utilisation, and maintenance of courses. In short, we will argue that taking into account the nature and stability of the presented content, as well as a thorough consideration of the affordable creation and maintenance effort, are crucial for the success of such concepts. In addition, the closer the concept is to pure e-learning, the more important a high digital presence of the lecturer becomes.},
journal = {Inf. Retr.},
month = apr,
pages = {117–147},
numpages = {31},
keywords = {Teaching information retrieval, Interaction, e-Learning, Blended learning}
}

@article{10.1007/s10791-008-9078-4,
author = {Macfarlane, Andrew},
title = {Teaching Mathematics for Search Using a Tutorial Style of Delivery},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9078-4},
doi = {10.1007/s10791-008-9078-4},
abstract = {Understanding of mathematics is needed to underpin the process of search, either explicitly with Exact Match (Boolean logic, adjacency) or implicitly with Best match natural language search. In this paper we outline some pedagogical challenges in teaching mathematics for information retrieval (IR) to postgraduate information science students. The aim is to take these challenges either found by experience or in the literature, to identify both theoretical and practical ideas in order to improve the delivery of the material and positively affect the learning of the target audience by using a tutorial style of teaching. Results show that there is evidence to support the notion that a more pro-active style of teaching using tutorials yield benefits both in terms of assessment results and student satisfaction.},
journal = {Inf. Retr.},
month = apr,
pages = {162–178},
numpages = {17},
keywords = {Boolean logic, Information retrieval, Information science, Teaching}
}

@article{10.1007/s10791-008-9077-5,
author = {Vilar, Polona and \v{Z}umer, Maja},
title = {The Bologna Reform at the Department of Library and Information Science and Book Studies, University of Ljubljana},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9077-5},
doi = {10.1007/s10791-008-9077-5},
abstract = {Relevance of the new Bologna study programme at the Department of Library and Information Science and Book Studies at University of Ljubljana is demonstrated from different aspects. The example of IS&amp;R themes and topics which are recognized as one of LIS core areas is used to show the differences from the previous study programme in terms of content, together with coverage of Web 2.0 related themes. In regard to teaching and learning methods it is shown how e-learning is used to support the educational process. At the end a few insights into employability of future graduates are added.},
journal = {Inf. Retr.},
month = apr,
pages = {102–116},
numpages = {15},
keywords = {Information seeking and retrieval, Curriculum, Slovenia, E-learning, Web 2.0, LIS education, Ljubljana, Employability, Bologna reform}
}

@article{10.1007/s10791-008-9076-6,
author = {Hersh, William and Voorhees, Ellen},
title = {TREC Genomics Special Issue Overview},
year = {2009},
issue_date = {February  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9076-6},
doi = {10.1007/s10791-008-9076-6},
journal = {Inf. Retr.},
month = feb,
pages = {1–15},
numpages = {15}
}

@article{10.1007/s10791-008-9075-7,
author = {Lu, Yue and Fang, Hui and Zhai, Chengxiang},
title = {An Empirical Study of Gene Synonym Query Expansion in Biomedical Information Retrieval},
year = {2009},
issue_date = {February  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9075-7},
doi = {10.1007/s10791-008-9075-7},
abstract = {Due to the heavy use of gene synonyms in biomedical text, people have tried many query expansion techniques using synonyms in order to improve performance in biomedical information retrieval. However, mixed results have been reported. The main challenge is that it is not trivial to assign appropriate weights to the added gene synonyms in the expanded query; under-weighting of synonyms would not bring much benefit, while overweighting some unreliable synonyms can hurt performance significantly. So far, there has been no systematic evaluation of various synonym query expansion strategies for biomedical text. In this work, we propose two different strategies to extend a standard language modeling approach for gene synonym query expansion and conduct a systematic evaluation of these methods on all the available TREC biomedical text collections for ad hoc document retrieval. Our experiment results show that synonym expansion can significantly improve the retrieval accuracy. However, different query types require different synonym expansion methods, and appropriate weighting of gene names and synonym terms is critical for improving performance.},
journal = {Inf. Retr.},
month = feb,
pages = {51–68},
numpages = {18},
keywords = {Synonym query expansion, Language modeling, Biomedical information retrieval}
}

@article{10.1007/s10791-008-9074-8,
author = {Lu, Zhiyong and Kim, Won and Wilbur, W. John},
title = {Evaluation of Query Expansion Using MeSH in PubMed},
year = {2009},
issue_date = {February  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9074-8},
doi = {10.1007/s10791-008-9074-8},
abstract = {This paper investigates the effectiveness of using MeSH® in PubMed through its automatic query expansion process: Automatic Term Mapping (ATM). We run Boolean searches based on a collection of 55 topics and about 160,000 MEDLINE® citations used in the 2006 and 2007 TREC Genomics Tracks. For each topic, we first automatically construct a query by selecting keywords from the question. Next, each query is expanded by ATM, which assigns different search tags to terms in the query. Three search tags: [MeSH Terms], [Text Words], and [All Fields] are chosen to be studied after expansion because they all make use of the MeSH field of indexed MEDLINE citations. Furthermore, we characterize the two different mechanisms by which the MeSH field is used. Retrieval results using MeSH after expansion are compared to those solely based on the words in MEDLINE title and abstracts. The aggregate retrieval performance is assessed using both F-measure and mean rank precision. Experimental results suggest that query expansion using MeSH in PubMed can generally improve retrieval performance, but the improvement may not affect end PubMed users in realistic situations.},
journal = {Inf. Retr.},
month = feb,
pages = {69–80},
numpages = {12},
keywords = {TREC genomics, Query expansion, PubMed, MeSH}
}

@article{10.1007/s10791-008-9073-9,
author = {Stokes, Nicola and Li, Yi and Cavedon, Lawrence and Zobel, Justin},
title = {Exploring Criteria for Successful Query Expansion in the Genomic Domain},
year = {2009},
issue_date = {February  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9073-9},
doi = {10.1007/s10791-008-9073-9},
abstract = {Query Expansion is commonly used in Information Retrieval to overcome vocabulary mismatch issues, such as synonymy between the original query terms and a relevant document. In general, query expansion experiments exhibit mixed results. Overall TREC Genomics Track results are also mixed; however, results from the top performing systems provide strong evidence supporting the need for expansion. In this paper, we examine the conditions necessary for optimal query expansion performance with respect to two system design issues: IR framework and knowledge source used for expansion. We present a query expansion framework that improves Okapi baseline passage MAP performance by 185%. Using this framework, we compare and contrast the effectiveness of a variety of biomedical knowledge sources used by TREC 2006 Genomics Track participants for expansion. Based on the outcome of these experiments, we discuss the success factors required for effective query expansion with respect to various sources of term expansion, such as corpus-based cooccurrence statistics, pseudo-relevance feedback methods, and domain-specific and domain-independent ontologies and databases. Our results show that choice of document ranking algorithm is the most important factor affecting retrieval performance on this dataset. In addition, when an appropriate ranking algorithm is used, we find that query expansion with domain-specific knowledge sources provides an equally substantive gain in performance over a baseline system.},
journal = {Inf. Retr.},
month = feb,
pages = {17–50},
numpages = {34},
keywords = {Corpus based query expansion, Passage retrieval for genomic queries, Knowledge based query expansion, TREC 2006 Genomics Track, Concept-based normalisation passage ranking, Pseudo relevance feedback}
}

@article{10.1007/s10791-008-9072-x,
author = {Roberts, Phoebe M. and Cohen, Aaron M. and Hersh, William R.},
title = {Tasks, Topics and Relevance Judging for the TREC Genomics Track: Five Years of Experience Evaluating Biomedical Text Information Retrieval Systems},
year = {2009},
issue_date = {February  2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9072-x},
doi = {10.1007/s10791-008-9072-x},
abstract = {With the help of a team of expert biologist judges, the TREC Genomics track has generated four large sets of "gold standard" test collections, comprised of over a hundred unique topics, two kinds of ad hoc retrieval tasks, and their corresponding relevance judgments. Over the years of the track, increasingly complex tasks necessitated the creation of judging tools and training guidelines to accommodate teams of part-time short-term workers from a variety of specialized biological scientific backgrounds, and to address consistency and reproducibility of the assessment process. Important lessons were learned about factors that influenced the utility of the test collections including topic design, annotations provided by judges, methods used for identifying and training judges, and providing a central moderator "meta-judge".},
journal = {Inf. Retr.},
month = feb,
pages = {81–97},
numpages = {17},
keywords = {Information retrieval, Text mining, Reference standards, Evaluation, Inter-annotator agreement}
}

@article{10.1007/s10791-008-9062-z,
author = {Luk, Robert W.},
title = {On Event Space and Rank Equivalence between Probabilistic Retrieval Models},
year = {2008},
issue_date = {December  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9062-z},
doi = {10.1007/s10791-008-9062-z},
abstract = {This paper discusses various issues about the rank equivalence of Lafferty and Zhai between the log-odds ratio and the query likelihood of probabilistic retrieval models. It highlights that Robertson's concerns about this equivalence may arise when multiple probability distributions are assumed to be uniformly distributed, after assuming that the marginal probability logically follows from Kolmogorov's probability axioms. It also clarifies that there are two types of rank equivalence relations between probabilistic models, namely strict and weak rank equivalence. This paper focuses on the strict rank equivalence which requires the event spaces of the participating probabilistic models to be identical. It is possible that two probabilistic models are strict rank equivalent when they use different probability estimation methods. This paper shows that the query likelihood,  p (  q |  d ,  r ), is strict rank equivalent to  p (  q |  d ) of the language model of Ponte and Croft by applying assumptions 1 and 2 of Lafferty and Zhai. In addition, some statistical component language model may be strict rank equivalent to the log-odds ratio, and that some statistical component model using the log-odds ratio may be strict rank equivalent to the query likelihood. Finally, we suggest adding a random variable for the user information need to the probabilistic retrieval models for clarification when these models deal with multiple requests.},
journal = {Inf. Retr.},
month = dec,
pages = {539–561},
numpages = {23},
keywords = {Information retrieval, Event space, Probabilistic models}
}

@article{10.1007/s10791-008-9061-0,
author = {Rokach, Lior and Romano, Roni and Maimon, Oded},
title = {Negation Recognition in Medical Narrative Reports},
year = {2008},
issue_date = {December  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9061-0},
doi = {10.1007/s10791-008-9061-0},
abstract = {Substantial medical data, such as discharge summaries and operative reports are stored in electronic textual form. Databases containing free-text clinical narratives reports often need to be retrieved to find relevant information for clinical and research purposes. The context of negation, a negative finding, is of special importance, since many of the most frequently described findings are such. When searching free-text narratives for patients with a certain medical condition, if negation is not taken into account, many of the documents retrieved will be irrelevant. Hence, negation is a major source of poor precision in medical information retrieval systems. Previous research has shown that negated findings may be difficult to identify if the words implying negations (negation signals) are more than a few words away from them. We present a new pattern learning method for automatic identification of negative context in clinical narratives reports. We compare the new algorithm to previous methods proposed for the same task, and show its advantages: accuracy improvement compared to other machine learning methods, and much faster than manual knowledge engineering techniques with matching accuracy. The new algorithm can be applied also to further context identification and information extraction tasks.},
journal = {Inf. Retr.},
month = dec,
pages = {499–538},
numpages = {40},
keywords = {Part-of-speech tagging, Narrative medical reports, Text classification, Artificial intelligence, Negation}
}

@article{10.1007/s10791-008-9060-1,
author = {Wang, Jun and Robertson, Stephen and Vries, Arjen P. and Reinders, Marcel J.},
title = {Probabilistic Relevance Ranking for Collaborative Filtering},
year = {2008},
issue_date = {December  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9060-1},
doi = {10.1007/s10791-008-9060-1},
abstract = {Collaborative filtering is concerned with making recommendations about items to users. Most formulations of the problem are specifically designed for predicting user ratings, assuming past data of explicit user ratings is available. However, in practice we may only have implicit evidence of user preference; and furthermore, a better view of the task is of generating a top-N list of items that the user is most likely to like. In this regard, we argue that collaborative filtering can be directly cast as a  relevance  ranking problem. We begin with the classic Probability Ranking Principle of information retrieval, proposing a probabilistic item ranking framework. In the framework, we derive two different ranking models, showing that despite their common origin, different factorizations reflect two distinctive ways to approach item ranking. For the model estimations, we limit our discussions to implicit user preference data, and adopt an approximation method introduced in the classic text retrieval model (i.e. the Okapi BM25 formula) to effectively decouple frequency counts and presence/absence counts in the preference data. Furthermore, we extend the basic formula by proposing the Bayesian inference to estimate the probability of relevance (and non-relevance), which largely alleviates the data sparsity problem. Apart from a theoretical contribution, our experiments on real data sets demonstrate that the proposed methods perform significantly better than other strong baselines.},
journal = {Inf. Retr.},
month = dec,
pages = {477–497},
numpages = {21},
keywords = {Relevance ranking, Personalization, Probability Ranking Principle, Collaborative filtering, Recommender systems}
}

@article{10.1007/s10791-008-9064-x,
author = {Murdock, Vanessa},
title = {Ellen Voorhees and Donna Harman (Eds): TREC Experiment and Evaluation in Information Retrieval},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9064-x},
doi = {10.1007/s10791-008-9064-x},
journal = {Inf. Retr.},
month = oct,
pages = {473–475},
numpages = {3}
}

@article{10.1007/s10791-008-9063-y,
author = {White, Bebo},
title = {Amy Langville and Carl Meyer, Google's Page Rank and Beyond: The Science of Search Engine Rankings},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9063-y},
doi = {10.1007/s10791-008-9063-y},
journal = {Inf. Retr.},
month = oct,
pages = {471–472},
numpages = {2}
}

@article{10.1007/s10791-008-9059-7,
author = {Sakai, Tetsuya and Kando, Noriko},
title = {On Information Retrieval Metrics Designed for Evaluation with Incomplete Relevance Assessments},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9059-7},
doi = {10.1007/s10791-008-9059-7},
abstract = {Modern information retrieval (IR) test collections have grown in size, but the available manpower for relevance assessments has more or less remained constant. Hence, how to reliably evaluate and compare IR systems using  incomplete  relevance data, where many documents exist that were never examined by the relevance assessors, is receiving a lot of attention. This article compares the robustness of IR metrics to incomplete relevance assessments, using four different sets of graded-relevance test collections with submitted runs--the TREC 2003 and 2004 robust track data and the NTCIR-6 Japanese and Chinese IR data from the crosslingual task. Following previous work, we artificially reduce the original relevance data to simulate IR evaluation environments with extremely incomplete relevance data. We then investigate the effect of this reduction on  discriminative power , which we define as the proportion of system pairs with a statistically significant difference for a given probability of Type I Error, and on  Kendall's rank correlation , which reflects the overall resemblance of two system rankings according to two different metrics or two different relevance data sets. According to these experiments, Q , nDCG and AP proposed by Sakai are superior to bpref proposed by Buckley and Voorhees and to Rank-Biased Precision proposed by Moffat and Zobel. We also point out some weaknesses of bpref and Rank-Biased Precision by examining their formal definitions.},
journal = {Inf. Retr.},
month = oct,
pages = {447–470},
numpages = {24},
keywords = {Evaluation metrics, Incompleteness, Relevance assessments, Test collections}
}

@article{10.1007/s10791-008-9058-8,
author = {Talvensaari, Tuomas and Pirkola, Ari and J\"{a}rvelin, Kalervo and Juhola, Martti and Laurikkala, Jorma},
title = {Focused Web Crawling in the Acquisition of Comparable Corpora},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9058-8},
doi = {10.1007/s10791-008-9058-8},
abstract = {Cross-Language Information Retrieval (CLIR) resources, such as dictionaries and parallel corpora, are scarce for special domains. Obtaining comparable corpora automatically for such domains could be an answer to this problem. The Web, with its vast volumes of data, offers a natural source for this. We experimented with focused crawling as a means to acquire comparable corpora in the genomics domain. The acquired corpora were used to statistically translate domain-specific words. The same words were also translated using a high-quality, but non-genomics-related parallel corpus, which fared considerably worse. We also evaluated our system with standard information retrieval (IR) experiments, combining statistical translation using the Web corpora with dictionary-based translation. The results showed improvement over pure dictionary-based translation. Therefore, mining the Web for comparable corpora seems promising.},
journal = {Inf. Retr.},
month = oct,
pages = {427–445},
numpages = {19},
keywords = {Focused crawling, Cross-language information retrieval, Comparable corpora}
}

@article{10.1007/s10791-008-9055-y,
author = {Magdy, Walid and Darwish, Kareem},
title = {Effect of OCR Error Correction on Arabic Retrieval},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9055-y},
doi = {10.1007/s10791-008-9055-y},
abstract = {Arabic documents that are available only in print continue to be ubiquitous and they can be scanned and subsequently OCR'ed to ease their retrieval. This paper explores the effect of context-based OCR correction on the effectiveness of retrieving Arabic OCR documents using different index terms. Different OCR correction techniques based on language modeling with different correction abilities were tested on real OCR and synthetic OCR degradation. Results show that the reduction of word error rates needs to pass a certain limit to get a noticeable effect on retrieval. If only moderate error reduction is available, then using short character n-gram for retrieval without error correction is not a bad strategy. Word-based correction in conjunction with language modeling had a statistically significant impact on retrieval even for character 3-grams, which are known to be among the best index terms for OCR degraded Arabic text. Further, using a sufficiently large language model for correction can minimize the need for morphologically sensitive error correction.},
journal = {Inf. Retr.},
month = oct,
pages = {405–425},
numpages = {21},
keywords = {OCR, Error correction, Information retrieval, Language modeling}
}

@article{10.1007/s10791-008-9053-0,
author = {Si, Luo and Yu, Danni and Kihara, Daisuke and Fang, Yi},
title = {Combining Gene Sequence Similarity and Textual Information for Gene Function Annotation in the Literature},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9053-0},
doi = {10.1007/s10791-008-9053-0},
abstract = {Annotation of the functions of genes and proteins is an essential step in genome analysis. Information extraction techniques have been proposed to obtain the function information of genes and proteins in the biomedical literature. However, the performance of most information extraction techniques of function annotation in the biomedical literature is not satisfactory due to the large variability in the expression of concepts in the biomedical literature. This paper proposes a framework to improve the gene function annotation in the literature by considering both the textual information in the literature and the functions of genes with sequences similar to a target gene. The new framework collects multiple types of evidence as: (i) textual information about gene functions by matching keywords of the gene functions; (ii) gene function information from the known functions of genes with sequences similar to a target gene; and (iii) the prior probabilities of gene functions to be associated with an arbitrary gene by mining the known gene functions from curated databases. A supervised learning method is utilized to obtain the weights for combining the three types of evidence to assign appropriate Gene Ontology terms for target genes. Empirical studies on two testbeds demonstrate that the combination of sequence similarity scores, function prior probabilities and textual information improves the accuracy of gene function annotation in the literature. The  F -measure scores obtained with the proposed framework are substantially higher than the scores of the solutions in prior research.},
journal = {Inf. Retr.},
month = oct,
pages = {389–404},
numpages = {16},
keywords = {Biomedical literature mining, Combination of multiple evidence, Gene function annotation}
}

@article{10.1007/s10791-008-9054-z,
author = {Fredriksson, Kimmo and Grabowski, Szymon},
title = {Efficient Algorithms for Pattern Matching with General Gaps, Character Classes, and Transposition Invariance},
year = {2008},
issue_date = {August    2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9054-z},
doi = {10.1007/s10791-008-9054-z},
abstract = {We develop efficient dynamic programming algorithms for pattern matching with general gaps and character classes. We consider patterns of the form  p   0   g (  a   0 ,  b   0 )  p   1   g (  a   1 ,  b   1 )  p    m  1 , where  p    i   Σ, Σ is some finite alphabet, and  g (  a    i  ,  b    i  ) denotes a gap of length  a    i    b    i   between symbols  p    i   and  p    i +1 . The text symbol  t    j   matches  p    i   iff  t    j    p    i  . Moreover, we require that if  p    i   matches  t    j  , then  p    i +1  should match one of the text symbols  $$ t_{j+a_i+1} ldots t_{j+b_i+1}.$$  Either or both of  a    i   and  b    i   can be negative. We also consider transposition invariant matching, i.e., the matching condition becomes  t    j    p    i   +  , for some constant   determined by the algorithms. We give algorithms that have efficient average and worst case running times. The algorithms have important applications in music information retrieval and computational biology. We give experimental results showing that the algorithms work well in practice.},
journal = {Inf. Retr.},
month = aug,
pages = {335–357},
numpages = {23},
keywords = {Transposition invariance, Bounded length gaps, Character classes, Sparse dynamic programming, String matching}
}

@article{10.1007/s10791-008-9052-1,
author = {Crestani, Fabio and Ferragina, Paolo and Sanderson, Mark},
title = {Preface},
year = {2008},
issue_date = {August    2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9052-1},
doi = {10.1007/s10791-008-9052-1},
journal = {Inf. Retr.},
month = aug,
pages = {267–268},
numpages = {2}
}

@article{10.1007/s10791-008-9050-3,
author = {Russo, Lu\'{\i}s M. and Oliveira, Arlindo L.},
title = {A Compressed Self-Index Using a Ziv---Lempel Dictionary},
year = {2008},
issue_date = {August    2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9050-3},
doi = {10.1007/s10791-008-9050-3},
abstract = {A compressed full-text self-index for a text  T , of size  u , is a data structure used to search for patterns  P , of size  m , in  T , that requires reduced space, i.e. space that depends on the empirical entropy (  H    k   or  H   0 ) of  T , and is, furthermore, able to reproduce any substring of  T . In this paper we present a new compressed self-index able to locate the occurrences of  P  in  O ((  m  +  occ )log  u ) time, where  occ  is the number of occurrences. The fundamental improvement over previous LZ78 based indexes is the reduction of the search time dependency on  m  from  O (  m   2 ) to  O (  m ). To achieve this result we point out the main obstacle to linear time algorithms based on LZ78 data compression and expose and explore the nature of a recurrent structure in LZ-indexes, the  $${mathcal{T}}_{78}$$  suffix tree. We show that our method is very competitive in practice by comparing it against other state of the art compressed indexes.},
journal = {Inf. Retr.},
month = aug,
pages = {359–388},
numpages = {30},
keywords = {Compressed index, Pattern matching, Text indexing, Data compression}
}

@article{10.1007/s10791-008-9048-x,
author = {Bast, Holger and Mortensen, Christian W. and Weber, Ingmar},
title = {Output-Sensitive Autocompletion Search},
year = {2008},
issue_date = {August    2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9048-x},
doi = {10.1007/s10791-008-9048-x},
abstract = {We consider the following autocompletion search scenario: imagine a user of a search engine typing a query; then with every keystroke display those completions of the last query word that would lead to the best hits, and also display the best such hits. The following problem is at the core of this feature: for a fixed document collection, given a set  D  of documents, and an alphabetical range  W  of words, compute the set of all word-in-document pairs (  w ,  d ) from the collection such that  w   W  and  d   D . We present a new data structure with the help of which such autocompletion queries can be processed, on the average, in time linear in the input plus output size, independent of the size of the underlying document collection. At the same time, our data structure uses no more space than an inverted index. Actual query processing times on a large test collection correlate almost perfectly with our theoretical bound.},
journal = {Inf. Retr.},
month = aug,
pages = {269–286},
numpages = {18},
keywords = {Output-sensitive, Index data structure, Autocompletion, Prefix search}
}

@article{10.1007/s10791-008-9047-y,
author = {Esuli, Andrea and Fagni, Tiziano and Sebastiani, Fabrizio},
title = {Boosting Multi-Label Hierarchical Text Categorization},
year = {2008},
issue_date = {August    2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9047-y},
doi = {10.1007/s10791-008-9047-y},
abstract = {  Hierarchical Text Categorization  (HTC) is the task of generating (usually by means of supervised learning algorithms) text classifiers that operate on hierarchically structured classification schemes. Notwithstanding the fact that most large-sized classification schemes for text have a hierarchical structure, so far the attention of text classification researchers has mostly focused on algorithms for "flat" classification, i.e. algorithms that operate on non-hierarchical classification schemes. These algorithms, once applied to a hierarchical classification problem, are not capable of taking advantage of the information inherent in the class hierarchy, and may thus be suboptimal, in terms of efficiency and/or effectiveness. In this paper we propose  TreeBoost.MH , a multi-label HTC algorithm consisting of a hierarchical variant of  AdaBoost.MH , a very well-known member of the family of "boosting" learning algorithms.  TreeBoost.MH  embodies several intuitions that had arisen before within HTC: e.g. the intuitions that both feature selection and the selection of negative training examples should be performed "locally", i.e. by paying attention to the topology of the classification scheme. It also embodies the novel intuition that the weight distribution that boosting algorithms update at every boosting round should likewise be updated "locally". All these intuitions are embodied within  TreeBoost.MH  in an elegant and simple way, i.e. by defining  TreeBoost.MH  as a recursive algorithm that uses  AdaBoost.MH  as its base step, and that recurs over the tree structure. We present the results of experimenting  TreeBoost.MH  on three HTC benchmarks, and discuss analytically its computational cost.},
journal = {Inf. Retr.},
month = aug,
pages = {287–313},
numpages = {27},
keywords = {Hierarchical text classification, Boosting}
}

@article{10.1007/s10791-008-9046-z,
author = {Farah, Mohamed and Vanderpooten, Daniel},
title = {An Outranking Approach for Information Retrieval},
year = {2008},
issue_date = {August    2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9046-z},
doi = {10.1007/s10791-008-9046-z},
abstract = {Over the last three decades, research in Information Retrieval (IR) shows performance improvement when many sources of evidence are combined to produce a ranking of documents. Most current approaches assess document relevance by computing a single score which aggregates values of some attributes or criteria. They use analytic aggregation operators which either lead to a loss of valuable information, e.g., the min or lexicographic operators, or allow very bad scores on some criteria to be compensated with good ones, e.g., the weighted sum operator. Moreover, all these approaches do not handle imprecision of criterion scores. In this paper, we propose a multiple criteria framework using a new aggregation mechanism based on decision rules identifying positive and negative reasons for judging whether a document should get a better ranking than another. The resulting procedure also handles imprecision in criteria design. Experimental results are reported showing that the suggested method performs better than standard aggregation operators.},
journal = {Inf. Retr.},
month = aug,
pages = {315–334},
numpages = {20},
keywords = {Information retrieval, Outranking approach, Aggregation, Multiple criteria, Relevance}
}

@article{10.1007/s10791-008-9045-0,
author = {Fuhr, Norbert},
title = {A Probability Ranking Principle for Interactive Information Retrieval},
year = {2008},
issue_date = {June      2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9045-0},
doi = {10.1007/s10791-008-9045-0},
abstract = {The classical Probability Ranking Principle (PRP) forms the theoretical basis for probabilistic Information Retrieval (IR) models, which are dominating IR theory since about 20 years. However, the assumptions underlying the PRP often do not hold, and its view is too narrow for interactive information retrieval (IIR). In this article, a new theoretical framework for interactive retrieval is proposed: The basic idea is that during IIR, a user moves between situations. In each situation, the system presents to the user a list of choices, about which s/he has to decide, and the first positive decision moves the user to a new situation. Each choice is associated with a number of cost and probability parameters. Based on these parameters, an optimum ordering of the choices can the derived--the PRP for IIR. The relationship of this rule to the classical PRP is described, and issues of further research are pointed out.},
journal = {Inf. Retr.},
month = jun,
pages = {251–265},
numpages = {15},
keywords = {Interactive retrieval, Optimum retrieval rule, Probabilistic retrieval}
}

@article{10.1007/s10791-008-9044-1,
author = {Wu, Yi-Fang Brook and Li, Quanzhi},
title = {Document Keyphrases as Subject Metadata: Incorporating Document Key Concepts in Search Results},
year = {2008},
issue_date = {June      2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9044-1},
doi = {10.1007/s10791-008-9044-1},
abstract = {Most search engines display some document metadata, such as title, snippet and URL, in conjunction with the returned hits to aid users in determining documents. However, metadata is usually fragmented pieces of information that, even when combined, does not provide an overview of a returned document. In this paper, we propose a mechanism of enriching metadata of the returned results by incorporating automatically extracted document keyphrases with each returned hit. We hypothesize that keyphrases of a document can better represent the major theme in that document. Therefore, by examining the keyphrases in each returned hit, users can better predict the content of documents and the time spent on downloading and examining the irrelevant documents will be reduced substantially.},
journal = {Inf. Retr.},
month = jun,
pages = {229–249},
numpages = {21},
keywords = {Document keyphrase, Keyphrase extraction, Search interface, Document metadata, Document surrogate}
}

@article{10.1007/s10791-007-9043-7,
author = {Keskustalo, Heikki and J\"{a}rvelin, Kalervo and Pirkola, Ari},
title = {Evaluating the Effectiveness of Relevance Feedback Based on a User Simulation Model: Effects of a User Scenario on Cumulated Gain Value},
year = {2008},
issue_date = {June      2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9043-7},
doi = {10.1007/s10791-007-9043-7},
abstract = {We propose a method for performing evaluation of relevance feedback based on simulating real users. The user simulation applies a model defining the user's relevance threshold to accept individual documents as feedback in a graded relevance environment; user's patience to browse the initial list of retrieved documents; and his/her effort in providing the feedback. We evaluate the result by using cumulated gain-based evaluation together with freezing all documents seen by the user in order to simulate the point of view of a user who is browsing the documents during the retrieval process. We demonstrate the method by performing a simulation in the laboratory setting and present the "branching" curve sets characteristic for the presented evaluation method. Both the average and topic-by-topic results indicate that if the freezing approach is adopted, giving feedback of mixed quality makes sense for various usage scenarios even though the modeled users prefer finding especially the most relevant documents.},
journal = {Inf. Retr.},
month = jun,
pages = {209–228},
numpages = {20},
keywords = {Simulation, Relevance feedback, Evaluation, User modeling}
}

@article{10.1007/s10791-007-9042-8,
author = {B\"{u}ttcher, Stefan and Clarke, Charles L.},
title = {Hybrid Index Maintenance for Contiguous Inverted Lists},
year = {2008},
issue_date = {June      2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9042-8},
doi = {10.1007/s10791-007-9042-8},
abstract = {Index maintenance strategies employed by dynamic text retrieval systems based on inverted files can be divided into two categories: merge-based and in-place update strategies. Within each category, individual update policies can be distinguished based on whether they store their on-disk posting lists in a contiguous or in a discontiguous fashion. Contiguous inverted lists, in general, lead to higher query performance, by minimizing the disk seek overhead at query time, while discontiguous inverted lists lead to higher update performance, requiring less effort during index maintenance operations. In this paper, we focus on retrieval systems with high query load, where the on-disk posting lists have to be stored in a contiguous fashion at all times. We discuss a combination of re-merge and in-place index update, called H  ybrid  I  mmediate  M  erge . The method performs strictly better than the re-merge baseline policy used in our experiments, as it leads to the same query performance, but substantially better update performance. The actual time savings achievable depend on the size of the text collection being indexed; a larger collection results in greater savings. In our experiments, variations of H  ybrid  I  mmediate  M  erge  were able to reduce the total index update overhead by up to 73% compared to the re-merge baseline.},
journal = {Inf. Retr.},
month = jun,
pages = {175–207},
numpages = {33},
keywords = {Text retrieval, Search engines, Index maintenance}
}

@article{10.1007/s10791-008-9057-9,
author = {Chevalier, Max},
title = {Zdravko Markov and Daniel T. Larose, Data Mining the Web: Uncovering Patterns in Web Content, Structure, and Usage},
year = {2008},
issue_date = {April     2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9057-9},
doi = {10.1007/s10791-008-9057-9},
journal = {Inf. Retr.},
month = apr,
pages = {169–174},
numpages = {6}
}

@article{10.1007/s10791-008-9056-x,
author = {Taksa, Isak},
title = {David Taniar: Research and Trends in Data Mining Technologies and Applications},
year = {2008},
issue_date = {April     2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-008-9056-x},
doi = {10.1007/s10791-008-9056-x},
journal = {Inf. Retr.},
month = apr,
pages = {165–167},
numpages = {3}
}

@article{10.1007/s10791-007-9041-9,
author = {Shakery, Azadeh and Zhai, Chengxiang},
title = {Smoothing Document Language Models with Probabilistic Term Count Propagation},
year = {2008},
issue_date = {April     2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9041-9},
doi = {10.1007/s10791-007-9041-9},
abstract = {Smoothing of document language models is critical in language modeling approaches to information retrieval. In this paper, we present a novel way of smoothing document language models based on propagating term counts probabilistically in a graph of documents. A key difference between our approach and previous approaches is that our smoothing algorithm can iteratively propagate counts and achieve smoothing with  remotely  related documents. Evaluation results on several TREC data sets show that the proposed method significantly outperforms the simple collection-based smoothing method. Compared with those other smoothing methods that also exploit local corpus structures, our method is especially effective in improving precision in top-ranked documents through "filling in" missing query terms in relevant documents, which is attractive since most users only pay attention to the top-ranked documents in search engine applications.},
journal = {Inf. Retr.},
month = apr,
pages = {139–164},
numpages = {26},
keywords = {Probabilistic propagation, Term count propagation, Language models, Smoothing}
}

@article{10.1007/s10791-007-9040-x,
author = {Losada, David E. and Azzopardi, Leif},
title = {An Analysis on Document Length Retrieval Trends in Language Modeling Smoothing},
year = {2008},
issue_date = {April     2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9040-x},
doi = {10.1007/s10791-007-9040-x},
abstract = {Document length is widely recognized as an important factor for adjusting retrieval systems. Many models tend to favor the retrieval of either short or long documents and, thus, a length-based correction needs to be applied for avoiding any length bias. In Language Modeling for Information Retrieval, smoothing methods are applied to move probability mass from document terms to unseen words, which is often dependant upon document length. In this article, we perform an in-depth study of this behavior, characterized by the document length retrieval trends, of three popular smoothing methods across a number of factors, and its impact on the length of documents retrieved and retrieval performance. First, we theoretically analyze the Jelinek---Mercer, Dirichlet prior and two-stage smoothing strategies and, then, conduct an empirical analysis. In our analysis we show how Dirichlet prior smoothing caters for document length more appropriately than Jelinek---Mercer smoothing which leads to its superior retrieval performance. In a follow up analysis, we posit that length-based priors can be used to offset any bias in the length retrieval trends stemming from the retrieval formula derived by the smoothing technique. We show that the performance of Jelinek---Mercer smoothing can be significantly improved by using such a prior, which provides a natural and simple alternative to decouple the query and document modeling roles of smoothing. With the analysis of retrieval behavior conducted in this article, it is possible to understand why the Dirichlet Prior smoothing performs better than the Jelinek---Mercer, and why the performance of the Jelinek---Mercer method is improved by including a length-based prior.},
journal = {Inf. Retr.},
month = apr,
pages = {109–138},
numpages = {30},
keywords = {Document length, Smoothing, Language models}
}

@article{10.1007/s10791-007-9039-3,
author = {Deselaers, Thomas and Keysers, Daniel and Ney, Hermann},
title = {Features for Image Retrieval: An Experimental Comparison},
year = {2008},
issue_date = {April     2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9039-3},
doi = {10.1007/s10791-007-9039-3},
abstract = {An experimental comparison of a large number of different image descriptors for content-based image retrieval is presented. Many of the papers describing new techniques and descriptors for content-based image retrieval describe their newly proposed methods as most appropriate without giving an in-depth comparison with all methods that were proposed earlier. In this paper, we first give an overview of a large variety of features for content-based image retrieval and compare them quantitatively on four different tasks: stock photo retrieval, personal photo collection retrieval, building retrieval, and medical image retrieval. For the experiments, five different, publicly available image databases are used and the retrieval performance of the features is analyzed in detail. This allows for a direct comparison of all features considered in this work and furthermore will allow a comparison of newly proposed features to these in the future. Additionally, the correlation of the features is analyzed, which opens the way for a simple and intuitive method to find an initial set of suitable features for a new task. The article concludes with recommendations which features perform well for what type of data. Interestingly, the often used, but very simple, color histogram performs well in the comparison and thus can be recommended as a simple baseline for many applications.},
journal = {Inf. Retr.},
month = apr,
pages = {77–107},
numpages = {31},
keywords = {Image classification, Quantitative comparison, Features, Image retrieval}
}

@article{10.1007/s10791-007-9038-4,
author = {Symeonidis, Panagiotis and Nanopoulos, Alexandros and Papadopoulos, Apostolos N. and Manolopoulos, Yannis},
title = {Nearest-Biclusters Collaborative Filtering Based on Constant and Coherent Values},
year = {2008},
issue_date = {February  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9038-4},
doi = {10.1007/s10791-007-9038-4},
abstract = {Collaborative Filtering (CF) Systems have been studied extensively for more than a decade to confront the "information overload" problem. Nearest-neighbor CF is based either on similarities between users or between items, to form a neighborhood of users or items, respectively. Recent research has tried to combine the two aforementioned approaches to improve effectiveness. Traditional clustering approaches (  k -means or hierarchical clustering) has been also used to speed up the recommendation process. In this paper, we use biclustering to disclose this duality between users and items, by grouping them in both dimensions simultaneously. We propose a novel nearest-biclusters algorithm, which uses a new similarity measure that achieves partial matching of users' preferences. We apply nearest-biclusters in combination with two different types of biclustering algorithms--Bimax and xMotif--for constant and coherent biclustering, respectively. Extensive performance evaluation results in three real-life data sets are provided, which show that the proposed method improves substantially the performance of the CF process.},
journal = {Inf. Retr.},
month = feb,
pages = {51–75},
numpages = {25},
keywords = {Collaborative filtering, Clustering, Nearest neighbor, Biclustering}
}

@article{10.1007/s10791-007-9037-5,
author = {Wan, Xiaojun},
title = {Using Only Cross-Document Relationships for Both Generic and Topic-Focused Multi-Document Summarizations},
year = {2008},
issue_date = {February  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9037-5},
doi = {10.1007/s10791-007-9037-5},
abstract = {In recent years graph-ranking based algorithms have been proposed for single document summarization and generic multi-document summarization. The algorithms make use of the "votings" or "recommendations" between sentences to evaluate the importance of the sentences in the documents. This study aims to differentiate the cross-document and within-document relationships between sentences for generic multi-document summarization and adapt the graph-ranking based algorithm for topic-focused summarization. The contributions of this study are two-fold: (1) For generic multi-document summarization, we apply the graph-based ranking algorithm based on each kind of sentence relationship and explore their relative importance for summarization performance. (2) For topic-focused multi-document summarization, we propose to integrate the relevance of the sentences to the specified topic into the graph-ranking based method. Each individual kind of sentence relationship is also differentiated and investigated in the algorithm. Experimental results on DUC 2002---DUC 2005 data demonstrate the great importance of the cross-document relationships between sentences for both generic and topic-focused multi-document summarizations. Even the approach based only on the cross-document relationships can perform better than or at least as well as the approaches based on both kinds of relationships between sentences.},
journal = {Inf. Retr.},
month = feb,
pages = {25–49},
numpages = {25},
keywords = {Multi-document summarization, Cross-document relationship, Graph-ranking, Topic-focused summarization}
}

@article{10.1007/s10791-007-9036-6,
author = {Si, Luo and Callan, Jamie and Cetintas, Suleyman and Yuan, Hao},
title = {An Effective and Efficient Results Merging Strategy for Multilingual Information Retrieval in Federated Search Environments},
year = {2008},
issue_date = {February  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9036-6},
doi = {10.1007/s10791-007-9036-6},
abstract = {Multilingual information retrieval is generally understood to mean the retrieval of relevant information in multiple target languages in response to a user query in a single source language. In a multilingual federated search environment, different information sources contain documents in different languages. A general search strategy in multilingual federated search environments is to translate the user query to each language of the information sources and run a monolingual search in each information source. It is then necessary to obtain a single ranked document list by merging the individual ranked lists from the information sources that are in different languages. This is known as the results merging problem for multilingual information retrieval. Previous research has shown that the simple approach of normalizing source-specific document scores is not effective. On the other side, a more effective merging method was proposed to download and translate all retrieved documents into the source language and generate the final ranked list by running a monolingual search in the search client. The latter method is more effective but is associated with a large amount of online communication and computation costs. This paper proposes an effective and efficient approach for the results merging task of multilingual ranked lists. Particularly, it downloads only a small number of documents from the individual ranked lists of each user query to calculate comparable document scores by utilizing both the query-based translation method and the document-based translation method. Then, query-specific and source-specific transformation models can be trained for individual ranked lists by using the information of these downloaded documents. These transformation models are used to estimate comparable document scores for all retrieved documents and thus the documents can be sorted into a final ranked list. This merging approach is efficient as only a subset of the retrieved documents are downloaded and translated online. Furthermore, an extensive set of experiments on the Cross-Language Evaluation Forum (CLEF) ( http://www.clef-campaign.org/ ) data has demonstrated the effectiveness of the query-specific and source-specific results merging algorithm against other alternatives. The new research in this paper proposes different variants of the query-specific and source-specific results merging algorithm with different transformation models. This paper also provides thorough experimental results as well as detailed analysis. All of the work substantially extends the preliminary research in (Si and Callan, in: Peters (ed.) Results of the cross-language evaluation forum-CLEF 2005, 2005).},
journal = {Inf. Retr.},
month = feb,
pages = {1–24},
numpages = {24},
keywords = {Multilingual information retrieval, Federated search, Results merging}
}

@article{10.1007/s10791-007-9035-7,
author = {Reforgiato Recupero, Diego},
title = {A New Unsupervised Method for Document Clustering by Using WordNet Lexical and Conceptual Relations},
year = {2007},
issue_date = {December  2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9035-7},
doi = {10.1007/s10791-007-9035-7},
abstract = {Text document clustering provides an effective and intuitive navigation mechanism to organize a large amount of retrieval results by grouping documents in a small number of meaningful classes. Many well-known methods of text clustering make use of a long list of words as vector space which is often unsatisfactory for a couple of reasons: first, it keeps the dimensionality of the data very high, and second, it ignores important relationships between terms like synonyms or antonyms. Our unsupervised method solves both problems by using ANNIE and WordNet lexical categories and WordNet ontology in order to create a well structured document vector space whose low dimensionality allows common clustering algorithms to perform well. For the clustering step we have chosen the bisecting  k -means and the Multipole tree, a modified version of the Antipole tree data structure for, respectively, their accuracy and speed.},
journal = {Inf. Retr.},
month = dec,
pages = {563–579},
numpages = {17},
keywords = {Antipole, Text documents, Clustering, Multipole, Bisecting k-means, WordNet}
}

@article{10.1007/s10791-007-9034-8,
author = {Diaz, Fernando},
title = {Regularizing Query-Based Retrieval Scores},
year = {2007},
issue_date = {December  2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9034-8},
doi = {10.1007/s10791-007-9034-8},
abstract = {We adapt the cluster hypothesis for score-based information retrieval by claiming that closely related documents should have similar scores. Given a retrieval from an arbitrary system, we describe an algorithm which directly optimizes this objective by adjusting retrieval scores so that topically related documents receive similar scores. We refer to this process as score regularization. Because score regularization operates on retrieval scores, regardless of their origin, we can apply the technique to arbitrary initial retrieval rankings. Document rankings derived from regularized scores, when compared to rankings derived from un-regularized scores, consistently and significantly result in improved performance given a variety of baseline retrieval algorithms. We also present several proofs demonstrating that regularization generalizes methods such as pseudo-relevance feedback, document expansion, and cluster-based retrieval. Because of these strong empirical and theoretical results, we argue for the adoption of score regularization as general design principle or post-processing step for information retrieval systems.},
journal = {Inf. Retr.},
month = dec,
pages = {531–562},
numpages = {32},
keywords = {Document expansion, Pseudo-relevance feedback, Cluster hypothesis, Query expansion, Cluster-based retrieval, Regularization}
}

@article{10.1007/s10791-007-9033-9,
author = {Savoy, Jacques},
title = {Searching Strategies for the Bulgarian Language},
year = {2007},
issue_date = {December  2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9033-9},
doi = {10.1007/s10791-007-9033-9},
abstract = {This paper reports on the underlying IR problems encountered when indexing and searching with the Bulgarian language. For this language we propose a general light stemmer and demonstrate that it can be quite effective, producing significantly better MAP (around + 34%) than an approach not applying stemming. We implement the GL2 model derived from the  Divergence from Randomness  paradigm and find its retrieval effectiveness better than other probabilistic, vector-space and language models. The resulting MAP is found to be about 50% better than the classical  tf idf  approach. Moreover, increasing the query size enhances the MAP by around 10% (from T to TD). In order to compare the retrieval effectiveness of our suggested stopword list and the light stemmer developed for the Bulgarian language, we conduct a set of experiments on another stopword list and also a more complex and aggressive stemmer. Results tend to indicate that there is no statistically significant difference between these variants and our suggested approach. This paper evaluates other indexing strategies such as 4-gram indexing and indexing based on the automatic decompounding of compound words. Finally, we analyze certain queries to discover why we obtained poor results, when indexing Bulgarian documents using the suggested word-based approach.},
journal = {Inf. Retr.},
month = dec,
pages = {509–529},
numpages = {21},
keywords = {Cross-language information retrieval, Stemmer, Bulgarian IR, Morphology, Evaluation}
}

@article{10.1007/s10791-007-9032-x,
author = {Buckley, Chris and Dimmick, Darrin and Soboroff, Ian and Voorhees, Ellen},
title = {Bias and the Limits of Pooling for Large Collections},
year = {2007},
issue_date = {December  2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9032-x},
doi = {10.1007/s10791-007-9032-x},
abstract = {Modern retrieval test collections are built through a process called pooling in which only a sample of the entire document set is judged for each topic. The idea behind pooling is to find enough relevant documents such that when unjudged documents are assumed to be nonrelevant the resulting judgment set is sufficiently complete and unbiased. Yet a constant-size pool represents an increasingly small percentage of the document set as document sets grow larger, and at some point the assumption of approximately complete judgments must become invalid. This paper shows that the judgment sets produced by traditional pooling when the pools are too small relative to the total document set size can be biased in that they favor relevant documents that contain topic title words. This phenomenon is wholly dependent on the collection size and does not depend on the number of relevant documents for a given topic. We show that the AQUAINT test collection constructed in the recent TREC 2005 workshop exhibits this biased relevance set; it is likely that the test collections based on the much larger GOV2 document set also exhibit the bias. The paper concludes with suggested modifications to traditional pooling and evaluation methodology that may allow very large reusable test collections to be built.},
journal = {Inf. Retr.},
month = dec,
pages = {491–508},
numpages = {18},
keywords = {Sampling bias, Test collections, Pooling}
}

@article{10.1007/s10791-007-9031-y,
author = {Yan, Rong and Hauptmann, Alexander G.},
title = {A Review of Text and Image Retrieval Approaches for Broadcast News Video},
year = {2007},
issue_date = {October   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4–5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9031-y},
doi = {10.1007/s10791-007-9031-y},
abstract = {The effectiveness of a video retrieval system largely depends on the choice of underlying text and image retrieval components. The unique properties of video collections (e.g., multiple sources, noisy features and temporal relations) suggest we examine the performance of these retrieval methods in such a multimodal environment, and identify the relative importance of the underlying retrieval components. In this paper, we review a variety of text/image retrieval approaches as well as their individual components in the context of broadcast news video. Numerous components of text/image retrieval have been discussed in detail, including retrieval models, text sources, temporal expansion methods, query expansion methods, image features, and similarity measures. For each component, we conduct a series of retrieval experiments on TRECVID video collections to identify their advantages and disadvantages. To provide a more complete coverage of video retrieval, we briefly discuss an emerging approach called concept-based video retrieval, and review strategies for combining multiple retrieval outputs.},
journal = {Inf. Retr.},
month = oct,
pages = {445–484},
numpages = {40},
keywords = {Fusion, Image retrieval, Concept-based retrieval, Video retrieval, Review, Text retrieval}
}

@article{10.1007/s10791-007-9030-z,
author = {Kettunen, Kimmo and Airio, Eija and J\"{a}rvelin, Kalervo},
title = {Restricted Inflectional Form Generation in Management of Morphological Keyword Variation},
year = {2007},
issue_date = {October   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4–5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9030-z},
doi = {10.1007/s10791-007-9030-z},
abstract = {Word form normalization through lemmatization or stemming is a standard procedure in information retrieval because morphological variation needs to be accounted for and several languages are morphologically non-trivial. Lemmatization is effective but often requires expensive resources. Stemming is also effective in most contexts, generally almost as good as lemmatization and typically much less expensive; besides it also has a query expansion effect. However, in both approaches the idea is to turn many inflectional word forms to a single lemma or stem both in the database index and in queries. This means extra effort in creating database indexes. In this paper we take an opposite approach: we leave the database index un-normalized and enrich the queries to cover for surface form variation of keywords. A potential penalty of the approach would be long queries and slow processing. However, we show that it only matters to cover a negligible number of possible surface forms even in morphologically complex languages to arrive at a performance that is almost as good as that delivered by stemming or lemmatization. Moreover, we show that, at least for typical test collections, it only matters to cover nouns and adjectives in queries. Furthermore, we show that our findings are particularly good for short queries that resemble normal searches of web users. Our approach is called FCG (for Frequent Case (form) Generation). It can be relatively easily implemented for Latin/Greek/Cyrillic alphabet languages by examining their (typically very skewed) nominal form statistics in a small text sample and by creating surface form generators for the 3---9 most frequent forms. We demonstrate the potential of our FCG approach for several languages of varying morphological complexity: Swedish, German, Russian, and Finnish in well-known test collections. Applications include in particular Web IR in languages poor in morphological resources.},
journal = {Inf. Retr.},
month = oct,
pages = {415–444},
numpages = {30},
keywords = {Inflected indexes, Best-match IR, Frequent case form generation for keywords, Generative methods in management of keyword variation}
}

@article{10.1007/s10791-007-9029-5,
author = {Lin, Jimmy and Wilbur, W. John},
title = {Syntactic Sentence Compression in the Biomedical Domain: Facilitating Access to Related Articles},
year = {2007},
issue_date = {October   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4–5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9029-5},
doi = {10.1007/s10791-007-9029-5},
abstract = {We explore a syntactic approach to sentence compression in the biomedical domain, grounded in the context of result presentation for related article search in the PubMed search engine. By automatically trimming inessential fragments of article titles, a system can effectively display more results in the same amount of space. Our implemented prototype operates by applying a sequence of syntactic trimming rules over the parse trees of article titles. Two separate studies were conducted using a corpus of manually compressed examples from MEDLINE: an automatic evaluation using B  leu  and a summative evaluation involving human assessors. Experiments show that a syntactic approach to sentence compression is effective in the biomedical domain and that the presentation of compressed article titles supports accurate "interest judgments", decisions by users as to whether an article is worth examining in more detail.},
journal = {Inf. Retr.},
month = oct,
pages = {393–414},
numpages = {22},
keywords = {MEDLINE, PubMed, Extrinsic evaluation, Genomics IR, Sentence compression}
}

@article{10.1007/s10791-007-9028-6,
author = {Zhang, Li and Li, Tao and Liu, Shixia and Pan, Yue},
title = {An Integrated System for Building Enterprise Taxonomies},
year = {2007},
issue_date = {October   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4–5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9028-6},
doi = {10.1007/s10791-007-9028-6},
abstract = {Although considerable research has been conducted in the field of hierarchical text categorization, little has been done on automatically collecting labeled corpus for building hierarchical taxonomies. In this paper, we propose an automatic method of collecting training samples to build hierarchical taxonomies. In our method, the category node is initially defined by some keywords, the web search engine is then used to construct a small set of labeled documents, and a topic tracking algorithm with keyword-based content normalization is applied to enlarge the training corpus on the basis of the seed documents. We also design a method to check the consistency of the collected corpus. The above steps produce a flat category structure which contains all the categories for building the hierarchical taxonomy. Next, linear discriminant projection approach is utilized to construct more meaningful intermediate levels of hierarchies in the generated flat set of categories. Experimental results show that the training corpus is good enough for statistical classification methods.},
journal = {Inf. Retr.},
month = oct,
pages = {365–391},
numpages = {27},
keywords = {Discriminant projection, Taxonomy, Consistency}
}

@article{10.1007/s10791-007-9027-7,
author = {Jiang, Jing and Zhai, Chengxiang},
title = {An Empirical Study of Tokenization Strategies for Biomedical Information Retrieval},
year = {2007},
issue_date = {October   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4–5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9027-7},
doi = {10.1007/s10791-007-9027-7},
abstract = {Due to the great variation of biological names in biomedical text, appropriate tokenization is an important preprocessing step for biomedical information retrieval. Despite its importance, there has been little study on the evaluation of various tokenization strategies for biomedical text. In this work, we conducted a careful, systematic evaluation of a set of tokenization heuristics on all the available TREC biomedical text collections for ad hoc document retrieval, using two representative retrieval methods and a pseudo-relevance feedback method. We also studied the effect of stemming and stop word removal on the retrieval performance. As expected, our experiment results show that tokenization can significantly affect the retrieval accuracy; appropriate tokenization can improve the performance by up to 96%, measured by mean average precision (MAP). In particular, it is shown that different query types require different tokenization heuristics, stemming is effective only for certain queries, and stop word removal in general does not improve the retrieval performance on biomedical text.},
journal = {Inf. Retr.},
month = oct,
pages = {341–363},
numpages = {23},
keywords = {Stop word, Biomedical information retrieval, Tokenization, Stemming}
}

@article{10.1007/s10791-007-9026-8,
author = {Kantor, Paul B.},
title = {Keith van Rijsbergen, The Geometry of Information Retrieval},
year = {2007},
issue_date = {October   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4–5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9026-8},
doi = {10.1007/s10791-007-9026-8},
journal = {Inf. Retr.},
month = oct,
pages = {485–489},
numpages = {5}
}

@article{10.1007/s10791-007-9025-9,
author = {Robertson, Stephen and Zaragoza, Hugo},
title = {On Rank-Based Effectiveness Measures and Optimization},
year = {2007},
issue_date = {June      2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9025-9},
doi = {10.1007/s10791-007-9025-9},
abstract = {Many current retrieval models and scoring functions contain free parameters which need to be set--ideally, optimized. The process of optimization normally involves some training corpus of the usual document-query-relevance judgement type, and some choice of measure that is to be optimized. The paper proposes a way to think about the process of exploring the space of parameter values, and how moving around in this space might be expected to affect different measures. One result, concerning local optima, is demonstrated for a range of rank-based evaluation measures.},
journal = {Inf. Retr.},
month = jun,
pages = {321–339},
numpages = {19},
keywords = {Effectiveness metrics, Ranking functions, Optimization}
}

@article{10.1007/s10791-007-9023-y,
author = {Wu, Shengli and McClean, Sally},
title = {Result Merging Methods in Distributed Information Retrieval with Overlapping Databases},
year = {2007},
issue_date = {June      2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9023-y},
doi = {10.1007/s10791-007-9023-y},
abstract = {In distributed information retrieval systems, document overlaps occur frequently among different component databases. This paper presents an experimental investigation and evaluation of a group of result merging methods including the shadow document method and the multi-evidence method in the environment of overlapping databases. We assume, with the exception of resultant document lists (either with rankings or scores), no extra information about retrieval servers and text databases is available, which is the usual case for many applications on the Internet and the Web.The experimental results show that the shadow document method and the multi-evidence method are the two best methods when overlap is high, while Round-robin is the best for low overlap. The experiments also show that [0,1] linear normalization is a better option than linear regression normalization for result merging in a heterogeneous environment.},
journal = {Inf. Retr.},
month = jun,
pages = {297–319},
numpages = {23},
keywords = {Distributed information retrieval, Overlapping databases, Result merging}
}

@article{10.1007/s10791-006-9021-5,
author = {Tanaka-Ishii, Kumiko and Ishii, Yuichiro},
title = {Multilingual Phrase-Based Concordance Generation in Real-Time},
year = {2007},
issue_date = {June      2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9021-5},
doi = {10.1007/s10791-006-9021-5},
abstract = {We present software that generates phrase-based concordances in real-time based on Internet searching. When a user enters a string of words for which he wants to find concordances, the system sends this string as a query to a search engine and obtains search results for the string. The concordances are extracted by performing statistical analysis on search results and then fed back to the user. Unlike existing tools, this concordance consultation tool is language-independent, so concordances can be obtained even in a language for which there are no well-established analytical methods. Our evaluation has revealed that concordances can be obtained more effectively than by only using a search engine directly.},
journal = {Inf. Retr.},
month = jun,
pages = {275–295},
numpages = {21},
keywords = {Concordance generation, Multilingual text analysis methods, Text mining}
}

@article{10.1007/s10791-006-9019-z,
author = {Metzler, Donald and Bruce Croft, W.},
title = {Linear Feature-Based Models for Information Retrieval},
year = {2007},
issue_date = {June      2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9019-z},
doi = {10.1007/s10791-006-9019-z},
abstract = {There have been a number of linear, feature-based models proposed by the information retrieval community recently. Although each model is presented differently, they all share a common underlying framework. In this paper, we explore and discuss the theoretical issues of this framework, including a novel look at the parameter space. We then detail supervised training algorithms that directly maximize the evaluation metric under consideration, such as mean average precision. We present results that show training models in this way can lead to significantly better test set performance compared to other training methods that do not directly maximize the metric. Finally, we show that linear feature-based models can consistently and significantly outperform current state of the art retrieval models with the correct choice of features.},
journal = {Inf. Retr.},
month = jun,
pages = {257–274},
numpages = {18},
keywords = {Linear models, Direct maximization, Retrieval models, Features}
}

@article{10.1007/s10791-006-9017-1,
author = {Amini, Massih R. and Tombros, Anastasios and Usunier, Nicolas and Lalmas, Mounia},
title = {Learning-Based Summarisation of XML Documents},
year = {2007},
issue_date = {June      2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9017-1},
doi = {10.1007/s10791-006-9017-1},
abstract = {Documents formatted in eXtensible Markup Language (XML) are available in collections of various document types. In this paper, we present an approach for the summarisation of XML documents. The novelty of this approach lies in that it is based on features not only from the content of documents, but also from their logical structure. We follow a machine learning, sentence extraction-based summarisation technique. To find which features are more effective for producing summaries, this approach views sentence extraction as an ordering task. We evaluated our summarisation model using the INEX and SUMMAC datasets. The results demonstrate that the inclusion of features from the logical structure of documents increases the effectiveness of the summariser, and that the learnable system is also effective and well-suited to the task of summarisation in the context of XML documents. Our approach is generic, and is therefore applicable, apart from entire documents, to elements of varying granularity within the XML tree. We view these results as a step towards the intelligent summarisation of XML documents.},
journal = {Inf. Retr.},
month = jun,
pages = {233–255},
numpages = {23},
keywords = {XML documents, Ranking functions, Text summarisation, Machine learning}
}

@article{10.1007/s10791-006-9014-4,
author = {Moffat, Alistair and Webber, William and Zobel, Justin and Baeza-Yates, Ricardo},
title = {A Pipelined Architecture for Distributed Text Query Evaluation},
year = {2007},
issue_date = {June      2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9014-4},
doi = {10.1007/s10791-006-9014-4},
abstract = {Two principal query-evaluation methodologies have been described for cluster-based implementation of distributed information retrieval systems: document partitioning and term partitioning. In a document-partitioned system, each of the processors hosts a subset of the documents in the collection, and executes every query against its local sub-collection. In a term-partitioned system, each of the processors hosts a subset of the inverted lists that make up the index of the collection, and serves them to a central machine as they are required for query evaluation.In this paper we introduce a pipelined query-evaluation methodology, based on a term-partitioned index, in which partially evaluated queries are passed amongst the set of processors that host the query terms. This arrangement retains the disk read benefits of term partitioning, but more effectively shares the computational load. We compare the three methodologies experimentally, and show that term distribution is inefficient and scales poorly. The new pipelined approach offers efficient memory utilization and efficient use of disk accesses, but suffers from problems with load balancing between nodes. Until these problems are resolved, document partitioning remains the preferred method.},
journal = {Inf. Retr.},
month = jun,
pages = {205–231},
numpages = {27},
keywords = {Distributed retrieval, Text searching, Index representations}
}

@article{10.1007/s10791-007-9024-x,
author = {Jung, Jason J.},
title = {Ontological Framework Based on Contextual Mediation for Collaborative Information Retrieval},
year = {2007},
issue_date = {April     2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9024-x},
doi = {10.1007/s10791-007-9024-x},
journal = {Inf. Retr.},
month = apr,
pages = {203},
numpages = {1}
}

@article{10.1007/s10791-007-9022-z,
author = {Crestani, Fabio and Ruthven, Ian},
title = {Introduction to Special Issue on Contextual Information Retrieval Systems},
year = {2007},
issue_date = {April     2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-007-9022-z},
doi = {10.1007/s10791-007-9022-z},
journal = {Inf. Retr.},
month = apr,
pages = {111–113},
numpages = {3}
}

@article{10.1007/s10791-006-9020-6,
author = {Liu, Zhenyu and Chu, Wesley W.},
title = {Knowledge-Based Query Expansion to Support Scenario-Specific Retrieval of Medical Free Text},
year = {2007},
issue_date = {April     2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9020-6},
doi = {10.1007/s10791-006-9020-6},
abstract = {In retrieving medical free text, users are often interested in answers pertinent to certain scenarios that correspond to common tasks performed in medical practice, e.g.,  treatment  or  diagnosis  of a disease. A major challenge in handling such queries is that scenario terms in the query (e.g.,  treatment ) are often too general to match specialized terms in relevant documents (e.g.,  chemotherapy ). In this paper, we propose a knowledge-based query expansion method that exploits the UMLS knowledge source to append the original query with additional terms that are specifically relevant to the query's scenario(s). We compared the proposed method with traditional statistical expansion that expands terms which are statistically correlated but not necessarily scenario specific. Our study on two standard testbeds shows that the knowledge-based method, by providing scenario-specific expansion, yields notable improvements over the statistical method in terms of average precision-recall. On the OHSUMED testbed, for example, the improvement is more than 5% averaging over all scenario-specific queries studied and about 10% for queries that mention certain scenarios, such as  treatment of a disease  and  differential diagnosis of a symptom/disease .},
journal = {Inf. Retr.},
month = apr,
pages = {173–202},
numpages = {30},
keywords = {Knowledge-based systems, Medical information retrieval, Scenario-specific information retrieval, Knowledge-based information retrieval, Query expansion}
}

@article{10.1007/s10791-006-9018-0,
author = {Hernandez, Nathalie and Mothe, Josiane and Chrisment, Claude and Egret, Daniel},
title = {Modeling Context through Domain Ontologies},
year = {2007},
issue_date = {April     2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9018-0},
doi = {10.1007/s10791-006-9018-0},
abstract = {Traditional information retrieval systems aim at satisfying most users for most of their searches, leaving aside the context in which the search takes place. We propose to model two main aspects of context: The themes of the user's information need and the specific data the user is looking for to achieve the task that has motivated his search. Both aspects are modeled by means of ontologies. Documents are semantically indexed according to the context representation and the user accesses information by browsing the ontologies. The model has been applied to a case study that has shown the added value of such a semantic representation of context.},
journal = {Inf. Retr.},
month = apr,
pages = {143–172},
numpages = {30},
keywords = {Task, Ontology, Semantic indexing, Document representation, Browsing interface}
}

@article{10.1007/s10791-006-9016-2,
author = {Campbell, D. R. and Culley, S. J. and Mcmahon, C. A. and Sellini, F.},
title = {An Approach for the Capture of Context-Dependent Document Relationships Extracted from Bayesian Analysis of Users' Interactions with Information},
year = {2007},
issue_date = {April     2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9016-2},
doi = {10.1007/s10791-006-9016-2},
abstract = {A number of technologies exist which enable the unobtrusive capture of computer interface interactions in the background of a user's working environment. The resulting data can be used in a variety of ways to model aspects of search activity and the general use of electronic documents in normal working routines. In this paper we present an approach for using captured data to identify relationships between documents used by an individual or group, representing their value in a given context--that may relate to specific information need or activity. The approach employs the use of a na\"{\i}ve Bayesian classifier to evaluate possible relationships that are derived implicitly from the data. It is intended that the relationships established be stored within an information retrieval (IR) system to aid in the retrieval of related documents where future users arrive at a similar context. In the evaluation of the approach over 70 hours of data from computer users in industrial and academic settings are collected to assess its overall feasibility. The results indicate that the approach provides a useful method for the establishment of identifiable relationships between documents based on the context of their usage, rather than their content.},
journal = {Inf. Retr.},
month = apr,
pages = {115–141},
numpages = {27},
keywords = {Context, Recommender systems, Na\"{\i}ve Bayesian classification, Implicit indicators}
}

@article{10.1007/s10791-006-9013-5,
author = {Jung, Jason J.},
title = {Ontological Framework Based on Contextual Mediation for Collaborative Information Retrieval},
year = {2007},
issue_date = {January   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9013-5},
doi = {10.1007/s10791-006-9013-5},
abstract = {On the heterogeneous web information spaces, users have been suffering from efficiently searching for relevant information. This paper proposes a mediator agent system to estimate the semantics of unknown web spaces by learning the fragments gathered during the users' focused crawling. This process is organized as the following three tasks; (i) gathering semantic information about web spaces from personal agents while focused crawling in unknown spaces, (ii) reorganizing the information by using ontology alignment algorithm, and (iii) providing relevant semantic information to personal agents right before focused crawling. It makes the personal agent possible to recognize the corresponding user's behaviors in semantically heterogeneous spaces and predict his searching contexts. For the experiments, we implemented comparison-shopping system with heterogeneous web spaces. As a result, our proposed method efficiently supported the users, and then, network traffic was also reduced.},
journal = {Inf. Retr.},
month = jan,
pages = {85–109},
numpages = {25},
keywords = {Multi-agent systems, Collaborative information retrieval, Feature manipulation, Focused crawling, Ontology, Mediation}
}

@article{10.1007/s10791-006-9012-6,
author = {Serrano, J. I. and Castillo, M. D.},
title = {Evolutionary Learning of Document Categories},
year = {2007},
issue_date = {January   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9012-6},
doi = {10.1007/s10791-006-9012-6},
abstract = {This paper deals with a supervised learning method devoted to producing categorization models of text documents. The goal of the method is to use a suitable numerical measurement of example similarity to find centroids describing different categories of examples. The centroids are not abstract or statistical models, but rather consist of bits of examples. The centroid-learning method is based on a Genetic Algorithm for Texts (GAT). The categorization system using this genetic algorithm infers a model by applying the genetic algorithm to each set of preclassified documents belonging to a category. The models thus obtained are the category centroids that are used to predict the category of a test document. The experimental results validate the utility of this approach for classifying incoming documents.},
journal = {Inf. Retr.},
month = jan,
pages = {69–83},
numpages = {15},
keywords = {Genetic algorithms, Text categorization, Distance-based methods}
}

@article{10.1007/s10791-006-9004-6,
author = {Zelikovitz, Sarah and Cohen, William W. and Hirsh, Haym},
title = {Extending WHIRL with Background Knowledge for Improved Text Classification},
year = {2007},
issue_date = {January   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9004-6},
doi = {10.1007/s10791-006-9004-6},
abstract = {Intelligent use of the many diverse forms of data available on the Internet requires new tools for managing and manipulating heterogeneous forms of information. This paper uses WHIRL, an extension of relational databases that can manipulate textual data using statistical similarity measures developed by the information retrieval community. We show that although WHIRL is designed for more general similarity-based reasoning tasks, it is competitive with mature systems designed explicitly for inductive classification. In particular, WHIRL is well suited for combining different sources of knowledge in the classification process. We show on a diverse set of tasks that the use of appropriate sets of unlabeled background knowledge often decreases error rates, particularly if the number of examples or the size of the strings in the training set is small. This is especially useful when labeling text is a labor-intensive job and when there is a large amount of information available about a particular problem on the World Wide Web.},
journal = {Inf. Retr.},
month = jan,
pages = {35–67},
numpages = {33},
keywords = {Background knowledge, Information retrieval, Query processing, Semi-supervised learning, Text categorization}
}

@article{10.1007/s10791-006-9001-9,
author = {Brisaboa, Nieves R. and Fari\~{n}a, Antonio and Navarro, Gonzalo and Param\'{a}, Jos\'{e} R.},
title = {Lightweight Natural Language Text Compression},
year = {2007},
issue_date = {January   2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9001-9},
doi = {10.1007/s10791-006-9001-9},
abstract = {Variants of Huffman codes where words are taken as the source symbols are currently the most attractive choices to compress natural language text databases. In particular, Tagged Huffman Code by Moura et al. offers fast direct searching on the compressed text and random access capabilities, in exchange for producing around 11% larger compressed files. This work describes End-Tagged Dense Code and (  s ,  c )-Dense Code, two new semistatic statistical methods for compressing natural language texts. These techniques permit simpler and faster encoding and obtain better compression ratios than Tagged Huffman Code, while maintaining its fast direct search and random access capabilities. We show that Dense Codes improve Tagged Huffman Code compression ratio by about 10%, reaching only 0.6% overhead over the optimal Huffman compression ratio. Being simpler, Dense Codes are generated 45% to 60% faster than Huffman codes. This makes Dense Codes a very attractive alternative to Huffman code variants for various reasons: they are simpler to program, faster to build, of almost optimal size, and as fast and easy to search as the best Huffman variants, which are not so close to the optimal size.},
journal = {Inf. Retr.},
month = jan,
pages = {1–33},
numpages = {33},
keywords = {Searching compressed text, Natural language text compression, Text databases}
}

@article{10.1007/s10791-006-9011-7,
author = {Rukoz, Marta and Manouvrier, Maude and Jomier, Genevi\`{e}ve},
title = {Δ-Distance: A Family of Dissimilarity Metrics between Images Represented by Multi-Level Feature Vectors},
year = {2006},
issue_date = {December  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9011-7},
doi = {10.1007/s10791-006-9011-7},
abstract = {This article presents the -distance, a family of distances between images recursively decomposed into segments and represented by multi-level feature vectors. Such a structure is a quad, a quin or a nona-tree resulting from a fixed and arbitrary image partition or from an image segmentation process. It handles positional information of image features (e.g. color, texture or shape). -distance is the generalized form of dissimilarity measures between multi-level feature vectors. Using different weights on tree nodes and different distances between nodes, distances between trees or visual similarity between images can be computed based on the general definition of . In this article, we present three -based distance families: two families of distances between tree structures, called  $$mathcal{T}$$   -distance (  $$mathcal{T}$$  for  Tree ) and  $$mathcal{S}$$   -distance  (  $$mathcal{S}$$  for  Segment ), and a family of visual distances between images, called (  $$mathcal{V}$$  for  Visual ). The  $$mathcal{V}$$ -distance visually compares two images using their tree representation and the other two distances compare the tree structures resulting from image segmentation. Moreover, we show how existing distances between multi-level feature vectors appear to be particular cases of the -distance},
journal = {Inf. Retr.},
month = dec,
pages = {633–655},
numpages = {23},
keywords = {Image database, Similarity, Content-based image retrieval, Distance between quad/quin or nona-trees, Similarity of image segments}
}

@article{10.1007/s10791-006-9010-8,
author = {Lau, Gloria T. and Law, Kincho H. and Wiederhold, Gio},
title = {A Relatedness Analysis of Government Regulations Using Domain Knowledge and Structural Organization},
year = {2006},
issue_date = {December  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9010-8},
doi = {10.1007/s10791-006-9010-8},
abstract = {The complexity and diversity of government regulations make understanding and retrieval of regulations a non-trivial task. One of the issues is the existence of multiple sources of regulations and interpretive guides with differences in format, terminology and context. This paper describes a comparative analysis scheme developed to help retrieval of related provisions from different regulatory documents. Specifically, the goal is to identify the most strongly related provisions between regulations. The relatedness analysis makes use of not only traditional term match but also a combination of feature matches, and not only content comparison but also structural analysis.Regulations are first compared based on conceptual information as well as domain knowledge through feature matching. Regulations also possess specific organizational structures, such as a tree hierarchy of provisions and heavy referencing between provisions. These structures represent useful information in locating related provisions, and are therefore exploited in the comparison of regulations for completeness. System performance is evaluated by comparing a similarity ranking produced by users with the machine-predicted ranking. Ranking produced by the relatedness analysis system shows a reduction in error compared to that of Latent Semantic Indexing. Various pairs of regulations are compared and the results are analyzed along with observations based on different feature usages. An example of an e-rulemaking scenario is shown to demonstrate capabilities and limitations of the prototype relatedness analysis system.},
journal = {Inf. Retr.},
month = dec,
pages = {657–680},
numpages = {24},
keywords = {E-rulemaking, Structural analysis, Feature matching, Relatedness analysis}
}

@article{10.1007/s10791-006-9009-1,
author = {Ahlgren, Per and Kek\"{a}l\"{a}inen, Jaana},
title = {Swedish Full Text Retrieval: Effectiveness of Different Combinations of Indexing Strategies with Query Terms},
year = {2006},
issue_date = {December  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9009-1},
doi = {10.1007/s10791-006-9009-1},
abstract = {In this paper, which treats Swedish full text retrieval, the problem of morphological variation of query terms in the document database is studied. The Swedish CLEF 2003 test collection was used, and the effects of combination of indexing strategies with query terms on retrieval effectiveness were studied. Four of the seven tested combinations involved indexing strategies that used normalization, a form of conflation. All of these four combinations employed compound splitting, both during indexing and at query phase. SWETWOL, a morphological analyzer for the Swedish language, was used for normalization and compound splitting. A fifth combination used stemming, while a sixth attempted to group related terms by right hand truncation of query terms. The truncation was performed by a search expert. These six combinations were compared to each other and to a baseline combination, where no attempt was made to counteract the problem of morphological variation of query terms in the document database. Both the truncation combination, the four combinations based on normalization and the stemming combination outperformed the baseline. Truncation had the best performance. The main conclusion of the paper is that truncation, normalization and stemming enhanced retrieval effectiveness in comparison to the baseline. Further, normalization and stemming were not far below truncation.},
journal = {Inf. Retr.},
month = dec,
pages = {681–697},
numpages = {17},
keywords = {Truncation, Indexing strategies, Swedish, Morphological analysis, Stemming}
}

@article{10.1007/s10791-006-9008-2,
author = {G\"{o}vert, Norbert and Fuhr, Norbert and Lalmas, Mounia and Kazai, Gabriella},
title = {Evaluating the Effectiveness of Content-Oriented XML Retrieval Methods},
year = {2006},
issue_date = {December  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9008-2},
doi = {10.1007/s10791-006-9008-2},
abstract = {Content-oriented XML retrieval approaches aim at a more focused retrieval strategy: Instead of retrieving whole documents, document components that are exhaustive to the information need while at the same time being as specific as possible should be retrieved. In this article, we show that the evaluation methods developed for standard retrieval must be modified in order to deal with the structure of XML documents. More precisely, the size and overlap of document components must be taken into account. For this purpose, we propose a new effectiveness metric based on the definition of a concept space defined upon the notions of exhaustiveness and specificity of a search result. We compare the results of this new metric by the results obtained with the official metric used in INEX, the evaluation initiative for content-oriented XML retrieval.},
journal = {Inf. Retr.},
month = dec,
pages = {699–722},
numpages = {24},
keywords = {Exhaustiveness and specificity, Metrics, Effectiveness, XML retrieval, Evaluation}
}

@article{10.1007/s10791-006-9006-4,
author = {Cronen-Townsend, Steve and Zhou, Yun and Croft, W. Bruce},
title = {Precision Prediction Based on Ranked List Coherence},
year = {2006},
issue_date = {December  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {6},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9006-4},
doi = {10.1007/s10791-006-9006-4},
abstract = {We introduce a statistical measure of the coherence of a list of documents called the  clarity score . Starting with a document list ranked by the query-likelihood retrieval model, we demonstrate the score's relationship to query ambiguity with respect to the collection. We also show that the clarity score is correlated with the average precision of a query and lay the groundwork for useful predictions by discussing a method of setting decision thresholds automatically. We then show that passage-based clarity scores correlate with average-precision measures of ranked lists of passages, where a passage is judged relevant if it contains correct answer text, which extends the basic method to passage-based systems. Next, we introduce variants of document-based clarity scores to improve the robustness, applicability, and predictive ability of clarity scores. In particular, we introduce the ranked list clarity score that can be computed with only a ranked list of documents, and the weighted clarity score where query terms contribute more than other terms. Finally, we show an approach to predicting queries that perform poorly on query expansion that uses techniques expanding on the ideas presented earlier.},
journal = {Inf. Retr.},
month = dec,
pages = {723–755},
numpages = {33},
keywords = {Performance prediction, Query expansion, Language models}
}

@article{10.1007/s10791-006-9007-3,
author = {Kang, In-Su and Na, Seung-Hoon and Lee, Jong-Hyeok},
title = {Collection-Based Compound Noun Segmentation for Korean Information Retrieval},
year = {2006},
issue_date = {November  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9007-3},
doi = {10.1007/s10791-006-9007-3},
abstract = {Compound noun segmentation is a key first step in language processing for Korean. Thus far, most approaches require some form of human supervision, such as pre-existing dictionaries, segmented compound nouns, or heuristic rules. As a result, they suffer from the unknown word problem, which can be overcome by unsupervised approaches. However, previous unsupervised methods normally do not consider all possible segmentation candidates, and/or rely on character-based segmentation clues such as bi-grams or all-length  n -grams. So, they are prone to falling into a local solution. To overcome the problem, this paper proposes an unsupervised segmentation algorithm that searches the most likely segmentation result from all possible segmentation candidates using a word-based segmentation context. As word-based segmentation clues, a dictionary is automatically generated from a corpus. Experiments using three test collections show that our segmentation algorithm is successfully applied to Korean information retrieval, improving a dictionary-based longest-matching algorithm.},
journal = {Inf. Retr.},
month = nov,
pages = {613–631},
numpages = {19},
keywords = {Compound noun segmentation, Unsupervised method, Korean information retrieval}
}

@article{10.1007/s10791-006-9005-5,
author = {Wei, Xing and Croft, Bruce and Mccallum, Andrew},
title = {Table Extraction for Answer Retrieval},
year = {2006},
issue_date = {November  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9005-5},
doi = {10.1007/s10791-006-9005-5},
abstract = {The ability to find tables and extract information from them is a necessary component of many information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form. Their rich combination of formatting and content presents difficulties for traditional retrieval techniques. This paper describes techniques for extracting tables from text and retrieving answers from the extracted information. We compare machine learning (especially, Conditional Random Fields) and heuristic methods for table extraction. To retrieve answers, our approach creates a cell document, which contains the cell and its metadata (headers, titles) for each table cell, and the retrieval model ranks the cells of the extracted tables using a language-modeling approach. Performance is tested using government statistical Web sites and news articles, and errors are analyzed in order to improve the system.},
journal = {Inf. Retr.},
month = nov,
pages = {589–611},
numpages = {23},
keywords = {Conditional random fields, Table extraction, Information extraction, Question answering}
}

@article{10.1007/s10791-006-9003-7,
author = {Lin, Jimmy and Demner-Fushman, Dina},
title = {Methods for Automatically Evaluating Answers to Complex Questions},
year = {2006},
issue_date = {November  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9003-7},
doi = {10.1007/s10791-006-9003-7},
abstract = {Evaluation is a major driving force in advancing the state of the art in language technologies. In particular, methods for automatically assessing the quality of machine output is the preferred method for measuring progress, provided that these metrics have been validated against human judgments. Following recent developments in the automatic evaluation of machine translation and document summarization, we present a similar approach, implemented in a measure called P  OURPRE , an automatic technique for evaluating answers to complex questions based on  n -gram co-occurrences between machine output and a human-generated answer key. Until now, the only way to assess the correctness of answers to such questions involves manual determination of whether an information "nugget" appears in a system's response. The lack of automatic methods for scoring system output is an impediment to progress in the field, which we address with this work. Experiments with the TREC 2003, TREC 2004, and TREC 2005 QA tracks indicate that rankings produced by our metric correlate highly with official rankings, and that P  OURPRE  outperforms direct application of existing metrics.},
journal = {Inf. Retr.},
month = nov,
pages = {565–587},
numpages = {23},
keywords = {Evaluation, Question answering}
}

@article{10.1007/s10791-006-9002-8,
author = {Wilbur, W. John and Kim, Won and Xie, Natalie},
title = {Spelling Correction in the PubMed Search Engine},
year = {2006},
issue_date = {November  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9002-8},
doi = {10.1007/s10791-006-9002-8},
abstract = {It is known that users of internet search engines often enter queries with misspellings in one or more search terms. Several web search engines make suggestions for correcting misspelled words, but the methods used are proprietary and unpublished to our knowledge. Here we describe the methodology we have developed to perform spelling correction for the PubMed search engine. Our approach is based on the noisy channel model for spelling correction and makes use of statistics harvested from user logs to estimate the probabilities of different types of edits that lead to misspellings. The unique problems encountered in correcting search engine queries are discussed and our solutions are outlined.},
journal = {Inf. Retr.},
month = nov,
pages = {543–564},
numpages = {22},
keywords = {Noisy channel model, Nonword error detection, Edit distance, User query logs, Trie}
}

@article{10.1007/s10791-006-9000-x,
author = {Zhao, Le and Zhang, Min and Ma, Shaoping},
title = {The Nature of Novelty Detection},
year = {2006},
issue_date = {November  2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9000-x},
doi = {10.1007/s10791-006-9000-x},
abstract = {Sentence level novelty detection aims at spotting sentences with novel information from an ordered sentence list. In the task, sentences appearing later in the list with no new meanings are eliminated. For the task of novelty detection, the contributions of this paper are three-fold. First, conceptually, this paper reveals the computational nature of the task currently overlooked by the Novelty community--Novelty as a combination of partial overlap (PO) and complete overlap (CO) relations between sentences. We define partial overlap between two sentences as a sharing of common facts, while complete overlap is when one sentence covers all of the meanings of the other sentence. Second, technically, a novel approach, the selected pool method is provided which follows naturally from the PO-CO computational structure. We provide formal error analysis for selected pool and methods based on this PO-CO framework. We address the question how accurate must the PO judgments be to outperform the baseline pool method. Third, experimentally, results were presented for all the three novelty datasets currently available. Results show that the selected pool is significantly better or no worse than the current methods, an indication that the term overlap criterion for the PO judgments could be adequately accurate.},
journal = {Inf. Retr.},
month = nov,
pages = {521–541},
numpages = {21},
keywords = {TREC, Overlap relations, Meanings, Novelty detection}
}

@article{10.1007/s10791-006-9397-2,
author = {Losada, David E. and Fern\'{a}ndez-Luna, Juan M.},
title = {Introduction to the Special Issue on the 27th European Conference on Information Retrieval Research},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-9397-2},
doi = {10.1007/s10791-006-9397-2},
journal = {Inf. Retr.},
month = sep,
pages = {395–397},
numpages = {3}
}

@article{10.1007/s10791-006-6614-y,
author = {Blanco, Roi and Barreiro, \'{A}lvaro},
title = {TSP and Cluster-Based Solutions to the Reassignment of Document Identifiers},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-6614-y},
doi = {10.1007/s10791-006-6614-y},
abstract = {Recent studies demonstrated that it is possible to reduce  Inverted Files  (IF) sizes by reassigning the document identifiers of the original collection, as this lowers the distance between the positions of documents related to a single term. Variable-bit encoding schemes can exploit the average gap reduction and decrease the total amount of bits per document pointer. This paper presents an efficient solution to the reassignment problem, which consists in reducing the input data dimensionality using a SVD transformation, as well as considering it a  Travelling Salesman Problem  (TSP). We also present some efficient solutions based on clustering. Finally, we combine both the TSP and the clustering strategies for reordering the document identifiers. We present experimental tests and performance results in two text TREC collections, obtaining good compression ratios with low running times, and advance the possibility of obtaining scalable solutions for web collections based on the techniques presented here.},
journal = {Inf. Retr.},
month = sep,
pages = {499–517},
numpages = {19},
keywords = {Compression, Clustering, TSP, SVD, Indexing, Document identifier reassignment}
}

@article{10.1007/s10791-006-6391-7,
author = {Vinay, Vishwa and Cox, Ingemar J. and Milic-Frayling, Natasa and Wood, Ken},
title = {Can Constrained Relevance Feedback and Display Strategies Help Users Retrieve Items on Mobile Devices?},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-6391-7},
doi = {10.1007/s10791-006-6391-7},
abstract = {Searching online information resources using mobile devices is affected by small screens which can display only a fraction of ranked search results. In this paper we investigate whether the search effort can be reduced by means of a simple user feedback: for a screenful of search results the user is encouraged to indicate a single most relevant document. In our approach we exploit the fact that, for small display sizes and limited user actions, we can construct a user decision tree representing all possible outcomes of the user interaction with the system. Examining the trees we can compute an upper limit on relevance feedback performance. In this study we consider three standard feedback algorithms: Rocchio, Robertson/Sparck-Jones (RSJ) and a Bayesian algorithm. We evaluate them in conjunction with two strategies for presenting search results: a document ranking that attempts to maximize information gain from the user's choices and the top-D ranked documents. Experimental results indicate that for RSJ feedback which involves an explicit feature selection policy, the greedy top-D display is more appropriate. For the other two algorithms, the exploratory display that maximizes information gain produces better results. We conducted a user study to compare the performance of the relevance feedback methods with real users and compare the results with the findings from the tree analysis. This comparison between the simulations and real user behaviour indicates that the Bayesian algorithm, coupled with the sampled display, is the most effective.},
journal = {Inf. Retr.},
month = sep,
pages = {435–453},
numpages = {19},
keywords = {Small displays, Relevance feedback, Display strategies}
}

@article{10.1007/s10791-006-6390-8,
author = {Vechtomova, Olga},
title = {Noun Phrases in Interactive Query Expansion and Document Ranking},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-6390-8},
doi = {10.1007/s10791-006-6390-8},
abstract = {The paper presents several techniques for selecting noun phrases for interactive query expansion following pseudo-relevance feedback and a new phrase-based document ranking method. A combined syntactico-statistical method was used for the selection of phrases for query expansion. Several statistical measures of phrase selection were evaluated. Experiments were also conducted studying the effectiveness of noun phrases in document ranking. One of the major problems in phrase-based document retrieval is weighting of overlapping and non-contiguous word sequences in documents. The paper presents a new method of phrase weighting, which addressed this problem, and its evaluation on the TREC dataset.},
journal = {Inf. Retr.},
month = sep,
pages = {399–420},
numpages = {22},
keywords = {Document ranking, Interactive query expansion, Noun phrases}
}

@article{10.1007/s10791-006-6389-1,
author = {Lehtokangas, Raija and Keskustalo, Heikki and J\"{a}rvelin, Kalervo},
title = {Experiments with Dictionary-Based CLIR Using Graded Relevance Assessments: Improving Effectiveness by Pseudo-Relevance Feedback},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-6389-1},
doi = {10.1007/s10791-006-6389-1},
abstract = {Research on cross-language information retrieval (CLIR) has typically been restricted to settings using binary relevance assessments. In this paper, we present evaluation results for dictionary-based CLIR using graded relevance assessments in a best match retrieval environment. A text database containing newspaper articles and a related set of 35 search topics were used in the tests. First, monolingual baseline queries were automatically formed from the topics. Secondly, source language topics (in English, German, and Swedish) were automatically translated into the target language (Finnish), using structured target queries. The effectiveness of the translated queries was compared to that of the monolingual queries. Thirdly, pseudo-relevance feedback was used to expand the original target queries. CLIR performance was evaluated using three relevance thresholds: stringent, regular, and liberal. When regular or liberal threshold was used, a reasonable performance was achieved. Using stringent threshold, equally high performance could not be achieved. On all the relevance thresholds the performance of the translated queries was successfully raised by pseudo-relevance feedback based query expansion. However, the performance of the stringent threshold in relation to the other thresholds could not be raised by this method.},
journal = {Inf. Retr.},
month = sep,
pages = {421–433},
numpages = {13},
keywords = {Relevance feedback, Cross-language information retrieval, Graded relevance assessments}
}

@article{10.1007/s10791-006-6388-2,
author = {Lu, Jie and Callan, Jamie},
title = {Full-Text Federated Search of Text-Based Digital Libraries in Peer-to-Peer Networks},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-6388-2},
doi = {10.1007/s10791-006-6388-2},
abstract = {Peer-to-peer (P2P) networks integrate autonomous computing resources without requiring a central coordinating authority, which makes them a potentially robust and scalable model for providing federated search capability to large-scale networks of text-based digital libraries. However, peer-to-peer networks have so far provided very limited support for full-text federated search with relevance-based document ranking. This paper provides solutions to full-text federated search of text-based digital libraries in hierarchical peer-to-peer networks. Existing approaches to full-text search are adapted and new methods are developed for the problems of resource representation, resource selection, and result merging according to the unique characteristics of hierarchical peer-to-peer networks. Experimental results demonstrate that the proposed approaches offer a better combination of accuracy and efficiency than more common alternatives for federated search of text-based digital libraries in peer-to-peer networks.},
journal = {Inf. Retr.},
month = sep,
pages = {477–498},
numpages = {22},
keywords = {Peer-to-peer networks, Text-based digital libraries, Full-text, Federated search}
}

@article{10.1007/s10791-006-6387-3,
author = {Suomela, Sari and Kek\"{a}l\"{a}inen, Jaana},
title = {User Evaluation of Ontology as Query Construction Tool},
year = {2006},
issue_date = {September 2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-6387-3},
doi = {10.1007/s10791-006-6387-3},
abstract = {This study examines the use of an ontology as a search tool. Sixteen subjects created queries using Concept-based Information Retrieval Interface (CIRI) and a regular baseline IR interface. The simulated work task method was used to make the searching situations realistic. Subjects' search experiences, queries and search results were examined. The numbers of search concepts and keys, as well as their overlap in the queries were investigated. The effectiveness of the CIRI and baseline queries was compared. An Ontology Index (OI) was calculated for all search tasks and the correlation between the OI and the overlap of search concepts and keys in queries was investigated. The number of search keys and concepts was higher in CIRI queries than in baseline interface queries. Also the overlap of search keys was higher among CIRI users than among baseline users. These both findings are due to CIRI's expansion feature. There was no clear correlation between OI and overlap of search concepts and keys. The search results were evaluated with generalised precision and recall, and relevance scores based on individual relevance assessments. The baseline interface queries performed better in all comparisons, but the difference was statistically significant only in relevance scores based on individual relevance assessments.},
journal = {Inf. Retr.},
month = sep,
pages = {455–475},
numpages = {21},
keywords = {Ontologies, Interactive information retrieval, User evaluation}
}

@article{10.1007/s10791-006-8703-3,
author = {Desouza, Kevin C.},
title = {Review of Profiling Machines: Mapping the Personal Information Economy},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-8703-3},
doi = {10.1007/s10791-006-8703-3},
journal = {Inf. Retr.},
month = jun,
pages = {387–389},
numpages = {3}
}

@article{10.1007/s10791-006-8702-4,
author = {Azzam, Saliha and Humphreys, Kevin},
title = {New Directions in Question Answering},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-8702-4},
doi = {10.1007/s10791-006-8702-4},
journal = {Inf. Retr.},
month = jun,
pages = {383–386},
numpages = {4}
}

@article{10.1007/s10791-006-4651-1,
author = {Jin, Rong and Si, Luo and Zhai, Chengxiang},
title = {A Study of Mixture Models for Collaborative Filtering},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-4651-1},
doi = {10.1007/s10791-006-4651-1},
abstract = {Collaborative filtering is a general technique for exploiting the preference patterns of a group of users to predict the utility of items for a particular user. Three different components need to be modeled in a collaborative filtering problem: users, items, and ratings. Previous research on applying probabilistic models to collaborative filtering has shown promising results. However, there is a lack of systematic studies of different ways to model each of the three components and their interactions. In this paper, we conduct a broad and systematic study on different mixture models for collaborative filtering. We discuss general issues related to using a mixture model for collaborative filtering, and propose three properties that a graphical model is expected to satisfy. Using these properties, we thoroughly examine five different mixture models, including Bayesian Clustering (BC), Aspect Model (AM), Flexible Mixture Model (FMM), Joint Mixture Model (JMM), and the Decoupled Model (DM). We compare these models both analytically and experimentally. Experiments over two datasets of movie ratings under different configurations show that in general, whether a model satisfies the proposed properties tends to be correlated with its performance. In particular, the Decoupled Model, which satisfies all the three desired properties, outperforms the other mixture models as well as many other existing approaches for collaborative filtering. Our study shows that graphical models are powerful tools for modeling collaborative filtering, but careful design is necessary to achieve good performance.},
journal = {Inf. Retr.},
month = jun,
pages = {357–382},
numpages = {26},
keywords = {Probabilistic model, Graphical model, Collaborative filtering}
}

@article{10.1007/s10791-006-4536-3,
author = {Nyongesa, H. O. and Maleki-Dizaji, S.},
title = {User Modelling Using Evolutionary Interactive Reinforcement Learning},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-4536-3},
doi = {10.1007/s10791-006-4536-3},
abstract = {As the volume and variety of information sources continues to grow, there is increasing difficulty with respect to obtaining information that accurately matches user information needs. A number of factors affect information retrieval effectiveness (the accuracy of matching user information needs against the retrieved information). First, users often do not present search queries in the form that optimally represents their information need. Second, the measure of a document's relevance is often highly subjective between different users. Third, information sources might contain heterogeneous documents, in multiple formats and the representation of documents is not unified. This paper discusses an approach for improvement of information retrieval effectiveness from document databases. It is proposed that retrieval effectiveness can be improved by applying computational intelligence techniques for modelling information needs, through interactive reinforcement learning. The method combines qualitative (subjective) user relevance feedback with quantitative (algorithmic) measures of the relevance of retrieved documents. An information retrieval is developed whose retrieval effectiveness is evaluated using traditional precision and recall.},
journal = {Inf. Retr.},
month = jun,
pages = {343–355},
numpages = {13},
keywords = {Interactive evolutionary learning, Information relevance, User information needs modelling, Adaptive information retrieval}
}

@article{10.1007/s10791-006-3609-7,
author = {Fragos, Kostas and Maistros, Yannis},
title = {A Goodness of Fit Test Approach in Information Retrieval},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-3609-7},
doi = {10.1007/s10791-006-3609-7},
abstract = {In many probabilistic modeling approaches to Information Retrieval we are interested in estimating how well a document model "fits" the user's information need (query model). On the other hand in statistics, goodness of fit tests are well established techniques for assessing the assumptions about the underlying distribution of a data set. Supposing that the query terms are randomly distributed in the various documents of the collection, we actually want to know whether the occurrences of the query terms are more frequently distributed by chance in a particular document. This can be quantified by the so-called goodness of fit tests. In this paper, we present a new document ranking technique based on Chi-square goodness of fit tests. Given the null hypothesis that there is no association between the query terms  q  and the document  d  irrespective of any chance occurrences, we perform a Chi-square goodness of fit test for assessing this hypothesis and calculate the corresponding Chi-square values. Our retrieval formula is based on ranking the documents in the collection according to these calculated Chi-square values. The method was evaluated over the entire test collection of TREC data, on disks 4 and 5, using the topics of TREC-7 and TREC-8 (50 topics each) conferences. It performs well, outperforming steadily the classical OKAPI term frequency weighting formula but below that of KL-Divergence from language modeling approach. Despite this, we believe that the technique is an important non-parametric way of thinking of retrieval, offering the possibility to try simple alternative retrieval formulas within  goodness-of-fit  statistical tests' framework, modeling the data in various ways estimating or assigning any arbitrary theoretical distribution in terms.},
journal = {Inf. Retr.},
month = jun,
pages = {331–342},
numpages = {12},
keywords = {Information Retrieval, goodness of fit tests}
}

@article{10.1007/s10791-006-1682-6,
author = {Cummins, Ronan and O'Riordan, Colm},
title = {Evolving Local and Global Weighting Schemes in Information Retrieval},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-1682-6},
doi = {10.1007/s10791-006-1682-6},
abstract = {This paper describes a method, using Genetic Programming, to automatically determine term weighting schemes for the vector space model. Based on a set of queries and their human determined relevant documents, weighting schemes are evolved which achieve a high average precision. In Information Retrieval (IR) systems, useful information for term weighting schemes is available from the query, individual documents and the collection as a whole.We evolve term weighting schemes in both local (within-document) and global (collection-wide) domains which interact with each other correctly to achieve a high average precision. These weighting schemes are tested on well-known test collections and are compared to the traditional  tf-idf  weighting scheme and to the BM25 weighting scheme using standard IR performance metrics.Furthermore, we show that the global weighting schemes evolved on small collections also increase average precision on larger TREC data. These global weighting schemes are shown to adhere to Luhn's resolving power as both high and low frequency terms are assigned low weights. However, the local weightings evolved on small collections do not perform as well on large collections. We conclude that in order to evolve improved local (within-document) weighting schemes it is necessary to evolve these on large collections.},
journal = {Inf. Retr.},
month = jun,
pages = {311–330},
numpages = {20},
keywords = {Genetic Programming, Term-Weighting Schemes, Information Retrieval}
}

@article{10.1007/s10791-006-1541-5,
author = {Lind\'{e}n, Krister},
title = {Multilingual Modeling of Cross-Lingual Spelling Variants},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-1541-5},
doi = {10.1007/s10791-006-1541-5},
abstract = {Technical term translations are important for cross-lingual information retrieval. In many languages, new technical terms have a common origin rendered with different spelling of the underlying sounds, also known as cross-lingual spelling variants (CLSV).To find the best CLSV in a text database index, we contribute a formulation of the problem in a probabilistic framework, and implement this with an instance of the general edit distance using weighted finite-state transducers. Some training data is required when estimating the costs for the general edit distance. We demonstrate that after some basic training our new multilingual model is robust and requires little or no adaptation for covering additional languages, as the model takes advantage of language independent transliteration patterns.We train the model with medical terms in seven languages and test it with terms from varied domains in six languages. Two test languages are not in the training data. Against a large text database index, we achieve 64---78 % precision at the point of 100% recall. This is a relative improvement of 22% on the simple edit distance.},
journal = {Inf. Retr.},
month = jun,
pages = {295–310},
numpages = {16},
keywords = {Term translations, Cross-lingual information retrieval, Systematic spelling variants, General edit distance}
}

@article{10.1007/s10791-006-0884-2,
author = {Airio, Eija},
title = {Word Normalization and Decompounding in Mono- and Bilingual IR},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-0884-2},
doi = {10.1007/s10791-006-0884-2},
abstract = {The present research studies the impact of decompounding and two different word normalization methods, stemming and lemmatization, on monolingual and bilingual retrieval. The languages in the monolingual runs are English, Finnish, German and Swedish. The source language of the bilingual runs is English, and the target languages are Finnish, German and Swedish. In the monolingual runs, retrieval in a lemmatized compound index gives almost as good results as retrieval in a decompounded index, but in the bilingual runs differences are found: retrieval in a lemmatized decompounded index performs better than retrieval in a lemmatized compound index. The reason for the poorer performance of indexes without decompounding in bilingual retrieval is the difference between the source language and target languages: phrases are used in English, while compounds are used instead of phrases in Finnish, German and Swedish. No remarkable performance differences could be found between stemming and lemmatization.},
journal = {Inf. Retr.},
month = jun,
pages = {249–271},
numpages = {23},
keywords = {Monolingual information retrieval, stemming, lemmatization, decompounding, bilingual information retrieval}
}

@article{10.1007/s10791-006-0882-4,
author = {Madigan, David and Vardi, Yehuda and Weissman, Ishay},
title = {Extreme Value Theory Applied to Document Retrieval from Large Collections},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-0882-4},
doi = {10.1007/s10791-006-0882-4},
abstract = {We consider text retrieval applications that assign query-specific relevance scores to documents drawn from particular collections. Such applications represent a primary focus of the annual Text Retrieval Conference (TREC), where the participants compare the empirical performance of different approaches.  P   (  K ) , the proportion of the top  K  documents that are relevant, is a popular measure of retrieval effectiveness.Participants in the TREC Very Large Corpus track have observed that when the target is a random sample from a collection,  P   (  K )  is substantially smaller than when the target is the entire collection. Hawking and Robertson (2003) confirmed this finding in a number of experimental settings. Hawking et al. (1999) posed as an open research question the cause of this phenomenon and proposed five possible explanatory hypotheses. In this paper, we present a mathematical analysis that sheds some light on these hypotheses and complements the experimental work of Hawking and Robertson (2003). We will also introduce  C   (  L ) , contamination at  L , the number of irrelevant documents amongst the top  L  relevant documents, and describe its properties.Our analysis shows that while  P   (  K )  typically will increase with collection size, the phenomenon is not universal. That is, the asymptotic behavior of  P   (  K )  and  C   (  L )  depends on the score distributions and relative proportions of relevant and irrelevant documents in the collection.},
journal = {Inf. Retr.},
month = jun,
pages = {273–294},
numpages = {22},
keywords = {very large corpus IR, precision at K, extreme value theory}
}

@article{10.1007/s10791-006-0837-9,
author = {Chang, Youjin and Kim, Minkoo and Raghavan, Vijay V.},
title = {Construction of Query Concepts Based on Feature Clustering of Documents},
year = {2006},
issue_date = {June      2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-0837-9},
doi = {10.1007/s10791-006-0837-9},
abstract = {In Information Retrieval, since it is hard to identify users' information needs, many approaches have been tried to solve this problem by expanding initial queries and reweighting the terms in the expanded queries using users' relevance judgments. Although relevance feedback is most effective when relevance information about retrieved documents is provided by users, it is not always available. Another solution is to use correlated terms for query expansion. The main problem with this approach is how to construct the term-term correlations that can be used effectively to improve retrieval performance. In this study, we try to construct  query concepts  that denote users' information needs from a document space, rather than to reformulate initial queries using the term correlations and/or users' relevance feedback. To form  query concepts , we extract features from each document, and then cluster the features into primitive concepts that are then used to form  query concepts . Experiments are performed on the Associated Press (AP) dataset taken from the TREC collection. The experimental evaluation shows that our proposed framework called QCM (Query Concept Method) outperforms baseline probabilistic retrieval model on TREC retrieval.},
journal = {Inf. Retr.},
month = jun,
pages = {231–248},
numpages = {18},
keywords = {query concepts, query reformulation, concept-based information retrieval}
}

@article{10.1007/s10791-006-7150-5,
author = {Tang, Thanh Tin and Craswell, Nick and Hawking, David and Griffiths, Kathy and Christensen, Helen},
title = {Quality and Relevance of Domain-Specific Search: A Case Study in Mental Health},
year = {2006},
issue_date = {March     2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-7150-5},
doi = {10.1007/s10791-006-7150-5},
abstract = {When searching for health information, results quality can be judged against available scientific evidence: Do search engines return advice consistent with evidence based medicine? We compared the performance of domain-specific health and depression search engines against a general-purpose engine (Google) on both relevance of results and quality of advice. Over 101 queries, to which the term `depression' was added if not already present, Google returned more relevant results than those of the domain-specific engines. However, over the 50 treatment-related queries, Google returned 70 pages recommending for or against a well studied treatment, of which 19 strongly disagreed with the scientific evidence. A domain-specific index of 4 sites selected by domain experts was only wrong in 5 of 50 recommendations. Analysis suggests a tension between relevance and quality. Indexing more pages can give a greater number of relevant results, but selective inclusion can give better quality.},
journal = {Inf. Retr.},
month = mar,
pages = {207–225},
numpages = {19},
keywords = {Mental health, Domain specific search, Depression, Focused crawling}
}

@article{10.1007/s10791-006-7149-y,
author = {Soricut, Radu and Brill, Eric},
title = {Automatic Question Answering Using the Web: Beyond the Factoid},
year = {2006},
issue_date = {March     2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-7149-y},
doi = {10.1007/s10791-006-7149-y},
abstract = {In this paper we describe and evaluate a Question Answering (QA) system that goes beyond answering factoid questions. Our approach to QA assumes no restrictions on the type of questions that are handled, and no assumption that the answers to be provided are factoids. We present an unsupervised approach for collecting question and answer pairs from FAQ pages, which we use to collect a corpus of 1 million question/answer pairs from FAQ pages available on the Web. This corpus is used to train various statistical models employed by our QA system: a statistical chunker used to transform a natural language-posed question into a phrase-based query to be submitted for exact match to an off-the-shelf search engine; an answer/question translation model, used to assess the likelihood that a proposed answer is indeed an answer to the posed question; and an answer language model, used to assess the likelihood that a proposed answer is a well-formed answer. We evaluate our QA system in a modular fashion, by comparing the performance of baseline algorithms against our proposed algorithms for various modules in our QA system. The evaluation shows that our system achieves reasonable performance in terms of answer accuracy for a large variety of complex, non-factoid questions.},
journal = {Inf. Retr.},
month = mar,
pages = {191–206},
numpages = {16}
}

@article{10.1007/s10791-006-7148-z,
author = {Smyth, Barry and Balfe, Evelyn},
title = {Anonymous Personalization in Collaborative Web Search},
year = {2006},
issue_date = {March     2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-7148-z},
doi = {10.1007/s10791-006-7148-z},
abstract = {We present an innovative approach to Web search, called  collaborative search , that seeks to cope with the type of vague queries that are commonplace in Web search. We do this by leveraging the search behaviour of previous searchers to personalize future result-lists according to the implied preferences of a community of like-minded individuals. This technique is implemented in the I-SPY meta-search engine and we present the results of a live-user trial which indicates that I-SPY can offer improved search performance when compared to a benchmark search engine, across a variety of performance metrics. In addition, I-SPY achieves its level of personalization while preserving the anonymity of individual users, and we argue that this offers unique privacy benefits compared to alternative approaches to personalization.},
journal = {Inf. Retr.},
month = mar,
pages = {165–190},
numpages = {26},
keywords = {Social search, Personalization, Web search}
}

@article{10.1007/s10791-006-7147-0,
author = {Plachouras, Vassilis and Cacheda, Fidel and Ounis, Iadh},
title = {A Decision Mechanism for the Selective Combination of Evidence in Topic Distillation},
year = {2006},
issue_date = {March     2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-7147-0},
doi = {10.1007/s10791-006-7147-0},
abstract = {The combination of evidence can increase retrieval effectiveness. In this paper, we investigate the effectiveness of a decision mechanism for the selective combination of evidence for Web Information Retrieval and particularly for topic distillation. We introduce two measures of a query's broadness and use them to select an appropriate combination of evidence for each query. The results from our experiments show that there is a statistically significant association between the output of the decision mechanism and the relative effectiveness of the different combinations of evidence. Moreover, we show that the proposed methodology can be applied in an operational setting, where relevance information is not available, by setting the decision mechanism's thresholds automatically.},
journal = {Inf. Retr.},
month = mar,
pages = {139–163},
numpages = {25},
keywords = {Decision mechanism, Selective combination of evidence, Aggregates, Query scope, Web information retrieval, Topic distillation}
}

@article{10.1007/s10791-006-7146-1,
author = {Broder, A. Z. and Lempel, R. and Maghoul, F. and Pedersen, J.},
title = {Efficient PageRank Approximation via Graph Aggregation},
year = {2006},
issue_date = {March     2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-7146-1},
doi = {10.1007/s10791-006-7146-1},
abstract = {We present a framework for approximating random-walk based probability distributions over Web pages using graph aggregation. The basic idea is to partition the graph into classes of quasi-equivalent vertices, to project the page-based random walk to be approximated onto those classes, and to compute the stationary probability distribution of the resulting class-based random walk. From this distribution we can quickly reconstruct a distribution on pages. In particular, our framework can approximate the well-known PageRank distribution by setting the classes according to the set of pages on each Web host.We experimented on a Web-graph containing over 1.4 billion pages and over 6.6 billion links from a crawl of the Web conducted by AltaVista in September 2003. We were able to produce a ranking that has Spearman rank-order correlation of 0.95 with respect to PageRank. The clock time required by a simplistic implementation of our method was less than half the time required by a highly optimized implementation of PageRank, implying that larger speedup factors are probably possible.},
journal = {Inf. Retr.},
month = mar,
pages = {123–138},
numpages = {16},
keywords = {Citation and link analysis, Web IR}
}

@article{10.1007/s10791-006-7145-2,
author = {Melucci, Massimo and Hawking, David},
title = {Introduction: A Perspective on Web Information Retrieval},
year = {2006},
issue_date = {March     2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-006-7145-2},
doi = {10.1007/s10791-006-7145-2},
journal = {Inf. Retr.},
month = mar,
pages = {119–122},
numpages = {4}
}

@article{10.1007/s10791-005-5724-2,
author = {Soergel, Dagobert},
title = {Information Representation and Retrieval in the Digital Age (ASIST Monograph Series) by Heting Chu, Medford, NJ: Information Today; 2003. 248 p. ISBN 1-57387-172-9},
year = {2006},
issue_date = {January   2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5724-2},
doi = {10.1007/s10791-005-5724-2},
journal = {Inf. Retr.},
month = jan,
pages = {111–112},
numpages = {2}
}

@article{10.1007/s10791-005-5723-3,
author = {Coden, Anni R. and Brown, Eric W.},
title = {Automatic Search from Streaming Data},
year = {2006},
issue_date = {January   2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5723-3},
doi = {10.1007/s10791-005-5723-3},
abstract = {Streaming data poses a variety of new and interesting challenges for information retrieval and text analysis. Unlike static document collections, which are typically analyzed and indexed off-line to support ad-hoc queries, streaming data often must be analyzed on the fly and acted on as the data passes through the analysis system. Speech is one example of streaming data that is a challenge to exploit, yet has significant potential to provide value in a knowledge management system. We are specifically interested in techniques that analyze streaming data and automatically find  collateral information , or information that clarifies, expands, and generally enhances the value of the streaming data. We present a system that analyzes a data stream and automatically finds documents related to the current topic of discussion in the data stream. Experimental results show that the system generates result lists with an average precision at 10 hits of better than 60%. We also present a hit-list re-ranking technique based on named entity analysis and automatic text categorization that can improve the search results by 6%---12%.},
journal = {Inf. Retr.},
month = jan,
pages = {95–109},
numpages = {15},
keywords = {Speech retrieval, Text mining, Information retrieval}
}

@article{10.1007/s10791-005-5722-4,
author = {Mart\'{\i}nez-Santiago, Fernando and Ure\~{n}a-L\'{o}pez, L. Alfonso and Mart\'{\i}n-Valdivia, Maite},
title = {A Merging Strategy Proposal: The 2-Step Retrieval Status Value Method},
year = {2006},
issue_date = {January   2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5722-4},
doi = {10.1007/s10791-005-5722-4},
abstract = {A usual strategy to implement CLIR (Cross-Language Information Retrieval) systems is the so-called query translation approach. The user query is translated for each language present in the multilingual collection in order to compute an independent monolingual information retrieval process per language. Thus, this approach divides documents according to language. In this way, we obtain as many different collections as languages. After searching in these corpora and obtaining a result list per language, we must merge them in order to provide a single list of retrieved articles.In this paper, we propose an approach to obtain a single list of relevant documents for CLIR systems driven by query translation. This approach, which we call 2-step RSV (RSV: Retrieval Status Value), is based on the re-indexing of the retrieval documents according to the query vocabulary, and it performs noticeably better than traditional methods.The proposed method requires query vocabulary alignment: given a word for a given query, we must know the translation or translations to the other languages. Because this is not always possible, we have researched on a mixed model. This mixed model is applied in order to deal with queries with partial word-level alignment. The results prove that even in this scenario, 2-step RSV performs better than traditional merging methods.},
journal = {Inf. Retr.},
month = jan,
pages = {71–93},
numpages = {23},
keywords = {CLIR, Pseudo-relevance feedback, 2-step RSV, Mixed 2-step RSV, Merging strategies}
}

@article{10.1007/s10791-005-5721-5,
author = {Fuhr, Norbert and G\"{o}vert, Norbert},
title = {Retrieval Quality vs. Effectiveness of Specificity-Oriented Search in XML Collections},
year = {2006},
issue_date = {January   2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5721-5},
doi = {10.1007/s10791-005-5721-5},
abstract = {Content-only queries in hierarchically structured documents should retrieve the most specific document nodes which are exhaustive to the information need. For this problem, we investigate two methods of augmentation, which both yield high retrieval quality. As retrieval effectiveness, we consider the ratio of retrieval quality and response time; thus, fast approximations to the 'correct' retrieval result may yield higher effectiveness. We present a classification scheme for algorithms addressing this issue, and adopt known algorithms from standard document retrieval for XML retrieval. As a new strategy, we propose  incremental-interruptible retrieval , which allows for instant presentation of the top ranking documents. We develop a new algorithm implementing this strategy and evaluate the different methods with the INEX collection.},
journal = {Inf. Retr.},
month = jan,
pages = {55–70},
numpages = {16},
keywords = {Efficiency, Content-only search, Ranked retrieval, Incremental algorithm, XML retrieval}
}

@article{10.1007/s10791-005-5720-6,
author = {Korenius, Tuomo and Laurikkala, Jorma and Juhola, Martti and J\"{a}rvelin, Kalervo},
title = {Hierarchical Clustering of a Finnish Newspaper Article Collection with Graded Relevance Assessments},
year = {2006},
issue_date = {January   2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5720-6},
doi = {10.1007/s10791-005-5720-6},
abstract = {Search facilitated with agglomerative hierarchical clustering methods was studied in a collection of Finnish newspaper articles (  N  = 53,893). To allow quick experiments, clustering was applied to a sample (  N  = 5,000) that was reduced with principal components analysis. The dendrograms were heuristically cut to find an optimal partition, whose clusters were compared with each of the 30 queries to retrieve the best-matching cluster. The four-level relevance assessment was collapsed into a binary one by (A) considering all the relevant and (B) only the highly relevant documents relevant, respectively. Single linkage (SL) was the worst method. It created many tiny clusters, and, consequently, searches enabled with it had high precision and low recall. The complete linkage (CL), average linkage (AL), and Ward's methods (WM) returned reasonably-sized clusters typically of 18---32 documents. Their recall (A: 27---52%, B: 50---82%) and precision (A: 83---90%, B: 18---21%) was higher than and comparable to those of the SL clusters, respectively. The AL and WM clustering had 1---8% better effectiveness than nearest neighbor searching (NN), and SL and CL were 1---9% less efficient that NN. However, the differences were statistically insignificant. When evaluated with the liberal assessment A, the results suggest that the AL and WM clustering offer better retrieval ability than NN. Assessment B renders the AL and WM clustering better than NN, when recall is considered more important than precision. The results imply that collections in the highly inflectional and agglutinative languages, such as Finnish, may be clustered as the collections in English, provided that documents are appropriately preprocessed.},
journal = {Inf. Retr.},
month = jan,
pages = {33–53},
numpages = {21},
keywords = {Hierarchical clustering, Graded relevance, Principal components analysis, Finnish language}
}

@article{10.1007/s10791-005-5719-z,
author = {Yang, Hui and Zhang, Minjie},
title = {Two-Stage Statistical Language Models for Text Database Selection},
year = {2006},
issue_date = {January   2006},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {9},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5719-z},
doi = {10.1007/s10791-005-5719-z},
abstract = {As the number and diversity of distributed Web databases on the Internet exponentially increase, it is difficult for user to know which databases are appropriate to search. Given database language models that describe the content of each database, database selection services can provide assistance in locating databases relevant to the information needs of users. In this paper, we propose a database selection approach based on statistical language modeling. The basic idea behind the approach is that, for databases that are categorized into a topic hierarchy, individual language models are estimated at different search stages, and then the databases are ranked by the similarity to the query according to the estimated language model. Two-stage smoothed language models are presented to circumvent inaccuracy due to word sparseness. Experimental results demonstrate that such a language modeling approach is competitive with current state-of-the-art database selection approaches.},
journal = {Inf. Retr.},
month = jan,
pages = {5–31},
numpages = {27},
keywords = {Statistical language modeling, Text database selection, Hierarchical topics, Query expansion, Database language model, Distributed information retrieval}
}

@article{10.1007/s10791-005-0751-6,
author = {Piwowarski, Benjamin and Gallinari, Patrick},
title = {A Bayesian Framework for XML Information Retrieval: Searching and Learning with the INEX Collection},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0751-6},
doi = {10.1007/s10791-005-0751-6},
abstract = {Most recent document standards like XML rely on structured representations. On the other hand, current information retrieval systems have been developed for flat document representations and cannot be easily extended to cope with more complex document types. The design of such systems is still an open problem. We present a new model for structured document retrieval which allows computing scores of document parts. This model is based on Bayesian networks whose conditional probabilities are learnt from a labelled collection of structured documents--which is composed of documents, queries and their associated assessments. Training these models is a complex machine learning task and is not standard. This is the focus of the paper: we propose here to train the structured Bayesian Network model using a cross-entropy training criterion. Results are presented on the INEX corpus of XML documents.},
journal = {Inf. Retr.},
month = dec,
pages = {655–681},
numpages = {27},
keywords = {XML, machine learning for structured retrieval, Bayesian Networks, structured information retrieval}
}

@article{10.1007/s10791-005-0750-7,
author = {Kamps, Jaap and Rijke, Maarten De and Sigurbj\"{o}rnsson, B\"{o}rkur},
title = {The Importance of Length Normalization for XML Retrieval},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0750-7},
doi = {10.1007/s10791-005-0750-7},
abstract = {XML retrieval is a departure from standard document retrieval in which each individual XML element, ranging from italicized words or phrases to full blown articles, is a retrievable unit. The distribution of XML element lengths is unlike what we usually observe in standard document collections, prompting us to revisit the issue of document length normalization. We perform a comparative analysis of arbitrary elements versus relevant elements, and show the importance of element length as a parameter for XML retrieval. Within the language modeling framework, we investigate a range of techniques that deal with length either directly or indirectly. We observe a length-bias introduced by the amount of smoothing, and show the importance of extreme length bias for XML retrieval. We also show that simply removing shorter elements from the index (by introducing a cut-off value) does not create an appropriate element length normalization. Even after restricting the minimal size of XML elements occurring in the index, the importance of an extreme explicit length bias remains.},
journal = {Inf. Retr.},
month = dec,
pages = {631–654},
numpages = {24},
keywords = {smoothing, XML retrieval, length normalization, language models}
}

@article{10.1007/s10791-005-0749-0,
author = {Larson, Ray R.},
title = {A Fusion Approach to XML Structured Document Retrieval},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0749-0},
doi = {10.1007/s10791-005-0749-0},
abstract = {In this paper we evaluate the application of data fusion or meta-search methods, combining different algorithms and XML elements, to content-oriented retrieval of XML structured data. The primary approach is the combination of a probabilistic methods using Logistic regression and the Okapi BM-25 algorithm for estimation of document relevance or XML element relevance, in conjunction with Boolean approaches for some query elements. In the evaluation we use the INEX XML test collection to examine the relative performance of individual algorithms and elements and compare these to the performance of the data fusion approaches.},
journal = {Inf. Retr.},
month = dec,
pages = {601–629},
numpages = {29},
keywords = {data fusion, XML retrieval, probabilistic retrieval, logistic regression}
}

@article{10.1007/s10791-005-0748-1,
author = {Pehcevski, Jovan and Thom, James A. and Vercoustre, Anne-Marie},
title = {Hybrid XML Retrieval: Combining Information Retrieval and a Native XML Database},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0748-1},
doi = {10.1007/s10791-005-0748-1},
abstract = {This paper investigates the impact of three approaches to XML retrieval: using Zettair, a full-text information retrieval system; using eXist, a native XML database; and using a hybrid system that takes full article answers from Zettair and uses eXist to extract elements from those articles. For the content-only topics, we undertake a preliminary analysis of the INEX 2003 relevance assessments in order to identify the types of highly relevant document components. Further analysis identifies two complementary sub-cases of relevance assessments (  General  and  Specific ) and two categories of topics (  Broad  and  Narrow ). We develop a novel retrieval module that for a content-only topic utilises the information from the resulting answer list of a native XML database and dynamically determines the preferable units of retrieval, which we call  Coherent Retrieval Elements.  The results of our experiments show that--when each of the three systems is evaluated against different retrieval scenarios (such as different cases of relevance assessments, different topic categories and different choices of evaluation metrics)--the XML retrieval systems exhibit varying behaviour and the best performance can be reached for different values of the retrieval parameters. In the case of INEX 2003 relevance assessments for the content-only topics, our newly developed hybrid XML retrieval system is substantially more effective than either Zettair or eXist, and yields a robust and a very effective XML retrieval.},
journal = {Inf. Retr.},
month = dec,
pages = {571–600},
numpages = {30},
keywords = {Zettair, eXist, XML information retrieval, XML databases, INEX}
}

@article{10.1007/s10791-005-0747-2,
author = {List, Johan and Mihajlovic, Vojkan and Ram\'{\i}rez, Georgina and Vries, Arjen P. and Hiemstra, Djoerd and Blok, Henk Ernst},
title = {TIJAH: Embracing IR Methods in XML Databases},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0747-2},
doi = {10.1007/s10791-005-0747-2},
abstract = {This paper discusses our participation in INEX (the Initiative for the Evaluation of XML Retrieval) using the TIJAH XML-IR system. TIJAH's system design follows a `standard' layered database architecture, carefully separating the conceptual, logical and physical levels. At the conceptual level, we classify the INEX XPath-based query expressions into three different query patterns. For each pattern, we present its mapping into a query execution strategy. The logical layer exploits  score region algebra  (SRA) as the basis for query processing. We discuss the region operators used to select and manipulate XML document components. The logical algebra expressions are mapped into efficient relational algebra expressions over a physical representation of the XML document collection using the `pre-post numbering scheme'. The paper concludes with an analysis of experiments performed with the INEX test collection.},
journal = {Inf. Retr.},
month = dec,
pages = {547–570},
numpages = {24},
keywords = {structured document retrieval}
}

@article{10.1007/s10791-005-0746-3,
author = {Schenkel, Ralf and Theobald, Anja and Weikum, Gerhard},
title = {Semantic Similarity Search on Semistructured Data with the XXL Search Engine},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0746-3},
doi = {10.1007/s10791-005-0746-3},
abstract = {Query languages for XML such as XPath or XQuery support Boolean retrieval: a query result is a (possibly restructured) subset of XML elements or entire documents that satisfy the search conditions of the query. This search paradigm works for highly schematic XML data collections such as electronic catalogs. However, for searching information in open environments such as the Web or intranets of large corporations, ranked retrieval is more appropriate: a query result is a ranked list of XML elements in descending order of (estimated) relevance. Web search engines, which are based on the ranked retrieval paradigm, do, however, not consider the additional information and rich annotations provided by the structure of XML documents and their element names.This article presents the XXL search engine that supports relevance ranking on XML data. XXL is particularly geared for path queries with wildcards that can span multiple XML collections and contain both exact-match as well as semantic-similarity search conditions. In addition, ontological information and suitable index structures are used to improve the search efficiency and effectiveness. XXL is fully implemented as a suite of Java classes and servlets. Experiments in the context of the INEX benchmark demonstrate the efficiency of the XXL search engine and underline its effectiveness for ranked retrieval.},
journal = {Inf. Retr.},
month = dec,
pages = {521–545},
numpages = {25},
keywords = {semistructured data, XML retrieval, ranked retrieval}
}

@article{10.1007/s10791-005-0745-4,
author = {Fuhr, Norbert and Lalmas, Mounia},
title = {Introduction to the Special Issue on INEX},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-0745-4},
doi = {10.1007/s10791-005-0745-4},
abstract = {This special issue contains articles describing XML retrieval approaches developed and evaluated during the second year of INEX, the evaluation initiative for XML retrieval.},
journal = {Inf. Retr.},
month = dec,
pages = {515–519},
numpages = {5}
}

@article{10.1007/s10791-005-6996-2,
author = {Ivory, Melody Y.},
title = {Mapping Scientific Frontiers: The Quest for Knowledge Visualization by Chaomei Chen. New York: Springer Verlag; 2003, 256 Pps, $79.95 (ISBN: 0-85233-494-0)},
year = {2005},
issue_date = {May 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6996-2},
doi = {10.1007/s10791-005-6996-2},
journal = {Inf. Retr.},
month = may,
pages = {505–507},
numpages = {3}
}

@article{10.1007/s10791-005-6995-3,
author = {Metzler, Donald and Croft, W. Bruce},
title = {Analysis of Statistical Question Classification for Fact-Based Questions},
year = {2005},
issue_date = {May 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6995-3},
doi = {10.1007/s10791-005-6995-3},
abstract = {Question classification systems play an important role in question answering systems and can be used in a wide range of other domains. The goal of question classification is to accurately assign labels to questions based on expected answer type. Most approaches in the past have relied on matching questions against hand-crafted rules. However, rules require laborious effort to create and often suffer from being too specific. Statistical question classification methods overcome these issues by employing machine learning techniques. We empirically show that a statistical approach is robust and achieves good performance on three diverse data sets with little or no hand tuning. Furthermore, we examine the role different syntactic and semantic features have on performance. We find that semantic features tend to increase performance more than purely syntactic features. Finally, we analyze common causes of misclassification error and provide insight into ways they may be overcome.},
journal = {Inf. Retr.},
month = may,
pages = {481–504},
numpages = {24},
keywords = {machine learning, question classification, semantic features, Support Vector Machines, WordNet, syntactic features, question answering}
}

@article{10.1007/s10791-005-6994-4,
author = {Frank Hsu, D. and Taksa, Isak},
title = {Comparing Rank and Score Combination Methods for Data Fusion in Information Retrieval},
year = {2005},
issue_date = {May 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6994-4},
doi = {10.1007/s10791-005-6994-4},
abstract = {Combination of multiple evidences (multiple query formulations, multiple retrieval schemes or systems) has been shown (mostly experimentally) to be effective in data fusion in information retrieval. However, the question of why and how combination should be done still remains largely unanswered. In this paper, we provide a model for simulation and a framework for analysis in the study of data fusion in the information retrieval domain. A  rank/score function  is defined and the concept of a Cayley graph is used in the design and analysis of our framework. The model and framework have led us to better understanding of the data fusion phenomena in information retrieval. In particular, by exploiting the graphical properties of the rank/score function, we have shown analytically and by simulation that combination using rank performs better than combination using score under certain conditions. Moreover, we demonstrated that the rank/score function might be used as a predictive variable for the effectiveness of combination of multiple evidences.},
journal = {Inf. Retr.},
month = may,
pages = {449–480},
numpages = {32},
keywords = {symmetric group, Cayley graphs and digraphs, information retrieval (IR), multiple evidences, data fusion (DF), permutation, evidence combinations, rank combination, rank/score function, score combination}
}

@article{10.1007/s10791-005-6993-5,
author = {Srinivasan, P. and Menczer, F. and Pant, G.},
title = {A General Evaluation Framework for Topical Crawlers},
year = {2005},
issue_date = {May 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6993-5},
doi = {10.1007/s10791-005-6993-5},
abstract = {Topical crawlers are becoming important tools to support applications such as specialized Web portals, online searching, and competitive intelligence. As the Web mining field matures, the disparate crawling strategies proposed in the literature will have to be evaluated and compared on common tasks through well-defined performance measures. This paper presents a general framework to evaluate topical crawlers. We identify a class of tasks that model crawling applications of different nature and difficulty. We then introduce a set of performance measures for fair comparative evaluations of crawlers along several dimensions including generalized notions of precision, recall, and efficiency that are appropriate and practical for the Web. The framework relies on independent relevance judgements compiled by human editors and available from public directories. Two sources of evidence are proposed to assess crawled pages, capturing different relevance criteria. Finally we introduce a set of topic characterizations to analyze the variability in crawling effectiveness across topics. The proposed evaluation framework synthesizes a number of methodologies in the topical crawlers literature and many lessons learned from several studies conducted by our group. The general framework is described in detail and then illustrated in practice by a case study that evaluates four public crawling algorithms. We found that the proposed framework is effective at evaluating, comparing, differentiating and interpreting the performance of the four crawlers. For example, we found the IS crawler to be most sensitive to the popularity of topics.},
journal = {Inf. Retr.},
month = may,
pages = {417–447},
numpages = {31},
keywords = {precision, tasks, efficiency, evaluation, recall, Web crawlers, topics}
}

@article{10.1007/s10791-005-6992-6,
author = {Das, Subrata and Shuster, Kurt and Wu, Curt and Levit, Igor},
title = {Mobile Agents for Distributed and Heterogeneous Information Retrieval},
year = {2005},
issue_date = {May 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6992-6},
doi = {10.1007/s10791-005-6992-6},
abstract = {The heterogeneous, distributed and voluminous nature of many government and corporate data sources impose severe constraints on meeting the diverse requirements of users who analyze the data. Additionally, communication bandwidth limitations, time constraints, and multiple data formats impose further restrictions on users of these distributed data sources. In this paper, we present an Agent-based Complex QUerying and Information Retrieval Engine (ACQUIRE) for large, heterogeneous, and distributed data sources. ACQUIRE acts as a softbot or interface agent by presenting users with a view of a single, unified, homogenous data source, against which users can pose high-level declarative queries. ACQUIRE translates each such user query into a set of sub-queries by employing a combination of planning and traditional database query optimization techniques. ACQUIRE then spawns a set of mobile agents corresponding to these sub-queries, which in turn retrieve the data from various distributed data sources by dynamically optimizing the retrieval strategy as it is carried out. These mobile agents carry with them data-processing code that can be executed at the remote site, thus reducing the size of data returned by the agent. When all mobile agents have returned, ACQUIRE filters and merges the retrieved data and presents the results to the user. While the system is still very much a work in progress, current validation experiments on simulated NASA Distributed Active Archive Centers (DAACs) have demonstrated that complex queries can be effectively decomposed and retrieved by this approach.},
journal = {Inf. Retr.},
month = may,
pages = {383–416},
numpages = {34},
keywords = {mobile agents, query optimization, information retrieval, query planning, heterogeneous and distributed data}
}

@article{10.1007/s10791-005-6991-7,
author = {Trotman, Andrew},
title = {Learning to Rank},
year = {2005},
issue_date = {May 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6991-7},
doi = {10.1007/s10791-005-6991-7},
abstract = {New general purpose ranking functions are discovered using genetic programming. The TREC WSJ collection was chosen as a training set. A baseline comparison function was chosen as the best of inner product, probability, cosine, and Okapi BM25. An elitist genetic algorithm with a population size 100 was run 13 times for 100 generations and the best performing algorithms chosen from these. The best learned functions, when evaluated against the best baseline function (BM25), demonstrate some significant performance differences, with improvements in mean average precision as high as 32% observed on one TREC collection not used in training. In no test is BM25 shown to significantly outperform the best learned function.},
journal = {Inf. Retr.},
month = may,
pages = {359–381},
numpages = {23},
keywords = {document ranking, machine learning, genetic programming, searching}
}

@article{10.1007/s10791-005-6047-z,
author = {Dominich, S\'{a}ndor and Lalmas, Mounia and Rijsbergen, Cornelius Joost (Keith)},
title = {Guest Editorial: Spaces, Logic, and Link Analysis in IR: Recent Advances From A Mathematical and Logical Perspective},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-6047-z},
doi = {10.1007/s10791-005-6047-z},
journal = {Inf. Retr.},
month = apr,
pages = {175–179},
numpages = {5}
}

@article{10.1007/s10791-005-5666-8,
author = {Kogan, Jacob and Teboulle, Marc and Nicholas, Charles},
title = {Data Driven Similarity Measures for K-Means Like Clustering Algorithms},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5666-8},
doi = {10.1007/s10791-005-5666-8},
abstract = {We present an optimization approach that generates  k -means like clustering algorithms. The batch  k -means and the incremental  k -means are two well known versions of the classical  k -means clustering algorithm (Duda et al. 2000). To benefit from the speed of the batch version and the accuracy of the incremental version we combine the two in a "ping--pong" fashion. We use a distance-like function that combines the squared Euclidean distance with relative entropy. In the extreme cases our algorithm recovers the classical  k -means clustering algorithm and generalizes the Divisive Information Theoretic clustering algorithm recently reported independently by Berkhin and Becher (2002) and Dhillon1 et al. (2002). Results of numerical experiments that demonstrate the viability of our approach are reported.},
journal = {Inf. Retr.},
month = apr,
pages = {331–349},
numpages = {19},
keywords = {optimization, entropy, clustering algorithms}
}

@article{10.1007/s10791-005-5665-9,
author = {Robertson, Stephen},
title = {On Event Spaces and Probabilistic Models in Information Retrieval},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5665-9},
doi = {10.1007/s10791-005-5665-9},
abstract = {A basic notion of probability theory is the event space, on which the probability measure is defined. A probabilistic model needs an event space. However, some classes of events (which we may want to model probabilistically) exhibit structure which does not fit well into the traditional event space notion. A simple one-to-many example is discussed at length. The information retrieval case, involving queries, documents and relevance, is analysed. The event space issue makes for some difficulty in comparing different probabilistic models in IR.},
journal = {Inf. Retr.},
month = apr,
pages = {319–329},
numpages = {11},
keywords = {information retrieval, event space, probabilistic models}
}

@article{10.1007/s10791-005-5664-x,
author = {Bordogna, Gloria and Pasi, Gabriella},
title = {Personalised Indexing and Retrieval of Heterogeneous Structured Documents},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5664-x},
doi = {10.1007/s10791-005-5664-x},
abstract = {In this paper the problem of indexing heterogeneous structured documents and of retrieving semi-structured documents is considered. We propose a flexible paradigm for both indexing such documents and formulating user queries specifying soft constraints on both documents' structure and content. At the indexing level we propose a model that achieves flexibility by constructing personalised document representations based on users' views of the documents. This is obtained by allowing users to specify their preferences on the documents' sections that they estimate to bear the most interesting information, as well as to linguistically quantify the number of sections which determine the global potential interest of the documents. At the query language level, a flexible query language for expressing soft selection conditions on both the documents' structure and content is proposed.},
journal = {Inf. Retr.},
month = apr,
pages = {301–318},
numpages = {18},
keywords = {heterogeneous structured documents, Ordered Weighted Averaging Operators, content-based and structure-based querying}
}

@article{10.1007/s10791-005-5663-y,
author = {Cheung, Karen S. and Vogel, Douglas},
title = {Complexity Reduction in Lattice-Based Information Retrieval},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5663-y},
doi = {10.1007/s10791-005-5663-y},
abstract = {Though lattice-based information representation has the advantage of providing efficient visual interface over textual display, the complexity of a lattice may grow rapidly with the size of the database. In this paper we formally draw the analogy between Vector Space Model and Concept Lattice, from which we introduce the notion of Term-Document Lattice as a model for information retrieval. We then propose to use the idea of quotient lattice to reduce the complexity of a Term-Document Lattice. The equivalence relation required to construct the quotient lattice is obtained by performing a Singular Value Decomposition on the original term-document matrix.},
journal = {Inf. Retr.},
month = apr,
pages = {285–299},
numpages = {15},
keywords = {lattice theory, information retrieval, concept lattice}
}

@article{10.1007/s10791-005-5662-z,
author = {G\'{o}th, J\'{u}lia and Skrop, Adrienn},
title = {Varying Retrieval Categoricity Using Hyperbolic Geometry},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5662-z},
doi = {10.1007/s10791-005-5662-z},
abstract = {The paper proposes a Vector Space Model over the Cayley-Klein Hyperbolic Geometry (referred to as Hyperbolic Information Retrieval = HIR) using a similarity measure derived from the hyperbolic distance. It is shown that the proposed model is equivalent with the classical Vector Space Model using Cosine measure with normalized weighting scheme. It is also shown that the categoricity of the new retrieval system can be varied by only modifying the radius of the hyperbolic space and without using a different weighting scheme and similarity measure, which is not the case in the VSM, where the same effect can only be obtained by both changing the weighting scheme and similarity measure at the expense of a more costly computation. Experiments are also reported to demonstrate and support the ideas, and they show that categoricity in HIR can be varied more than  O (  n ) faster, where  n  is the number of index terms, than in the VSM.},
journal = {Inf. Retr.},
month = apr,
pages = {265–283},
numpages = {19},
keywords = {similarity measures, ranking order preservation, hyperbolic geometry, information search and retrieval, Euclidean geometry, Cayley-Klein model}
}

@article{10.1007/s10791-005-5661-0,
author = {Lempel, R. and Moran, S.},
title = {Rank-Stability and Rank-Similarity of Link-Based Web Ranking Algorithms in Authority-Connected Graphs},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5661-0},
doi = {10.1007/s10791-005-5661-0},
abstract = {Web search algorithms that rank Web pages by examining the link structure of the Web are attractive from both theoretical and practical aspects. Today's prevailing link-based ranking algorithms rank Web pages by using the dominant eigenvector of certain matrices--like the co-citation matrix or variations thereof. Recent analyses of ranking algorithms have focused attention on the case where the corresponding matrices are irreducible, thus avoiding singularities of reducible matrices. Consequently, rank analysis has been concentrated on  authority connected  graphs, which are graphs whose co-citation matrix is irreducible (after deleting zero rows and columns). Such graphs conceptually correspond to thematically related collections, in which most pages pertain to a single, dominant topic of interest.A link-based search algorithm  A  is  rank-stable  if minor changes in the link structure of the input graph, which is usually a subgraph of the Web, do not affect the ranking it produces; algorithms  A ,  B  are  rank-similar  if they produce similar rankings. These concepts were introduced and studied recently for various existing search algorithms.This paper studies the rank-stability and rank-similarity of three link-based ranking algorithms--PageRank, HITS and SALSA--in authority connected graphs. For this class of graphs, we show that neither HITS nor PageRank is rank stable. We then show that HITS and PageRank are not rank similar on this class, nor is any of them rank similar to SALSA.},
journal = {Inf. Retr.},
month = apr,
pages = {245–264},
numpages = {20},
keywords = {link analysis, Web IR, citation}
}

@article{10.1007/s10791-005-5660-1,
author = {Agosti, Maristella and Pretto, Luca},
title = {A Theoretical Study of a Generalized Version of Kleinberg's HITS Algorithm},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5660-1},
doi = {10.1007/s10791-005-5660-1},
abstract = {Kleinberg's HITS algorithm (Kleinberg 1999), which was originally developed in a Web context, tries to infer the authoritativeness of a Web page in relation to a specific query using the structure of a subgraph of the Web graph, which is obtained considering this specific query. Recent applications of this algorithm in contexts far removed from that of Web searching (Bacchin, Ferro and Melucci 2002, Ng et al. 2001) inspired us to study the algorithm in the abstract, independently of its particular applications, trying to mathematically illuminate its behaviour. In the present paper we detail this theoretical analysis. The original work starts from the definition of a revised and more general version of the algorithm, which includes the classic one as a particular case. We perform an analysis of the structure of two particular matrices, essential to studying the behaviour of the algorithm, and we prove the convergence of the algorithm in the most general case, finding the analytic expression of the vectors to which it converges. Then we study the symmetry of the algorithm and prove the equivalence between the existence of symmetry and the independence from the order of execution of some basic operations on initial vectors. Finally, we expound some interesting consequences of our theoretical results.},
journal = {Inf. Retr.},
month = apr,
pages = {219–243},
numpages = {25},
keywords = {ranking, World Wide Web retrieval, link analysis, Kleinberg's HITS algorithm}
}

@article{10.1007/s10791-005-5659-7,
author = {Plachouras, Vassilis and Ounis, Iadh},
title = {Dempster-Shafer Theory for a Query-Biased Combination of Evidence on the Web},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5659-7},
doi = {10.1007/s10791-005-5659-7},
abstract = {This paper reports on a large-scale experiment for the evaluation of a formal query-biased combination of evidence mechanism. We use the Dempster-Shafer theory of evidence to combine optimally results obtained by content and link analyses on the Web. The query-biased mechanism is based on the query scope, a measure of the query specificity. The query scope is defined using a probabilistic propagation mechanism on top of the hierarchical structure of concepts provided by WordNet. We use two standard Web test collections and two different link analysis approaches. The results show that the proposed approach could improve the retrieval effectiveness.},
journal = {Inf. Retr.},
month = apr,
pages = {197–218},
numpages = {22},
keywords = {Dempster-Shafer theory of evidence, query-biased combination of evidence, query scope, combination of content and link analysis, Web information retrieval}
}

@article{10.1007/s10791-005-5658-8,
author = {Brants, Thorsten},
title = {Test Data Likelihood for PLSA Models},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-005-5658-8},
doi = {10.1007/s10791-005-5658-8},
abstract = {Probabilistic Latent Semantic Analysis (PLSA) is a statistical latent class model that has recently received considerable attention. In its usual formulation it cannot assign likelihoods to unseen documents. Furthermore, it assigns a probability of zero to unseen documents during training. We point out that one of the two existing alternative formulations of the Expectation-Maximization algorithms for PLSA does not require this assumption. However, even that formulation does not allow calculation ofthe actual likelihood values. We therefore derive a new test-data likelihood substitute for PLSA and compare it to three existing likelihood substitutes. An empirical evaluation shows that our new likelihood substitute produces the best predictions about accuracies in two different IR tasks and is therefore best suited to determine the number of EM steps when training PLSA models. The new likelihood measure and its evaluation also suggest that PLSA is not very sensitive to overfitting for the two tasks considered. This renders additions like tempered EM that especially address overfitting unnecessary.},
journal = {Inf. Retr.},
month = apr,
pages = {181–196},
numpages = {16},
keywords = {likelihood, PLSA, Probabilistic Latent Semantic Analysis}
}

@article{10.1023/B:INRT.0000048496.31867.62,
author = {Xu, Yunjie and Benaroch, Michel},
title = {Information Retrieval with a Hybrid Automatic Query Expansion and Data Fusion Procedure},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048496.31867.62},
doi = {10.1023/B:INRT.0000048496.31867.62},
abstract = {We propose a hybrid information retrieval (IR) procedure that builds on two well-known IR approaches: data fusion and query expansion via relevance feedback. This IR procedure is designed to exploit the strengths of data fusion and relevance feedback and to avoid some weaknesses of these approaches. We show that our IR procedure is built on postulates that can be justified analytically and empirically. Additionally, we offer an empirical investigation of the procedure, showing that it is superior to relevance feedback on some dimensions and comparable on other dimensions. The empirical investigation also verifies the conditions under which the use of our IR procedure could be beneficial.},
journal = {Inf. Retr.},
month = jan,
pages = {41–65},
numpages = {25},
keywords = {relevance-feedback, data fusion, multiple queries}
}

@article{10.1023/B:INRT.0000048495.64628.ea,
author = {Geffet, Maayan and Wiseman, Yair and Feitelson, Dror},
title = {Automatic Alphabet Recognition},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048495.64628.ea},
doi = {10.1023/B:INRT.0000048495.64628.ea},
abstract = {The last step of the Information Retrieval process is to display the found documents to the user. However, some difficulties might occur at that point. English texts are usually written in the ASCII standard. Unlike the English language, many languages have different character sets, and do not have one standard. This plurality of standards causes problems, especially in a web environment, where one may download a document with an unknown standard. This paper suggests a purely automatic way of finding the standard which was used by the document writer based on the statistical letters distribution in the language. We developed a vector-space-based method that creates frequencies vectors for each letter of the language and then matches a new document's vectors to the pre-computed templates. The algorithm was applied on various types of corpora in Hebrew, Russian and English, and provides an efficient solution to the stated problem in most cases.},
journal = {Inf. Retr.},
month = jan,
pages = {25–40},
numpages = {16},
keywords = {letters' mapping, characters set, natural language alphabet}
}

@article{10.1023/B:INRT.0000048494.05013.6a,
author = {Spinellis, Diomidis},
title = {Index-Based Persistent Document Identifiers},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048494.05013.6a},
doi = {10.1023/B:INRT.0000048494.05013.6a},
abstract = {The infrastructure of a typical search engine can be used to calculate and resolve persistent document identifiers: a string that can uniquely identify and locate a document on the Internet without reference to its original location (URL). Bookmarking a document using such an identifier allows its retrieval even if the document's URL, and, in many cases, its contents change. Web client applications can offer facilities for users to bookmark a page by reference to a search engine and the persistent identifier instead of the original URL. The identifiers are calculated using a global Internet term index; a document's unique identifier consists of a word or word combination that occurs uniquely in the specific document. We use a genetic algorithm to locate a minimal unique document identifier: the shortest word or word combination that will locate the document. We tested our approach by implementing tools for indexing a document collection, calculating the persistent identifiers, performing queries, and distributing the computation and storage load among many computers.},
journal = {Inf. Retr.},
month = jan,
pages = {5–24},
numpages = {20},
keywords = {search engine, distributed approach, index, persistency, URL}
}

@article{10.1023/B:INRT.0000048493.67375.93,
author = {Liggett, Walter and Buckley, Chris},
title = {System Performance and Natural Language Expression of Information Needs},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048493.67375.93},
doi = {10.1023/B:INRT.0000048493.67375.93},
abstract = {Consider information retrieval systems that respond to a query (a natural language statement of a topic, an information need) with an ordered list of 1000 documents from the document collection. From the responses to queries that all express the same topic, one can discern how the words associated with a topic result in particular system behavior. From what is discerned from different topics, one can hypothesize abstract topic factors that influence system performance. An example of such a factor is the specificity of the topic's primary key word. This paper shows that statements about the effect of abstract topic factors on system performance can be supported empirically. A combination of statistical methods is applied to system responses from NIST's Text REtrieval Conference. We analyze each topic using a measure of irrelevant-document exclusion computed for each response and a measure of dissimilarity between relevant-document return orders computed for each pair of responses. We formulate topic factors through graphical comparison of measurements for different topics. Finally, we propose for each topic a four-dimensional summarization that we use to select topic comparisons likely to depict topic factors clearly.},
journal = {Inf. Retr.},
month = jan,
pages = {101–128},
numpages = {28},
keywords = {query expansion, term weighting, research method, performance indicators, multidimensional scaling}
}

@article{10.1023/B:INRT.0000048492.50961.a6,
author = {Lemire, Daniel},
title = {Scale and Translation Invariant Collaborative Filtering Systems},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048492.50961.a6},
doi = {10.1023/B:INRT.0000048492.50961.a6},
abstract = {Collaborative filtering systems are prediction algorithms over sparse data sets of user preferences. We modify a wide range of state-of-the-art collaborative filtering systems to make them scale and translation invariant and generally improve their accuracy without increasing their computational cost. Using the EachMovie and the Jester data sets, we show that learning-free constant time scale and translation invariant schemes outperforms other learning-free constant time schemes by at least 3% and perform as well as expensive memory-based schemes (within 4%). Over the Jester data set, we show that a scale and translation invariant Eigentaste algorithm outperforms Eigentaste 2.0 by 20%. These results suggest that scale and translation invariance is a desirable property.},
journal = {Inf. Retr.},
month = jan,
pages = {129–150},
numpages = {22},
keywords = {recommender system, regression, e-commerce, incomplete vectors, energy minimization}
}

@article{10.1023/B:INRT.0000048491.59134.94,
author = {Bennett, Paul N. and Dumais, Susan T. and Horvitz, Eric},
title = {The Combination of Text Classifiers Using Reliability Indicators},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048491.59134.94},
doi = {10.1023/B:INRT.0000048491.59134.94},
abstract = {The intuition that different text classifiers behave in qualitatively different ways has long motivated attempts to build a better metaclassifier via some combination of classifiers. We introduce a probabilistic method for combining classifiers that considers the context-sensitive reliabilities of contributing classifiers. The method harnesses reliability indicators—variables that provide signals about the performance of classifiers in different situations. We provide background, present procedures for building metaclassifiers that take into consideration both reliability indicators and classifier outputs, and review a set of comparative studies undertaken to evaluate the methodology.},
journal = {Inf. Retr.},
month = jan,
pages = {67–100},
numpages = {34},
keywords = {text classification, classifier combination, reliability indicators, feature selection, metaclassifiers}
}

@article{10.1023/B:INRT.0000048490.99518.5c,
author = {Anh, Vo Ngoc and Moffat, Alistair},
title = {Inverted Index Compression Using Word-Aligned Binary Codes},
year = {2005},
issue_date = {January 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000048490.99518.5c},
doi = {10.1023/B:INRT.0000048490.99518.5c},
abstract = {We examine index representation techniques for document-based inverted files, and present a mechanism for compressing them using word-aligned binary codes. The new approach allows extremely fast decoding of inverted lists during query processing, while providing compression rates better than other high-throughput representations. Results are given for several large text collections in support of these claims, both for compression effectiveness and query efficiency.},
journal = {Inf. Retr.},
month = jan,
pages = {151–166},
numpages = {16},
keywords = {index representation, integer coding, index compression}
}

@article{10.1023/B:INRT.0000011242.39361.cb,
author = {Sebastiani, Fabrizio},
title = {Introduction: Special Issue on the 25th European Conference on Information Retrieval Research},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011242.39361.cb},
doi = {10.1023/B:INRT.0000011242.39361.cb},
journal = {Inf. Retr.},
month = sep,
pages = {235–237},
numpages = {3}
}

@article{10.1023/B:INRT.0000011212.66249.b7,
author = {Cheung, Kwok-Wai and Tian, Lily F.},
title = {Learning User Similarity and Rating Style for Collaborative Recommendation},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011212.66249.b7},
doi = {10.1023/B:INRT.0000011212.66249.b7},
abstract = {Information filtering is an area getting more important as we have long been flooded with too much information, where product brokering in e-commerce is a typical example. Systems which can provide personalized product recommendations to their users (often called recommender systems) have gained a lot of interest in recent years. Collaborative filtering is one of the commonly used approaches which normally requires a definition of user similarity measure. In the literature, researchers have proposed different choices for the similarity measure using different approaches, and yet there is no guarantee for optimality. In this paper, we propose the use of machine learning techniques to learn the optimal user similarity measure as well as user rating styles for enhancing recommendation acurracy. Based on a criterion function measuring the overall prediction error, several ratings transformation functions for modeling rating styles together with their learning algorithms are derived. With the help of the formulation and the optimization framework, subjective components in user ratings are removed so that the transformed ratings can then be compared. We have evaluated our proposed methods using the EachMovie dataset and succeeded in obtaining significant improvement in recommendation accuracy when compared with the standard correlation-based algorithm.},
journal = {Inf. Retr.},
month = sep,
pages = {395–410},
numpages = {16},
keywords = {collaborative filtering, machine learning, rating style, recommender systems, user similarity}
}

@article{10.1023/B:INRT.0000011211.50590.71,
author = {Lin, Raz and Kraus, Sarit and Tew, Jeffrey},
title = {OSGS—A Personalized Online Store for E-Commerce Environments},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011211.50590.71},
doi = {10.1023/B:INRT.0000011211.50590.71},
abstract = {Current online stores suffer from a cardinal problem. There are too many products to offer, and customers find themselves lost due to the vast selection. As opposed to traditional stores, there is little or no guidance that helps the customers as they search. In this paper, we propose a new approach for designing a successful personalized online store enabling the successful searching of customers in the store. This approach is based on algorithms commonly used in recommendation systems, but which are rarely used for searches in online stores. We employ this approach for both keyword and browse searches, and present an implementation of this approach. We compared several search guide algorithms experimentally, and the experiments' results show that the suggested algorithms are applicable to the domain of online stores.},
journal = {Inf. Retr.},
month = sep,
pages = {369–394},
numpages = {26},
keywords = {browse search, information retrieval, collaborative filtering, E-commerce, keyword search}
}

@article{10.1023/B:INRT.0000011210.12953.86,
author = {Makkonen, Juha and Ahonen-Myka, Helena and Salmenkivi, Marko},
title = {Simple Semantics in Topic Detection and Tracking},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011210.12953.86},
doi = {10.1023/B:INRT.0000011210.12953.86},
abstract = {Topic Detection and Tracking (TDT) is a research initiative that aims at techniques to organize news documents in terms of news events. We propose a method that incorporates simple semantics into TDT by splitting the term space into groups of terms that have the meaning of the same type. Such a group can be associated with an external ontology. This ontology is used to determine the similarity of two terms in the given group. We extract proper names, locations, temporal expressions and normal terms into distinct sub-vectors of the document representation. Measuring the similarity of two documents is conducted by comparing a pair of their corresponding sub-vectors at a time. We use a simple perceptron to optimize the relative emphasis of each semantic class in the tracking and detection decisions. The results suggest that the spatial and the temporal similarity measures need to be improved. Especially the vagueness of spatial and temporal terms needs to be addressed.},
journal = {Inf. Retr.},
month = sep,
pages = {347–368},
numpages = {22},
keywords = {topic detection and tracking, temporal expression, geographical ontology, retrieval model, information extraction}
}

@article{10.1023/B:INRT.0000011209.19643.e2,
author = {Peng, Fuchun and Schuurmans, Dale and Wang, Shaojun},
title = {Augmenting Naive Bayes Classifiers with Statistical Language Models},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011209.19643.e2},
doi = {10.1023/B:INRT.0000011209.19643.e2},
abstract = {We augment naive Bayes models with statistical n-gram language models to address short-comings of the standard naive Bayes text classifier. The result is a generalized naive Bayes classifier which allows for a local Markov dependence among observations; a model we refer to as the Chain Augmented Naive Bayes (CAN) Bayes classifier. CAN models have two advantages over standard naive Bayes classifiers. First, they relax some of the independence assumptions of naive Bayes—allowing a local Markov chain dependence in the observed variables—while still permitting efficient inference and learning. Second, they permit straightforward application of sophisticated smoothing techniques from statistical language modeling, which allows one to obtain better parameter estimates than the standard Laplace smoothing used in naive Bayes classification. In this paper, we introduce CAN models and apply them to various text classification problems. To demonstrate the language independent and task independent nature of these classifiers, we present experimental results on several text classification problems—authorship attribution, text genre classification, and topic detection—in several languages—Greek, English, Japanese and Chinese. We then systematically study the key factors in the CAN model that can influence the classification performance, and analyze the strengths and weaknesses of the model.},
journal = {Inf. Retr.},
month = sep,
pages = {317–345},
numpages = {29},
keywords = {text classification, n-gram language models, smoothing, naive Bayes}
}

@article{10.1023/B:INRT.0000011208.60754.a1,
author = {Braschler, Martin and Ripplinger, B\"{a}rbel},
title = {How Effective is Stemming and Decompounding for German Text Retrieval?},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011208.60754.a1},
doi = {10.1023/B:INRT.0000011208.60754.a1},
abstract = {Information retrieval systems operating on free text face difficulties when word forms used in the query and documents do not match. The usual solution is the use of a “stemming component” that reduces related word forms to a common stem. Extensive studies of such components exist for English, but considerably less is known for other languages. Previously, it has been claimed that stemming is essential for highly declensional languages. We report on our experiments on stemming for German, where an additional issue is the handling of compounds, which are formed by concatenating several words. The major contribution of our work that goes beyond its focus on German lies in the investigation of a complete spectrum of approaches, ranging from language-independent to elaborate linguistic methods. The main findings are that stemming is beneficial even when using a simple approach, and that carefully designed decompounding, the splitting of compound words, remarkably boosts performance. All findings are based on a thorough analysis using a large reliable test collection.},
journal = {Inf. Retr.},
month = sep,
pages = {291–316},
numpages = {26},
keywords = {morphological analysis, German, evaluation, stemming, decompounding}
}

@article{10.1023/B:INRT.0000011207.45988.bb,
author = {Harper, David J. and Koychev, Ivan and Sun, Yixing and Pirie, Iain},
title = {Within-Document Retrieval: A User-Centred Evaluation of Relevance Profiling},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011207.45988.bb},
doi = {10.1023/B:INRT.0000011207.45988.bb},
abstract = {We present a user-centred, task-oriented, comparative evaluation of two within-document retrieval tools. ProfileSkim computes a relevance profile for a document with respect to a query, and presents the profile as an interactive bar graph. FindSkim provides similar functionality to the web browser “Find” command. A novel simulated work task was devised, where participants are asked to identify (index) relevant pages of an electronic book, given topics from the existing book index. The original book index provides the ground truth, against which the indexing results of the participants can be compared. We confirmed a major hypothesis, namely ProfileSkim proved significantly more efficient than Find-Skim, as measured by time for task. The study indicates that ProfileSkim was as least as effective as FindSkim in identifying relevant pages, as measured by traditional information retrieval measures, and there is some evidence that ProfileSkim is a precision-enhancing tool. Based on qualitative data from questionnaires, we also provide strong evidence to support our conjecture that the participants would be more satisfied when using ProfileSkim than FindSkim. The experimental study confirmed the potential of relevance profiling for improving within-document retrieval. Relevance profiling should prove highly beneficial for users trying to identify relevant information within long documents.},
journal = {Inf. Retr.},
month = sep,
pages = {265–290},
numpages = {26},
keywords = {task-oriented evaluation, relevance profiling, interactive information retrieval, language models, within-document retrieval}
}

@article{10.1023/B:INRT.0000011206.23588.ab,
author = {Gurrin, Cathal and Smeaton, Alan F.},
title = {Replicating Web Structure in Small-Scale Test Collections},
year = {2004},
issue_date = {September-December 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000011206.23588.ab},
doi = {10.1023/B:INRT.0000011206.23588.ab},
abstract = {Linkage analysis as an aid to web search has been assumed to be of significant benefit and we know that it is being implemented by many major Search Engines. Why then have few TREC participants been able to scientifically prove the benefits of linkage analysis in recent years? In this paper we put forward reasons why many disappointing results have been found in TREC experiments and we identify the linkage density requirements of a dataset to faithfully support experiments into linkage-based retrieval by examining the linkage structure of the WWW. Based on these requirements we report on methodologies for synthesising such a test collection.},
journal = {Inf. Retr.},
month = sep,
pages = {239–263},
numpages = {25},
keywords = {test collections, retrieval evaluation, linkage analysis, search engine}
}

@article{10.1023/B:INRT.0000009472.59294.f6,
author = {Peters, Carol and Braschler, Martin},
title = {Editorial},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009472.59294.f6},
doi = {10.1023/B:INRT.0000009472.59294.f6},
journal = {Inf. Retr.},
month = jan,
pages = {5},
numpages = {1}
}

@article{10.1023/B:INRT.0000009446.22036.e3,
author = {Oard, Douglas W. and Gonzalo, Julio and Sanderson, Mark and L\'{o}pez-Ostenero, Fernando and Wang, Jianqiang},
title = {Interactive Cross-Language Document Selection},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009446.22036.e3},
doi = {10.1023/B:INRT.0000009446.22036.e3},
abstract = {The problem of finding documents written in a language that the searcher cannot read is perhaps the most challenging application of cross-language information retrieval technology. In interactive applications, that task involves at least two steps: (1) the machine locates promising documents in a collection that is larger than the searcher could scan, and (2) the searcher recognizes documents relevant to their intended use from among those nominated by the machine. This article presents the results of experiments designed to explore three techniques for supporting interactive relevance assessment: (1) full machine translation, (2) rapid term-by-term translation, and (3) focused phrase translation. Machine translation was found to better support this task than term-by-term translation, and focused phrase translation further improved recall without an adverse effect on precision. The article concludes with an assessment of the strengths and weaknesses of the evaluation framework used in this study and some remarks on implications of these results for future evaluation campaigns.},
journal = {Inf. Retr.},
month = jan,
pages = {205–228},
numpages = {24},
keywords = {cross-language information retrieval, interactive information retrieval, evaluation of information retrieval systems, machine translation}
}

@article{10.1023/B:INRT.0000009445.19495.46,
author = {Braschler, Martin},
title = {Combination Approaches for Multilingual Text Retrieval},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009445.19495.46},
doi = {10.1023/B:INRT.0000009445.19495.46},
abstract = {We describe the Eurospider component for Cross-Language Information Retrieval (CLIR) that has been employed for experiments at all three CLEF campaigns to date. The central aspect of our efforts is the use of combination approaches, effectively combining multiple language pairs, translation resources and translation methods into one multilingual retrieval system. We discuss the implications of building a system that allows flexible combination, give details of the various translation resources and methods, and investigate the impact of merging intermediate results generated by the individual steps. An analysis of the resulting combination system is given which also takes into account additional requirements when deploying the system as a component in an operational, commercial setting.},
journal = {Inf. Retr.},
month = jan,
pages = {183–204},
numpages = {22},
keywords = {operational systems, combination methods, Cross-Language Information Retrieval, merging}
}

@article{10.1023/B:INRT.0000009444.89549.90,
author = {Chen, Aitao and Gey, Fredric C.},
title = {Multilingual Information Retrieval Using Machine Translation, Relevance Feedback and Decompounding},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009444.89549.90},
doi = {10.1023/B:INRT.0000009444.89549.90},
abstract = {Multilingual retrieval (querying of multiple document collections each in a different language) can be achieved by combining several individual techniques which enhance retrieval: machine translation to cross the language barrier, relevance feedback to add words to the initial query, decompounding for languages with complex term structure, and data fusion to combine monolingual retrieval results from different languages. Using the CLEF 2001 and CLEF 2002 topics and document collections, this paper evaluates these techniques within the context of a monolingual document ranking formula based upon logistic regression. Each individual technique yields improved performance over runs which do not utilize that technique. Moreover the techniques are complementary, in that combining the best techniques outperforms individual technique performance. An approximate but fast document translation using bilingual wordlists created from machine translation systems is presented and evaluated. The fast document translation is as effective as query translation in multilingual retrieval. Furthermore, when fast document translation is combined with query translation in multilingual retrieval, the performance is significantly better than that of query translation or fast document translation.},
journal = {Inf. Retr.},
month = jan,
pages = {149–182},
numpages = {34},
keywords = {multilingual information retrieval, results merging, cross-language information retrieval, relevance feedback, decompounding}
}

@article{10.1023/B:INRT.0000009443.51912.e7,
author = {Savoy, Jacques},
title = {Combining Multiple Strategies for Effective Monolingual and Cross-Language Retrieval},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009443.51912.e7},
doi = {10.1023/B:INRT.0000009443.51912.e7},
abstract = {This paper describes and evaluates different retrieval strategies that are useful for search operations on document collections written in various European languages, namely French, Italian, Spanish and German. We also suggest and evaluate different query translation schemes based on freely available translation resources. In order to cross language barriers, we propose a combined query translation approach that has resulted in interesting retrieval effectiveness. Finally, we suggest a collection merging strategy based on logistic regression that tends to perform better than other merging approaches.},
journal = {Inf. Retr.},
month = jan,
pages = {121–148},
numpages = {28},
keywords = {learning curve, cross-language information retrieval, collection merging strategies, bilingual information retrieval, evaluation}
}

@article{10.1023/B:INRT.0000009442.34054.55,
author = {Hedlund, Turid and Airio, Eija and Keskustalo, Heikki and Lehtokangas, Raija and Pirkola, Ari and J\"{a}rvelin, Kalervo},
title = {Dictionary-Based Cross-Language Information Retrieval: Learning Experiences from CLEF 2000–2002},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009442.34054.55},
doi = {10.1023/B:INRT.0000009442.34054.55},
abstract = {In this study the basic framework and performance analysis results are presented for the three year long development process of the dictionary-based UTACLIR system. The tests expand from bilingual CLIR for three language pairs Swedish, Finnish and German to English, to six language pairs, from English to French, German, Spanish, Italian, Dutch and Finnish, and from bilingual to multilingual. In addition, transitive translation tests are reported. The development process of the UTACLIR query translation system will be regarded from the point of view of a learning process. The contribution of the individual components, the effectiveness of compound handling, proper name matching and structuring of queries are analyzed. The results and the fault analysis have been valuable in the development process. Overall the results indicate that the process is robust and can be extended to other languages. The individual effects of the different components are in general positive. However, performance also depends on the topic set and the number of compounds and proper names in the topic, and to some extent on the source and target language. The dictionaries used affect the performance significantly.},
journal = {Inf. Retr.},
month = jan,
pages = {99–119},
numpages = {21},
keywords = {transitive CLIR, compound handling, proper name matching, UTACLIR query translation system, cross-language information retrieval}
}

@article{10.1023/B:INRT.0000009441.78971.be,
author = {Mcnamee, Paul and Mayfield, James},
title = {Character <i>N</i>-Gram Tokenization for European Language Text Retrieval},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009441.78971.be},
doi = {10.1023/B:INRT.0000009441.78971.be},
abstract = {The Cross-Language Evaluation Forum has encouraged research in text retrieval methods for numerous European languages and has developed durable test suites that allow language-specific techniques to be investigated and compared. The labor associated with crafting a retrieval system that takes advantage of sophisticated linguistic methods is daunting. We examine whether language-neutral methods can achieve accuracy comparable to language-specific methods with less concomitant software complexity. Using the CLEF 2002 test set we demonstrate empirically how overlapping character n-gram tokenization can provide retrieval accuracy that rivals the best current language-specific approaches for European languages. We show that n = 4 is a good choice for those languages, and document the increased storage and time requirements of the technique. We report on the benefits of and challenges posed by n-grams, and explain peculiarities attendant to bilingual retrieval. Our findings demonstrate clearly that accuracy using n-gram indexing rivals or exceeds accuracy using unnormalized words, for both monolingual and bilingual retrieval.},
journal = {Inf. Retr.},
month = jan,
pages = {73–97},
numpages = {25},
keywords = {European languages, language-neutral retrieval, character n-grams, Cross Language Evaluation Forum, cross-language information retrieval}
}

@article{10.1023/B:INRT.0000009440.64411.ad,
author = {Bertoldi, Nicola and Federico, Marcello},
title = {Statistical Models for Monolingual and Bilingual Information Retrieval},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009440.64411.ad},
doi = {10.1023/B:INRT.0000009440.64411.ad},
abstract = {This work reviews information retrieval systems developed at ITC-irst which were evaluated through several tracks of CLEF, during the last three years. The presentation tries to follow the progress made over time in developing new statistical models first for monolingual information retrieval, then for cross-language information retrieval. Besides describing the underlying theory, performance of monolingual and bilingual information retrieval models are reported, respectively, on Italian monolingual tracks and Italian-English bilingual tracks of CLEF. Monolingual systems by ITC-irst performed consistently well in all the official evaluations, while the bilingual system ranked in CLEF 2002 just behind competitors using commercial machine translation engines. However, by experimentally comparing our statistical topic translation model against a state-of-the-art commercial system, no statistically significant difference in retrieval performance could be measured on a larger set of queries.},
journal = {Inf. Retr.},
month = jan,
pages = {53–72},
numpages = {20},
keywords = {monolingual information retrieval, machine translation, statistical models, cross-language information retrieval}
}

@article{10.1023/B:INRT.0000009439.19151.4c,
author = {Hollink, Vera and Kamps, Jaap and Monz, Christof and De Rijke, Maarten},
title = {Monolingual Document Retrieval for European Languages},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009439.19151.4c},
doi = {10.1023/B:INRT.0000009439.19151.4c},
abstract = {Recent years have witnessed considerable advances in information retrieval for European languages other than English. We give an overview of commonly used techniques and we analyze them with respect to their impact on retrieval effectiveness. The techniques considered range from linguistically motivated techniques, such as morphological normalization and compound splitting, to knowledge-free approaches, such as n-gram indexing. Evaluations are carried out against data from the CLEF campaign, covering eight European languages. Our results show that for many of these languages a modicum of linguistic techniques may lead to improvements in retrieval effectiveness, as can the use of language independent techniques.},
journal = {Inf. Retr.},
month = jan,
pages = {33–52},
numpages = {20},
keywords = {tokenization, morphological normalization, cross-lingual information retrieval, monolingual document retrieval, European languages}
}

@article{10.1023/B:INRT.0000009438.69013.fa,
author = {Braschler, Martin and Peters, Carol},
title = {Cross-Language Evaluation Forum: Objectives, Results, Achievements},
year = {2004},
issue_date = {January-April 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/B:INRT.0000009438.69013.fa},
doi = {10.1023/B:INRT.0000009438.69013.fa},
abstract = {The Cross-Language Evaluation Forum (CLEF) is now in its fourth year of activity. We summarize the main lessons learned during this period, outline the state-of-the-art of the research reported in the CLEF experiments and discuss the contribution that this initiative has made to research and development in the multilingual information access domain. We also make proposals for future directions in system evaluation aimed at meeting emerging needs.},
journal = {Inf. Retr.},
month = jan,
pages = {7–31},
numpages = {25},
keywords = {CLIR state-of-the-art, evaluation campaign, evaluation methodology, cross-language information retrieval}
}

@article{10.1023/A:1026080230789,
author = {Nottelmann, Henrik and Fuhr, Norbert},
title = {From Retrieval Status Values to Probabilities of Relevance for Advanced IR Applications},
year = {2003},
issue_date = {September-December 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026080230789},
doi = {10.1023/A:1026080230789},
abstract = {Information Retrieval systems typically sort the result with respect to document retrieval status values (RSV). According to the Probability Ranking Principle, this ranking ensures optimum retrieval quality if the RSVs are monotonously increasing with the probabilities of relevance (as e.g. for probabilistic IR models). However, advanced applications like filtering or distributed retrieval require estimates of the actual probability of relevance. The relationship between the RSV of a document and its probability of relevance can be described by a “normalisation” function which maps the retrieval status value onto the probability of relevance (“mapping functions”). In this paper, we explore the use of linear and logistic mapping functions for different retrieval methods. In a series of upper-bound experiments, we compare the approximation quality of the different mapping functions. We also investigate the effect on the resulting retrieval quality in distributed retrieval (only merging, without resource selection). These experiments show that good estimates of the actual probability of relevance can be achieved, and that the logistic model outperforms the linear one. Retrieval quality for distributed retrieval is only slightly improved by using the logistic function.},
journal = {Inf. Retr.},
month = sep,
pages = {363–388},
numpages = {26},
keywords = {evaluation, formal models, parameter learning, retrieval status value, probability of inference}
}

@article{10.1023/A:1026028229881,
author = {Huang, Xiangji and Peng, Fuchun and Schuurmans, Dale and Cercone, Nick and Robertson, Stephen E.},
title = {Applying Machine Learning to Text Segmentation for Information Retrieval},
year = {2003},
issue_date = {September-December 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026028229881},
doi = {10.1023/A:1026028229881},
abstract = {We propose a self-supervised word segmentation technique for text segmentation in Chinese information retrieval. This method combines the advantages of traditional dictionary based, character based and mutual information based approaches, while overcoming many of their shortcomings. Experiments on TREC data show this method is promising. Our method is completely language independent and unsupervised, which provides a promising avenue for constructing accurate multi-lingual or cross-lingual information retrieval systems that are flexible and adaptive. We find that although the segmentation accuracy of self-supervised segmentation is not as high as some other segmentation methods, it is enough to give good retrieval performance. It is commonly believed that word segmentation accuracy is monotonically related to retrieval performance in Chinese information retrieval. However, for Chinese, we find that the relationship between segmentation and retrieval performance is in fact nonmonotonic; that is, at around 70% word segmentation accuracy an over-segmentation phenomenon begins to occur which leads to a reduction in information retrieval performance. We demonstrate this effect by presenting an empirical investigation of information retrieval on Chinese TREC data, using a wide variety of word segmentation algorithms with word segmentation accuracies ranging from 44% to 95%, including 70% word segmentation accuracy from our self-supervised word-segmentation approach. It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate segmenters, while they are broken up by less accurate (but reasonable) segmenters, to a surprising advantage. This suggests that words themselves might be too broad a notion to conveniently capture the general semantic meaning of Chinese text. Our research suggests machine learning techniques can play an important role in building adaptable information retrieval systems and different evaluation standards for word segmentation should be given to different applications.},
journal = {Inf. Retr.},
month = sep,
pages = {333–362},
numpages = {30},
keywords = {Chinese information retrieval, machine learning, EM algorithm, word segmentation}
}

@article{10.1023/A:1026024513043,
author = {Wang, Quan and Ng, Yiu-Kai},
title = {An Ontology-Based Binary-Categorization Approach for Recognizing Multiple-Record Web Documents Using a Probabilistic Retrieval Model},
year = {2003},
issue_date = {September-December 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026024513043},
doi = {10.1023/A:1026024513043},
abstract = {The Web contains a tremendous amount of information. It is challenging to determine which Web documents are relevant to a user query, and even more challenging to rank them according to their degrees of relevance. In this paper, we propose a probabilistic retrieval model using logistic regression for recognizing multiple-record Web documents against an application ontology, a simple conceptual modeling approach. We notice that many Web documents contain a sequence of chunks of textual information, each of which constitutes a “record.” This type of documents is referred to as multiple-record documents. In our categorization approach, a document is represented by a set of term frequencies of index terms, a density heuristic value, and a grouping heuristic value. We first apply the logistic regression analysis on relevant probabilities using the (i) index terms, (ii) density value, and (iii) grouping value of each training document. Hereafter, the relevant probability of each test document is interpolated from the fitting curves. Contrary to other probabilistic retrieval models, our model makes only a weak independent assumption and is capable of handling any important dependent relationships among index terms. In addition, we use logistic regression, instead of linear regression analysis, because the relevance probabilities of training documents are discrete. Using a test set of car-ads and another one for obituary Web documents, our probabilistic model achieves the averaged recall ratio of 100%, precision ratio of 83.3%, and accuracy ratio of 92.5%.},
journal = {Inf. Retr.},
month = sep,
pages = {295–332},
numpages = {38},
keywords = {logistic regression analysis, application ontology, probabilistic model, binary categorization}
}

@article{10.1023/A:1023992406935,
author = {Katopol, Patricia},
title = {Knowledge Management in the Socio Technical World—The Graffiti Continues},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023992406935},
doi = {10.1023/A:1023992406935},
journal = {Inf. Retr.},
month = apr,
pages = {281–284},
numpages = {4}
}

@article{10.1023/A:1023988306026,
author = {Sisson, Scott},
title = {Principles of Data Mining},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023988306026},
doi = {10.1023/A:1023988306026},
journal = {Inf. Retr.},
month = apr,
pages = {275–277},
numpages = {3}
}

@article{10.1023/A:1023984205118,
author = {Guo, David and Berry, Michael W. and Thompson, Bryan B. and Bailin, Sidney},
title = {Knowledge-Enhanced Latent Semantic Indexing},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023984205118},
doi = {10.1023/A:1023984205118},
abstract = {Latent Semantic Indexing (LSI) is a popular information retrieval model for concept-based searching. As with many vector space IR models, LSI requires an existing term-document association structure such as a term-by-document matrix. The term-by-document matrix, constructed during document parsing, can only capture weighted vocabulary occurrence patterns in the documents. However, for many knowledge domains there are pre-existing semantic structures that could be used to organize and categorize information. The goals of this study are (i) to demonstrate how such semantic structures can be automatically incorporated into the LSI vector space model, and (ii) to measure the effect of these structures on query matching performance. The new approach, referred to as Knowledge-Enhanced LSI, is applied to documents in the OHSUMED medical abstracts collection using the semantic structures provided by the UMLS Semantic Network and MeSH. Results based on precision-recall data (11-point average precision values) indicate that a MeSH-enhanced search index is capable of delivering noticeable incremental performance gain (as much as 35%) over the original LSI for modest constraints on precision. This performance gain is achieved by replacing the original query with the MeSH heading extracted from the query text via regular expression matches.},
journal = {Inf. Retr.},
month = apr,
pages = {225–250},
numpages = {26},
keywords = {latent semantic indexing, MeSH, metathesaurus, OHSUMED, semantic network, UMLS}
}

@article{10.1023/A:1023947204209,
author = {Lu, Zhihong and McKinley, Kathryn S.},
title = {Partial Collection Replication for Information Retrieval},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023947204209},
doi = {10.1023/A:1023947204209},
abstract = {The explosion of content in distributed information retrieval (IR) systems requires new mechanisms in order to attain timely and accurate retrieval of unstructured text. This paper shows how to exploit locality by building, using, and searching partial replicas of text collections in a distributed IR system. In this work, a partial replica includes a subset of the documents from larger collection(s) and the corresponding inference network search mechanism. For each query, the distributed system determines if partial replica is a good match and then searches it, or it searches the original collection. We demonstrate the scenarios where partial replication performs better than systems that use caches which only store previous query and answer pairs. We first use logs from THOMAS and Excite to examine query locality using query similarity versus exact match. We show that searching replicas can improve locality (from 3 to 19%) over the exact match required by caching. Replicas increase locality because they satisfy queries which are distinct but return the same or very similar answers. We then present a novel inference network replica selection function. We vary its parameters and compare it to previous collection selection functions, demonstrating a configuration that directs most of the appropriate queries to replicas in a replica hierarchy. We then explore the performance of partial replication in a distributed IR system. We compare it with caching and partitioning. Our validated simulator shows that the increases in locality due to replication make it preferable to caching alone, and that even a small increase of 4% in locality translates into a performance advantage. We also show a hybrid system with caches and replicas that performs better than each on their own.},
journal = {Inf. Retr.},
month = apr,
pages = {159–198},
numpages = {40},
keywords = {replica selection, partial replication, distributed information retrieval architectures}
}

@article{10.1023/A:1023944523773,
author = {Solomon, Paul},
title = {Looking for Information—A Survey of Research on Information Seeking, Needs, and Behavior},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023944523773},
doi = {10.1023/A:1023944523773},
journal = {Inf. Retr.},
month = apr,
pages = {284–288},
numpages = {5}
}

@article{10.1023/A:1023940422865,
author = {Wacholder, Nina},
title = {Spotting and Discovering Terms Through Natural Language Processing},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023940422865},
doi = {10.1023/A:1023940422865},
journal = {Inf. Retr.},
month = apr,
pages = {277–281},
numpages = {5}
}

@article{10.1023/A:1023936321956,
author = {Vechtomova, Olga and Robertson, Stephen and Jones, Susan},
title = {Query Expansion with Long-Span Collocates},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023936321956},
doi = {10.1023/A:1023936321956},
abstract = {The paper presents two novel approaches to query expansion with long-span collocates—words, significantly co-occurring in topic-size windows with query terms. In the first approach—global collocation analysis—collocates of query terms are extracted from the entire collection, in the second—local collocation analysis—from a subset of retrieved documents. The significance of association between collocates was estimated using modified Mutual Information and Z score. The techniques were tested using the Okapi IR system. The effect of different parameters on performance was evaluated: window size, number of expansion terms, measures of collocation significance and types of expansion terms. We present performance results of these techniques and provide comparison with related approaches.},
journal = {Inf. Retr.},
month = apr,
pages = {251–273},
numpages = {23},
keywords = {automatic query expansion, relevance feedback, long-span word collocation, probabilistic information retrieval}
}

@article{10.1023/A:1023932221048,
author = {Mostafa, Javed and Mukhopadhyay, Snehasis and Palakal, Mathew},
title = {Simulation Studies of Different Dimensions of Users' Interests and Their Impact on User Modeling and Information Filtering},
year = {2003},
issue_date = {April 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1023932221048},
doi = {10.1023/A:1023932221048},
abstract = {Modeling users in information filtering systems is a difficult challenge due to dimensions such as nature, scope, and variability of interests. Numerous machine-learning approaches have been proposed for user modeling in filtering systems. The focus has been primarily on techniques for user model capture and representation, with relatively simple assumptions made about the type of users' interests. Although many studies claim to deal with “adaptive” techniques and thus they pay heed to the fact that different types of interests must be modeled or even changes in interests have to be captured, few studies have actually focused on the dynamic nature and the variability of user-interests and their impact on the modeling process. A simulation based information filtering environment called SIMSFITER was developed to overcome some of the barriers associated with conducting studies on user-oriented factors that can impact interests. SIMSIFTER implemented a user modeling approach known as reinforcement learning that has proven to be effective in previous filtering studies involving humans. This paper reports on several studies conducted using SIMSIFTER that examined the impact of key dimensions such as type of interests, rate of change of interests and level of user-involvement on modeling accuracy and ultimately on filtering effectiveness.},
journal = {Inf. Retr.},
month = apr,
pages = {199–223},
numpages = {25},
keywords = {information filtering, user modeling, reinforcement learning, user-oriented factors}
}

@article{10.1023/A:1022952531694,
author = {Elovici, Yuval and Shapira, Bracha and Kantor, Paul B.},
title = {Using the Information Structure Model to Compare Profile-Based Information Filtering Systems},
year = {2003},
issue_date = {January 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1022952531694},
doi = {10.1023/A:1022952531694},
abstract = {In the IR field it is clear that the value of a system depends on the cost and benefit profiles of its users. It would seem obvious that different users would prefer different systems. In the TREC-9 filtering track, systems are evaluated by a utility measure specifying a given cost and benefit. However, in the study of decision systems it is known that, in some cases, one system may be unconditionally better than another. In this paper we employ a decision theoretic approach to find conditions under which an Information Filtering (IF) system is unconditionally superior to another for all users regardless of their cost and benefit profiles.It is well known that if two IF systems have equal precision the system with better recall will be preferred by all users. Similarly, with equal recall, better precision is universally preferred. We confirm these known results and discover an unexpected dominance relation in which a system with lower recall will be universally preferred provided its precision is sufficiently higher.},
journal = {Inf. Retr.},
month = jan,
pages = {75–97},
numpages = {23},
keywords = {user-profile, information economics, performance, evaluation, formal model}
}

@article{10.1023/A:1022949613039,
author = {Trotman, Andrew},
title = {Compressing Inverted Files},
year = {2003},
issue_date = {January 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1022949613039},
doi = {10.1023/A:1022949613039},
abstract = {Research into inverted file compression has focused on compression ratio—how small the indexes can be. Compression ratio is important for fast interactive searching. It is taken as read, the smaller the index, the faster the search.The premise “smaller is better” may not be true. To truly build faster indexes it is often necessary to forfeit compression. For inverted lists consisting of only 128 occurrences compression may only add overhead. Perhaps the inverted list could be stored in 128 bytes in place of 128 words, but it must still be stored on disk. If the minimum disk sector read size is 512 bytes and the word size is 4 bytes, then both the compressed and raw postings would require one disk seek and one disk sector read. A less efficient compression technique may increase the file size, but decrease load/decompress time, thereby increasing throughput.Examined here are five compression techniques, Golomb, Elias gamma, Elias delta, Variable Byte Encoding and Binary Interpolative Coding. The effect on file size, file seek time, and file read time are all measured as is decompression time. A quantitative measure of throughput is developed and the performance of each method is determined.},
journal = {Inf. Retr.},
month = jan,
pages = {5–19},
numpages = {15},
keywords = {document indexing, index compression, inverted files, text searching}
}

@article{10.1023/A:1022948414856,
author = {Sakkis, Georgios and Androutsopoulos, Ion and Paliouras, Georgios and Karkaletsis, Vangelis and Spyropoulos, Constantine D. and Stamatopoulos, Panagiotis},
title = {A Memory-Based Approach to Anti-Spam Filtering for Mailing Lists},
year = {2003},
issue_date = {January 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1022948414856},
doi = {10.1023/A:1022948414856},
abstract = {This paper presents an extensive empirical evaluation of memory-based learning in the context of anti-spam filtering, a novel cost-sensitive application of text categorization that attempts to identify automatically unsolicited commercial messages that flood mailboxes. Focusing on anti-spam filtering for mailing lists, a thorough investigation of the effectiveness of a memory-based anti-spam filter is performed using a publicly available corpus. The investigation includes different attribute and distance-weighting schemes, and studies on the effect of the neighborhood size, the size of the attribute set, and the size of the training corpus. Three different cost scenarios are identified, and suitable cost-sensitive evaluation functions are employed. We conclude that memory-based anti-spam filtering for mailing lists is practically feasible, especially when combined with additional safety nets. Compared to a previously tested Naive Bayes filter, the memory-based filter performs on average better, particularly when the misclassification cost for non-spam messages is high.},
journal = {Inf. Retr.},
month = jan,
pages = {49–73},
numpages = {25},
keywords = {text categorization, unsolicited commercial e-mail, machine learning, spam}
}

@article{10.1023/A:1022944313947,
author = {Van Der Pol, Ruud},
title = {Dipe-D: A Tool for Knowledge-Based Query Formulation in Information Retrieval},
year = {2003},
issue_date = {January 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1022944313947},
doi = {10.1023/A:1022944313947},
abstract = {The paper reports the development of Dipe-D, a knowledge-based procedure for the formulation of Boolean queries in information retrieval. Dipe-D creates a query in two steps: (1) the user's information need is developed interactively, while identifying the concepts of the information need, and subsequently (2) the collection of concepts identified is automatically transformed into a Boolean query. In the first step, the subject area—as represented in a knowledge base—is explored by the user. He does this by means of specifying the (concepts that meet his) information need in an artificial language and looking through the solution as provided by the computer. The specification language allows one to specify concepts by their features, both in precise terms as well as vaguely. By repeating the process of specifying the information need and exploring the resulting concepts, the user may precisely single out the concepts that describe his information need. In the second step, the program provides the designations (and variants) for the concepts identified, and connects them by appropriate operators. Dipe-D is meant to improve on existing procedures that identify the concepts less systematically, create a query manually, and then sometimes expand that query. Experiments are reported on each of the two steps; they indicate that the first step identifies only but not all the relevant concepts, and the second step performs (at least) as good as human beings do.},
journal = {Inf. Retr.},
month = jan,
pages = {21–47},
numpages = {27},
keywords = {information retrieval, knowledge engineering/artificial intelligence, query formulation}
}

@article{10.1023/A:1022904715765,
author = {Hawking, David and Robertson, Stephen},
title = {On Collection Size and Retrieval Effectiveness},
year = {2003},
issue_date = {January 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {6},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1022904715765},
doi = {10.1023/A:1022904715765},
abstract = {The relationship between collection size and retrieval effectiveness is particularly important in the context of Web search. We investigate it first analytically and then experimentally, using samples and subsets of test collections. Different retrieval systems vary in how the score assigned to an individual document in a sample collection relates to the score it receives in the full collection; we identify four cases.We apply signal detection (SD) theory to retrieval from samples, taking into account the four cases and using a variety of shapes for relevant and irrelevant distributions. We note that the SD model subsumes several earlier hypotheses about the causes of the decreased precision in samples. We also discuss other models which contribute to an understanding of the phenomenon, particularly relating to the effects of discreteness. Different models provide complementary insights.Extensive use is made of test data, some from official submissions to the TREC-6 VLC track and some new, to illustrate the effects and test hypotheses. We empirically confirm predictions, based on SD theory, that P@n should decline when moving to a sample collection and that average precision and R-precision should remain constant. SD theory suggests the use of recall-fallout plots as operating characteristic (OC) curves. We plot OC curves of this type for a real retrieval system and query set and show that curves for sample collections are similar but not identical to the curve for the full collection.},
journal = {Inf. Retr.},
month = jan,
pages = {99–105},
numpages = {7},
keywords = {text retrieval models, relevance score distributions, collection sampling, signal detection theory}
}

@article{10.1023/A:1020499411651,
author = {Bookstein, Abraham and Kulyukin, Vladimir A. and Raita, Timo},
title = {Generalized Hamming Distance},
year = {2002},
issue_date = {October 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1020499411651},
doi = {10.1023/A:1020499411651},
abstract = {Many problems in information retrieval and related fields depend on a reliable measure of the distance or similarity between objects that, most frequently, are represented as vectors. This paper considers vectors of bits. Such data structures implement entities as diverse as bitmaps that indicate the occurrences of terms and bitstrings indicating the presence of edges in images. For such applications, a popular distance measure is the Hamming distance. The value of the Hamming distance for information retrieval applications is limited by the fact that it counts only exact matches, whereas in information retrieval, corresponding bits that are close by can still be considered to be almost identical. We define a “Generalized Hamming distance” that extends the Hamming concept to give partial credit for near misses, and suggest a dynamic programming algorithm that permits it to be computed efficiently. We envision many uses for such a measure. In this paper we define and prove some basic properties of the “Generalized Hamming distance”, and illustrate its use in the area of object recognition. We evaluate our implementation in a series of experiments, using autonomous robots to test the measure's effectiveness in relating similar bitstrings.},
journal = {Inf. Retr.},
month = oct,
pages = {353–375},
numpages = {23},
keywords = {image retrieval, metrics, object recognition, hamming distance, robot vision, information retrieval, computer vision}
}

@article{10.1023/A:1020447427581,
author = {French, James C. and Powell, Allison L. and Gey, Fredric and Perelman, Natalia},
title = {Exploiting Manual Indexing to Improve Collection Selection and Retrieval Effectiveness},
year = {2002},
issue_date = {October 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1020447427581},
doi = {10.1023/A:1020447427581},
abstract = {Vocabulary incompatibilities arise when the terms used to index a document collection are largely unknown, or at least not well-known to the users who eventually search the collection. No matter how comprehensive or well-structured the indexing vocabulary, it is of little use if it is not used effectively in query formulation. This paper demonstrates that techniques for mapping user queries into the controlled indexing vocabulary have the potential to radically improve document retrieval performance. We also show how the use of controlled indexing vocabulary can be employed to achieve performance gains for collection selection. Finally, we demonstrate the potential benefit of combining these two techniques in an interactive retrieval environment. Given a user query, our evaluation approach simulates the human user's choice of terms for query augmentation given a list of controlled vocabulary terms suggested by a system. This strategy lets us evaluate interactive strategies without the need for human subjects.},
journal = {Inf. Retr.},
month = oct,
pages = {323–351},
numpages = {29},
keywords = {collection selection, query augmentation, entry vocabulary, interactive retrieval}
}

@article{10.1023/A:1020443909834,
author = {Herlocker, Jon and Konstan, Joseph A. and Riedl, John},
title = {An Empirical Analysis of Design Choices in Neighborhood-Based Collaborative Filtering Algorithms},
year = {2002},
issue_date = {October 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1020443909834},
doi = {10.1023/A:1020443909834},
abstract = {Collaborative filtering systems predict a user's interest in new items based on the recommendations of other people with similar interests. Instead of performing content indexing or content analysis, collaborative filtering systems rely entirely on interest ratings from members of a participating community. Since predictions are based on human ratings, collaborative filtering systems have the potential to provide filtering based on complex attributes, such as quality, taste, or aesthetics. Many implementations of collaborative filtering apply some variation of the neighborhood-based prediction algorithm. Many variations of similarity metrics, weighting approaches, combination measures, and rating normalization have appeared in each implementation. For these parameters and others, there is no consensus as to which choice of technique is most appropriate for what situations, nor how significant an effect on accuracy each parameter has. Consequently, every person implementing a collaborative filtering system must make hard design choices with little guidance. This article provides a set of recommendations to guide design of neighborhood-based prediction systems, based on the results of an empirical study. We apply an analysis framework that divides the neighborhood-based prediction approach into three components and then examines variants of the key parameters in each component. The three components identified are similarity computation, neighbor selection, and rating combination.},
journal = {Inf. Retr.},
month = oct,
pages = {287–310},
numpages = {24},
keywords = {information filtering, collaborative filtering, preference prediction, empirical studies}
}

@article{10.1023/A:1020443310743,
author = {Nilsson, Martin},
title = {Hierarchical Clustering Using Non-Greedy Principal Direction Divisive Partitioning},
year = {2002},
issue_date = {October 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1020443310743},
doi = {10.1023/A:1020443310743},
abstract = {We present a non-greedy version of the recently published Principal Direction Divisive Partitioning (PDDP) algorithm. The PDDP algorithm creates a hierarchical taxonomy of a data set by successively splitting the data into sub-clusters. At each level the cluster with largest variance is split by a hyper-plane orthogonal to its leading principal component. The PDDP algorithm is known to produce high quality clusters, especially when applied to high dimensional data, such as document-word feature matrices. It also scales well with both the size and the dimensionality of the data set. However, at each level only the locally optimal choice of spitting is considered. At a later stage this often leads to a non-optimal global partitioning of the data. The non-greedy version of the PDDP algorithm (NGPDDP) presented in this paper address this problem. At each level multiple alternative splitting strategies are considered. Results from applying the algorithm to generated and real data (feature vectors from sets of text documents) are presented. The results show substantial improvements in the cluster quality.},
journal = {Inf. Retr.},
month = oct,
pages = {311–321},
numpages = {11},
keywords = {PCA, taxonomy, classification, clustering}
}

@article{10.1023/A:1015797928606,
author = {Soboroff, Ian M. and Nicholas, Charles K.},
title = {Related, but Not Relevant: Content-Based Collaborative Filtering in TREC-8},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015797928606},
doi = {10.1023/A:1015797928606},
abstract = {Historically, solutions to the TREC filtering tasks have focused exclusively on the content of documents and search topic descriptions as training data. These approaches are well-known for their ability to focus on those salient concepts in the document stream which are most useful for separating relevant documents from irrelevant ones. However, one kind of information that has not been used is the relationships among the topics themselves. In our TREC-8 routing experiments, we employed a collaborative (or social) filtering algorithm, based on latent semantic indexing which highlights common term usage patterns among groups of filtering profiles. Our hypothesis was that this would allow related topics to share common relevant documents. We found, however, that the algorithm also recommends many documents of related, yet irrelevant interest. As a result of this process, many similar search topics are “linked” together by common sets of documents recommended to them. We visualize these topic relationships using graphs where topics are nodes and edges exist where two topics share a recommended document.},
journal = {Inf. Retr.},
month = apr,
pages = {189–208},
numpages = {20},
keywords = {content-based filtering, collaborative filtering, routing, profile learning}
}

@article{10.1023/A:1015793827697,
author = {Allan, James},
title = {Detection As Multi-Topic Tracking},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015793827697},
doi = {10.1023/A:1015793827697},
abstract = {The topic tracking task from TDT is a variant of information filtering tasks that focuses on event-based topics in streams of broadcast news. In this study, we compare tracking to another TDT task, detection, which has the goal of partitioning i&gt;all arriving news into topics, regardless of whether the topics are of interest to anyone, and even when a new topic appears that had not been previous anticipated. There are clear relationships between the two tasks (under some assumptions, a “perfect” tracking system could “solve” the detection problem), but they are evaluated quite differently. We describe the two tasks and discuss their similarities. We show how viewing detection as a form of multi-topic parallel tracking can illuminate the performance tradeoffs of detection over tracking.},
journal = {Inf. Retr.},
month = apr,
pages = {139–157},
numpages = {19},
keywords = {event-based information organization, evaluation, topic detection and tracking (TDT), information filtering}
}

@article{10.1023/A:1015758214493,
author = {Zaragoza, Hugo},
title = {Information Retrieval: Algorithms and Heuristics},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015758214493},
doi = {10.1023/A:1015758214493},
journal = {Inf. Retr.},
month = apr,
pages = {271–274},
numpages = {4}
}

@article{10.1023/A:1015754113585,
author = {Robertson, Stephen},
title = {Comparing the Performance of Adaptive Filtering and Ranked Output Systems},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015754113585},
doi = {10.1023/A:1015754113585},
abstract = {Some insight into the behavior of adaptive filtering systems may be gained by comparing them with similar ranked-output retrieval systems. This is not easy; however, a new optimization measure, introduced for the TREC-9 filtering track, makes some such comparison possible. A series of experiments using the TREC-9 filtering data shows that filtering effectiveness is comparable to routing effectiveness, and demonstrates the gains to be made from adaptation.},
journal = {Inf. Retr.},
month = apr,
pages = {257–268},
numpages = {12},
keywords = {filtering, ranked output, performance}
}

@article{10.1023/A:1015750012676,
author = {Eichmann, David and Srinivasan, Padmini},
title = {Adaptive Filtering of Newswire Stories Using Two-Level Clustering},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015750012676},
doi = {10.1023/A:1015750012676},
abstract = {Adaptive filtering of news is an area of information retrieval gaining substantial interest as services become more available on the Internet. This paper reports on a number of experiments involving a two-level clustering approach using a variety of techniques including threshold adaptation, topic vocabulary adaptation and both noun phrase and named entity adaptation. Our goal in this exploratory research is to empirically compare alternative configurations of our filtering approach that will allow us to better understand the relative value of the component subsystems.},
journal = {Inf. Retr.},
month = apr,
pages = {209–237},
numpages = {29},
keywords = {document clustering, part-of-speech tagging, adaptive filtering, named entity extraction}
}

@article{10.1023/A:1015745911767,
author = {Ault, Thomas Galen and Yang, Yiming},
title = {Information Filtering in TREC-9 and TDT-3: A Comparative Analysis},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015745911767},
doi = {10.1023/A:1015745911767},
abstract = {Much work on automated information filtering has been done in the TREC and TDT domains, but differences in corpora, the nature of TREC topics vs. TDT events, the constraints imposed on training and testing, and the choices of performance measures confound any meaningful comparison between these domains. We attempt to bridge the gap between them by evaluating the performance of the k-nearest-neighbor (kNN) classification system on the corpus and categories from one domain using the constraints of the other. To maximize comparability and understand the effect of the evaluation metrics specific to each domain, we optimize the performance of kNN separately for the i&gt;F1, i&gt;T9P (preferred metric for TREC-9) and i&gt;Ctrk (official metric for TDT-3) metrics. Through a thorough comparison of our within-domain and cross-domain results, our results demonstrate that the corpus used for TREC-9 is more challenging for an information filtering system than the TDT-3 corpus and strongly suggest that the TDT-3 event tracking task itself is more difficult than the TREC batch filtering task. We also show that optimizing performance in TREC-9 and TDT-3 tends to result in systems with different performance characteristics, confounding any meaningful comparison between the two domains, and that i&gt;T9P and i&gt;Ctrk both have properties that make them undesirable as general information filtering metrics.},
journal = {Inf. Retr.},
month = apr,
pages = {159–187},
numpages = {29},
keywords = {information filtering, TREC, TDT, topic tracking}
}

@article{10.1023/A:1015721010859,
author = {Robertson, Stephen},
title = {Introduction to the Special Issue: Overview of the TREC Routing and Filtering Tasks},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015721010859},
doi = {10.1023/A:1015721010859},
abstract = {This paper introduces the special issue, and reviews the routing and filtering tasks as defined and evaluated at TREC. The tasks attempt to simulate a specific service situation: the system is assumed to process an incoming stream of documents against profiles of user interest, strictly in the time order in which they arrive, and immediately refer any matching document to the user. In the adaptive filtering version of the task, the user is assumed to provide a relevance judgement instantly. The rationale for the task definitions and the evaluation measures used is discussed.},
journal = {Inf. Retr.},
month = apr,
pages = {127–137},
numpages = {11},
keywords = {routing, filtering, TREC}
}

@article{10.1023/A:1015710331332,
author = {Holbrooks, M. Zoe},
title = {The Text in the Machine: Electronic Texts in the Humanities},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015710331332},
doi = {10.1023/A:1015710331332},
journal = {Inf. Retr.},
month = apr,
pages = {274–278},
numpages = {5}
}

@article{10.1023/A:1015706230423,
author = {Thompson, Paul},
title = {Finding Out About: A Cognitive Perspective on Search Engine Technology and the WWW},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015706230423},
doi = {10.1023/A:1015706230423},
journal = {Inf. Retr.},
month = apr,
pages = {269–271},
numpages = {3}
}

@article{10.1023/A:1015702129514,
author = {Robertson, Stephen},
title = {Threshold Setting and Performance Optimization in Adaptive Filtering},
year = {2002},
issue_date = {April-July 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1015702129514},
doi = {10.1023/A:1015702129514},
abstract = {An experimental adaptive filtering system, built on the Okapi search engine, is described. In addition to the regular text retrieval functions, the system requires a complex set of procedures for setting score thresholds and adapting them following feedback. These procedures need to be closely related to the evaluation measures to be used. A mixture of quantitative methods relating a threshold to the number of documents expected to be retrieved in a time period, and qualitative methods relating to the probability of relevance, is defined. Experiments under the TREC-9 Adaptive Filtering Track rules are reported. The system is seen to perform reasonably well in comparison with other systems at TREC. Some of the variables that may affect performance are investigated.},
journal = {Inf. Retr.},
month = apr,
pages = {239–256},
numpages = {18},
keywords = {optimization, adaptation, filtering, thresholds}
}

@article{10.1023/A:1012782908347,
author = {Ruiz, Miguel E. and Srinivasan, Padmini},
title = {Hierarchical Text Categorization Using Neural Networks},
year = {2002},
issue_date = {January 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1012782908347},
doi = {10.1023/A:1012782908347},
abstract = {This paper presents the design and evaluation of a text categorization method based on the Hierarchical Mixture of Experts model. This model uses a divide and conquer principle to define smaller categorization problems based on a predefined hierarchical structure. The final classifier is a hierarchical array of neural networks. The method is evaluated using the UMLS Metathesaurus as the underlying hierarchical structure, and the OHSUMED test set of MEDLINE records. Comparisons with an optimized version of the traditional Rocchio's algorithm adapted for text categorization, as well as flat neural network classifiers are provided. The results show that the use of the hierarchical structure improves text categorization performance with respect to an equivalent flat model. The optimized Rocchio algorithm achieves a performance comparable with that of the hierarchical neural networks.},
journal = {Inf. Retr.},
month = jan,
pages = {87–118},
numpages = {32},
keywords = {automatic text categorization, applied neural networks, hierarchical classifiers}
}

@article{10.1023/A:1012778807438,
author = {Kuriyama, Kazuko and Kando, Noriko and Nozue, Toshihiko and Eguchi, Koji},
title = {Pooling for a Large-Scale Test Collection: An Analysis of the Search Results from the First NTCIR Workshop},
year = {2002},
issue_date = {January 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1012778807438},
doi = {10.1023/A:1012778807438},
abstract = {We have conducted a study to: (1) verify the exhaustiveness of pooling for the purpose of constructing a large-scale test collection, and (2) examine whether a difference in the number of pool documents can affect the relative evaluation of IR systems. We carried out the experiments using search topics, their relevance assessments, and the search results that were submitted for both the pre-test and test of the first NTCIR Workshop.Our results verified the efficiency and the effectiveness of the pooling method, the exhaustiveness of the relevance assessments, and the reliability of the evaluation using the test collection based on the pooling method.},
journal = {Inf. Retr.},
month = jan,
pages = {41–59},
numpages = {19},
keywords = {exhaustiveness of pooling, test collection, evaluation methodology, IR system, relevance assessment}
}

@article{10.1023/A:1012730924277,
author = {Chen, Zhixiang and Zhu, Binhai},
title = {Some Formal Analysis of Rocchio's Similarity-Based Relevance Feedback Algorithm},
year = {2002},
issue_date = {January 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1012730924277},
doi = {10.1023/A:1012730924277},
abstract = {Rocchio's similarity-based Relevance feedback algorithm, one of the most important query reformation methods in information retrieval, is essentially an adaptive supervised learning algorithm from examples. In spite of its popularity in various applications there is little rigorous analysis of its learning complexity in literature. In this paper we show that in the binary vector space model, if the initial query vector is  0 , then for any of the four typical similarities (inner product, dice coefficient, cosine coefficient, and Jaccard coefficient), Rocchio's similarity-based relevance feedback algorithm makes at least i&gt;n mistakes when used to search for a collection of documents represented by a monotone disjunction of at most i&gt;k relevant features (or terms) over the i&gt;n-dimensional binary vector space {0, 1}i&gt;n. When an arbitrary initial query vector in {0, 1}i&gt;n is used, it makes at least (i&gt;n + i&gt;k \'{y} 3)/2 mistakes to search for the same collection of documents. The linear lower bounds are independent of the choices of the threshold and coefficients that the algorithm may use in updating its query vector and making its classification.},
journal = {Inf. Retr.},
month = jan,
pages = {61–86},
numpages = {26},
keywords = {supervised learning, vector space, lower bound, relevance feedback, similarity}
}

@article{10.1023/A:1012714523368,
author = {Ko\l{}cz, Aleksander and Alspector, Joshua},
title = {Asymmetric Missing-Data Problems: Overcoming the Lack of Negative Data in Preference Ranking},
year = {2002},
issue_date = {January 2002},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1012714523368},
doi = {10.1023/A:1012714523368},
abstract = {In certain classification problems there is a strong a asymmetry between the number of labeled examples available for each of the classes involved. In an extreme case, there may be a complete lack of labeled data for one of the classes while, at the same time, there are adequate labeled examples for the others, accompanied by a large body of unlabeled data. Since most classification algorithms require some information about all classes involved, label estimation for the un-represented class is desired. An important representative of this group of problems is that of user interest/preference modeling where there may be a large number of examples of what the user likes with essentially no counterexamples.Recently, there has been much interest in applying the EM algorithm to incomplete data problems in the area of text retrieval and categorization. We adapt this approach to the asymmetric case of modeling user interests in news articles, where only labeled positive training data are available, with access to a large corpus of unlabeled documents. User modeling is here equivalent to that of user-specific document ranking. EM is used in conjunction with the Naive Bayes model while its output is also utilized by a Support Vector Machine and Rocchio's technique.Our findings demonstrate that the EM algorithm can be quite effective in modeling the negative class under a number of different initialization schemes. Although primarily just the negative training examples are needed, a natural question is whether using all of the estimated labels (i.e., positive and negative) would be more (or less) beneficial. This is important considering that, in this context, the initialization of the negative class for EM is likely not to be very accurate. Experimental results suggest that EM output should be limited to negative label estimates only.},
journal = {Inf. Retr.},
month = jan,
pages = {5–40},
numpages = {36},
keywords = {user modeling, incomplete data problems, imbalanced training data, personalization, information retrieval}
}

@article{10.5555/593964.594032,
author = {Vakkari, Pertti},
title = {Changes in Search Tactics and Relevance Judgements When Preparing a Research Proposal A Summary of the Findings of a Longitudinal Study},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
abstract = {The article summarizes the empirical results on relations between students' problem stages in the course of writing their research proposals for their master's theses and the information sought, choice of search terms and tactics and relevance assessments of the information found for that task. The study is based on Kuhlthau's model of the information search process. The results of the study show that there is a close connection between the students' problem stages (mental model) in the task performance and the information sought, search tactics used, and the assessment of the relevance and utility of the information found. The corroborated hypotheses extend and specify ideas in Kuhlthau's model in the domain of IR. A theory of task-based information searching based on the empirical findings of the study is presented.},
journal = {Inf. Retr.},
month = sep,
pages = {295–310},
numpages = {16},
keywords = {a theory of information retrieval, tasks, relevance, usefullness on information, search tactics}
}

@article{10.1023/A:1011998222190,
author = {J\"{a}rvelin, Kalervo and Kek\"{a}l\"{a}inen, Jaana and Niemi, Timo},
title = {ExpansionTool: Concept-Based Query Expansion and Construction},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011998222190},
doi = {10.1023/A:1011998222190},
abstract = {We develop a deductive data model for concept-based query expansion. It is based on three abstraction levels: the conceptual, linguistic and string levels. Concepts and relationships among them are represented at the conceptual level. The linguistic level gives natural language expressions for concepts. Each expression has one or more matching patterns at the string level. The models specify the matching of the expression in database indices built in varying ways. The data model supports a declarative concept-based query expansion and formulation tool, the ExpansionTool, for heterogeneous IR system environments. Conceptual expansion is implemented by a novel intelligent operator for traversing transitive relationships among cyclic concept networks. The number of expansion links followed, their types, and weights can be used to control expansion. A sample empirical experiment illustrating the use of the ExpansionTool in IR experiments is presented.},
journal = {Inf. Retr.},
month = sep,
pages = {231–255},
numpages = {25},
keywords = {deductive data model, ontology, concept-based information retrieval, conceptual models, query formulation}
}

@article{10.1023/A:1011994105352,
author = {Pirkola, Ari and Hedlund, Turid and Keskustalo, Heikki and J\"{a}rvelin, Kalervo},
title = {Dictionary-Based Cross-Language Information Retrieval: Problems, Methods, and Research Findings},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011994105352},
doi = {10.1023/A:1011994105352},
abstract = {This paper reviews literature on dictionary-based cross-language information retrieval (CLIR) and presents CLIR research done at the University of Tampere (UTA). The main problems associated with dictionary-based CLIR, as well as appropriate methods to deal with the problems are discussed. We will present the structured query model by Pirkola and report findings for four different language pairs concerning the effectiveness of query structuring. The architecture of our automatic query translation and construction system is presented.},
journal = {Inf. Retr.},
month = sep,
pages = {209–230},
numpages = {22},
keywords = {cross-language information retrieval, structured queries, dictionary-based translation}
}

@article{10.1023/A:1011980920373,
author = {Kek\"{a}l\"{a}inen, Jaana},
title = {Information Retrieval Special Issue: Conceptual, Linguistic and Task-Based IR: Research at the University of Tampere},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011980920373},
doi = {10.1023/A:1011980920373},
journal = {Inf. Retr.},
month = sep,
pages = {191–194},
numpages = {4}
}

@article{10.1023/A:1011954407169,
author = {Markkula, Marjo and Tico, Marius and Sepponen, Bemmu and Nirkkonen, Katja and Sormunen, Eero},
title = {A Test Collection for the Evaluation of Content-Based Image Retrieval Algorithms—A User and Task-Based Approach},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011954407169},
doi = {10.1023/A:1011954407169},
abstract = {Content-based image retrieval (CBIR) algorithms have been seen as a promising access method for digital photograph collections. Unfortunately, we have very little evidence of the usefulness of these algorithms in real user needs and contexts. In this paper, we introduce a test collection for the evaluation of CBIR algorithms. In the test collection, the performance testing is based on photograph similarity perceived by end-users in the context of realistic illustration tasks and environment. The building process and the characteristics of the resulting test collection are outlined, including a typology of similarity criteria expressed by the subjects judging the similarity of photographs. A small-scale study on the consistency of similarity assessments is presented. A case evaluation of two CBIR algorithms is reported. The results show clear correlation between the subjects' similarity assessments and the functioning of feature parameters of the tested algorithms.},
journal = {Inf. Retr.},
month = sep,
pages = {275–293},
numpages = {19},
keywords = {evaluation, test collections, content-based image retrieval, user needs}
}

@article{10.1023/A:1011950323099,
author = {Sormunen, Eero},
title = {Extensions to the STAIRS Study—Empirical Evidence for the Hypothesised Ineffectiveness of Boolean Queries in Large Full-Text Databases},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011950323099},
doi = {10.1023/A:1011950323099},
abstract = {The STAIRS study conducted by Blair and Maron in the mid-80's is a milestone in the history of IR evaluation. Blair and Maron made strong conclusion about the inadequacy of free-text searching large databases, and their study has been widely referred in the literature to justify the problems of effectiveness in IR systems. However, some critics of the study have plausibly pointed out that the ineffectiveness conclusions were not solidly based on empirical data.This paper introduces a new theoretical and empirical approach to study the problems of high recall searching in large databases and reports the results of a case experiment. The findings verify some of the hypothetical conclusions introduced in the STAIRS study, and expands the picture of falling performance. It is shown that low precision in high recall searching is unavoidable in exact-match Boolean searching since even major concepts are often expressed implicitly in relevant documents. The author suggests that the problem could be reduced in facet-based best-match searching.},
journal = {Inf. Retr.},
month = sep,
pages = {257–273},
numpages = {17},
keywords = {STAIRS study, full-text databases, Boolean queries, IR evaluation}
}

@article{10.1023/A:1011942104443,
author = {Alkula, Riitta},
title = {From Plain Character Strings to Meaningful Words: Producing Better Full Text Databases for Inflectional and Compounding Languages with Morphological Analysis Software},
year = {2001},
issue_date = {September-December 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {3–4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011942104443},
doi = {10.1023/A:1011942104443},
abstract = {The paper deals with linguistic processing and retrieval techniques in fulltext databases. Special attention is focused on the characteristics of highly inflectional languages, and how morphological structure of a language should be taken into account, when designing and developing information retrieval systems. Finnish is used as an example of a language, which has a more complicated inflectional structure than the English language. In the FULLTEXT project, natural language analysis modules for Finnish were incorporated into the commercial BASIS information retrieval system, which is based on inverted files and Boolean searching. Several test databases were produced, each using one or two Finnish morphological analysis programs.},
journal = {Inf. Retr.},
month = sep,
pages = {195–208},
numpages = {14},
keywords = {natural language processing, full text retrieval, stemming, morphology}
}

@article{10.5555/593963.594025,
author = {Kantor, Paul B.},
title = {Book Reviews},
year = {2001},
issue_date = {July 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {2},
issn = {1386-4564},
journal = {Inf. Retr.},
month = jul,
pages = {175–181},
numpages = {7}
}

@article{10.1023/A:1011471129047,
author = {Lopresti, Daniel P.},
title = {A Comparison of Text-Based Methods for Detecting Duplication in Scanned Document Databases},
year = {2001},
issue_date = {July 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011471129047},
doi = {10.1023/A:1011471129047},
abstract = {This paper presents an experimental evaluation of several text-based methods for detecting duplication in scanned document databases using uncorrected OCR output. This task is made challenging both by the wide range of degradations printed documents can suffer, and by conflicting interpretations of what it means to be a “duplicate.” We report results for four sets of experiments exploring various aspects of the problem space. While the techniques studied are generally robust in the face of most types of OCR errors, there are nonetheless important differences which we identify and discuss in detail.},
journal = {Inf. Retr.},
month = jul,
pages = {153–173},
numpages = {21},
keywords = {optical character recognition, duplicate detection, approximate string matching, information retrieval, document analysis}
}

@article{10.1023/A:1011466928139,
author = {Kim, Jee-Hyub and Kwak, Byung-Kwan and Lee, Seungwoo and Lee, Geunbae and Lee, Jong-Hyeok},
title = {A Corpus-Based Learning Method of Compound Noun Indexing Rules for Korean},
year = {2001},
issue_date = {July 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011466928139},
doi = {10.1023/A:1011466928139},
abstract = {In Korean information retrieval, compound nouns play an important role in improving precision in search experiments. There are two major approaches to compound noun indexing in Korean: statistical and linguistic. Each method, however, has its own shortcomings, such as limitations when indexing diverse types of compound nouns, over-generation of compound nouns, and data sparseness in training. In this paper, we propose a corpus-based learning method, which can index diverse types of compound nouns using rules automatically extracted from a large corpus. The automatic learning method is more portable and requires less human effort, although it exhibits a performance level similar to the manual-linguistic approach. We also present a new filtering method to solve the problems of compound noun over-generation and data sparseness.},
journal = {Inf. Retr.},
month = jul,
pages = {115–132},
numpages = {18},
keywords = {corpus-based learning, information retrieval, filtering, compound noun indexing, search performance evaluation}
}

@article{10.1023/A:1011458711300,
author = {Benkhalifa, Mohammed and Mouradi, Abdelhak and Bouyakhf, Houssaine},
title = {Integrating External Knowledge to Supplement Training Data in Semi-Supervised Learning for Text Categorization},
year = {2001},
issue_date = {July 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011458711300},
doi = {10.1023/A:1011458711300},
abstract = {Text Categorization (TC) is the automated assignment of text documents to predefined categories based on document contents. TC has been an application for many learning approaches, which prove effective. Nevertheless, TC provides many challenges to machine learning. In this paper, we suggest, for text categorization, the integration of external WordNet lexical information to supplement training data for a semi-supervised clustering algorithm which can learn from both training and test documents to classify new unseen documents. This algorithm is the “Semi-Supervised Fuzzy c-Means” (ssFCM). Our experiments use Reuters 21578 database and consist of binary classifications for categories selected from the 115 TOPICS classes of the Reuters collection. Using the Vector Space Model, each document is represented by its original feature vector augmented with external feature vector generated using WordNet. We verify experimentally that the integration of WordNet helps ssFCM improve its performance, effectively addresses the classification of documents into categories with few training documents and does not interfere with the use of training data.},
journal = {Inf. Retr.},
month = jul,
pages = {91–113},
numpages = {23},
keywords = {text categorization, vector space model, Reuters Database, WordNet lexical database, semi supervised Fuzzy c Means}
}

@article{10.1023/A:1011419012209,
author = {Goldberg, Ken and Roeder, Theresa and Gupta, Dhruv and Perkins, Chris},
title = {Eigentaste: A Constant Time Collaborative Filtering Algorithm},
year = {2001},
issue_date = {July 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011419012209},
doi = {10.1023/A:1011419012209},
abstract = {Eigentaste is a collaborative filtering algorithm that uses i&gt;universal queries to elicit real-valued user ratings on a common set of items and applies principal component analysis (PCA) to the resulting dense subset of the ratings matrix. PCA facilitates dimensionality reduction for offline clustering of users and rapid computation of recommendations. For a database of i&gt;n users, standard nearest-neighbor techniques require i&gt;O(i&gt;n) processing time to compute recommendations, whereas Eigentaste requires i&gt;O(1) (constant) time. We compare Eigentaste to alternative algorithms using data from i&gt;Jester, an online joke recommending system.Jester has collected approximately 2,500,000 ratings from 57,000 users. We use the Normalized Mean Absolute Error (NMAE) measure to compare performance of different algorithms. In the Appendix we use Uniform and Normal distribution models to derive analytic estimates of NMAE when predictions are random. On the Jester dataset, Eigentaste computes recommendations two orders of magnitude faster with no loss of accuracy. Jester is online at: http://eigentaste.berkeley.edu},
journal = {Inf. Retr.},
month = jul,
pages = {133–151},
numpages = {19},
keywords = {collaborative filtering, recommender systems, dimensionality reduction, jokes}
}

@article{10.1023/A:1011476409104,
author = {Liddy, Elizabeth},
title = {Advances in Automatic Text Summarization},
year = {2001},
issue_date = {April 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011476409104},
doi = {10.1023/A:1011476409104},
journal = {Inf. Retr.},
month = apr,
pages = {82–83},
numpages = {2}
}

@article{10.1023/A:1011472308196,
author = {Hersh, William},
title = {Managing Gigabytes—Compressing and Indexing Documents and Images (Second Edition)},
year = {2001},
issue_date = {April 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011472308196},
doi = {10.1023/A:1011472308196},
journal = {Inf. Retr.},
month = apr,
pages = {79–80},
numpages = {2}
}

@article{10.1023/A:1011468107287,
author = {Hawking, David and Craswell, Nick and Bailey, Peter and Griffihs, Kathleen},
title = {Measuring Search Engine Quality},
year = {2001},
issue_date = {April 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011468107287},
doi = {10.1023/A:1011468107287},
abstract = {The effectiveness of twenty public search engines is evaluated using TREC-inspired methods and a set of 54 queries taken from real Web search logs. The World Wide Web is taken as the test collection and a combination of crawler and text retrieval system is evaluated. The engines are compared on a range of measures derivable from binary relevance judgments of the first seven live results returned. Statistical testing reveals a significant difference between engines and high intercorrelations between measures. Surprisingly, given the dynamic nature of the Web and the time elapsed, there is also a high correlation between results of this study and a previous study by Gordon and Pathak. For nearly all engines, there is a gradual decline in precision at increasing cutoff after some initial fluctuation. Performance of the engines as a group is found to be inferior to the group of participants in the TREC-8 Large Web task, although the best engines approach the median of those systems. Shortcomings of current Web search evaluation methodology are identified and recommendations are made for future improvements. In particular, the present study and its predecessors deal with queries which are assumed to derive from a need to find a selection of documents relevant to a topic. By contrast, real Web search reflects a range of other information need types which require different judging and different measures.},
journal = {Inf. Retr.},
month = apr,
pages = {33–59},
numpages = {27},
keywords = {search engines, Web search, evaluation}
}

@article{10.1023/A:1011441423217,
author = {Zhang, Tong and J. Oles, Frank},
title = {Text Categorization Based on Regularized Linear Classification Methods},
year = {2001},
issue_date = {April 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011441423217},
doi = {10.1023/A:1011441423217},
abstract = {A number of linear classification methods such as the linear least squares fit (LLSF), logistic regression, and support vector machines (SVM's) have been applied to text categorization problems. These methods share the similarity by finding hyperplanes that approximately separate a class of document vectors from its complement. However, support vector machines are so far considered special in that they have been demonstrated to achieve the state of the art performance. It is therefore worthwhile to understand whether such good performance is unique to the SVM design, or if it can also be achieved by other linear classification methods. In this paper, we compare a number of known linear classification methods as well as some variants in the framework of regularized linear systems. We will discuss the statistical and numerical properties of these algorithms, with a focus on text categorization. We will also provide some numerical experiments to illustrate these algorithms on a number of datasets.},
journal = {Inf. Retr.},
month = apr,
pages = {5–31},
numpages = {27},
keywords = {linear classification, regularization, text categorization}
}

@article{10.1023/A:1011424425034,
author = {Kantor, Paul},
title = {Foundations of Statistical Natural Language Processing},
year = {2001},
issue_date = {April 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011424425034},
doi = {10.1023/A:1011424425034},
journal = {Inf. Retr.},
month = apr,
pages = {80–81},
numpages = {2}
}

@article{10.1023/A:1011420324125,
author = {Zhang, Jin},
title = {The Characteristic Analysis of the DARE Visual Space},
year = {2001},
issue_date = {April 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {4},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1011420324125},
doi = {10.1023/A:1011420324125},
abstract = {In this paper a distance-angle-based visual retrieval tool i&gt;DARE is introduced. The distance-based similarity distribution, angle-based similarity distribution, and the differences of their distributions in the visual space are analyzed. The document cluster analysis in the visual space and the document cluster comparison between the document space and the visual space are addressed. A new conceptDistance to Reference Axisis introduced to better understand the visual space. The impact of other operations in DARE on the document distribution is discussed. Future research directions including significance of the index term distribution in the visual space and a user study are addressed.},
journal = {Inf. Retr.},
month = apr,
pages = {61–78},
numpages = {18},
keywords = {angle-base similarity measure, DARE, visualization for information retrieval, Visual space analysis, distance-based similarity measure}
}

@article{10.1023/A:1009986331526,
author = {Liddy, Elizabeth D. and Diamond, Ted and Mckenna, Mary},
title = {DR-LINK in TIPSTER III},
year = {2000},
issue_date = {December 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009986331526},
doi = {10.1023/A:1009986331526},
abstract = {A Natural Language Processing based Information Retrieval System that was one of the original systems developed in Phase I of TIPSTER, was the basis of research in TIPSTER III the goal of which was to add two extended capabilities to the core system. Following a description of the multiple levels of linguistic processing that were developed for the original DR-LINK System, details are provided on research into query-specific data fusion and query-specific cross-document summarization. Experimental results show that there is potential for improving retrieval through query-specific fusion and that analysts found the Detailed Multiple Document Summary to be extremely useful for almost every query, while the Thumbnail sketch was useful in approximately 50% of the queries.},
journal = {Inf. Retr.},
month = dec,
pages = {291–311},
numpages = {21},
keywords = {natural language processing, automatic summarization, data fusion, information retrieval}
}

@article{10.1023/A:1009955715597,
author = {Kwok, K. L.},
title = {Improving English and Chinese Ad-Hoc Retrieval: A Tipster Text Phase 3 Project Report},
year = {2000},
issue_date = {December 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009955715597},
doi = {10.1023/A:1009955715597},
abstract = {Both English and Chinese ad-hoc information retrieval were investigated in this Tipster 3 project. Part of our objectives is to study the use of various term level and phrasal level evidence to improve retrieval accuracy. For short queries, we studied five term level techniques that together can lead to good improvements over standard ad-hoc 2-stage retrieval for TREC5-8 experiments. For long queries, we studied the use of linguistic phrases to re-rank retrieval lists. Its effect is small but consistently positive.For Chinese IR, we investigated three simple representations for documents and queries: short-words, bigrams and characters. Both approximate short-word segmentation or bigrams, augmented with characters, give highly effective results. Accurate word segmentation appears not crucial for overall result of a query set. Character indexing by itself is not competitive. Additional improvements may be obtained using collection enrichment and combination of retrieval lists.Our PIRCS document-focused retrieval is also shown to have similarity with a simple language model approach to IR.},
journal = {Inf. Retr.},
month = dec,
pages = {313–338},
numpages = {26},
keywords = {language model and PIRCS retrieval model, pseudo-relevance feedback, ad-hoc two-stage retrieval, segmentation and Chinese IR, collection enrichment}
}

@article{10.1023/A:1009911900286,
author = {Yager, Ronald R.},
title = {A Hierarchical Document Retrieval Language},
year = {2000},
issue_date = {December 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009911900286},
doi = {10.1023/A:1009911900286},
abstract = {The focus of this work is on the development of a document retrieval language which attempts to enable users to better represent their requirements with respect to retrieved documents. We describe a framework for evaluating documents which allows, in the spirit of computing with words, a linguistic specification of the interrelationship between the desired attributes. This framework, which makes considerable use of the Ordered Weighted Averaging (OWA) operator, also supports a hierarchical structure which allows for an increased expressiveness of queries.},
journal = {Inf. Retr.},
month = dec,
pages = {357–377},
numpages = {21},
keywords = {aggregation methods, hierarchical concepts, concept formation, information retrieval}
}

@article{10.1023/A:1009907816505,
author = {Davis, Mark W. and Ogden, William C.},
title = {Towards Universal Text Retrieval: Tipster Text Retrieval Research at New Mexico State University},
year = {2000},
issue_date = {December 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009907816505},
doi = {10.1023/A:1009907816505},
abstract = {New Mexico State University's Computing Research Lab has participated in research in all three phases of the US Government's Tipster program. Our work on information retrieval has focused on research and development of multilingual and cross-language approaches to automatic retrieval. The work on automatic systems has been supplemented by additional research into the role of the IR system user in interactive retrieval scenarios: monolingual, multilingual and cross-language. The combined efforts suggest that “universal” text retrieval, in which a user can find, access and use documents in the face of language differences and information overload, may be possible.},
journal = {Inf. Retr.},
month = dec,
pages = {339–356},
numpages = {18},
keywords = {user studies, multilingual retrieval, unicode, interactive retrieval, cross-language retrieval}
}

@article{10.1023/A:1026572910743,
author = {Baumgarten, Christoph},
title = {Retrieving Information from a Distributed Heterogeneous Document Collection},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026572910743},
doi = {10.1023/A:1026572910743},
abstract = {This paper describes a probabilistic model for optimum information retrieval in a distributed heterogeneous environment.The model assumes the collection of documents offered by the environment to be partitioned into subcollections. Documents as well as subcollections have to be indexed, where indexing methods using different indexing vocabularies can be employed. A query provided by a user is answered in terms of a ranked list of documents. The model determines a procedure for ranking the documents that stems from the Probability Ranking Principle: For each subcollection, the subcollection's documents are ranked; the resulting ranked lists are combined into a final ranked list of documents, where the ordering is determined by the documents' probabilities of being relevant with respect to the user's query. Various probabilistic ranking methods may be involved in the distributed ranking process. A criterion for effectively limiting the ranking process to a subset of subcollections extends the model.The property that different ranking methods and indexing vocabularies can be used is important when the subcollections are heterogeneous with respect to their content.The model's applicability is experimentally confirmed. When exploiting the degrees of freedom provided by the model, experiments showed evidence that the model even outperforms comparable models for the non-distributed case with respect to retrieval effectiveness.},
journal = {Inf. Retr.},
month = oct,
pages = {253–271},
numpages = {19},
keywords = {heterogeneity, distributed information retrieval, probability ranking principle}
}

@article{10.1023/A:1026568809834,
author = {Csillaghy, A. and Hinterberger, H. and Benz, A. O.},
title = {Content-Based Image Retrieval in Astronomy},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026568809834},
doi = {10.1023/A:1026568809834},
abstract = {Content-based image retrieval in astronomy needs methods that can deal with an image content made of noisy and diffuse structures. This motivates investigations on how information should be summarized and indexed for this specific kind of images. The method we present first summarizes the image information content by partitioning the image in regions with same texture. We call this process texture summarization. Second, indexing features are generated by examining the distribution of parameters describing image regions. Indexing features can be associated with global or local image characteristics. Both kinds of indexing features are evaluated on the retrieval system of the Zurich archive of solar radio spectrograms. The evaluation shows that generating local indexing features using self-organizing maps yields the best effectiveness of all tested methods.},
journal = {Inf. Retr.},
month = oct,
pages = {229–241},
numpages = {13},
keywords = {image feature indexing, self-organizing maps, astronomy, image archives}
}

@article{10.1023/A:1026564708926,
author = {Mittendorf, Elke and Sch\"{a}uble, Peter},
title = {Information Retrieval Can Cope with Many Errors},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026564708926},
doi = {10.1023/A:1026564708926},
abstract = {The retrieval of documents that originate from digitized and OCR-converted paper documents is an important task for modern retrieval systems. The problems that OCR errors cause for the retrieval process have been subject to research for several years now. We approach the problem from a theoretical point of view and model OCR conversion as a random experiment. Our theoretical results, which are supported by experiments, show clearly that information retrieval can cope even with many errors. It is, however, important that the documents are not too short and that recognition errors are distributed appropriately among words and documents. These results disclose that an expensive manual or automatic post-processing of OCR-converted documents usually does not make sense, but that scanning and OCR must be performed in an appropriate way and with care.},
journal = {Inf. Retr.},
month = oct,
pages = {189–216},
numpages = {28},
keywords = {optical character recognition, probabilistic modelling, data corruption, retrieval effectiveness}
}

@article{10.1023/A:1026560608017,
author = {Sch\"{a}uble, Peter and Mittendorf, Elke},
title = {Introduction},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026560608017},
doi = {10.1023/A:1026560608017},
journal = {Inf. Retr.},
month = oct,
pages = {171–172},
numpages = {2}
}

@article{10.1023/A:1026525127581,
author = {Braschler, Martin and Sch\"{a}uble, Peter},
title = {Using Corpus-Based Approaches in a System for Multilingual Information Retrieval},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026525127581},
doi = {10.1023/A:1026525127581},
abstract = {We present a system for multilingual information retrieval that allows users to formulate queries in their preferred language and retrieve relevant information from a collection containing documents in multiple languages. The system is based on a process of document level alignments, where documents of different languages are paired according to their similarity. The resulting mapping allows us to produce a multilingual comparable corpus. Such a corpus has multiple interesting applications. It allows us to build a data structure for query translation in cross-language information retrieval (CLIR). Moreover, we also perform pseudo relevance feedback on the alignments to improve our retrieval results. And finally, multiple retrieval runs can be merged into one unified result list. The resulting system is inexpensive, adaptable to domain-specific collections and new languages and has performed very well at the TREC-7 conference CLIR system comparison.},
journal = {Inf. Retr.},
month = oct,
pages = {273–284},
numpages = {12},
keywords = {cross-language information retrieval, document alignments, multilingual information retrieval, corpus-based approaches}
}

@article{10.1023/A:1026520926673,
author = {Mittendorf, Elke and Mateev, Bojidar and Sch\"{a}uble, Peter},
title = {Using the Co-Occurrence of Words for Retrieval Weighting},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026520926673},
doi = {10.1023/A:1026520926673},
abstract = {We have applied the well-known Robertson-Sparck Jones weighting to sets of indexing features that are different from word-based features. Our features describe the co-occurrences of words in a window range of predefined size. The experiments have been designed to analyse the value of features that are beyond word-based features but all used retrieval methods can be motivated strictly in the probabilistic framework. Among the several implications of our experiments for weighted retrieval is the surprising result that features that describe the co-occurrences of words in sentence-size or paragraph-size windows are significantly better descriptors than purely word-based indexing features.},
journal = {Inf. Retr.},
month = oct,
pages = {243–251},
numpages = {9},
keywords = {word concurrences, term phase weighting, retrieval routing, probabilistic term weighting}
}

@article{10.1023/A:1026516825764,
author = {Wechsler, Martin and Sch\"{a}uble, Peter},
title = {The Probability Ranking Principle Revisited},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026516825764},
doi = {10.1023/A:1026516825764},
abstract = {A theoretic framework for multimedia information retrieval is introduced which guarantees optimal retrieval effectiveness. In particular, a Ranking Principle for Distributed Multimedia-Documents (RPDM) is described together with an algorithm that satisfies this principle. Finally, the RPDM is shown to be a generalization of the Probability Ranking principle (PRP) which guarantees optimal retrieval effectiveness in the case of text document retrieval. The PRP justifies theoretically the relevance ranking adopted by modern search engines. In contrast to the classical PRP, the new RPDM takes into account transmission and inspection time, and most importantly, aspectual recall rather than simple recall.},
journal = {Inf. Retr.},
month = oct,
pages = {217–227},
numpages = {11},
keywords = {relevance ranking, multimedia information retrieval, optimal search performance, maximum retrieval effectiveness, probability ranking principle}
}

@article{10.1023/A:1026512724855,
author = {Wechsler, Martin and Munteanu, Eugen and Sch\"{a}uble, Peter},
title = {New Approaches to Spoken Document Retrieval},
year = {2000},
issue_date = {October 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1026512724855},
doi = {10.1023/A:1026512724855},
abstract = {This paper presents four novel techniques for open-vocabulary spoken document retrieval: a method to detect slots that possibly contain a query feature; a method to estimate occurrence probabilities; a technique that we call collection-wide probability re-estimation and a weighting scheme which takes advantage of the fact that long query features are detected more reliably. These four techniques have been evaluated using the TREC-6 spoken document retrieval test collection to determine the improvements in retrieval effectiveness with respect to a baseline retrieval method. Results show that the retrieval effectiveness can be improved considerably despite the large number of speech recognition errors.},
journal = {Inf. Retr.},
month = oct,
pages = {173–188},
numpages = {16},
keywords = {spoken document retrieval, speech recognition, retrieval effectiveness}
}

@article{10.1023/A:1009953814988,
author = {McCallum, Andrew Kachites and Nigam, Kamal and Rennie, Jason and Seymore, Kristie},
title = {Automating the Construction of Internet Portals with Machine Learning},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009953814988},
doi = {10.1023/A:1009953814988},
abstract = {Domain-specific internet portals are growing in popularity because they gather content from the Web and organize it for easy access, retrieval and search. For example, www.campsearch.com allows complex queries by age, location, cost and specialty over summer camps. This functionality is not possible with general, Web-wide search engines. Unfortunately these portals are difficult and time-consuming to maintain. This paper advocates the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific Internet portals. We describe new research in reinforcement learning, information extraction and text classification that enables efficient spidering, the identification of informative text segments, and the population of topic hierarchies. Using these techniques, we have built a demonstration system: a portal for computer science research papers. It already contains over 50,000 papers and is publicly available at www.cora.justresearch.com. These techniques are widely applicable to portal creation in other domains.},
journal = {Inf. Retr.},
month = jul,
pages = {127–163},
numpages = {37},
keywords = {text classification, expectation-maximization, unlabeled data, hidden Markov models, information extraction, reinforcement learning, naive Bayes, spidering, crawling}
}

@article{10.1023/A:1009942513170,
author = {Wermter, Stefan},
title = {Neural Network Agents for Learning Semantic Text Classification},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009942513170},
doi = {10.1023/A:1009942513170},
abstract = {The research project AgNeT develops Agents for Neural Text routing in the internet. Unrestricted potentially faulty text messages arrive at a certain delivery point (e.g. email address or world wide web address). These text messages are scanned and then distributed to one of several expert agents according to a certain task criterium. Possible specific scenarios within this framework include the learning of the routing of publication titles or news titles. In this paper we describe extensive experiments for semantic text routing based on classified library titles and newswire titles. This task is challenging since incoming messages may contain constructions which have not been anticipated. Therefore, the contributions of this research are in learning and generalizing neural architectures for the robust interpretation of potentially noisy unrestricted messages. Neural networks were developed and examined for this topic since they support robustness and learning in noisy unrestricted real-world texts. We describe and compare different sets of experiments. The first set of experiments tests a recurrent neural network for the task of library title classification. Then we describe a larger more difficult newswire classification task from information retrieval. The comparison of the examined models demonstrates that techniques from information retrieval integrated into recurrent plausibility networks performed well even under noise and for different corpora.},
journal = {Inf. Retr.},
month = jul,
pages = {87–103},
numpages = {17},
keywords = {news agent, text classification, neural networks, machine learning, recurrent plausibility network}
}

@article{10.1023/A:1009901830009,
author = {Moghrabi, I. A. R. and Makholian, R. A.},
title = {A New Approach to Clustering Records in Information Retrieval Systems},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009901830009},
doi = {10.1023/A:1009901830009},
abstract = {This work introduces a new approach to record clustering where a hybrid algorithm is presented to cluster records based upon threshold values and the query patterns made to a particular database. The Hamming Distance of a file is used as a measure of space density. The objective of the algorithm is to minimize the Hamming Distance of the file while attaching significance to the most frequent queries being asked. Simulation experiments conducted proved that a great reduction in response time is yielded after the restructuring of a file. We study the space density properties of a file and how it affects retrieval time before and after clustering, as a means of predicting file performance and making appropriate choices of parameters. Criteria, such as, block size, threshold value, percentage of records satisfying a given set of queries, etc., which affect clustering and response time are also studied.},
journal = {Inf. Retr.},
month = jul,
pages = {105–126},
numpages = {22},
keywords = {information retrieval, database systems, statistical analysis, clustering}
}

@article{10.1023/A:1013002601898,
author = {Moffat, Alistair and Stuiver, Lang},
title = {Binary Interpolative Coding for Effective Index Compression},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1013002601898},
doi = {10.1023/A:1013002601898},
abstract = {Information retrieval systems contain large volumes of text, and currently have typical sizes into the gigabyte range. Inverted indexes are one important method for providing search facilities into these collections, but unless compressed require a great deal of space. In this paper we introduce a new method for compressing inverted indexes that yields excellent compression, fast decoding, and exploits clustering—the tendency for words to appear relatively frequently in some parts of the collection and infrequently in others. We also describe two other quite separate applications for the same compression method: representing the MTF list positions generated by the Burrows-Wheeler Block Sorting transformation; and transmitting the codebook for semi-static block-based minimum-redundancy coding.},
journal = {Inf. Retr.},
month = jul,
pages = {25–47},
numpages = {23},
keywords = {document database, context-based model, index compression}
}

@article{10.1023/A:1009973300990,
author = {Zobel, Justin},
title = {Guest Introduction},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009973300990},
doi = {10.1023/A:1009973300990},
journal = {Inf. Retr.},
month = jul,
pages = {5–6},
numpages = {2}
}

@article{10.1023/A:1009934302807,
author = {Navarro, Gonzalo and De Moura, Edleno Silva and Neubert, Marden and Ziviani, Nivio and Baeza-Yates, Ricardo},
title = {Adding Compression to Block Addressing Inverted Indexes},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009934302807},
doi = {10.1023/A:1009934302807},
abstract = {Inverted index compression, block addressing and sequential search on compressed text are three techniques that have been separately developed for efficient, low-overhead text retrieval. Modern text compression techniques can reduce the text to less than 30% of its size and allow searching it directly and faster than the uncompressed text. Inverted index compression obtains significant reduction of its original size at the same processing speed. Block addressing makes the inverted lists point to text blocks instead of exact positions and pay the reduction in space with some sequential text scanning.In this work we combine the three ideas in a single scheme. We present a compressed inverted file that indexes compressed text and uses block addressing. We consider different techniques to compress the index and study their performance with respect to the block size. We compare the index against three separate techniques for varying block sizes, showing that our index is superior to each isolated approach. For instance, with just 4% of extra space overhead the index has to scan less than 12% of the text for exact searches and about 20% allowing one error in the matches.},
journal = {Inf. Retr.},
month = jul,
pages = {49–77},
numpages = {29},
keywords = {text compression, block addressing, text databases, inverted files}
}

@article{10.1023/A:1009910017828,
author = {Klein, Shmuel T.},
title = {Skeleton Trees for the Efficient Decoding of Huffman Encoded Texts},
year = {2000},
issue_date = {July 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009910017828},
doi = {10.1023/A:1009910017828},
abstract = {A new data structure is investigated, which allows fast decoding of texts encoded by canonical Huffman codes. The storage requirements are much lower than for conventional Huffman trees, O(log ^2 n) for trees of depth O(log n), and decoding is faster, because a part of the bit-comparisons necessary for the decoding may be saved. Empirical results on large real-life distributions show a reduction of up to 50% and more in the number of bit operations. The basic idea is then generalized, yielding further savings.},
journal = {Inf. Retr.},
month = jul,
pages = {7–23},
numpages = {17},
keywords = {skeleton trees, canonical Huffman codes, decoding, Huffman trees}
}

@article{10.1023/A:1009976227802,
author = {Turney, Peter D.},
title = {Learning Algorithms for Keyphrase Extraction},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009976227802},
doi = {10.1023/A:1009976227802},
abstract = {Many academic journals ask their authors to provide a list of about five to fifteen keywords, to appear on the first page of each article. Since these key words are often phrases of two or more words, we prefer to call them keyphrases. There is a wide variety of tasks for which keyphrases are useful, as we discuss in this paper. We approach the problem of automatically extracting keyphrases from text as a supervised learning task. We treat a document as a set of phrases, which the learning algorithm must learn to classify as positive or negative examples of keyphrases. Our first set of experiments applies the C4.5 decision tree induction algorithm to this learning task. We evaluate the performance of nine different configurations of C4.5. The second set of experiments applies the GenEx algorithm to the task. We developed the GenEx algorithm specifically for automatically extracting keyphrases from text. The experimental results support the claim that a custom-designed algorithm (GenEx), incorporating specialized procedural domain knowledge, can generate better keyphrases than a general-purpose algorithm (C4.5). Subjective human evaluation of the keyphrases generated by GenEx suggests that about 80% of the keyphrases are acceptable to human readers. This level of performance should be satisfactory for a wide variety of applications.},
journal = {Inf. Retr.},
month = may,
pages = {303–336},
numpages = {34},
keywords = {indexing, keywords, summarization, keyphrase extraction, machine learning}
}

@article{10.1023/A:1009932512781,
author = {Jones, Gareth and Sakai, Tetsuya and Kajiura, Masahiro and Sumita, Kazuo},
title = {Incremental Relevance Feedback in Japanese Text Retrieval},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009932512781},
doi = {10.1023/A:1009932512781},
abstract = {The application of relevance feedback techniques has been shown to improve retrieval performance for a number of information retrieval tasks. This paper explores incremental relevance feedback for ad hoc Japanese text retrieval; examining, separately and in combination, the utility of term reweighting and query expansion using a probabilistic retrieval model. Retrieval performance is evaluated in terms of standard precision-recall measures, and also using “number-to-view” graphs. Experimental results, on the standard BMIR-J2 Japanese language retrieval collection, show that both term reweighting and query expansion improve retrieval performance. This is reflected in improvements in both precision and recall, but also a reduction in the average number of documents which must be viewed to find a selected number of relevant items. In particular, using a simple simulation of user searching, incremental application of relevance information is shown to lead to progressively improved retrieval performance and an overall reduction in the number of documents that a user must view to find relevant ones.},
journal = {Inf. Retr.},
month = may,
pages = {361–384},
numpages = {24},
keywords = {probabilistic retrieval, incremental relevance feedback, query expansion, term reweighting, number-to-view graphs, Japanese text}
}

@article{10.1023/A:1009928328710,
author = {Wondergem, B. C. M. and van Bommel, P. and van der Weide, Th. P.},
title = {Matching Index Expressions for Information Retrieval},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009928328710},
doi = {10.1023/A:1009928328710},
abstract = {The INN system is a dynamic hypertext tool for searching and exploring the WWW. It uses a dynamically built ancillary layer to support easy interaction. This layer features the subexpressions of index expressions that are extracted from rendered documents. Currently, the INN system uses keyword based matching. The effectiveness of the INN system may be increased by using matching functions for index expressions. In the design of such functions, several constraints stemming from the INN must be taken into account. Important constraints are a limited response time and storage space, a focus on discriminating (different notions of) subexpressions for index expressions, and domain independency. With these contextual constraints in mind, several matching functions are designed and both theoretically and practically evaluated.},
journal = {Inf. Retr.},
month = may,
pages = {337–360},
numpages = {24},
keywords = {information retrieval, index expressions, similarity, matching}
}

@article{10.1023/A:1009915010963,
author = {Hughey, M. K. and Berry, M. W.},
title = {Improved Query Matching Using Kd-Trees: A Latent Semantic Indexing Enhancement},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009915010963},
doi = {10.1023/A:1009915010963},
abstract = {Efficient information searching and retrieval methods are needed to navigate the ever increasing volumes of digital information. Traditional lexical information retrieval methods can be inefficient and often return inaccurate results. To overcome problems such as polysemy and synonymy, concept-based retrieval methods have been developed. One such method is Latent Semantic Indexing (LSI), a vector-space model, which uses the singular value decomposition (SVD) of a term-by-document matrix to represent terms and documents in k-dimensional space. As with other vector-space models, LSI is an attempt to exploit the underlying semantic structure of word usage in documents. During the query matching phase of LSI, a user's query is first projected into the term-document space, and then compared to all terms and documents represented in the vector space. Using some similarity measure, the nearest (most relevant) terms and documents are identified and returned to the user. The current LSI query matching method requires that the similarity measure be computed between the query and every term and document in the vector space. In this paper, the kd-tree searching algorithm is used within a recent LSI implementation to reduce the time and computational complexity of query matching. The kd-tree data structure stores the term and document vectors in such a way that only those terms and documents that are most likely to qualify as nearest neighbors to the query will be examined and retrieved.},
journal = {Inf. Retr.},
month = may,
pages = {287–302},
numpages = {16},
keywords = {latent semantic indexing, kd-trees, query matching, vector-space model}
}

@article{10.1023/A:1009962928226,
author = {Srihari, Rohini K. and Zhang, Zhongfei and Rao, Aibing},
title = {Intelligent Indexing and Semantic Retrieval of Multimodal Documents},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009962928226},
doi = {10.1023/A:1009962928226},
abstract = {Finding useful information from large multimodal document collections such as the WWW without encountering numerous false positives poses a challenge to multimedia information retrieval systems (MMIR). This research addresses the problem of finding pictures. The fact that images do not appear in isolation, but rather with accompanying, collateral text is exploited. Taken independently, existing techniques for picture retrieval using (i) text-based and (ii) image-based methods have several limitations. This research presents a general model for multimodal information retrieval that addresses the following issues: (i) users' information need, (ii) expressing information need through composite, multimodal queries, and (iii) determining the most appropriate weighted combination of indexing techniques in order to best satisfy information need. A machine learning approach is proposed for the latter. The focus is on improving precision and recall in a MMIR system by optimally combining text and image similarity. Experiments are presented which demonstrate the utility of individual indexing systems in improving overall average precision.},
journal = {Inf. Retr.},
month = may,
pages = {245–275},
numpages = {31},
keywords = {text indexing, image indexing, content-based retrieval, multimodal query processing, multimedia information retrieval}
}

@article{10.1023/A:1009958827317,
author = {Williams, William J. and Zalubas, Eugene J. and Hero, Alfred O.},
title = {Word Spotting in Bitmapped Fax Documents},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009958827317},
doi = {10.1023/A:1009958827317},
abstract = {Images and signals may be represented by forms invariant to time shifts, spatial shifts, frequency shifts, and scale changes. Advances in time-frequency analysis and scale transform techniques have made this possible. However, factors such as noise contamination and “style” differences complicate this. An example is found in text, where letters and words may vary in size and position. Examples of complicating variations include the font used, corruption during facsimile (fax) transmission, and printer characteristics. The solution advanced in this paper is to cast the desired invariants into separate subspaces for each extraneous factor or group of factors. The first goal is to have minimal overlap between these subspaces and the second goal is to be able to identify each subspace accurately. Concepts borrowed from high-resolution spectral analysis, but adapted uniquely to this problem have been found to be useful in this context. Once the pertinent subspace is identified, the recognition of a particular invariant form within this subspace is relatively simple using well-known singular value decomposition (SVD) techniques. The basic elements of the approach can be applied to a variety of pattern recognition problems. The specific application covered in this paper is word spotting in bitmapped fax documents.},
journal = {Inf. Retr.},
month = may,
pages = {207–226},
numpages = {20},
keywords = {scale, invariant, word spotting, position, facsimile}
}

@article{10.1023/A:1009958408662,
author = {Baird, Henry S. and Chen, Francine R.},
title = {Introduction},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009958408662},
doi = {10.1023/A:1009958408662},
journal = {Inf. Retr.},
month = may,
pages = {139–140},
numpages = {2}
}

@article{10.1023/A:1009954710479,
author = {Lopresti, Daniel and Zhou, Jiangying},
title = {Locating and Recognizing Text in WWW Images},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009954710479},
doi = {10.1023/A:1009954710479},
abstract = {The explosive growth of the World Wide Web has resulted in a distributed database consisting of hundreds of millions of documents. While existing search engines index a page based on the text that is readily extracted from its HTML encoding, an increasing amount of the information on the Web is embedded in images. This situation presents a new and exciting challenge for the fields of document analysis and information retrieval, as WWW image text is typically rendered in color and at very low spatial resolutions. In this paper, we survey the results of several years of our work in the area. For the problem of locating text in Web images, we describe a procedure based on clustering in color space followed by a connected-components analysis that seems promising. For character recognition, we discuss techniques using polynomial surface fitting and “fuzzy” n-tuple classifiers. Also presented are the results of several experiments that demonstrate where our methods perform well and where more work needs to be done. We conclude with a discussion of topics for further research.},
journal = {Inf. Retr.},
month = may,
pages = {177–206},
numpages = {30},
keywords = {document analysis, WWW image text, optical character recognition, information retrieval}
}

@article{10.1023/A:1009950525500,
author = {Mitra, M. and Chaudhuri, B. B.},
title = {Information Retrieval from Documents: A Survey},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009950525500},
doi = {10.1023/A:1009950525500},
abstract = {Given the phenomenal growth in the variety and quantity of data available to users through electronic media, there is a great demand for efficient and effective ways to organize and search through all this information. Besides speech, our principal means of communication is through visual media, and in particular, through documents. In this paper, we provide an update on Doermann's comprehensive survey (1998) of research results in the broad area of document-based information retrieval. The scope of this survey is also somewhat broader, and there is a greater emphasis on relating document image analysis methods to conventional IR methods.Documents are available in a wide variety of formats. Technical papers are often available as ASCII files of clean, correct, text. Other documents may only be available as hardcopies. These documents have to be scanned and stored as images so that they may be processed by a computer. The textual content of these documents may also be extracted and recognized using OCR methods. Our survey covers the broad spectrum of methods that are required to handle different formats like text and images. The core of the paper focuses on methods that manipulate document images directly, and perform various information processing tasks such as retrieval, categorization, and summarization, without attempting to completely recognize the textual content of the document. We start, however, with a brief overview of traditional IR techniques that operate on clean text. We also discuss research dealing with text that is generated by running OCR on document images. Finally, we also briefly touch on the related problem of content-based image retrieval.},
journal = {Inf. Retr.},
month = may,
pages = {141–163},
numpages = {23},
keywords = {document image analysis, image retrieval, optical character recognition, text retrieval}
}

@article{10.1023/A:1009910911387,
author = {Hu, Jianying and Kashi, Ramanujan and Wilfong, Gordon},
title = {Comparison and Classification of Documents Based on Layout Similarity},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009910911387},
doi = {10.1023/A:1009910911387},
abstract = {This paper describes features and methods for document image comparison and classification at the spatial layout level. The methods are useful for visual similarity based document retrieval as well as fast algorithms for initial document type classification without OCR. A novel feature set called interval encoding is introduced to capture elements of spatial layout. This feature set encodes region layout information in fixed-length vectors by capturing structural characteristics of the image. These fixed-length vectors are then compared to each other through a Manhattan distance computation for fast page layout comparison. The paper describes experiments and results to rank-order a set of document pages in terms of their layout similarity to a test document. We also demonstrate the usefulness of the features derived from interval coding in a hidden Markov model based page layout classification system that is trainable and extendible. The methods described in the paper can be used in various document retrieval tasks including visual similarity based retrieval, categorization and information extraction.},
journal = {Inf. Retr.},
month = may,
pages = {227–243},
numpages = {17},
keywords = {edit distance, Manhattan distance, document retrieval, hidden Markov models, dynamic warping, clustering, document classification}
}

@article{10.1023/A:1009902609570,
author = {Kantor, Paul B. and Voorhees, Ellen M.},
title = {The TREC-5 Confusion Track: Comparing Retrieval Methods for Scanned Text},
year = {2000},
issue_date = {May 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {2–3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009902609570},
doi = {10.1023/A:1009902609570},
abstract = {A known-item search is a particular information retrieval task in which the system is asked to find a single target document in a large document set. The TREC-5 confusion track used a set of 49 known-item tasks to study the impact of data corruption on retrieval system performance. Two corrupted versions of a 55,600 document corpus whose true content was known were created by applying OCR techniques to page images. The first version of the corpus used the page images as scanned, resulting in an estimated character error rate of approximately 5%. The second version used page images that had been down-sampled, resulting in an estimated character error rate of approximately 20%. The true text and each of the corrupted versions were then searched using the same set of 49 questions. In general, retrieval methods that attempted a probabilistic reconstruction of the original clean text fared better than methods that simply accepted corrupted versions of the query text.},
journal = {Inf. Retr.},
month = may,
pages = {165–176},
numpages = {12},
keywords = {optical character recognition (OCR), text retrieval, evaluation, TREC}
}

@article{10.1023/A:1009998002873,
author = {Ruthven, Ian},
title = {Incorporating Aspects of Information Use into Relevance Feedback},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009998002873},
doi = {10.1023/A:1009998002873},
abstract = {In this paper we look at some of the problems in interacting with
best-match retrieval systems. In particular, we examine the areas of
interaction, some investigations of the complexity and breadth of
interaction and attempts to categorise user's information seeking
behaviour. We suggest that one of the difficulties of traditional IR
systems in supporting information seeking is the way the information
content of documents is represented. We discuss an alternative
representation, based on how information is used within
documents.},
journal = {Inf. Retr.},
month = feb,
pages = {83–88},
numpages = {6},
keywords = {relevance feedback, information seeking, interaction}
}

@article{10.1023/A:1009989801965,
author = {Adriani, Mirna},
title = {Using Statistical Term Similarity for Sense Disambiguationin Cross-Language Information Retrieval},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009989801965},
doi = {10.1023/A:1009989801965},
abstract = {With the increasing availability of machine-readable
bilingual dictionaries, dictionary-based automatic query translation
has become a viable approach to Cross-Language Information Retrieval
(CLIR). In this approach, resolving term ambiguity is a crucial step.
We propose a sense disambiguation technique based on a
term-similarity measure for selecting the right translation sense of
a query term. In addition, we apply a query expansion technique which
is also based on the term similarity measure to improve the
effectiveness of the translation queries. The results of our
Indonesian to English and English to Indonesian CLIR experiments
demonstrate the effectiveness of the sense disambiguation technique.
As for the query expansion technique, it is shown to be effective as
long as the term ambiguity in the queries has been resolved. In the
effort to solve the term ambiguity problem, we discovered that
differences in the pattern of word-formation between the two
languages render query translations from one language to the other
difficult.},
journal = {Inf. Retr.},
month = feb,
pages = {71–82},
numpages = {12},
keywords = {term disambiguation, cross-language information retrieval}
}

@article{10.1023/A:1009973415168,
author = {Crestani, Fabio},
title = {Exploiting the Similarity of Non-Matching Terms at RetrievalTime},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009973415168},
doi = {10.1023/A:1009973415168},
abstract = {In classic Information Retrieval systems a relevant
document will not be retrieved in response to a query if the document
and query representations do not share at least one term. This
problem, known as “term mismatch”, has been recognised for a long
time by the Information Retrieval community and a number of possible
solutions have been proposed. Here I present a preliminary
investigation into a new class of retrieval models that attempt to
solve the term mismatch problem by exploiting complete or partial
knowledge of term similarity in the term space. The use of term
similarity enables to enhance classic retrieval models by taking into
account non-matching terms. The theoretical advantages and drawbacks
of these models are presented and compared with other models tackling
the same problem. A preliminary experimental investigation into the
performance gain achieved by exploiting term similarity with the
proposed models is presented and discussed.},
journal = {Inf. Retr.},
month = feb,
pages = {27–47},
numpages = {21},
keywords = {term similarity, information retrieval, retrieval model, term mismatch problem}
}

@article{10.1023/A:1009969229281,
author = {van Rijsbergen, C. J.},
title = {Another Look at the Logical Uncertainty Principle},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009969229281},
doi = {10.1023/A:1009969229281},
abstract = {The Logical Uncertainty Principle is
re-examined from the point of classical logic. Two interpretations
are given, an objective one in terms of an axiomatic theory of information,
and a subjective one based on Ramsey‘s theory of probability.},
journal = {Inf. Retr.},
month = feb,
pages = {17–26},
numpages = {10},
keywords = {information theory, information retrieval model, Ramsey test, uncertainty, Bayesian inference}
}

@article{10.1023/A:1009933700147,
author = {Sanderson, Mark},
title = {Retrieving with Good Sense},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009933700147},
doi = {10.1023/A:1009933700147},
abstract = {Although always present in text, word sense
ambiguity only recently became regarded as a
problem to information retrieval which was
potentially solvable. The growth of interest in
word senses resulted from new directions taken in
disambiguation research. This paper first outlines
this research and surveys the resulting efforts in
information retrieval. Although the majority of
attempts to improve retrieval effectiveness were
unsuccessful, much was learnt from the research.
Most notably a notion of under what circumstance
disambiguation may prove of use to retrieval.},
journal = {Inf. Retr.},
month = feb,
pages = {49–69},
numpages = {21},
keywords = {information retrieval, word sense ambiguity, word sense disambiguation, stemming}
}

@article{10.1023/A:1009906420620,
author = {Reid, Jane},
title = {A Task-Oriented Non-Interactive Evaluation Methodologyfor Information Retrieval Systems},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009906420620},
doi = {10.1023/A:1009906420620},
abstract = {Past research has identified many different types of
relevance in information retrieval (IR). So far, however, most
evaluation of IR systems has been through batch experiments conducted
with test collections containing only expert, topical relevance
judgements. Recently, there has been some movement away from this
traditional approach towards interactive, more user-centred methods
of evaluation. However, these are expensive for evaluators in terms
both of time and of resources. This paper describes a new evaluation
methodology, using a task-oriented test collection, which combines
the advantages of traditional non-interactive testing with a more
user-centred emphasis. The main features of a task-oriented test
collection are the adoption of the task, rather than the query, as
the primary unit of evaluation and the naturalistic character of the
relevance judgements.},
journal = {Inf. Retr.},
month = feb,
pages = {115–129},
numpages = {15},
keywords = {user-centred evaluation, test collection, nature of relevance, task framework}
}

@article{10.1023/A:1009905228372,
author = {Dunlop, Mark and Lalmas, Mounia},
title = {Introduction},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009905228372},
doi = {10.1023/A:1009905228372},
journal = {Inf. Retr.},
month = feb,
pages = {9–15},
numpages = {7}
}

@article{10.1023/A:1009902203782,
author = {Campbell, Iain},
title = {Interactive Evaluation of the Ostensive ModelUsing a New Test Collection of Images with Multiple Relevance Assessments},
year = {2000},
issue_date = {February 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {2},
number = {1},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009902203782},
doi = {10.1023/A:1009902203782},
abstract = {The Ostensive Model proposes a manner of structuring
the uncertainty associated with individual relevance
judgements as sources of evidence in relevance feedback. It
proposes temporal profiles of uncertainty, motivating the application
of a particular class of discount function with respect to the age of
the evidence. This paper presents an initial evaluation of the relative
effectiveness of different uncertainty discount functions.A novel direct manipulation interface to a multimedia
retrieval system embodying the Ostensive Model is outlined briefly. The
paper describes the construction and
characteristics of a new image test collection utilising multiple
binary relevance assessments. The use of such multiple assessments
and multiple interpretations of them are discussed. The evaluation
environment is detailed in terms of the
interface, test collection, and tasks set to users. Multiple
interpretations of the results, and the statistical significance
of comparisons are presented.The results obtained in the evaluation are consistent
with the proposals of the
Ostensive Model—reinforcing a particular evidence profile. The
results give clear pointers to further, more specific, evaluations.},
journal = {Inf. Retr.},
month = feb,
pages = {89–114},
numpages = {26},
keywords = {fisheye, evidence discounting, relevance feedback, Ostensive Model, image test collection, browsing, interactive evaluation, ostension}
}

@article{10.1023/A:1009995816485,
author = {Markkula, Marjo and Sormunen, Eero},
title = {End-User Searching Challenges Indexing Practices Inthe Digital Newspaper Photo Archive},
year = {2000},
issue_date = {January 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009995816485},
doi = {10.1023/A:1009995816485},
abstract = {Previous research in conceptual indexing methods of images
has furnished us with refined
theoretical frameworks characterising various aspects of
images that could and should be indexed
using textual descriptors. The development of digital image
processing technologies has bred a
brigade of content-based indexing and retrieval methods
available for applications. What the users
need and in what kinds of environments different indexing and
retrieval methods are relevant, has
remained an area of less intensive research work.This article presents the results of a field study
concentrating on journalists as users of a
digital newspaper photo archive. The expressed photo needs,
applied selection criteria and
observed searching behaviours in journalists' daily work were
contrasted with the indexing
practices applied by the archivists. The results showed that
the journalists achieved satisfactory
results when trivial query terms were available, e.g. when
photos of named persons were needed.
Browsing was the main searching strategy applied by the
journalists, but the system did not
support browsing well. The access problems faced by the users
in particular photo needs are discussed in detail. The paper
concludes by discussing the potential approaches in developing both
the concept-based and content-based indexing methods as well
as the user interfaces in photo retrieval systems.},
journal = {Inf. Retr.},
month = jan,
pages = {259–285},
numpages = {27},
keywords = {indexing practices, user needs, newspaper photographs, image retrieval, searching behavior}
}

@article{10.1023/A:1009983401464,
author = {Kek\"{a}l\"{a}Inen, Jaana and J\"{a}rvelin, Kalervo},
title = {The Co-Effects of Query Structure and Expansion on RetrievalPerformance in Probabilistic Text Retrieval},
year = {2000},
issue_date = {January 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009983401464},
doi = {10.1023/A:1009983401464},
abstract = {The effects of query structures and query expansion (QE) on retrieval performance were tested with a best match retrieval system (InQuery ^1 ). Query structure means the use of operators to express the relations between search keys. Six different structures were tested, representing strong structures (e.g., queries with facets or concepts identified) and weak structures (no concepts identified, a query is ‘a bag of search keys'). QE was based on concepts, which were first selected from a searching thesaurus, and then expanded by semantic relationships given in the thesaurus. The expansion levels were (a) no expansion, (b) a synonym expansion, (c) a narrower concept expansion, (d) an associative concept expansion, and (e) a cumulative expansion of all other expansions. With weak structures and Boolean structured queries, QE was not very effective. The best performance was achieved with a combination of a facet structure, where search keys within a facet were treated as instances of one search key (the SYN operator), and the largest expansion.},
journal = {Inf. Retr.},
month = jan,
pages = {329–344},
numpages = {16},
keywords = {query structures, text retrieval, query expansion, concept-based query formulation, semantic conceptual relationships}
}

@article{10.1023/A:1009979200555,
author = {Frost, C. Olivia and Taylor, Bradley and Noakes, Anna and Markel, Stephen and Torres, Deborah and Drabenstott, Karen M.},
title = {Browse and Search Patterns in a Digital Image Database},
year = {2000},
issue_date = {January 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009979200555},
doi = {10.1023/A:1009979200555},
abstract = {A prototype image retrieval system with browse and search
capabilities was developed to investigate patterns of searching a
collection of digital visual images, as well as factors, such as
image size, resolution, and download speed, which affect browsing.
The subject populations were art history specialists and
non-specialists. Through focus group interviews, a controlled test,
post-test interviews and an online survey, data was gathered to
compare preferences and actual patterns of use in browsing and
searching. While specialists preferred direct search to browsing, and
generalists used browsing as their preferred mode, both user groups
found each mode to play a role depending on information need, and
found value in a system combining both browse and direct search.
There were no significant differences in performance among the search
modes of browse, search, and combined browse/search models when the
quasi-controlled study tested the different modes.},
journal = {Inf. Retr.},
month = jan,
pages = {287–313},
numpages = {27},
keywords = {user studies, image retrieval, browsing, digital images}
}

@article{10.1023/A:1009931317394,
author = {Bookstein, A. and Klein, St and Raita, T.},
title = {Simple Bayesian Model for Bitmap Compression},
year = {2000},
issue_date = {January 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009931317394},
doi = {10.1023/A:1009931317394},
abstract = {Bitmaps are a useful, but storage voracious, component of many
information retrieval systems. Earlier efforts to compress bitmaps
were based on models of bit generation, particularly Markov models.
While these permitted considerable reduction in storage, the short
memory of Markov models may limit their compression efficiency. In
this paper we accept the state orientation of Markov models, but
introduce a Bayesian approach to assess the state; the analysis is
based on data accumulating in a growing window. The paper describes
the details of the probabilistic assumptions governing the Bayesian
analysis, as well as the protocol for controlling the window that
receives the data. We find slight improvement over the best
performing strictly Markov models.},
journal = {Inf. Retr.},
month = jan,
pages = {315–328},
numpages = {14},
keywords = {concordances, bitmap compression, IR models, Markov modelling}
}

@article{10.1023/A:1009983522080,
author = {Weigend, Andreas S. and Wiener, Erik D. and Pedersen, Jan O.},
title = {Exploiting Hierarchy in Text Categorization},
year = {1999},
issue_date = {October 1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009983522080},
doi = {10.1023/A:1009983522080},
abstract = {With the recent dramatic increase in electronic access to
documents, text categorization—the task of assigning topics to a
given document—has moved to the center of the information sciences
and knowledge management. This article uses the structure that is
present in the semantic space of topics in order to improve
performance in text categorization: according to their meaning,
topics can be grouped together into “meta-topics”, e.g., gold,
silver, and copper are all metals. The proposed architecture matches
the hierarchical structure of the topic space, as opposed to a flat
model that ignores the structure. It accommodates both single and
multiple topic assignments for each document. Its probabilistic
interpretation allows its predictions to be combined in a principled
way with information from other sources. The first level of the
architecture predicts the probabilities of the meta-topic groups.
This allows the individual models for each topic on the second level
to focus on finer discriminations within the group. Evaluating the
performance of a two-level implementation on the Reuters-22173
testbed of newswire articles shows the most significant improvement
for rare classes.},
journal = {Inf. Retr.},
month = oct,
pages = {193–216},
numpages = {24},
keywords = {machine learning, neural networks, text categorization, text mining, problem decomposition, performance evaluation, information retrieval, hierarchical models, probabilistic models, topic spotting, knowledge management}
}

@article{10.1023/A:1009980820262,
author = {Vogt, Christopher C. and Cottrell, Garrison W.},
title = {Fusion Via a Linear Combination of Scores},
year = {1999},
issue_date = {October 1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009980820262},
doi = {10.1023/A:1009980820262},
abstract = {We present a thorough analysis of the capabilities of the linear
combination (LC) model for fusion of information retrieval systems.
The LC model combines the results lists of multiple IR systems by
scoring each document using a weighted sum of the scores from each of
the component systems. We first present both empirical and analytical
justification for the hypotheses that such a model should only be used
when the systems involved have high performance, a large overlap of
relevant documents, and a small overlap of nonrelevant documents. The
empirical approach allows us to very accurately predict the
performance of a combined system. We also derive a formula for a
theoretically optimal weighting scheme for combining 2 systems. We
introduce d—the difference between the average score on relevant
documents and the average score on nonrelevant documents—as a
performance measure which not only allows mathematical reasoning about
system performance, but also allows the selection of weights which
generalize well to new documents. We describe a number of experiments
involving large numbers of different IR systems which support these
findings.},
journal = {Inf. Retr.},
month = oct,
pages = {151–173},
numpages = {23},
keywords = {routing, performance evaluation, neural networks, linear combination, fusion}
}

@article{10.1023/A:1009939707058,
author = {Pirkola, Ari and Keskustalo, Heikki and J\"{a}rvelin, Kalervo},
title = {The Effects of Conjunction, Facet Structure, and Dictionary Combinations in Concept-Based Cross-Language Retrieval},
year = {1999},
issue_date = {October 1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009939707058},
doi = {10.1023/A:1009939707058},
abstract = {The paper studies concept-based cross-language information retrieval
(CLIR). The document collection was a subset of the TREC collection. The test
requests were formed from TREC‘s health related topics. As translation
dictionaries the study used a general dictionary and a domain-specific 
(=medical)
dictionary. The effects of translation method, conjunction, and facet order on
the effectiveness of concept-based cross-language queries were studied, and
concept-based structuring of cross-language queries was compared to mechanical
structuring based on the output of dictionaries. The performance of translated
Finnish queries against English documents was compared to the performance of
original English queries against the English documents, and the performance of
different CLIR query types was compared with one another. No major 
difference was
found between concept-based and mechanical structuring. The best translation
method was a simultaneous look-up in the medical dictionary and the general
dictionary, in which case cross-language queries performed as well as 
the original
English queries. The results showed that especially at high exhaustivity (the
number of mutually restrictive concepts in a request) levels cross-language
queries perform well in relation to monolingual queries. This suggests that
conjunction disambiguates cross-language queries. An extensive study 
was made of
the relative importance of the concepts of requests. On the basis of the
classification data of request concepts it was shown how the order 
of facets in a
query affects cross-language as well as monolingual queries.},
journal = {Inf. Retr.},
month = oct,
pages = {217–250},
numpages = {34},
keywords = {cross-language information retrieval, dictionary-based translation, Boolean conjuction, concept-based queries}
}

@article{10.1023/A:1009931404333,
author = {Boughanem, M. and Chrisment, C. and Tamine, L.},
title = {Genetic Approach to Query Space Exploration},
year = {1999},
issue_date = {October 1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {3},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009931404333},
doi = {10.1023/A:1009931404333},
abstract = {This paper describes a genetic algorithm approach for
intelligent information retrieval. The goal is to find an optimal set
of documents which best matches the user‘s needs by exploring and
exploiting the document space. More precisely, we define a specific
genetic algorithm for information retrieval based on knowledge based
operators and guided by a heuristic for relevance multi-modality
problem solving. Experiments with TREC-6 French data and queries
show the effectiveness of our approach.},
journal = {Inf. Retr.},
month = oct,
pages = {175–192},
numpages = {18},
keywords = {information retrieval, relevance feedback, genetic algorithm}
}

@article{10.1023/A:1009990414324,
author = {Kantor, Paul and Robertson, Steve},
title = {Editorial},
year = {1999},
issue_date = {1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009990414324},
doi = {10.1023/A:1009990414324},
journal = {Inf. Retr.},
month = may,
pages = {5},
numpages = {1}
}

@article{10.1023/A:1009984519381,
author = {Banks, David and Over, Paul and Zhang, Nien-Fan},
title = {Blind Men and Elephants: Six Approaches to TREC Data},
year = {1999},
issue_date = {1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009984519381},
doi = {10.1023/A:1009984519381},
abstract = {The paper reviews six recent efforts to better understand performance

measurements on information retrieval (IR) systems within the

framework of the Text REtrieval Conferences (TREC): analysis of

variance, cluster analyses, rank correlations, beadplots,

multidimensional scaling, and item response analysis. None of this

work has yielded any substantial new insights. Prospects that

additional work along these lines will yield more interesting results

vary but are in general not promising. Some suggestions are made for

paying greater attention to richer descriptions of IR system behavior

but within smaller, better controlled settings.},
journal = {Inf. Retr.},
month = may,
pages = {7–34},
numpages = {28},
keywords = {multidimensional scaling, cluster analysis, rank correlation}
}

@article{10.1023/A:1009982220290,
author = {Yang, Yiming},
title = {An Evaluation of Statistical Approaches to Text Categorization},
year = {1999},
issue_date = {1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009982220290},
doi = {10.1023/A:1009982220290},
abstract = {This paper focuses on a comparative evaluation of a wide-range of

text categorization methods, including previously published results on the

Reuters corpus and new results of additional experiments. A

controlled study using three classifiers, kNN, LLSF and WORD, was

conducted to examine the impact of configuration variations in five

versions of Reuters on the observed performance of classifiers.

Analysis and empirical evidence suggest that the evaluation results on

some versions of Reuters were significantly affected by the inclusion

of a large portion of unlabelled documents, mading those results

difficult to interpret and leading to considerable confusions in the

literature. Using the results evaluated on the other versions of

Reuters which exclude the unlabelled documents, the performance of

twelve methods are compared directly or indirectly. For indirect

compararions, kNN, LLSF and WORD were used as baselines, since they

were evaluated on all versions of Reuters that exclude the unlabelled

documents. As a global observation, kNN, LLSF and a neural network

method had the best performance; except for a Naive Bayes approach,

the other learning algorithms also performed relatively well.},
journal = {Inf. Retr.},
month = may,
pages = {69–90},
numpages = {22},
keywords = {text categorization, evaluation, statistical learning algorithms, comparative study}
}

@article{10.1023/A:1009938405269,
author = {Hawking, David and Thistlewaite, Paul and Harman, Donna},
title = {Scaling Up the TREC Collection},
year = {1999},
issue_date = {1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009938405269},
doi = {10.1023/A:1009938405269},
abstract = {Due to the popularity of Web search engines, a large proportion of

real text retrieval queries are now processed over collections measured 

in tens or hundreds

of gigabytes. A new Very Large test Collection (VLC) has been created to

support qualification, measurement and comparison of systems operating

at this level and to permit the study of the properties of very large

collections. The VLC is an extension of the well-known TREC

collection and has been distributed under the same conditions.

A simple set of efficiency and effectiveness measures have been defined 

to encourage comparability of reporting.

The 20 gigabyte first-edition of the VLC and a representative 10%

sample have been used in a special interest track of the 1997 Text

Retrieval Conference (TREC-6).

The unaffordable cost of obtaining complete relevance

assessments over collections of this scale is avoided by concentrating

on early precision and relying on the core TREC collection to support

detailed effectiveness studies.

Results obtained by TREC-6 VLC track participants are presented here.

All groups observed a significant increase in early precision as 

collection size increased. Explanatory hypotheses are advanced for

future empirical testing. A 100 gigabyte second edition VLC (VLC2) has 

recently been compiled

and distributed for use in TREC-7 in 1998.},
journal = {Inf. Retr.},
month = may,
pages = {115–137},
numpages = {23},
keywords = {very large databases, test collection, text retrieval}
}

@article{10.1023/A:1009934321199,
author = {Melucci, Massimo},
title = {An Evaluation of Automatically Constructed Hypertexts for InformationRetrieval},
year = {1999},
issue_date = {1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009934321199},
doi = {10.1023/A:1009934321199},
abstract = {This paper assesses the retrieval effectiveness of

automatically constructed inter-document hypertext links in

Information Retrieval (IR). The objectives of the experiments

described are to obtain evidence concerning the usefulness of

querying and browsing automatically constructed IR hypertexts. Links

are built by using IR techniques, as these enable rapid, automatic

production of hypertexts from a document collection for accessing the

collection itself. These tests are carried out in a laboratory

environment and through simulation of link browsing. Results of

experiments show that browsing has little impact on the retrieval of

relevant documents if used in place of querying or relevance feedback

methods, though may be practical if used in combination with

them.},
journal = {Inf. Retr.},
month = may,
pages = {91–114},
numpages = {24},
keywords = {evaluation, automatic construction of hypertexts, statistical methods, hypertext/hypermedia}
}

@article{10.1023/A:1009930203452,
author = {Mani, Inderjeet and Bloedorn, Eric},
title = {Summarizing Similarities and Differences Among Related Documents},
year = {1999},
issue_date = {1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {1},
number = {1–2},
issn = {1386-4564},
url = {https://doi.org/10.1023/A:1009930203452},
doi = {10.1023/A:1009930203452},
abstract = {In many modern information retrieval applications, a common problem

which arises is the existence of multiple documents covering similar

information, as in the case of multiple news stories about an event or

a sequence of events. A particular challenge for text summarization is

to be able to summarize the similarities and differences in

information content among these documents. The approach

described here exploits the results of recent progress in information

extraction to represent salient units of text and their relationships.

By exploiting meaningful relations between units based on an

analysis of text cohesion and the context in which the

comparison is desired, the summarizer can pinpoint similarities and

differences, and align text segments. In evaluation experiments, these

techniques for exploiting cohesion relations result in summaries which

(i) help users more quickly complete a retrieval task (ii) result in

improved alignment accuracy over baselines, and (iii) improve

identification of topic-relevant similarities and differences.},
journal = {Inf. Retr.},
month = may,
pages = {35–67},
numpages = {33},
keywords = {text summarization, natural language processing, information retrieval}
}

