@inproceedings{10.1145/1553374.1553375,
author = {Adams, Ryan Prescott and Ghahramani, Zoubin},
title = {Archipelago: Nonparametric Bayesian Semi-Supervised Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553375},
doi = {10.1145/1553374.1553375},
abstract = {Semi-supervised learning (SSL), is classification where additional unlabeled data can be used to improve accuracy. Generative approaches are appealing in this situation, as a model of the data's probability density can assist in identifying clusters. Nonparametric Bayesian methods, while ideal in theory due to their principled motivations, have been difficult to apply to SSL in practice. We present a nonparametric Bayesian method that uses Gaussian processes for the generative model, avoiding many of the problems associated with Dirichlet process mixture models. Our model is fully generative and we take advantage of recent advances in Markov chain Monte Carlo algorithms to provide a practical inference method. Our method compares favorably to competing approaches on synthetic and real-world multi-class data.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1–8},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553376,
author = {Adams, Ryan Prescott and Murray, Iain and MacKay, David J. C.},
title = {Tractable Nonparametric Bayesian Inference in Poisson Processes with Gaussian Process Intensities},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553376},
doi = {10.1145/1553374.1553376},
abstract = {The inhomogeneous Poisson process is a point process that has varying intensity across its domain (usually time or space). For nonparametric Bayesian modeling, the Gaussian process is a useful way to place a prior distribution on this intensity. The combination of a Poisson process and GP is known as a Gaussian Cox process, or doubly-stochastic Poisson process. Likelihood-based inference in these models requires an intractable integral over an infinite-dimensional random function. In this paper we present the first approach to Gaussian Cox processes in which it is possible to perform inference without introducing approximations or finitedimensional proxy distributions. We call our method the Sigmoidal Gaussian Cox Process, which uses a generative model for Poisson data to enable tractable inference via Markov chain Monte Carlo. We compare our methods to competing methods on synthetic data and apply it to several real-world data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {9–16},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553377,
author = {Aiolli, Fabio and Da San Martino, Giovanni and Sperduti, Alessandro},
title = {Route Kernels for Trees},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553377},
doi = {10.1145/1553374.1553377},
abstract = {Almost all tree kernels proposed in the literature match substructures without taking into account their relative positioning with respect to one another. In this paper, we propose a novel family of kernels which explicitly focus on this type of information. Specifically, after defining a family of tree kernels based on routes between nodes, we present an efficient implementation for a member of this family. Experimental results on four different datasets show that our method is able to reach state of the art performances, obtaining in some cases performances better than computationally more demanding tree kernels.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {17–24},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553378,
author = {Andrzejewski, David and Zhu, Xiaojin and Craven, Mark},
title = {Incorporating Domain Knowledge into Topic Modeling via Dirichlet Forest Priors},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553378},
doi = {10.1145/1553374.1553378},
abstract = {Users of topic modeling methods often have knowledge about the composition of words that should have high or low probability in various topics. We incorporate such domain knowledge using a novel Dirichlet Forest prior in a Latent Dirichlet Allocation framework. The prior is a mixture of Dirichlet tree distributions with special structures. We present its construction, and inference via collapsed Gibbs sampling. Experiments on synthetic and real datasets demonstrate our model's ability to follow and generalize beyond user-specified domain knowledge.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {25–32},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553379,
author = {Bailly, Rapha\"{e}l and Denis, Fran\c{c}ois and Ralaivola, Liva},
title = {Grammatical Inference as a Principal Component Analysis Problem},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553379},
doi = {10.1145/1553374.1553379},
abstract = {One of the main problems in probabilistic grammatical inference consists in inferring a stochastic language, i.e. a probability distribution, in some class of probabilistic models, from a sample of strings independently drawn according to a fixed unknown target distribution p. Here, we consider the class of rational stochastic languages composed of stochastic languages that can be computed by multiplicity automata, which can be viewed as a generalization of probabilistic automata. Rational stochastic languages p have a useful algebraic characterization: all the mappings up: v → p(uv) lie in a finite dimensional vector subspace Vp* of the vector space ℝ 〈〈Σ〉〉 composed of all real-valued functions defined over Σ*. Hence, a first step in the grammatical inference process can consist in identifying the subspace Vp*. In this paper, we study the possibility of using Principal Component Analysis to achieve this task. We provide an inference algorithm which computes an estimate of this space and then build a multiplicity automaton which computes an estimate of the target distribution. We prove some theoretical properties of this algorithm and we provide results from numerical simulations that confirm the relevance of our approach.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {33–40},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553380,
author = {Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Collobert, Ronan and Weston, Jason},
title = {Curriculum Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553380},
doi = {10.1145/1553374.1553380},
abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them "curriculum learning". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {41–48},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553381,
author = {Beygelzimer, Alina and Dasgupta, Sanjoy and Langford, John},
title = {Importance Weighted Active Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553381},
abstract = {We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {49–56},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553382,
author = {Bouchard, Guillaume and Zoeter, Onno},
title = {Split Variational Inference},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553382},
doi = {10.1145/1553374.1553382},
abstract = {We propose a deterministic method to evaluate the integral of a positive function based on soft-binning functions that smoothly cut the integral into smaller integrals that are easier to approximate. In combination with mean-field approximations for each individual sub-part this leads to a tractable algorithm that alternates between the optimization of the bins and the approximation of the local integrals. We introduce suitable choices for the binning functions such that a standard mean field approximation can be extended to a split mean field approximation without the need for extra derivations. The method can be seen as a revival of the ideas underlying the mixture mean field approach. The latter can be obtained as a special case by taking soft-max functions for the binning.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {57–64},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553383,
author = {Boularias, Abdeslam and Chaib-draa, Brahim},
title = {Predictive Representations for Policy Gradient in POMDPs},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553383},
doi = {10.1145/1553374.1553383},
abstract = {We consider the problem of estimating the policy gradient in Partially Observable Markov Decision Processes (POMDPs) with a special class of policies that are based on Predictive State Representations (PSRs). We compare PSR policies to Finite-State Controllers (FSCs), which are considered as a standard model for policy gradient methods in POMDPs. We present a general Actor-Critic algorithm for learning both FSCs and PSR policies. The critic part computes a value function that has as variables the parameters of the policy. These latter parameters are gradually updated to maximize the value function. We show that the value function is polynomial for both FSCs and PSR policies, with a potentially smaller degree in the case of PSR policies. Therefore, the value function of a PSR policy can have less local optima than the equivalent FSC, and consequently, the gradient algorithm is more likely to converge to a global optimal solution.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {65–72},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553384,
author = {Boutilier, Craig and Regan, Kevin and Viappiani, Paolo},
title = {Online Feature Elicitation in Interactive Optimization},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553384},
doi = {10.1145/1553374.1553384},
abstract = {Most models of utility elicitation in decision support and interactive optimization assume a predefined set of "catalog" features over which user preferences are expressed. However, users may differ in the features over which they are most comfortable expressing their preferences. In this work we consider the problem of feature elicitation: a user's utility function is expressed using features whose definitions (in terms of "catalog" features) are unknown. We cast this as a problem of concept learning, but whose goal is to identify only enough about the concept to enable a good decision to be recommended. We describe computational procedures for identifying optimal alternatives w.r.t. minimax regret in the presence of concept uncertainty; and describe several heuristic query strategies that focus on reduction of relevant concept uncertainty.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {73–80},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553385,
author = {B\"{u}hler, Thomas and Hein, Matthias},
title = {Spectral Clustering Based on the Graph <i>p</i>-Laplacian},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553385},
abstract = {We present a generalized version of spectral clustering using the graph p-Laplacian, a nonlinear generalization of the standard graph Laplacian. We show that the second eigenvector of the graph p-Laplacian interpolates between a relaxation of the normalized and the Cheeger cut. Moreover, we prove that in the limit as p → 1 the cut found by thresholding the second eigenvector of the graph p-Laplacian converges to the optimal Cheeger cut. Furthermore, we provide an efficient numerical scheme to compute the second eigenvector of the graph p-Laplacian. The experiments show that the clustering found by p-spectral clustering is at least as good as normal spectral clustering, but often leads to significantly better results.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {81–88},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553386,
author = {Burl, Michael C. and Wang, Esther},
title = {Active Learning for Directed Exploration of Complex Systems},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553386},
doi = {10.1145/1553374.1553386},
abstract = {Physics-based simulation codes are widely used in science and engineering to model complex systems that would be infeasible to study otherwise. Such codes provide the highest-fidelity representation of system behavior, but are often so slow to run that insight into the system is limited. For example, conducting an exhaustive sweep over a d-dimensional input parameter space with k-steps along each dimension requires kd simulation trials (translating into kd CPU-days for one of our current simulations). An alternative is directed exploration in which the next simulation trials are cleverly chosen at each step. Given the results of previous trials, supervised learning techniques (SVM, KDE, GP) are applied to build up simplified predictive models of system behavior. These models are then used within an active learning framework to identify the most valuable trials to run next. Several active learning strategies are examined including a recently-proposed information-theoretic approach. Performance is evaluated on a set of thirteen synthetic oracles, which serve as surrogates for the more expensive simulations and enable the experiments to be replicated by other researchers.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {89–96},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553387,
author = {Busetto, Alberto Giovanni and Ong, Cheng Soon and Buhmann, Joachim M.},
title = {Optimized Expected Information Gain for Nonlinear Dynamical Systems},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553387},
doi = {10.1145/1553374.1553387},
abstract = {This paper addresses the problem of active model selection for nonlinear dynamical systems. We propose a novel learning approach that selects the most informative subset of time-dependent variables for the purpose of Bayesian model inference. The model selection criterion maximizes the expected Kullback-Leibler divergence between the prior and the posterior probabilities over the models. The proposed strategy generalizes the standard D-optimal design, which is obtained from a uniform prior with Gaussian noise. In addition, our approach allows us to determine an information halting criterion for model identification. We illustrate the benefits of our approach by differentiating between 18 published biochemical models of the TOR signaling pathway, a model selection problem in systems biology. By generating pivotal selection experiments, our strategy outperforms the standard Aoptimal, D-optimal and E-optimal sequential design techniques.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {97–104},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553388,
author = {Cai, Deng and Wang, Xuanhui and He, Xiaofei},
title = {Probabilistic Dyadic Data Analysis with Local and Global Consistency},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553388},
doi = {10.1145/1553374.1553388},
abstract = {Dyadic data arises in many real world applications such as social network analysis and information retrieval. In order to discover the underlying or hidden structure in the dyadic data, many topic modeling techniques were proposed. The typical algorithms include Probabilistic Latent Semantic Analysis (PLSA) and Latent Dirichlet Allocation (LDA). The probability density functions obtained by both of these two algorithms are supported on the Euclidean space. However, many previous studies have shown naturally occurring data may reside on or close to an underlying submanifold. We introduce a probabilistic framework for modeling both the topical and geometrical structure of the dyadic data that explicitly takes into account the local manifold structure. Specifically, the local manifold structure is modeled by a graph. The graph Laplacian, analogous to the Laplace-Beltrami operator on manifolds, is applied to smooth the probability density functions. As a result, the obtained probabilistic distributions are concentrated around the data manifold. Experimental results on real data sets demonstrate the effectiveness of the proposed approach.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {105–112},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553389,
author = {de Campos, Cassio P. and Zeng, Zhi and Ji, Qiang},
title = {Structure Learning of Bayesian Networks Using Constraints},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553389},
doi = {10.1145/1553374.1553389},
abstract = {This paper addresses exact learning of Bayesian network structure from data and expert's knowledge based on score functions that are decomposable. First, it describes useful properties that strongly reduce the time and memory costs of many known methods such as hill-climbing, dynamic programming and sampling variable orderings. Secondly, a branch and bound algorithm is presented that integrates parameter and structural constraints with data in a way to guarantee global optimality with respect to the score function. It is an any-time procedure because, if stopped, it provides the best current solution and an estimation about how far it is from the global solution. We show empirically the advantages of the properties and the constraints, and the applicability of the algorithm to large data sets (up to one hundred variables) that cannot be handled by other current methods (limited to around 30 variables).},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {113–120},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553390,
author = {Cesa-Bianchi, Nicol\`{o} and Gentile, Claudio and Orabona, Francesco},
title = {Robust Bounds for Classification via Selective Sampling},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553390},
doi = {10.1145/1553374.1553390},
abstract = {We introduce a new algorithm for binary classification in the selective sampling protocol. Our algorithm uses Regularized Least Squares (RLS) as base classifier, and for this reason it can be efficiently run in any RKHS. Unlike previous margin-based semi-supervised algorithms, our sampling condition hinges on a simultaneous upper bound on bias and variance of the RLS estimate under a simple linear label noise model. This fact allows us to prove performance bounds that hold for an arbitrary sequence of instances. In particular, we show that our sampling strategy approximates the margin of the Bayes optimal classifier to any desired accuracy ε by asking \~{O} (d/ε2) queries (in the RKHS case d is replaced by a suitable spectral quantity). While these are the standard rates in the fully supervised i.i.d. case, the best previously known result in our harder setting was \~{O} (d3/ε4). Preliminary experiments show that some of our algorithms also exhibit a good practical performance.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {121–128},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553391,
author = {Chaudhuri, Kamalika and Kakade, Sham M. and Livescu, Karen and Sridharan, Karthik},
title = {Multi-View Clustering via Canonical Correlation Analysis},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553391},
doi = {10.1145/1553374.1553391},
abstract = {Clustering data in high dimensions is believed to be a hard problem in general. A number of efficient clustering algorithms developed in recent years address this problem by projecting the data into a lower-dimensional subspace, e.g. via Principal Components Analysis (PCA) or random projections, before clustering. Here, we consider constructing such projections using multiple views of the data, via Canonical Correlation Analysis (CCA).Under the assumption that the views are un-correlated given the cluster label, we show that the separation conditions required for the algorithm to be successful are significantly weaker than prior results in the literature. We provide results for mixtures of Gaussians and mixtures of log concave distributions. We also provide empirical support from audio-visual speaker clustering (where we desire the clusters to correspond to speaker ID) and from hierarchical Wikipedia document clustering (where one view is the words in the document and the other is the link structure).},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {129–136},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553392,
author = {Chen, Jianhui and Tang, Lei and Liu, Jun and Ye, Jieping},
title = {A Convex Formulation for Learning Shared Structures from Multiple Tasks},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553392},
abstract = {Multi-task learning (MTL) aims to improve generalization performance by learning multiple related tasks simultaneously. In this paper, we consider the problem of learning shared structures from multiple related tasks. We present an improved formulation (iASO) for multi-task learning based on the non-convex alternating structure optimization (ASO) algorithm, in which all tasks are related by a shared feature representation. We convert iASO, a non-convex formulation, into a relaxed convex one, which is, however, not scalable to large data sets due to its complex constraints. We propose an alternating optimization (cASO) algorithm which solves the convex relaxation efficiently, and further show that cASO converges to a global optimum. In addition, we present a theoretical condition, under which cASO can find a globally optimal solution to iASO. Experiments on several benchmark data sets confirm our theoretical analysis.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {137–144},
numpages = {8}
}

@inbook{10.1145/1553374.1553393,
author = {Chen, Yihua and Gupta, Maya R. and Recht, Benjamin},
title = {Learning Kernels from Indefinite Similarities},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553393},
abstract = {Similarity measures in many real applications generate indefinite similarity matrices. In this paper, we consider the problem of classification based on such indefinite similarities. These indefinite kernels can be problematic for standard kernel-based algorithms as the optimization problems become non-convex and the underlying theory is invalidated. In order to adapt kernel methods for similarity-based learning, we introduce a method that aims to simultaneously find a reproducing kernel Hilbert space based on the given similarities and train a classifier with good generalization in that space. The method is formulated as a convex optimization problem. We propose a simplified version that can reduce overfitting and whose associated convex conic program can be solved efficiently. We compare the proposed simplified version with six other methods on a collection of real data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {145–152},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553394,
author = {Cheng, Chih-Chieh and Sha, Fei and Saul, Lawrence K.},
title = {Matrix Updates for Perceptron Training of Continuous Density Hidden Markov Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553394},
doi = {10.1145/1553374.1553394},
abstract = {In this paper, we investigate a simple, mistake-driven learning algorithm for discriminative training of continuous density hidden Markov models (CD-HMMs). Most CD-HMMs for automatic speech recognition use multivariate Gaussian emission densities (or mixtures thereof) parameterized in terms of their means and covariance matrices. For discriminative training of CD-HMMs, we reparameterize these Gaussian distributions in terms of positive semidefinite matrices that jointly encode their mean and covariance statistics. We show how to explore the resulting parameter space in CDHMMs with perceptron-style updates that minimize the distance between Viterbi decodings and target transcriptions. We experiment with several forms of updates, systematically comparing the effects of different matrix factorizations, initializations, and averaging schemes on phone accuracies and convergence rates. We present experimental results for context-independent CD-HMMs trained in this way on the TIMIT speech corpus. Our results show that certain types of perceptron training yield consistently significant and rapid reductions in phone error rates.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {153–160},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553395,
author = {Cheng, Weiwei and H\"{u}hn, Jens and H\"{u}llermeier, Eyke},
title = {Decision Tree and Instance-Based Learning for Label Ranking},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553395},
abstract = {The label ranking problem consists of learning a model that maps instances to total orders over a finite set of predefined labels. This paper introduces new methods for label ranking that complement and improve upon existing approaches. More specifically, we propose extensions of two methods that have been used extensively for classification and regression so far, namely instance-based learning and decision tree induction. The unifying element of the two methods is a procedure for locally estimating predictive probability models for label rankings.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {161–168},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553396,
author = {Cho, Youngmin and Saul, Lawrence K.},
title = {Learning Dictionaries of Stable Autoregressive Models for Audio Scene Analysis},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553396},
doi = {10.1145/1553374.1553396},
abstract = {In this paper, we explore an application of basis pursuit to audio scene analysis. The goal of our work is to detect when certain sounds are present in a mixed audio signal. We focus on the regime where out of a large number of possible sources, a small but unknown number combine and overlap to yield the observed signal. To infer which sounds are present, we decompose the observed signal as a linear combination of a small number of active sources. We cast the inference as a regularized form of linear regression whose sparse solutions yield decompositions with few active sources. We characterize the acoustic variability of individual sources by autoregressive models of their time domain waveforms. When we do not have prior knowledge of the individual sources, the coefficients of these autoregressive models must be learned from audio examples. We analyze the dynamical stability of these models and show how to estimate stable models by substituting a simple convex optimization for a difficult eigenvalue problem. We demonstrate our approach by learning dictionaries of musical notes and using these dictionaries to analyze polyphonic recordings of piano, cello, and violin.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {169–176},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553397,
author = {Choi, Myung Jin and Chandrasekaran, Venkat and Willsky, Alan S.},
title = {Exploiting Sparse Markov <i>and</i> Covariance Structure in Multiresolution Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553397},
doi = {10.1145/1553374.1553397},
abstract = {We consider Gaussian multiresolution (MR) models in which coarser, hidden variables serve to capture statistical dependencies among the finest scale variables. Tree-structured MR models have limited modeling capabilities, as variables at one scale are forced to be uncorrelated with each other conditioned on other scales. We propose a new class of Gaussian MR models that capture the residual correlations within each scale using sparse covariance structure. Our goal is to learn a tree-structured graphical model connecting variables across different scales, while at the same time learning sparse structure for the conditional covariance within each scale conditioned on other scales. This model leads to an efficient, new inference algorithm that is similar to multipole methods in computational physics.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {177–184},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553398,
author = {Cl\'{e}men\c{c}on, St\'{e}phan and Vayatis, Nicolas},
title = {Nonparametric Estimation of the Precision-Recall Curve},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553398},
doi = {10.1145/1553374.1553398},
abstract = {The Precision-Recall (PR) curve is a widely used visual tool to evaluate the performance of scoring functions in regards to their capacities to discriminate between two populations. The purpose of this paper is to examine both theoretical and practical issues related to the statistical estimation of PR curves based on classification data. Consistency and asymptotic normality of the empirical counterpart of the PR curve in sup norm are rigorously established. Eventually, the issue of building confidence bands in the PR space is considered and a specific resampling procedure based on a smoothed and truncated version of the empirical distribution of the data is promoted. Arguments of theoretical and computational nature are presented to explain why such a bootstrap is preferable to a "naive" bootstrap in this setup.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {185–192},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553399,
author = {Dai, Wenyuan and Jin, Ou and Xue, Gui-Rong and Yang, Qiang and Yu, Yong},
title = {EigenTransfer: A Unified Framework for Transfer Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553399},
doi = {10.1145/1553374.1553399},
abstract = {This paper proposes a general framework, called EigenTransfer, to tackle a variety of transfer learning problems, e.g. cross-domain learning, self-taught learning, etc. Our basic idea is to construct a graph to represent the target transfer learning task. By learning the spectra of a graph which represents a learning task, we obtain a set of eigenvectors that reflect the intrinsic structure of the task graph. These eigenvectors can be used as the new features which transfer the knowledge from auxiliary data to help classify target data. Given an arbitrary non-transfer learner (e.g. SVM) and a particular transfer learning task, EigenTransfer can produce a transfer learner accordingly for the target transfer learning task. We apply EigenTransfer on three different transfer learning tasks, cross-domain learning, cross-category learning and self-taught learning, to demonstrate its unifying ability, and show through experiments that EigenTransfer can greatly outperform several representative non-transfer learners.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {193–200},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553400,
author = {Daitch, Samuel I. and Kelner, Jonathan A. and Spielman, Daniel A.},
title = {Fitting a Graph to Vector Data},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553400},
abstract = {We introduce a measure of how well a combinatorial graph fits a collection of vectors. The optimal graphs under this measure may be computed by solving convex quadratic programs and have many interesting properties. For vectors in d dimensional space, the graphs always have average degree at most 2(d + 1), and for vectors in 2 dimensions they are always planar. We compute these graphs for many standard data sets and show that they can be used to obtain good solutions to classification, regression and clustering problems.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {201–208},
numpages = {8}
}

@inbook{10.1145/1553374.1553401,
author = {Daum\'{e}, Hal},
title = {Unsupervised Search-Based Structured Prediction},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553401},
abstract = {We describe an adaptation and application of a search-based structured prediction algorithm "Searn" to unsupervised learning problems. We show that it is possible to reduce unsupervised learning to supervised learning and demonstrate a high-quality un-supervised shift-reduce parsing model. We additionally show a close connection between unsupervised Searn and expectation maximization. Finally, we demonstrate the efficacy of a semi-supervised extension. The key idea that enables this is an application of the predict-self idea for unsupervised learning.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {209–216},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553402,
author = {Davis, Jesse and Domingos, Pedro},
title = {Deep Transfer via Second-Order Markov Logic},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553402},
doi = {10.1145/1553374.1553402},
abstract = {Standard inductive learning requires that training and test instances come from the same distribution. Transfer learning seeks to remove this restriction. In shallow transfer, test instances are from the same domain, but have a different distribution. In deep transfer, test instances are from a different domain entirely (i.e., described by different predicates). Humans routinely perform deep transfer, but few learning systems, if any, are capable of it. In this paper we propose an approach based on a form of second-order Markov logic. Our algorithm discovers structural regularities in the source domain in the form of Markov logic formulas with predicate variables, and instantiates these formulas with predicates from the target domain. Using this approach, we have successfully transferred learned knowledge among molecular biology, social network and Web domains. The discovered patterns include broadly useful properties of predicates, like symmetry and transitivity, and relations among predicates, such as various forms of homophily.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {217–224},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553403,
author = {Deisenroth, Marc Peter and Huber, Marco F. and Hanebeck, Uwe D.},
title = {Analytic Moment-Based Gaussian Process Filtering},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553403},
doi = {10.1145/1553374.1553403},
abstract = {We propose an analytic moment-based filter for nonlinear stochastic dynamic systems modeled by Gaussian processes. Exact expressions for the expected value and the covariance matrix are provided for both the prediction step and the filter step, where an additional Gaussian assumption is exploited in the latter case. Our filter does not require further approximations. In particular, it avoids finite-sample approximations. We compare the filter to a variety of Gaussian filters, that is, the EKF, the UKF, and the recent GP-UKF proposed by Ko et al. (2007).},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {225–232},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553404,
author = {Dekel, Ofer and Shamir, Ohad},
title = {Good Learners for Evil Teachers},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553404},
doi = {10.1145/1553374.1553404},
abstract = {We consider a supervised machine learning scenario where labels are provided by a heterogeneous set of teachers, some of which are mediocre, incompetent, or perhaps even malicious. We present an algorithm, built on the SVM framework, that explicitly attempts to cope with low-quality and malicious teachers by decreasing their influence on the learning process. Our algorithm does not receive any prior information on the teachers, nor does it resort to repeated labeling (where each example is labeled by multiple teachers). We provide a theoretical analysis of our algorithm and demonstrate its merits empirically. Finally, we present a second algorithm with promising empirical results but without a formal analysis.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {233–240},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553405,
author = {Deodhar, Meghana and Gupta, Gunjan and Ghosh, Joydeep and Cho, Hyuk and Dhillon, Inderjit},
title = {A Scalable Framework for Discovering Coherent Co-Clusters in Noisy Data},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553405},
doi = {10.1145/1553374.1553405},
abstract = {Clustering problems often involve datasets where only a part of the data is relevant to the problem, e.g., in microarray data analysis only a subset of the genes show cohesive expressions within a subset of the conditions/features. The existence of a large number of non-informative data points and features makes it challenging to hunt for coherent and meaningful clusters from such datasets. Additionally, since clusters could exist in different subspaces of the feature space, a co-clustering algorithm that simultaneously clusters objects and features is often more suitable as compared to one that is restricted to traditional "one-sided" clustering. We propose Robust Overlapping Co-Clustering (ROCC), a scalable and very versatile framework that addresses the problem of efficiently mining dense, arbitrarily positioned, possibly overlapping co-clusters from large, noisy datasets. ROCC has several desirable properties that make it extremely well suited to a number of real life applications.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {241–248},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553406,
author = {Diuk, Carlos and Li, Lihong and Leffler, Bethany R.},
title = {The Adaptive <i>k</i>-Meteorologists Problem and Its Application to Structure Learning and Feature Selection in Reinforcement Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553406},
doi = {10.1145/1553374.1553406},
abstract = {The purpose of this paper is three-fold. First, we formalize and study a problem of learning probabilistic concepts in the recently proposed KWIK framework. We give details of an algorithm, known as the Adaptive k-Meteorologists Algorithm, analyze its sample-complexity upper bound, and give a matching lower bound. Second, this algorithm is used to create a new reinforcement-learning algorithm for factored-state problems that enjoys significant improvement over the previous state-of-the-art algorithm. Finally, we apply the Adaptive k-Meteorologists Algorithm to remove a limiting assumption in an existing reinforcement-learning algorithm. The effectiveness of our approaches is demonstrated empirically in a couple benchmark domains as well as a robotics navigation problem.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {249–256},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553407,
author = {Do, Chuong B. and Le, Quoc V. and Foo, Chuan-Sheng},
title = {Proximal Regularization for Online and Batch Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553407},
doi = {10.1145/1553374.1553407},
abstract = {Many learning algorithms rely on the curvature (in particular, strong convexity) of regularized objective functions to provide good theoretical performance guarantees. In practice, the choice of regularization penalty that gives the best testing set performance may result in objective functions with little or even no curvature. In these cases, algorithms designed specifically for regularized objectives often either fail completely or require some modification that involves a substantial compromise in performance.We present new online and batch algorithms for training a variety of supervised learning models (such as SVMs, logistic regression, structured prediction models, and CRFs) under conditions where the optimal choice of regularization parameter results in functions with low curvature. We employ a technique called proximal regularization, in which we solve the original learning problem via a sequence of modified optimization tasks whose objectives are chosen to have greater curvature than the original problem. Theoretically, our algorithms achieve low regret bounds in the online setting and fast convergence in the batch setting. Experimentally, our algorithms improve upon state-of-the-art techniques, including Pegasos and bundle methods, on medium and large-scale SVM and structured learning tasks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {257–264},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553408,
author = {Do, Trinh-Minh-Tri and Arti\`{e}res, Thierry},
title = {Large Margin Training for Hidden Markov Models with Partially Observed States},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553408},
doi = {10.1145/1553374.1553408},
abstract = {Large margin learning of Continuous Density HMMs with a partially labeled dataset has been extensively studied in the speech and handwriting recognition fields. Yet due to the non-convexity of the optimization problem, previous works usually rely on severe approximations so that it is still an open problem. We propose a new learning algorithm that relies on non-convex optimization and bundle methods and allows tackling the original optimization problem as is. It is proved to converge to a solution with accuracy ε with a rate O (1/ε). We provide experimental results gained on speech and handwriting recognition that demonstrate the potential of the method.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {265–272},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553409,
author = {Doshi-Velez, Finale and Ghahramani, Zoubin},
title = {Accelerated Sampling for the Indian Buffet Process},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553409},
doi = {10.1145/1553374.1553409},
abstract = {We often seek to identify co-occurring hidden features in a set of observations. The Indian Buffet Process (IBP) provides a non-parametric prior on the features present in each observation, but current inference techniques for the IBP often scale poorly. The collapsed Gibbs sampler for the IBP has a running time cubic in the number of observations, and the uncollapsed Gibbs sampler, while linear, is often slow to mix. We present a new linear-time collapsed Gibbs sampler for conjugate likelihood models and demonstrate its efficacy on large real-world datasets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {273–280},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553410,
author = {Doyle, Gabriel and Elkan, Charles},
title = {Accounting for Burstiness in Topic Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553410},
doi = {10.1145/1553374.1553410},
abstract = {Many different topic models have been used successfully for a variety of applications. However, even state-of-the-art topic models suffer from the important flaw that they do not capture the tendency of words to appear in bursts; it is a fundamental property of language that if a word is used once in a document, it is more likely to be used again. We introduce a topic model that uses Dirichlet compound multinomial (DCM) distributions to model this burstiness phenomenon. On both text and non-text datasets, the new model achieves better held-out likelihood than standard latent Dirichlet allocation (LDA). It is straightforward to incorporate the DCM extension into topic models that are more complex than LDA.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {281–288},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553411,
author = {Duan, Lixin and Tsang, Ivor W. and Xu, Dong and Chua, Tat-Seng},
title = {Domain Adaptation from Multiple Sources via Auxiliary Classifiers},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553411},
doi = {10.1145/1553374.1553411},
abstract = {We propose a multiple source domain adaptation method, referred to as Domain Adaptation Machine (DAM), to learn a robust decision function (referred to as target classifier) for label prediction of patterns from the target domain by leveraging a set of pre-computed classifiers (referred to as auxiliary/source classifiers) independently learned with the labeled patterns from multiple source domains. We introduce a new data-dependent regularizer based on smoothness assumption into Least-Squares SVM (LS-SVM), which enforces that the target classifier shares similar decision values with the auxiliary classifiers from relevant source domains on the unlabeled patterns of the target domain. In addition, we employ a sparsity regularizer to learn a sparse target classifier. Comprehensive experiments on the challenging TRECVID 2005 corpus demonstrate that DAM outperforms the existing multiple source domain adaptation methods for video concept detection in terms of effectiveness and efficiency.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {289–296},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553412,
author = {Duchi, John and Singer, Yoram},
title = {Boosting with Structural Sparsity},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553412},
doi = {10.1145/1553374.1553412},
abstract = {We derive generalizations of AdaBoost and related gradient-based coordinate descent methods that incorporate sparsity-promoting penalties for the norm of the predictor that is being learned. The end result is a family of coordinate descent algorithms that integrate forward feature induction and back-pruning through regularization and give an automatic stopping criterion for feature induction. We study penalties based on the l1, l2, and l∞ norms of the predictor and introduce mixed-norm penalties that build upon the initial penalties. The mixed-norm regularizers facilitate structural sparsity in parameter space, which is a useful property in multiclass prediction and other related tasks. We report empirical results that demonstrate the power of our approach in building accurate and structurally sparse models.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {297–304},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553413,
author = {Farhangfar, Alireza and Greiner, Russell and Szepesv\'{a}ri, Csaba},
title = {Learning to Segment from a Few Well-Selected Training Images},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553413},
doi = {10.1145/1553374.1553413},
abstract = {We address the task of actively learning a segmentation system: given a large number of unsegmented images, and access to an oracle that can segment a given image, decide which images to provide, to quickly produce a segmenter (here, a discriminative random field) that is accurate over this distribution of images. We extend the standard models for active learner to define a system for this task that first selects the image whose expected label will reduce the uncertainty of the other unlabeled images the most, and then after greedily selects, from the pool of unsegmented images, the most informative image. The results of our experiments, over two real-world datasets (segmenting brain tumors within magnetic resonance images; and segmenting the sky in real images) show that training on very few informative images (here, as few as 2) can produce a segmenter that is as good as training on the entire dataset.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {305–312},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553414,
author = {Flores, M. Julia and G\'{a}mez, Jos\'{e} A. and Mart\'{\i}nez, Ana M. and Puerta, Jos\'{e} M.},
title = {GAODE and HAODE: Two Proposals Based on AODE to Deal with Continuous Variables},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553414},
doi = {10.1145/1553374.1553414},
abstract = {AODE (Aggregating One-Dependence Estimators) is considered one of the most interesting representatives of the Bayesian classifiers, taking into account not only the low error rate it provides but also its efficiency. Until now, all the attributes in a dataset have had to be nominal to build an AODE classifier or they have had to be previously discretized. In this paper, we propose two different approaches in order to deal directly with numeric attributes. One of them uses conditional Gaussian networks to model a dataset exclusively with numeric attributes; and the other one keeps the superparent on each model discrete and uses univariate Gaussians to estimate the probabilities for the numeric attributes and multinomial distributions for the categorical ones, it also being able to model hybrid datasets. Both of them obtain competitive results compared to AODE, the latter in particular being a very attractive alternative to AODE in numeric datasets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {313–320},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553415,
author = {Foo, Chuan-Sheng and Do, Chuong B. and Ng, Andrew Y.},
title = {A Majorization-Minimization Algorithm for (Multiple) Hyperparameter Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553415},
doi = {10.1145/1553374.1553415},
abstract = {We present a general Bayesian framework for hyperparameter tuning in L2-regularized supervised learning models. Paradoxically, our algorithm works by first analytically integrating out the hyperparameters from the model. We find a local optimum of the resulting non-convex optimization problem efficiently using a majorization-minimization (MM) algorithm, in which the non-convex problem is reduced to a series of convex L2-regularized parameter estimation tasks. The principal appeal of our method is its simplicity: the updates for choosing the L2-regularized subproblems in each step are trivial to implement (or even perform by hand), and each subproblem can be efficiently solved by adapting existing solvers. Empirical results on a variety of supervised learning models show that our algorithm is competitive with both grid-search and gradient-based algorithms, but is more efficient and far easier to implement.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {321–328},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553416,
author = {Fu, Wenjie and Song, Le and Xing, Eric P.},
title = {Dynamic Mixed Membership Blockmodel for Evolving Networks},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553416},
doi = {10.1145/1553374.1553416},
abstract = {In a dynamic social or biological environment, interactions between the underlying actors can undergo large and systematic changes. Each actor can assume multiple roles and their degrees of affiliation to these roles can also exhibit rich temporal phenomena. We propose a state space mixed membership stochastic blockmodel which can track across time the evolving roles of the actors. We also derive an efficient variational inference procedure for our model, and apply it to the Enron email networks, and rewiring gene regulatory networks of yeast. In both cases, our model reveals interesting dynamical roles of the actors.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {329–336},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553417,
author = {Garg, Rahul and Khandekar, Rohit},
title = {Gradient Descent with Sparsification: An Iterative Algorithm for Sparse Recovery with Restricted Isometry Property},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553417},
doi = {10.1145/1553374.1553417},
abstract = {We present an algorithm for finding an s-sparse vector x that minimizes the square-error ∥y -- Φx∥2 where Φ satisfies the restricted isometry property (RIP), with isometric constant δ2s &lt; 1/3. Our algorithm, called GraDeS (Gradient Descent with Sparsification) iteratively updates x as: [EQUATION]where γ &gt; 1 and Hs sets all but s largest magnitude coordinates to zero. GraDeS converges to the correct solution in constant number of iterations. The condition δ2s &lt; 1/3 is most general for which a near-linear time algorithm is known. In comparison, the best condition under which a polynomial-time algorithm is known, is δ2s &lt; √2 -- 1.Our Matlab implementation of GraDeS outperforms previously proposed algorithms like Subspace Pursuit, StOMP, OMP, and Lasso by an order of magnitude. Curiously, our experiments also uncovered cases where L1-regularized regression (Lasso) fails but GraDeS finds the correct solution.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {337–344},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553418,
author = {Garnett, Roman and Osborne, Michael A. and Roberts, Stephen J.},
title = {Sequential Bayesian Prediction in the Presence of Changepoints},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553418},
doi = {10.1145/1553374.1553418},
abstract = {We introduce a new sequential algorithm for making robust predictions in the presence of changepoints. Unlike previous approaches, which focus on the problem of detecting and locating changepoints, our algorithm focuses on the problem of making predictions even when such changes might be present. We introduce nonstationary covariance functions to be used in Gaussian process prediction that model such changes, then proceed to demonstrate how to effectively manage the hyperparameters associated with those covariance functions. By using Bayesian quadrature, we can integrate out the hyperparameters, allowing us to calculate the marginal predictive distribution. Furthermore, if desired, the posterior distribution over putative changepoint locations can be calculated as a natural byproduct of our prediction algorithm.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {345–352},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553419,
author = {Germain, Pascal and Lacasse, Alexandre and Laviolette, Fran\c{c}ois and Marchand, Mario},
title = {PAC-Bayesian Learning of Linear Classifiers},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553419},
doi = {10.1145/1553374.1553419},
abstract = {We present a general PAC-Bayes theorem from which all known PAC-Bayes risk bounds are obtained as particular cases. We also propose different learning algorithms for finding linear classifiers that minimize these bounds. These learning algorithms are generally competitive with both AdaBoost and the SVM.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {353–360},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553421,
author = {Gieseke, Fabian and Pahikkala, Tapio and Kramer, Oliver},
title = {Fast Evolutionary Maximum Margin Clustering},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553421},
doi = {10.1145/1553374.1553421},
abstract = {The maximum margin clustering approach is a recently proposed extension of the concept of support vector machines to the clustering problem. Briefly stated, it aims at finding an optimal partition of the data into two classes such that the margin induced by a subsequent application of a support vector machine is maximal. We propose a method based on stochastic search to address this hard optimization problem. While a direct implementation would be infeasible for large data sets, we present an efficient computational shortcut for assessing the "quality" of intermediate solutions. Experimental results show that our approach outperforms existing methods in terms of clustering accuracy.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {361–368},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553422,
author = {Rodrigues Gomes, Eduardo and Kowalczyk, Ryszard},
title = {Dynamic Analysis of Multiagent <i>Q</i>-Learning with ε-Greedy Exploration},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553422},
abstract = {The development of mechanisms to understand and model the expected behaviour of multiagent learners is becoming increasingly important as the area rapidly find application in a variety of domains. In this paper we present a framework to model the behaviour of Q-learning agents using the ε-greedy exploration mechanism. For this, we analyse a continuous-time version of the Q-learning update rule and study how the presence of other agents and the ε-greedy mechanism affect it. We then model the problem as a system of difference equations which is used to theoretically analyse the expected behaviour of the agents. The applicability of the framework is tested through experiments in typical games selected from the literature.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {369–376},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553423,
author = {Guiver, John and Snelson, Edward},
title = {Bayesian Inference for Plackett-Luce Ranking Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553423},
doi = {10.1145/1553374.1553423},
abstract = {This paper gives an efficient Bayesian method for inferring the parameters of a Plackett-Luce ranking model. Such models are parameterised distributions over rankings of a finite set of objects, and have typically been studied and applied within the psychometric, sociometric and econometric literature. The inference scheme is an application of Power EP (expectation propagation). The scheme is robust and can be readily applied to large scale data sets. The inference algorithm extends to variations of the basic Plackett-Luce model, including partial rankings. We show a number of advantages of the EP approach over the traditional maximum likelihood method. We apply the method to aggregate rankings of NASCAR racing drivers over the 2002 season, and also to rankings of movie genres.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {377–384},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553424,
author = {Haider, Peter and Scheffer, Tobias},
title = {Bayesian Clustering for Email Campaign Detection},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553424},
doi = {10.1145/1553374.1553424},
abstract = {We discuss the problem of clustering elements according to the sources that have generated them. For elements that are characterized by independent binary attributes, a closed-form Bayesian solution exists. We derive a solution for the case of dependent attributes that is based on a transformation of the instances into a space of independent feature functions. We derive an optimization problem that produces a mapping into a space of independent binary feature vectors; the features can reflect arbitrary dependencies in the input space. This problem setting is motivated by the application of spam filtering for email service providers. Spam traps deliver a real-time stream of messages known to be spam. If elements of the same campaign can be recognized reliably, entire spam and phishing campaigns can be contained. We present a case study that evaluates Bayesian clustering for this application.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {385–392},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553425,
author = {Hazan, Elad and Seshadhri, C.},
title = {Efficient Learning Algorithms for Changing Environments},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553425},
abstract = {We study online learning in an oblivious changing environment. The standard measure of regret bounds the difference between the cost of the online learner and the best decision in hindsight. Hence, regret minimizing algorithms tend to converge to the static best optimum, clearly a suboptimal behavior in changing environments. On the other hand, various metrics proposed to strengthen regret and allow for more dynamic algorithms produce inefficient algorithms.We propose a different performance metric which strengthens the standard metric of regret and measures performance with respect to a changing comparator. We then describe a series of data-streaming-based reductions which transform algorithms for minimizing (standard) regret into adaptive algorithms albeit incurring only poly-logarithmic computational overhead.Using this reduction, we obtain efficient low adaptive-regret algorithms for the problem of online convex optimization. This can be applied to various learning scenarios, i.e. online portfolio selection, for which we describe experimental results showing the advantage of adaptivity.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {393–400},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553426,
author = {Heidrich-Meisner, Verena and Igel, Christian},
title = {Hoeffding and Bernstein Races for Selecting Policies in Evolutionary Direct Policy Search},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553426},
doi = {10.1145/1553374.1553426},
abstract = {Uncertainty arises in reinforcement learning from various sources, and therefore it is necessary to consider statistics based on several roll-outs for evaluating behavioral policies. We add an adaptive uncertainty handling based on Hoeffding and empirical Bernstein races to the CMA-ES, a variable metric evolution strategy proposed for direct policy search. The uncertainty handling adjusts individually the number of episodes considered for the evaluation of a policy. The performance estimation is kept just accurate enough for a sufficiently good ranking of candidate policies, which is in turn sufficient for the CMA-ES to find better solutions. This increases the learning speed as well as the robustness of the algorithm.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {401–408},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553427,
author = {Helleputte, Thibault and Dupont, Pierre},
title = {Partially Supervised Feature Selection with Regularized Linear Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553427},
abstract = {This paper addresses feature selection techniques for classification of high dimensional data, such as those produced by microarray experiments. Some prior knowledge may be available in this context to bias the selection towards some dimensions (genes) a priori assumed to be more relevant. We propose a feature selection method making use of this partial supervision. It extends previous works on embedded feature selection with linear models including regularization to enforce sparsity. A practical approximation of this technique reduces to standard SVM learning with iterative rescaling of the inputs. The scaling factors depend here on the prior knowledge but the final selection may depart from it. Practical results on several microarray data sets show the benefits of the proposed approach in terms of the stability of the selected gene lists with improved classification performances.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {409–416},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553429,
author = {Huang, Junzhou and Zhang, Tong and Metaxas, Dimitris},
title = {Learning with Structured Sparsity},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553429},
doi = {10.1145/1553374.1553429},
abstract = {This paper investigates a new learning formulation called structured sparsity, which is a natural extension of the standard sparsity concept in statistical learning and compressive sensing. By allowing arbitrary structures on the feature set, this concept generalizes the group sparsity idea. A general theory is developed for learning with structured sparsity, based on the notion of coding complexity associated with the structure. Moreover, a structured greedy algorithm is proposed to efficiently solve the structured sparsity problem. Experiments demonstrate the advantage of structured sparsity over standard sparsity.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {417–424},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553430,
author = {Huang, Tzu-Kuo and Schneider, Jeff},
title = {Learning Linear Dynamical Systems without Sequence Information},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553430},
doi = {10.1145/1553374.1553430},
abstract = {Virtually all methods of learning dynamic systems from data start from the same basic assumption: that the learning algorithm will be provided with a sequence, or trajectory, of data generated from the dynamic system. In this paper we consider the case where the data is not sequenced. The learning algorithm is presented a set of data points from the system's operation but with no temporal ordering. The data are simply drawn as individual disconnected points.While making this assumption may seem absurd at first glance, we observe that many scientific modeling tasks have exactly this property. In this paper we restrict our attention to learning linear, discrete time models. We propose several algorithms for learning these models based on optimizing approximate likelihood functions and test the methods on several synthetic data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {425–432},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553431,
author = {Jacob, Laurent and Obozinski, Guillaume and Vert, Jean-Philippe},
title = {Group Lasso with Overlap and Graph Lasso},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553431},
doi = {10.1145/1553374.1553431},
abstract = {We propose a new penalty function which, when used as regularization for empirical risk minimization procedures, leads to sparse estimators. The support of the sparse vector is typically a union of potentially overlapping groups of co-variates defined a priori, or a set of covariates which tend to be connected to each other when a graph of covariates is given. We study theoretical properties of the estimator, and illustrate its behavior on simulated and breast cancer gene expression data.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {433–440},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553432,
author = {Jebara, Tony and Wang, Jun and Chang, Shih-Fu},
title = {Graph Construction and <i>b</i>-Matching for Semi-Supervised Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553432},
doi = {10.1145/1553374.1553432},
abstract = {Graph based semi-supervised learning (SSL) methods play an increasingly important role in practical machine learning systems. A crucial step in graph based SSL methods is the conversion of data into a weighted graph. However, most of the SSL literature focuses on developing label inference algorithms without extensively studying the graph building method and its effect on performance. This article provides an empirical study of leading semi-supervised methods under a wide range of graph construction algorithms. These SSL inference algorithms include the Local and Global Consistency (LGC) method, the Gaussian Random Field (GRF) method, the Graph Transduction via Alternating Minimization (GTAM) method as well as other techniques. Several approaches for graph construction, sparsification and weighting are explored including the popular k-nearest neighbors method (kNN) and the b-matching method. As opposed to the greedily constructed kNN graph, the b-matched graph ensures each node in the graph has the same number of edges and produces a balanced or regular graph. Experimental results on both artificial data and real benchmark datasets indicate that b-matching produces more robust graphs and therefore provides significantly better prediction accuracy without any significant change in computation time.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {441–448},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553433,
author = {Jetchev, Nikolay and Toussaint, Marc},
title = {Trajectory Prediction: Learning to Map Situations to Robot Trajectories},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553433},
abstract = {Trajectory planning and optimization is a fundamental problem in articulated robotics. Algorithms used typically for this problem compute optimal trajectories from scratch in a new situation. In effect, extensive data is accumulated containing situations together with the respective optimized trajectories - but this data is in practice hardly exploited. The aim of this paper is to learn from this data. Given a new situation we want to predict a suitable trajectory which only needs minor refinement by a conventional optimizer. Our approach has two essential ingredients. First, to generalize from previous situations to new ones we need an appropriate situation descriptor - we propose a sparse feature selection approach to find such well-generalizing features of situations. Second, the transfer of previously optimized trajectories to a new situation should not be made in joint angle space - we propose a more efficient task space transfer of old trajectories to new situations. Experiments on a simulated humanoid reaching problem show that we can predict reasonable motion prototypes in new situations for which the refinement is much faster than an optimization from scratch.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {449–456},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553434,
author = {Ji, Shuiwang and Ye, Jieping},
title = {An Accelerated Gradient Method for Trace Norm Minimization},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553434},
doi = {10.1145/1553374.1553434},
abstract = {We consider the minimization of a smooth loss function regularized by the trace norm of the matrix variable. Such formulation finds applications in many machine learning tasks including multi-task learning, matrix classification, and matrix completion. The standard semidefinite programming formulation for this problem is computationally expensive. In addition, due to the non-smooth nature of the trace norm, the optimal first-order black-box method for solving such class of problems converges as O(1/√k), where k is the iteration counter. In this paper, we exploit the special structure of the trace norm, based on which we propose an extended gradient algorithm that converges as O(1/k). We further propose an accelerated gradient algorithm, which achieves the optimal convergence rate of O(1/k2) for smooth problems. Experiments on multi-task learning problems demonstrate the efficiency of the proposed algorithms.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {457–464},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553435,
author = {Jin, Wei and Ho, Hung Hay},
title = {A Novel Lexicalized HMM-Based Learning Framework for Web Opinion Mining},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553435},
doi = {10.1145/1553374.1553435},
abstract = {NOTE FROM ACM: A Joint ACM Conference Committee has determined that the authors of this article violated ACM's publication policy on simultaneous submissions. Therefore ACM has shut off access to this paper.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {465–472},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553436,
author = {Johnson, Jason K. and Chernyak, Vladimir Y. and Chertkov, Michael},
title = {Orbit-Product Representation and Correction of Gaussian Belief Propagation},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553436},
doi = {10.1145/1553374.1553436},
abstract = {We present a new view of Gaussian belief propagation (GaBP) based on a representation of the determinant as a product over orbits of a graph. We show that the GaBP determinant estimate captures totally backtracking orbits of the graph and consider how to correct this estimate. We show that the missing orbits may be grouped into equivalence classes corresponding to backtrackless orbits and the contribution of each equivalence class is easily determined from the GaBP solution. Furthermore, we demonstrate that this multiplicative correction factor can be interpreted as the determinant of a backtrackless adjacency matrix of the graph with edge weights based on GaBP. Finally, an efficient method is proposed to compute a truncated correction factor including all backtrackless orbits up to a specified length.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {473–480},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553437,
author = {Kamisetty, Hetunandan and Langmead, Christopher J.},
title = {A Bayesian Approach to Protein Model Quality Assessment},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553437},
doi = {10.1145/1553374.1553437},
abstract = {Given multiple possible models b1, b2, ... bn for a protein structure, a common sub-task in in-silico Protein Structure Prediction is ranking these models according to their quality. Extant approaches use MLE estimates of parameters ri to obtain point estimates of the Model Quality. We describe a Bayesian alternative to assessing the quality of these models that builds an MRF over the parameters of each model and performs approximate inference to integrate over them. Hyperparameters w are learnt by optimizing a list-wise loss function over training data. Our results indicate that our Bayesian approach can significantly outperform MLE estimates and that optimizing the hyper-parameters can further improve results.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {481–488},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553438,
author = {Karampatziakis, Nikos and Kozen, Dexter},
title = {Learning Prediction Suffix Trees with Winnow},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553438},
doi = {10.1145/1553374.1553438},
abstract = {Prediction suffix trees (PSTs) are a popular tool for modeling sequences and have been successfully applied in many domains such as compression and language modeling. In this work we adapt the well studied Winnow algorithm to the task of learning PSTs. The proposed algorithm automatically grows the tree, so that it provably remains competitive with any fixed PST determined in hindsight. At the same time we prove that the depth of the tree grows only logarithmically with the number of mistakes made by the algorithm. Finally, we empirically demonstrate its effectiveness in two different tasks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {489–496},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553439,
author = {K\'{e}gl, Bal\'{a}zs and Busa-Fekete, R\'{o}bert},
title = {Boosting Products of Base Classifiers},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553439},
doi = {10.1145/1553374.1553439},
abstract = {In this paper we show how to boost products of simple base learners. Similarly to trees, we call the base learner as a subroutine but in an iterative rather than recursive fashion. The main advantage of the proposed method is its simplicity and computational efficiency. On benchmark datasets, our boosted products of decision stumps clearly outperform boosted trees, and on the MNIST dataset the algorithm achieves the second best result among no-domain-knowledge algorithms after deep belief nets. As a second contribution, we present an improved base learner for nominal features and show that boosting the product of two of these new subset indicator base learners solves the maximum margin matrix factorization problem used to formalize the collaborative filtering task. On a small benchmark dataset, we get experimental results comparable to the semi-definite-programming-based solution but at a much lower computational cost.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {497–504},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553440,
author = {Kok, Stanley and Domingos, Pedro},
title = {Learning Markov Logic Network Structure via Hypergraph Lifting},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553440},
doi = {10.1145/1553374.1553440},
abstract = {Markov logic networks (MLNs) combine logic and probability by attaching weights to first-order clauses, and viewing these as templates for features of Markov networks. Learning MLN structure from a relational database involves learning the clauses and weights. The state-of-the-art MLN structure learners all involve some element of greedily generating candidate clauses, and are susceptible to local optima. To address this problem, we present an approach that directly utilizes the data in constructing candidates. A relational database can be viewed as a hypergraph with constants as nodes and relations as hyperedges. We find paths of true ground atoms in the hypergraph that are connected via their arguments. To make this tractable (there are exponentially many paths in the hypergraph), we lift the hypergraph by jointly clustering the constants to form higherlevel concepts, and find paths in it. We variabilize the ground atoms in each path, and use them to form clauses, which are evaluated using a pseudo-likelihood measure. In our experiments on three real-world datasets, we find that our algorithm outperforms the state-of-the-art approaches.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {505–512},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553441,
author = {Kolter, J. Zico and Ng, Andrew Y.},
title = {Near-Bayesian Exploration in Polynomial Time},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553441},
doi = {10.1145/1553374.1553441},
abstract = {We consider the exploration/exploitation problem in reinforcement learning (RL). The Bayesian approach to model-based RL offers an elegant solution to this problem, by considering a distribution over possible models and acting to maximize expected reward; unfortunately, the Bayesian solution is intractable for all but very restricted cases. In this paper we present a simple algorithm, and prove that with high probability it is able to perform ε-close to the true (intractable) optimal Bayesian policy after some small (polynomial in quantities describing the system) number of time steps. The algorithm and analysis are motivated by the so-called PAC-MDP approach, and extend such results into the setting of Bayesian RL. In this setting, we show that we can achieve lower sample complexity bounds than existing algorithms, while using an exploration strategy that is much greedier than the (extremely cautious) exploration of PAC-MDP algorithms.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {513–520},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553442,
author = {Kolter, J. Zico and Ng, Andrew Y.},
title = {Regularization and Feature Selection in Least-Squares Temporal Difference Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553442},
abstract = {We consider the task of reinforcement learning with linear value function approximation. Temporal difference algorithms, and in particular the Least-Squares Temporal Difference (LSTD) algorithm, provide a method for learning the parameters of the value function, but when the number of features is large this algorithm can over-fit to the data and is computationally expensive. In this paper, we propose a regularization framework for the LSTD algorithm that overcomes these difficulties. In particular, we focus on the case of l1 regularization, which is robust to irrelevant features and also serves as a method for feature selection. Although the l1 regularized LSTD solution cannot be expressed as a convex optimization problem, we present an algorithm similar to the Least Angle Regression (LARS) algorithm that can efficiently compute the optimal solution. Finally, we demonstrate the performance of the algorithm experimentally.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {521–528},
numpages = {8}
}

@inbook{10.1145/1553374.1553443,
author = {Kondor, Risi and Shervashidze, Nino and Borgwardt, Karsten M.},
title = {The Graphlet Spectrum},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553443},
abstract = {Current graph kernels suffer from two limitations: graph kernels based on counting particular types of subgraphs ignore the relative position of these subgraphs to each other, while graph kernels based on algebraic methods are limited to graphs without node labels. In this paper we present the graphlet spectrum, a system of graph invariants derived by means of group representation theory that capture information about the number as well as the position of labeled subgraphs in a given graph. In our experimental evaluation the graphlet spectrum outperforms state-of-the-art graph kernels.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {529–536},
numpages = {8}
}

@inbook{10.1145/1553374.1553444,
author = {Kot\l{}owski, Wojciech and S\l{}owi\'{n}ski, Roman},
title = {Rule Learning with Monotonicity Constraints},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553444},
abstract = {In classification with monotonicity constraints, it is assumed that the class label should increase with increasing values on the attributes. In this paper we aim at formalizing the approach to learning with monotonicity constraints from statistical point of view. Motivated by the statistical analysis, we present an algorithm for learning rule ensembles. The algorithm first "monotonizes" the data using a nonparametric classification procedure and then generates a rule ensemble consistent with the training set. The procedure is justified by a theoretical analysis and verified in a computational experiment.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {537–544},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553445,
author = {Kowalski, Matthieu and Szafranski, Marie and Ralaivola, Liva},
title = {Multiple Indefinite Kernel Learning with Mixed Norm Regularization},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553445},
doi = {10.1145/1553374.1553445},
abstract = {We address the problem of learning classifiers using several kernel functions. On the contrary to many contributions in the field of learning from different sources of information using kernels, we here do not assume that the kernels used are positive definite. The learning problem that we are interested in involves a misclassification loss term and a regularization term that is expressed by means of a mixed norm. The use of a mixed norm allows us to enforce some sparsity structure, a particular case of which is, for instance, the Group Lasso. We solve the convex problem by employing proximal minimization algorithms, which can be viewed as refined versions of gradient descent procedures capable of naturally dealing with nondifferentiability. A numerical simulation on a Uci dataset shows the modularity of our approach.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {545–552},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553446,
author = {Kumar, Sanjiv and Mohri, Mehryar and Talwalkar, Ameet},
title = {On Sampling-Based Approximate Spectral Decomposition},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553446},
doi = {10.1145/1553374.1553446},
abstract = {This paper addresses the problem of approximate singular value decomposition of large dense matrices that arises naturally in many machine learning applications. We discuss two recently introduced sampling-based spectral decomposition techniques: the Nystr\"{o}m and the Column-sampling methods. We present a theoretical comparison between the two methods and provide novel insights regarding their suitability for various applications. We then provide experimental results motivated by this theory. Finally, we propose an efficient adaptive sampling technique to select informative columns from the original matrix. This novel technique outperforms standard sampling methods on a variety of datasets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {553–560},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553447,
author = {Kunegis, J\'{e}r\^{o}me and Lommatzsch, Andreas},
title = {Learning Spectral Graph Transformations for Link Prediction},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553447},
abstract = {We present a unified framework for learning link prediction and edge weight prediction functions in large networks, based on the transformation of a graph's algebraic spectrum. Our approach generalizes several graph kernels and dimensionality reduction methods and provides a method to estimate their parameters efficiently. We show how the parameters of these prediction functions can be learned by reducing the problem to a one-dimensional regression problem whose runtime only depends on the method's reduced rank and that can be inspected visually. We derive variants that apply to undirected, weighted, unweighted, unipartite and bipartite graphs. We evaluate our method experimentally using examples from social networks, collaborative filtering, trust networks, citation networks, authorship graphs and hyperlink networks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {561–568},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553448,
author = {Ku\v{z}elka, Ond\v{r}ej and \v{z}elezn\'{y}, Filip},
title = {Block-Wise Construction of Acyclic Relational Features with Monotone Irreducibility and Relevancy Properties},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553448},
doi = {10.1145/1553374.1553448},
abstract = {We describe an algorithm for constructing a set of acyclic conjunctive relational features by combining smaller conjunctive blocks. Unlike traditional level-wise approaches which preserve the monotonicity of frequency, our block-wise approach preserves a form of monotonicity of the irreducibility and relevancy feature properties, which are important in propositionalization employed in the context of classification learning. With pruning based on these properties, our block-wise approach efficiently scales to features including tens of first-order literals, far beyond the reach of state-of-the art propositionalization or inductive logic programming systems.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {569–576},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553449,
author = {Lan, Yanyan and Liu, Tie-Yan and Ma, Zhiming and Li, Hang},
title = {Generalization Analysis of Listwise Learning-to-Rank Algorithms},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553449},
abstract = {This paper presents a theoretical framework for ranking, and demonstrates how to perform generalization analysis of listwise ranking algorithms using the framework. Many learning-to-rank algorithms have been proposed in recent years. Among them, the listwise approach has shown higher empirical ranking performance when compared to the other approaches. However, there is no theoretical study on the listwise approach as far as we know. In this paper, we propose a theoretical framework for ranking, which can naturally describe various listwise learning-to-rank algorithms. With this framework, we prove a theorem which gives a generalization bound of a listwise ranking algorithm, on the basis of Rademacher Average of the class of compound functions. The compound functions take listwise loss functions as outer functions and ranking models as inner functions. We then compute the Rademacher Averages for existing listwise algorithms of ListMLE, ListNet, and RankCosine. We also discuss the tightness of the bounds in different situations with regard to the list length and transformation function.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {577–584},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553450,
author = {Lang, Tobias and Toussaint, Marc},
title = {Approximate Inference for Planning in Stochastic Relational Worlds},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553450},
doi = {10.1145/1553374.1553450},
abstract = {Relational world models that can be learned from experience in stochastic domains have received significant attention recently. However, efficient planning using these models remains a major issue. We propose to convert learned noisy probabilistic relational rules into a structured dynamic Bayesian network representation. Predicting the effects of action sequences using approximate inference allows for planning in complex worlds. We evaluate the effectiveness of our approach for online planning in a 3D simulated blocksworld with an articulated manipulator and realistic physics. Empirical results show that our method can solve problems where existing methods fail.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {585–592},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553451,
author = {Langford, John and Salakhutdinov, Ruslan and Zhang, Tong},
title = {Learning Nonlinear Dynamic Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553451},
doi = {10.1145/1553374.1553451},
abstract = {We present a novel approach for learning nonlinear dynamic models, which leads to a new set of tools capable of solving problems that are otherwise difficult. We provide theory showing this new approach is consistent for models with long range structure, and apply the approach to motion capture and high-dimensional video data, yielding results superior to standard alternatives.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {593–600},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553452,
author = {Lawrence, Neil D. and Urtasun, Raquel},
title = {Non-Linear Matrix Factorization with Gaussian Processes},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553452},
doi = {10.1145/1553374.1553452},
abstract = {A popular approach to collaborative filtering is matrix factorization. In this paper we develop a non-linear probabilistic matrix factorization using Gaussian process latent variable models. We use stochastic gradient descent (SGD) to optimize the model. SGD allows us to apply Gaussian processes to data sets with millions of observations without approximate methods. We apply our approach to benchmark movie recommender data sets. The results show better than previous state-of-the-art performance.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {601–608},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553453,
author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
title = {Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553453},
abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {609–616},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553454,
author = {Li, Bin and Yang, Qiang and Xue, Xiangyang},
title = {Transfer Learning for Collaborative Filtering via a Rating-Matrix Generative Model},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553454},
doi = {10.1145/1553374.1553454},
abstract = {Cross-domain collaborative filtering solves the sparsity problem by transferring rating knowledge across multiple domains. In this paper, we propose a rating-matrix generative model (RMGM) for effective cross-domain collaborative filtering. We first show that the relatedness across multiple rating matrices can be established by finding a shared implicit cluster-level rating matrix, which is next extended to a cluster-level rating model. Consequently, a rating matrix of any related task can be viewed as drawing a set of users and items from a user-item joint mixture model as well as drawing the corresponding ratings from the cluster-level rating model. The combination of these two models gives the RMGM, which can be used to fill the missing ratings for both existing and new users. A major advantage of RMGM is that it can share the knowledge by pooling the rating data from multiple tasks even when the users and items of these tasks do not overlap. We evaluate the RMGM empirically on three real-world collaborative filtering data sets to show that RMGM can outperform the individual models trained separately.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {617–624},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553455,
author = {Li, Ping},
title = {ABC-Boost: Adaptive Base Class Boost for Multi-Class Classification},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553455},
doi = {10.1145/1553374.1553455},
abstract = {We propose abc-boost (adaptive base class boost) for multi-class classification and present abc-mart, an implementation of abc-boost, based on the multinomial logit model. The key idea is that, at each boosting iteration, we adaptively and greedily choose a base class. Our experiments on public datasets demonstrate the improvement of abc-mart over the original mart algorithm.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {625–632},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553456,
author = {Li, Yu-Feng and Kwok, James T. and Zhou, Zhi-Hua},
title = {Semi-Supervised Learning Using Label Mean},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553456},
doi = {10.1145/1553374.1553456},
abstract = {Semi-Supervised Support Vector Machines (S3VMs) typically directly estimate the label assignments for the unlabeled instances. This is often inefficient even with recent advances in the efficient training of the (supervised) SVM. In this paper, we show that S3VMs, with knowledge of the means of the class labels of the unlabeled data, is closely related to the supervised SVM with known labels on all the unlabeled data. This motivates us to first estimate the label means of the unlabeled data. Two versions of the meanS3VM, which work by maximizing the margin between the label means, are proposed. The first one is based on multiple kernel learning, while the second one is based on alternating optimization. Experiments show that both of the proposed algorithms achieve highly competitive and sometimes even the best performance as compared to the state-of-the-art semi-supervised learners. Moreover, they are more efficient than existing S3VMs.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {633–640},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553457,
author = {Liang, Percy and Jordan, Michael I. and Klein, Dan},
title = {Learning from Measurements in Exponential Families},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553457},
doi = {10.1145/1553374.1553457},
abstract = {Given a model family and a set of unlabeled examples, one could either label specific examples or state general constraints---both provide information about the desired model. In general, what is the most cost-effective way to learn? To address this question, we introduce measurements, a general class of mechanisms for providing information about a target model. We present a Bayesian decision-theoretic framework, which allows us to both integrate diverse measurements and choose new measurements to make. We use a variational inference algorithm, which exploits exponential family duality. The merits of our approach are demonstrated on two sequence labeling tasks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {641–648},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553458,
author = {Liu, Han and Palatucci, Mark and Zhang, Jian},
title = {Blockwise Coordinate Descent Procedures for the Multi-Task Lasso, with Applications to Neural Semantic Basis Discovery},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553458},
doi = {10.1145/1553374.1553458},
abstract = {We develop a cyclical blockwise coordinate descent algorithm for the multi-task Lasso that efficiently solves problems with thousands of features and tasks. The main result shows that a closed-form Winsorization operator can be obtained for the sup-norm penalized least squares regression. This allows the algorithm to find solutions to very large-scale problems far more efficiently than existing methods. This result complements the pioneering work of Friedman, et al. (2007) for the single-task Lasso. As a case study, we use the multi-task Lasso as a variable selector to discover a semantic basis for predicting human neural activation. The learned solution outperforms the standard basis for this task on the majority of test participants, while requiring far fewer assumptions about cognitive neuroscience. We demonstrate how this learned basis can yield insights into how the brain represents the meanings of words.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {649–656},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553459,
author = {Liu, Jun and Ye, Jieping},
title = {Efficient Euclidean Projections in Linear Time},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553459},
doi = {10.1145/1553374.1553459},
abstract = {We consider the problem of computing the Euclidean projection of a vector of length n onto a closed convex set including the l1 ball and the specialized polyhedra employed in (Shalev-Shwartz &amp; Singer, 2006). These problems have played building block roles in solving several l1-norm based sparse learning problems. Existing methods have a worst-case time complexity of O(n log n). In this paper, we propose to cast both Euclidean projections as root finding problems associated with specific auxiliary functions, which can be solved in linear time via bisection. We further make use of the special structure of the auxiliary functions, and propose an improved bisection algorithm. Empirical studies demonstrate that the proposed algorithms are much more efficient than the competing ones for computing the projections.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {657–664},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553460,
author = {Liu, Yan and Niculescu-Mizil, Alexandru and Gryc, Wojciech},
title = {Topic-Link LDA: Joint Models of Topic and Author Community},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553460},
doi = {10.1145/1553374.1553460},
abstract = {Given a large-scale linked document collection, such as a collection of blog posts or a research literature archive, there are two fundamental problems that have generated a lot of interest in the research community. One is to identify a set of high-level topics covered by the documents in the collection; the other is to uncover and analyze the social network of the authors of the documents. So far these problems have been viewed as separate problems and considered independently from each other. In this paper we argue that these two problems are in fact inter-dependent and should be addressed together. We develop a Bayesian hierarchical approach that performs topic modeling and author community discovery in one unified framework. The effectiveness of our model is demonstrated on two blog data sets in different domains and one research paper citation data from CiteSeer.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {665–672},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553461,
author = {Lu, Zhengdong and Jain, Prateek and Dhillon, Inderjit S.},
title = {Geometry-Aware Metric Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553461},
doi = {10.1145/1553374.1553461},
abstract = {In this paper, we introduce a generic framework for semi-supervised kernel learning. Given pair-wise (dis-)similarity constraints, we learn a kernel matrix over the data that respects the provided side-information as well as the local geometry of the data. Our framework is based on metric learning methods, where we jointly model the metric/kernel over the data along with the underlying manifold. Furthermore, we show that for some important parameterized forms of the underlying manifold model, we can estimate the model parameters and the kernel matrix efficiently. Our resulting algorithm is able to incorporate local geometry into the metric learning task; at the same time it can handle a wide class of constraints. Finally, our algorithm is fast and scalable -- unlike most of the existing methods, it is able to exploit the low dimensional manifold structure and does not require semi-definite programming. We demonstrate wide applicability and effectiveness of our framework by applying to various machine learning tasks such as semi-supervised classification, colored dimensionality reduction, manifold alignment etc. On each of the tasks our method performs competitively or better than the respective state-of-the-art method.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {673–680},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553462,
author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
title = {Identifying Suspicious URLs: An Application of Large-Scale Online Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553462},
doi = {10.1145/1553374.1553462},
abstract = {This paper explores online learning approaches for detecting malicious Web sites (those involved in criminal scams) using lexical and host-based features of the associated URLs. We show that this application is particularly appropriate for online algorithms as the size of the training data is larger than can be efficiently processed in batch and because the distribution of features that typify malicious URLs is changing continuously. Using a real-time system we developed for gathering URL features, combined with a real-time source of labeled URLs from a large Web mail provider, we demonstrate that recently-developed online algorithms can be as accurate as batch techniques, achieving classification accuracies up to 99% over a balanced data set.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {681–688},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553463,
author = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
title = {Online Dictionary Learning for Sparse Coding},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553463},
doi = {10.1145/1553374.1553463},
abstract = {Sparse coding---that is, modelling data vectors as sparse linear combinations of basis elements---is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on learning the basis set, also called dictionary, to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {689–696},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553464,
author = {Makino, Takaki},
title = {Proto-Predictive Representation of States with Simple Recurrent Temporal-Difference Networks},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553464},
abstract = {We propose a new neural network architecture, called Simple Recurrent Temporal-Difference Networks (SR-TDNs), that learns to predict future observations in partially observable environments. SR-TDNs incorporate the structure of simple recurrent neural networks (SRNs) into temporal-difference (TD) networks to use proto-predictive representation of states. Although they deviate from the principle of predictive representations to ground state representations on observations, they follow the same learning strategy as TD networks, i.e., applying TD-learning to general predictions. Simulation experiments revealed that SR-TDNs can correctly represent states with an incomplete set of core tests (question networks), and consequently, SR-TDNs have better on-line learning capacity than TD networks in various environments.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {697–704},
numpages = {8}
}

@inbook{10.1145/1553374.1553465,
author = {Marlin, Benjamin M. and Murphy, Kevin P.},
title = {Sparse Gaussian Graphical Models with Unknown Block Structure},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553465},
abstract = {Recent work has shown that one can learn the structure of Gaussian Graphical Models by imposing an L1 penalty on the precision matrix, and then using efficient convex optimization methods to find the penalized maximum likelihood estimate. This is similar to performing MAP estimation with a prior that prefers sparse graphs. In this paper, we use the stochastic block model as a prior. This prefer graphs that are blockwise sparse, but unlike previous work, it does not require that the blocks or groups be specified a priori. The resulting problem is no longer convex, but we devise an efficient variational Bayes algorithm to solve it. We show that our method has better test set likelihood on two different datasets (motion capture and gene expression) compared to independent L1, and can match the performance of group L1 using manually created groups.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {705–712},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553466,
author = {Martins, Andr\'{e} F. T. and Smith, Noah A. and Xing, Eric P.},
title = {Polyhedral Outer Approximations with Application to Natural Language Parsing},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553466},
doi = {10.1145/1553374.1553466},
abstract = {Recent approaches to learning structured predictors often require approximate inference for tractability; yet its effects on the learned model are unclear. Meanwhile, most learning algorithms act as if computational cost was constant within the model class. This paper sheds some light on the first issue by establishing risk bounds for max-margin learning with LP relaxed inference and addresses the second issue by proposing a new paradigm that attempts to penalize "time-consuming" hypotheses. Our analysis relies on a geometric characterization of the outer polyhedra associated with the LP relaxation. We then apply these techniques to the problem of dependency parsing, for which a concise LP formulation is provided that handles non-local output features. A significant improvement is shown over arc-factored models.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {713–720},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553467,
author = {McFee, Brian and Lanckriet, Gert},
title = {Partial Order Embedding with Multiple Kernels},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553467},
doi = {10.1145/1553374.1553467},
abstract = {We consider the problem of embedding arbitrary objects (e.g., images, audio, documents) into Euclidean space subject to a partial order over pair-wise distances. Partial order constraints arise naturally when modeling human perception of similarity. Our partial order framework enables the use of graph-theoretic tools to more efficiently produce the embedding, and exploit global structure within the constraint set.We present an embedding algorithm based on semidefinite programming, which can be parameterized by multiple kernels to yield a unified space from heterogeneous features.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {721–728},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553468,
author = {de Mesmay, Fr\'{e}d\'{e}ric and Rimmel, Arpad and Voronenko, Yevgen and P\"{u}schel, Markus},
title = {Bandit-Based Optimization on Graphs with Application to Library Performance Tuning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553468},
abstract = {The problem of choosing fast implementations for a class of recursive algorithms such as the fast Fourier transforms can be formulated as an optimization problem over the language generated by a suitably defined grammar. We propose a novel algorithm that solves this problem by reducing it to maximizing an objective function over the sinks of a directed acyclic graph. This algorithm valuates nodes using Monte-Carlo and grows a subgraph in the most promising directions by considering local maximum k-armed bandits. When used inside an adaptive linear transform library, it cuts down the search time by an order of magnitude compared to the existing algorithm. In some cases, the performance of the implementations found is also increased by up to 10% which is of considerable practical importance since it consequently improves the performance of all applications using the library.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {729–736},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553469,
author = {Mobahi, Hossein and Collobert, Ronan and Weston, Jason},
title = {Deep Learning from Temporal Coherence in Video},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553469},
doi = {10.1145/1553374.1553469},
abstract = {This work proposes a learning method for deep architectures that takes advantage of sequential data, in particular from the temporal coherence that naturally exists in unlabeled video recordings. That is, two successive frames are likely to contain the same object or objects. This coherence is used as a supervisory signal over the unlabeled data, and is used to improve the performance on a supervised task of interest. We demonstrate the effectiveness of this method on some pose invariant object and face recognition tasks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {737–744},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553470,
author = {Mooij, Joris and Janzing, Dominik and Peters, Jonas and Sch\"{o}lkopf, Bernhard},
title = {Regression by Dependence Minimization and Its Application to Causal Inference in Additive Noise Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553470},
abstract = {Motivated by causal inference problems, we propose a novel method for regression that minimizes the statistical dependence between regressors and residuals. The key advantage of this approach to regression is that it does not assume a particular distribution of the noise, i.e., it is non-parametric with respect to the noise distribution. We argue that the proposed regression method is well suited to the task of causal inference in additive noise models. A practical disadvantage is that the resulting optimization problem is generally non-convex and can be difficult to solve. Nevertheless, we report good results on one of the tasks of the NIPS 2008 Causality Challenge, where the goal is to distinguish causes from effects in pairs of statistically dependent variables. In addition, we propose an algorithm for efficiently inferring causal models from observational data for more than two variables. The required number of regressions and independence tests is quadratic in the number of variables, which is a significant improvement over the simple method that tests all possible DAGs.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {745–752},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553471,
author = {Neumann, Gerhard and Maass, Wolfgang and Peters, Jan},
title = {Learning Complex Motions by Sequencing Simpler Motion Templates},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553471},
doi = {10.1145/1553374.1553471},
abstract = {Abstraction of complex, longer motor tasks into simpler elemental movements enables humans and animals to exhibit motor skills which have not yet been matched by robots. Humans intuitively decompose complex motions into smaller, simpler segments. For example when describing simple movements like drawing a triangle with a pen, we can easily name the basic steps of this movement.Surprisingly, such abstractions have rarely been used in artificial motor skill learning algorithms. These algorithms typically choose a new action (such as a torque or a force) at a very fast time-scale. As a result, both policy and temporal credit assignment problem become unnecessarily complex - often beyond the reach of current machine learning methods.We introduce a new framework for temporal abstractions in reinforcement learning (RL), i.e. RL with motion templates. We present a new algorithm for this framework which can learn high-quality policies by making only few abstract decisions.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {753–760},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553472,
author = {Nickisch, Hannes and Seeger, Matthias W.},
title = {Convex Variational Bayesian Inference for Large Scale Generalized Linear Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553472},
abstract = {We show how variational Bayesian inference can be implemented for very large generalized linear models. Our relaxation is proven to be a convex problem for any log-concave model. We provide a generic double loop algorithm for solving this relaxation on models with arbitrary super-Gaussian potentials. By iteratively decoupling the criterion, most of the work can be done by solving large linear systems, rendering our algorithm orders of magnitude faster than previously proposed solvers for the same problem. We evaluate our method on problems of Bayesian active learning for large binary classification models, and show how to address settings with many candidates and sequential inclusion steps.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {761–768},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553473,
author = {Nowozin, Sebastian and Jegelka, Stefanie},
title = {Solution Stability in Linear Programming Relaxations: Graph Partitioning and Unsupervised Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553473},
doi = {10.1145/1553374.1553473},
abstract = {We propose a new method to quantify the solution stability of a large class of combinatorial optimization problems arising in machine learning. As practical example we apply the method to correlation clustering, clustering aggregation, modularity clustering, and relative performance significance clustering. Our method is extensively motivated by the idea of linear programming relaxations. We prove that when a relaxation is used to solve the original clustering problem, then the solution stability calculated by our method is conservative, that is, it never overestimates the solution stability of the true, unrelaxed problem. We also demonstrate how our method can be used to compute the entire path of optimal solutions as the optimization problem is increasingly perturbed. Experimentally, our method is shown to perform well on a number of benchmark problems.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {769–776},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553474,
author = {Paisley, John and Carin, Lawrence},
title = {Nonparametric Factor Analysis with Beta Process Priors},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553474},
doi = {10.1145/1553374.1553474},
abstract = {We propose a nonparametric extension to the factor analysis problem using a beta process prior. This beta process factor analysis (BP-FA) model allows for a dataset to be decomposed into a linear combination of a sparse set of factors, providing information on the underlying structure of the observations. As with the Dirichlet process, the beta process is a fully Bayesian conjugate prior, which allows for analytical posterior calculation and straightforward inference. We derive a varia-tional Bayes inference algorithm and demonstrate the model on the MNIST digits and HGDP-CEPH cell line panel datasets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {777–784},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553475,
author = {Pan, Wei and Torresani, Lorenzo},
title = {Unsupervised Hierarchical Modeling of Locomotion Styles},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553475},
doi = {10.1145/1553374.1553475},
abstract = {This paper describes an unsupervised learning technique for modeling human locomotion styles, such as distinct related activities (e.g. running and striding) or variations of the same motion performed by different subjects. Modeling motion styles requires identifying the common structure in the motions and detecting style-specific characteristics. We propose an algorithm that learns a hierarchical model of styles from unlabeled motion capture data by exploiting the cyclic property of human locomotion. We assume that sequences with the same style contain locomotion cycles generated by noisy, temporally warped versions of a single latent cycle. We model these style-specific latent cycles as random variables drawn from a common "parent" cycle distribution, representing the structure shared by all motions. Given these hierarchical priors, the algorithm learns, in a completely unsupervised fashion, temporally aligned latent cycle distributions, each modeling a specific locomotion style, and computes for each example the style label posterior distribution, the segmentation into cycles, and the temporal warping with respect to the latent cycles. We demonstrate the flexibility of the model on several application problems such as style clustering, animation, style blending, and filling in of missing data.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {785–792},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553476,
author = {Pazis, Jason and Lagoudakis, Michail G.},
title = {Binary Action Search for Learning Continuous-Action Control Policies},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553476},
doi = {10.1145/1553374.1553476},
abstract = {Reinforcement Learning methods for controlling stochastic processes typically assume a small and discrete action space. While continuous action spaces are quite common in real-world problems, the most common approach still employed in practice is coarse discretization of the action space. This paper presents a novel method, called Binary Action Search, for realizing continuousaction policies by searching efficiently the entire action range through increment and decrement modifications to the values of the action variables according to an internal binary policy defined over an augmented state space. The proposed approach essentially approximates any continuous action space to arbitrary resolution and can be combined with any discrete-action reinforcement learning algorithm for learning continuous-action policies. Binary Action Search eliminates the restrictive modification steps of Adaptive Action Modification and requires no temporal action locality in the domain. Our approach is coupled with two well-known reinforcement learning algorithms (Least-Squares Policy Iteration and Fitted Q-Iteration) and its use and properties are thoroughly investigated and demonstrated on the continuous state-action Inverted Pendulum, Double Integrator, and Car on the Hill domains.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {793–800},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553477,
author = {Peters, Jonas and Janzing, Dominik and Gretton, Arthur and Sch\"{o}lkopf, Bernhard},
title = {Detecting the Direction of Causal Time Series},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553477},
doi = {10.1145/1553374.1553477},
abstract = {We propose a method that detects the true direction of time series, by fitting an autoregressive moving average model to the data. Whenever the noise is independent of the previous samples for one ordering of the observations, but dependent for the opposite ordering, we infer the former direction to be the true one. We prove that our method works in the population case as long as the noise of the process is not normally distributed (for the latter case, the direction is not identifiable). A new and important implication of our result is that it confirms a fundamental conjecture in causal reasoning --- if after regression the noise is independent of signal for one direction and dependent for the other, then the former represents the true causal direction --- in the case of time series. We test our approach on two types of data: simulated data sets conforming to our modeling assumptions, and real world EEG time series. Our method makes a decision for a significant fraction of both data sets, and these decisions are mostly correct. For real world data, our approach outperforms alternative solutions to the problem of time direction recovery.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {801–808},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553478,
author = {Petrik, Marek and Zilberstein, Shlomo},
title = {Constraint Relaxation in Approximate Linear Programs},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553478},
abstract = {Approximate Linear Programming (ALP) is a reinforcement learning technique with nice theoretical properties, but it often performs poorly in practice. We identify some reasons for the poor quality of ALP solutions in problems where the approximation induces virtual loops. We then introduce two methods for improving solution quality. One method rolls out selected constraints of the ALP, guided by the dual information. The second method is a relaxation of the ALP, based on external penalty methods. The latter method is applicable in domains in which rolling out constraints is impractical. Both approaches show promising empirical results for simple benchmark problems as well as for a realistic blood inventory management problem.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {809–816},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553479,
author = {Plath, Nils and Toussaint, Marc and Nakajima, Shinichi},
title = {Multi-Class Image Segmentation Using Conditional Random Fields and Global Classification},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553479},
doi = {10.1145/1553374.1553479},
abstract = {A key aspect of semantic image segmentation is to integrate local and global features for the prediction of local segment labels. We present an approach to multi-class segmentation which combines two methods for this integration: a Conditional Random Field (CRF) which couples to local image features and an image classification method which considers global features. The CRF follows the approach of Reynolds &amp; Murphy (2007) and is based on an unsupervised multi scale pre-segmentation of the image into patches, where patch labels correspond to the random variables of the CRF. The output of the classifier is used to constraint this CRF. We demonstrate and compare the approach on a standard semantic segmentation data set.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {817–824},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553480,
author = {P\'{o}czos, Barnab\'{a}s and Abbasi-Yadkori, Yasin and Szepesv\'{a}ri, Csaba and Greiner, Russell and Sturtevant, Nathan},
title = {Learning When to Stop Thinking and Do Something!},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553480},
doi = {10.1145/1553374.1553480},
abstract = {An anytime algorithm is capable of returning a response to the given task at essentially any time; typically the quality of the response improves as the time increases. Here, we consider the challenge of learning when we should terminate such algorithms on each of a sequence of iid tasks, to optimize the expected average reward per unit time. We provide a system for addressing this challenge, which combines the global optimizer Cross-Entropy method with local gradient ascent. This paper theoretically investigates how far the estimated gradient is from the true gradient, then empirically demonstrates that this system is effective by applying it to a toy problem, as well as on a real-world face detection task.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {825–832},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553481,
author = {Putthividhya, Duangmanee (Pew) and Attias, Hagai T. and Nagarajan, Srikantan},
title = {Independent Factor Topic Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553481},
doi = {10.1145/1553374.1553481},
abstract = {Topic models such as Latent Dirichlet Allocation (LDA) and Correlated Topic Model (CTM) have recently emerged as powerful statistical tools for text document modeling. In this paper, we improve upon CTM and propose Independent Factor Topic Models (IFTM) which use linear latent variable models to uncover the hidden sources of correlation between topics. There are 2 main contributions of this work. First, by using a sparse source prior model, we can directly visualize sparse patterns of topic correlations. Secondly, the conditional independence assumption implied in the use of latent source variables allows the objective function to factorize, leading to a fast Newton-Raphson based variational inference algorithm. Experimental results on synthetic and real data show that IFTM runs on average 3--5 times faster than CTM, while giving competitive performance as measured by perplexity and loglikelihood of held-out data.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {833–840},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553482,
author = {Qi, Guo-Jun and Tang, Jinhui and Zha, Zheng-Jun and Chua, Tat-Seng and Zhang, Hong-Jiang},
title = {An Efficient Sparse Metric Learning in High-Dimensional Space via <i>l</i><sub>1</sub>-Penalized Log-Determinant Regularization},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553482},
doi = {10.1145/1553374.1553482},
abstract = {This paper proposes an efficient sparse metric learning algorithm in high dimensional space via an l1-penalized log-determinant regularization. Compare to the most existing distance metric learning algorithms, the proposed algorithm exploits the sparsity nature underlying the intrinsic high dimensional feature space. This sparsity prior of learning distance metric serves to regularize the complexity of the distance model especially in the "less example number p and high dimension d" setting. Theoretically, by analogy to the covariance estimation problem, we find the proposed distance learning algorithm has a consistent result at rate O (√m2 log d)/n) to the target distance matrix with at most m nonzeros per row. Moreover, from the implementation perspective, this l1-penalized log-determinant formulation can be efficiently optimized in a block coordinate descent fashion which is much faster than the standard semi-definite programming which has been widely adopted in many other advanced distance learning algorithms. We compare this algorithm with other state-of-the-art ones on various datasets and competitive results are obtained.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {841–848},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553483,
author = {Qian, Xian and Jiang, Xiaoqian and Zhang, Qi and Huang, Xuanjing and Wu, Lide},
title = {Sparse Higher Order Conditional Random Fields for Improved Sequence Labeling},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553483},
doi = {10.1145/1553374.1553483},
abstract = {In real sequence labeling tasks, statistics of many higher order features are not sufficient due to the training data sparseness, very few of them are useful. We describe Sparse Higher Order Conditional Random Fields (SHO-CRFs), which are able to handle local features and sparse higher order features together using a novel tractable exact inference algorithm. Our main insight is that states and transitions with same potential functions can be grouped together, and inference is performed on the grouped states and transitions. Though the complexity is not polynomial, SHO-CRFs are still efficient in practice because of the feature sparseness. Experimental results on optical character recognition and Chinese organization name recognition show that with the same higher order feature set, SHO-CRFs significantly outperform previous approaches.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {849–856},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553484,
author = {Quattoni, Ariadna and Carreras, Xavier and Collins, Michael and Darrell, Trevor},
title = {An Efficient Projection for <i>l</i><sub>1</sub>, <sub>∞</sub> Regularization},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553484},
doi = {10.1145/1553374.1553484},
abstract = {In recent years the l1, ∞ norm has been proposed for joint regularization. In essence, this type of regularization aims at extending the l1 framework for learning sparse models to a setting where the goal is to learn a set of jointly sparse models. In this paper we derive a simple and effective projected gradient method for optimization of l1, ∞ regularized problems. The main challenge in developing such a method resides on being able to compute efficient projections to the l1, ∞ ball. We present an algorithm that works in O(n log n) time and O(n) memory where n is the number of parameters. We test our algorithm in a multi-task image annotation problem. Our results show that l1, ∞ leads to better performance than both l2 and l1 regularization and that it is is effective in discovering jointly sparse solutions.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {857–864},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553485,
author = {Radovanovi\'{c}, Milo\v{s} and Nanopoulos, Alexandros and Ivanovi\'{c}, Mirjana},
title = {Nearest Neighbors in High-Dimensional Data: The Emergence and Influence of Hubs},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553485},
doi = {10.1145/1553374.1553485},
abstract = {High dimensionality can pose severe difficulties, widely recognized as different aspects of the curse of dimensionality. In this paper we study a new aspect of the curse pertaining to the distribution of k-occurrences, i.e., the number of times a point appears among the k nearest neighbors of other points in a data set. We show that, as dimensionality increases, this distribution becomes considerably skewed and hub points emerge (points with very high k-occurrences). We examine the origin of this phenomenon, showing that it is an inherent property of high-dimensional vector space, and explore its influence on applications based on measuring distances in vector spaces, notably classification, clustering, and information retrieval.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {865–872},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553486,
author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
title = {Large-Scale Deep Unsupervised Learning Using Graphics Processors},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553486},
doi = {10.1145/1553374.1553486},
abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton &amp; Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples.In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {873–880},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553487,
author = {Raman, Sudhir and Fuchs, Thomas J. and Wild, Peter J. and Dahl, Edgar and Roth, Volker},
title = {The Bayesian Group-Lasso for Analyzing Contingency Tables},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553487},
doi = {10.1145/1553374.1553487},
abstract = {Group-Lasso estimators, useful in many applications, suffer from lack of meaningful variance estimates for regression coefficients. To overcome such problems, we propose a full Bayesian treatment of the Group-Lasso, extending the standard Bayesian Lasso, using hierarchical expansion. The method is then applied to Poisson models for contingency tables using a highly efficient MCMC algorithm. The simulated experiments validate the performance of this method on artificial datasets with known ground-truth. When applied to a breast cancer dataset, the method demonstrates the capability of identifying the differences in interactions patterns of marker proteins between different patient groups.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {881–888},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553488,
author = {Raykar, Vikas C. and Yu, Shipeng and Zhao, Linda H. and Jerebko, Anna and Florin, Charles and Valadez, Gerardo Hermosillo and Bogoni, Luca and Moy, Linda},
title = {Supervised Learning from Multiple Experts: Whom to Trust When Everyone Lies a Bit},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553488},
doi = {10.1145/1553374.1553488},
abstract = {We describe a probabilistic approach for supervised learning when we have multiple experts/annotators providing (possibly noisy) labels but no absolute gold standard. The proposed algorithm evaluates the different experts and also gives an estimate of the actual hidden labels. Experimental results indicate that the proposed method is superior to the commonly used majority voting baseline.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {889–896},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553489,
author = {Reid, Mark D. and Williamson, Robert C.},
title = {Surrogate Regret Bounds for Proper Losses},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553489},
doi = {10.1145/1553374.1553489},
abstract = {We present tight surrogate regret bounds for the class of proper (i.e., Fisher consistent) losses. The bounds generalise the margin-based bounds due to Bartlett et al. (2006). The proof uses Taylor's theorem and leads to new representations for loss and regret and a simple proof of the integral representation of proper losses. We also present a different formulation of a duality result of Bregman divergences which leads to a simple demonstration of the convexity of composite losses using canonical link functions.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {897–904},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553490,
author = {Roy, Sushmita and Lane, Terran and Werner-Washburne, Margaret},
title = {Learning Structurally Consistent Undirected Probabilistic Graphical Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553490},
doi = {10.1145/1553374.1553490},
abstract = {In many real-world domains, undirected graphical models such as Markov random fields provide a more natural representation of the statistical dependency structure than directed graphical models. Unfortunately, structure learning of undirected graphs using likelihood-based scores remains difficult because of the intractability of computing the partition function. We describe a new Markov random field structure learning algorithm, motivated by canonical parameterization of Abbeel et al. We provide computational improvements on their parameterization by learning per-variable canonical factors, which makes our algorithm suitable for domains with hundreds of nodes. We compare our algorithm against several algorithms for learning undirected and directed models on simulated and real datasets from biology. Our algorithm frequently outperforms existing algorithms, producing higher-quality structures, suggesting that enforcing consistency during structure learning is beneficial for learning undirected graphs.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {905–912},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553491,
author = {Rueping, Stefan},
title = {Ranking Interesting Subgroups},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553491},
doi = {10.1145/1553374.1553491},
abstract = {Subgroup discovery is the task of identifying the top k patterns in a database with most significant deviation in the distribution of a target attribute Y. Subgroup discovery is a popular approach for identifying interesting patterns in data, because it combines statistical significance with an understandable representation of patterns as a logical formula. However, it is often a problem that some subgroups, even if they are statistically highly significant, are not interesting to the user. We present an approach based on the work on ranking Support Vector Machines that ranks subgroups with respect to the user's concept of interestingness, and finds more interesting subgroups. This approach can significantly increase the quality of the subgroups.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {913–920},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553492,
author = {Schmidt, Mikkel N.},
title = {Function Factorization Using Warped Gaussian Processes},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553492},
doi = {10.1145/1553374.1553492},
abstract = {We introduce a new approach to non-linear regression called function factorization, that is suitable for problems where an output variable can reasonably be modeled by a number of multiplicative interaction terms between non-linear functions of the inputs. The idea is to approximate a complicated function on a high-dimensional space by the sum of products of simpler functions on lower-dimensional subspaces. Function factorization can be seen as a generalization of matrix and tensor factorization methods, in which the data are approximated by the sum of outer products of vectors. We present a non-parametric Bayesian approach to function factorization where the priors over the factorizing functions are warped Gaussian processes, and we do inference using Hamiltonian Markov chain Monte Carlo. We demonstrate the superior predictive performance of the method on a food science data set compared to Gaussian process regression and tensor factorization using PARAFAC and GEMANOVA models.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {921–928},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553493,
author = {Shalev-Shwartz, Shai and Tewari, Ambuj},
title = {Stochastic Methods for <i>l</i><sub>1</sub> Regularized Loss Minimization},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553493},
doi = {10.1145/1553374.1553493},
abstract = {We describe and analyze two stochastic methods for l1 regularized loss minimization problems, such as the Lasso. The first method updates the weight of a single feature at each iteration while the second method updates the entire weight vector but only uses a single training example at each iteration. In both methods, the choice of feature/example is uniformly at random. Our theoretical runtime analysis suggests that the stochastic methods should outperform state-of-the-art deterministic approaches, including their deterministic counterparts, when the size of the problem is large. We demonstrate the advantage of stochastic methods by experimenting with synthetic and natural data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {929–936},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553494,
author = {Shaw, Blake and Jebara, Tony},
title = {Structure Preserving Embedding},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553494},
doi = {10.1145/1553374.1553494},
abstract = {Structure Preserving Embedding (SPE) is an algorithm for embedding graphs in Euclidean space such that the embedding is low-dimensional and preserves the global topological properties of the input graph. Topology is preserved if a connectivity algorithm, such as k-nearest neighbors, can easily recover the edges of the input graph from only the coordinates of the nodes after embedding. SPE is formulated as a semidefinite program that learns a low-rank kernel matrix constrained by a set of linear inequalities which captures the connectivity structure of the input graph. Traditional graph embedding algorithms do not preserve structure according to our definition, and thus the resulting visualizations can be misleading or less informative. SPE provides significant improvements in terms of visualization and lossless compression of graphs, outperforming popular methods such as spectral embedding and Laplacian eigen-maps. We find that many classical graphs and networks can be properly embedded using only a few dimensions. Furthermore, introducing structure preserving constraints into dimensionality reduction algorithms produces more accurate representations of high-dimensional data.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {937–944},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553495,
author = {Silver, David and Tesauro, Gerald},
title = {Monte-Carlo Simulation Balancing},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553495},
doi = {10.1145/1553374.1553495},
abstract = {In this paper we introduce the first algorithms for efficiently learning a simulation policy for Monte-Carlo search. Our main idea is to optimise the balance of a simulation policy, so that an accurate spread of simulation outcomes is maintained, rather than optimising the direct strength of the simulation policy. We develop two algorithms for balancing a simulation policy by gradient descent. The first algorithm optimises the balance of complete simulations, using a policy gradient algorithm; whereas the second algorithm optimises the balance over every two steps of simulation. We compare our algorithms to reinforcement learning and supervised learning algorithms for maximising the strength of the simulation policy. We test each algorithm in the domain of 5 x 5 and 6 x 6 Computer Go, using a softmax policy that is parameterised by weights for a hundred simple patterns. When used in a simple Monte-Carlo search, the policies learnt by simulation balancing achieved significantly better performance, with half the mean squared error of a uniform random policy, and similar overall performance to a sophisticated Go engine.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {945–952},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553496,
author = {Sindhwani, Vikas and Melville, Prem and Lawrence, Richard D.},
title = {Uncertainty Sampling and Transductive Experimental Design for Active Dual Supervision},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553496},
doi = {10.1145/1553374.1553496},
abstract = {Dual supervision refers to the general setting of learning from both labeled examples as well as labeled features. Labeled features are naturally available in tasks such as text classification where it is frequently possible to provide domain knowledge in the form of words that associate strongly with a class. In this paper, we consider the novel problem of active dual supervision, or, how to optimally query an example and feature labeling oracle to simultaneously collect two different forms of supervision, with the objective of building the best classifier in the most cost effective manner. We apply classical uncertainty and experimental design based active learning schemes to graph/kernel-based dual supervision models. Empirical studies confirm the potential of these schemes to significantly reduce the cost of acquiring labeled data for training high-quality models.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {953–960},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553497,
author = {Song, Le and Huang, Jonathan and Smola, Alex and Fukumizu, Kenji},
title = {Hilbert Space Embeddings of Conditional Distributions with Applications to Dynamical Systems},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553497},
doi = {10.1145/1553374.1553497},
abstract = {In this paper, we extend the Hilbert space embedding approach to handle conditional distributions. We derive a kernel estimate for the conditional embedding, and show its connection to ordinary embeddings. Conditional embeddings largely extend our ability to manipulate distributions in Hilbert spaces, and as an example, we derive a nonparametric method for modeling dynamical systems where the belief state of the system is maintained as a conditional embedding. Our method is very general in terms of both the domains and the types of distributions that it can handle, and we demonstrate the effectiveness of our method in various dynamical systems. We expect that conditional embeddings will have wider applications beyond modeling dynamical systems.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {961–968},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553498,
author = {Streich, Andreas P. and Frank, Mario and Basin, David and Buhmann, Joachim M.},
title = {Multi-Assignment Clustering for Boolean Data},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553498},
doi = {10.1145/1553374.1553498},
abstract = {Conventional clustering methods typically assume that each data item belongs to a single cluster. This assumption does not hold in general. In order to overcome this limitation, we propose a generative method for clustering vectorial data, where each object can be assigned to multiple clusters. Using a deterministic annealing scheme, our method decomposes the observed data into the contributions of individual clusters and infers their parameters.Experiments on synthetic Boolean data show that our method achieves higher accuracy in the source parameter estimation and superior cluster stability compared to state-of-the-art approaches. We also apply our method to an important problem in computer security known as role mining. Experiments on real-world access control data show performance gains in generalization to new employees against other multi-assignment methods. In challenging situations with high noise levels, our approach maintains its good performance, while alternative state-of-the-art techniques lack robustness.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {969–976},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553499,
author = {Sun, Liang and Ji, Shuiwang and Ye, Jieping},
title = {A Least Squares Formulation for a Class of Generalized Eigenvalue Problems in Machine Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553499},
doi = {10.1145/1553374.1553499},
abstract = {Many machine learning algorithms can be formulated as a generalized eigenvalue problem. One major limitation of such formulation is that the generalized eigenvalue problem is computationally expensive to solve especially for large-scale problems. In this paper, we show that under a mild condition, a class of generalized eigenvalue problems in machine learning can be formulated as a least squares problem. This class of problems include classical techniques such as Canonical Correlation Analysis (CCA), Partial Least Squares (PLS), and Linear Discriminant Analysis (LDA), as well as Hypergraph Spectral Learning (HSL). As a result, various regularization techniques can be readily incorporated into the formulation to improve model sparsity and generalization ability. In addition, the least squares formulation leads to efficient and scalable implementations based on the iterative conjugate gradient type algorithms. We report experimental results that confirm the established equivalence relationship. Results also demonstrate the efficiency and effectiveness of the equivalent least squares formulations on large-scale problems.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {977–984},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553500,
author = {Sutskever, Ilya},
title = {A Simpler Unified Analysis of Budget Perceptrons},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553500},
doi = {10.1145/1553374.1553500},
abstract = {The kernel Perceptron is an appealing online learning algorithm that has a drawback: whenever it makes an error it must increase its support set, which slows training and testing if the number of errors is large. The Forgetron and the Randomized Budget Perceptron algorithms overcome this problem by restricting the number of support vectors the Perceptron is allowed to have. These algorithms have regret bounds whose proofs are dissimilar. In this paper we propose a unified analysis of both of these algorithms by observing that the way in which they remove support vectors can be seen as types of L2-regularization. By casting these algorithms as instances of online convex optimization problems and applying a variant of Zinkevich's theorem for noisy and incorrect gradient, we can bound the regret of these algorithms more easily than before. Our bounds are similar to the existing ones, but the proofs are less technical.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {985–992},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553501,
author = {Sutton, Richard S. and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv\'{a}ri, Csaba and Wiewiora, Eric},
title = {Fast Gradient-Descent Methods for Temporal-Difference Learning with Linear Function Approximation},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553501},
doi = {10.1145/1553374.1553501},
abstract = {Sutton, Szepesv\'{a}ri and Maei (2009) recently introduced the first temporal-difference learning algorithm compatible with both linear function approximation and off-policy training, and whose complexity scales only linearly in the size of the function approximator. Although their gradient temporal difference (GTD) algorithm converges reliably, it can be very slow compared to conventional linear TD (on on-policy problems where TD is convergent), calling into question its practical utility. In this paper we introduce two new related algorithms with better convergence rates. The first algorithm, GTD2, is derived and proved convergent just as GTD was, but uses a different objective function and converges significantly faster (but still not as fast as conventional TD). The second new algorithm, linear TD with gradient correction, or TDC, uses the same update rule as conventional TD except for an additional term which is initially zero. In our experiments on small test problems and in a Computer Go application with a million features, the learning rate of this algorithm was comparable to that of conventional TD. This algorithm appears to extend linear TD to off-policy learning with no penalty in performance while only doubling computational requirements.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {993–1000},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553502,
author = {Szita, Istv\'{a}n and L\H{o}rincz, Andr\'{a}s},
title = {Optimistic Initialization and Greediness Lead to Polynomial Time Learning in Factored MDPs},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553502},
abstract = {In this paper we propose an algorithm for polynomial-time reinforcement learning in factored Markov decision processes (FMDPs). The factored optimistic initial model (FOIM) algorithm, maintains an empirical model of the FMDP in a conventional way, and always follows a greedy policy with respect to its model. The only trick of the algorithm is that the model is initialized optimistically. We prove that with suitable initialization (i) FOIM converges to the fixed point of approximate value iteration (AVI); (ii) the number of steps when the agent makes non-near-optimal decisions (with respect to the solution of AVI) is polynomial in all relevant quantities; (iii) the per-step costs of the algorithm are also polynomial. To our best knowledge, FOIM is the first algorithm with these properties.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1001–1008},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553503,
author = {Szlam, Arthur and Sapiro, Guillermo},
title = {Discriminative <i>k</i>-Metrics},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553503},
doi = {10.1145/1553374.1553503},
abstract = {The k q-flats algorithm is a generalization of the popular k-means algorithm where q dimensional best fit affine sets replace centroids as the cluster prototypes. In this work, a modification of the k q-flats framework for pattern classification is introduced. The basic idea is to replace the original reconstruction only energy, which is optimized to obtain the k affine spaces, by a new energy that incorporates discriminative terms. This way, the actual classification task is introduced as part of the design and optimization. The presentation of the proposed framework is complemented with experimental results, showing that the method is computationally very efficient and gives excellent results on standard supervised learning benchmarks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1009–1016},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553504,
author = {Taylor, Gavin and Parr, Ronald},
title = {Kernelized Value Function Approximation for Reinforcement Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553504},
doi = {10.1145/1553374.1553504},
abstract = {A recent surge in research in kernelized approaches to reinforcement learning has sought to bring the benefits of kernelized machine learning techniques to reinforcement learning. Kernelized reinforcement learning techniques are fairly new and different authors have approached the topic with different assumptions and goals. Neither a unifying view nor an understanding of the pros and cons of different approaches has yet emerged. In this paper, we offer a unifying view of the different approaches to kernelized value function approximation for reinforcement learning. We show that, except for different approaches to regularization, Kernelized LSTD (KLSTD) is equivalent to a modelbased approach that uses kernelized regression to find an approximate reward and transition model, and that Gaussian Process Temporal Difference learning (GPTD) returns a mean value function that is equivalent to these other approaches. We also discuss the relationship between our modelbased approach and the earlier Gaussian Processes in Reinforcement Learning (GPRL). Finally, we decompose the Bellman error into the sum of transition error and reward error terms, and demonstrate through experiments that this decomposition can be helpful in choosing regularization parameters.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1017–1024},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553505,
author = {Taylor, Graham W. and Hinton, Geoffrey E.},
title = {Factored Conditional Restricted Boltzmann Machines for Modeling Motion Style},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553505},
doi = {10.1145/1553374.1553505},
abstract = {The Conditional Restricted Boltzmann Machine (CRBM) is a recently proposed model for time series that has a rich, distributed hidden state and permits simple, exact inference. We present a new model, based on the CRBM that preserves its most important computational properties and includes multiplicative three-way interactions that allow the effective interaction weight between two units to be modulated by the dynamic state of a third unit. We factor the three-way weight tensor implied by the multiplicative model, reducing the number of parameters from O(N3) to O(N2). The result is an efficient, compact model whose effectiveness we demonstrate by modeling human motion. Like the CRBM, our model can capture diverse styles of motion with a single set of parameters, and the three-way interactions greatly improve the model's ability to blend motion styles or to transition smoothly among them.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1025–1032},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553506,
author = {Tieleman, Tijmen and Hinton, Geoffrey},
title = {Using Fast Weights to Improve Persistent Contrastive Divergence},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553506},
abstract = {The most commonly used learning algorithm for restricted Boltzmann machines is contrastive divergence which starts a Markov chain at a data point and runs the chain for only a few iterations to get a cheap, low variance estimate of the sufficient statistics under the model. Tieleman (2008) showed that better learning can be achieved by estimating the model's statistics using a small set of persistent "fantasy particles" that are not reinitialized to data points after each weight update. With sufficiently small weight updates, the fantasy particles represent the equilibrium distribution accurately but to explain why the method works with much larger weight updates it is necessary to consider the interaction between the weight updates and the Markov chain. We show that the weight updates force the Markov chain to mix fast, and using this insight we develop an even faster mixing chain that uses an auxiliary set of "fast weights" to implement a temporary overlay on the energy landscape. The fast weights learn rapidly but also decay rapidly and do not contribute to the normal energy landscape that defines the model.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1033–1040},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553507,
author = {Tillman, Robert E.},
title = {Structure Learning with Independent Non-Identically Distributed Data},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553507},
doi = {10.1145/1553374.1553507},
abstract = {There are well known algorithms for learning the structure of directed and undirected graphical models from data, but nearly all assume that the data consists of a single i.i.d. sample. In contexts such as fMRI analysis, data may consist of an ensemble of independent samples from a common data generating mechanism which may not have identical distributions. Pooling such data can result in a number of well known statistical problems so each sample must be analyzed individually, which offers no increase in power due to the presence of multiple samples. We show how existing constraint based methods can be modified to learn structure from the aggregate of such data in a statistically sound manner. The prescribed method is simple to implement and based on existing statistical methods employed in metaanalysis and other areas, but works surprisingly well in this context where there are increased concerns due to issues such as retesting. We report results for directed models, but the method given is just as applicable to undirected models.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1041–1048},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553508,
author = {Toussaint, Marc},
title = {Robot Trajectory Optimization Using Approximate Inference},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553508},
doi = {10.1145/1553374.1553508},
abstract = {The general stochastic optimal control (SOC) problem in robotics scenarios is often too complex to be solved exactly and in near real time. A classical approximate solution is to first compute an optimal (deterministic) trajectory and then solve a local linear-quadratic-gaussian (LQG) perturbation model to handle the system stochasticity. We present a new algorithm for this approach which improves upon previous algorithms like iLQG. We consider a probabilistic model for which the maximum likelihood (ML) trajectory coincides with the optimal trajectory and which, in the LQG case, reproduces the classical SOC solution. The algorithm then utilizes approximate inference methods (similar to expectation propagation) that efficiently generalize to non-LQG systems. We demonstrate the algorithm on a simulated 39-DoF humanoid robot.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1049–1056},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553509,
author = {Usunier, Nicolas and Buffoni, David and Gallinari, Patrick},
title = {Ranking with Ordered Weighted Pairwise Classification},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553509},
doi = {10.1145/1553374.1553509},
abstract = {In ranking with the pairwise classification approach, the loss associated to a predicted ranked list is the mean of the pairwise classification losses. This loss is inadequate for tasks like information retrieval where we prefer ranked lists with high precision on the top of the list. We propose to optimize a larger class of loss functions for ranking, based on an ordered weighted average (OWA) (Yager, 1988) of the classification losses. Convex OWA aggregation operators range from the max to the mean depending on their weights, and can be used to focus on the top ranked elements as they give more weight to the largest losses. When aggregating hinge losses, the optimization problem is similar to the SVM for interdependent output spaces. Moreover, we show that OWA aggregates of margin-based classification losses have good generalization properties. Experiments on the Letor 3.0 benchmark dataset for information retrieval validate our approach.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1057–1064},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553510,
author = {Varma, Manik and Babu, Bodla Rakesh},
title = {More Generality in Efficient Multiple Kernel Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553510},
doi = {10.1145/1553374.1553510},
abstract = {Recent advances in Multiple Kernel Learning (MKL) have positioned it as an attractive tool for tackling many supervised learning tasks. The development of efficient gradient descent based optimization schemes has made it possible to tackle large scale problems. Simultaneously, MKL based algorithms have achieved very good results on challenging real world applications. Yet, despite their successes, MKL approaches are limited in that they focus on learning a linear combination of given base kernels.In this paper, we observe that existing MKL formulations can be extended to learn general kernel combinations subject to general regularization. This can be achieved while retaining all the efficiency of existing large scale optimization algorithms. To highlight the advantages of generalized kernel learning, we tackle feature selection problems on benchmark vision and UCI databases. It is demonstrated that the proposed formulation can lead to better results not only as compared to traditional MKL but also as compared to state-of-the-art wrapper and filter methods for feature selection.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1065–1072},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553511,
author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
title = {Information Theoretic Measures for Clusterings Comparison: Is a Correction for Chance Necessary?},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553511},
doi = {10.1145/1553374.1553511},
abstract = {Information theoretic based measures form a fundamental class of similarity measures for comparing clusterings, beside the class of pair-counting based and set-matching based measures. In this paper, we discuss the necessity of correction for chance for information theoretic based measures for clusterings comparison. We observe that the baseline for such measures, i.e. average value between random partitions of a data set, does not take on a constant value, and tends to have larger variation when the ratio between the number of data points and the number of clusters is small. This effect is similar in some other non-information theoretic based measures such as the well-known Rand Index. Assuming a hypergeometric model of randomness, we derive the analytical formula for the expected mutual information value between a pair of clusterings, and then propose the adjusted version for several popular information theoretic based measures. Some examples are given to demonstrate the need and usefulness of the adjusted measures.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1073–1080},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553512,
author = {Vlassis, Nikos and Toussaint, Marc},
title = {Model-Free Reinforcement Learning as Mixture Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553512},
doi = {10.1145/1553374.1553512},
abstract = {We cast model-free reinforcement learning as the problem of maximizing the likelihood of a probabilistic mixture model via sampling, addressing both the infinite and finite horizon cases. We describe a Stochastic Approximation EM algorithm for likelihood maximization that, in the tabular case, is equivalent to a non-bootstrapping optimistic policy iteration algorithm like Sarsa(1) that can be applied both in MDPs and POMDPs. On the theoretical side, by relating the proposed stochastic EM algorithm to the family of optimistic policy iteration algorithms, we provide new tools that permit the design and analysis of algorithms in that family. On the practical side, preliminary experiments on a POMDP problem demonstrated encouraging results.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1081–1088},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553513,
author = {Volkovs, Maksims N. and Zemel, Richard S.},
title = {BoltzRank: Learning to Maximize Expected Ranking Gain},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553513},
abstract = {Ranking a set of retrieved documents according to their relevance to a query is a popular problem in information retrieval. Methods that learn ranking functions are difficult to optimize, as ranking performance is typically judged by metrics that are not smooth. In this paper we propose a new listwise approach to learning to rank. Our method creates a conditional probability distribution over rankings assigned to documents for a given query, which permits gradient ascent optimization of the expected value of some performance measure. The rank probabilities take the form of a Boltzmann distribution, based on an energy function that depends on a scoring function composed of individual and pairwise potentials. Including pairwise potentials is a novel contribution, allowing the model to encode regularities in the relative scores of documents; existing models assign scores at test time based only on individual documents, with no pairwise constraints between documents. Experimental results on the LETOR3.0 data set show that our method out-performs existing learning approaches to ranking.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1089–1096},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553514,
author = {Wagstaff, Kiri L. and Bornstein, Benjamin},
title = {K-Means in Space: A Radiation Sensitivity Evaluation},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553514},
doi = {10.1145/1553374.1553514},
abstract = {Spacecraft increasingly employ onboard data analysis to inform further data collection and prioritization decisions. However, many spacecraft operate in high-radiation environments in which the reliability of dataintensive computation is not known. This paper presents the first study of radiation sensitivity for k-means clustering. Our key findings are 1) k-means data structures differ in sensitivity, which is not determined solely by the amount of memory exposed; 2) no special radiation protection is needed below a data-set-dependent radiation threshold, enabling the use of faster, smaller, and cheaper onboard memory; and 3) subsampling improves radiation tolerance slightly, but the use of kd-trees unfortunately reduces tolerance. Our conclusions can help tailor k-means for use in future high-radiation environments.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1097–1104},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553515,
author = {Wallach, Hanna M. and Murray, Iain and Salakhutdinov, Ruslan and Mimno, David},
title = {Evaluation Methods for Topic Models},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553515},
abstract = {A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1105–1112},
numpages = {8}
}

@inbook{10.1145/1553374.1553516,
author = {Weinberger, Kilian and Dasgupta, Anirban and Langford, John and Smola, Alex and Attenberg, Josh},
title = {Feature Hashing for Large Scale Multitask Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553516},
abstract = {Empirical evidence suggests that hashing is an effective strategy for dimensionality reduction and practical nonparametric estimation. In this paper we provide exponential tail bounds for feature hashing and show that the interaction between random subspaces is negligible with high probability. We demonstrate the feasibility of this approach with experimental results for a new use case --- multitask learning with hundreds of thousands of tasks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1113–1120},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553517,
author = {Welling, Max},
title = {Herding Dynamical Weights to Learn},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553517},
doi = {10.1145/1553374.1553517},
abstract = {A new "herding" algorithm is proposed which directly converts observed moments into a sequence of pseudo-samples. The pseudo-samples respect the moment constraints and may be used to estimate (unobserved) quantities of interest. The procedure allows us to sidestep the usual approach of first learning a joint model (which is intractable) and then sampling from that model (which can easily get stuck in a local mode). Moreover, the algorithm is fully deterministic, avoiding random number generation) and does not need expensive operations such as exponentiation.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1121–1128},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553518,
author = {Wood, Frank and Archambeau, C\'{e}dric and Gasthaus, Jan and James, Lancelot and Teh, Yee Whye},
title = {A Stochastic Memoizer for Sequence Data},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553518},
abstract = {We propose an unbounded-depth, hierarchical, Bayesian nonparametric model for discrete sequence data. This model can be estimated from a single training sequence, yet shares statistical strength between subsequent symbol predictive distributions in such a way that predictive performance generalizes well. The model builds on a specific parameterization of an unbounded-depth hierarchical Pitman-Yor process. We introduce analytic marginalization steps (using coagulation operators) to reduce this model to one that can be represented in time and space linear in the length of the training sequence. We show how to perform inference in such a model without truncation approximation and introduce fragmentation operators necessary to do predictive inference. We demonstrate the sequence memoizer by using it as a language model, achieving state-of-the-art results.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1129–1136},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553519,
author = {Xu, Linli and White, Martha and Schuurmans, Dale},
title = {Optimal Reverse Prediction: A Unified Perspective on Supervised, Unsupervised and Semi-Supervised Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553519},
doi = {10.1145/1553374.1553519},
abstract = {Training principles for unsupervised learning are often derived from motivations that appear to be independent of supervised learning. In this paper we present a simple unification of several supervised and unsupervised training principles through the concept of optimal reverse prediction: predict the inputs from the target labels, optimizing both over model parameters and any missing labels. In particular, we show how supervised least squares, principal components analysis, k-means clustering and normalized graph-cut can all be expressed as instances of the same training principle. Natural forms of semi-supervised regression and classification are then automatically derived, yielding semi-supervised learning algorithms for regression and classification that, surprisingly, are novel and refine the state of the art. These algorithms can all be combined with standard regularizers and made non-linear via kernels.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1137–1144},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553520,
author = {Xu, Zenglin and Jin, Rong and Ye, Jieping and Lyu, Michael R. and King, Irwin},
title = {Non-Monotonic Feature Selection},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553520},
doi = {10.1145/1553374.1553520},
abstract = {We consider the problem of selecting a subset of m most informative features where m is the number of required features. This feature selection problem is essentially a combinatorial optimization problem, and is usually solved by an approximation. Conventional feature selection methods address the computational challenge in two steps: (a) ranking all the features by certain scores that are usually computed independently from the number of specified features m, and (b) selecting the top m ranked features. One major shortcoming of these approaches is that if a feature f is chosen when the number of specified features is m, it will always be chosen when the number of specified features is larger than m. We refer to this property as the "monotonic" property of feature selection. In this work, we argue that it is important to develop efficient algorithms for non-monotonic feature selection. To this end, we develop an algorithm for non-monotonic feature selection that approximates the related combinatorial optimization problem by a Multiple Kernel Learning (MKL) problem. We also present a strategy that derives a discrete solution from the approximate solution of MKL, and show the performance guarantee for the derived discrete solution when compared to the global optimal solution for the related combinatorial optimization problem. An empirical study with a number of benchmark data sets indicates the promising performance of the proposed framework compared with several state-of-the-art approaches for feature selection.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1145–1152},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553521,
author = {Yang, Liu and Jin, Rong and Ye, Jieping},
title = {Online Learning by Ellipsoid Method},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553521},
abstract = {In this work, we extend the ellipsoid method, which was originally designed for convex optimization, for online learning. The key idea is to approximate by an ellipsoid the classification hypotheses that are consistent with all the training examples received so far. This is in contrast to most online learning algorithms where only a single classifier is maintained at each iteration. Efficient algorithms are presented for updating both the centroid and the positive definite matrix of ellipsoid given a misclassified example. In addition to the classical ellipsoid method, an improved version for online learning is also presented. Mistake bounds for both ellipsoid methods are derived. Evaluation with the USPS dataset and three UCI data-sets shows encouraging results when comparing the proposed online learning algorithm to two state-of-the-art online learners.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1153–1160},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553522,
author = {Yi, Sun and Wierstra, Daan and Schaul, Tom and Schmidhuber, J\"{u}rgen},
title = {Stochastic Search Using the Natural Gradient},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553522},
doi = {10.1145/1553374.1553522},
abstract = {To optimize unknown 'fitness' functions, we present Natural Evolution Strategies, a novel algorithm that constitutes a principled alternative to standard stochastic search methods. It maintains a multinormal distribution on the set of solution candidates. The Natural Gradient is used to update the distribution's parameters in the direction of higher expected fitness, by efficiently calculating the inverse of the exact Fisher information matrix whereas previous methods had to use approximations. Other novel aspects of our method include optimal fitness baselines and importance mixing, a procedure adjusting batches with minimal numbers of fitness evaluations. The algorithm yields competitive results on a number of benchmarks.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1161–1168},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553523,
author = {Yu, Chun-Nam John and Joachims, Thorsten},
title = {Learning Structural SVMs with Latent Variables},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553523},
doi = {10.1145/1553374.1553523},
abstract = {We present a large-margin formulation and algorithm for structured output prediction that allows the use of latent variables. Our proposal covers a large range of application problems, with an optimization problem that can be solved efficiently using Concave-Convex Programming. The generality and performance of the approach is demonstrated through three applications including motiffinding, noun-phrase coreference resolution, and optimizing precision at k in information retrieval.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1169–1176},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553524,
author = {Yu, Jia Yuan and Mannor, Shie},
title = {Piecewise-Stationary Bandit Problems with Side Observations},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553524},
doi = {10.1145/1553374.1553524},
abstract = {We consider a sequential decision problem where the rewards are generated by a piecewise-stationary distribution. However, the different reward distributions are unknown and may change at unknown instants. Our approach uses a limited number of side observations on past rewards, but does not require prior knowledge of the frequency of changes. In spite of the adversarial nature of the reward process, we provide an algorithm whose regret, with respect to the baseline with perfect knowledge of the distributions and the changes, is O(k log(T)), where k is the number of changes up to time T. This is in contrast to the case where side observations are not available, and where the regret is at least Ω(√T).},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1177–1184},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553525,
author = {Yu, Kai and Lafferty, John and Zhu, Shenghuo and Gong, Yihong},
title = {Large-Scale Collaborative Prediction Using a Nonparametric Random Effects Model},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553525},
abstract = {A nonparametric model is introduced that allows multiple related regression tasks to take inputs from a common data space. Traditional transfer learning models can be inappropriate if the dependence among the outputs cannot be fully resolved by known input-specific and task-specific predictors. The proposed model treats such output responses as conditionally independent, given known predictors and appropriate unobserved random effects. The model is nonparametric in the sense that the dimensionality of random effects is not specified a priori but is instead determined from data. An approach to estimating the model is presented uses an EM algorithm that is efficient on a very large scale collaborative prediction problem. The obtained prediction accuracy is competitive with state-of-the-art results.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1185–1192},
numpages = {8}
}

@inbook{10.1145/1553374.1553526,
author = {Yuan, Xiao-Tong and Hu, Bao-Gang},
title = {Robust Feature Extraction via Information Theoretic Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553526},
abstract = {In this paper, we present a robust feature extraction framework based on information-theoretic learning. Its formulated objective aims at simultaneously maximizing the Renyi's quadratic information potential of features and the Renyi's cross information potential between features and class labels. This objective function reaps the advantages in robustness from both redescending M-estimator and manifold regularization, and can be efficiently optimized via half-quadratic optimization in an iterative manner. In addition, the popular algorithms LPP, SRDA and LapRLS for feature extraction are all justified to be the special cases within this framework. Extensive comparison experiments on several real-world data sets, with contaminated features or labels, well validate the encouraging gain in algorithmic robustness from this proposed framework.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1193–1200},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553527,
author = {Yue, Yisong and Joachims, Thorsten},
title = {Interactively Optimizing Information Retrieval Systems as a Dueling Bandits Problem},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553527},
doi = {10.1145/1553374.1553527},
abstract = {We present an on-line learning framework tailored towards real-time learning from observed user behavior in search engines and other information retrieval systems. In particular, we only require pairwise comparisons which were shown to be reliably inferred from implicit feedback (Joachims et al., 2007; Radlinski et al., 2008b). We will present an algorithm with theoretical guarantees as well as simulation results.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1201–1208},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553528,
author = {Yuille, Alan and Zheng, Songfeng},
title = {Compositional Noisy-Logical Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553528},
doi = {10.1145/1553374.1553528},
abstract = {We describe a new method for learning the conditional probability distribution of a binary-valued variable from labelled training examples. Our proposed Compositional Noisy-Logical Learning (CNLL) approach learns a noisy-logical distribution in a compositional manner. CNLL is an alternative to the well-known AdaBoost algorithm which performs coordinate descent on an alternative error measure. We describe two CNLL algorithms and test their performance compared to AdaBoost on two types of problem: (i) noisy-logical data (such as noisy exclusive-or), and (ii) four standard datasets from the UCI repository. Our results show that we outperform AdaBoost while using significantly fewer weak classifiers, thereby giving a more transparent classifier suitable for knowledge extraction.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1209–1216},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553529,
author = {Zang, Peng and Zhou, Peng and Minnen, David and Isbell, Charles},
title = {Discovering Options from Example Trajectories},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553529},
doi = {10.1145/1553374.1553529},
abstract = {We present a novel technique for automated problem decomposition to address the problem of scalability in reinforcement learning. Our technique makes use of a set of near-optimal trajectories to discover options and incorporates them into the learning process, dramatically reducing the time it takes to solve the underlying problem. We run a series of experiments in two different domains and show that our method offers up to 30 fold speedup over the baseline.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1217–1224},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553530,
author = {Zhan, De-Chuan and Li, Ming and Li, Yu-Feng and Zhou, Zhi-Hua},
title = {Learning Instance Specific Distances Using Metric Propagation},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553530},
doi = {10.1145/1553374.1553530},
abstract = {In many real-world applications, such as image retrieval, it would be natural to measure the distances from one instance to others using instance specific distance which captures the distinctions from the perspective of the concerned instance. However, there is no complete framework for learning instance specific distances since existing methods are incapable of learning such distances for test instance and unlabeled data. In this paper, we propose the Isd method to address this issue. The key of Isd is metric propagation, that is, propagating and adapting metrics of individual labeled examples to individual unlabeled instances. We formulate the problem into a convex optimization framework and derive efficient solutions. Experiments show that Isd can effectively learn instance specific distances for labeled as well as unlabeled instances. The metric propagation scheme can also be used in other scenarios.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1225–1232},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553531,
author = {Zhang, Kai and Kwok, James T. and Parvin, Bahram},
title = {Prototype Vector Machine for Large Scale Semi-Supervised Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553531},
abstract = {Practical data mining rarely falls exactly into the supervised learning scenario. Rather, the growing amount of unlabeled data poses a big challenge to large-scale semi-supervised learning (SSL). We note that the computational intensiveness of graph-based SSL arises largely from the manifold or graph regularization, which in turn lead to large models that are difficult to handle. To alleviate this, we proposed the prototype vector machine (PVM), a highly scalable, graph-based algorithm for large-scale SSL. Our key innovation is the use of "prototypes vectors" for efficient approximation on both the graph-based regularizer and model representation. The choice of prototypes are grounded upon two important criteria: they not only perform effective low-rank approximation of the kernel matrix, but also span a model suffering the minimum information loss compared with the complete model. We demonstrate encouraging performance and appealing scaling properties of the PVM on a number of machine learning benchmark data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1233–1240},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553533,
author = {Zhang, Wei and Surve, Akshat and Fern, Xiaoli and Dietterich, Thomas},
title = {Learning Non-Redundant Codebooks for Classifying Complex Objects},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553533},
doi = {10.1145/1553374.1553533},
abstract = {Codebook-based representations are widely employed in the classification of complex objects such as images and documents. Most previous codebook-based methods construct a single codebook via clustering that maps a bag of low-level features into a fixed-length histogram that describes the distribution of these features. This paper describes a simple yet effective framework for learning multiple non-redundant codebooks that produces surprisingly good results. In this framework, each codebook is learned in sequence to extract discriminative information that was not captured by preceding codebooks and their corresponding classifiers. We apply this framework to two application domains: visual object categorization and document classification. Experiments on large classification tasks show substantial improvements in performance compared to a single codebook or codebooks learned in a bagging style.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1241–1248},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553534,
author = {Zhou, Zhi-Hua and Sun, Yu-Yin and Li, Yu-Feng},
title = {Multi-Instance Learning by Treating Instances as Non-I.I.D. Samples},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553534},
doi = {10.1145/1553374.1553534},
abstract = {Previous studies on multi-instance learning typically treated instances in the bags as independently and identically distributed. The instances in a bag, however, are rarely independent in real tasks, and a better performance can be expected if the instances are treated in an non-i.i.d. way that exploits relations among instances. In this paper, we propose two simple yet effective methods. In the first method, we explicitly map every bag to an undirected graph and design a graph kernel for distinguishing the positive and negative bags. In the second method, we implicitly construct graphs by deriving affinity matrices and propose an efficient graph kernel considering the clique information. The effectiveness of the proposed methods are validated by experiments.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1249–1256},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553535,
author = {Zhu, Jun and Ahmed, Amr and Xing, Eric P.},
title = {MedLDA: Maximum Margin Supervised Topic Models for Regression and Classification},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553535},
doi = {10.1145/1553374.1553535},
abstract = {Supervised topic models utilize document's side information for discovering predictive low dimensional representations of documents; and existing models apply likelihood-based estimation. In this paper, we present a max-margin supervised topic model for both continuous and categorical response variables. Our approach, the maximum entropy discrimination latent Dirichlet allocation (MedLDA), utilizes the max-margin principle to train supervised topic models and estimate predictive topic representations that are arguably more suitable for prediction. We develop efficient variational methods for posterior inference and demonstrate qualitatively and quantitatively the advantages of MedLDA over likelihood-based topic models on movie review and 20 Newsgroups data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1257–1264},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553536,
author = {Zhu, Jun and Xing, Eric P.},
title = {On Primal and Dual Sparsity of Markov Networks},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553536},
doi = {10.1145/1553374.1553536},
abstract = {Sparsity is a desirable property in high dimensional learning. The l1-norm regularization can lead to primal sparsity, while max-margin methods achieve dual sparsity. Combining these two methods, an l1-norm max-margin Markov network (l1-M3N) can achieve both types of sparsity. This paper analyzes its connections to the Laplace max-margin Markov network (LapM3N), which inherits the dual sparsity of max-margin models but is pseudo-primal sparse, and to a novel adaptive M3N (AdapM3N). We show that the l1-M3N is an extreme case of the LapM3N, and the l1-M3N is equivalent to an AdapM3N. Based on this equivalence we develop a robust EM-style algorithm for learning an l1-M3N. We demonstrate the advantages of the simultaneously (pseudo-) primal and dual sparse models over the ones which enjoy either primal or dual sparsity on both synthetic and real data sets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1265–1272},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553537,
author = {Zhuang, Jinfeng and Tsang, Ivor W. and Hoi, Steven C. H.},
title = {SimpleNPKL: Simple Non-Parametric Kernel Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553537},
abstract = {Previous studies of Non-Parametric Kernel (NPK) learning usually reduce to solving some Semi-Definite Programming (SDP) problem by a standard SDP solver. However, time complexity of standard interior-point SDP solvers could be as high as O(n6.5). Such intensive computation cost prohibits NPK learning applicable to real applications, even for data sets of moderate size. In this paper, we propose an efficient approach to NPK learning from side information, referred to as SimpleNPKL, which can efficiently learn non-parametric kernels from large sets of pairwise constraints. In particular, we show that the proposed SimpleNPKL with linear loss has a closed-form solution that can be simply computed by the Lanczos algorithm. Moreover, we show that the SimpleNPKL with square hinge loss can be re-formulated as a saddle-point optimization task, which can be further solved by a fast iterative algorithm. In contrast to the previous approaches, our empirical results show that our new technique achieves the same accuracy, but is significantly more efficient and scalable.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1273–1280},
numpages = {8}
}

@inproceedings{10.1145/1553374.1553538,
author = {Cortes, Corinna},
title = {Invited Talk: Can Learning Kernels Help Performance?},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553538},
doi = {10.1145/1553374.1553538},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {1},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553539,
author = {Freund, Yoav},
title = {Invited Talk: Drifting Games, Boosting and Online Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553539},
doi = {10.1145/1553374.1553539},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {2},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553540,
author = {Agosta, John Mark and Almond, Russell and Buede, Dennis and Druzdzel, Marek J. and Goldsmith, Judy and Renooij, Silja},
title = {Workshop Summary: Seventh Annual Workshop on Bayes Applications},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553540},
doi = {10.1145/1553374.1553540},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {3},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553542,
author = {Murphy, Robert F. and Hsu, Chun-Nan and Nanni, Loris},
title = {Workshop Summary: Automated Interpretation and Modelling of Cell Images},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553542},
doi = {10.1145/1553374.1553542},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {4},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553543,
author = {Yu, Kay and Salakhutdinov, Ruslan and LeCun, Yann and Hinton, Geoff and Bengio, Yoshua},
title = {Workshop Summary: Workshop on Learning Feature Hierarchies},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553543},
doi = {10.1145/1553374.1553543},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {5},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553544,
author = {Wingate, David and Diuk, Carlos and Li, Lihong and Taylor, Matthew and Frank, Jordan},
title = {Workshop Summary: Results of the 2009 Reinforcement Learning Competition},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553544},
doi = {10.1145/1553374.1553544},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {6},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553546,
author = {Drummond, Chris and Japkowicz, Nathalie and Klement, William and Macskassy, Sofus},
title = {Workshop Summary: The Fourth Workshop on Evaluation Methods for Machine Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553546},
doi = {10.1145/1553374.1553546},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {7},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553547,
author = {Audibert, Jean-Yves and Auer, Peter and Lazaric, Alessandro and Munos, Remi and Ryabko, Daniil and Szepesvari, Csaba},
title = {Workshop Summary: On-Line Learning with Limited Feedback},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553547},
doi = {10.1145/1553374.1553547},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {8},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553548,
author = {Seeger, Matthias and Sra, Suvrit and Cunningham, John P.},
title = {Workshop Summary: Numerical Mathematics in Machine Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553548},
doi = {10.1145/1553374.1553548},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {9},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553550,
author = {Simsek, Ozgur},
title = {Workshop Summary: Abstraction in Reinforcement Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553550},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {10},
numpages = {1}
}

@inproceedings{10.1145/1553374.1553551,
author = {Eck, Douglas and Ellis, Dan and Hamel, Philippe},
title = {Workshop Summary: Sparse Methods for Music Audio},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553551},
doi = {10.1145/1553374.1553551},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {11},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553552,
author = {Beygelzimer, Alina and Langford, John and Zadrozny, Bianca},
title = {Tutorial Summary: Reductions in Machine Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553552},
doi = {10.1145/1553374.1553552},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {12},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553553,
author = {Even-Dar, Eyal and Mirrokni, Vahab},
title = {Tutorial Summary: Convergence of Natural Dynamics to Equilibria},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553553},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {13},
numpages = {1}
}

@inproceedings{10.1145/1553374.1553554,
author = {Tresp, Volker and Yu, Kai},
title = {Tutorial Summary: Learning with Dependencies between Several Response Variables},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553554},
doi = {10.1145/1553374.1553554},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {14},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553555,
author = {Warmuth, Manfred K. and Vishwanathan, S.V.N.},
title = {Tutorial Summary: Survey of Boosting from an Optimization Perspective},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553555},
doi = {10.1145/1553374.1553555},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {15},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553557,
author = {Niv, Yael},
title = {Tutorial Summary: The Neuroscience of Reinforcement Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553557},
doi = {10.1145/1553374.1553557},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {16},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553558,
author = {Bennett, Paul and Bilenko, Misha and Collins-Thompson, Kevyn},
title = {Tutorial Summary: Machine Learning in IR: Recent Successes and New Opportunities},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553558},
doi = {10.1145/1553374.1553558},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {17},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553559,
author = {Dasgupta, Sanjoy and Langford, John},
title = {Tutorial Summary: Active Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553559},
doi = {10.1145/1553374.1553559},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {18},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{10.1145/1553374.1553560,
author = {Leskovec, Jure},
title = {Tutorial Summary: Large Social and Information Networks: Opportunities for ML},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553560},
doi = {10.1145/1553374.1553560},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {19},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inbook{10.1145/1553374.1553561,
author = {Smith, Noah},
title = {Tutorial Summary: Structured Prediction for Natural Language Processing},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553561},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
articleno = {20},
numpages = {1}
}

