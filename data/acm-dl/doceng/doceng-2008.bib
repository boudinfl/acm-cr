@inproceedings{10.1145/3247155,
author = {da Graca, Maria},
title = {Session Details: Keynote},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247155},
doi = {10.1145/3247155},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410143,
author = {Shilman, Michael},
title = {Aggregate Documents: Making Sense of a Patchwork of Topical Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410143},
doi = {10.1145/1410140.1410143},
abstract = {With the dramatic increase in quantity and diversity of online content, particularly in the form of user generated content, we now have access to unprecedented amounts of information. Whether you are researching the purchase of a new cell phone, planning a vacation, or trying to assess a political candidate, there are now countless resources at your fingertips. However, finding and making sense of all this information is laborious and it is difficult to assess high-level trends in what is said. Web sites like Wikipedia and Digg democratize the process of organizing the information from countless document into a single source where it is somewhat easier to understand what is important and interesting. In this talk, I describe a complementary set of automated alternatives to these approaches, demonstrate these approaches with a working example, the commercial web site Wize.com, and derive some basic principles for aggregating a diverse set of documents into a coherent and useful summary.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {3–7},
numpages = {5},
keywords = {aggregation, information retrieval, summarization, analysis},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247156,
author = {Munson, Ethan},
title = {Session Details: Scalable Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247156},
doi = {10.1145/3247156},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410145,
author = {Boyer, John M.},
title = {Interactive Office Documents: A New Face for Web 2.0 Applications},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410145},
doi = {10.1145/1410140.1410145},
abstract = {As the world wide web transforms from a vehicle of information dissemination and e-commerce transactions into a writable nexus of human collaboration, the Web 2.0 technologies at the forefront of the tranformation may be seen as special cases of a more general shift in the conceptual application model of the web. This paper recognizes the conceptual transition and explores the connections to a new class of interactive office documents that become possible by tighter integration of the Open Document Format with the W3C's next generation web forms technology (XForms). The connections transcend simple provisioning of office document editing and persistence capabilities on the web. Rather, the advantages of office documents as self-contained entities that flow through a collaborative network or business process are combined with web application qualities such as intelligent behavioral interaction, in-process web service access, and control of server submission content. An office document mashup called 'Dual Forms' is presented to demonstrate the feasibility of office document centric web applications.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {8–17},
numpages = {10},
keywords = {ODF, web service, SOA, office document, user interaction, XForms, business process, XML signature},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410146,
author = {Jansen, Jack and Bulterman, Dick C.A.},
title = {Enabling Adaptive Time-Based Web Applications with SMIL State},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410146},
doi = {10.1145/1410140.1410146},
abstract = {In this paper we examine adaptive time-based web applications (or presentations). These are interactive presentations where time dictates the major structure, and that require interactivity and other dynamic adaptation. We investigate the current technologies available to create such presentations and their shortcomings, and suggest a mechanism for addressing these shortcomings. This mechanism, SMIL State, can be used to add user-defined state to declarative time-based languages such as SMIL or SVG animation, thereby enabling the author to create control flows that are difficult to realize within the temporal containment model of the host languages. In addition, SMIL State can be used as a bridging mechanism between languages, enabling easy integration of external components into the web application.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {18–27},
numpages = {10},
keywords = {multimedia web applications, SMIL, delayed ad viewing, declarative languages},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410147,
author = {Mik\'{a}c, Jan and Roisin, C\'{e}cile and Le Duc, Bao},
title = {An Export Architecture for a Multimedia Authoring Environment},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410147},
doi = {10.1145/1410140.1410147},
abstract = {In this paper, we propose an export architecture that provides a clear separation of multimedia authoring services from publicaction services. We illustrate this architecture with the LimSee3 authoring tool and several standard publication formats: Timesheets, SMIL, and XHTML.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {28–31},
numpages = {4},
keywords = {multimedia document, export, SMIL, timesheets, publishing format},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410148,
author = {Pellan, Beno\^{\i}t and Concolato, Cyril},
title = {Adaptation of Scalable Multimedia Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410148},
doi = {10.1145/1410140.1410148},
abstract = {Several scalable media codecs have been standardized in recent years to cope with heterogeneous usage conditions and to aim at always providing audio, video and image content in the best possible quality. Today, interactive multimedia presentations are becoming accessible on handheld terminals and face the same adaptation challenges as the media elements they present: quite diversified screen, memory and processing power capabilities. In this paper, we address the adaptation of multimedia documents by applying the concept of scalability to their presentation.The Scalable MSTI document model introduced in this paper has been designed with two main requirements in mind. First, the adaptation process must be simple to execute because it may be performed on limited terminals in broadcast scenarios. Second, the adaptation process must be simple to describe so that authored adaptation directives can be transported along with the document with a limited bandwidth overhead. The Scalable MSTI model achieves both objectives by specifying Spatial, Temporal and Interactive scalability axes on which incremental authoring can be performed to create progressive presentation layers.Our experiments are conducted on scalable multimedia documents designed for Digital Radio services on DMB channels using MPEG-4 BIFS and also for web services using XHTML, SVG, SMIL and Flash. A scalable image gallery is described throughout this article and illustrates the features offered by our document model in a rich multimedia example.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {32–41},
numpages = {10},
keywords = {document adaptation, document model, multimedia scalability},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247157,
author = {Bulterman, Dick},
title = {Session Details: Structured Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247157},
doi = {10.1145/3247157},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410150,
author = {Balinsky, Helen and Wiley, Anthony and Rhodes, Michael and Abdul-Rahman, Alfie},
title = {Automated Repurposing of Implicitly Structured Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410150},
doi = {10.1145/1410140.1410150},
abstract = {The different visual cues present in a document - such as spatial intervals and positions, contrast in font families, sizes and weights - combine to form the document's visual hierarchy. This hierarchy is essential to the reader, allowing scanning and comprehension; in contrast, this information is often ignored by machine processing. At the same time, the document structure is often not available in a machine readable form due to the ways documents were originally created or later transformed. This paper addresses the challenge of automatic document repurposing - applying styling and formatting from one 'implicitly' structured document to another, whilst preserving the underlying visual hierarchy. Using visual perception analysis, the proportionality mapping is established, according to which the original document content is transformed into the new style without breaking the original hierarchical structure. Spatial relationships, location and frequency analysis are then used to fine-tune the transformation.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {42–51},
numpages = {10},
keywords = {hierarchical metrics and structure, x-height, document repurposing, cap-height, injective mapping},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410151,
author = {R\"{o}nnau, Sebastian and Pauli, Christian and Borghoff, Uwe M.},
title = {Merging Changes in XML Documents Using Reliable Context Fingerprints},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410151},
doi = {10.1145/1410140.1410151},
abstract = {Different dialects of XML have emerged as ubiquitous document exchange formats. For effective collaboration based on such documents, the capability to propagate edit operations performed on a document is indispensable. In order to avoid the transmission of whole documents, deltas are used to describe these edit operations, allowing the construction of a new version of a document. However, patching a document with a delta it was not generated for is error-prone, and any insert or delete operations performed on the document are likely to affect all subsequent paths within that document.In this paper, we present a delta format for XML documents that uses context-aware fingerprints to identify edit operations. This allows our XML patch procedure to find the correct position of an edit operation, even if the document was updated in the meantime. Possible conflicts are detected. Experimental results show the reliability of the presented fingerprinting technique and prove the high quality of the resulting patched documents.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {52–61},
numpages = {10},
keywords = {CSCW, version control, XML diff, XML patch, fingerprint, office applications},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410152,
author = {Kerne, Andruid and Toups, Zachary O. and Dworaczyk, Blake and Khandelwal, Madhur},
title = {A Concise XML Binding Framework Facilitates Practical Object-Oriented Document Engineering},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410152},
doi = {10.1145/1410140.1410152},
abstract = {Semantic web researchers tend to assume that XML Schema and OWL-S are the correct means for representing the types, structure, and semantics of XML data used for documents and interchange between programs and services. These technologies separate information representation from implementation. The separation may seem like a benefit, because it is platform-agnostic. The problem is that the separation interferes with writing correct programs for practical document engineering, because it violates a primary principle of object-oriented programming: integration of data structures and algorithms. We develop an XML binding framework that connects Java object declarations with serialized XML representation. A basis of the framework is a metalanguage, embedded in Java object and field declarations, designed to be particularly concise, to facilitate the authoring and maintenance of programs that generate and manipulate XML documents. The framework serves as the foundation for a layered software architecture that includes meta-metadata descriptions for multimedia information extraction, modeling, and visualization; Lightweight Semantic Distributed Computing Services; interaction logging services; and a user studies framework.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {62–65},
numpages = {4},
keywords = {XML, metalanguage, Java, translation, binding framework, object-oriented programming},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410153,
author = {Blouin, Arnaud and Beaudoux, Olivier and Loiseau, St\'{e}phane},
title = {Malan: A Mapping Language for the Data Manipulation},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410153},
doi = {10.1145/1410140.1410153},
abstract = {Malan is a MApping LANguage that allows the generation of transformation programs by specifying a schema mapping between a source and target data schema. By working at the schema level, Malan remains independent of any transformation process; it also naturally guarantees the correctness of the transformation target relative to its schema. Moreover, by expressing schemas as UML class diagrams, Malan schema mappings can be written on top of UML modellers. This paper describes the overall approach by focusing on the Malan language itself, and its use within a transformation process.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {66–75},
numpages = {10},
keywords = {schema transformation, malan, mapping, data manipulation, schema translation, UML},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247158,
author = {Gormish, Michael},
title = {Session Details: Variable Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247158},
doi = {10.1145/3247158},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410155,
author = {Lumley, John and Gimson, Roger and Rees, Owen},
title = {Configurable Editing of XML-Based Variable-Data Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410155},
doi = {10.1145/1410140.1410155},
abstract = {Variable data documents can be considered as functions of their bindings to values, and this function could be arbitrarily complex to build strongly-customised but high-value documents. We outline an approach for editing such documents from example instances, which is highly configurable in terms of controlling exactly what is editable and how, capable of being used with a wide variety of XML-based document formats and processing pipelines, if certain reasonable properties are supported and can generate appropriate editors automatically, including web-service deployment.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {76–85},
numpages = {10},
keywords = {document editing, functional programming, XSLT, document construction, SVG},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410156,
author = {Ollis, James A. and Bagley, Steven R. and Brailsford, David F.},
title = {Tracking Sub-Page Components in Document Workflows},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410156},
doi = {10.1145/1410140.1410156},
abstract = {Documents go through numerous transformations and intermediate formats as they are processed, in a workflow, from abstract markup into final printable form. Unfortunately, it is common to find that ideas about document components, which might exist in the source code for the document, become completely lost within an amorphous, unstructured, page of PDF prior to being rendered. Given the importance of a component-based approach in Variable Data Printing (VDP) we have developed a collection of tools that allow information about the various transformations to be embedded at each stage in the workflow, together with a visualization tool that uses this embedded information to display the relationships between the various intermediate documents.We demonstrate these tools in the context of an example workflow using DocBook markup but the techniques described are widely applicable and would be easily adaptable to other workflows and for use in teaching tools to illustrate document component and VDP concepts.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {86–89},
numpages = {4},
keywords = {VDP, XSL-FO, document components, education, XSLT, COGs, document workflows, PDF, DocBook},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410157,
author = {Di Iorio, Angelo and Furini, Luca and Vitali, Fabio and Lumley, John and Wiley, Tony},
title = {Higher-Level Layout through Topological Abstraction},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410157},
doi = {10.1145/1410140.1410157},
abstract = {Existing layout languages provide support for geometric properties allowing - and in a sense forcing - users to give a complete geometric description of the desired output: if the characteristics of the output medium change, the layout of the whole document has to be reworked completely, as the properties set by the user are no longer appropriate for the modified context.In this paper we propose a different paradigm which allows users to produce layouts by describing their topological and abstract properties, rather than geometric ones. We first define and detail topological properties as abstract relationships between the document components, independent from the output characteristics, and then describe an XML-based layout language based on these concepts, called TALL.A running engine able to transform topological layouts into actual PDF files, based on XSLT and the DDF framework, is presented as well.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {90–99},
numpages = {10},
keywords = {topological layouts, XSLT, automatic layouts, DDF, TALL},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247159,
author = {Nicholas, Charles},
title = {Session Details: Demo Session A},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247159},
doi = {10.1145/3247159},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410159,
author = {Boyer, John M. and Dunn, Eric and Kraft, Maureen and Liu, Jun S.H. and Shah, Mihir R. and Su, He Feng and Tiwari, Saurabh},
title = {An Office Document Mashup for Document-Centric Business Processes},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410159},
doi = {10.1145/1410140.1410159},
abstract = {An office document mashup called 'Dual Forms' is presented to demonstrate the feasibility and advantages of imbuing an office document with intelligent interaction capabilities, access to web services of a service-oriented architecture (SOA), digital signatures for legally binding contractual agreements, and a self-submission capability that allows the document to flow through a collaborative network or business process.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {100–101},
numpages = {2},
keywords = {SOA, web service, business process, user interaction, ODF, XForms, office document, XML signature},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410160,
author = {Obrador, Pere and Moroney, Nathan and MacDowell, Ian and O'Brien-Strain, Eamonn},
title = {Image Collection Taxonomies for Photo-Book Auto-Population with Intuitive Interaction},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410160},
doi = {10.1145/1410140.1410160},
abstract = {We demonstrate a system for automatic image selection for photobook creation, along with an intuitive user interface for fine tuning of the selection results. A versatile image collection representation is introduced, which allows for automatic scalable selection in order to target a specific image count for a predetermined size photobook. The images are selected based on their relevance, while preserving a good coverage of the event (time plus people) in order to maintain the storytelling potential of the selection. The selected images are laid out and presented to the user through an Adobe Flex user interface, which allows them to select images and swap them by semantically related ones, in an intuitive manner. The final result is output to a PDF file.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {102–103},
numpages = {2},
keywords = {image appeal, time clustering, near-duplicate detection, scalability, hierarchy, automatic photo selection, image collection},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410161,
author = {Bulc\~{a}o-Neto, Renato de Freitas and Camacho-Guerrero, Jos\'{e} Antonio and Macedo, Alessandra Alaniz},
title = {A Prototype Documenter System for Medical Grand Rounds},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410161},
doi = {10.1145/1410140.1410161},
abstract = {This paper demonstrates our ongoing experience on a documenter system for medical grand rounds. The system captures and synchronizes the set of material presented and corresponding physicians' interactions, automatically relates clinical cases of patients, and then generates web-accessible documents with all information captured. The resulting documentation can be used for several purposes such as teaching, research and presurgical decision taking.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {104–105},
numpages = {2},
keywords = {documentation, extension, pervasive healthcare},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247160,
author = {Hurst, Nathan},
title = {Session Details: Finding, Mashing and Mixing},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247160},
doi = {10.1145/3247160},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410163,
author = {Rinaldi, Antonio M.},
title = {A Content-Based Approach for Document Representation and Retrieval},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410163},
doi = {10.1145/1410140.1410163},
abstract = {In the last few years, the problem of defining efficient techniques for knowledge representation is becoming a challenging topic in both academic and industrial community. The large amount of available data creates several problems in terms of information overload. In this framework, we assume that new approaches for knowledge definition and representation may be useful, in particular the ones based on the concept of ontology. In this paper we propose a suitable model for knowledge representation purposes using linguistic concepts and properties. We implement our model in a system which, using novel techniques and metrics, analyzes documents from a semantic point of view using as context of interest the Web. Experiments are performed on a test set built using a directory service to have information about analyzed documents. The obtained results compared with other similar systems show an effective improvement.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {106–109},
numpages = {4},
keywords = {ontologies, WordNet, semantic relatedness metrics},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410164,
author = {Codocedo, V\'{\i}ctor and Astudillo, Hern\'{a}n},
title = {No Mining, No Meaning: Relating Documents across Repositories with Ontology-Driven Information Extraction},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410164},
doi = {10.1145/1410140.1410164},
abstract = {Far from eliminating documents as some expected, the Internet has lead to a proliferation of digital documents, without a centralized control or indexing. Thus, identifying relevant documents becomes simultaneously more important and much harder, since what users require may be dispersed across many documents and many repositories. This paper describes Ontologic Anchoring, a technique to relate documents in domain ontologies, using named entity recognition (a natural-language processing approach) and semantic annotation to relate individual documents to elements in ontologies. This approach allows document retrieval using domain-level inferences, and integration of repositories with heterogeneous media, languages and structure. Ontological anchoring is a two-way street: ontologies allow semantic indexing of documents, and simultaneously new documents enrich ontologies. The approach is illustrated with an initial deployment for heritage documents in Spanish.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {110–118},
numpages = {9},
keywords = {information extraction, NLP, metadata creation, ontology, human-in-the-loop, ontological anchoring},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410165,
author = {Gormish, Michael and Wolff, Greg and Piersol, Kurt and Hart, Peter},
title = {Document Logs: A Distributed Approach to Metadata for Better Security and Flexibility},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410165},
doi = {10.1145/1410140.1410165},
abstract = {A document log is an ordered list of entries providing a history for any sort of media or file, just as a logfile provides a history of a computer program and a logbook provides a history of a journey. The history of a document may consist of copyright information, approvals, annotations, or any sort of metadata. This paper describes a metadata architecture using Content Based Identifiers and Document Logs that facilitates location of metadata from distributed sources, caching, ordering of log entries, and detection of changes in metadata or documents. The techniques used complement existing metadata format standards and are contrasted with storage of metadata in a file or document management system.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {119–122},
numpages = {4},
keywords = {uuid, hash chain, time-stamp},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410166,
author = {Schmitz, Patrick},
title = {The CONCUR Framework Forcommunity Maintenance of Curated Resources},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410166},
doi = {10.1145/1410140.1410166},
abstract = {The increasing use of computational linguistics for semantic search and discovery tools requires much work on development and maintenance of associated ontologies. Related applications depend upon curated resources like dictionaries, gazetteers, etc. In order to scale these application models and leverage the respective communities of interest, a new set of tools is needed that facilitate community development and extension of these resources while retaining the curatorial model to ensure a reliable, high quality resource. We describe the requirements and principles for such a system, and present the CONCUR framework that addresses these needs. CONCUR defines a reputation model and a set of reusable infrastructure services to maintain the resource. The reputation model combines correctness as well as utility of participants' contributions, tracked over time and by sub-domain within the resource. We describe the architectural issues of the model, potential applications, and continuing research on the model.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {123–126},
numpages = {4},
keywords = {SOA, curation, ontology, community, structured information},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410167,
author = {Doumat, Reim and Egyed-Zsigmond, El\"{o}d and Pinon, Jean-Marie and Csiszar, Emese},
title = {Online Ancient Documents: Armarius},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410167},
doi = {10.1145/1410140.1410167},
abstract = {Many museums and libraries digitize their collections of historical manuscripts to preserve the historic documents and to facilitate their browsing. The collections are available as digital images and they need annotation to be accessible and exploitable. The annotations can be created manually, automatically or semi-automatically. Manual annotation is expensive and tedious; hence the reuse of users' experiences, by tracing their actions during the annotation process, helps other users to accomplish repetitive tasks in a semi-automatic manner. In this article we present a digital archive model and prototype of a collaborative system for the management of online ancient manuscript. The application offers an online annotation service, an assistant for semi-automatic annotation, and a tracing system that saves traces of important actions in order to reuse them in a recommender system afterward.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {127–130},
numpages = {4},
keywords = {document categorization and classification, system, integrating documents with other digital artifacts},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247161,
author = {Simske, Steven},
title = {Session Details: Document/Image Layout},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247161},
doi = {10.1145/3247161},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410169,
author = {Hurst, Nathan and Marriott, Kim},
title = {Satisficing Scrolls: A Shortcut to Satisfactory Layout},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410169},
doi = {10.1145/1410140.1410169},
abstract = {We present at a new approach to finding aesthetically pleasing page layouts. We do not aim to find an optimal layout, rather the aim is to find a layout which is not obviously wrong. We consider vertical scroll-like layout with floating figures referenced within the text where floats can have alternate sizes, may be optional, move from one side to the other and change their order. We also allow pagination. Our approach is to use a randomised local search algorithm to explore different configurations of floats, i.e. choice of floats and relative ordering. For a particular float configuration we use an efficient gradient projection-like continuous optimization algorithm. The resulting system is fast and provides an efficient warm start option to improve interactive support.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {131–140},
numpages = {10},
keywords = {multi-column layout, floating figure, optimisation techniques},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410170,
author = {de Oliveira, Jo\~{a}o Batista S.},
title = {Two Algorithms for Automatic Document Page Layout},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410170},
doi = {10.1145/1410140.1410170},
abstract = {This paper describes two approaches to the problem of automatically placing document items on pages of some output device. Both solutions partition the page into regions where each item is to be placed, but work on different input data according to the application: One approach assumes that previously defined rectangular items are to be placed freely on the page (as in a sales brochure), whereas the second approach places free-form items on pages divided into columns (as in a newspaper). Moreover, both approaches try to preserve the reading order provided by the input and use all available area on the page. The algorithms implementing those approaches and based on recursive page division are presented, as well as test results, possible changes and research directions.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {141–149},
numpages = {9},
keywords = {automatic page layout, placement algorithms, packing},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410171,
author = {Chao, Hui and Staelin, Carl and Schein, Sagi and Vans, Marie and Lumley, John},
title = {PDF Document Restoration and Optimization during Image Enhancement},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410171},
doi = {10.1145/1410140.1410171},
abstract = {We present a document processing method that addresses some of the practical challenges in image enhancement for digital photo album in PDF documents. With the advent of digital offset presses, consumer photo books are becoming increasingly popular, and most such workflows convert the consumer's photos and layout into PDF documents. In order to produce appealing photo albums from consumer photographs, some form of automatic enhancement is usually required, and this enhancement is often done late in the workflow just before printing, and therefore it is done on the PDF file. If each and every PDF generation tool simply inserted a single complete image each time an image appeared in the document, then the process of opening a PDF document, iterating through the document, extracting, enhancing, and replacing images, and then saving the enhanced document would be relatively easy. Unfortunately, PDF generation tools often violate that assumption in two ways. Firstly, large images are often written as a set of small images in strips or tiles, which visually appear to be a single image. Secondly, an image in a PDF document may be reused in the document on different position and pages; directly enhancing images without the consideration of the reuse model could result in great increase in the document size and poor system performance. Therefore, image reconstruction and document optimization were performed in our PDF photo album enhancement solution.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {150–153},
numpages = {4},
keywords = {document enhancement, image stitching, PDF optimization},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410172,
author = {McCormack, Cameron and Marriott, Kim and Meyer, Bernd},
title = {Authoring Adaptive Diagrams},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410172},
doi = {10.1145/1410140.1410172},
abstract = {The web and digital media requires intelligent, adaptive documents whose appearance and content adapts to the viewing context and which support user interaction. While previous research has focussed on textual and multimedia content, this is also true for diagrammatic conte nt. We have designed and implemented an authoring tool which supports the construction of adaptive diagrams. Adaptive layout behaviour is specified by using constraint-based placement tools as well as by allowing the author to specify more radical layout changes using alternate layout configurations. As well as specifying alternate layouts, the author can specify alternate representations for an object, alternate styles and alternate textual content. The resulting space of different versions of the diagram is the cross product of these different alternatives. At display time the version is constructed dynamically, taking into account the author specified preference order on the alternatives, current viewing environment, and user interaction.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {154–163},
numpages = {10},
keywords = {authoring, adaptive layout, diagrams},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247162,
author = {Soares, Luiz Fernando G.},
title = {Session Details: Modelling Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247162},
doi = {10.1145/3247162},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410174,
author = {Alkhateeb, Faisal and Laborie, S\'{e}bastien},
title = {Towards Extending and Using SPARQL for Modular Document Generation},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410174},
doi = {10.1145/1410140.1410174},
abstract = {RDF is one of the most used languages for resource description and SPARQL has become its standard query language. Nonetheless, SPARQL remains limited to generate automatically documents from RDF repositories, as it can be used to construct only RDF documents. We propose in this paper an extension to SPARQL that allows to generate any kind of XML documents from multiple RDF data and a given XML template. Thanks to this extension, an XML template can itself contain SPARQL queries that can import template instances. Such an approach allows to reuse templates, divide related information into various templates and avoid templates containing mixed languages. Moreover, reasoning capabilities can be exploited using RDF Schema or simply RDFS.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {164–172},
numpages = {9},
keywords = {XML document generation, template, semantic web, RDF, SPARQL},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410175,
author = {Valle, Eduardo and Cord, Matthieu and Philipp-Foliguet, Sylvie},
title = {Fast Identification of Visual Documents Using Local Descriptors},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410175},
doi = {10.1145/1410140.1410175},
abstract = {In this paper we introduce a system for the identification of visual documents. Since it stems from content-based document indexing and retrieval, our system does not need to rely on textual annotations, watermarks or other metadata, which can be missing or incorrect. Our retrieval system is based on local descriptors, which have been shown to provide accurate and robust description. Because of the high computational costs associated to the matching of local descriptors, we propose Projection KD-Forest: an indexing technique which allows efficient approximate k nearest neighbors search. Experiments demonstrate that the Projection KD-Forest allows the system to provide prompt results with negligible loss on accuracy. The Projection KD-Forest also compares well when contrasted to other strategies of k nearest neighbors search.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {173–176},
numpages = {4},
keywords = {k nearest neighbors search, local descriptors, multidimensional indexing, copy detection, image retrieval, document identification},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410176,
author = {Schroeder, Rebeca and Mello, Ronaldo dos Santos},
title = {Improving Query Performance on XML Documents: A Workload-Driven Design Approach},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410176},
doi = {10.1145/1410140.1410176},
abstract = {As XML has emerged as a data representation format and as great quantities of data have been stored in the XML format, XML document design has become an important and evident issue in several application contexts. Methodologies based on conceptual modeling are being tightly applied for designing XML documents. However, the conversion of a conceptual schema to an XML schema is a complex process. In many cases, conceptual relationships cannot be represented in a hierarchy so that they have to be represented by reference relationships in the XML schema. The problem is that reference relationships generate a disconnected XML structure and, consequently, produce an overhead cost for query processing on XML documents.This paper presents a design approach for generating XML schemas from conceptual schemas considering the expected workload of the XML applications. Query workload is used to produce XML schemas which minimize the impact of the reference relationships on query performance. We evaluate our approach through a case study where a set of XML documents are redesigned by our methodology. The results demonstrate that query performance is improved in terms of the number of accesses generated by the queries on the XML documents designed by our approach.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {177–186},
numpages = {10},
keywords = {conceptual schemas, query performance, XML schemas},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410177,
author = {Ml\'{y}nkov\'{a}, Irena},
title = {Similarity of XML Schema Definitions},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410177},
doi = {10.1145/1410140.1410177},
abstract = {In this paper we propose a technique for evaluating similarity of XML Schema fragments. Firstly, we define classes of structurally and semantically equivalent XSD constructs. Then we propose a similarity measure that is based on the idea of edit distance utilized to XSD constructs and enables one to involve various additional similarity aspects. In particular, we exploit the equivalence classes and semantic similarity of element/attribute names. Using experiments we show the behavior and advantages of the proposal.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {187–190},
numpages = {4},
keywords = {similarity, XML schema, equivalence of XSD constructs},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410178,
author = {Kade, Adrovane M. and Heuser, Carlos A.},
title = {Matching XML Documents in Highly Dynamic Applications},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410178},
doi = {10.1145/1410140.1410178},
abstract = {Highly dynamic applications like the Web and peer-to-peer systems require a great deal of effort in document management. Documents from different sources may contain parts that, although having different structure or different contents, may be considered as representing the same conceptual information. One essential task in this scenario is the identification of complementary or overlapping documents that need to be integrated. In this paper, we deal specifically with documents represented in the XML format. XML document integration is an important process in highly dynamic applications, for the volume of data available in this format is constantly growing. XML integration is also a challenging task, due to the flexible nature of XML, which may lead to structure divergences and content conflicts between the documents. In this work, we present a novel approach to the matching problem, i.e., the problem of defining which parts of two documents contain the same information. Matching is usually the first step of an integration process. Our approach is novel in the sense it combines similarity information from the content of the elements with information from the structure of the documents. This feature, as our experiments confirm, makes our approach capable of dealing with content as well as structural divergences.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {191–198},
numpages = {8},
keywords = {XML, matching, similarity measure, document management},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247163,
author = {Lumley, John},
title = {Session Details: Information Extraction in Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247163},
doi = {10.1145/3247163},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410180,
author = {Kumar, Niraj and Srinathan, Kannan},
title = {Automatic Keyphrase Extraction from Scientific Documents Using N-Gram Filtration Technique},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410180},
doi = {10.1145/1410140.1410180},
abstract = {In this paper we present an automatic Keyphrase extraction technique for English documents of scientific domain. The devised algorithm uses n-gram filtration technique, which filters sophisticated n-grams {1dnd4} along with their weight from the words of input document. To develop n-gram filtration technique, we have used (1) LZ78 data compression based technique, (2) a simple refinement step, (3) A simple Pattern Filtration algorithm and, (4) a term weighting scheme. In term weighting scheme, we have introduced the importance of position of sentence (where given phrase occurs first) in document and position of phrase in sentence for documents of scientific domain (which is literally more organized than other domains). The entire system is based upon statistical observations, simple grammatical facts, heuristics, and lexical information of English language. We remark that the devised system does not require a learning phase. Our experimental results with publically available text dataset, shows that the devised system is comparable with other known algorithms.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {199–208},
numpages = {10},
keywords = {information retrieval, information extraction, scientific domain, keyphrase extraction},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410181,
author = {al-Saffar, Sinan and Heileman, Gregory L.},
title = {Semantic Impact Graphs for Information Valuation},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410181},
doi = {10.1145/1410140.1410181},
abstract = {Information valuation has typically been carried out implicitly in question-answering and document retrieval systems. We argue that explicit information valuation is needed to move away from the system and process-centric nature of implicit valuation which has also hindered the theoretical study of information value under a unified and explicit framework. In this paper we present a graphical-based model for explicit information valuation. Our model caters to the subjective nature of information quality by measuring the impact a candidate piece of information may have on a knowledge base representing the recipient's world view. Our model is capable of evaluating information semantically at the statement level and is in effect basing information-valuation on information-understanding. However, information value can be computed and predicted using our causal graph model without requiring full logical inference typically needed for information-understanding.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {209–212},
numpages = {4},
keywords = {semantic web search, document ranking, information retrieval, information valuation},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410182,
author = {Adam, Cl\'{e}mentine and Delpech, Estelle and Saint-Dizier, Patrick},
title = {Identifying and Expanding Titles in Web Texts},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410182},
doi = {10.1145/1410140.1410182},
abstract = {In this paper, we present an analysis based on linguistic and typographic features that allows for the identification of titles in web documents. We focus in particular on procedural texts. Identifying titles is a difficult task because ways of encoding them are very diverse. A number of titles are also incomplete because of context, we propose therefore a way to retrieve the missing elements, in particular predicates, so that titles are fully intelligible.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {213–216},
numpages = {4},
keywords = {text titles, structure analysis, text semantics},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247164,
author = {Nicholas, Charles},
title = {Session Details: Demo Session B},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247164},
doi = {10.1145/3247164},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410184,
author = {Lumley, John and Gimson, Roger and Rees, Owen},
title = {A Demonstration of a Configurable Editing Framework},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410184},
doi = {10.1145/1410140.1410184},
abstract = {XML-based variable data documents are special cases of XML documents subjected to processing before final visualisation. We demonstrate how such 'templates' can be edited from specific instances in a generalised manner and that this can be supported by a highly extensible and configurable editing framework. The demonstration covers simple authoring actions, higher-level authoring control (altering the editability within a document), reconfiguring the overall editor capability, using alternative 'views' of documents and exploiting the framework to modify generalised XML 'files', including some of those that define the editor itself.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {217–218},
numpages = {2},
keywords = {functional programming, document editing, SVG, document construction, XSLT},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410185,
author = {Concolato, Cyril and Le Feuvre, Jean},
title = {Playback of Mixed Multimedia Document},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410185},
doi = {10.1145/1410140.1410185},
abstract = {Many multimedia languages exist today to describe animated, interactive, 2D or 3D graphics and media elements, and each language has its merits. We studied the problems underlying the integration of all these languages in a single player. We present here the result of this work, and in particular, we demonstrate the mixed playback of SVG, BIFS, LASeR, Flash or VRML/X3D content.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {219–220},
numpages = {2},
keywords = {BIFS, mixed documents, SVG, multimedia player, VRML},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410186,
author = {Pellan, Benoit and Concolato, Cyril},
title = {Scalable Multimedia Documents for Digital Radio},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410186},
doi = {10.1145/1410140.1410186},
abstract = {In this paper, we demonstrate the adaptation of multimedia digital radio services in broadcast environments based on scalable multimedia documents. The authoring of our multimedia services relies on the Scalable MSTI model that decomposes multimedia documents into three ordered dimensions: Spatial, Temporal and Interactive descriptions. Our demonstration shows Scalable MSTI multimedia documents that can be adapted to typical T-DMB digital radio usage scenarios.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {221–222},
numpages = {2},
keywords = {DMB digital radio, multimedia radio services, digital radio, multimedia scalability, document adaptation},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247165,
author = {Brailsford, David},
title = {Session Details: Generation and Printing},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247165},
doi = {10.1145/3247165},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410188,
author = {Giannetti, Fabio},
title = {An Exploratory Mapping Strategy for Web-Driven Magazines},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410188},
doi = {10.1145/1410140.1410188},
abstract = {"There will always (I hope) be print books, but just as the advent of photography changed the role of painting or film changed the role of theater in our culture, electronic publishing is changing the world of print media. To look for a one-to-one transposition to the new medium is to miss the future until it has passed you by." - Tim O'Reilly [1].It is not hard to envisage that publishers will leverage subscribers' information, interest groups' shared knowledge and others sources to enhance their publications. While this enhances the value of the publication through more accurate and personalized content, it also brings a new set of challenges to the publisher. Content is now driven by web and in a truly automated system no designer "re-touch" intervention can be envisaged. The paper introduces an exploratory mapping strategy to allocate web driven content in a highly graphical publication like a traditional magazine. Two major aspects of the mapping are covered, which enables different level of flexibility and addresses different content flowing strategies. The last contribution is an evaluation of existing standards, which potentially can leverage this work to incorporate more flexible mapping, and subsequently, composition capabilities.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {223–229},
numpages = {7},
keywords = {XPS, XSL-FO, SVG, transactional printing, content driven pagination, layout, XML, variable data print, print, template},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410189,
author = {Baldwin, Jennifer and Rowson, James A. and Coady, Yvonne},
title = {PrintMonkey: Giving Users a Grip on Printing the Web},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410189},
doi = {10.1145/1410140.1410189},
abstract = {Web content is notoriously difficult to capture on a printed page due to inconsistent and undesired results. Items that users may not want to print, such as media, navigation menus and more show up on their page. Other items that they may care about are truncated or spread across several pages. Some tools exist to help users with what is printed, but they often are cumbersome to use or are costly for a company to maintain. Therefore, we introduce PrintMonkey, which allows users to write their own printing templates and share them with others on the web. No modifications to the original webpages are required and users with less development experience can use and develop templates. A comparison with four alternative solutions reveals the concrete ways in which PrintMonkey improves upon existing approaches in terms of functionality, customizability and scalability.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {230–239},
numpages = {10},
keywords = {printing the web, screen scraping, customized browsing, JavaScript, print templates},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247166,
author = {Roisin, Cecile},
title = {Session Details: Content Processing},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247166},
doi = {10.1145/3247166},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410191,
author = {Alu\'{\i}sio, Sandra M. and Specia, Lucia and Pardo, Thiago A.S. and Maziero, Erick G. and Fortes, Renata P.M.},
title = {Towards Brazilian Portuguese Automatic Text Simplification Systems},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410191},
doi = {10.1145/1410140.1410191},
abstract = {In this paper we investigate the main linguistic phenomena that can make texts complex and how they could be simplified. We focus on a corpus analysis of simple account texts available on the web for Brazilian Portuguese and propose simplification strategies for this language. This study illustrates the need for text simplification to facilitate accessibility to information by poor literacy readers and potentially by people with other cognitive disabilities. It also highlights characteristics of simplification for Portuguese, which may differ from other languages. Such study consists of the first step towards building Brazilian Portuguese text simplification systems. One of the scenarios in which these systems could be used is that of reading electronic texts produced, e.g., by the Brazilian government or by relevant news agencies.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {240–248},
numpages = {9},
keywords = {Brazilian Portuguese, natural language processing, text simplification, corpus analysis, poor literacy readers},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410192,
author = {Fontan, Lionel and Saint-Dizier, Patrick},
title = {Constructing a Know-How Repository of Advices and Warnings from Procedural Texts},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410192},
doi = {10.1145/1410140.1410192},
abstract = {In this paper, we show how a domain dependent know-how textual database of advices and warnings can be constructed from procedural texts. We show how arguments of type warnings and advices can be annotated and extracted from procedural texts, and propose a format and a strategy to automatically generate a know-how textual database.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {249–252},
numpages = {4},
keywords = {automatically generated document, text semantics, structure and content analysis},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410193,
author = {Gon\c{c}alves, Patricia Nunes and Rino, Lucia and Vieira, Renata},
title = {Summarizing and Referring: Towards Cohesive Extracts},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410193},
doi = {10.1145/1410140.1410193},
abstract = {In this paper we propose and evaluate a system for summary post-edition, which aims at replacing referential expressions, trying to avoid referencial cohesion problems. To propose expressions that best represent the evoked entity, the system uses knowledge about coreference chains. We evaluate the system both with knowledge provided by manual and automatic annotation of coreference chains.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {253–256},
numpages = {4},
keywords = {coreference chains, automatic summarization, referencial cohesion},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247167,
author = {Pimentel, Maria da Graca},
title = {Session Details: Closing Keynote},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247167},
doi = {10.1145/3247167},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410195,
author = {Laender, Alberto H.F. and Gon\c{c}alves, Marcos Andr\'{e} and Cota, Ricardo G. and Ferreira, Anderson A. and Santos, Rodrygo L. T. and Silva, Allan J.C.},
title = {Keeping a Digital Library Clean: New Solutions to Old Problems},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410195},
doi = {10.1145/1410140.1410195},
abstract = {Digital Libraries are complex information systems that involve rich sets of digital objects and their respective metadata, along with multiple organizational structures and services (e.g., searching, browsing, and personalization), and are normally built having a target community of users with specific interests. Central to the success of this type of system is the quality of their services and content. In the context of DLs of scientific literature, among the many problems faced to sustain their information quality, two specific ones, related to information consistency, have taken a lot of attention from the research community: name disambiguation and lack of information to access the full-text of cataloged documents. In this paper, we examine these two problems and describe the solutions we have proposed to solve them.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {257–262},
numpages = {6},
keywords = {citation management, name disambiguation, information quality, digital libraries, full-text management},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247168,
author = {King, Peter},
title = {Session Details: Recognizing Characters},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247168},
doi = {10.1145/3247168},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410197,
author = {Sturgill, Margaret and Simske, Steven J.},
title = {An Optical Character Recognition Approach to Qualifying Thresholding Algorithms},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410197},
doi = {10.1145/1410140.1410197},
abstract = {Pre-processing for raster image based document segmentation begins with image thresholding, which is a binarization process separating foreground from background. In this paper, we compare an existing (Otsu), modified existing (Kittler-Illingworth) and simple peak-based thresholding approach on a set of 982 documents for which existing ground truth (full text) is available. We use the output of an open source OCR engine which incorporates an adaptive/dynamic thresholder that can be bypassed by one of the three global thresholds we tested. This allowed comparison of these three approaches in the aggregate. We then used an independently-generated dictionary as a means of characterizing thresholder efficacy. Such an approach, if successful, will provide the means for selecting an optimal thresholder in the absence of a large set of ground truthed documents. Our preliminary findings here indicate that this approach may provide a reliable means for thresholder comparison and eventually preclude the need for time-intensive human ground truthing.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {263–266},
numpages = {4},
keywords = {threshold, Kittler-Illingworth, otsu, testing, accuracy, OCR, meta-algorithms},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410198,
author = {Nguyen, Duc Thanh},
title = {A Rotation Method for Binary Document Images Using DDA Algorithm},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410198},
doi = {10.1145/1410140.1410198},
abstract = {DDA (Digital Differential Analyzer) is a famous algorithm used commonly in computer graphics to interpolate integer coordinate pixels of a straight line. In this paper, we introduce a method of image rotation for binary document images using DDA algorithm with assumption that the true skew angles of the documents have already been computed. The proposed method applies the main idea of DDA algorithm with some modifications for the skew scanning lines along to the inverse direction of the skew angle. In this method the ratios between the length of black runs and the whole scan line are guaranteed. Thus the algorithm can overcome disadvantages of mathematical rotation such as white holes and over segmentation. Moreover, using DDA algorithm to approximate integer points helps this method reduce the number of rotation operations.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {267–270},
numpages = {4},
keywords = {skew correction, DDA, rotation algorithm},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410199,
author = {Mello, Carlos A.B. and Roe, Edward and Lacerda, Everton B.},
title = {Segmentation of Overlapping Cursive Handwritten Digits},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410199},
doi = {10.1145/1410140.1410199},
abstract = {In this paper, we describe an approach for the problem of segmenting overlapping characters. We are working with digit segmentation for bank check processing. Our method is based on the idea of a hypothetical ball traversing the number. The inertia of the movement segments the overlapping digits. Rules are defined for this movement. Our initial proposal achieved very good results with O(n2) complexity.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {271–274},
numpages = {4},
keywords = {segmentation, overlapping digits, document processing},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/3247169,
author = {Schmitz, Patrick},
title = {Session Details: Modeling, Editing, Adaptation},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3247169},
doi = {10.1145/3247169},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
numpages = {1},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410201,
author = {Cesar, Pablo and Vaishnavi, Ishan and Kernchen, Ralf and Meissner, Stefan and Hesselman, Cristian and Boussard, Matthieu and Spedalieri, Antonietta and Bulterman, Dick C.A. and Gao, Bo},
title = {Multimedia Adaptation in Ubiquitous Environments: Benefits of Structured Multimedia Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410201},
doi = {10.1145/1410140.1410201},
abstract = {This paper demonstrates the advantages of using structured multimedia documents for session management and media distribution in ubiquitous environments. We show how document manipulations can be used to perform powerful operations such as content to context adaptation and presentation continuity. When consuming media in ubiquitous environments, where the set of devices surrounding a user may change, dynamic media adaptation and session transfer become primary requirements. This paper presents a working system, based on a representative scenario, in which multimedia content is distributed and adapted to a movable user to best suit his/her contextual situation. The implemented scenario includes the following scenes: content selection using a personal mobile phone, content distribution to the most suitable device according to the user's context, and presentation continuity when the user moves to another location. This paper introduces the underlying document manipulations that turn the scenario into a working system.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {275–284},
numpages = {10},
keywords = {session continuity, SMIL, multimedia adaptation, structured multimedia documents},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410202,
author = {Laiola Guimar\~{a}es, Rodrigo and de Salles Soares Neto, Carlos and Gomes Soares, Luiz Fernando},
title = {A Visual Approach for Modeling Spatiotemporal Relations},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410202},
doi = {10.1145/1410140.1410202},
abstract = {Textual programming languages have proven to be difficult to learn and to use effectively for many people. For this sake, visual tools can be useful to abstract the complexity of such textual languages, minimizing the specification efforts. In this paper we present a visual approach for high level specification of spatiotemporal relations. In order to accomplish this task, our visual representation provides an intuitive way to specify complex synchronization events amongst media. Finally, to validate our work, the visual specification is mapped to NCL (Nested Context Language), the standard declarative language of the Brazilian Terrestrial Digital TV System.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {285–288},
numpages = {4},
keywords = {SBTVD, synchronization, visual representation, visual specification, connector, spatiotemporal relations, NCL},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410203,
author = {Costa, Romualdo Monteiro de Resende and Moreno, Marcelo Ferreira and Gomes Soares, Luiz Fernando},
title = {Intermedia Synchronization Management in DTV Systems},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410203},
doi = {10.1145/1410140.1410203},
abstract = {Intermedia synchronization is related with spatial and temporal relationships among media objects that compound a DTV application. From the server side (usually a broadcaster's server or a Web Server) to receivers, end-to-end intermedia synchronization support must be provided. Based on application specifications, several abstract data structures should be created to guide all synchronization control processes. A special data structure, a labeled digraph called HTG (Hypermedia Temporal Graph) is proposed in this paper as the basis of all other data structures. From HTG, receivers derive a presentation plan to orchestrate media content presentations that make up a DTV application. From this plan other data structures are derived to estimate when media players should be instantiated and when data contents should be retrieved from a DSM-CC carousel or from a return channel. If the return channel provides QoS support, another data structure is derived from the presentation plan, in order to determine when resource reservation should take place. For content pushed by broadcasters, HTG is used in the server side as the basis for building the carousel plan, a data structure that guides the order and frequency that media objects should be broadcasted.The paper's proposals were partially put into practice in the current open source reference implementation of the standard middleware of the Brazilian Terrestrial Digital TV System. However, this reference implementation is used just as a proof of concept. The ideas presented can be extended to any multimedia document presentation player (user agent) and content distribution server.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {289–297},
numpages = {9},
keywords = {middleware, intermedia synchronization, NCL, temporal graph, digital TV},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

@inproceedings{10.1145/1410140.1410204,
author = {Pimentel, Maria da Gra\c{c}a C. and Cattelan, Renan G. and Melo, Erick L. and Teixeira, Cesar A.C.},
title = {End-User Editing of Interactive Multimedia Documents},
year = {2008},
isbn = {9781605580814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1410140.1410204},
doi = {10.1145/1410140.1410204},
abstract = {The problem of allowing user-centric control within multimedia presentations is important to document engineering when the presentations are specified as structured multimedia documents. In this paper we investigate the problem in the context of end-user "real-time" editing of interactive video programs.},
booktitle = {Proceedings of the Eighth ACM Symposium on Document Engineering},
pages = {298–301},
numpages = {4},
keywords = {interactive video, interactive multimedia},
location = {Sao Paulo, Brazil},
series = {DocEng '08}
}

