@inproceedings{10.5555/1145675.1145676,
author = {Pretorius, Marco C. and Calitz, Andr\'{e} P. and van Greunen, Darelle},
title = {The Added Value of Eye Tracking in the Usability Evaluation of a Network Management Tool},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Usability evaluation techniques have evolved over several years to assess the user interface of systems with regard to efficiency, interaction flexibility, interaction robustness and quality of use. The evaluation of the user's thought process is difficult to access with traditional usability techniques. Eye movement data and eye fixations can supplement the data obtained through usability testing by providing more specific information on the user's visual attention. Network Management (NM) tools have been developed to analyse the large amount of data generated by network applications and to display the data using various information visualisation techniques. The general increase in the use of information visualisation techniques has highlighted the need for methodologies to evaluate the user interface of software, including NM tools. This paper investigates how eye tracking data can supplement the usability evaluation data of NM tools. This paper further discusses the results obtained from a usability evaluation that used a methodology combining traditional usability methods and eye tracking methods for the usability evaluation of the visualisation techniques used by a NM tool. The results show that eye tracking does provide additional value to the usability evaluation results of NM tools.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {1–10},
numpages = {10},
keywords = {visualisation evaluation, network management, usability evaluation, eye tracking},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145677,
author = {Subotic, Sasa and Bishop, Judith},
title = {Emergent Behaviour of Aspects in High Performance and Distributed Computing},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {In this paper we discuss the characteristics of Aspect Oriented Programming (AOP), and the development of new or existing applications using AOP. Aspects are emerging everywhere, and there is a particular need to introduce and practice them strategically in areas such as parallel and distributed computing. We will show that this attractive technology is useful for solving the problems of code scattering and tangling in high performance parallel computing. The performance related aspects are most noticeable for high performance applications. Then we discuss AOP impact in the distributed environment. Programming in a distributed environment is a complex task where object orientation has been of limited success in managing crosscutting concerns such as synchronization, scheduling, fault tolerance and security. Our aspect research vehicle at the Polelo Research Group is the Algon distributed framework (ALGOrithms on the Net). The focus here is to show how AOP can be applied to an Algon application aiming at a better separation of concerns. Basic examples are logging, debugging and performance related aspects associated with this system. We argue that this modern programming paradigm allows existing systems to be re-designed or modified as a viable approach to improve the functionality and flexibility of the system.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {11–19},
numpages = {9},
keywords = {AspectJ, High Performance Computing (HPC), Aspect Oriented Programming (AOP), algorithms on the network (Algon), Distributed Computer-Systems (DS)},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145678,
author = {Glass, Kevin and Bangay, Shaun},
title = {Evaluating Parts-of-Speech Taggers for Use in a Text-to-Scene Conversion System},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This paper presents parts-of-speech tagging as a first step towards an autonomous text-to-scene conversion system. It categorizes some freely available taggers, according to the techniques used by each in order to automatically identify word-classes. In addition, the performance of each identified tagger is verified experimentally. The SUSANNE corpus is used for testing and reveals the complexity of working with different tagsets, resulting in substantially lower accuracies in our tests than in those reported by the developers of each tagger. The taggers are then grouped to form a voting system to attempt to raise accuracies, but in no cases do the combined results improve upon the individual accuracies. Additionally a new metric, agreement, is tentatively proposed as an indication of confidence in the output of a group of taggers where such output cannot be validated.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {20–28},
numpages = {9},
keywords = {corpora, parts-of-speech tagging},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145679,
author = {Alexander, PM and Phahlamohlaka, LJ},
title = {Information Flows for Meaningful Implementation of the Promotion of Administrative Justice Act of South Africa},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {The Promotion of Administrative Justice Act of South Africa (AJA) requires administrators to provide those who have been negatively affected by a decision with reasonable explanations if these are requested. Fair and accountable administration is identified as a basic constitutional right in South Africa. However, ensuring that state departments can provide information on request to even remote and poorly resourced citizens is a major undertaking and, other than taking grievances to court, it is difficult to initiate, respond to and monitor the process. The information flows pose the most significant challenges. An investigation is underway into how rural Communities can use Information and Communication Technology (ICT) to access this right. Sen's Capabilities Approach is used to relate the role of ICT to an expansion of the capabilities of individuals and communities, which translates into them acquiring genuine options to access their constitutional right. The research has already involved interviewing representatives from a number of groups. This was done to identify the possible information flows, end-user requirements and social and individual constraints. The paper proposes an information flow incorporating facilitators and a 'clearing house' in addition to the citizens and administrators.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {29–37},
numpages = {9},
keywords = {end-user requirements, developing countries, socio-economic development, capabilities approach, human rights, computers and society, community-based information systems},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145680,
author = {Cleophas, Loek and Watson, Bruce W. and Kourie, Derrick G. and Boake, Andrew},
title = {TABASCO: A Taxonomy-Based Domain Engineering Method},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {We discuss TABASCO, a method for constructing Domain-Specific Toolkits (DSTs). We present TABASCO in the context of domain engineering and generative programming. We discuss the steps of TABASCO in detail, with a focus on the software construction side, giving examples based on actual applications of the method. In doing so, we show that TABASCO is a domain engineering method aimed at a particular kind of software domain, and how this method is applied in practice.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {38–47},
numpages = {10},
keywords = {domain engineering, toolkits, software construction, algorithm derivation, taxonomy},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145681,
author = {Kruger, Hein and Sanders, Ian},
title = {Orthogonal Axial Line Placement in Hole Free Collections of Rectangles},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Previous research showed that the problem of finding the smallest set of orthogonal axial lines needed to cross all adjacencies between rectangles in a collection of orthogonal rectangles (ALP-OLOR) is NP-Complete. There are, however, some cases where the problem can be solved in polynomial time by mapping adjacencies to intervals on a line and finding a clique cover of the resulting interval graph. In this paper we extend that result and show that ALP-OLOR can be solved in polynomial time for all hole free collections of rectangles as well as for some collections of rectangles with holes.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {48–55},
numpages = {8},
keywords = {ALP-OLOR, clique cover, computational geometry, axial line placement, special cases},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145682,
author = {Kassa, Debessay Fesehaye and Krzesinski, A. E.},
title = {A Queueing Network Model of TCP Performance},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Measurement, simulation and analytical models are the techniques and tools that can be used to understand and investigate the Internet and its performance. Measurements become costly and inflexible with the growth and complexity of the Internet. Simulation models do not scale with the growth of network capacities and the number of users. Computationally efficient analytical models are therefore important tools for investigating, designing, dimensioning and planning IP (Internet Protocol) networks.This study presents a simple, fast and detailed analytical model of the Transmission Control Protocol (TCP) which is the dominant transport protocol for the end-to-end control of information transfer. The model gives Internet performance metrics, assuming that only basic network parameters such as the network topology, the number of TCP connections for large file transfers, link capacity, distance between network nodes and router buffer sizes are known.The performance metrics are obtained by using TCP and network sub-models and solving them using a fixed point algorithm. Each of the TCP sub-models is developed using a closed network of ./G/∞ queues where each queue represents a state of a TCP connection. Each network sub-model which represents the output interface of an IP router with a buffer capacity of K -- 1 packets is modeled using an M/M/1/K queue.Numerical results based on comparisons against ns2 simulations show that our model is as accurate, yet simpler and computationally more efficient than another well known TCP model. Our model can therefore be used to rapidly analyze network topologies with several bottlenecks and obtain detailed performance metrics. Our model also gives closed form expressions for important TCP performance values and distributions.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {56–65},
numpages = {10},
keywords = {quality of service, TCP tahoe, analytical models, TCP},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145683,
author = {Pillay, Nelishia},
title = {A Genetic Programming System for the Induction of Iterative Solution Algorithms to Novice Procedural Programming Problems},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {The study presented in this paper evaluates genetic programming (GP) as a means of evolving solution algorithms to novice iterative programming problems. This research forms part of a study aimed at reducing the costs associated with developing intelligent programming tutors by inducing solutions to the programming problems presented to students, instead of requiring the lecturer to provide these solutions. The paper proposes a GP system for the induction of algorithms using iteration and nested iteration. The proposed system was tested on 15 randomly selected novice procedural programming problems requiring the use of iterative and nested-iterative constructs. The system was able to evolve solutions to eight of these problems. Premature convergence of the GP algorithm as a result of fitness function biases was identified as the cause of the failure of the system to induce solutions to the remaining seven problems. The iterative structure-based algorithm (ISBA) was developed and successfully implemented to escape local optima caused by fitness function biases and evolve solutions to these problems.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {66–77},
numpages = {12},
keywords = {genetic programming, automatic programming, intelligent programming tutors},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145684,
author = {Schoeman, Lona and Engelbrecht, Andries P.},
title = {Containing Particles inside Niches When Optimizing Multimodal Functions},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Traditionally particle swarm optimization was employed to locate a single optimal solution in a search space. The strategy can be adapted in niching algorithms to find multiple optimal solutions in a problem domain. Initially good candidate solutions must be found to serve as nuclei around which subswarms can be optimized to converge on multiple optimal solutions. Several strategies have been developed to address the problem. Algorithms to accomplish this should not depend on prior knowledge of the objective function to find starting points and estimate the niche boundaries.In previous work the authors introduced a vector-based approach to identify and demarcate the initial niches. Niches were originally optimized sequentially and later in parallel. A critical objective entailed the minimization of tunable parameters and problem dependence. This paper presents an enhanced parallel vector-based particle swarm optimizer where niches are identified using vector operations and subswarms optimized in parallel without using a niche radius.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {78–85},
numpages = {8},
keywords = {optimization},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145685,
author = {Maunder, Andrew and van Rooyen, Reinhardt and Suleman, Hussein},
title = {Designing a 'universal' Web Application Server},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Modern Web server systems typically consist of a single Web server instance capable of utilising various backend technologies. For security reasons this Web server instance is run as the unprivileged user, the user 'nobody'. This has the implication of having users make their Web components world-accessible so that such an unprivileged Web server instance may access them. World accessible files or directories are open to many threats including modification and removal by any system user, authorised or unauthorised. The X-Switch system attempts to provide a solution to this problem by allowing Web components to be run with an identical set of privileges as the component owner, an essential feature for maintaining secure multi-user server environments. The X-Switch system is a generalisation of existing solutions but attempts to provide a higher level of performance and scalability while maintaining the benefits of being independent of the implementation language used.The X-Switch system's experimental results demonstrated that a Web server that utilises run-time context switching can achieve a high level of performance. Furthermore it was shown that an X-Switch compatible engine can be developed to provide functionality matching that of existing Web application servers but with the added benefit of multi-user support. Finally the X-Switch system showed that it is feasible to completely separate issues of performance from the Web component code thus ensuring that the developer is free from the task of modifying his/her code to make it compatible with the deployment platform.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {86–94},
numpages = {9},
keywords = {context switching, Web application servers, modularity, scalability, process persistence},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145686,
author = {Vorster, Anita and Labuschagne, Les},
title = {A Framework for Comparing Different Information Security Risk Analysis Methodologies},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Organisations wanting to conduct information security risk analysis may find selecting a methodology problematic. Currently there are numerous risk analysis methodologies available, some of which are qualitative while others are more quantitative in nature. These methodologies have a common goal of estimating the overall risk value. An organisation must select the most appropriate methodology based on its specific needs. This article addresses the problem by presenting a framework that can be used to compare different risk analysis methodologies. Five methodologies, which are currently available, were analysed in order to establish the framework for comparison.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {95–103},
numpages = {9},
keywords = {methodologies, framework for comparison, information security risk analysis, risk management},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145687,
author = {Olivier, Martin S.},
title = {Distributed Proxies for Browsing Privacy: A Simulation of Flocks},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {In previous work we introduced an anonymising proxy scheme --- called Flocks --- to be used for browsing privacy. Flocks is similar to Crowds in that each proxy randomly decides whether to forward any request it receives to the destination Web server, or whether to forward the request to another proxy. In this manner request chains are formed that hide the details of an originator of a request from the destination server as well as from the various proxies.Flocks differs from Crowds (and similar Privacy-enhancing Technologies or PETs) because it caches pages that are requested. Unlike related PETs, Flocks is intended for deployment within an organisation. Caching minimises the need for communication between an organisation and external content providers, decreasing cost and potentially increasing access speed. Logging in Flocks is designed to balance privacy with the need to conduct forensic investigations when required (with safeguards to prevent unauthorised breaches of privacy).Two parameters determine the behaviour of Flocks: α is the probability with which any proxy will forward a request to an external server (rather than to another proxy) and N is the number of proxies in the system. In previous work we analytically determined the impact of these two parameters on privacy and performance aspects of Flocks.The current paper reports on simulations that were performed to gain deeper insight into the behaviour of Flocks. The simulations confirm the analytic results of our previous work. They also shed light on performance-related issues such as the number and positions of access to external servers, saturation levels and traffic patterns. This information will be useful to decide on appropriate values of α and N from a performance point of view.The simulations also highlight the problem of overly long chains that will occasionally occur. A simple solution is proposed and tested empirically. The privacy and performance implications of this solution are discussed; it is found that the solution is usable, but has a profound impact on the choice of the a and N parameters.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {104–112},
numpages = {9},
keywords = {privacy architecture, privacy-enhancing technologies, personal privacy},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145688,
author = {Tillwick, Heiko and Olivier, Martin},
title = {Towards a Framework for Connection Anonymity},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Anonymising services have evolved from simple proxies to complex systems. Numerous techniques have been developed to thwart and confuse attackers, thereby improving the degree of anonymity. These techniques are often presented as additional advantages of specific anonymising services. Comparisons of anonymity services exist, however, there is a need for a more structured approach towards the understanding of the various techniques employed by these services.This paper takes a meta-level look at connection anonymity, how it has evolved and how and why certain design choices are made. A conceptual framework describing what we consider to be important connection anonymity factors will be proposed. We consider design factors, fundamental connection anonymity functions and objectives. The framework aims to provide for a more structured and formal view of current anonymising strategies and techniques. It should thereby set the stage for further advances in connection anonymity.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {113–122},
numpages = {10},
keywords = {connection anonymity, privacy, anonymising technologies, unlinkability, anonymity, framework},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145689,
author = {Laubscher, R. and Olivier, M. S. and Venter, H. S. and Eloff, J. H. P. and Rabe, D. J.},
title = {The Role of Key Loggers in Computer-Based Assessment Forensics},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {When conducting a computer-based assessment in an educational environment, several infringements of assessment regulations could arise. Examples are, illegal communication (e.g. by e-mail, web or cell phone); hiding of computer objects with the aim of accessing or utilising it; impersonation of another student and presenting the assessment material (e.g. file containing answers of WebCT test, files that form part of a programming project) of another student. To determine beyond reasonable doubt that no infringement has taken place, various tools could be utilised. One such a tool, the key logger, is the subject of scrutiny for this study. Key loggers are considered a type of spyware. Spyware is software that gathers information secretly about a computer's use, usually installed without the user's consent or knowledge, and relays that information, also covertly, back to a third party. This paper reports the results of an explorative experiment applied to computer-based assessments with the aim to investigate the role of key loggers in computer-based assessment forensics. This exploratory experiment was conducted during computer-based assessments of different groups of students in different subjects. The results include a description of the set up of the controlled environment for the computer-based assessment, execution of the assessment with the accompanying data collection, preserving of the data, analysis of the data, effectiveness of the specific key logger in the forensic process and the conclusions derived from the data.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {123–130},
numpages = {8},
keywords = {digital evidence collection, computer-based assessment forensics},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145690,
author = {Byrne, Elaine},
title = {Using Action Research in Information Systems Design to Address Change: A South African Health Information Systems Case Study},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This paper advocates for the use of Action Research (AR) approaches in the designing of Information Systems (IS). Following a brief overview of the history of AR as a research methodology and it's use in IS research a framework for describing the AR process is developed. This framework is then used to describe the AR process involved in the design and development of a paper based and orally communicated child health IS. A common criticism of AR in IS design is the focus on the output of the design and the lack of rigour in the description of AR projects. This paper addresses this gap by focusing on the process of the design and development of the IS in the case study, but also contributes to AR by outlining a number of concerns which should be addressed by the IS researcher if AR is to viewed as rigourous. The concerns which need to be addressed are the need: to make explicit the epistemology of the researcher(s) or practitioner(s) in any AR project; to adopt a participatory AR and longitudinal approach to avoid the conflict of 'serving two masters'; to develop networks of action, and; to develop and disseminate generalisations and learnings from the research.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {131–141},
numpages = {11},
keywords = {research methodology, participatory action research, information system design},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145691,
author = {de Villiers, M. R.},
title = {Three Approaches as Pillars for Interpretive Information Systems Research: Development Research, Action Research and Grounded Theory},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This paper addresses practical approaches and models, based on the paradigm of the 'interpretivist school', to operationalise research in information systems. The study overviews research paradigms and some current issues in IS research, then describes, discusses and illustrates three approaches, namely, development research, action research, and grounded theory, advocating them as proposed pillars for interpretive IS research. With the present emphasis on user-centricity and empowerment of previously technologically-disenfranchised domains, inquiry processes emanating from the social sciences and humanities are relevant to IS, particularly with relation to interactive systems to bridge the digital divide and for the design and development of emerging technology. Each of the approaches suggested has an underlying theoretical framework and reflective methods, and can serve as a model to guide the research process, offering a unifying thread, cohesion and internal consistency to a research study.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {142–151},
numpages = {10},
keywords = {models, research philosophy, research methodology, reflection, metaresearch, human-computer interaction},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145692,
author = {Leonard, Awie},
title = {A Conceptual Framework for Explaining the Value of End User Maturity Levels for IT Management},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This paper proposes a conceptual framework of three maturity levels for the effective management of end users during systems development. The framework is based on a model that explains all the important elements involved during the establishment and maintenance of sound relationships between the different role players in a software project team. It is argued that the level of end user maturity is determined by the experience and knowledge of the end user regarding the nature of a given project. As such it is directly linked to the type of IT-end user relationship. The value of the three levels lies therein that it gives the IT department the advantage of understanding and supporting end users in a more effective way during systems development. The research was done by means of a qualitative approach in which thought experiments were used to inductively refine the results of the research study.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {152–158},
numpages = {7},
keywords = {relationships, soft issues, maturity levels, relationship management, quality assurance, end users, end user involvement, systems development, project management},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145693,
author = {Grant, Tim},
title = {Unifying Planning and Control Using an OODA-Based Architecture},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Planning and real-time control are closely related, but separate research fields. An architecture that unifies planning and control, together with related processes, is needed for autonomous systems, for military command and control (C2), for agile manufacturing, and for many other domains. This paper proposes an operational-view architecture that unifies planning and control based on Boyd's Observe-Orient-Decide-Act (OODA) process model [Boyd, 1996]. The shortcomings of OODA are identified by comparing it with other process models. OODA is then rationally reconstructed using use-cases and formalised using Structured Analysis &amp; Design Technique (SADT). The next step is to develop the systems view in Unified Modeling Language (UML). The architecture will then be verified by implementing and testing a C2 system demonstrator.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {159–170},
numpages = {12},
keywords = {dynamic risk management, real-time, sense-making, Observe-Orient-Decide-Act (OODA), Structured Analysis &amp; Design Technique (SADT)},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145694,
author = {Strauss, Tinus and Kourie, Derrick G. and Olivier, Martin S.},
title = {A Simulation Study of Traffic Conditioner Performance},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This article reports on the results of a simulation study to investigate the relative performance of five Differentiated Services traffic conditioners in a range of situation created by varying traffic patterns and subscription levels in a fixed topology network. Two performance measures---TargetRatio and GreenRatio---are defined, justified, and used to compare the traffic conditioners. One measure was more discriminating than the other. A variant of the second measure was used to further illuminate the differences between conditioners. The results suggest that the performance of the conditioners are sensitive to parameter values such as token bucket size and that the traffic patterns should also be taken into consideration when deciding on values for the configuration parameters.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {171–181},
numpages = {11},
keywords = {simulation, traffic conditioners, differentiated services},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145695,
author = {Berg, Kathrin and Bishop, Judith and Muthig, Dirk},
title = {Tracing Software Product Line Variability: From Problem to Solution Space},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {The management of variability plays an important role in successful software product line engineering. There is a need for a universal variability management approach to be consistent and scalable; it should provide traceability between variations at different levels of abstraction and across various generic development artifacts; and there should be a means for visualizing variability. Focusing specifically on the aspect of traceability in the context of such an approach, we define a conceptual variability model that captures variability information in a third dimension, and allows a 1-to-1 mapping of variability between the problem space and the solution space. Decision models, of which the feature model is most popular, are commonly used for, amongst others, managing traceability of variation. These, however, usually reside in a two dimensional space. We analyze the feature model in a small case study with regards to our conceptual variability model, and present our findings.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {182–191},
numpages = {10},
keywords = {software product line engineering, variability management, traceability},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145696,
author = {Alexander, PM and van Loggerenberg, JJ},
title = {The Repertory Grid: "Discovering" a 50-Year-Old Research Technique},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Empirical research in any discipline is heavily dependent on the quality of data collected and the meaning which subsequent analysis reveals. This obvious statement underlies the debates on rigor, and less directly on relevance, which recur periodically in the journals devoted to Information Systems. Empirical research in Information Systems (IS) is largely based upon data collected by means of questionnaires, interviews, documentation and observation. Inexperienced researchers find questionnaires and interviews particularly attractive as a data gathering methodology as they can draw on their own experience of having to fill in forms and being interviewed. However, as many researchers have discovered, it is not as simple as it appears at first to draft a good questionnaire. Also, respondents are notoriously unenthusiastic when it comes to filling out questionnaires. The result is that their answers are very often superficial which impacts negatively on the quality of the research. Interviewing provides richer data and hence overcomes some of the problems of questionnaires, but still leaves the researcher with few guidelines. This paper explores the potential of a technique called the Repertory Grid as an alternative means of gathering meaningful empirical data. It traces it origins, describes how it works, analyses the strengths and weaknesses and looks at instances where it has already been used in IS research. It then describes the authors' experience in the use of this technique and concludes that it well worth considering by inexperienced and experienced IS researchers alike. Although the technique may initially appear to be positivist this is not the case. It can be used for both ideographic and nomothetic research. It uncovers perceptions, assumptions, and concepts from the research participants while striving to minimise the degree to which the researcher influences the outcomes.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {192–199},
numpages = {8},
keywords = {data collection, repertory grid, research methods, cognition},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145697,
author = {Brown, Irwin and Buys, Michael},
title = {A Cross-Cultural Investigation into Customer Satisfaction with Internet Banking Security},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Consumer Internet banking has been fairly successful in South Africa, with all major retail banks providing this service to customers. Approximately one million Internet users make use of this channel, with the profile tending to be those with higher incomes and occupying managerial and professional jobs. Recent media attention given to security breaches with Internet banking provides an opportunity to assess what impact this has had on perceptions of security across different cultural groups. In a study examining cultural values of managers from different ethnic groups in South Africa, it was found that groups differed mainly on the dimension of uncertainty avoidance. In this study therefore it was posited that those groups with higher scores for uncertainty avoidance would react more strongly to perceived security threats given the uncertainty that this created, and would therefore be less satisfied with security than those lower in uncertainty avoidance. In order to investigate this proposition, data gathered from a survey of postgraduate and MBA students at two leading business schools in South Africa was analysed. Respondents were surveyed as to their banking habits, cultural values and satisfaction with Internet banking. The findings confirm the above proposition as those groups with higher uncertainty avoidance were less satisfied with security than those groups with lower uncertainty avoidance. The implications of these findings are discussed.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {200–207},
numpages = {8},
keywords = {security, customer information satisfaction, culture, internet banking},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145698,
author = {Wesson, Janet L. and van der Walt, Darryn F.},
title = {Implementing Mobile Services: Does the Platform Really Make a Difference?},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This paper discusses an investigation into two different platforms for developing mobile services, namely Microsoft .NET Mobile and J2ME. A mobile student information and services (MSS) application was developed in both platforms. Comparisons were made based on various criteria, both from the developer and the user perspective. The results show that both platforms have certain advantages and that selection of the appropriate platform will depend on the specific situation. Several implications for future developers are provided as well as recommendations as to when each platform is more appropriate.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {208–216},
numpages = {9},
keywords = {user interface design, mobile services, usability},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145699,
author = {Jolliffe, Bob},
title = {The Word-Processing Patent: A Sceptical View from a Person Having Ordinary Skill in the Art},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {In April of 2004 a patent was published by the South African patent office entitled: "Word-processing document stored in a single XML file that may be manipulated by applications that understand XML". The description refers to a word-processing program which reads and writes documents in a native XML format. The patent application, number ZA200303346, was filed by Microsoft Corporation. That such an item should have washed up on our shores (we can be reasonably sure it did not originate here) is surprising for a number of reasons. The South African Patent Act specifically excludes computer programs (and the presentation of information) from patentability. The Act also sets out requirements for novelty, non-obviousness and an inventive step, all of which seem to be somewhat lacking in this application.In this short paper I provide a brief overview of the international "intellectual property" environment which forms the backdrop to this strange arrival in our local patent office. I go on to argue that this particular patent, if it were to be enforced, could have a number of negative consequences which far outweigh any value it may have to our local economy and well-being.With an eye to the conference theme of "Research for a changing world", I argue that the most fundamental and far-reaching of changes we have seen in our field in the past few years, have not been technical, but rather changes in the normative assumptions surrounding the ownership of so called "intellectual property". The proliferation of software patents which are over reaching in their scope, or predatory, trivial, or just plain nonsense reflects the new thinking. Patent number ZA200303346 falls somewhere amongst these categories.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {217–225},
numpages = {9},
keywords = {free/open source software, globalisation, legal aspects of computing, software patents, computers and society, intellectual property},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145700,
author = {Grobler, Janno and Kourie, Derrick},
title = {Design of a High Resolution Soft Real-Time Timer under a Win32 Operating},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {This article defines a real-time timer, and shows that a Win32 PC operating system does not provide a timer that fits this definition. Without a real-time timer, a true hard real-time system cannot be implemented. Not withstanding this, some companies, including Microsoft itself, provide real-time extensions to the Win32 PC platform, enabling the development of real-time implementations. Bearing this in mind, a solution is presented in which a workaround is found for the shortcomings of the timers provided Win32 PC platform, without looking to real-time extensions as the solution. Also considered is the question of whether the workaround offered here is likely to be compatible with expected advances in future Central Processing Unit (CPU) technologies.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {226–235},
numpages = {10},
keywords = {timers, real-time implementations, hyper-threading, events},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145701,
author = {Bachoo, Asheer Kasar and Tapamo, Jules-Raymond},
title = {Texture Detection for Segmentation of Iris Images},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {The idea of using the distinct spatial distribution of patterns in the human iris for person authentication is now a widely developing technology. Current systems rely on a set of basic assumptions in order to improve the accuracy and running time of the recognition process. The advent of a robust system implies a viable solution to a number of general problems. This paper focuses on a common yet difficult problem - the segmentation of eyelashes from iris texture. Tests give promising results when using grey level co-occurrence matrix (GLCM) approach.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {236–243},
numpages = {8},
keywords = {GLCM, localization, iris, classification, K-Means, texture},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145702,
author = {Adesemowo, A. Kayode and Tucker, William D.},
title = {Instant Messaging on Handhelds: An Affective Gesture Approach},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Text communication can be perceived as lacking in chat spontaneity, or plastic, due to medium limitations during interaction. A form of text messaging, Instant Messaging (IM), is now on the uptake, even on mobile handhelds. This paper presents results of using affective gesture to rubberise IM chat in order to improve synchronous communication spontaneity. The experimental design makes use of a text-only IM tool, running on handhelds, built with the Session Initiation Protocol (SIP) and the SIP Instant Messaging and Presence Leveraging Extensions (SIMPLE). The tool was developed with a novel user-defined hotkey -- a one-click context menu that fast-tracks the creation and transmission of text-gestures and emoticons. A hybrid quantitative and qualitative approach was taken in order to enable data triangulation. Data collected from user trials affirms that the affective gesture hotkey facility improves chat responsiveness, thus enhancing chat spontaneity.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {244–251},
numpages = {8},
keywords = {affective gesture, text communication, SIMPLE, handhelds, instant messaging, chat spontaneity},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145703,
author = {van Kempen, Marc and Chaudron, Michel and Kourie, Derrick and Boake, Andrew},
title = {Towards Proving Preservation of Behaviour of Refactoring of UML Models},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Refactoring of a design before updating and modifying software has become an accepted practice in order to prepare the design for the upcoming changes. This paper describes a refactoring of the design of a particular application to illustrate a suggested approach. In this approach, we represent the design using UML, more specifically the structure using class diagrams, and the behaviour of each class using statecharts.Examining metrics of the specific design, we suggest a refactoring that changes a centralized control structure into one that employs more delegation, showing the refactored class and statechart diagrams. As preserving behaviour is one of the defining attributes of a refactoring, we use a csp-based formalism to describe the refactoring, and show that the refactoring indeed preserves behaviour.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {252–259},
numpages = {8},
keywords = {restructuring, CSP, behaviour, refactoring, statechart, process algebra, UML},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145704,
author = {Tsoaeli, Tebalo and Bishop, Judith},
title = {Enhancing Adaptability of Distributed Groupware Applications},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Distributed Groupware applications must be designed to cope with an increasingly diverse set of operational conditions. The available network bandwidth and latency, the network connectivity, the number of users, the type of devices, the system load, are, among others, examples of parameters that may change at run-time. This paper proposes an adaptive layer which uses monitoring and filtering techniques to adapt to changes in the communication environment/current context. The Nomad system is used as a case study for this concept.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {260–267},
numpages = {8},
keywords = {groupware, context awareness, adaptive, mobile devices, adaptive layer, adaptability},
location = {White River, South Africa},
series = {SAICSIT '05}
}

@inproceedings{10.5555/1145675.1145705,
author = {Theunissen, W. H. Morkel and Boake, Andrew and Kourie, Derrick G.},
title = {In Search of the Sweet Spot: Agile Open Collaborative Corporate Software Development},
year = {2005},
isbn = {1595932585},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Corporate software developers are faced with many difficulties. Development windows are decreasing; scale and complexity are increasing; business requirements are vague and changing; and the underlying technology moves ever on. Agile methods have emerged as leading contenders to tame these challenges. Small teams, face-to-face communication, an emphasis on simplicity and a selection of development best practices contribute to software development which is relevant, yet fast and flexible. At the same time, Open Source Software is increasingly providing infrastructure, tools and components to companies. Progressive development teams are beginning to work in more open, collaborative, and distributed ways. In some respects these practices are similar to agile practices, but in important ways, very different. Yet, both are important and offer unique benefits. This paper discusses the prospects of combining the two in the context of corporate software development, and the approach we suggest to do this.},
booktitle = {Proceedings of the 2005 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {268–277},
numpages = {10},
keywords = {software process engineering metamodel, progressive open source, corporate, agile software development, open source software development, hybrid},
location = {White River, South Africa},
series = {SAICSIT '05}
}

