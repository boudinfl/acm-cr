@inproceedings{10.1145/1097047.1097048,
author = {Kossmann, Donald},
title = {A Web of Data: New Architectures for New Technology?},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097048},
doi = {10.1145/1097047.1097048},
abstract = {The last decade has seen a wave of new technology to publish, access, and integrate data on the Web. Furthermore, many new applications have emerged and Web technologies have penetrated almost all systems from small mobile applications to large-scale enterprise applications. Nevertheless, the way we build those applications has not changed much; imperative programming languages (e.g., Java or C#) and middleware architectures are still dominant in industry. This talk tries to describe why these old architectures are problematic and presents ideas for novel software architectures to build Web applications.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {1},
numpages = {1},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/3246250,
author = {Dekhtyar, A.},
title = {Session Details: Web Ranking and Retrieval},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3246250},
doi = {10.1145/3246250},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
numpages = {1},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097050,
author = {Eirinaki, Magdalini and Vazirgiannis, Michalis and Kapogiannis, Dimitris},
title = {Web Path Recommendations Based on Page Ranking and Markov Models},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097050},
doi = {10.1145/1097047.1097050},
abstract = {Markov models have been widely used for modelling users' navigational behaviour in the Web graph, using the transitional probabilities between web pages, as recorded in the web logs. The recorded users' navigation is used to extract popular web paths and predict current users' next steps. Such purely usage-based probabilistic models, however, present certain shortcomings. Since the prediction of users' navigational behaviour is based solely on the usage data, structural properties of the Web graph are ignored. Thus important - in terms of pagerank authority score - paths may be underrated. In this paper we present a hybrid probabilistic predictive model extending the properties of Markov models by incorporating link analysis methods. More specifically, we propose the use of a PageRank-style algorithm for assigning prior probabilities to the web pages based on their importance in the web site's graph. We prove, through experimentation, that this approach results in more objective and representative predictions than the ones produced from the pure usage-based approaches.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {2–9},
numpages = {8},
keywords = {Markov models, link analysis, PageRank, web personalization},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097051,
author = {Varelas, Giannis and Voutsakis, Epimenidis and Raftopoulou, Paraskevi and Petrakis, Euripides G.M. and Milios, Evangelos E.},
title = {Semantic Similarity Methods in WordNet and Their Application to Information Retrieval on the Web},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097051},
doi = {10.1145/1097047.1097051},
abstract = {Semantic Similarity relates to computing the similarity between concepts which are not lexicographically similar. We investigate approaches to computing semantic similarity by mapping terms (concepts) to an ontology and by examining their relationships in that ontology. Some of the most popular semantic similarity methods are implemented and evaluated using WordNet as the underlying reference ontology. Building upon the idea of semantic similarity, a novel information retrieval method is also proposed. This method is capable of detecting similarities between documents containing semantically similar but not necessarily lexicographically similar terms. The proposed method has been evaluated in retrieval of images and documents on the Web. The experimental results demonstrated very promising performance improvements over state-of-the-art information retrieval methods.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {10–16},
numpages = {7},
keywords = {world wide web, information retrieval, WordNet, semantic similarity},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097052,
author = {Krikos, Vlassis and Stamou, Sofia and Kokosis, Pavlos and Ntoulas, Alexandros and Christodoulakis, Dimitris},
title = {DirectoryRank: Ordering Pages in Web Directories},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097052},
doi = {10.1145/1097047.1097052},
abstract = {Web Directories are repositories of Web pages organized in a hierarchy of topics and sub-topics. In this paper, we present DirectoryRank, a ranking framework that orders the pages within a given topic according to how informative they are about the topic. Our method works in three steps: first, it processes Web pages within a topic in order to extract structures that are called lexical chains, which are then used for measuring how informative a page is for a particular topic. Then, it measures the relative semantic similarity of the pages within a topic. Finally, the two metrics are combined for ranking all the pages within a topic before presenting them to the users.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {17–22},
numpages = {6},
keywords = {web directory, semantic similarity, ranking},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/3246251,
author = {Petrakis, E. G. M.},
title = {Session Details: XML Data Management and Web Discovery},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3246251},
doi = {10.1145/3246251},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
numpages = {1},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097054,
author = {Weigel, Felix and Schulz, Klaus U. and Meuss, Holger},
title = {Exploiting Native XML Indexing Techniques for XML Retrieval in Relational Database Systems},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097054},
doi = {10.1145/1097047.1097054},
abstract = {In XML retrieval, two distinct approaches have been established and pursued without much cross-fertilization taking place so far. On the one hand, native XML databases tailored to the semistructured data model have received considerable attention, and a wealth of index structures, join algorithms, tree encodings and query rewriting techniques for XML have been proposed. On the other hand, the question how to make XML fit the relational data model has been studied in great detail, giving rise to a multitude of storage schemes for XML in relational database systems (RDBSs). In this paper we examine how native XML indexing techniques can boost the retrieval of XML stored in an RDBS. We present the Relational CADG (RCADG), an adaptation of several native indexing approaches to the relational model, and show how it supports the evaluation of a clean formal language of conjunctive XML queries. Unlike relational storage schemes for XML, the RCADG largely preserves the underlying tree structure of the data in the RDBS, thus addressing several open problems known from the literature. Experiments show that the RCADG accelerates retrieval by up to two or even three orders of magnitude compared to both native and relational approaches.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {23–30},
numpages = {8},
keywords = {query evaluation, Relational CADG, XML retrieval, CADG, RDBMS, relational database, RDBS, XML indexing, storage scheme, RCADG, content-aware dataGuide},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097055,
author = {Chen, Cindy X. and Mihaila, George A. and Padmanabhan, Sriram and Rouvellou, Isabelle M.},
title = {Query Translation Scheme for Heterogeneous XML Data Sources},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097055},
doi = {10.1145/1097047.1097055},
abstract = {In order to formulate a meaningful XML query, a user must have some knowledge of the schema of the XML documents to be queried. The query will succeed only if the schema of the actual documents is consistent with the user's information. When a user queries a collection of documents collected from heterogeneous XML data sources, there is a high possibility that these documents do not all conform to the same schema assumed by the user, thus causing the query to fail. In this paper, we try to solve this query and data schema mismatching problem by proposing a query translation scheme. Without attempting to solve the general problem of schema integration, we present an inclusion mapping algorithm that decides how compatible the schema of the query and the schema of the target XML documents are. Based upon the compatibility, the query will be executed directly, or translated according to the target schema and then executed, or rejected.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {31–38},
numpages = {8},
keywords = {XML, heterogeneous databases},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097056,
author = {Guerrini, Giovanna and Mesiti, Marco and Rossi, Daniele},
title = {Impact of XML Schema Evolution on Valid Documents},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097056},
doi = {10.1145/1097047.1097056},
abstract = {In this paper we investigate the problem of XML Schema evolution. We first discuss the different kinds of changes that may be needed on an XML Schema. Then, we investigate how to minimize document revalidation, that is, detecting the document parts potentially invalidated by the schema changes that should be revalidated.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {39–44},
numpages = {6},
keywords = {document revalidation, XML, schema evolution},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097057,
author = {Pathak, Jyotishman and Koul, Neeraj and Caragea, Doina and Honavar, Vasant G.},
title = {A Framework for Semantic Web Services Discovery},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097057},
doi = {10.1145/1097047.1097057},
abstract = {This paper describes a framework for ontology-based flexible discovery of Semantic Web services. The proposed approach relies on user-supplied, context-specific mappings from an user ontology to relevant domain ontologies used to specify Web services. We show how a user's query for a Web service that meets certain selection criteria can be transformed into queries that can be processed by a matchmaking engine that is aware of the relevant domain ontologies and Web services. We also describe how user-specified preferences for Web services in terms of non-functional requirements (e.g., QoS) can be incorporated into the Web service discovery mechanism to generate a partially ordered list of services that meet user-specified functional requirements.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {45–50},
numpages = {6},
keywords = {ontologies, quality of service, semantic web, web service discovery},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/3246252,
author = {Chen, C.},
title = {Session Details: Web Clustering, Filtering and Applications},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3246252},
doi = {10.1145/3246252},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
numpages = {1},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097059,
author = {Zhang, Yongzheng and Zincir-Heywood, Nur and Milios, Evangelos},
title = {Narrative Text Classification for Automatic Key Phrase Extraction in Web Document Corpora},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097059},
doi = {10.1145/1097047.1097059},
abstract = {Automatic key phrase extraction is a useful tool in many text related applications such as clustering and summarization. State-of-the-art methods are aimed towards extracting key phrases from traditional text such as technical papers. Application of these methods on Web documents, which often contain diverse and heterogeneous contents, is of particular interest and challenge in the information age. In this work, we investigate the significance of narrative text classification in the task of automatic key phrase extraction in Web document corpora. We benchmark three methods, TFIDF, KEA, and Keyterm, used to extract key phrases from all the plain text and from only the narrative text of Web pages. ANOVA tests are used to analyze the ranking data collected in a user study using quantitative measures of acceptable percentage and quality value. The evaluation shows that key phrases extracted from the narrative text only are significantly better than those obtained from all plain text of Web pages. This demonstrates that narrative text classification is indispensable for effective key phrase extraction in Web document corpora.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {51–58},
numpages = {8},
keywords = {acceptable percentage, narrative text classification, key phrase extraction},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097060,
author = {Cui, Qing and Dekhtyar, Alex},
title = {On Improving Local Website Search Using Web Server Traffic Logs: A Preliminary Report},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097060},
doi = {10.1145/1097047.1097060},
abstract = {In this paper we give a preliminary report on our study of the use of web server traffic logs to improve local search. Web server traffic logs are, typically, private to individual websites and as such -- are unavailable to traditional web search engines conducting searches across multiple web sites. However, they can be used to augment search performed by a local search engine, restricted to a single site.Web server traffic logs, which we will refer to as simply logs throughout this paper, contain information on traffic patterns on a web site. By using this information, instead of pure link counts in the computation of PageRank, we can obtain a new local measure of web site importance, based on frequency of visits to a page, rather than simply on the amount of links.In this paper we describe the architecture of a search engine we have built for the Eastern Kentucky University (EKU) website and some preliminary experiments we have conducted with it.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {59–66},
numpages = {8},
keywords = {probabilistic automata, Markov decision process, PageRank, web search, web traffic logs, local web search},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097061,
author = {Chirita, Paul-Alexandru and Nejdl, Wolfgang and Zamfir, Cristian},
title = {Preventing Shilling Attacks in Online Recommender Systems},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097061},
doi = {10.1145/1097047.1097061},
abstract = {Collaborative filtering techniques have been successfully employed in recommender systems in order to help users deal with information overload by making high quality personalized recommendations. However, such systems have been shown to be vulnerable to attacks in which malicious users with carefully chosen profiles are inserted into the system in order to push the predictions of some targeted items. In this paper we propose several metrics for analyzing rating patterns of malicious users and evaluate their potential for detecting such shilling attacks. Building upon these results, we propose and evaluate an algorithm for protecting recommender systems against shilling attacks. The algorithm can be employed for monitoring user ratings and removing shilling attacker profiles from the process of computing recommendations, thus maintaining the high quality of the recommendations.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {67–74},
numpages = {8},
keywords = {shilling attacks, web applications, collaborative filtering, recommender systems},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097062,
author = {Barbosa, Luciano and Salgado, Ana Carolina and de Carvalho, Francisco and Robin, Jacques and Freire, Juliana},
title = {Looking at Both the Present and the Past to Efficiently Update Replicas of Web Content},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097062},
doi = {10.1145/1097047.1097062},
abstract = {Since Web sites are autonomous and independently updated, applications that keep replicas of Web data, such as Web warehouses and search engines, must periodically poll the sites and check for changes.Since this is a resource-intensive task, in order to keep the copies up-to-date, it is important to devise efficient update schedules that adapt to the change rate of the pages and avoid visiting pages not modified since the last visit.In this paper, we propose a new approach that learns to predict the change behavior of Web pages based both on the static features and change history of pages, and refreshes the copies accordingly.Experiments using real-world data show that our technique leads to substantial performance improvements compared to previously proposed approaches.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {75–80},
numpages = {6},
keywords = {update policy, indexing update, machine learning},
location = {Bremen, Germany},
series = {WIDM '05}
}

@inproceedings{10.1145/1097047.1097063,
author = {Toda, Hiroyuki and Kataoka, Ryoji},
title = {A Search Result Clustering Method Using Informatively Named Entities},
year = {2005},
isbn = {1595931945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1097047.1097063},
doi = {10.1145/1097047.1097063},
abstract = {Clustering the results of a search helps the user to overview the information returned. In this paper, we regard the clustering task as indexing the search results. Here, an index means a structured label list that can makes it easier for the user to comprehend the labels and search results. To realize this goal, we make three proposals. First is to use Named Entity Extraction for term extraction. Second is a new label selecting criterion based on importance in the search result and the relation between terms and search queries. The third is label categorization using category information of labels, which is generated by NE extraction. We implement a prototype system based on these proposals and find that it offers much higher performance than existing methods; we focus on news articles in this paper.},
booktitle = {Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management},
pages = {81–86},
numpages = {6},
keywords = {search result clustering, named entity},
location = {Bremen, Germany},
series = {WIDM '05}
}

