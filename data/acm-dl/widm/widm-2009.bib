@inproceedings{10.1145/3261248,
author = {Mitra, Prasenjit},
title = {Session Details: Querying, Question Answering, &amp; Searching},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3261248},
doi = {10.1145/3261248},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
numpages = {1},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651589,
author = {Lee, Dik Lun},
title = {User Profiling and Personalized Information Delivery on the Static and Mobile Web},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651589},
doi = {10.1145/1651587.1651589},
abstract = {Imagine a system that can push highly selective information right to our hands when and only when we need it. This requires a mind-reading machine, but unfortunately we don't have one --- yet. User profiling attempts to estimate what is most important to a user at a particular point in time and space. In this talk, I will start with simple raw data such as the users' queries and clicks on the web and places they have visited to estimate what they might be interested in. We further divide user interests into content-based and location-based. We discuss issues involving the transformation of raw activities to conceptual needs, identifying user groups for collaborative filtering and the roles of locations in personalized information delivery.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {1–2},
numpages = {2},
keywords = {clickthrough, query clustering, user clustering, user profiling},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651590,
author = {Pera, Maria S. and Qumsiyeh, Rani and Shaikh, Meher T. and Ng, Yiu-Kai},
title = {Retrieving Good, Better, and Best Answers to Questions in Advertisements},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651590},
doi = {10.1145/1651587.1651590},
abstract = {Question-Answering (QA) service is a growing area of research study, and commercial QA systems have recently been developed. We are motivated to provide complementary QA service that answers questions in advertisements (ads). These days with almost all businesses online, potential buyers who search for merchandises to purchase through the Internet are also flourishing. When a Web user looks for products online, he may have many questions on his mind for which he would be eager to receive answers prior to finalizing his purchasing decision. Although some ads Web sites are complemented with FAQs, their QA services either are non-existent or do not provide answers to inquires in real time automatically. We address these problems by answering user's questions such as "Which is the cheapest car?", "Are there any entry-level, software developer positions?", etc., spontaneously in real time. Existing general-purpose QA systems, such as Ask.com, provide answers to a user's question Q in a list format. A more sophisticated approach is to order the answers to Q according to their degrees of relevance to Q. We propose a QA system which deals with the challenge of interpreting users' questions and retrieves correct, as well as partially-matched ranked, answers. Experimental results have verified that the proposed QA system is highly accurate in answering users' questions on car ads.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {3–6},
numpages = {4},
keywords = {similarity measure, partial matching, question answering},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651591,
author = {Stamou, Sofia and Kozanidis, Lefteris},
title = {Impact of Search Results on User Queries},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651591},
doi = {10.1145/1651587.1651591},
abstract = {In this paper, we experimentally study how web searchers select the keywords to describe their information needs and specifically we investigate whether query keyword selections are influenced by the results the users reviewed for a previous search. For our study, we determine two types of searches: (i) those in which users define their queries without any external influence and which we call tightly-focused and (ii) those in which users define their queries under some external influence and which we call loosely-focused. Based on the analysis of the user querying trends and web visits on the query results, we propose a model that tries to capture the results' influence on the specification of the subsequent user queries. The application of our model on a search trace of 19,250 queries issued to Google by 18 users over a period of two months reveals that in overall search results influence the specification of 12.79% of the web queries.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {7–10},
numpages = {4},
keywords = {querying trends, web search, search results influence},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651592,
author = {Skopal, Tom\'{a}\v{s} and Dohnal, Vlastislav and Batko, Michal and Zezula, Pavel},
title = {Distinct Nearest Neighbors Queries for Similarity Search in Very Large Multimedia Databases},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651592},
doi = {10.1145/1651587.1651592},
abstract = {As the volume of multimedia data available on internet is tremendously increasing, the content-based similarity search becomes a popular approach to multimedia retrieval. The most popular retrieval concept is the k nearest neighbor (kNN) search. For a long time, the kNN queries provided an effective retrieval in multimedia databases. However, as today's multimedia databases available on the web grow to massive volumes, the classic kNN query quickly loses its descriptive power. In this paper, we introduce a new similarity query type, the k distinct nearest neighbors (kDNN), which aims to generalize the classic kNN query to be more robust with respect to the database size. In addition to retrieving just objects similar to the query example, the kDNN further ensures the objects within the result have to be distinct enough, i.e. excluding near duplicates.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {11–14},
numpages = {4},
keywords = {content-based retrieval, similarity search, knn query},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/3261249,
author = {Choi, Bryon},
title = {Session Details: Web Algorithms},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3261249},
doi = {10.1145/3261249},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
numpages = {1},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651594,
author = {Suzuki, Nobutaka and Fukushima, Yuji},
title = {Satisfiability of Simple Xpath Fragments in the Presence of Dtds},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651594},
doi = {10.1145/1651587.1651594},
abstract = {For an XPath expression q and a DTD D, q is satisfiable under D if there exists an XML document t such that t is valid against D and that the answer of q on t is nonempty. Evaluating an unsatisfiable XPath expression is meaningless, since such an expression can always be replaced by an empty set without evaluating it. However, it is shown that the XPath satisfiability problem is intractable for a large number of XPath fragments. In this paper, we consider simple XPath fragments under two restrictions; (i) only a label can be specified as a node test and (ii) operators such as qualifier ([]) and union (∪) are not allowed. We first show that, for some small XPath fragments under the above restrictions, the satisfiability problem is still NP-complete. Then we show that there exist XPath fragments, containing the above small fragments, for which the satisfiability problem is in PTIME under duplicate-free DTDs.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {15–22},
numpages = {8},
keywords = {xpath, xml, satisfiability, dtd},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651595,
author = {Hasan, Tahira and Mudur, Sudhir P. and Shiri, Nematollaah},
title = {A Session Generalization Technique for Improved Web Usage Mining},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651595},
doi = {10.1145/1651587.1651595},
abstract = {Generalization of web sessions is an effective approach used to overcome two major challenges in web usage mining, namely quality and scalability. Given a concept hierarchy, such as a website, generalization replaces actual page-clicks with their general concepts, i.e., nodes at higher levels. Presently known methods do this by choosing a level in the hierarchy, below which all the nodes are generalized to nodes at this level. The problem with this is that significant items may be coalesced, and insignificant ones may be retained. We present a usage driven generalization algorithm, which coalesces less significant pages into more general ones, independent of their level in the hierarchy. Based on actual usage set of sessions, item significance is estimated approximately but fast, using a small stratified sample of the large dataset. While providing scalability, the proposed generalization technique results in improved efficiency and quality of the discovered usage model, demonstrated through numerous experiments in our work.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {23–30},
numpages = {8},
keywords = {usage profiles, recommender systems, web usage mining, data generalization, fuzzy clustering},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651596,
author = {Zhang, Xianchao and Han, Bo and Liang, Wenxin},
title = {Automatic Seed Set Expansion for Trust Propagation Based Anti-Spamming Algorithms},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651596},
doi = {10.1145/1651587.1651596},
abstract = {Seed sets are of significant importance for trust propagation based anti-spamming algorithms, e.g., TrustRank. Conventional approaches require manual evaluation to construct a seed set, which restricts the seed set to be small in size, since it would cost too much and may even be impossible to construct a very large seed set manually. The small-sized seed set can cause detrimental effect on the final ranking results. Thus, it is desirable to automatically expand an initial seed set to a much larger one. In this paper, we propose the first automatic seed set expansion algorithm (ASE), which expands a small seed set by selecting reputable seeds that are found and guaranteed to be reputable through a joint recommendation link structure. Experimental results on the WEBSPAM-2007 dataset show that with the same manual evaluation efforts, ASE can automatically obtain a large number of reputable seeds with high precision, thus significantly improving the performance of the baseline algorithm in terms of both reputable site promotion and spam site demotion.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {31–38},
numpages = {8},
keywords = {link analysis, seed selection, seed expansion, trustrank, spam},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/3261250,
author = {Fletcher, George},
title = {Session Details: Web Information Mining &amp; Extraction Techniques},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3261250},
doi = {10.1145/3261250},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
numpages = {1},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651598,
author = {Lee, Jung-Jin and Lee, Jung-Hyun and Ha, JongWoo and Lee, SangKeun},
title = {Novel Web Page Classification Techniques in Contextual Advertising},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651598},
doi = {10.1145/1651587.1651598},
abstract = {Contextual advertising seeks to place relevant ads to generic web pages based on their contents. Recently, it has been observed that classifying web pages into a well-organized taxonomy of topics is promising for matching topically relevant ads to web pages. Following the observation, in this paper we propose two methods to increase classification accuracy for web pages in the context of contextual advertising. Our strategy is to enhance the baseline classifier by reflecting unique features of web pages and the taxonomy. In particular, category tags extracted from web pages are utilized to augment term weights, and the hierarchical structure of the taxonomy is taken into account to categorize web pages with high confidence. We conduct a series of experiments to evaluate the proposed methods, and the results show that classification accuracy is increased up to 11% compared to the baseline classifier.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {39–47},
numpages = {9},
keywords = {comparative distance score, category tag, web page classification, concept hierarchy},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651599,
author = {Nguyen Hoang, Tu Anh and Hoang, Kiem},
title = {Efficient Approach for Incremental Vietnamese Document Clustering},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651599},
doi = {10.1145/1651587.1651599},
abstract = {In this paper, we present how to use graph model for clustering Vietnamese document incrementally. Graph based model allows us to model completely the structure of not only each document but also the whole collection of documents. The graph structure is easily updated when there is a new document. When building the graph incrementally we can identify representative subgraph features, which are later used for calculating hybrid pair-wise document similarity. These subgraph features make clustering process less sensitive to the Vietnamese word segmentation step. Based on the hybrid similarity measure, the documents are groups into clusters on-the-fly without any assumptions on the number of clusters and without retrieving previous documents.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {47–54},
numpages = {8},
keywords = {graph model, incremental document clustering, shared phrases, vietnamese},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651600,
author = {Chen, You and Yang, Sen and Cheng, XueQi},
title = {Bursty Topics Extraction for Web Forums},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651600},
doi = {10.1145/1651587.1651600},
abstract = {Many bursty topics which are difficult to summarize and search exist in web forums. Most existing topic detection and tracking (TDT) methods deal with the news stories, but the language used in web forums are much casual, oral and informal compared with news data. In this paper, we present a noise-filtered model to extract bursty topics from web forums using terms and participations of users. Conducting experiments in ShuiMu community we demonstrate the efficiency of our model. Our model not only extracts bursty topics which are better organized for search and visualization, but also discoveries communities corresponding to these topics.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {55–58},
numpages = {4},
keywords = {frequency segment, bursty topics, web forums, feature trajectory},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651601,
author = {Liu, Yanhong and Jin, Peiquan and Yue, Lihua},
title = {Extracting Position Relations from the Web},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651601},
doi = {10.1145/1651587.1651601},
abstract = {In this paper, we present a new algorithm to extract people's position in a corporation from the Web. People's position in a corporation, which the term position relation refers to, is a kind of significant competitive intelligence for enterprises. Our algorithm is based on the structural feature of position relation in Web contents, i.e., position relation is usually described in Web pages as a table or a list. In order to define the structural feature of Web contents, we first introduce a structural coefficient for each Web page. This structural coefficient is then used to generate structural file segments from Web pages. A structural file segment consists of all the candidates of position relation with a similar structure. We then employ a pattern-matching method to extract position relations from the structural file segments. Finally, we conduct experiments on a real data set containing 6028 Chinese Web pages gathered through the Baidu search engine, and evaluate the precision and recall of our approach. The experimental results show that our algorithm has a high precision over 96% as well as a recall over 87%.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {59–62},
numpages = {4},
keywords = {position relation, relation extraction, structural file segment},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651602,
author = {Ahmed, Emdad and Jamil, Hasan M.},
title = {Post Processing Wrapper Generated Tables for Labeling Anonymous Datasets},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651602},
doi = {10.1145/1651587.1651602},
abstract = {A large number of wrappers generate tables without column names for human consumption because the meaning of the columns are apparent from the context and easy for humans to understand, but in emerging applications, labels are needed for autonomous assignment and schema mapping where machine try to understand the tables. Autonomous label assignment is critical in volume data processing where ad hoc mediation, extraction and querying is involved. We propose an algorithm Lads for Labeling Anonymous Datasets, which can holistically label tabular web document. The algorithm has been tested on anonymous datasets from a number of sites, e.g music, movie, political, demographic, athletic obtained through different search engines such as Google, Yahoo and MSN. The comparative probabilities of attributes being candidate labels are presented which seem to be very promising, achieved as high as 93% probability of assigning good label to anonymous attribute. To the best of our knowledge, this is the first of its kind for label assignment based on multiple search engines' recommendation.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {63–66},
numpages = {4},
keywords = {ontology, anonymous datasets, html forms, wrapper, hidden web, web data integration},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/3261251,
author = {Wong, Raymond Chi-Wing},
title = {Session Details: Searching, Matching, &amp; Browsing},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3261251},
doi = {10.1145/3261251},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
numpages = {1},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651604,
author = {Motoyama, Marti and Varghese, George},
title = {I Seek You: Searching and Matching Individuals in Social Networks},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651604},
doi = {10.1145/1651587.1651604},
abstract = {The first task any individual faces after joining an online social network (OSN) is locating friends that are present on that particular site. Most OSNs offer some variation of a tool that imports email contact lists to facilitate the task of finding one's friends. However, given that OSNs attempt to reconnect individuals with past acquaintances, one might not have access to the email address for a long lost friend. Furthermore, people tend to utilize a number of aliases online, meaning that an email address cannot always be used to reliably find a friend. Thus, new members must still manually search for friends based on a number of biographical attributes, such as gender, age, hometown, etc. It is not clear, however, what attributes are useful for conducting the search. Even after the search has been performed, the person performing the search might be left with a number of candidate profiles. In this paper, we develop a system for searching and matching individuals in OSNs. We evaluate the efficacy of our person matching techniques by measuring the overlap between social networks, and comparing our results to those published by compete.com. We then look at several interesting properties of overlapping profiles in both networks.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {67–75},
numpages = {9},
keywords = {social networks, crawling, analysis},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651605,
author = {Han, Xianpei and Zhao, Jun},
title = {Web Personal Name Disambiguation Based on Reference Entity Tables Mined from the Web},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651605},
doi = {10.1145/1651587.1651605},
abstract = {Ambiguous personal names are common on the Web, which pose a challenge for many different tasks. The traditional disambiguation employs the clustering methods. However, without reference entity tables, the clustering method can only identify whether two names refer to the same entity, rather than identify which entities they refer to. Furthermore, clustering methods are difficult to achieve robust performance on different names. Some recent disambiguation methods (the link-with-entity-base methods) extract the reference entity tables from online entity bases. The link-with-entity-base methods, however, suffer from the entity base's limited coverage problem, so it can only disambiguate names in a limited coverage.In this paper, to overcome the previous methods' deficiencies, we propose a web-querying method to mine the reference entity tables from the Web automatically with the help of professional category knowledge. Then, we disambiguate personal names by linking them to the personal entities within the mined tables through categorization. The experimental results on the dataset extracted from Freebase show that our web-querying method can effectively mine personal entity with an F-measure 0.90. The disambiguation results on WePS datasets show that our method can achieve more robust and informative performance than the traditional clustering methods; and outperforms the traditional link-with-entity-base methods with a 0.29 improvement in F-measure.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {75–82},
numpages = {8},
keywords = {person resolution, web person search, named entity disambiguation, name disambiguation},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651606,
author = {Asahi, Naoto and Yamamoto, Takehiro and Nakamura, Satoshi and Tanaka, Katsumi},
title = {Finding Intermediate Entity between Two Examples on the Web},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651606},
doi = {10.1145/1651587.1651606},
abstract = {We propose a method for finding an intermediate entity between two examples on the Web. For example, a user wants to find events that occurred between the Battle of Red Cliffs and the death of Cao Cao. In this situation, the user wants to find something intermediate between two events, processes, or objects. We first describe the problem of finding an entity between two examples. We then propose a method for extracting an intermediate entity between two inputs using a Web search engine. The method focuses on the positions of words in Web pages and then extracts words that are likely to appear between the two inputs. Finally, we show the usefulness of our method based on experiments.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {83–87},
numpages = {5},
keywords = {interpolation search, knowledge extraction, intermediate entity, web search},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651607,
author = {Tsatsaronis, George and Varlamis, Iraklis and Stamou, Sofia and N\o{}rv\r{a}g, Kjetil and Vazirgiannis, Michalis},
title = {Semantic Relatedness Hits Bibliographic Data},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651607},
doi = {10.1145/1651587.1651607},
abstract = {In this paper we introduce a novel approach for the thematic organization of bibliographic records that builds upon a semantic relatedness measure we have implemented for this task. In particular, we introduce the Omiotis measure, which captures the semantic relatedness between text segments and enables the thematic organization of the bibliographic data stored in online databases. Experimental evaluation demonstrates that Omiotis can significantly improve the performance of several data mining tasks, such as publications' classification and clustering, compared to existing approaches; even when considering a limited amount of information, i.e., the paper titles.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {87–90},
numpages = {4},
keywords = {bibliographic data management, semantic relatedness},
location = {Hong Kong, China},
series = {WIDM '09}
}

@inproceedings{10.1145/1651587.1651608,
author = {Iwata, Mayu and Arase, Yuki and Hara, Takahiro and Nishio, Shojiro},
title = {Investigation of Children's Characteristics for Web Browsing},
year = {2009},
isbn = {9781605588087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1651587.1651608},
doi = {10.1145/1651587.1651608},
abstract = {Owing to the proliferation of Internet environment, young children have started accessing the Web. However, most existing pages are oriented for grown-ups. Particularly, children are not good at browsing Web pages with full of characters, such as news site. Though such general pages have variety and detailed information than pages for children, children cannot understand their information in a current presentation style. In this paper, we investigate children's characteristics on Web browsing. First, we implemented a Web browser for children, which converts general pages into a children-friendly presentation. Then, we conducted a user experiment to compare our browser with two conventional Web browsers. The result shows that dividing a Web page into contents and showing each of them with animations and changing difficult expressions into easy and friendly ones are effective to keep children's interest and help them to understand the contents.},
booktitle = {Proceedings of the Eleventh International Workshop on Web Information and Data Management},
pages = {91–94},
numpages = {4},
keywords = {bubble metaphor, web browser, children's characteristics},
location = {Hong Kong, China},
series = {WIDM '09}
}

