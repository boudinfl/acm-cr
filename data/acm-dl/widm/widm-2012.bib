@inproceedings{10.1145/2389936.2389938,
author = {Grineva, Maria},
title = {Search beyond the Web: Data from Social Networks and Native Apps},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389938},
doi = {10.1145/2389936.2389938},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {1–2},
numpages = {2},
keywords = {social networks, search, social media, native apps},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389940,
author = {Christiansen, Laura and Schimoler, Thomas and Burke, Robin and Mobasher, Bamshad},
title = {Modeling Topic Trends on the Social Web Using Temporal Signatures},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389940},
doi = {10.1145/2389936.2389940},
abstract = {The Social Web makes visible the ebb and flow of popular interest in topics both newsworthy ("GulfSpill") and trivial ("Lolcat"). Understanding this emergent behavior is a fundamental goal for Social Web research. Key problems include discovering emergent topics from online text sources, modeling burst activity, and predicting the future trajectory of a given topic. Past work has addressed such problems individually for specific applications, but has lacked a generalizable framework for performing both classification and prediction of topic usage. Our approach is to model a topic as a temporally ordered sequence of derived feature states and capture characteristic changes in the topic trend. These sequences are drawn from a dynamic segmentation of frequency data based on change point analysis. We employ Partitioning Around Medoids clustering on these segments to produce signatures which highlight characteristic patterns of usage growth and decay. We demonstrate how this signature model can be used to define distinctive classes of topics in multiple online contexts, including tagging systems and web-based information retrieval. Additionally, we show how the model can predict the general trajectory of interest in a particular topic.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {3–10},
numpages = {8},
keywords = {collaborative tagging, change point analysis, trend detection, social web},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389941,
author = {Ishihara, Yasunori and Hashimoto, Kenji and Shimizu, Shogo and Fujiwara, Toru},
title = {XPath Satisfiability with Downward and Sibling Axes is Tractable under Most of Real-World DTDs},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389941},
doi = {10.1145/2389936.2389941},
abstract = {This paper aims at finding a subclass of DTDs that covers real-world DTDs but still has non-trivial tractability for XPath satisfiability problem. Known subclasses of DTDs, such as duplicate-free DTDs proposed by Montazerian et al. and disjunction-capsuled DTDs and their extension called DC?+-DTDs proposed by Ishihara et al., have tractability against various XPath classes but are somewhat smaller than real-world DTDs. In our examination, 6 out of 27 real-world DTDs are neither duplicate-free nor disjunction-capsuled.This paper proposes a subclass of DTDs, called RW-DTDs, as a model of real-world DTDs. RW-DTDs cover 26 out of the 27 real-world DTDs and 1406 out of the 1407 DTD rules. The idea for assuring the non-trivial tractability under RW-DTDs is twofold. One is to hybridize duplicate-free DTDs and disjunction-capsuled DTDs. In an RW-DTD, each part of the content model of each DTD rule must be either duplicate-free or disjunction-capsuled. Thus, RW-DTDs are a proper superclass of, but expected to inherit the tractability from, the two original classes. The other is to introduce into regular expressions a new operator representing "either or both." The new operator is useful for avoiding tag name duplication and non-capsuled disjunction in content models of DTD rules. Next, this paper shows that under RW-DTDs, XPath satisfiability with child, descendant-or-self, and sibling axes is tractable. Note that under arbitrary DTDs, satisfiability for the same XPath class is known to be NP-complete. Moreover, as non-trivial limitations, this paper also shows that RW-DTDs do not inherit the tractability from the two original classes when the XPath class contains parent axes or qualifiers.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {11–18},
numpages = {8},
keywords = {complexity, xpath, satisfiability},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389942,
author = {Braga, Reinaldo Bezerra and Tahir, Ali and Bertolotto, Michela and Martin, Herv\'{e}},
title = {A Multi-Layer Data Representation of Trajectories in Social Networks Based on Points of Interest},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389942},
doi = {10.1145/2389936.2389942},
abstract = {Social networking, and sophisticated wireless and positioning systems are fast developing and ever increasing technologies. Mobile social applications have the ability to increase the social connectivity by capturing automatically users' daily routines with Global Positioning System (GPS) receivers. These applications allow to record users' trajectories based on daily travel routes as well as to share experiences and interests among friends. However, there is always an increasing demand for providing an easy way to manipulate trajectory data, to generate and compare user profiles. Effective analysis of spatial trajectories has become an essential requirement to explore and understand the behavior of moving objects. In this paper, we highlight the importance of capturing users' daily routines in the form of trajectories in order to strengthen social connectivity. We also present the conceptual approach to multi-layer data representation in order to extract points of interest of correlated trajectories. Finally, we show how the data model could provide mobile social applications with direct support for trajectories at different abstraction levels.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {19–26},
numpages = {8},
keywords = {mobile social application, geographic information system, multi-layer representation},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389943,
author = {Zhong, Ming and Liu, Mengchi},
title = {A Distributed Index for Efficient Parallel Top-k Keyword Search on Massive Graphs},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389943},
doi = {10.1145/2389936.2389943},
abstract = {Recently, a variety of indexing techniques have been proposed for optimizing keyword search on graph. However, graph indexing has very high space and time complexities, and thus these single-machine in-memory indices are usually not affordable for massive graphs. In this paper, we propose a novel distributed disk-based index, which organizes the local topology information in the graph to track and prune matched vertices that will not participate in the top-k answers to a specified query before search with heuristics. The distributed index can be constructed in a MapReduce manner. Moreover, a parallel search algorithm is also developed. It runs multiple asynchronous search instances that incrementally enumerate the current best local answers and then produces the global top-k answers from them. Lastly, we perform experiments on both synthetic and real graphs with various configurations. The results show that our approach can improve search efficiency on massive graphs significantly with affordable indexing overheads.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {27–32},
numpages = {6},
keywords = {parallel algorithm, keyword search, graph, distributed index},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389945,
author = {Li, Hua and Alonso, Rafael},
title = {Managing Analysis Context},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389945},
doi = {10.1145/2389936.2389945},
abstract = {Modern intelligence analysis often involves a complex, iterative, highly branched sequence of information gathering and processing steps. Analysts can benefit greatly from Mind Snaps, semantic bookmarks that would allow them to return to a particular point in the analysis and recreate the complete context they had at that time. This paper addresses some basic issues related to creating and maintaining Mind Snaps. One issue is how frequently we need to take a Mind Snap. Our experiment shows that 10 to 30 analyst events offer 85 percent to 95 percent precision in the ability to distinguish analysts working on different tasks. This translates into an interval for taking Mind Snaps that should be between five to 15 minutes. Another important issue the paper addresses is how to separate actions into multiple micro-contexts in an environment where the analyst often concurrently engages in multiple tasks. The key to this issue is the ability to detect the change in contexts, i.e., context switch. We have developed an algorithm for separating context based on user modeling. Our experiment uses this algorithm to demonstrate the feasibility of capturing and disentangling the analytic micro-contexts. In particular, our results show that context switches can be successfully detected using as few as 10 analysis log event (ALE) windows. Better detection is achieved with larger windows. At a widow size of 30 ALE, we achieved a precision of 73 percent and a recall of 70 percent.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {33–40},
numpages = {8},
keywords = {machine learning, context switch, user modeling, reinforcement, implicit feedback, adaptive information retrieval, virtual interest group, intelligence analysis},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389946,
author = {Hariri, Negar and Mobasher, Bamshad and Burke, Robin},
title = {Using Social Tags to Infer Context in Hybrid Music Recommendation},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389946},
doi = {10.1145/2389936.2389946},
abstract = {Contextual factors can greatly influence users' decisions in selecting items, such as songs when listening to music. The goal of a context-aware recommender system is to adapt its recommendations not just to the general preferences of users, but also to the context in which users are seeking those recommendations. In the domain of music recommendation, the explicit contextual factors and their values might not be known to the system, a priori. Moreover, the contextual state of a user can be dynamic and change during an interaction with the system. In this paper, we present a hybrid context-aware recommender system which infers contextual information from the sequence of songs listened to or specified by a user and uses this information to produce context-aware recommendations. Our system mines popular tags for songs from social media Web sites and uses a topic modeling approach to learn latent topics representing various contexts. We then model each song as a set of latent topics capturing the general characteristics of that song. This representation is used to track and detect changes in user's choice of music, as reflected in a playlist of song sequence, and adjust the recommendations to better meet the current context of the user. Using our approach, the contextual information can be integrated with any traditional recommendation algorithm to produce context-aware recommendations. For our system, we designed and evaluated two hybrid methods. The first hybrid combines collaborative filtering and content-based recommendation techniques, and the second hybrid additionally incorporates information about pairwise song associations. Our evaluation results show that both the hybrid approach and the contextualization can enhance the performance of baseline music recommendation method.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {41–48},
numpages = {8},
keywords = {hybrid recommendation, context-aware recommendation, collaborative filtering, recommender systems},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389947,
author = {Amato, Flora and Chianese, Angelo and Moscato, Vincenzo and Picariello, Antonio and Sperli, Giancarlo},
title = {SNOPS: A Smart Environment for Cultural Heritage Applications},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389947},
doi = {10.1145/2389936.2389947},
abstract = {In this paper, we describe the project SNOPS, a smart-city environment based on Future Internet technologies. We focused on the context-aware recommendation services provided in the platform, which accommodates location dependent multimedia information with user's needs in a mobile environment related to an outdoor scenario within the Cultural Heritage domain. In particular, we describe a recommendation strategy for planning browsing activities exploiting objects features, users' behaviors and context information gathered by apposite sensor networks. Preliminary experimental results, related to user's satisfaction, have been carried out and discussed.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {49–56},
numpages = {8},
keywords = {recommendation systems, knowledge management, internet of things},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389949,
author = {Wu, Jian and Teregowda, Pradeep and Khabsa, Madian and Carman, Stephen and Jordan, Douglas and San Pedro Wandelmer, Jose and Lu, Xin and Mitra, Prasenjit and Giles, C. Lee},
title = {Web Crawler Middleware for Search Engine Digital Libraries: A Case Study for CiteseerX},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389949},
doi = {10.1145/2389936.2389949},
abstract = {Middleware is an important part of many search engine web crawling processes. We developed a middleware, the Crawl Document Importer (CDI), which selectively imports documents and the associated metadata to the digital library CiteSeerX crawl repository and database. This middleware is designed to be extensible as it provides a universal interface to the crawl database. It is designed to support input from multiple open source crawlers and archival formats, e.g., ARC, WARC. It can also import files downloaded via FTP. To use this middleware for another crawler, the user only needs to write a new log parser which returns a resource object with the standard metadata attributes and tells the middleware how to access downloaded files. When importing documents, users can specify document mime types and obtain text extracted from PDF/postscript documents. The middleware can adaptively identify academic research papers based on document context features. We developed a web user interface where the user can submit importing jobs. The middleware package can also work on supplemental jobs related to the crawl database and respository. Though designed for the CiteSeerX search engine, we feel this design would be appropriate for many search engine web crawling systems.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {57–64},
numpages = {8},
keywords = {web crawling, search engine, middleware, information retrieval, ingestion},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389950,
author = {Mohammadzadeh, Hadi and Gottron, Thomas and Schweiggert, Franz and Heyer, Gerhard},
title = {TitleFinder: Extracting the Headline of News Web Pages Based on Cosine Similarity and Overlap Scoring Similarity},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389950},
doi = {10.1145/2389936.2389950},
abstract = {Automatically extracting the headline of online web articles has many applications in web mining and information retrieval. In this paper, we developed a content-based and domain-and language-independent approach, TitleFinder, for unsupervised extraction of the headline of web articles. TitleFinder starts by using a heuristic to select a candidate headline. In a second step the contents of each text fragment in the HTML file are compared to the candidate headline. We implemented four types of similarity for this comparison: two variations of the cosine similarity based on tf and tf-idf weighting schemata, an overlap scoring similarity and an aggregated metric combining the scores of the previous three similarities. Our method achieves high performance in terms of effectiveness and efficiency and outperforms approaches operating on structural and visual features on a test set consisting of 11,218 news web pages from 15 different domains.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {65–72},
numpages = {8},
keywords = {title extraction, cosine similarity, html web pages, overlap scoring similarity, headline extraction, vector space model, information retrieval},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

@inproceedings{10.1145/2389936.2389951,
author = {Bernardi, Mario Luca and Cimitile, Marta and Di Lucca, Giuseppe Antonio and Maggi, Fabrizio M.},
title = {M3D: A Tool for the Model Driven Development of Web Applications},
year = {2012},
isbn = {9781450317207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389936.2389951},
doi = {10.1145/2389936.2389951},
abstract = {Nowadays, Web Applications (WAs) are complex software systems, used by multiple users with different roles and often developed to support and manage business processes. Due to the changing nature of the supported processes, WAs need to be easily and quickly modified, to adapt and align them to the processes they support. In recent years, Model Driven Engineering (MDE) approaches have been proposed and used to develop and evolve WAs. However, the definition of appropriate MDE approaches for the development of flexible process-centric WAs is still limited. In particular, (flexible) workflow models have never been integrated with the models (e.g., presentation, information models) used in MDE approaches to develop this type of applications. In this paper, we present M3D (Model Driven Development with Declare), a tool for developing WAs that integrates three MDE metamodels used to represent the main components of a WA with the metamodel of Declare, a declarative language to model business processes. The tool exploits and combines the declarative nature of Declare and the advantages of MDE to get an efficient roundtrip engineering support to develop and evolve flexible process-centric WAs.},
booktitle = {Proceedings of the Twelfth International Workshop on Web Information and Data Management},
pages = {73–80},
numpages = {8},
keywords = {code generation, domain specific languages, web applications development and evolution, declarative processes, model driven engineering},
location = {Maui, Hawaii, USA},
series = {WIDM '12}
}

