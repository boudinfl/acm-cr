@inproceedings{10.1145/3282894.3282910,
author = {Mai, Christian and Bartsch, Sarah Aragon and Rieger, Lea},
title = {Evaluating Shared Surfaces for Co-Located Mixed-Presence Collaboration},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282910},
doi = {10.1145/3282894.3282910},
abstract = {When wearing a head-mounted display (HMD) in everyday environments, interactions with real world bystanders often fail due to the visual barrier. As a result, the HMD user takes off the headset, which ends the virtual reality (VR) experience. We address this problem by providing a shared surface with the same content for both users, which is located at the same physical position in the real and the virtual world. In a between-subject user study (N = 40), we investigate the effects of a shared surface for short-term collaboration in co-located mixed-presence scenarios. We compare (a) real-world collaboration, (b) having a shared surface only and (c) combining the shared surface with an avatar representation of the real world user in VR. We could show that shared surfaces are helpful for mixed-presence collaboration. Adding an avatar in VR improves performance measures such as task-completion time, error rate and number of clarifying questions. To support future work in this field, we finally propose design implications and research directions.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {1–5},
numpages = {5},
keywords = {Head-Mounted Displays, Collaboration, Mixed-Presence},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282898,
author = {Hoppe, Matthias and Knierim, Pascal and Kosch, Thomas and Funk, Markus and Futami, Lauren and Schneegass, Stefan and Henze, Niels and Schmidt, Albrecht and Machulla, Tonja},
title = {VRHapticDrones: Providing Haptics in Virtual Reality through Quadcopters},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282898},
doi = {10.1145/3282894.3282898},
abstract = {We present VRHapticDrones, a system utilizing quadcopters as levitating haptic feedback proxy. A touchable surface is attached to the side of the quadcopters to provide unintrusive, flexible, and programmable haptic feedback in virtual reality. Since the users' sense of presence in virtual reality is a crucial factor for the overall user experience, our system simulates haptic feedback of virtual objects. Quadcopters are dynamically positioned to provide haptic feedback relative to the physical interaction space of the user. In a first user study, we demonstrate that haptic feedback provided by VRHapticDrones significantly increases users' sense of presence compared to vibrotactile controllers and interactions without additional haptic feedback. In a second user study, we explored the quality of induced feedback regarding the expected feeling of different objects. Results show that VRHapticDrones is best suited to simulate objects that are expected to feel either light-weight or have yielding surfaces. With VRHapticDrones we contribute a solution to provide unintrusive and flexible feedback as well as insights for future VR haptic feedback systems.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {7–18},
numpages = {12},
keywords = {force feedback, virtual reality, haptic feedback, presence, quadcopter, immersion},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282932,
author = {Berger, Laurenz and Wolf, Katrin},
title = {WIM: Fast Locomotion in Virtual Reality with Spatial Orientation Gain &amp; without Motion Sickness},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282932},
doi = {10.1145/3282894.3282932},
abstract = {For locomotion in Virtual Reality (VR), different approaches exist. While continuously moving across the ground through walking techniques or controller input is considered to be most similar compared to the way we move through physical space, this technique causes motion sickness and results in lack of spatial orientation. Teleportation has been shown to result in less motion sickness, while being slower than moving continuously in most virtual environments. World-in-miniature (WIM) allows the user for changing his/her viewpoint through picking and relocating his/her representing icon in a virtual miniature replica of the VR he/she is located in. To see if WIM may be an alternative locomotion technique to continuous motion, we compared the three locomotion techniques contentious motion, teleportation and, WIM (see Fig. 1). We found that WIM outperforms the other two techniques in navigation time for longer distances. Furthermore, it provides best spatial knowledge while causing least motion sickness among the compared methods. We conclude with proposing to provide VR users with a set of locomotion techniques that allows for continuous motion when only moving little, while WIM could be used for moving over longer distances and in environments that are difficult to oversee.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {19–24},
numpages = {6},
keywords = {Locomotion, Motion Sickness, Virtual Reality},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282908,
author = {Felka, Patrick and Sterz, Artur and Keller, Katharina and Freisleben, Bernd and Hinz, Oliver},
title = {The Context Matters: Predicting the Number of In-Game Actions Using Traces of Mobile Augmented Reality Games},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282908},
doi = {10.1145/3282894.3282908},
abstract = {Augmented Reality (AR) is an approach to enrich the real world with additional information. It allows users to interact with virtual objects that are linked to locations in the real world. In the area of mobile computer games, AR is quite demanding for managing resources in communication networks, since in-game points of interest typically lead to high network loads, whereas network utilization is otherwise below the average. Predicting the number of in-game actions of mobile AR games can help to scale the game back-end reasonably without over- or under-provisioning of resources. Context information like weather or available Wi-Fi access points can play a key role in estimating or predicting the number of in-game actions. In this paper, we analyze a comprehensive dataset that contains players' actions of one of the most popular mobile AR games, Ingress. The dataset entails more than 23.9 million player actions over a period of 17 months, as well as additional contextual information. Our analysis shows a highly significant relationship between context factors and in-game actions, which explains large parts of users' behavior in terms of when, where and how often they play the game. By combining four different context factors (i.e., time, user, physical and computing context), our analysis can explain up to 84.44% of the variation in the number of in-game actions.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {25–35},
numpages = {11},
keywords = {Mobile Computing, Augmented Reality, Context Awareness},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282922,
author = {Gatica-Perez, Daniel and Sanchez-Cortes, Dairazalia and Do, Trinh Minh Tri and Jayagopi, Dinesh Babu and Otsuka, Kazuhiro},
title = {Vlogging Over Time: Longitudinal Impressions and Behavior in YouTube},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282922},
doi = {10.1145/3282894.3282922},
abstract = {YouTube vlogging, as a popular genre of ubiquitous social video, engages people in entertainment, civic, and social activities. Although several aspects of vlogging have been studied in media studies and multimedia analysis, the longitudinal angle of vlogging regarding recognition of personal state and trait impressions from behavior has not been yet analyzed. We present a study using behavioral data of vloggers who posted vlogs on YouTube for a period between three and six years. We use online crowdsourcing to collect a rich set of 21 impression variables for each video, including perceived personality, mood, skills, and expertise. Acoustic and motion features are extracted to characterize basic nonverbal behavior. The analysis shows that only a couple of perceived variables, including perceived expertise and perceived quality of audio and video, display weak temporal patterns. Furthermore, we show that the use of longitudinal data helps to improve the automatic inference of impressions for several of the impression variables.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {37–46},
numpages = {10},
keywords = {YouTube, vlog, impressions, behavior, social media},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282899,
author = {Senette, Caterina and Buzzi, Maria Claudia and Paratore, Maria Teresa and Trujillo, Amaury},
title = {Persuasive Design of a Mobile Coaching App to Encourage a Healthy Lifestyle during Menopause},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282899},
doi = {10.1145/3282894.3282899},
abstract = {The menopause transition is associated with physiological changes that increase women's cardiovascular and metabolic risk. Healthier and more conscious behavior in specific areas (diet, physical activity, smoking, etc.) can mitigate this risk. However, in order to modify such behavior, women must be aware of the need to use endogenous and exogenous strategies to improve their lifestyle habits. Despite the explosion of health-related apps, there are currently no innovative examples addressing a self-care approach to menopause by applying personalization, adaptability, and persuasion to induce women to improve their health-related lifestyle. Therefore, this paper describes the theoretical foundations and design phases of a system that coaches women to improve their lifestyle during menopause. To this end, we used a Participatory Design approach involving different groups of women along the different design phases to define the system's user interfaces and interaction mechanisms.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {47–58},
numpages = {12},
keywords = {UIs design, eHealth apps, Participative Design, Mobile, Behavioral change, Persuasive systems, Menopause},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282897,
author = {Haas, Gabriel and Stemasov, Evgeny and Rukzio, Enrico},
title = {Can't You Hear Me? Investigating Personal Soundscape Curation},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282897},
doi = {10.1145/3282894.3282897},
abstract = {Continuous advances in personal audio technology (e.g. headphones), led to efficient noise cancellation and allowed users to build and influence their personal acoustic environment. Despite the high adoption and ubiquitous character of the technology, we do not fully understand which particular factors influence and form usage patterns. As a step towards understanding the usage of personal audio technology, we conducted two focus groups (n=10) to investigate current headphone usage and users' wishes regarding current and future personal audio technology. Based on this data, we derive a model for what we call personal soundscape curation. This model was assessed with the data of a crowdsourced survey on Amazon Mechanical Turk (n=194) on state of the art practices. Personal soundscape curation allows to describe usage strategies (curation, adaptation, renunciation) and break down influencing factors of context and environment as well as illustrate which consequences may arise from the users' behavior.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {59–69},
numpages = {11},
keywords = {Headphones, Soundscapes, Personal Audio, Usage Behavior},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282914,
author = {Nunes, Francisco and Ribeiro, Jorge and Braga, Cristiana and Lopes, Paula},
title = {Supporting the Self-Care Practices of Shift Workers},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282914},
doi = {10.1145/3282894.3282914},
abstract = {Working in shifts can cause great disruption in a person's life, impacting their health, family, and social life. Previous work has raised numerous issues of shift work, but there is little understanding of how workers practically deal with the challenges of shift work. This study investigates how shift workers engage in self-care to avoid health issues and deal with their shifts in practical terms. Findings show that shift workers engage in numerous activities for preparing, managing, and recovering from night shifts. Moreover, we describe the design of a mobile app for shift workers, designed based on the characteristics and self-care practices of shift workers.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {71–81},
numpages = {11},
keywords = {mobile apps, sleep, Shift workers, shift work, self-care technologies, self-care},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282928,
author = {Holl\"{a}nder, Kai and Pfleging, Bastian},
title = {Preparing Drivers for Planned Control Transitions in Automated Cars},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282928},
doi = {10.1145/3282894.3282928},
abstract = {In the near future we expect automated driving to be available for specific segments of a journey, e.g., when driving on the highway. At the end of such a route segment, a (planned) control transition from system to driver occurs. While immediate (unpredictable) take-over situations are heavily investigated, there is still a gap in understanding how to present planned take-over requests, especially while drivers might be involved in non-driving-related activities (NDRAs). We investigated the effect of three different visual representations to indicate planned take-over requests (TOR) on usability, comfort, and driving quality. Additionally, we explored the influences of different NDRAs and the device used for this activity. The results of our simulator study (N=24) indicate that (1) upcoming take-over requests should be displayed dynamically, (2) preferred devices depend on the performed task and (3) take-over requests should be presented with auditory, visual, and tactile cues. Based on our findings, we contribute design recommendations to support the development of safe and comfortable planned control transitions.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {83–92},
numpages = {10},
keywords = {Automated Driving, Non-Driving-Related Activities, Planned Control Transitions, Take-Over Requests},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282911,
author = {Basta, Nardine and ElNahas, Amal and Grossmann, Hans-Peter and Abdennadher, Slim},
title = {Guess Where I Go? A Mobility Predictor for Smart Vehicles},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282911},
doi = {10.1145/3282894.3282911},
abstract = {Ubiquitous computing is the growing trend of establishing a place for technology in the background, rather than the foreground, of our lives through embedding computational capability into everyday objects to make them effectively communicate and perform useful tasks. Hence, the goal of pervasive computing is to make devices "smart". Standing on this ground, the model subject of this work enhances the vehicles intelligence through enabling them to accurately predict the drivers destination without their intervention through an optimized four dimensional destination prediction model. Moreover, it takes the lead in leveraging the semantic properties of both the locations of interest and the social relations affecting the visiting activities of the drivers. In line with this, our proposed model simultaneously utilizes an optimization algorithm to blend the different dimensions and to accommodate the evolving human mobility behavior. The experimental results demonstrate that the optimized model significantly outperforms the basic model achieving an average prediction accuracy of 95% when compared to the real trace. Show the XML Only},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {93–102},
numpages = {10},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282901,
author = {M\"{u}ller, Jonas and Anneser, Christoph and Sandstede, Malte and Rieger, Lea and Alhomssi, Adnan and Schwarzmeier, Felix and Bittner, Bj\"{o}rn and Aslan, Ilhan and Andr\'{e}, Elisabeth},
title = {Honeypot: A Socializing App to Promote Train Commuters' Wellbeing},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282901},
doi = {10.1145/3282894.3282901},
abstract = {The number of commuters has been increasing for many years and the negative effects on wellbeing are therefore affecting more and more people. Following a user centered design process that focuses on known wellbeing determinants, such as relatedness and empathy, we developed the Honeypot socializing app. The app allows commuters to find other travelers to chat with and meet in person to enhance their wellbeing through fostering meaningful and contextual social interactions. First, we describe the development of the idea and the design of the app. Then, we report on a field study with 16 participants, which we carried out on trains. The study results show that the app helps to get in contact with fellow travelers and that it has the potential to promote the wellbeing of commuters in the long term.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {103–108},
numpages = {6},
keywords = {Wellbeing, Positive Computing, Commuting},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282905,
author = {Yadav, Ashish and Arif, Ahmed Sabbir},
title = {Effects of Keyboard Background on Mobile Text Entry},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282905},
doi = {10.1145/3282894.3282905},
abstract = {This paper presents results of a comparative study that investigated the effects of different types of keyboard backgrounds (themes) on actual and perceived text entry performance, in terms of speed and accuracy. Two color and two image backgrounds were compared with the default Google Android keyboard. Results revealed that keyboard background does not affect actual performance, however has a significant effect on perceived performance. Most participants felt that image backgrounds, regardless of whether they were pre or self-selected, affected their speed and accuracy. This suggests that it may be possible to enhance one's text entry experience simply by designing an effective keyboard theme. This paper concludes with reflections on how these findings could benefit text entry researchers and keyboard developers.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {109–114},
numpages = {6},
keywords = {Text entry, background, mobile, color, virtual keyboard, smartphone, Qwerty, theme, touchscreen},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282903,
author = {Rothe, Sylvia and Althammer, Felix and Khamis, Mohamed},
title = {GazeRecall: Using Gaze Direction to Increase Recall of Details in Cinematic Virtual Reality},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282903},
doi = {10.1145/3282894.3282903},
abstract = {In this work, we show how the use of flickering in Cinematic Virtual Reality (CVR) content can not only guide the user's attention, but also significantly improve recall of details. The findings are particularly useful for practitioners who generate educational and corporate training content, as well as for directors of CVR videos who want to draw the user's attention to certain details in movies or virtual tours. We report on a between-subjects user study, in which we experimented with flickering methods to increase user's recall of certain details in CVR videos. Participants had to report details of objects on which the method was applied. In our experiments, the intensive flicker improved the recall of details significantly. We discuss how the studied methods can improve recall of details in different use cases.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {115–119},
numpages = {5},
keywords = {Cinematic Virtual Reality, omnidirectional guiding attention, 360° movie, Subtle Gaze Direction},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282925,
author = {Muralidhar, Skanda and Siegfried, R\'{e}my and Odobez, Jean-Marc and Gatica-Perez, Daniel},
title = {Facing Employers and Customers: What Do Gaze and Expressions Tell About Soft Skills?},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282925},
doi = {10.1145/3282894.3282925},
abstract = {Eye gaze and facial expressions are central to face-to-face social interactions. These behavioral cues and their connections to first impressions have been widely studied in psychology and computing literature, but limited to a single situation. Utilizing ubiquitous multimodal sensors coupled with advances in computer vision and machine learning, we investigate the connections between these behavioral cues and perceived soft skills in two diverse workplace situations (job interviews and reception desk). Pearson's correlation analysis shows a moderate connection between certain facial expressions, eye gaze cues and perceived soft skills in job interviews (r ϵ [-30,30]) and desk (r ϵ [20,36]) situations. Results of our computational framework to infer perceived soft skills indicates a low predictive power of eye gaze, facial expressions, and their combination in both interviews (R2 ϵ [0.02,0.21]) and desk (R2 ϵ [0.05,0.15]) situations. Our work has important implications for employee training and behavioral feedback systems.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {121–126},
numpages = {6},
keywords = {First impressions, job performance, hirability, eye gaze, social computing, hospitality, multimodal interaction, facial expressions},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282896,
author = {Rothe, Sylvia and H\"{o}llerer, Tobias and Hu\ss{}mann, Heinrich},
title = {CVR-Analyzer: A Tool for Analyzing Cinematic Virtual Reality Viewing Patterns},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282896},
doi = {10.1145/3282894.3282896},
abstract = {Cinematic Virtual Reality has been increasing in popularity over the last years. Watching omnidirectional movies with head mounted displays, viewers can freely choose the direction of view, and thus the visible section of the movie. In order to explore the users' viewing behavior, methods are needed for collecting and analyzing data. We developed an analyzing tool, the CVR-Analyzer, which can be used for inspecting head pose and eye tracking data of viewers experiencing CVR movies. The visualized data are displayed on a flattened projection of the movie as flexibly controlled augmenting annotations, such as tracks or heatmaps, synchronously with the time code of the movie and allow inspecting and comparing the users' viewing behavior in different use cases.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {127–137},
numpages = {11},
keywords = {head pose, omnidirectional movie, eye tracking, heatmaps, 360° movie, Cinematic Virtual Reality},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282913,
author = {Drewes, Heiko and Khamis, Mohamed and Alt, Florian},
title = {Smooth Pursuit Target Speeds and Trajectories},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282913},
doi = {10.1145/3282894.3282913},
abstract = {In this paper we present an investigation of how the speed and trajectory of smooth pursuits targets impact on detection rates in gaze interfaces. Previous work optimized these values for the specific application for which smooth pursuit eye movements were employed. However, this may not always be possible. For example UI designers may want to minimize distraction caused by the stimulus, integrate it with a certain UI element (e.g., a button), or limit it to a certain area of the screen. In these cases an in-depth understanding of the interplay between speed, trajectory, and accuracy is required. To achieve this, we conducted a user study with 15 participants who had to follow targets with different speeds and on different trajectories using their gaze. We evaluated the data with respect to detectability. As a result, we obtained reasonable ranges for target speeds and demonstrate the effects of trajectory shapes. We show that slow moving targets are hard to detect by correlation and that introducing a delay improves the detection rate for fast moving targets. Our research is complemented by design rules which enable designers to implement better pursuit detectors and pursuit-based user interfaces.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {139–146},
numpages = {8},
keywords = {pursuit detection, Eye tracking, trajectories, smooth pursuits},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282919,
author = {Saad, Alia and Chukwu, Michael and Schneegass, Stefan},
title = {Communicating Shoulder Surfing Attacks to Users},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282919},
doi = {10.1145/3282894.3282919},
abstract = {Since mobile interaction takes place in almost every context, shoulder surfing attacks are becoming more and more a threat to user's privacy. While several approaches exist to prevent these attacks for the authentication process, protecting the actual interaction has not yet been in the main focus of research. In this work, we present the concept of communicating shoulder surfing attacks to the user. This should create awareness on the user side and help preventing this type of privacy invasion. We present out shoulder surfer detection mobile application, called DSSytem, and report on a focus group that helped to design this system. We also report on the results of a user study in which we compare four different notification methods, namely, vibro-tactile, front LED, on-screen icon, and video preview feedback. Vibro-tactile feedback results in the lowest reaction time of the participants and is also favoured throughout the follow-up semi-structured interviews.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {147–152},
numpages = {6},
keywords = {Notification, Usable Security and Privacy, Shoulder Surfing},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282923,
author = {Mecke, Lukas and Pfeuffer, Ken and Prange, Sarah and Alt, Florian},
title = {Open Sesame! User Perception of Physical, Biometric, and Behavioural Authentication Concepts to Open Doors},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282923},
doi = {10.1145/3282894.3282923},
abstract = {In usable security (e.g., smartphone authentication), a lot of emphasis is put on low-effort authentication and access concepts. Yet, only very few approaches exist where such concepts are applied beyond digital devices. We investigate and explore seamless authentication systems at doors, where most currently used systems for seamless access rely on the use of tokens. In a Wizard-of-Oz study, we investigate three different authentication schemes, namely (1) key, (2) palm vein scanner and (3) gait-based authentication (compare Fig. 1). Most participants in our study (N=15) preferred the palm vein scanner, while ranking unlocking with a key and gait-based recognition second and third. Our results propose that recovery costs for a failed authentication attempt have an impact on user perception. Furthermore, while the participants appreciated seamless authentication via biometrics, they also valued the control they gain from the possession of a physical token.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {153–159},
numpages = {7},
keywords = {(Behavioural) Biometrics, Wizard-of-Oz, Authentication, User Perception},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282931,
author = {AlJarrah, Abeer and Shehab, Mohamed},
title = {CordovaConfig: A Tool for Mobile Hybrid Apps' Configuration},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282931},
doi = {10.1145/3282894.3282931},
abstract = {Despite their recentness, hybrid mobile apps have established an increasing share in the mobile apps market. This can be attributed to the fact that these apps offer the balance between providing full functionality at an affordable development cost. Hybrid mobile apps are web apps hosted in a thin native container. Several libraries facilitate building hybrid apps by providing interfaces through which native phone resources can be accessed using Javascript code. Configuring mobile hybrid apps properly is an important but often neglected activity. Coarse-grained configurations and risky default settings result in several privacy and security breaches. Moreover, middleware libraries provide a basic interface to the developers which may drive them off from changing the default settings. We are seeking to provide an automated, interactive, and contextual support for configuring hybrid apps. In this paper, we present a tool prototype, CordovaConfig, which provides fine-grained configurations that are aligned with the app's behavior. We evaluate the potential use and effectiveness of CordovaConfig on 22 students. Our results demonstrate that interactive configuration support can (1) help address this important non-functional requirement early in the development cycle (2) increase programmers awareness in potential risks associated with insecure settings (3) increase developers understanding of configuration items. This is supported by a quantitative and qualitative evaluation. We also uncover common programmers practices and perceptions of hybrid apps security &amp; configurations},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {161–170},
numpages = {10},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282902,
author = {Klinkhammer, Daniel and Mateescu, Magdalena and Zahn, Carmen and Reiterer, Harald},
title = {Mine, Yours, Ours: Coordination through Workspace Arrangements and Territoriality in Tabletop Interaction},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282902},
doi = {10.1145/3282894.3282902},
abstract = {Previous research shows that territories help people coordinate their task and social interaction at large interactive tabletops. However, little is known about the interplay between territorially and the reorientation of digital objects and their influence on task performance. In this paper, we advance the hypothesis that territories are states of spatial arrangements continually changing during the collaborative activity and seek to better understand their role as a main mechanism in coordinating group activities. We report results from an explorative tabletop study that compares two types of technical settings workspaces supporting a brainstorming task. Our results show evidence of different territorial strategies dependent on the two conditions. We discuss the role of territoriality and orientation of digital notes as a mechanism for coordinating group activity and their influence on task performance and outcome. Finally, we present design recommendations derived from our findings.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {171–182},
numpages = {12},
keywords = {personal space, social interaction, Tabletop, collaboration, territoriality, tablet},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282906,
author = {Aslan, Ilhan and Bittner, Bj\"{o}rn and M\"{u}ller, Florian and Andr\'{e}, Elisabeth},
title = {Exploring the User Experience of Proxemic Hand and Pen Input Above and Aside a Drawing Screen},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282906},
doi = {10.1145/3282894.3282906},
abstract = {Digital drawing experiences are not only fused by the flexibility of digital materials but also influenced by the availability of interaction space. In this paper, we first present a prototype, which implements a method to turn the (mid-air) space above and aside a drawing screen in a desktop setting dynamically into sensory space for gestural and spatial input. Then we report on a user study exploring how participants experience digital drawing when the additional interaction space above and aside a screen is exploited for exemplary proxemic input techniques for zooming and panning a drawing. Our results show that the new multimodal input techniques are perceived as significantly more attractive than a baseline drawing condition which only utilizes touch based input. We conclude by discussing implications and limitations of our findings and input above and aside a drawing screen in general.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {183–192},
numpages = {10},
keywords = {Proxemic Input, Bi-manual, User Experience, Pen and Mid-air Gestures, Interaction Technique},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282916,
author = {Hild\'{e}n, Elina and V\"{a}\"{a}n\"{a}nen, Kaisa and Chistov, Pavel},
title = {Travel Experience Toolkit: Bus-Specific Tools for Digital Service Design},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282916},
doi = {10.1145/3282894.3282916},
abstract = {To design desirable digital services for public transportation, passengers' needs and expectations should be considered. This paper presents a novel bus-specific Travel Experience Toolkit to support the design of digital traveling services in the context of intra-city bus transportation. The toolkit is structured in three areas of user experience, or travel experience: user (passenger), context (bus) and system (public transportation). The initial toolkit includes three tools derived from the findings of our qualitative passenger studies conducted in Finland using interviews, co-design workshops, and the diary method. The tools are: Bus Passenger Personas, a card-based design tool Context Cards, and Passenger Journey Map. With the help of the Travel Experience Toolkit, digital services can be developed with a focus on passengers' needs, improving the bus travel experience and thus enhancing the desirability of public transportation. We evaluated the tools with software developers and present the key findings.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {193–197},
numpages = {5},
keywords = {Bus, public transportation, design tool, travel experience, toolkit},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282912,
author = {H\"{a}kkil\"{a}, Jonna and Forsman, Meri-Tuulia and Colley, Ashley},
title = {Navigating the Graveyard: Designing Technology for Deathscapes},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282912},
doi = {10.1145/3282894.3282912},
abstract = {In this paper, we consider graveyards as a design context, and present a prototype graveyard-navigator mobile application. The app enables search and navigation to particular graves and provides information on family connections between the buried. We evaluate the application, and chart general perceptions of technology use in graveyards through in situ interviews in a graveyard (n=12). Our findings reveal that navigating in a graveyard with the mobile application was found both useful and acceptable, whereas visualizing family trees was perceived with mixed feelings, due to privacy concerns. The perceptions of technology use in the graveyard emphasized the importance of unobtrusiveness and respect for the peace and privacy of other visitors, as well as for the context.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {199–204},
numpages = {6},
keywords = {mobile application, designing for sensitive contexts, deathscapes, experience design, death, user study, unobtrusive interaction, cemetery, Graveyards},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282915,
author = {de Assuncao, Willian Garcias and de Almeida Neris, Vania Paula},
title = {An Algorithm for Music Recommendation Based on the User's Musical Preferences and Desired Emotions},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282915},
doi = {10.1145/3282894.3282915},
abstract = {Studies show that music is an effective form of emotional induction and can change the emotional behavior of the user. In view of this, this article seeks to create a "selection" algorithm that includes a subset of songs chosen by the user, while taking account of their current emotional state and allowing them to achieve the emotional state that is desired. In carrying out the experiment, we established the current emotional state, the desired emotional state and 20 suggestions of musical items from a sample of 20 users. With the aim of achieving the desired emotional state, the proposed algorithm returned a new list of musical items for each participant. The participants underwent an evaluation during and after playing the music to assess the effectiveness of the returned list. The results suggest that when listening to the songs selected by the algorithm, the user can approach the desired emotional state.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {205–213},
numpages = {9},
keywords = {Music recommendation, Affective computing, Emotion recognition, Music information retrieval, User experience},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282930,
author = {Salah, Jailan and Abdelrahman, Yomna and Dakrouni, Ahmed and Abdennadher, Slim},
title = {Judged by the Cover: Investigating the Effect of Adaptive Game Interface on the Learning Experience},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282930},
doi = {10.1145/3282894.3282930},
abstract = {Adaptive educational games have shown potential in enhancing the learning experience in educational setups. Most of the conducted research used the content and level of difficulty as the adaptive aspect. However, in this work we aim to evaluate the effect of changing the game interface including; background music and color as well as dynamics represented by the timer and scoring technique. We built adaptive educational games using subjective measures, where the adaptive features are manipulated based on reported emotions by the participants. We conducted a between subject study with 30 participants using adaptive and non-adaptive version of the game to assess the effectiveness of the proposed adaptive aspects on the learning experience, namely, learning gain and the engagement level. Our findings showed a significant increase in the learning gain and the engagement level of the participants who used the adaptive version of the system over the other. Finally, we discuss the implication of our findings and potential added value of our findings.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {215–225},
numpages = {11},
keywords = {Subjective Measurements, Education, Adaptive},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282927,
author = {Pouke, Matti and Ylipulli, Johanna and Minyaev, Ilya and Pakanen, Minna and Alavesa, Paula and Alatalo, Toni and Ojala, Timo},
title = {Virtual Library: Blending Mirror and Fantasy Layers into a VR Interface for a Public Library},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282927},
doi = {10.1145/3282894.3282927},
abstract = {We present an immersive VR interface for a public library where a mirror-world like virtual copy of the physical library is blended with imaginary virtual fantasy layers into a hybrid space for library content. The design of the system was guided by multi-stakeholder Participatory Design process involving library staff, library customers and researchers. The findings of the qualitative user evaluation of the prototype suggest that this kind of a VR interface is an exciting extension to a physical library, indicating the unlimited possibilities offered by the VR's ability to send the user into imaginary places.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {227–231},
numpages = {5},
keywords = {participatory design, Mirror world, digital library services, fantasy worlds, hybrid space},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282926,
author = {Schneegass, Christina and Terzimehi\'{c}, Naundefineda and Nettah, Mariam and Schneegass, Stefan},
title = {Informing the Design of User-Adaptive Mobile Language Learning Applications},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282926},
doi = {10.1145/3282894.3282926},
abstract = {Smartphones enable people to learn new languages whenever and wherever they want. This popularized mobile language learning apps (MLLAs) and in particular micro learning that offers simple and short learning units to keep the user on track. Due to the ubiquitous use of these applications, they have to adapt to the users' current situation to provide an optimal learning experience. To gain insights into how users perceive common usage scenarios, we conducted an online survey (N=74) and clustered all described learning scenarios into five categories of usage situations. We outlined internal and contextual factors which are characteristic for these situations and discussed those in a follow-up focus group with HCI experts (N=4). During this focus group, we collected four design recommendations to adapt MLLAs to situations of users' (a) high attention levels, (b) tiredness or exhaustion, (c) highly demanding environments, or (d) low motivation.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {233–238},
numpages = {6},
keywords = {Context-aware Learning, User Adaption, Mobile Learning, Cognition-aware Learning},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282917,
author = {Dingler, Tilman and Tag, Benjamin and Lehrer, Sabrina and Schmidt, Albrecht},
title = {Reading Scheduler: Proactive Recommendations to Help Users Cope with Their Daily Reading Volume},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282917},
doi = {10.1145/3282894.3282917},
abstract = {To help deal with daily reading volumes, we present Reading Scheduler, a smartphone application linked to people's reading list, which triggers reading reminders throughout the day. The app suggests articles according to their length, complexity, and the time available for reading as indicated by the user. In a field study, we collected usage data from ten participants over the course of two weeks. During this time, we recorded mobile sensor data and trained a classifier to detect opportune moments for reading. Participants read 182 articles while we collected 787,752 sensor data points. Together with an assessment of the feasibility of proactive reading suggestions, we present a prediction model with close to 73% accuracy, that can be used to build mobile recommender systems for utilizing idle moments for reading throughout the user's day.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {239–244},
numpages = {6},
keywords = {Reading Scheduler, Reading Context, Mobile Reading},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282920,
author = {Abdelrahman, Yomna and Wozniak, Pawel and Knierim, Pascal and Henze, Niels and Schmidt, Albrecht},
title = {Exploration of Alternative Vision Modes Using Depth and Thermal Cameras},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282920},
doi = {10.1145/3282894.3282920},
abstract = {Human vision is limited to a small band of the electromagnetic spectrum. It has been shown that extending visual perception can be beneficial, but it is unclear if this is useful for a broader range of applications. In this paper, we explore user reactions to extended visual perception. We describe the design and implementation of TriSight, a head-mounted display that allows the user to perceive the environment in the visual spectrum, the thermal spectrum, and through depth maps. In a study, we asked participants to perform everyday tasks in a created home, kitchen, office and basement with TriSight. Through analyzing videos, interviews, questionnaires and logs we chart the users' feedback towards the augmented visual perception. Our findings, imply the positive impact of extended vision, as well as the potential of thermal vision as alternative perception mode in performing daily tasks. Finally, we discuss the implications for designing devices that extend human's visual perception beyond the visual spectrum.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {245–252},
numpages = {8},
keywords = {Amplified Vision, Head Mounted Displays, Depth Sensor, Thermal Imaging},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282929,
author = {Miazi, Nazmus Sakib and Castro, Carlos Alberto Campos and Shehab, Mohamed},
title = {Mobile Users as Advertisers: User Perceptions of Product Sensitivity, Exposure, and Public Influence},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282929},
doi = {10.1145/3282894.3282929},
abstract = {Today mobile marketing is booming at an exponential rate with the increased use of smartphones and other mobile devices. Smartphones provide ubiquitous access to digital information anywhere, anytime, thus enabling the marketers to reach customers more directly, and engagingly. A scalable amalgamation of cellular networks, WiFi, and BLE Beacons enable us to formulate a new mode of advertising, where we can employ mobile users as live and localized advertisers. That means a user can potentially be an advertiser for a company using smartphones by creating an ad and broadcasting it to people around them. Implementation of this idea integrates Consumer Generated Advertising (CGA), as the users actively customize the ads. In this paper, we explore the user's perception toward sharing personal information along with the ads they advertise. We tested our hypothesis by conducting a user study that investigates two key factors: the sensitivity level of the product, and the exposure level to the public. Also, we analyzed the effect of the public influence on the consumers' minds. Our result shows that people share more information with not-sensitive products than they share with sensitive products. We found several factors that can be utilized to conduct our future studies.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {253–264},
numpages = {12},
keywords = {Mobile CGA, Privacy, Beacons, Users-as-Beacons},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282900,
author = {Salah, Jailan and Abdelrahman, Yomna and Abdrabou, Yasmeen and Kassem, Khaled and Abdennadher, Slim},
title = {Exploring the Usage of Commercial Bio-Sensors for Multitasking Detection},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282900},
doi = {10.1145/3282894.3282900},
abstract = {Most of the current adaptive systems support single task activities. The rise in the number of daily interactive devices and sources of information made multitasking an integral activity in our daily life. Affect-aware systems show exciting potential to support the user, however, they focus on the induced effect of an additional task in terms of cognitive load and stress, rather than the influence of the number of tasks i.e. multitasking. This paper presents indicators of the number of tasks being performed by the user using a set of bio-sensors. A preliminary user study was conducted with two follow-up explorations. Our findings imply that we can distinguish between the number of tasks performed based on high-end as well as cheap Heart Rate sensors. Additionally, tasks number correlates with other signals, namely wrist and forehead temperature. We provide empirical evidence showing how to differentiate between single- and dual-tasking activities.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {265–277},
numpages = {13},
keywords = {Multitasking, Affective Computing, Galvanic Skin Conductance, Thermal Imaging, Heart Rate},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282924,
author = {Prange, Sarah and Buschek, Daniel and Alt, Florian},
title = {An Exploratory Study on Correlations of Hand Size and Mobile Touch Interactions},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282924},
doi = {10.1145/3282894.3282924},
abstract = {We report on an exploratory study investigating the relationship of users' hand sizes and aspects of their mobile touch interactions. Estimating hand size from interaction could inform, for example, UI adaptation, occlusion-aware UIs, and biometrics. We recorded touch data from 62 participants performing six touch tasks on a smartphone. Our results reveal considerable correlations between hand size and aspects of touch interaction, both for tasks with unrestricted "natural" postures and restricted hand locations. We discuss implications for applications and ideas for future work.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {279–283},
numpages = {5},
keywords = {Correlation, Touch, Swiping, Scrolling, Hand Size, Targeting},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282907,
author = {Rzayev, Rufat and Dingler, Tilman and Henze, Niels},
title = {ReflectiveDiary: Fostering Human Memory through Activity Summaries Created from Implicit Data Collection},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282907},
doi = {10.1145/3282894.3282907},
abstract = {Reflecting on previous activities can improve episodic memory and well-being. While manually recording activities and experiences is not always feasible, there is a range of mobile sensors that allow implicit recording of users' lives. In this work, we investigate how reflection on daily summaries created from implicitly collected data improves episodic memory. Therefore, we built ReflectiveDiary, an Android application that collects personal data streams to create daily summaries automatically. Over the course of 16 days, we collected data from 11 participants using information, such as calls, messages, and calendar data to help people recollect their activities. By comparing reflected with non-reflected days, we show that reflecting on implicitly collected data improves remembering of events and their surrounding details. We further present an analysis of different types of memory cues and their usefulness to inform the design of reflective tools that help people to improve their episodic memory.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {285–291},
numpages = {7},
keywords = {Human memory, recognition, recording, reflection},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282895,
author = {Huebner, Johannes and Frey, Remo Manuel and Ammendola, Christian and Fleisch, Elgar and Ilic, Alexander},
title = {What People Like in Mobile Finance Apps: An Analysis of User Reviews},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282895},
doi = {10.1145/3282894.3282895},
abstract = {Even though app store reviews provide highly valuable information on how people use mobile apps and what they expect from them, the systematic, timely analysis of an ever-growing volume of such unstructured reviews across many apps remains a challenge. We analyzed more than 300'000 review sentences belonging to 1'610 finance apps using a machine learning-based approach to investigate the impact that different aspects of finance apps have on their ratings. Additionally, we manually categorized all apps into sub-categories such as payment or trading apps to discuss our findings on an extra level of detail. This work illustrates how different aspects of mobiles apps affect their ratings, how this varies across sub-categories, and discusses the role of privacy, user interfaces, signup experiences, notifications, when the use of location services may be appropriate, and other aspects of mobile finance apps, to provide detailed insights into users' expectations and perception of finance apps.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {293–304},
numpages = {12},
keywords = {machine learning, App store reviews, mobile finance apps},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282921,
author = {Ballantyne, Mars and Jha, Archit and Jacobsen, Anna and Hawker, J. Scott and El-Glaly, Yasmine N.},
title = {Study of Accessibility Guidelines of Mobile Applications},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282921},
doi = {10.1145/3282894.3282921},
abstract = {With the increased ubiquity of mobile devices around the world, it is imperative to ensure that these devices and their applications (apps) are accessible to users with disabilities. Although design style guides are undergoing a paradigm shift with the promotion of 'mobile-first' ideology, we have yet to witness a concrete step being taken towards the establishment of universal guidelines for mobile app accessibility. To address this issue, we compile an exhaustive list of guidelines to gauge mobile app accessibility. We present a mobile-specific framework to categorize the guidelines. We then underline the importance of these clearly defined guidelines by putting the most popular 25 apps from the Google Play Store under their lens. The results indicate low rates of violations of accessibility guidelines at the system level, and a high rate of violations at design and content levels. We highlight the most and the least violated guidelines. We discuss in detail the overall accessibility of evaluated apps and identified patterns in violations of established rules.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {305–315},
numpages = {11},
keywords = {mobile, people with disabilities, evaluation, heuristics, Accessibility, applications},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282904,
author = {Schuhmacher, Lisa and Pagenkopf, Anne and Lingamaneni, Ragavendra and Scheible, J\"{u}rgen},
title = {Emotion Enhancement through Ubiquitous Media Technology in a Smart Kitchen Environment},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282904},
doi = {10.1145/3282894.3282904},
abstract = {Today, Human Computer Interaction is increasingly shifting from 'information worlds' towards 'experience worlds'. Still, much research of smart environment technologies focuses merely on functional aspects. This paper recognizes the relevance of smart environment technologies on emotional experiences. We developed a ubiquitous media technology in a smart kitchen environment to enhance the user's emotions: A touch and voice controlled Visual Atmosphere App (VAA) that can change kitchen ambience through different atmospheric themes by using visual projection on the kitchen surfaces and sound effects. In a quantitative and qualitative laboratory user study (N=30) we measured the impact of the VAA on the user's emotional state. Our findings show that this ubiquitous media technology in a smart environment can have a significant (p&lt;0.05) effect on emotion enhancement. This result is even stronger if the smart environment fits the user's personal preferences. This study is a step towards emotional experiences caused by smart environment technologies to foster desired psychological states.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {317–325},
numpages = {9},
keywords = {Smart Environment, User Experience, Emotional Experience, Human Computer Interaction, Smart Kitchen, Emotion Enhancement},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282909,
author = {H\"{a}kkil\"{a}, Jonna and Li, Hong and Koskinen, Saara and Colley, Ashley},
title = {Connected Candles as Peripheral Emotional User Interface},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282909},
doi = {10.1145/3282894.3282909},
abstract = {We present Connected Candles, a peripheral aesthetic display for creating awareness and connecting people in long distance relationships (LDRs). The system consists of a pair of candle stands, which each include two candles, one being a real candle and the other electronic. The candle stands are placed at different locations, and are connected over the Internet such that lighting the real candle illuminates the electronic candle at the distant location. We present the concept's design, prototype, and its evaluation in a focus group based user study. Our findings illustrate the potential for using candles as a peripheral user interface to mediate emotional communication between couples in long-distance relationships.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {327–333},
numpages = {7},
keywords = {peripheral displays, fire, Emotional communication, long-distance relationships, candles, tangible user interfaces, LDR, materiality, ephemeral user interfaces, user experience, ambient communication},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3282918,
author = {M\"{u}ller, Niklas and Eska, Bettina and Sch\"{a}ffer, Richard and V\"{o}lkel, Sarah Theres and Braun, Michael and Wiegand, Gesa and Alt, Florian},
title = {Arch'n'Smile: A Jump'n'Run Game Using Facial Expression Recognition Control For Entertaining Children During Car Journeys},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3282918},
doi = {10.1145/3282894.3282918},
abstract = {Children can be a distraction to the driver during a car ride. With our work, we try to combine the possibility of facial expression recognition in the car with a game for children. The goal is that the parents can focus on the driving task while the child is busy and entertained. We conducted a study with children and parents in a real driving situation. It turned out that children can handle and enjoy games with facial recognition controls, which leads us to the conclusion that face recognition in the car as a entertaining system for children should be developed further to exploit its full potential.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {335–339},
numpages = {5},
keywords = {Children, Facial Expression, Driving, Distraction, Entertainment, Game, Face Recognition},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289724,
author = {Kimura, Risa and Nakajima, Tatsuo},
title = {Sharing Collective Human's Eye Views for Stimulating Reflective Thinking},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289724},
doi = {10.1145/3282894.3289724},
abstract = {Our daily lives are becoming increasingly complex. We sometimes tend to forget what is essential in our daily lives. In the near future, wearable devices such as smart eyeglasses will have cameras, so people's eye views captured by the cameras of the devices may be shared with other people. Our approach projects collective human's eye views in a virtual reality space that can easily be used in our daily lives to help people reflect various issues in the world. To explore our approach, we built an initial prototype system and conducted a preliminary user study to investigate some future challenges of the currently developed prototype system.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {341–349},
numpages = {9},
keywords = {Research through Design, Virtual Reality, Collective Human Eye Views, Reflective Thinking, Eye Gaze-based Gesture, Sharing Economy},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289725,
author = {Abdrabou, Yasmeen and Mourad, Nadeen and Elmougy, Amr},
title = {Exploring the Scalability of Behavioral Mid-Air Gestures Authentication},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289725},
doi = {10.1145/3282894.3289725},
abstract = {Gesture-based authentication systems are gaining increasing attention from the research community due to their promising usability. However, the scalability of these systems has not been properly investigated against the number of users and the number of gestures. Accordingly, in this paper, we explore the scalability of mid-air gesture-based systems in both aforementioned dimensions to enhance the already existing systems. We implemented a gesture-based authentication model with 20 gestures and we invited 39 users for data collection. A Support Vector Machine (SVM) classifier with Grid search cross-validation was used for training to prove the concept of the model's prototype. The obtained results proved that with the upscaling of the system from the aspect of the number of users, performance gets worse. On the other hand, as gestures introduced to the system increases, the performance improves.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {351–357},
numpages = {7},
keywords = {Gestures, User Identification, User Authentication, Behavioral biometrics},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289726,
author = {Ahlstr\"{o}m, David and Hasan, Khalad and Lank, Edward and Liang, Robert},
title = {TiltCrown: Extending Input on a Smartwatch with a Tiltable Digital Crown},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289726},
doi = {10.1145/3282894.3289726},
abstract = {Many smartwatches have a digital crown as a complementary input modality to the touchscreen. While the crown eliminates issues of touchscreen occlusion and imprecision, i.e., the 'fat-finger' problem, the crown input is limited as it only supports bi-directional rotations along a single dimension. We present TiltCrown, a crown prototype that increases a smartwatch's input bandwidth through an isometric joystick. TiltCrown supports angular tilt, rotations and button press events for touchless smartwatch interaction. In a user study we explore how accurate and how fast users can perform item selection tasks using TiltCrown.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {359–366},
numpages = {8},
keywords = {Radial Interfaces, Isometric Joystick, Item Selection, Smartwatches, Digital Crowns},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289727,
author = {Santos, Pedro Albuquerque and Madeira, Rui Neves and Correia, Nuno},
title = {Designing a Framework to Support the Development of Smart Cross-Device Applications},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289727},
doi = {10.1145/3282894.3289727},
abstract = {We live surrounded by computing devices, but applications are mostly confined to run on a single device. It should be possible to make better use of the multiple devices around us by coming up with ways of integrating and combining them, while leveraging the specific strengths of some devices and minimizing the individual weaknesses of others. We want to explore the possibility of building applications that have their user interface seamlessly distributed across co-located devices. We created the YanuX Framework to provide the guidelines and tools needed by developers to build those applications. This paper presents the framework and its architecture, which is outlined along with the description of its components. We end by presenting an early evaluation of YanuX and by discussing the status of our work along with directions for further research.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {367–374},
numpages = {8},
keywords = {Framework, cross-device applications, proxemics},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289728,
author = {Nakatani, Tomoya and Kuga, Ryohei and Maekawa, Takuya},
title = {Preliminary Investigation of Object-Based Activity Recognition Using Egocentric Video Based on Web Knowledge},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289728},
doi = {10.1145/3282894.3289728},
abstract = {This study shows a preliminary investigation of daily activity recognition based on a wearable camera without using training data prepared by a user in her environment. Recently, deep learning frameworks have been publicly available, and we can now easily use deep convolutional neural networks (CNNs) pre-trained on a large image data set. In our method, we first detect objects used in the user's activity from her first-person images using a pre-trained CNN for object recognition. We then estimate an activity of the user using the object detection result because objects used in an activity strongly relate to the activity. To estimate the activity without using training data, we utilize knowledge on the Web because the Web is a repository of knowledge that reflects real-world events and common sense. Specifically, we compute semantic similarity between a list of the detected object names and a name of each activity class based on the Web knowledge. The activity class with the largest similarity value is the estimated activity of the user.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {375–381},
numpages = {7},
keywords = {Activity recognition, object detection, egocentric video},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289729,
author = {Braun, Michael and V\"{o}lkel, Sarah Theres and Wiegand, Gesa and Puls, Thomas and Steidl, Daniel and Wei\ss{}, Yannick and Alt, Florian},
title = {The Smile is The New Like: Controlling Music with Facial Expressions to Minimize Driver Distraction},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289729},
doi = {10.1145/3282894.3289729},
abstract = {The control of user interfaces while driving is a textbook example for driver distraction. Modern in-car interfaces are growing in complexity and visual demand, yet they need to stay simple enough to handle while driving. One common approach to solve this problem are multimodal interfaces, incorporating e.g. touch, speech, and mid-air gestures for the control of distinct features. This allows for an optimization of used cognitive resources and can relieve the driver of potential overload. We introduce a novel modality for in-car interaction: our system allows drivers to use facial expressions to control a music player.The results of a user study show that both implicit emotion recognition and explicit facial expressions are applicable for music control in cars. Subconscious emotion recognition could decrease distraction, while explicit expressions can be used as an alternative input modality. A simple smiling gesture showed good potential, e.g. to save favorite songs.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {383–389},
numpages = {7},
keywords = {Multimodal Interaction, Driver Distraction, Face Recognition, Affective Computing, Automotive User Interfaces},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289730,
author = {Samer, Seif Eldin and Maghraby, Amr Ahmed and Zook, Yousef and Haiba, Amira and Lazem, Shaimaa and Shawky, Sherif M. and Elkhamisy, Sherif F.},
title = {Al-Metyaf: A Smart Phone Application for Colorimetric Analysis},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289730},
doi = {10.1145/3282894.3289730},
abstract = {Colorimetric analysis is a method of determining the concentration of a chemical element or chemical compound in a solution with the aid of a color reagent. This poster explores the utilization of smartphones for colorimetric quantification of biological macromolecules. A low-cost optomechanical device and an Android application were designed to capture the image of a substance sample, and detect its concentration using the Saturation channel from the HSV color space. We report the device design and findings from preliminary experiments.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {391–396},
numpages = {6},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289731,
author = {Chen, Heng-Yi and Lin, Tse-Yu and Huang, Li-Yang and Chen, An-Chun and Zheng, Yu-Chen and Wang, Hsing-Mang and Wei, Shi-Yao and Chou, Yin-Yu},
title = {HP2: Using Machine Learning Model to Play Serious Game with IMU Smart Suit},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289731},
doi = {10.1145/3282894.3289731},
abstract = {Office workers usually have problems of back and neck pain because of their bad posture which they always keep. In order to solve the problems, we design a smart suit, Heath Posture Protector (HP2), and 4 serious games for rehabilitation. Besides, we use machine learning to train the motion model and apply the model in playing the serious games. We expect the user who wears the smart suit HP2 can easily play the serious games, and furthermore, they can stretch the muscles of upper body by the guidance in games to reduce or even prevent the problems of upper-body pains.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {397–402},
numpages = {6},
keywords = {Wearable device, Inertial measurement units(IMUs), Machine learning, Serious game},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289732,
author = {Voit, Alexandra and Weber, Dominik and Imeri, Amil and Eidner, Annika and Tsoulos, Anton and Koch, Daniel and Chen, Kai and Rottsch\"{a}fer, Marcus and Schweiker, Robin and S\"{o}hnel, Steven and Sabbatino, Valentino and Henze, Niels},
title = {Exploration of a Multi-Device Smart Calendar Platform for Smart Homes},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289732},
doi = {10.1145/3282894.3289732},
abstract = {Calendars are an essential tool for users to manage their daily schedules. With the expanding availability of Internet of Things (IoT) devices and smart home appliances, more and more connected devices appear in the homes of users. Some of these devices have the potential to complement, extend or even replace existing physical and digital calendars. However, little is known about how these devices should display calendar information without overwhelming users and negatively influencing their digital well-being. In this paper, we report the results of a lab study with 18 participants in which we compared calendars on seven different types of devices in the smart home context, from existing smartphone apps to novel e-paper displays and smart mirrors. We developed a smart calendar platform as a research probe and provide first insights into how different devices should convey information in future smart homes.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {403–410},
numpages = {8},
keywords = {internet of things, multi-device, ambient information system, smart home, Smart calendar},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289733,
author = {Visuri, Aku and Poguntke, Romina and Kuosmanen, Elina},
title = {Proposing Design Recommendations for an Intelligent Recommender System Logging Stress},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289733},
doi = {10.1145/3282894.3289733},
abstract = {The connection between stress and smartphone usage behavior has been investigated extensively. While the prediction results using machine learning are encouraging, the challenge of how to cope with data loss remains. Addressing this problem, we propose an Intelligent Recommender System for logging stress based on adding a subjective user data-based validation to predictions made by intelligent algorithms. In a user study involving 731 daily stress self-reports from 30 participants we found discrepancies between subjective and smartphone usage data, i.e. battery, call information, or network usage. Despite the good prediction accuracy of 65% using a Random Forest classifier, combining both information would be beneficial for avoiding data and improving prediction accuracy. For realizing such a system (i.e., a mobile application), we propose three design recommendations, based on the capabilities of frequently used machine learning classifiers, enabling users to annotate their daily stress levels with a predict-and-validate methodology.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {411–417},
numpages = {7},
keywords = {Sensor Data, Smartphones, Stress Recognition},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289734,
author = {Mahmoud, Ahmed Hamdy and Abdullatif, Yara and Lazem, Shaimaa},
title = {PI Floor: Portable Interactive Floor with High Resilience and Minimal Setup for Edutainment},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289734},
doi = {10.1145/3282894.3289734},
abstract = {Merging gaming in education produces sweet results for both the students and the teachers. Children nowadays tend to use mobile devices for a big amount of time and don't tend to do physical activities. Interactive floors urge the students to move while learning. Nonetheless, most floor designs require expensive or extensive setup to operate. We present the design and implementation of a prototype of an educational interactive floor utilizing only printed sheets of paper and an android phone. The design is optimized towards minimalism. Which makes it usable, affordable and in budget for students in poor areas. We tested the application in the lab and responses level were satisfactory. However, this is still a work in progress project. Involving students in future experiments is a must.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {419–423},
numpages = {5},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289735,
author = {Al-Rumayyan, Nafla and AlMadi, Nora and Alay, Nada and Al-Megren, Shiroq},
title = {Evaluating TP-Link Smart Plug: Perceived Usability and Effects on User Performance},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289735},
doi = {10.1145/3282894.3289735},
abstract = {Smart home technology has recently expanded due to advancements in wireless network sensors and mobile devices. A smart home is a home that is comprised of devices that can interact with each other and be controlled remotely via mobile applications. Smart home devices include smart bulbs, smart switches, smart plugs, smart TVs, and surveillance cameras. Employing such devices and applications could lead to some usability issues if usability is not taken into consideration during the development phase of the smart home technology. This paper investigates the usability of the TP-link smart plug and its smartphone application. The data was collected from pre- and post-test questionnaires, observation during tests, and post-test interviews. The findings show that linking the smart plug to the application was somewhat difficult, but using the smart plug was generally easy. Furthermore, recommendations were suggested to enhance the interface of the smart plug's smartphone application.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {425–432},
numpages = {8},
keywords = {usability, smart home, user experience, Smart plug},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289736,
author = {Ben-Hanania, Adam and Goldberg, Joshua and Cauchard, Jessica R.},
title = {Multi-User Control for Domestic Robots with Natural Interfaces},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289736},
doi = {10.1145/3282894.3289736},
abstract = {Our environments are increasingly being populated with intelligent devices and robots. People use digital assistants with speech interfaces to play music, find out about the weather, or call a taxi. Such interfaces are designed for single user control, and often fail when multiple people interact simultaneously. For instance, if two users keep asking for a different song, the digital assistant will keep changing the music with no regards for users' comfort or any conflict that may arise. As these devices are shared, it is crucial that the interface is built to consider more than one user. This work investigates which control schemes are suitable for multiple users to simultaneously interact with a single domestic cleaning robot. The control schemes will be tested with small groups of people who live together. Our work will inform researchers on how to build control schemes that are acceptable and suitable in shared environments.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {433–439},
numpages = {7},
keywords = {Human-Robot Interaction, Natural Interfaces, Multi-user interaction},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289737,
author = {Kuosmanen, Elina and Kan, Valerii and Visuri, Aku and Vega, Julio and Nishiyama, Yuuki and Dey, Anind K. and Harper, Simon and Ferreira, Denzil},
title = {Mobile-Based Monitoring of Parkinson's Disease},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289737},
doi = {10.1145/3282894.3289737},
abstract = {Parkinson's disease (PD) is the second most common neurodegenerative disorder, impacting an estimated seven to ten million people worldwide. It is commonly accepted that improving medication adherence alleviates symptoms and maintains motor capabilities. Not following the medication regimen (e.g., skipping or over-medicating) may worsen side-effects, which mislead clinicians and patients. We developed and evaluated a mobile application, STOP, for screening the PD symptoms and medication intake. It contains a game for tracking the PD symptoms, and a medication journal for recording medical intake and adherence. We conducted a 1-month long real-world deployment with 13 PD patients from two countries. We found that the application medication adherence tracking provides non-bias information, and users are receptive to share such data with their care and medical personnel.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {441–448},
numpages = {8},
keywords = {logging, gamification, Parkinson's disease, empirical evaluation, smartphone},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289738,
author = {Rodrigues, Andr\'{e} and Correia, Nuno and Fortunato, Elvira},
title = {Mellitus: A Smartphone Application for Image Processing and Colorimetric Analysis},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289738},
doi = {10.1145/3282894.3289738},
abstract = {Together with materials researchers at CENIMAT, a mobile application was developed in order to perform colorimetric analysis of a glucose paper biosensor to be used for the diagnostic of one of the most incident diseases in the world, Diabetes, using Image Processing Techniques and Machine Learning algorithms. This application was designed based on a User Story and various scenarios describing how users can interact with it. Testing showed that the app is capable of distinguishing high glucose concentrations from low concentrations, while a usability questionnaire made to potential users showed that they thought the application was easy to use, being capable of becoming a portable and fast mean of diagnostic.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {449–455},
numpages = {7},
keywords = {Colorimetric Analysis, Mobile Application, Paper, Classification, Diabetes, Biosensor, Image Processing},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289739,
author = {Faltaous, Sarah and Elbolock, Alia and Talaat, Mostafa and Abdennadher, Slim and Schneegass, Stefan},
title = {Virtual Reality for Cultural Competences},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289739},
doi = {10.1145/3282894.3289739},
abstract = {With the expansion of multicultural communities, raising awareness to diminish cultural misconceptions became a must. We investigate different research probes using interactive Virtual Reality (VR) applications to increase such awareness. VR environments provide a high sense of immersion, which enhance the user's experience. In this work, we present three VR interactive research probes that allow users to understand cultural differences and to reduce cultural misconceptions.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {457–461},
numpages = {5},
keywords = {Virtual Reality, Multicultural, Understanding Cultural Differences},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289740,
author = {Ostrin, Gilad and Frey, J\'{e}r\'{e}my and Cauchard, Jessica R.},
title = {Interactive Narrative in Virtual Reality},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289740},
doi = {10.1145/3282894.3289740},
abstract = {Interactive fiction is a literary genre that is rapidly gaining popularity. In this genre, readers are able to explicitly take actions in order to guide the course of the story. With the recent popularity of narrative focused games, we propose to design and develop an interactive narrative tool for content creators. In this extended abstract, we show how we leverage this interactive medium to present a tool for interactive storytelling in virtual reality. Using a simple markup language, content creators and researchers are now able to create interactive narratives in a virtual reality environment. We further discuss the potential future directions for a virtual reality storytelling engine.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {463–467},
numpages = {5},
keywords = {Interactive Fiction, Visualization, Storytelling, Virtual Reality},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289741,
author = {Abdrabou, Yasmeen and Khamis, Mohamed and Eisa, Rana Mohamed and Ismael, Sherif and Elmougy, Amr},
title = {ENGAGE: Resisting Shoulder Surfing Using Novel Gaze Gestures Authentication},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289741},
doi = {10.1145/3282894.3289741},
abstract = {Most of the already existing authentication schemes are subject to multiple types of side-channel attacks such as shoulder surfing, smudge attacks, and thermal attacks. Meanwhile, motion sensors and eye trackers are becoming more accurate. We propose a novel authentication technique that leverages a combination of mid-air gestures and gaze input for shoulder surfing resilient authentication. The aim is to complicate shoulder surfing attacks by dividing the attacker's attention onto 1) the user's eyes, 2) hand-gestures, and 3) the screen. We report on the concept and implementation of the approach using both random and fixed layouts.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {469–473},
numpages = {5},
keywords = {Multimodal Authentication, Gestures, Gaze},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289742,
author = {Majrashi, Khalid and Hamilton, Margaret and Uitdenbogerd, Alexandra L.},
title = {Task Continuity and Mobile User Interfaces},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289742},
doi = {10.1145/3282894.3289742},
abstract = {Task continuity is an important inter-usability attribute, for enhancing user transitioning experience. Mobile devices are commonly used in cross-device interaction, in combination with desktops or laptops devices. However, a lack of studies explored and compared factors affecting task continuity when users transit to and from the different types of mobile user interfaces: native mobile application, mobile website and mobile responsive website. To address this, we conducted a user study, with twenty-four voluntary participants, to investigate factors affecting task continuity when users switch between desktop website and the different types of mobile user interfaces. We used think-aloud protocols, observation and questionnaire to gather data. During our experiments, each participant switched between desktop and mobile interfaces to perform inter-related tasks. Inconsistency was a principle factor affecting task continuity when participants switched from and to mobile native applications and mobile websites. The difficulty in controlling user interface components and the slow loading of contents were two main factors affecting task continuity when users switched to continue working on mobile websites and mobile responsive websites.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {475–481},
numpages = {7},
keywords = {Inter-usability, User Transitioning Experience, Task Continuity, Mobile User Interfaces},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289743,
author = {Trotter, Ludwig and Prange, Sarah and Khamis, Mohamed and Davies, Nigel and Alt, Florian},
title = {Design Considerations for Secure and Usable Authentication on Situated Displays},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289743},
doi = {10.1145/3282894.3289743},
abstract = {Users often need to authenticate at situated displays in order to, for example, make purchases, access sensitive information, or confirm an identity. However, the exposure of interactions in public spaces introduces a large attack surface (e.g., observation, smudge or thermal attacks). A plethora of authentication models and input modalities that aim at disguising users' input has been presented in the past. However, a comprehensive analysis on the requirements for secure and usable authentication on public displays is still missing. This work presents 13 design considerations suitable to inform practitioners and researchers during the development process of authentication systems for situated displays in public spaces. It draws on a comprehensive analysis of prior literature and subsequent discussion with five experts in the fields of pervasive displays, human-computer-interaction and usable security.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {483–490},
numpages = {8},
keywords = {User Interface Design, Input Modalities, Public Displays, Design Considerations, Authentication},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289744,
author = {Antoun, Sara and Auda, Jonas and Schneegass, Stefan},
title = {SlidAR: Towards Using AR in Education},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289744},
doi = {10.1145/3282894.3289744},
abstract = {Applying Augmented Reality in education is being explored by many scientists. Therefore, we augment digital slides of lectures in higher education. We implemented a web server application, which allows professors to create their own AR slides. We also developed a mobile app for students to scan the slides and view the augmentation in lectures or learning sessions. To assess the usability of our system, we conducted a study with fifteen students and two professors. Students' feedback indicated that our AR app could be integrated into education. Professors, on the other hand, reported improvement suggestions. However, both groups supported applying the system in real lectures.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {491–498},
numpages = {8},
keywords = {Augmented Reality, Education},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289745,
author = {V\"{a}yrynen, Jani and Suoheimo, Mari and Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {Exploring Head Mounted Display Based Augmented Reality for Factory Workers},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289745},
doi = {10.1145/3282894.3289745},
abstract = {We present our prototype application of head mounted display (HMD) based augmented reality (AR) for use in in factory contexts. The prototype was evaluated in a focus group based user study held at an industrial production line. The prototype was implemented using a Microsoft HoloLens, and supported placing different AR notifications, such as machinery fault or maintenance messages, in the environment. The prototype was used as a stimulus in the focus group consisting of factory workers (n = 6) for exploring the potential use of HMD AR in the industrial production line context. As the main findings, we identified two themes where factory workers saw HMD AR as a potential technology: in task instruction, and in confirming correct functionality. The technology was seen as having potential for collaborative tasks, especially for receiving instructions. Hands-free usage and ability to interact whilst wearing gloves were highly appreciated.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {499–505},
numpages = {7},
keywords = {augmented reality, factory workers, user studies, HMD},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289716,
author = {Livia, Claudia and Zakirova, Nilufer and Wolf, Katrin},
title = {Fragments: Memory De- &amp; Reconstruction of Historical Imaging},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289716},
doi = {10.1145/3282894.3289716},
abstract = {Fragments is an interactive installation that represents historical moments of Berlin's Potsdamer Platz. The installation is an embodied interaction where people walk into and bring through their body movements the installation to live.Through a constantly changing interactively generated image collage, Fragments mimics the way the human brain retrieves memories as well as how novel memories are constructed as an interaction and a collage of different memorized images that overlay, overlap, and partly fade out. Different archival photographs taken throughout time show past moments of the historically important place. When the viewer approaches the installation, images of the past appear on transparent curtains hanged from the ceiling close to the visitor's position. Fragments generates new images with those that newly appeared as a collective collage of historical fragments. Thereby, the installation shows the transparence of memory, its overlap with other memories, and the creation of collective memory stories consisting out of a memory fragment collage.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {507–511},
numpages = {5},
keywords = {Memory, Installation, augmented rooms, Media Art, Reflection, Interactive installation, media spaces},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289718,
author = {Minyaev, Ilya and Pouke, Matti and Ylipulli, Johanna and Ojala, Timo},
title = {Implementation of a Virtual Reality Interface for a Public Library},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289718},
doi = {10.1145/3282894.3289718},
abstract = {In this demo paper we describe the development process and technical implementation of an interactive Virtual Reality (VR) application dubbed Virtual Library. The application utilizes consumer VR hardware and Unreal Engine to provide an immersive virtual interface to a physical library and its selected services, as well as browsing of literature content in aesthetic fantasy realms. The prototype is publicly available at the Oulu City Library.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {513–519},
numpages = {7},
keywords = {Digital library services, mirror world, fantasy worlds, Unreal Engine},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289719,
author = {Holappa, Harri and Ylipulli, Johanna and Rautiainen, Sami and Minyaev, Ilya and Pouke, Matti and Ojala, Timo},
title = {VR Application for Technology Education in a Public Library},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289719},
doi = {10.1145/3282894.3289719},
abstract = {In this video paper we report on our experiences of deploying a VR point at a public library for the purpose of educating library patrons on VR technology. The primary application offered at the VR point is called Virtual Library, a VR application developed specifically for the Oulu City Library. The Virtual Library application provides an immersive virtual interface into selected library services, as well as allows library patrons to browse literature recommendations inside genre-specific fantasy realms. Based on the observations of the first week weeks of deployment, the VR point and the Virtual Library are successful approaches for technology education in a public library.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {521–527},
numpages = {7},
keywords = {Digital library services, mirror world, fantasy worlds, participatory design, technology education, hybrid space},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289746,
author = {Skowronski, Moritz and Wieland, Jonathan and Borowski, Marcel and Fink, Daniel and Gr\"{o}schel, Carla and Klinkhammer, Daniel and Reiterer, Harald},
title = {Blended Museum: The Interactive Exhibition "Rebuild Palmyra?"},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289746},
doi = {10.1145/3282894.3289746},
abstract = {"Rebuild Palmyra?" is a multimedia exhibition about the ancient city of Palmyra, its destruction by Daesh, and the question of whether it should be rebuilt. As such, it tackles today's pressing question of how humanity should deal with the destruction of cultural heritage. In the design of the exhibition, we pursued the Blended Museum approach, in which we strive to seamlessly integrate interactive media into exhibition design to increase the overall visitor experience. In this work, we present the exhibition, which consists of four rooms. We focus on three interactive installations in which the topic of reconstructing Palmyra is mediated using new technologies such as 3D Printing, Augmented Reality, and Virtual Reality. The installations helped visitors in developing their own point of view on the question of rebuilding Palmyra. Lastly, we provide insights into the technical implementation of the installations and discuss the results of quantitative and qualitative evaluations.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {529–535},
numpages = {7},
keywords = {Augmented Reality, Virtual Reality, 3D Printing, Tabletop, Cultural Heritage, Scenography, Blended Museum, Exhibition},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289747,
author = {Druzetic, Ivana and B\"{u}ntig, Fabian and Vogel, Christoph and Treskunov, Anastasia and Bertram, Michael and Geiger, Christian},
title = {Photo Sprayer: A VR Application for Digital Art Creation},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289747},
doi = {10.1145/3282894.3289747},
abstract = {Photo Sprayer is a virtual painting tool for creation of digital art in virtual reality (VR) by using images of the real-world surrounding as its painting palette. The users can capture images of local sights, objects, faces or random details and turn them into colors and patterns for their digital artwork on 2D surfaces and 3D objects in VR. The application is conceptualized as a playful approach to the predominance of contemporary digital imagery, symbolically empowering the user to emancipate from the image dominance. It was developed for simple use by anyone interested in digital art, enabling a wide array of people to assume the role of an artist. The projection of the real-time painting process allows the observers to continuously follow the progress, while they become part of the artwork though their presence captured in the images.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {537–543},
numpages = {7},
keywords = {virtual reality, mixed reality, participatory art, digital immersive art, spray can brush},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3286058,
author = {Monastero, Beatrice and Lucero, Andr\'{e}s and Takala, Tapio and Olsson, Thomas and Jacucci, Giulio and Mitchell, Robb},
title = {Multimedia Ubiquitous Technology for Opportunistic Social Interactions},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3286058},
doi = {10.1145/3282894.3286058},
abstract = {This workshop will discuss how different multimedia applications and interaction techniques have been employed to support public sociality---from collocated interactions to social awareness and feeling of community. Participants will discuss recent work and join hands-on design activities to envision new ways for potential users to discover and learn how to use ubiquitous technologies for opportunistic social interactions.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {545–550},
numpages = {6},
keywords = {ubiquitous computing, public space, Social interaction},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3286059,
author = {Elagroudy, Passant and Abdelrahman, Yomna and Faltaous, Sarah and Schneegass, Stefan and Davis, Hilary},
title = {Workshop on Amplified and Memorable Food Interactions},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3286059},
doi = {10.1145/3282894.3286059},
abstract = {Cooking has the potential to bring joy, a sense of achievement and social presence to individuals and groups. Food properties (food cues) such as scent, sound and taste are rich cues to the state of the cooking process, as well as, providing memories evoking emotions attached to social situations and people from the past. Thus, optimal methods to capture and present these cues is an on-going research challenge. In this workshop, we bring researchers, amateur cooks, and designers together to explore two research questions:1) how does enhancing our awareness of food temperature support a joyful and/or a memorable cooking experience? and 2) how can we use food cues to enhance our sense of joy, empower reminiscence and nudge communication between individuals?. We aim through this event to foster a research community that uses food interaction as a medium to promote a sense of joyfulness and social wellbeing.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {551–555},
numpages = {5},
keywords = {reminiscence, food interaction, communication, memory augmentation, thermal imaging, amplified perception},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3286060,
author = {El Bolock, Alia and Salah, Jailan and Abdelrahman, Yomna and Herbert, Cornelia and Abdennadher, Slim},
title = {Character Computing: Computer Science Meets Psychology},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3286060},
doi = {10.1145/3282894.3286060},
abstract = {Now that most daily endeavors have migrated to computers and the Internet, having systems that adapt to users is a rising trend. By detecting and adapting to the user's traits and character instead of only the current states, there is great potential for novel user experiences. Character Computing which was introduced in [3] is now extended to the field of experimental psychology and psychological theorizing. Our approach integrates psychological and computational aspects of advanced sensing and processing technologies to detect the building blocks of a user's character traits and states which will allow computer systems to adapt to the user's behavior and his/her feelings more reliably and mimic them according to situational demands. Accordingly, in this workshop the different aspects of Character Computing are to be discussed from an interdisciplinary perspective taking computational and psychological accounts into consideration in order to strengthen already investigated and potential applications as well as the theoretical foundation and challenges of Character Computing.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {557–562},
numpages = {6},
keywords = {Character Computing, Affective Computing, Adaptive Systems, Ubiquitous Computing, Psychology, Personality, Interactive Systems},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3291046,
author = {Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {Service Design Methods for Human Computer Interaction},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3291046},
doi = {10.1145/3282894.3291046},
abstract = {This tutorial addresses the application of service design methods for Human Computer Interaction (HCI). The tutorial will cover methodological and practical aspects of service design, focusing on three key tools -- stakeholder maps, consumer journey and business model canvas. The service design methods are tried out with interactive exercises, where participants in groups apply the methods to a design case. Service design is an emerging field, which applies a holistic design approach to understand and design for human experience. With an increasing number of digital services, both in commercial and public frontiers, it is important to develop services that are easy to use, and where the consumer's journey through the service pathways is fluent and consistent.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {563–566},
numpages = {4},
keywords = {HCI, Service design, participatory design, user centric design},
location = {Cairo, Egypt},
series = {MUM 2018}
}

@inproceedings{10.1145/3282894.3289721,
author = {ElBolock, Alia},
title = {Defining Character Computing from the Perspective of Computer Science and Psychology},
year = {2018},
isbn = {9781450365949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282894.3289721},
doi = {10.1145/3282894.3289721},
abstract = {The emerging field of Character Computing aims at combining computer science and Psychology to achieve humanaware computing that considers all aspects of human behavior and human experience, including the human user's states, traits, and surrounding situations. We propose developing an computational and psychologically-driven architecture for Character Computing based on existing accepted psychological models of cognition, personality and emotions. This would help towards further defining Character Computing and setting strong theoretical foundations for it. The computational architecture is at the heart of this PHD thesis. Developing the architecture requires input from Psychology and Computer Science which is currently already ensured by continuous input from the supervisors Prof. Cornelia Herbert (Ulm University) and Prof. Slim Abdennadher (GUC). Beta-versions of the architecture are then tested in experimental psychological experiments and use-cases that would most benefit from considering the character of the user as a component. The situations most telling and affected by that are investigated through machine learning techniques, experimental psychological methods and computational modeling. The use-cases range from IoT applications, smart assistants, autonomous cars to health care and education.},
booktitle = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia},
pages = {567–572},
numpages = {6},
location = {Cairo, Egypt},
series = {MUM 2018}
}

