@inproceedings{10.1145/1149941.1149944,
author = {Qi, Yan and Candan, K. Sel\c{c}uk},
title = {CUTS: <i>CU</i>Rvature-Based Development Pattern Analysis and Segmentation for Blogs and Other <i>T</i>Ext <i>S</i>Treams},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149944},
doi = {10.1145/1149941.1149944},
abstract = {Weblogs (blogs) are becoming prominent forms of information exchange in the Internet. A large number and variety of blogs, like personal journals or commentaries, are available for general consumption. However, effective indexes and navigation structures (like the table of content in a book) are not available for blogs. Therefore, it is generally not possible to navigate among entries in a given collection of blog entries in an informed manner. This paper focuses on the segmentation of entries in filter-type [9] blogs, with the aim of using this information for developing hypertext and navigational helps. In particular, we are interested in the analysis of topic development patterns that can provide information about not only the entries themselves, but how these entries develop and relate to each other. The proposed algorithm, CUTS, maps entries into a curve in a way that makes apparent a variety of topic development patterns. We then use curve analysis for automatic segmentation of topics. The resulting base topic segments are classified into different topic development patterns that can be visualized and indexed. Experimental results show that the proposed technique has very good performance in identifying boundaries in text streams, especially filter style blogs, versus existing schemes. Furthermore, compared with other topic segmentation methods, the proposed mechanism highlights not only topic boundaries, but also topic development patterns.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {1–10},
numpages = {10},
keywords = {weblogs, curve segmentation, topic segmentation, topic development patterns},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149945,
author = {Chin, Alvin and Chignell, Mark},
title = {A Social Hypertext Model for Finding Community in Blogs},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149945},
doi = {10.1145/1149941.1149945},
abstract = {Blogging has become the newest communication medium for creating a virtual community, a set of blogs linking back and forth to one another's postings, while discussing common topics. In this paper, we examine how communities can be discovered through interconnected blogs as a form of social hypertext [14]. We propose a method and model that detects structures of community in the social network of blogs by integrating McMillan and Chavis' sense of community [26] along with network analysis [8, 11]. From the model, we measure community in the blogs by aligning centrality measures from social network analysis [17] with measures of sense of community obtained using behavioural surveys. We then illustrate the use of this approach with a case study built around an independent music blog. The strength of community measures were found to be well aligned with the network structure, based on centrality measures. Even though the sample size from the case study was small, once the structure and measure of communities are calibrated according to our social hypertext model, communities can be automatically found and measured for other blogs without the need for behavioural surveys.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {11–22},
numpages = {12},
keywords = {virtual community, social networks, sense of community, hypertext, blogs},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149946,
author = {Zhang, Yuejiao},
title = {Wiki Means More: Hyperreading in Wikipedia},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149946},
doi = {10.1145/1149941.1149946},
abstract = {Based on the open-sourcing technology of wiki, Wikipedia has initiated a new fashion of hyperreading. Reading Wikipedia creates an experience distinct from reading a traditional encyclopedia. In an attempt to disclose one of the site's major appeals to the Web users, this paper approaches the characteristics of hyperreading activities in Wikipedia from three perspectives. Discussions are made regarding reading path, user participation, and navigational apparatus in Wikipedia.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {23–26},
numpages = {4},
keywords = {wiki, open-sourcing, collaborative authoring, Web 2.0, hyperreading, encyclopedia, linking, information system},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149947,
author = {Millard, David E. and Ross, Martin},
title = {Web 2.0: Hypertext by Any Other Name?},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149947},
doi = {10.1145/1149941.1149947},
abstract = {Web 2.0 is the popular name of a new generation of Web applications, sites and companies that emphasis openness, community and interaction. Examples include technologies such as Blogs and Wikis, and sites such as Flickr. In this paper we compare these next generation tools to the aspirations of the early Hypertext pioneers to see if their aims have finally been realized.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {27–30},
numpages = {4},
keywords = {Web 2.0, hypertext functionality, hypertext pioneers},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149949,
author = {Marlow, Cameron and Naaman, Mor and Boyd, Danah and Davis, Marc},
title = {HT06, Tagging Paper, Taxonomy, Flickr, Academic Article, to Read},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149949},
doi = {10.1145/1149941.1149949},
abstract = {In recent years, tagging systems have become increasingly popular. These systems enable users to add keywords (i.e., "tags") to Internet resources (e.g., web pages, images, videos) without relying on a controlled vocabulary. Tagging systems have the potential to improve search, spam detection, reputation systems, and personal organization while introducing new modalities of social communication and opportunities for data mining. This potential is largely due to the social structure that underlies many of the current systems.Despite the rapid expansion of applications that support tagging of resources, tagging systems are still not well studied or understood. In this paper, we provide a short description of the academic related work to date. We offer a model of tagging systems, specifically in the context of web-based systems, to help us illustrate the possible benefits of these tools. Since many such systems already exist, we provide a taxonomy of tagging systems to help inform their analysis and design, and thus enable researchers to frame and compare evidence for the sustainability of such systems. We also provide a simple taxonomy of incentives and contribution models to inform potential evaluative frameworks. While this work does not present comprehensive empirical results, we present a preliminary study of the photo-sharing and tagging system Flickr to demonstrate our model and explore some of the issues in one sample system. This analysis helps us outline and motivate possible future directions of research in tagging systems.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {31–40},
numpages = {10},
keywords = {tagging systems, tagsonomy, social software, categorization, Flickr, folksonomy, classification, social networks, research, models, incentives, taxonomy},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149950,
author = {Mertens, Robert and Farzan, Rosta and Brusilovsky, Peter},
title = {Social Navigation in Web Lectures},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149950},
doi = {10.1145/1149941.1149950},
abstract = {Web lectures are a form of educational content that differs from classic hypertext in a number of ways. Web lectures are easier to produce and therefore large amounts of material become accumulated in a short time. The recordings are significantly less structured than traditional web based learning content and they are time based media. Both the lack of structure and their time based nature pose difficulties for navigation in web lectures. The approach presented in this paper applies the basic concept of social navigation to facilitate navigation in web lectures. Social navigation support has been successfully employed for hypertext and picture augmented hypertext in the education domain. This paper describes how social navigation can be implemented for web lectures and how it can be used to augment existent navigation features.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {41–44},
numpages = {4},
keywords = {video, presentation recoding, continuous media, web lectures, hypermedia, user interfaces, social navigation, lecture recording},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149951,
author = {Bucur, Johanna},
title = {HyWrite: Writing in Hypermedia ELearning Environments},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149951},
doi = {10.1145/1149941.1149951},
abstract = {The paper focuses on the practical reality of eLearning in Higher Education with special emphasis on media integration from the perspective of a spiral curriculum.[12] It presents an innovative model of media art education integrated in a creative writing program and concentrates upon the re-design of writing with the help of hypermedia in customized eLearning environments. HyWrite is the name of an authoring tool, an "educational facilitator", currently being developed at the University of Passau.This tool is meant to be used both in higher education for teacher training purposes and in secondary education as a teacher and student's hypertext writing assistant. HyWrite is backed by an elaborate didactic design based on students' active participation and all-round involvement in the learning process. The didactic goals pursued are on the one hand the acquisition of a set of primary skills like for instance essay writing and on the other hand getting acquainted with a host of complementary skills not explicitly mentioned by the curriculum yet presupposed by the Information and Knowledge Society. These skills are dealt with in a systematical approach and reflect the actual state of affairs, namely what "every schoolboy and girl should know".[3] An overview of the above mentioned competences is available in the core skill cluster below. The skill cluster under discussion covers competences pertaining to four ranges of action: writing techniques, media literacy, aesthetic features combined with ergonomic design from the point of view of accessibility and usability, and -last but not least- the social skills imposed by cooperative work.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {45–48},
numpages = {4},
keywords = {cooperative work, learning communities, Social Constructionist Pedagogy (SCP), hypertext, spiral curriculum, eLearning, media literacy},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149952,
author = {Ruddle, Roy A.},
title = {Using String-Matching to Analyze Hypertext Navigation},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149952},
doi = {10.1145/1149941.1149952},
abstract = {A method of using string-matching to analyze hypertext navigation was developed, and evaluated using two weeks of website logfile data. The method is divided into phases that use: (i) exact string-matching to calculate subsequences of links that were repeated in different navigation sessions (common trails through the website), and then (ii) inexact matching to find other similar sessions (a community of users with a similar interest). The evaluation showed how subsequences could be used to understand the information pathways users chose to follow within a website, and that exact and inexact matching provided complementary ways of identifying information that may have been of interest to a whole community of users, but which was only found by a minority. This illustrates how string-matching could be used to improve the structure of hypertext collections.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {49–52},
numpages = {4},
keywords = {analysis, string-matching, navigation},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149953,
author = {Wang, Weigang and Rubart, Jessica},
title = {A Cognitive and Social Framework for Shared Understanding in Cooperative Hypermedia Authoring},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149953},
doi = {10.1145/1149941.1149953},
abstract = {Creating shared knowledge structures using cooperative hypermedia is a joint activity. The knowledge structures created should fit into the real world environment and reflect the common ground reached and evolved in the cooperation process of the knowledge workers. In order to facilitate the development of shared understanding among knowledge workers, Herbert Clark's theory on language use and Jean Piaget's cognitive theory are applied to the use of hypermedia language in cooperative work settings. To make the theories easier to apply, a conceptual framework is derived from them, which can inform the design and comparison of cooperative hypermedia systems and the use of hypermedia in cooperative settings.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {53–56},
numpages = {4},
keywords = {common ground, cooperative hypermedia, grounding, joint cognition, shared knowledge structure},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149955,
author = {Garzotto, Franca and Forfori, Matteo},
title = {Hyperstories and Social Interaction in 2D and 3D Edutainment Spaces for Children},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149955},
doi = {10.1145/1149941.1149955},
abstract = {This paper presents FaTe2, an edutainment environment for children that combines a variety of paradigms: storytelling, hypertext, games, collaborative learning, and social interaction. FaTe2 provides a web based, multi-user, multi-dimension hyperspace, where children (aged 8-11) can meet, chat, play, and perform storytelling activities in collaboration. Small groups of kids -- working both shoulder to shoulder and remotely - can explore together multimedia interactive stories rendered by means of 2D and 3D scenes; they can perform a variety of educational games and narrative activities; they can personalize scene elements and collaboratively create their own narrative flows, generating a multidimensional (i.e., 2D and 3D) hyperstory from the linear multimedia stories that are built-in in the system. The paper describes the background of FaTe2, its "child-centered" design (informed by field studies on kids' storytelling), and its implementation approach. We finally discuss how kids represent a challenging "category of target users" who may open new perspectives for hypertext practice and research.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {57–68},
numpages = {12},
keywords = {edutainment, hypernarrative, social interaction, story grammar, IDC (Interaction Design and Children), collaborative storytelling},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149956,
author = {Al-Khalifa, Hend S. and Davis, Hugh C.},
title = {The Evolution of Metadata from Standards to Semantics in E-Learning Applications},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149956},
doi = {10.1145/1149941.1149956},
abstract = {Metadata attempts to describe the content, format, purpose and structure of data. Over the past few years, the IEEE-LOM standard has dominated the metadata world in e-learning applications. However, with the advent of the Semantic Web, e-learning applications are beginning to evolve their metadata representation from these standards by adding semantic structure or by converting entirely to semantic representations of structure. This shift enables the implementation of a range of new tools which can reason over the metadata, providing added value from the stored data. This review paper summarizes this evolution of metadata used in e-learning applications from standards to semantic representation.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {69–72},
numpages = {4},
keywords = {E-learning, standard metadata, semantic metadata},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149957,
author = {Mandl, Thomas},
title = {Implementation and Evaluation of a Quality-Based Search Engine},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149957},
doi = {10.1145/1149941.1149957},
abstract = {In this paper, an approach for the implementation of a quality-based Web search engine is proposed. Quality retrieval is introduced and an overview on previous efforts to implement such a service is given. Machine learning approaches are identified as the most promising methods to determine the quality of Web pages. Features for the most appropriate characterization of Web pages are determined. A quality model is developed based on human judgments. This model is integrated into a meta search engine which assesses the quality of all results at run time. The evaluation results show that quality based ranking does lead to better results concerning the perceived quality of Web pages presented in the result set. The quality models are exploited to identify potentially important features and characteristics for the quality of Web pages.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {73–84},
numpages = {12},
keywords = {web design, quality search, web metrics, quality models},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149958,
author = {Kazienko, Przemys\l{}aw and Pilarczyk, Marcin},
title = {Hyperlink Assessment Based on Web Usage Mining},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149958},
doi = {10.1145/1149941.1149958},
abstract = {One of the basic methods of web usage mining are association rules that indicate relationships among common use of web pages. Positive and confined negative association rules are the components of the new quality measures: Positive and Negative Quality function, respectively. These functions are used to evaluate the quality of hyperlinks existing on web pages. A number of statistics and the expert validation revealed the usefulness of association rules for the assessment of hyperlink usability.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {85–88},
numpages = {4},
keywords = {negative association rules, hyperlink assessment, web mining},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149960,
author = {Delort, Jean-Yves},
title = {Identifying Commented Passages of Documents Using Implicit Hyperlinks},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149960},
doi = {10.1145/1149941.1149960},
abstract = {This paper addresses the issue of automatically selecting passages of blog posts using readers' comments. The problem is difficult because: (i) the textual content of blogs is often noisy, (ii) comments do not always target passages of the posts and, (iii) comments are not equally useful for identifying important passages. We have developed a system for selecting commented passages which takes as input blog posts and their comments and delivers, for each post, the sentences of the post which are the most commented and/or the most discussed. Our approach combines three steps to identify commented passages of a post. The first step is to remove the complexity of processing the contents of posts and comments using heuristics adapted to the language of the blog. The second step is to find useful comments and assigns them a degree of relevance using a model automatically built and validated by an expert. The third step is to identify important passages using relevant comments. We conducted two experiments to evaluate the usefulness and the effectiveness of our approach. The first study show that in only 50% of the posts, the most commented sentence elicited by our approach corresponds to the post extract generated using generic summarization. In the second study, human participants confirmed that, in practice, selected passages are frequently commented passages.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {89–98},
numpages = {10},
keywords = {weblogs, implicit links, passage extraction},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149961,
author = {Anderson, Kenneth M. and Hansen, Frank Allan and Bouvin, Niels Olof},
title = {Templates and Queries in Contextual Hypermedia},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149961},
doi = {10.1145/1149941.1149961},
abstract = {This paper presents a new definition of context for context-aware computing based on a model that relies on dynamic queries over structured objects. This new model enables developers to flexibly specify the relationship between context and context data for their context-aware applications. We discuss a framework, HyConSC, that implements this model and describe how it can be used to build new contextual hypermedia systems. Our framework aids the developer in the iterative development of contextual queries (via a dynamic query browser) and offers support for con-text matching, a key feature of contextual hypermedia. We have tested the framework with data and sensors taken from the HyCon contextual hypermedia system and are now migrating HyCon to this new framework.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {99–110},
numpages = {12},
keywords = {user interfaces, search, structural computing, templates, context-aware systems},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149962,
author = {Wu, Harris and Zubair, Mohammad and Maly, Kurt},
title = {Harvesting Social Knowledge from Folksonomies},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149962},
doi = {10.1145/1149941.1149962},
abstract = {Collaborative tagging systems, or folksonomies, have the potential of becoming technological infrastructure to support knowledge management activities in an organization or a society. There are many challenges, however. This paper presents designs that enhance collaborative tagging systems to meet some key challenges: community identification, ontology generation, user and document recommendation. Design prototypes, evaluation methodology and selected preliminary results are presented.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {111–114},
numpages = {4},
keywords = {link analysis, collaborative filtering, collaborative tagging},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149963,
author = {Tzagarakis, Manolis and Vaitis, Michail and Karousos, Nikos},
title = {Supporting the Design of Behaviors in Callimachus},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149963},
doi = {10.1145/1149941.1149963},
abstract = {Behaviors play an important role to relationship semantics. In this paper, we present how behavioral aspects of structures are conceived in Callimachus, a structural computing environment. Callimachus supports the definition of behavioral designs called propagation templates that assist in addressing behavioral concerns of structures within structure servers. Propagation templates provide a higher level of abstraction and signify an attempt to move from an atom-based view of behaviors to a system and pattern-based view.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {115–118},
numpages = {4},
keywords = {models, behavior, structural computing},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149965,
author = {Gr\o{}nb\ae{}k, Kaj},
title = {Ubiquitous Hypermedia and Social Interaction in Physical Environments},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149965},
doi = {10.1145/1149941.1149965},
abstract = {Hypermedia and the Web have been successful means to create global social networks via the Internet. Collaborative hypermedia systems and standards like BSCW, Wikis, and WebDAV enable people to establish formal and informal collaboration patterns across the Internet. The easy to use Blog/Weblog systems have made it possible for people to establish communities, express opinions, and spark debates over the Internet with minimal effort. Open hypermedia and annotation systems have been developed to support linking and commenting on existing Web documents to support scholarly discourse of online material. Many e-learning applications have been built on top of these systems to provide support for remote learning activities in schools and at workplaces.However, this focus on remote and distributed social networks has to some degree taken the focus away from social networks and collaboration among people who share the same physical environment whether face-to-face or over time. Physical environments in this context may be public spaces or buildings such as workplaces, schools, libraries, museums, and homes. Some of the technologies listed above may of course be applied by people who are in close proximity to each other who shares the same space over time, but I will argue that there is a need to focus on and conduct research in new ubiquitous hypermedia infrastructures and interaction techniques to also support social interaction and networking among people who share the same physical environment.In the Center for Interactive Spaces and predecessor projects, we have focused on the development of various kinds of ubiquitous hypermedia infrastructures and applications that support collaboration or social interaction among proximate peers at work, at school, at libraries, at museums, etc. We are applying various augmented reality tagging mechanisms (e.g., geo-tags, RFID, Bluetags, and visual tags) to provide hypermedia links among digital resources, people, objects and places. We are applying various mobile, spatial, and multi-user interaction techniques to provide new types of interfaces for social interaction in physical spaces.In the Center for Interactive Spaces we have developed several examples of ubiquitous hypermedia applications: eBag -- an electronic schoolbag system with seamless login based on bluetooth ID; iFloor -- an interactive floor for libraries and schools providing hypermedia functionality for collective search, exploration, debate, and knowledge sharing; InfoGallery -- an exhibition system for digital resources and debates at libraries, museums, attractions, and cityscapes; HyConExplorer utilizing geo- and RFID-tagging to annotate the outdoor environment for school projects or the like.Related examples from other projects and labs are Slogan-benches from the Presence project in Amsterdam; Informative Art from PLAY at Chalmers University, Sweden; the CatchBob! pervasive game developed at EPFL, Switzerland.The talk will: motivate the research in ubiquitous hypermedia supporting social interaction in physical environments; provide a brief overview of ubiquitous hypermedia techniques; give examples of ubiquitous hypermedia used for social interaction in specific domains; and, finally, outline further research issues for developing novel hypermedia techniques to be integrated in physical spaces.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {119–120},
numpages = {2},
keywords = {social computing, augmented reality, ubiquitous hypermedia, context awareness},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149967,
author = {Hansen, Frank Allan},
title = {Ubiquitous Annotation Systems: Technologies and Challenges},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149967},
doi = {10.1145/1149941.1149967},
abstract = {Ubiquitous annotation systems allow users to annotate physical places, objects, and persons with digital information. Especially in the field of location based information systems much work has been done to implement adaptive and context-aware systems, but few efforts have focused on the general requirements for linking information to objects in both physical and digital space. This paper surveys annotation techniques from open hypermedia systems, Web based annotation systems, and mobile and augmented reality systems to illustrate different approaches to four central challenges ubiquitous annotation systems have to deal with: anchoring, structuring, presentation, and authoring. Through a number of examples each challenge is discussed and HyCon, a context-aware hypermedia framework developed at the University of Aarhus, Denmark, is used to illustrate an integrated approach to ubiquitous annotations. Finally, a taxonomy of annotation systems is presented. The taxonomy can be used both to categorize system based on the way they present annotations and to choose the right technology for interfacing with annotations when implementing new systems.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {121–132},
numpages = {12},
keywords = {annotation, context-aware computing, mobile computing, ubiquitous hypermedia},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149968,
author = {De Bra, Paul and Smits, David and Stash, Natalia},
title = {The Design of AHA!},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149968},
doi = {10.1145/1149941.1149968},
abstract = {"The Design of AHA!" is an adaptive hypertext, and thus not presented in its entirety in this short paper. Because it is not only a hypertext but also adaptive it cannot simply be presented using a linear paper or a set of HTML pages.This paper describes the design of, and demonstrates AHA! (Version 3.0), an Open Source adaptive hypermedia platform, capable of performing content and link adaptation in (x)html and xml documents. Its development started in 1996. During 10 years of research and development different new presentation, adaptation and user modeling methods and techniques have been added, turning AHA! into a general-purpose adaptive hypermedia platform. This paper presents an overview of the design and architecture of AHA!, with parts that have been published before and with recent additions like style adaptation and a new very flexible link annotation mechanism.Unlike other adaptive hypermedia systems, AHA! is not aimed at a single application area and does not prescribe a single fixed presentation style. Creating applications, defining the user models and the adaptive behavior are all done using graphical authoring tools. End-users are presented with what looks like a normal website, and need not be aware of the adaptation that goes on behind the scenes. Their browsing results in updates to a user model that is stored either in an xml file or a mySQL database, and that is thus also (in principle) available to other applications. Apart from providing a design overview this paper highlights two essential parts of AHA!: the reasoning / rule engine that translates the end-user's actions into user model updates, and the adaptive resource selection, which is used in the conditional inclusion of objects presentation technique and in the conditional link destinations navigation support technique.This paper is itself an adaptive hyperdocument. The order in which the different topics are visited determines the links that are presented and the contents of each (web)page. No matter how you browse through this paper you should end up with a very similar overall impression, and you should have seen all the information the paper contains. However, the actual contents of the pages and the actual link destinations do depend on your browsing order, so different users will not see exactly the same pages and links.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {133–134},
numpages = {2},
keywords = {adaptive hypermedia, authoring, adaptation platform},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149969,
author = {Jatowt, Adam and Kawai, Yukiko and Nakamura, Satoshi and Kidawara, Yutaka and Tanaka, Katsumi},
title = {Journey to the Past: Proposal of a Framework for Past Web Browser},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149969},
doi = {10.1145/1149941.1149969},
abstract = {While the Internet community recognized early on the need to store and preserve past content of the Web for future use, the tools developed so far for retrieving information from Web archives are still difficult to use and far less efficient than those developed for the "live Web." We expect that future information retrieval systems will utilize both the "live" and "past Web" and have thus developed a general framework for a past Web browser. A browser built using this framework would be a client-side system that downloads, in real time, past page versions from Web archives for their customized presentation. It would use passive browsing, change detection and change animation to provide a smooth and satisfactory browsing experience. We propose a meta-archive approach for increasing the coverage of past Web pages and for providing a unified interface to the past Web. Finally, we introduce query-based and localized approaches for filtered browsing that enhance and speed up browsing and information retrieval from Web archives.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {135–144},
numpages = {10},
keywords = {web archive, past web browser, past web},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149971,
author = {Harrison, Terry L. and Nelson, Michael L.},
title = {Just-in-Time Recovery of Missing Web Pages},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149971},
doi = {10.1145/1149941.1149971},
abstract = {We present Opal, a light-weight framework for interactively locating missing web pages (http status code 404). Opal is an example of "in vivo" preservation: harnessing the collective behavior of web archives, commercial search engines, and research projects for the purpose of preservation. Opal servers learn from their experiences and are able to share their knowledge with other Opal servers by mutual harvesting using the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH). Using cached copies that can be found on the web, Opal creates lexical signatures which are then used to search for similar versions of the web page. We present the architecture of the Opal framework, discuss a reference implementation of the framework, and present a quantitative analysis of the framework that indicates that Opal could be effectively deployed.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {145–156},
numpages = {12},
keywords = {404 web pages, digital preservation, apache web server},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149972,
author = {McCown, Frank and Nelson, Michael L.},
title = {Evaluation of Crawling Policies for a Web-Repository Crawler},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149972},
doi = {10.1145/1149941.1149972},
abstract = {We have developed a web-repository crawler that is used for reconstructing websites when backups are unavailable. Our crawler retrieves web resources from the Internet Archive, Google, Yahoo and MSN. We examine the challenges of crawling web repositories, and we discuss strategies for overcoming some of these obstacles. We propose three crawling policies which can be used to reconstruct websites. We evaluate the effectiveness of the policies by reconstructing 24 websites and comparing the results with live versions of the websites. We conclude with our experiences reconstructing lost websites on behalf of others and discuss plans for improving our web-repository crawler.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {157–168},
numpages = {12},
keywords = {search engine, website reconstruction, digital preservation, crawler policy},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149974,
author = {Jensen, Niels and Mandl, Thomas},
title = {Different Indexing Strategies for Multilingual Web Retrieval: Experiments with the EuroGOV Corpus},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149974},
doi = {10.1145/1149941.1149974},
abstract = {Experiments with a multi-lingual web collection are presented. The EuroGOV corpus is the first multi-lingual web corpus for retrieval evaluation. We show how indexes based on words and n-rams are developed for different document parts. Different indexes werde based on the full document content, partial content and the title. The best results were achieved for a title only index based on words.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {169–170},
numpages = {2},
keywords = {web retrieval, multi-lingual systems},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

@inproceedings{10.1145/1149941.1149942,
author = {De Bra, Paul and Smits, David and Stash, Natalia},
title = {The Design of AHA!},
year = {2006},
isbn = {1595934170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1149941.1149942},
doi = {10.1145/1149941.1149942},
abstract = {AHA! is an Open Source adaptive hypermedia platform, capable of performing content and link adaptation in (x)html and xml documents. Its development started in 1996. During 10 years of research and development different new presentation, adaptation and user modeling methods and techniques have been added, turning AHA! into a general-purpose adaptive hypermedia platform. This paper presents an overview of the design and architecture of AHA!, with parts that have been published before and with recent additions like style adaptation and a new very flexible link annotation mechanism.Unlike other adaptive hypermedia systems, AHA! is not aimed at a single application area and does not prescribe a single fixed presentation style. Creating applications, defining the user models and the adaptive behavior are all done using graphical authoring tools. End-users are presented with what looks like a normal website, and need not be aware of the adaptation that goes on behind the scenes. Their browsing results in updates to a user model that is stored either in an xml file or a mySQL database, and that is thus also (in principle) available to other applications.Apart from providing a design overview this paper highlights two essential parts of AHA!: the reasoning / rule engine that translates the end-user's actions into user model updates, and the adaptive resource selection, which is used in the conditional inclusion of objects presentation technique and in the conditional link destinations navigation support technique.This paper is itself an adaptive hyperdocument. The order in which the different topics are visited determines the links that are presented and the contents of each (web)page. No matter how you browse through this paper you should end up with a very similar overall impression, and you should have seen all the information the paper contains. However, the actual contents of the pages and the actual link destinations do depend on your browsing order, so different users will not see exactly the same pages and links.Although strictly speaking this paper could be presented using normal linear text, making it an adaptive hyperdocument transforms it from being "just" a paper into being a paper and a demo all in one.},
booktitle = {Proceedings of the Seventeenth Conference on Hypertext and Hypermedia},
pages = {171–195},
numpages = {25},
location = {Odense, Denmark},
series = {HYPERTEXT '06}
}

