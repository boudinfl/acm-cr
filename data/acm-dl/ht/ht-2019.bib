@inproceedings{10.1145/3342220.3345459,
author = {Grigar, Dene},
title = {Tear Down the Walls: An Exhibition of Hypertext &amp; Participatory Narrative},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3345459},
doi = {10.1145/3342220.3345459},
abstract = {What does it mean to reunify different areas of scholarship surrounding hypertext and social media? The response this exhibition offers is: Reunification would include, not only papers by researchers, but also creative output by artists who use various hypertextual strategies and participatory involvement for producing highly experimental narratives. Included in this exhibition, therefore, are eight leading artists from Europe, North America, and Australia who explore 3D animation, mobile technology, hypertext platforms like Storyspace and Twine, and web languages for the purpose of storytelling. Coordinating with the conference theme, the exhibition shows how hypertext and social media can be used for human creative expression and so extends our understanding of these technologies. Works include John Barber &amp; Greg Philbrook, Sound Spheres: Hyper Sound-Based Narratives; Mark Bernstein, Those Trojan Girls; Mez Breeze, A Place Called Ormalcy and V[R]ignettes: A VR Microstories Series; Serge BOUCHARDON and co-authors: Marion Coisnard, Martin Delabre, Maxime Garnier, Huichuan LI, Marie Margerand, Marion Schildknecht, Alexandre Truong, Nicolas Vigne, and Yihui Yang, "fred:-)"; J-B-W-E-L-L, TRAINING TO BE KING WHEN YOU BLOWN IT ONCE ALREADY: A short novel on the crime(s) of usurpation; Judy Malloy, The Yellow Bowl II; and John McDaid, We Knew The Glass Man.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {1},
numpages = {1},
keywords = {mobile narrative, generative hypertext, storyspace, sculptural hypertext, cult novel, vr/xr literature, hypertext fiction, electronic literature, sound-based storytelling, interactive narrative},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344782,
author = {van Dam, Andries},
title = {Reflections on a Half-Century of Hypertext},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344782},
doi = {10.1145/3342220.3344782},
abstract = {2019 marks not only the 30th anniversary of the falling of the Berlin Wall, but also the 50th anniversaries of equally momentous events of 1968-1969 in the US and elsewhere. Martin Luther King and Robert Kennedy were assassinated. Hippie "flower power" and the closely related anti-Vietnam war movement were socio-political revolutions. In Europe, 2019 marks the 100th anniversary of the end of the "war to end all wars" and the 75th anniversary of D-Day. Counterpointing this societal turmoil, technology gave us hope. Neil Armstrong and Buzz Aldrin walked on the moon. Doug Engelbart and his team presented the "Mother of All Demos" of NLS at the '68 Fall Joint Computer Conference. Ivan Sutherland's pioneering Sketchpad (that demo'd interactive graphics in 1963) and Engelbart's NLS demo were two landmark events that were early examples of interactive computing in an era of batch computation. Interactive computing on time-sharing systems, combined with microminiaturization, would lead more than a decade later to the birth of the personal computer. It caused a revolution in the dominant model of computing that was centered on large mainframes and minicomputers used for science and engineering, finance and commerce. Interactive computing based on computer graphics and its use in hypermedia systems characterizes most of my research career. In 2019, it is difficult to remember the impact that interaction-based information structuring and sharing had on society; it certainly shaped my research career. In this presentation, I will reflect on the development of five decades of hypermedia systems and will demo three systems that have been highlights of my journey in hyperland. First, I'll show our FRESS hypertext system (still running 50-year old assembly code!), with the database of poetry used by a class of English students in 1976 in what is arguably the first online scholarly community. Next, I will demo our TAG (Touch Art Gallery) used by the Nobel Foundation a few years ago for a traveling exhibition on Alfred Nobel and all the Nobel Laureates. Finally, I'll interweave the hypertext-centric parts of my talk with some source material stored in an unbounded 2D workspace, using our current hypermedia system Dash, which is still under development and in an early but already useful state. These systems will be presented in the context of the research trends that led, ultimately, to the interconnected society in which we live. All of us working on our first hypertext systems in the '60s understood the potential of this technology. What I did not predict is that 50 years later the revolution in human-centered computing would remain far too unfinished in terms of its positive societal impact. Indeed, that impact and utility are increasingly in jeopardy from a variety of forces, both economic and political. I will close with some thoughts on both deliberately designed and unanticipated societal issues of social media that I feel we technologists must urgently help address.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {3–4},
numpages = {2},
keywords = {societal impact, dash, hypermedia, social media, tag, information structuring tools, fress, hypertext},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344783,
author = {Barnet, Belinda},
title = {Getting Our Bearings},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344783},
doi = {10.1145/3342220.3344783},
abstract = {Navigation is pointless unless you remember where you've been. As we steer full tilt into a horizon line of machine learning, social media, and data analytics, it is time to take our bearings.This is the 30th ACM Hypertext conference, and with that in mind, I've decided to gather some memories from hypertext pioneers about the early vision of those first conferences three decades ago. Where have we been?},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {5},
numpages = {1},
keywords = {computing history, computing, data brokers, augmentation, engelbart, data collection},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344784,
author = {Weber, Manfred},
title = {Tearing Down Walls: The European Way of Life},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344784},
doi = {10.1145/3342220.3344784},
abstract = {Manfred Weber is the leader of the European People's Party (EPP) in the European Parliament. His main political focus is on bringing Europe back to the people and on uniting them behind concrete common ideas for the future of our continent, such as the fight on climate change, a European master plan against cancer and more fairness in a digitalized economy. In his keynote speech he stressed the need for further democratization of the European Union. Only if the people feel involved, we will be able to jointly take up the big challenges of our time and to defend our freedom, our unity and our "European way of life" instead of creating new divisions. 30 years ago, the fall of the Berlin Wall and the Iron Curtain brought freedom and prosperity to the people of Europe. If we want to preserve these huge achievements, we must also break down the walls in other areas or prevent new walls from being built.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {7},
numpages = {1},
keywords = {european union, iron curtain, politics, democratization, europe, berlin wall, freedom, people, citizens, digitalization, epp},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343671,
author = {Alpizar-Chacon, Isaac and Sosnovsky, Sergey},
title = {Expanding the Web of Knowledge: One Textbook at a Time},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343671},
doi = {10.1145/3342220.3343671},
abstract = {Textbooks are educational documents created, structured and formatted in a way that facilitates understanding. Most digital textbooks are released as mere digital copies of their printed counterparts. We present a mechanism that extracts knowledge models from textbooks and enriches their content with additional links (both internal and external). The textbooks essentially become hypertext documents where individual pages are annotated with important concepts in the domain. We also show that extracted models can be automatically connected to the Linked Open Data cloud, which helps further facilitate access, discovery, enrichment, and adaptation of textbook content. Integrating multiple textbooks from the same domain increases the coverage of the composite model while keeping its accuracy relatively high. The overall results of the evaluation show that the proposed approach can generate models of good quality and is applicable across multiple domains.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {9–18},
numpages = {10},
keywords = {dbpedia, named entity disambiguation, textbook, semantic linking, knowledge extraction},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343666,
author = {Bouvin, Niels Olof},
title = {From NoteCards to Notebooks: There and Back Again},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343666},
doi = {10.1145/3342220.3343666},
abstract = {Fifty years since the beginning of the Internet, and three decades of the Dexter Hypertext Reference Model and the World Wide Web mark an opportune time to take stock and consider how hypermedia has developed, and in which direction it might be headed. The modern Web has on one hand turned into a place where very few, very large companies control all major platforms with some highly unfortunately consequences. On the other hand, it has also led to the creation of a highly flexible and nigh ubiquitous set of technologies and practices, which can be used as the basis for future hypermedia research with the rise of computational notebooks as a prime example of a new kind of collaborative and highly malleable applications.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {19–28},
numpages = {10},
keywords = {open hypermedia, world wide web, computational notebooks, computational literacy, end user programming, hypermedia},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343669,
author = {Atzenbeck, Claus and N\"{u}rnberg, Peter J.},
title = {Hypertext as Method},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343669},
doi = {10.1145/3342220.3343669},
abstract = {Historically, there has been a tendency to consider hypertext as a type of system, perhaps characterized by provision of links or other structure to users. In this paper, we consider hypertext as a method of inquiry, a way of viewing arbitrary systems. In this view, what are traditionally called "navigational hypertext systems" might be considered as information retrieval systems, "spatial hypertext systems" as brainstorming systems, etc., while their "hypertext" nature results from the way in which such systems are conceived, developed, and/or presented. The benefit of such a shift is the ability to apply this hypertextual method of inquiry to systems not normally considered part of the hypertext community. In this paper, we specifically apply this view to artificial intelligence, and examine how this application can be productive.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {29–38},
numpages = {10},
keywords = {hypertext history, research communities, structures, intelligence, context, man-machine, infrastructure, hypertext, intellect, augmentation, ai},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343649,
author = {Brooker, Samuel},
title = {Man Proposes, God Disposes: Re-Assessing Correspondences in Hypertext and Anti-Authorist Literary Theory},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343649},
doi = {10.1145/3342220.3343649},
abstract = {Second-wave criticism of literary hypertext fiction (2000-2010) consisted largely of reading studies and alternative semiotic models that challenged first wave assumptions (1992-1999) on empirical grounds. Focus on the phenomenology of reading did not directly question inconsistencies in the correspondence between Continental literary and hypertext theory. This paper argues that philosophical approaches to freedom found respectively in 1960s Continental literary theory and the Bay Area counterculture that influenced early digital computing are incompatible, despite being the foundation for early criticism of literary hypertext fiction. 1960s Continental literary theory emphasised a philosophical liberation from the author, with interpretation a demarcated and sacrosanct space outside the impositions of an author; contemporaneous computer and information science theorists, however, emphasised a framework within which the reader could access knowledge according to their need.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {39–48},
numpages = {10},
keywords = {narrative, hypertext fiction, digital humanities},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343667,
author = {Foradi, Maryam and Ka\ss{}el, Jan and Pein, Johannes and Crane, Gregory R.},
title = {Multi-Modal Citizen Science: From Disambiguation to Transcription of Classical Literature},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343667},
doi = {10.1145/3342220.3343667},
abstract = {The engagement of citizens in the research projects, including Digital Humanities projects, has risen in prominence in recent years. This type of engagement not only leads to incidental learning of participants but also indicates the added value of corpus enrichment via different types of annotations undertaken by users generating so-called smart texts. Our work focuses on the continuous task of adding new layers of annotation to Classical Literature. We aim to provide more extensive tools for readers of smart texts, enhancing their reading comprehension and at the same time empowering the language learning by introducing intellectual tasks, i.e., linking, tagging, and disambiguation. The current study adds a new mode of annotation-audio annotations-to the extensively annotated corpus of poetry by the Persian poet Hafiz. By proposing tasks with three different difficulty levels, we estimate the users' ability of providing correct annotations in order to rate their answers in further stages of the project, where no ground truth data is available. While proficiency in Persian is beneficial, annotators with no knowledge of Persian are also able to add annotations to the corpus.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {49–53},
numpages = {5},
keywords = {user experience design, citizen science, computer assisted language learning (call), smart texts},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343653,
author = {Kitromili, Sofia and Jordan, James and Millard, David E.},
title = {What is Hypertext Authoring?},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343653},
doi = {10.1145/3342220.3343653},
abstract = {Despite a proliferation of hypertext systems used for fiction, and accompanying authoring tools for those systems, relatively few studies have looked at what are the distinct activities involved in hypertext authoring. This has meant that research into authoring tools has not sufficiently targeted specific activities, leading to complexity for users, and confusion over what research findings actually mean. In this paper we present a systematic literature review and analysis of all the papers published in ACM Hypertext (since 1987) and the International Conference on Interactive Digital Storytelling (ICIDS since 2008, and preceding events ICVS and TIDSE 2001-2007) that describe a distinct authoring activity. We discover seventeen papers that between them cover six common activities: Training/Support, Planning, Visualising/Structuring. Writing, Editing, and Compiling/Testing, as well as a seventh category for non-common Advanced activities for specialist domains. Planning and Editing tend to treat structure and content as a duality, while Structuring and Writing treat them as separate aspects of the digital narrative. All six activities have foundations in the Hypertext conference in its first decade, and have seen somewhat of a resurgence of interest in ICIDS in the last decade - although overall numbers are surprisingly low, especially given the size of the proceedings reviewed, indicating how little is known about the human experience of hypertext authoring. Our findings will help structure the work of those studying hypertext authoring and help focus the efforts of those developing new authoring applications.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {55–59},
numpages = {5},
keywords = {authoring, hypertext, interactive fiction, digital interactive storytelling, authoring tools, hypertext fiction},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343645,
author = {G\'{o}mez-Zar\'{a}, Diego and Chiuminatto, Pablo and Nussbaum, Miguel},
title = {Using Multimodal and Hyperlinked Representations of Knowledge as Academic Writing Aids},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343645},
doi = {10.1145/3342220.3343645},
abstract = {Representing knowledge in written papers may be one of the biggest challenges that students face in higher education. This study analyzes how hypermedia structures can facilitate students' critical reflection on their papers by using multimodal resources. By converging academic writing, knowledge representation, and multimedia resources, we designed a hypermedia system that enables the visualization and representation of students' papers using text, images, audio, hyperlinks, and videos. To test the system, we conducted a pilot study in which we instructed 160 undergraduate students to write a paper in the following three-step exercise: First, students submitted an initial draft of their papers. Then, they used the system to translate the papers' content into different multimodal resources. Finally, they rewrote their papers with insights gained from the process. In a concluding survey, students reported that translating text to multimodal resources deepened their understanding of their papers' content and improved their topic organization.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {61–65},
numpages = {5},
keywords = {transmediation process, hypermedia, multimodality, information visualization, text production},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343659,
author = {Ro\ss{}ner, Daniel and Atzenbeck, Claus and Gross, Tom},
title = {Visualization of the Relevance: Using Physics Simulations for Encoding Context},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343659},
doi = {10.1145/3342220.3343659},
abstract = {The task of organizing and retrieving knowledge is often elaborative and involves different types of media including digital or analog. In this paper we describe a system that is based on related research in the fields of spatial hypertext, information retrieval, and visualization. It utilizes a 2D space on which users can add, remove, or manipulate information entities (so-called user nodes) visually. A spatial parser recognizes the evolving structure and queries a knowledge base for helpful other information entities (so-called suggestions nodes). Similar to user nodes, those suggestions are presented as visual objects in the space. We propose a physics model to simulate their behavior. Their characteristics encode the relevance of suggestions to user nodes and to each other. This enables human recipients to interpret the given visual clues and, thus, identify information of interest. The way users organize nodes spatially influences the parsed spatial structures, i.e., the placement of suggestion nodes. This allows the creation of complex queries without any prior knowledge, yet the users do not have to be aware of that, because they can express their thoughts implicitly by manipulating their nodes. We discuss the strengths of a physics based simulation to encode context visually and point to open issues and potential solutions. On the basis of an implemented demonstrator we show the benefits compared to similar and related applications in the field of information visualization, especially when it comes to tasks where a high portion of creativity is involved and the information space is not well known.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {67–76},
numpages = {10},
keywords = {semantics visualization, mother, spatial hypertext},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343655,
author = {Green, Daniel and Hargood, Charlie and Charles, Fred},
title = {Novella 2.0: A Hypertextual Architecture for Interactive Narrative in Games},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343655},
doi = {10.1145/3342220.3343655},
abstract = {The hypertext community has a history of research in Interactive Digital Narrative (IDN), including experimental works and systems to support authoring. Arguably the most prevalent contemporary form of IDN is within the world of computer games where a mixture of large-scale commercial works and smaller indie experimental pieces continue to develop new forms of interactive storytelling. We can explore these pieces through the lens of hypertextual theory and support them with hypertextual architectures, but there are unique challenges within modern game-based storytelling that these frameworks sometimes struggle to capture on a content level, leaving us in some cases with insufficient models and vocabulary. In this paper, we build upon previous work by presenting a discussion on techniques of modeling video game narrative. This is followed by thorough presentation and demonstration of our game-centric theoretical model of interactive narrative, Novella 2.0, which builds upon our previous contributions. This model is then positioned within a novel architecture for the authoring, interchange, integration, and simulation of video game narrative. We present alongside the architecture four key innovations towards supporting game narrative. We include support for Discoverable Narrative and other game narrative content alongside structural features in a deference of responsibility to game engines and our own approach to mixing calligraphic and sculptural hypertext structure.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {77–86},
numpages = {10},
keywords = {interactive narrative, narrative modeling, video games},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343652,
author = {Seng\"{u}n, Sercan and Salminen, Joni and Mawhorter, Peter and Jung, Soon-gyo and Jansen, Bernard},
title = {Exploring the Relationship Between Game Content and Culture-Based Toxicity: A Case Study of League of Legends and MENA Players},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343652},
doi = {10.1145/3342220.3343652},
abstract = {We examine culture- and racial-based toxicity and hate speech in player communities and explore how this toxicity might be informed and affected by the design of the game elements and content. To illustrate these effects, we used a mixed method approach to analyze the experiences of players from the Middle East and North Africa (MENA) regions within the League of Legends (LoL) community as a case study. By qualitatively and quantitatively analyzing more than 2 million lines of in-game chats from 30,000 game sessions on 2 LoL servers and also 89 forum discussions containing hundreds of lines of text, we find that despite the world and characters of LoL being fictional, they are recognized by the player base as having connections to the real-world cultures and, accordingly, they affect the way that players communicate. We provide specific examples of both negative and positive inspirations to elaborate on how the design of certain regions and characters affects the way that the MENA players and issues are received or addressed. Additional analysis of in-game chat data describes other topics where toxic behavior emerges and how these topics correlate.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {87–95},
numpages = {9},
keywords = {league of legends, middle east, online toxicity, gaming culture},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343647,
author = {Rettberg, Jill Walker and Gunderson, Marianne and Kronman, Linda and Solberg, Ragnhild and Stokkedal, Linn Heidi},
title = {Mapping Cultural Representations of Machine Vision: Developing Methods to Analyse Games, Art and Narratives},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343647},
doi = {10.1145/3342220.3343647},
abstract = {Machine vision technologies are increasingly ubiquitous in society and have become part of everyday life. However, the rapid adoption has led to ethical concerns relating to privacy, agency, bias and accuracy. This paper presents the methodology and preliminary results from a digital humanities project that maps and categorises references to and uses of machine vision in digital art, narratives and games in order to find patterns to help us analyse broader cultural understandings of machine vision in society. Understanding the cultural significance and valence of machine vision is crucial for developers of machine vision technologies, so that new technologies are designed to meet general needs and ethical concerns, and ultimately contribute to a better, more just society.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {97–101},
numpages = {5},
keywords = {digital art, network analysis, science fiction, methodology, computer vision, narratives, computer games, machine vision, digital humanities},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343665,
author = {Mason, Stacey and Bernstein, Mark},
title = {On Links: Exercises in Style},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343665},
doi = {10.1145/3342220.3343665},
abstract = {Links are the most important new punctuation mark since the invention of the comma, but it has been years since the last in-depth discussions of link poetics. Taking inspiration Raymond Queneau'sExercices De Style, we explore the poetics of contemporary link usage by offering exercises in which the same piece of text is divided and linked in different ways. We present three different exercises---varying the division of a text into lexia, varying links among lexia, and varying links within lexia---while pointing toward potential aesthetic considerations of each variation. Our exercises are intended descriptively, not prescriptively, as a conversational starting point for analysis and as a compendium of useful techniques upon which artists might build.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {103–110},
numpages = {8},
keywords = {poetics, link poetics, exercises in style, links, hypertext},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343646,
author = {Antonini, Alessio and Gomez Mejia, Gustavo and Lupi, Lucia},
title = {All We Do is "Stalking": Studying New Forms of Reading in Social Networks},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343646},
doi = {10.1145/3342220.3343646},
abstract = {A particular use of the term "stalking" is emerging in social networks to indicate a wide range of reading practices aimed to gain insight on a subject. As a new type of reading, "stalking" does not always have a negative connotation and it is not limited to the personal sphere but ranging from ludic to professional aims. Considering the preliminary results of a case study in the READ-IT project, this contribution wishes to engage the hypertext research community in considering "stalking" as a type of reading activity emerging from the unique features of social networks related both to "stalkers" (as hypertext readers), and to the "stalked" (as a type of contents) within the context of social networking platforms (as a type of medium and environment for reading).},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {111–115},
numpages = {5},
keywords = {profile staking, digital reading, digital humanities, social networks, social media, reading experience},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343654,
author = {Ackermans, Hannah},
title = {Narrating the Sociality of the Database: A Digital Hermeneutic Reading of The Atlas Group Archive and HaikU},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343654},
doi = {10.1145/3342220.3343654},
abstract = {In this paper, I investigate the database characteristics of electronic literature that makes them into social forms. Database structures are both fragmented and relational, displaying hypertext characteristics. I approach The Atlas Group Archive [15] and haikU [24], two works of electronic literature, as examples of material and conceptual databases in order to explore the database function so saturated in our daily life. Both works highlight a database aesthetics [19], although the ways they do so are polar opposites. I analyze the works within the framework of digital hermeneutics [18], continuously considering the relationship between text and context, between parts and whole. I demonstrate how AGA is an explicit database, supposedly showing a 'complete' archive, whereas haikU is an implicit database that hides the corpus of sentences. I show the sociality of the databases, thematizing both the human process behind database formation as a whole, as well as how the individual elements influence the perception of the overall database. Finally, I take my findings to a broader perspective and consider what AGA and haikU can teach us about the materiality, conceptuality, and sociality of the omnipresent structure of the database.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {117–121},
numpages = {5},
keywords = {digital humanities, electronic literature, databases, database narratives, digital hermeneutics},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343643,
author = {Kalyani, Rishita and Gadiraju, Ujwal},
title = {Understanding User Search Behavior Across Varying Cognitive Levels},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343643},
doi = {10.1145/3342220.3343643},
abstract = {The ubiquitous accessibility of the world-wide web has led people to increasingly use web search to learn or acquire new knowledge. Recent research efforts have targeted the optimization of web search to satisfy learning related needs. However, there is little known about how one's search interactions differ across varying cognitive levels that correspond to one's learning. In this paper, we address this knowledge gap by investigating how the search interactions of 150 users vary across 6 search tasks corresponding to distinct cognitive levels. We also analyze how users' knowledge gain varies across the cognitive levels. Our findings suggest that the cognitive learning level of a user in a search session has a significant impact on the user's search behavior and knowledge gain. Estimating the cognitive level of users during their interactions with search systems will allow us to construct and improve learning experiences for the users. For example, learners can be served content that corresponds to their current cognitive level within their learning process.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {123–132},
numpages = {10},
keywords = {information retrieval, web search, learners, analyze, cognitive levels, create, users, understand, cognition, learning, bloom's taxonomy, remember},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343648,
author = {Ramaciotti Morales, Pedro and Tabourier, Lionel and Ung, Sylvain and Prieur, Christophe},
title = {Role of the Website Structure in the Diversity of Browsing Behaviors},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343648},
doi = {10.1145/3342220.3343648},
abstract = {The quantitative measurement of the diversity of information consumption has emerged as a prominent tool in the examination of relevant phenomena such as filter bubbles. This paper proposes an analysis of the diversity of the navigation of users inside a website through the analysis of server log files. The methodology, guided and illustrated by a case study, but easily applicable to other cases, establishes relations between types of users' behavior, site structure, and diversity of web browsing. Using the navigation paths of sessions reconstructed from the log file, the proposed methodology offers three main insights: 1) it reveals diversification patterns associated with the page network structure, 2) it relates human browsing characteristics (such as multi-tabbing or click frequency) with the degree of diversity, and 3) it helps identifying diversification patterns specific to subsets of users. These results are in turn useful in the analysis of recommender systems and in the design of websites when there are diversity-related goals or constrains.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {133–142},
numpages = {10},
keywords = {web-browsing patterns, log analysis, filter bubbles, diversity},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343650,
author = {Koopmann, Tobias and Dallmann, Alexander and Hettinger, Lena and Niebler, Thomas and Hotho, Andreas},
title = {On the Right Track! Analysing and Predicting Navigation Success in Wikipedia},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343650},
doi = {10.1145/3342220.3343650},
abstract = {Understanding and modeling user navigation behaviour in the web is of interest for different applications. For example, e-commerce portals can be adjusted to strengthen customer engagement or information sites can be optimized to improve the availability of relevant content to the user. In web navigation, the users goal and whether she reached it, is typically unknown. This makes navigation games particularly interesting to researchers, since they capture human navigation towards a known goal and allowbuilding labelled datasets suitable for supervised machine learning models. In this work, we show that a recurrent neural network model can predict game success from a partial click trail without knowledge of the users navigation goal. We evaluate our approach on data from WikiSpeedia and WikiGame, two well known navigation games and achieve an AUC of 86% and 90%, respectively. Furthermore, we show that our model outperforms a baseline that leverages the navigation goal on the WikiSpeedia dataset. A detailed analysis of both datasets with regards to structural and content related properties reveals significant differences in navigation behaviour, which confirms the applicability of our approach to different settings.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {143–152},
numpages = {10},
keywords = {user behaviour, user modelling, web navigation},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343668,
author = {Poghosyan, Gevorg and Ifrim, Georgiana},
title = {SocialTree: Socially Augmented Structured Summaries of News Stories},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343668},
doi = {10.1145/3342220.3343668},
abstract = {News story understanding entails having an effective summary of a related group of articles that may span different time ranges, involve different topics and entities, and have connections to other stories. In this work, we present an approach to efficiently extract structured summaries of news stories by augmenting news media with the structure of social discourse as reflected in social media in the form of social tags. Existing event detection, topic-modeling, clustering and summarization methods yield news story summaries based only on noun phrases and named entities. These representations are sensitive to the article wording and the keyword extraction algorithm. Moreover, keyword-based representations are rarely helpful for highlighting the inter-story connections or for reflecting the inner structure of the news story because of high word ambiguity and clutter from the large variety of keywords describing news stories. Our method combines the news and social media domains to create structured summaries of news stories in the form of hierarchies of keywords and social tags, named SocialTree. We show that the properties of social tags can be exploited to augment the construction of hierarchical summaries of news stories and to alleviate the weaknesses of existing keyword-based representations. In our quantitative and qualitative evaluation the proposed method strongly outperforms the state-of-the-art with regard to both coverage and informativeness of the summaries.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {153–162},
numpages = {10},
keywords = {social indexing, news summarizarion, association rules},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343660,
author = {Desouki, Abdelmoneim Amer and R\"{o}der, Michael and Ngonga Ngomo, Axel-Cyrille},
title = {Ranking on Very Large Knowledge Graphs},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343660},
doi = {10.1145/3342220.3343660},
abstract = {Ranking plays a central role in a large number of applications driven by RDF knowledge graphs. Over the last years, many popular RDF knowledge graphs have grown so large that rankings for the facts they contain cannot be computed directly using the currently common 64-bit platforms. In this paper, we tackle two problems: Computing ranks on such large knowledge bases efficiently and incrementally. First, we present \dh{}are, a distributed approach for computing ranks on very large knowledge graphs. \dh{}are assumes the random surfer model and relies on data partitioning to compute matrix multiplications and transpositions on disk for matrices of arbitrary size. Moreover, the data partitioning underlying \dh{}are allows the execution of most of its steps in parallel. As very large knowledge graphs are often updated periodically, we tackle the incremental computation of ranks on large knowledge bases as a second problem. We address this problem by presenting ihare, an approximation technique for calculating the overall ranking scores of a knowledge without the need to recalculate the ranking from scratch at each new revision. We evaluate our approaches by calculating ranks on the $3 times 10^9$ and $2.4 times 10^9$ triples from Wikidata resp. LinkedGeoData. Our evaluation demonstrates that \dh{}are is the first holistic approach for computing ranks on very large RDF knowledge graphs. In addition, our incremental approach achieves a root mean squared error of less than $10^-7 $ in the best case. Both \dh{}are and ihare are open-source and are available at: urlhttps://github.com/dice-group/incrementalHARE.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {163–171},
numpages = {9},
keywords = {random surfer model, ranking rdf, knowledge graphs},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343664,
author = {Rokka Chhetri, Sujit and Goyal, Palash and Canedo, Arquimedes},
title = {Tracking Temporal Evolution of Graphs Using Non-Timestamped Data},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343664},
doi = {10.1145/3342220.3343664},
abstract = {Datasets to study the temporal evolution of graphs are scarce. To encourage the research of novel dynamic graph learning algorithms we introduce YoutubeGraph-Dyn (available at https://github.com/palash1992/YoutubeGraph-Dyn), an evolving graph dataset generated from YouTube real-world interactions. YoutubeGraph-Dyn provides intra-day time granularity (with 416 snapshots taken every 6 hours for a period of 104 days), multi-modal relationships that capture different aspects of the data, multiple attributes including timestamped, non-timestamped, word embeddings, and integers. Our data collection methodology emphasizes the creation of time evolving graphs from non-timestamped data. In this paper, we provide various graph statistics of YoutubeGraph-Dyn and test state-of-the-art graph clustering algorithms to detect community migration, and time series analysis and recurrent neural network algorithms to forecast non-timestamped data.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {173–180},
numpages = {8},
keywords = {social network analysis, machine learning, dynamic graph embedding, dataset},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343651,
author = {Kawase, Ricardo and Diana, Francesca and Czeladka, Mateusz and Sch\"{u}ler, Markus and Faust, Manuela},
title = {Internet Fraud: The Case of Account Takeover in Online Marketplace},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343651},
doi = {10.1145/3342220.3343651},
abstract = {Account takeover is a form of online identity theft where a fraudster gains unauthorized access to an individual's account in a given system. Depending on the system, this unauthorized access can lead to severe consequences of privacy breach and financial loss to the victims, to the companies that maintain the system and to other users. In this paper, we present the work done in order to prevent and detect account takeovers at mobile.de, an online vehicle marketplace. To tackle the prevention problem, we first present a behavioral analysis of how fraudsters operate, and implemented a mutual two-factor authentication that achieved a reduction of 43% of account takeovers. To tackle the detection problem, we introduce a concept drift sensitive machine learning training approach that was able to improve our baseline methods by 18% in detection rates. The automatic detection reduced the exposure of fraudulent listings by 69%, resulting in a safer marketplace for buyers and sellers.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {181–190},
numpages = {10},
keywords = {compromised accounts, internet fraud, online marketplaces, fraud prevention, account takeover, fraud detection, mutual two-factor authentication},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343663,
author = {Wobbrock, Jacob O. and Hsu, Anya K. and Burger, Marijn A. and Magee, Michael J.},
title = {Isolating the Effects of Web Page Visual Appearance on the Perceived Credibility of Online News among College Students},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343663},
doi = {10.1145/3342220.3343663},
abstract = {Online news sources have transformed civic discourse, and much has been made of their credibility. Although web page credibility has been investigated generally, most work has focused on the credibility of web page content. In this work, we study the isolated appearance of news-like web pages. Specifically, we report on a laboratory experiment involving 31 college students rating the perceived credibility of news-like web pages devoid of meaningful content. These pages contain only "lorem ipsum" text, indistinct videos and images, non-functional links, and various font settings. Our findings show that perceived credibility is indeed affected by some purely presentational factors. Specifically, video presence increased credibility, while large fonts and having no images reduced credibility. Having a few, but not too many, images increased credibility for short articles, especially in the presence of large fonts. We also conducted follow-up interviews, which revealed that participants noticed images, videos, and font sizes when making credibility judgments, corroborating our quantitative experimental results.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {191–200},
numpages = {10},
keywords = {video, trust, web page, fonts, visual presentation, content, visual appearance, believability, online news, credibility, images},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343670,
author = {Huang, Dongchen and Zhu, Yige and Mustafaraj, Eni},
title = {How Dependable Are "First Impressions" to Distinguish between Real and Fake NewsWebsites?},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343670},
doi = {10.1145/3342220.3343670},
abstract = {In an increasingly information-dense web, how do we ensure that we do not fall for unreliable information? To design better web literacy practices for assessing online information, we need to understand how people perceive the credibility of unfamiliar websites under time constraints. Would they be able to rate real news websites as more credible and fake news websites as less credible? We investigated this research question through an experimental study with 42 participants (mean age = 28.3) who were asked to rate the credibility of various "real news'' (n = 14) and "fake news'' (n = 14) websites under different time conditions (6s, 12s, 20s), and with a different advertising treatment (with or without ads). Participants did not visit the websites to make their credibility assessments; instead, they interacted with the images of website screen captures, which were modified to remove any mention of website names, to avoid the effect of name recognition. Participants rated the credibility of each website on a scale from 1 to 7 and in follow-up interviews provided justifications for their credibility scores. Through hypothesis testing, we find that participants, despite limited time exposure to each website (between 6 and 20 seconds), are quite good at the task of distinguishing between real and fake news websites, with real news websites being overall rated as more credible than fake news websites. Our results agree with the well-known theory of "first impressions'' from psychology, that has established the human ability to infer character traits from faces. That is, participants can quickly infer meaningful visual and content cues from a website, that are helping them make the right credibility evaluation decision.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {201–210},
numpages = {10},
keywords = {web literacy, advertising, fake news websites, real news websites, website credibility, experimental study, first impression, halo effect},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343644,
author = {Gadiraju, Ujwal and Demartini, Gianluca},
title = {Understanding Worker Moods and Reactions to Rejection in Crowdsourcing},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343644},
doi = {10.1145/3342220.3343644},
abstract = {Requesters on crowdsourcing platforms typically exercise the power to decide the fate of tasks completed by crowd workers. Rejecting work has a direct impact on workers; (i) they may not be rewarded for the work completed and for their effort that has been exerted, and (ii) rejection affects worker reputation and may limit their access to future work opportunities. This paper presents a comprehensive study that aims to understand worker moods and how workers react to rejections in microtask crowdsourcing. We experimentally investigate the effect of the mood of workers on their performance, and the interaction of their moods with their reactions to rejection. Finally, we explore techniques such as presenting social comparative explanations to foster positive reactions to rejection. We found that workers in pleasant moods significantly outperform those in unpleasant moods. Workers whose work is rejected due to narrowly failing pre-screening tests exhibited the most negative emotional responses.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {211–220},
numpages = {10},
keywords = {mood, performance, rejection sensitivity, rejection, accuracy, emotion, crowdsourcing, microtasks},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343642,
author = {Simko, Jakub and Hanakova, Martina and Racsko, Patrik and Tomlein, Matus and Moro, Robert and Bielikova, Maria},
title = {Fake News Reading on Social Media: An Eye-Tracking Study},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343642},
doi = {10.1145/3342220.3343642},
abstract = {The online spreading of fake news (and misinformation in general) has been recently identified as a major issue threatening entire societies. Much of this spreading was enabled by new media formats, namely social networks and online media sites. Researchers and practitioners have been trying to answer this by characterizing the fake news and devising automated methods for detecting them. The detection methods had so far only limited success, mostly due to the complexity of the news content and context and lack of properly annotated datasets. One possible way to boost the efficiency of automated misinformation detection methods, is to imitate the detection work of humans. In a broader sense of dealing with fake news spreading, it is also important to understand the news consumption behavior of online users. In this paper, we present an eye-tracking study, in which we let 44 participants to casually read through a social media feed containing posts with news articles. Some of the presented articles were fake. In a second run, we asked the participants to decide on the truthfulness of these articles. We present the description of the study, characteristics of the resulting dataset (which we hereby publish) and several findings.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {221–230},
numpages = {10},
keywords = {reading, misinformation, eye tracking, social media, fake news, user study},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343656,
author = {Sales, Allan and Balby, Leandro and Veloso, Adriano},
title = {Media Bias Characterization in Brazilian Presidential Elections},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343656},
doi = {10.1145/3342220.3343656},
abstract = {News media bias is commonly associated with framing information so as to influence readers judgments. One way to expose such bias is to compare different news outlets on the same stories and look for divergences. In this paper, we investigate news media bias in the context of Brazilian presidential elections by comparing four popular news outlets during three consecutive election years (2010, 2014, and 2018). We analyse the textual content of news stories in search for three kinds of bias: coverage, association, and subjective language. Coverage bias has to do with differences in mention rates of candidates and parties. Association bias occurs when, for example, one candidate is associated with a negative concept while another not. Subjective bias, in turn, has to do with wording that attempts to influence the readers by appealing to emotion, stereotypes, or persuasive language. We perform a thorough analysis on a large scale news data set where several of such biases are exposed.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {231–240},
numpages = {10},
keywords = {brazilian presidential elections, news outlets, coverage, subjectivity, association, media bias, text processing},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343661,
author = {Badache, Ismail},
title = {Users' Traces for Enhancing Arabic Facebook Search},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343661},
doi = {10.1145/3342220.3343661},
abstract = {This paper proposes an approach on Facebook search in Arabic, which exploits several users' traces (e.g. comment, share, reactions) left on Facebook posts to estimate their social importance. Our goal is to show how these social traces (signals) can play a vital role in improving Arabic Facebook search. Firstly, we identify polarities (positive or negative) carried by the textual signals (e.g. comments) and non-textual ones (e.g. the reactions love and sad) for a given Facebook post. Therefore, the polarity of each comment expressed on a given Facebook post, is estimated on the basis of a neural sentiment model in Arabic language. Secondly, we group signals according to their complementarity using features selection algorithms. Thirdly, we apply learning to rank (LTR) algorithms to re-rank Facebook search results based on the selected groups of signals. Finally, experiments are carried out on 13,500 Facebook posts, collected from 45 topics in Arabic language. Experiments results reveal that Random Forests combined with ReliefFAttributeEval (RLF) was the most effective LTR approach for this task.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {241–245},
numpages = {5},
keywords = {sentiment analysis, user generated content, facebook search},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343657,
author = {Trevisan, Martino and Vassio, Luca and Drago, Idilio and Mellia, Marco and Murai, Fabricio and Figueiredo, Flavio and Couto da Silva, Ana Paula and Almeida, Jussara M.},
title = {Towards Understanding Political Interactions on Instagram},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343657},
doi = {10.1145/3342220.3343657},
abstract = {Online Social Networks (OSNs) allow personalities and companies to communicate directly with the public, bypassing filters of traditional medias. As people rely on OSNs to stay up-to-date, the political debate has moved online too. We witness the sudden explosion of harsh political debates and the dissemination of rumours in OSNs. Identifying such behaviour requires a deep understaning on how people interact via OSNs during political debates. We present a preliminary study of interactions in a popular OSN, namely Instagram. We take Italy as a case study in the period before the 2019 European Elections. We observe the activity of top Italian Instagram profiles in different categories: politics, music, sport and show. We record their posts for more than two months, tracking "likes'' and comments from users. Results suggest that profiles of politicians attract markedly different interactions than other categories. People tend to comment more, with longer comments, debating for longer time, with a large number of replies, most of which are not explicitly solicited. Moreover, comments tend to come from a small group of very active users. Finally, we witness substantial differences when comparing profiles of different parties.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {247–251},
numpages = {5},
keywords = {online social networks, politics, instagram, user behaviour},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343658,
author = {Knoche, Markus and Popovi\'{c}, Radomir and Lemmerich, Florian and Strohmaier, Markus},
title = {Identifying Biases in Politically Biased Wikis through Word Embeddings},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343658},
doi = {10.1145/3342220.3343658},
abstract = {With the increase of biased information available online, the importance of analysis and detection of such content has also significantly risen. In this paper, we aim to quantify different kinds of social biases using word embeddings. Towards this goal we train such embeddings on two politically biased MediaWiki instances, namely RationalWiki and Conservapedia. Additionally we included Wikipedia as an online encyclopedia, which is accepted by the general public. Utilizing and combining state-of-the-art word embedding models with WEAT and WEFAT, we display to what extent biases exist in the above-mentioned corpora. By comparing embeddings we observe interesting differences between different kinds of wikis.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {253–257},
numpages = {5},
keywords = {weat, stereotypes, conservapedia, embeddings, rationalwiki, bias},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3343662,
author = {Soliman, Ahmed and Hafer, Jan and Lemmerich, Florian},
title = {A Characterization of Political Communities on Reddit},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343662},
doi = {10.1145/3342220.3343662},
abstract = {The social news aggregator Reddit is among the most popular websites on the internet. Many online users use the platform to anonymously share and discuss (mostly US-centric) political content. In this ongoing work, we perform a comparative large-scale analysis of political subcommunities (subreddits) on Reddit using a dataset of more than 100 million posts from around 5 million users. In particular, we investigate these communities with respect to (1) the content posted, (2) their relationships to other subreddits, and (3) the distribution of attention received in these subcommunities. We find that left-leaning communities use derogatory language less often than right-leaning communities, but are more focused on news sources reflecting their own political leaning. We also observe that right-leaning communities are more interconnected with right-leaning subreddits on European politics. Finally, the attention of individual submissions (as measured by their number of up-votes or comments received) is spread more evenly in right-leaning communities.The social news aggregator Reddit is among the most popular websites on the internet. Many online users use the platform to anonymously share and discuss (mostly US-centric) political content. In this ongoing work, we perform a comparative large-scale analysis of political subcommunities (subreddits) on Reddit using a dataset of more than 100 million posts from around 5 million users. In particular, we investigate these communities with respect to (1) the content posted, (2) their relationships to other subreddits, and (3) the distribution of attention received in these subcommunities. We find that left-leaning communities use derogatory language less often than right-leaning communities, but are more focused on news sources reflecting their own political leaning. We also observe that right-leaning communities are more interconnected with right-leaning subreddits on European politics. Finally, the attention of individual submissions (as measured by their number of up-votes or comments received) is spread more evenly in right-leaning communities.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {259–263},
numpages = {5},
keywords = {politics, reddit},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344937,
author = {Hsu, Bay-Yuan and Tu, Chia-Lin and Chang, Ming-Yi and Shen, Chih-Ya},
title = {On Crawling Community-Aware Online Social Network Data},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344937},
doi = {10.1145/3342220.3344937},
abstract = {In this paper, we make our first attempt to address this issue by proposing a new research problem to identify a group of users from the OSN, such that the group is a socially tight community and the users' willingness of data contribution is maximized. We propose an effective algorithm, named Community-aware Group Identification with Maximum Willingness (CIW). We conduct extensive experiments on multiple real datasets, and the proposed CIW outperforms the other baselines in terms of both solution quality and efficiency.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {265–266},
numpages = {2},
keywords = {crawling, social networks, willingness},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344921,
author = {Mamo, Nicholas and Azzopardi, Joel and Layfield, Colin},
title = {ELD: Event TimeLine Detection -- A Participant-Based Approach to Tracking Events},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344921},
doi = {10.1145/3342220.3344921},
abstract = {People all over the world talk as events unfold, but what does it take for a machine to truly track an event? Event TimeLine Detection (ELD) is a real-time Topic Detection and Tracking (TDT) solution to track events using Twitter with the hypothesis that it takes a deeper understanding of the event's domain for a machine to describe its evolution.In ELD, understanding takes the form of identifying the participants that would eventually drive the event's evolution. We propose Automatic Participant Detection (APD) as a way of identifying event participants, which ELD then tracks during the proceedings. TDT then mines the resulting Twitter stream, extracting developments and describing them as a timeline using a summarization algorithm.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {267–268},
numpages = {2},
keywords = {automatic participant detection, twitter, breaking news, summarization, topic detection and tracking},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344922,
author = {Vo\ss{}, Jakob},
title = {An Infrastructure-Agnostic Model of Hypertext},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344922},
doi = {10.1145/3342220.3344922},
abstract = {This short paper summarizes a new interpretation of the original vision of hypertext: infrastructure-agnostic hypertext is independent from specific formats and protocols. References to existing technologies for implementations are included nevertheless.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {269–270},
numpages = {2},
keywords = {hypermedia, xanadu, hyperdata, transclusion, documents},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344923,
author = {Ho, Justin Chun-Ting},
title = {Assessing the Bias of Facebook's Graph API},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344923},
doi = {10.1145/3342220.3344923},
abstract = {Facebook research has proliferated during recent years. However, Facebook has introduced a new limitation on the maximum amount of page posts retrievable through the Graph API in November 2017 while there is limited documentation on how these posts are selected. This paper compares two datasets of the same Facebook page, a full dataset obtained before the introduction of the limitation and a partial dataset obtained after, and employs bootstrapping technique to assess the bias caused by the limitation. This paper demonstrates that posts with high user engagement, Photo posts, and Video posts are over-represented while Link posts are under-represented. Top term analysis reveals that there are significant differences in the most prominent terms between the full and partial dataset. This paper also reverse engineered the new API's ranking algorithm to identify the features of a post that would affect its odds of being selected.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {271–272},
numpages = {2},
keywords = {api, bias detection, data mining, facebook, social media},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344924,
author = {Vieira, Augusto and Brand\~{a}o, Wladmir},
title = {Evaluating Acceptance of Video Games Using Convolutional Neural Networks for Sentiment Analysis of User Reviews},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344924},
doi = {10.1145/3342220.3344924},
abstract = {Video game and interactive media are currently among the most profitable industries in the world. In this competitive marketing, game producers are interested in designing products with aspects that increase user acceptance, such as a well written story, stable servers for multiplayer games, and fluid combat mechanics. Although user-expressed feelings about game aspects seem to correlate with user acceptance, sentiment analysis is under-exploited for video games user acceptance evaluation. In this poster, we propose an approach to evaluate the user acceptance of video games by using convolutional neural networks for aspect-based sentiment analysis of user text reviews.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {273–274},
numpages = {2},
keywords = {opinion mining, video game, sentiment analysis, machine learning, game acceptance, neural network},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344925,
author = {Beigi, Ghazaleh and Shu, Kai and Guo, Ruocheng and Wang, Suhang and Liu, Huan},
title = {Privacy Preserving Text Representation Learning},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344925},
doi = {10.1145/3342220.3344925},
abstract = {Online users generate tremendous amounts of textual information by participating in different online activities. This data provides opportunities for researchers and business partners to understand individuals. However, this user-generated textual data not only can reveal the identity of the user but also may contain individual's private attribute information. Publishing the textual data thus compromises the privacy of users. It is challenging to design effective anonymization techniques for textual information which minimize the chances of re-identification and does not contain private information while retaining the textual semantic meaning. In this paper, we study this problem and propose a novel double privacy preserving text representation learning framework, DPText. We show the effectiveness of DPText in preserving privacy and utility.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {275–276},
numpages = {2},
keywords = {adversarial learning, differential privacy, utility, text representation},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344926,
author = {Flores-Saviaga, Claudia and Hammer, Jessica and Flores, Juan Pablo and Seering, Joseph and Reeves, Stuart and Savage, Saiph},
title = {Audience and Streamer Participation at Scale on Twitch},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344926},
doi = {10.1145/3342220.3344926},
abstract = {Large-scale streaming platforms such as Twitch are becoming increasingly popular, but detailed audience-streamer interaction dynamics remain unexplored at scale. In this paper, we perform a mixed methods study on a dataset with over 12 million audience chat messages and 45 hours of streamed video to understand audience participation and streamer performance on Twitch. We uncover five types of streams based on size and audience participation styles, from small streams with close streamer-audience interactions to massive streams with the stadium-style audiences. We discuss challenges and opportunities emerging for streamers and audiences from each style and conclude by providing data-backed design implications that empower streamers, audiences, live streaming platforms, and game designers.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {277–278},
numpages = {2},
keywords = {audience participation, games, data analysis, twitch},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344927,
author = {Patro, Jasabanta and Baruah, Sabyasachee and Gupta, Vivek and Choudhury, Monojit and Goyal, Pawan and Mukherjee, Animesh},
title = {Characterizing the Spread of Exaggerated Health News Content over Social Media},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344927},
doi = {10.1145/3342220.3344927},
abstract = {In this paper, we consider a dataset comprising press releases about health research from different universities in the UK along with a corresponding set of news articles. We find that tweets sharing exaggerated news have a significantly different linguistic structure from those that share non-exaggerated news.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {279–280},
numpages = {2},
keywords = {exaggeration characterization, tweet analysis},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344928,
author = {Procaci, Thiago Baesso and Siqueira, Sean and Pereira Nunes, Bernardo and Gadiraju, Ujwal},
title = {How Do Outstanding Users Differ From Other Users in Q&amp;A Communities?},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344928},
doi = {10.1145/3342220.3344928},
abstract = {This paper reports on an investigation into outstanding and ordinary users of two Question &amp; Answer (Q&amp;A) communities. Considering some behavior perspectives such as participation, linguistic traits, social ties, influence, and focus, we found that outstanding users (i) are more likely to engage in discussions; (ii) tend to use more sophisticated linguistic traits; (iii) generate longer debates; (iv) value the diversity of their connections; and (v) participate in several topics, rather than one specialist niche. These findings allow us to use behavioral patterns to predict if a given user is outstanding and predict which answer gives a definitive solution for a question. Then, we present two feature learning methods to automatically generate the inputs for the prediction model to classify users as outstanding or ordinary. Our feature learning approaches outperformed related methods and generated competitive results when compared to feature engineering based on behavioral patterns.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {281–282},
numpages = {2},
keywords = {learning behavior, interaction analysis, graph analysis, machine learning, q&amp;a community analysis},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344929,
author = {Mishra, Shubhanshu},
title = {Multi-Dataset-Multi-Task Neural Sequence Tagging for Information Extraction from Tweets},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344929},
doi = {10.1145/3342220.3344929},
abstract = {Multi-task learning is effective in reducing the required data for learning a task, while ensuring competitive accuracy with respect to single task learning. We study effectiveness of multi-dataset-multi-task learning in training neural models for four sequence tagging tasks for Twitter data, namely, part of speech (POS) tagging, chunking, super sense tagging, and named entity recognition (NER). We utilize -- 7 POS, 10 NER, 1 Chunking, and 2 super sense -- tagged publicly available datasets. We use a multi-dataset-multi-task neural model based on pre-trained contextual text embeddings and compare it against single-dataset-single-task, and multi-dataset-single-task models. Even within a task, the tagging schemes may differ across datasets. The model learns using this tagging diversity across all datasets for a task. The models are more effective compared to single data/task models, leading to significant improvements for POS (1-2% acc., 7 datasets), NER (1-10% F1, 9 datasets), and chunking (4%). For super sense tagging there is 2% improvement in F1 for out of domain data. Our models and tools can be found at https://socialmediaie.github.io/},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {283–284},
numpages = {2},
keywords = {multitask learning, part of speech tagging, machine learning, open source tool, information extraction, deep learning, open data, twitter, supersense tagging, chunking, named entity recognition, social media},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344930,
author = {Ghosh Chowdhury, Arijit and Didolkar, Aniket and Sawhney, Ramit and Ratn Shah, Rajiv},
title = {Beyond Hostile Linguistic Cues: The Gravity of Online Milieu for Hate Speech Detection in Arabic},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344930},
doi = {10.1145/3342220.3344930},
abstract = {Religious Hate speech poses grave dangers for the cohesion of a democratic society, the protection of human rights and the rule of law. While previous work has shown that linguistic features can be effectively used for text categorization in Arabic, employing information coming from users` social networks has not yet been explored for such complex user characteristics. Systems relying on language information tend to have low precision because they tend to rely on messages containing particular terms indicating hate speech. In this paper, we study the novel problem of exploiting social context for detection of religious hate speech in Arabic tweets, given information extracted from their online milieu by learning a low-dimensional vector representation of users.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {285–286},
numpages = {2},
keywords = {social media, social networks, arabic-nlp, hate speech},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344931,
author = {Goyal, Nidhi and Sachdeva, Niharika and Choudhary, Vijay and Kar, Rijula and Kumaraguru, Ponnurangam and Rajput, Nitendra},
title = {Con2KG-A Large-Scale Domain-Specific Knowledge Graph},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344931},
doi = {10.1145/3342220.3344931},
abstract = {This paper presents Con2KG, a large-scale recruitment domain Knowledge Graph that describes 4 million triples as facts from 250 thousands of unstructured data of job postings. We propose a novel framework for Knowledge Graph construction from unstructured text and an unsupervised, dynamically evolving ontology that helps Con2KG to capture hierarchical links between the entities missed by explicit relational facts in the triples. To enrich our graph, we include entity context and its polarity. Towards this end, we discuss Con2KG applications that may benefit the recruitment domain.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {287–288},
numpages = {2},
keywords = {recruitment domain, knowledge graph, natural language processing},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344932,
author = {Frank, Ingo},
title = {Rewriting History: Towards Diagrammatic Hypertext for Digital Historiography},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344932},
doi = {10.1145/3342220.3344932},
abstract = {It is argued that historians should make explicit their causal claims in their narrative explanations for better communication of research findings. The poster presents experiments for an approach towards visual historiography to support historical understanding. A case study from historical sociology demonstrates the added value of diagrammatic representation of causal narratives. The advantage of using diagrams with a hypertextual approach is that idiographic details can still be communicated through textual information in the hypertext nodes due to multimodal combination of diagram and written language. I suggest a semantic wiki with suitable domain ontologies as a tool for structured writing---i.,e. modeling---of causal processes as described in causal narratives. As the approach enables the (re)presentation of history as diagram by means of diagrammatic reasoning according to Peircean semiotics I propose the label diagrammatic hypertext.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {289–290},
numpages = {2},
keywords = {multiperspectivity, historical understanding, narrative explanation, digital history, diagrammatic hypertext, visual historiography},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344933,
author = {Almerekhi, Hind and Kwak, Haewoon and Jansen, Bernard J. and Salminen, Joni},
title = {Detecting Toxicity Triggers in Online Discussions},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344933},
doi = {10.1145/3342220.3344933},
abstract = {Despite the considerable interest in the detection of toxic comments, there has been little research investigating the causes -- i.e., triggers -- of toxicity. In this work, we first propose a formal definition of triggers of toxicity in online communities. We proceed to build an LSTM neural network model using textual features of comments, and then, based on a comprehensive review of previous literature, we incorporate topical and sentiment shift in interactions as features. Our model achieves an average accuracy of 82.5% of detecting toxicity triggers from diverse Reddit communities.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {291–292},
numpages = {2},
keywords = {toxicity, trigger detection, neural networks, social media, reddit},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344934,
author = {Hadgu, Asmelash Teka and Gundam, Jayanth Kumar Reddy},
title = {User Identity Linking Across Social Networks by Jointly Modeling Heterogeneous Data with Deep Learning},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344934},
doi = {10.1145/3342220.3344934},
abstract = {People have presence across different information networks on the social web. The problem of user identity linking, is the task of establishing a connection between accounts of the same user across different networks. Solving this problem is useful for: personalized recommendations, cross platform data enrichment and verifying online information among others. In this paper, we propose a deep learning based approach that jointly models heterogeneous data: text content, network structure as well as profile names and images, in order to solve the user identity linking problem. We perform experiments on a real world problem of connecting the social profile (Twitter) and academic profile (DBLP) of researchers. Our experimental results show that our joint model outperforms state-of-the-art results that consider profile, content or network features only.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {293–294},
numpages = {2},
keywords = {user identity linking, deep learning, social network},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344935,
author = {Deshmukh, Ajita},
title = {Measuring the Elusive Engagement in an Academic Facebook Group},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344935},
doi = {10.1145/3342220.3344935},
abstract = {This poster presents the measurement of student engagement in a Facebook group for higher secondary school used as an educational scaffold. This mixed method research uses the student engagement instrument (SEI), adapted for the online environment. The inadequacies of social media analytics necessitated the use of the self-reported tool to measure student engagement in the Facebook group further triangulated by the focus group discussions. Thus, this study calls for comprehensive social media analytics that go beyond 'views', 'likes' and comments as a measure of engagement.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {295–296},
numpages = {2},
keywords = {facebook, online scaffold, social media analytics., online engagement},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3344936,
author = {Maenishi, Taka and Tajima, Keishi},
title = {Identifying Tags Describing Image Contents},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3344936},
doi = {10.1145/3342220.3344936},
abstract = {On many photo-sharing social media, e.g., Instagram, a user posting a photo can add tags, i.e., words describing it. Tags are used for keyword-based image search. Some tags, however, describe not image contents but some metadata, e.g., camera names. We propose a method of determining which tag is more likely to describe the associated image contents. We determine it based on pairwise comparisons of tags. Given a pair of tags A and B, we compare three sets of images: (1) those associated with A, (2) those associated with B, and (3) those associated with both A and B. If (3) is more similar to (1) than to (2), A is more likely to describe image contents. Our experiment with Instagram data shows that our method is effective.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {297–298},
numpages = {2},
keywords = {image captioning, tag ranking, image tags, social tagging},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3345458,
author = {Bernstein, Mark},
title = {48 Hour Hypertext Challenge},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3345458},
doi = {10.1145/3342220.3345458},
abstract = {A challenge was issued to members of the hypertext research community to create a complete hypertext fiction in no more than 48 hours of work. Writers were asked to submit the work as well as short reflections on issues of craft and technique they encountered in the course of the project. We expect the results of the challenge will present an opportunity for an engaging panel that could influence hypertext writing, pedagogy and technology.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {299–300},
numpages = {2},
keywords = {fiction, hypertext, experience},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3349530,
author = {Augstein, Mirjam and Herder, Eelco and W\"{o}rndl, Wolfgang and Yigitbas, Enes},
title = {ABIS 2019 - 23rd International Workshop on Personalization and Recommendation on the Web and Beyond},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3349530},
doi = {10.1145/3342220.3349530},
abstract = {ABIS 2019 is an international workshop, organized by the SIG on Adaptivity and User Modeling of the German Gesellschaft f\"{u}r Informatik. For more than 20 years, the ABIS Workshop has been a highly interactive forum for discussing the state of the art in personalization and user modeling. Latest developments in industry and research are presented in plenary sessions, forums, and tutorials. Related ABIS 2019 Workshop Proceedings are available in the ACM DL at: urlhttps://dl.acm.org/citation.cfm?id=3345002},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {301–302},
numpages = {2},
keywords = {user modeling, human-computer interaction, personalization, recommendation},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3349531,
author = {Rubart, Jessica and Atzenbeck, Claus},
title = {2nd Workshop on Human Factors in Hypertext (HUMAN '19)},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3349531},
doi = {10.1145/3342220.3349531},
abstract = {HUMAN '19 is the second workshop of a new series for the ACM Hypertext conferences. It has a strong focus on the user and thus is complementary to the strong machine analytics research direction that could be experienced in previous conferences. The user-centric view on hypertext not only includes user interfaces and interaction, but also discussions about hypertext application domains. Furthermore, the workshop raises the question of how original hypertext ideas (e.g., Doug Engelbart's "augmenting human intellect" or Frank Halasz' "hypertext as a medium for thinking and communication") can improve today's hypertext systems.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {303–304},
numpages = {2},
keywords = {intercultural aspects, user interaction, user interfaces, augmentation, digital humanities, human factors, hypermedia, user-centric, hypertext, cognitive aspects, collaboration, adaptive hypertext, communication, annotation, information structuring, decision making},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3349532,
author = {Gadiraju, Ujwal and Bohlouli, Mahdi and Demartini, Gianluca and Margaryan, Anoush},
title = {JobNoW'19 - 1st International Workshop on Job Knowledge Discovery on the Web &amp; Social Media},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3349532},
doi = {10.1145/3342220.3349532},
abstract = {To gain insights into labor demands or supply, researchers and policymakers have traditionally relied on interviews, trade publications, surveys, and vacancies. Although such traditional data sources have some clear advantages, they are also characterized by limitations that can be addressed by using web-based data available in abundance.The scope of this workshop includes the vision of an open 'job knowledge base' that can be used by employers, employees, job seekers, labor market experts and policy makers. Such a knowledge base could contain different types of information such as responsibilities and roles, required competences, that could be used to develop trainings and identify priorities, wage information, geographical and demographic trends, cultural issues, demands of the job markets in different domains, job announcement information and rates, job popularity and other useful labor market dynamics. This workshop aims at identifying the challenges for job knowledge discovery, and proposing solutions to overcome these challenges. Due to the compelling human factors that play a vital role in decision-making processes related to job search, job satisfaction, etc. we are particularly interested in inter-disciplinary approaches that can support job knowledge discovery.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {305–306},
numpages = {2},
keywords = {job knowledge, job posting, web data, social media, job search, employers, labor market},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3349533,
author = {Hargood, Charlie and Millard, David E. and Bernstein, Mark},
title = {NHT'19: Narrative and Hypertext 2019},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3349533},
doi = {10.1145/3342220.3349533},
abstract = {NHT is a continuing workshop series associated with the ACM Hypertext conference. The workshop acts as forum of discussion for the narrative systems community within the wider audience of the Hypertext conference. The workshop runs both presentations from authors of accepted short research papers, panel discussions of experts, and unstructured unconference sessions to provide a venue for important discussions of issues facing and opportunities for members of the narrative and hypertext community.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {307–308},
numpages = {2},
keywords = {digital storytelling, narrative, hypertext, interactive narrative, games, authoring tools},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3342220.3349535,
author = {Di Caro, Luigi and Cataldi, Mario and Schifanella, Claudio},
title = {SIDEWAYS'19: 5th International Workshop on Social Media World Sensors},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3349535},
doi = {10.1145/3342220.3349535},
abstract = {Social media services represent freely-accessible social networks allowing registered members to broadcast short posts referring to a potentially-unlimited range of topics, by also exploiting the immediateness of handy smart devices. This workshop wanted to stress the vision of this powerful communication channel as a social sensor, which can be used to detect and characterize interesting and yet unreported information and events in real time, crossing all topics and locations. Future technologies on this connectivity may also provide applications with automatic techniques for the generation of news (filtered over user profiles), offering a sideways to the existing authoritative information media.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {309–310},
numpages = {2},
keywords = {social networks, social media, web platforms, natural language processing, trend detection, topic detection, machine learning, social sensors, data analysis, analytics},
location = {Hof, Germany},
series = {HT '19}
}

