@inproceedings{10.1145/3078714.3078750,
author = {Lerman, Kristina},
title = {A Meme is Not a Virus: The Role of Cognitive Heuristics in Information Diffusion},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078750},
doi = {10.1145/3078714.3078750},
abstract = {The many decisions people make about what information to consume affect emerging trends, their popularity, and the diffusion of information through online social networks. Due to constraints of available time and cognitive resources, the ease of discovery strongly affects how people allocate their attention. Through empirical analysis and online experiments, I measure the impact of cognitive biases on collective attention. I show that position of information in the user interface strongly determines whether it is seen, while explicit signals about its popularity increases the likelihood of response. Accounting for these factors simplifies dynamics of information diffusion, allows for more accurate prediction of social behavior, and explains why most memes fail to spread widely online.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {1},
numpages = {1},
keywords = {social media, cognitive biases, information diffusion},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078751,
author = {Mika, Peter},
title = {What Happened To The Semantic Web?},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078751},
doi = {10.1145/3078714.3078751},
abstract = {The idea of the Semantic Web has surfaced in the literature over 20 years ago, and this area has been a major focus of academic research and standardisation for almost as long. In this talk, we look back at the history of the Semantic Web. We discuss what the original aspirations of its creators were, and what has been achieved in practice in these two decades. We also seek to find where the Semantic Web has failed and succeeded, illustrated by usage in web search, e-commerce and online media. Further, we will attempt to understand whether it makes sense to pursue at least some of these ideas in a different age, with new opportunities brought about by recent developments in Big Data, cloud computing, and Deep Learning.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {3},
numpages = {1},
keywords = {linked data, ontology, semantic web},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078715,
author = {Gadiraju, Ujwal and Yang, Jie and Bozzon, Alessandro},
title = {Clarity is a Worthwhile Quality: On the Role of Task Clarity in Microtask Crowdsourcing},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078715},
doi = {10.1145/3078714.3078715},
abstract = {Workers of microtask crowdsourcing marketplaces strive to find a balance between the need for monetary income and the need for high reputation. Such balance is often threatened by poorly formulated tasks, as workers attempt their execution despite a sub-optimal understanding of the work to be done.In this paper we highlight the role of clarity as a characterising property of tasks in crowdsourcing. We surveyed 100 workers of the CrowdFlower platform to verify the presence of issues with task clarity in crowdsourcing marketplaces, reveal how crowd workers deal with such issues, and motivate the need for mechanisms that can predict and measure task clarity. Next, we propose a novel model for task clarity based on the goal and role clarity constructs. We sampled 7.1K tasks from the Amazon mTurk marketplace, and acquired labels for task clarity from crowd workers. We show that task clarity is coherently perceived by crowd workers, and is affected by the type of the task. We then propose a set of features to capture task clarity, and use the acquired labels to train and validate a supervised machine learning model for task clarity prediction. Finally, we perform a long-term analysis of the evolution of task clarity on Amazon mTurk, and show that clarity is not a property suitable for temporal characterisation.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {5–14},
numpages = {10},
keywords = {microtasks, crowdsourcing, crowd workers, performance, goal clarity, prediction, role clarity, task clarity},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078716,
author = {Millard, David E. and Hargood, Charlie},
title = {Tiree Tales: A Co-Operative Inquiry into the Poetics of Location-Based Narrative},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078716},
doi = {10.1145/3078714.3078716},
abstract = {In a location-based story a reader's movement through physical space is translated into movement through narrative space, typically by presenting them with text fragments on a smart device triggered by location changes. Despite the increasing popularity of such systems their poetics are poorly understood, meaning limited guidance for authors, and few authoring tools. To explore these poetics we present a co-operative inquiry into the authoring of an interactive location-based narrative, `The Isle of Brine', set on the island of Tiree. Our inquiry reveals both pragmatic and aesthetic considerations driven by the locations themselves, that affect the design of both the Story (narrative structure) and Fabula (events within the story). These include the importance of paths, bottlenecks, and junctions as a physical manifestation of calligraphic patterns, the need for coherent narrative areas, and the requirement to use evocative places and to manage thematic and tonal discord between the landscape and the narrative.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {15–24},
numpages = {10},
keywords = {location-based narrative, locative stories, sculptural hypertext},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078717,
author = {Thalhammer, Andreas and Thoma, Steffen and Harth, Andreas and Studer, Rudi},
title = {Entity-Centric Data Fusion on the Web},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078717},
doi = {10.1145/3078714.3078717},
abstract = {A lot of current web pages include structured data which can directly be processed and used. Search engines, in particular, gather that structured data and provide question answering capabilities over the integrated data with an entity-centric presentation of the results. Due to the decentralized nature of the web, multiple structured data sources can provide similar information about an entity. But data from different sources may involve different vocabularies and modeling granularities, which makes integration difficult. We present an approach that identifies similar entity-specific data across sources, independent of the vocabulary and data modeling choices. We apply our method along the scenario of a trustable knowledge panel, conduct experiments in which we identify and process entity data from web sources, and compare the output to a competing system. The results underline the advantages of the presented entity-centric data fusion approach.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {25–34},
numpages = {10},
keywords = {entity-centric data fusion, data/knowledge fusion, structured data, entity data fusion, linked data, data provenance, n-ary relations},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078718,
author = {Atzenbeck, Claus and Schedel, Thomas and Tzagarakis, Manolis and Ro\ss{}ner, Daniel and Mages, Lucas},
title = {Revisiting Hypertext Infrastructure},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078718},
doi = {10.1145/3078714.3078718},
abstract = {Specialized systems aiming at offering hypertext functionality in users' computing have been discussed since the early days of hypertext. However, with the claim to also support other structure domains than node-link structures, hypertext systems had to overcome some challenges. Researchers came up with component-based approaches and low level structure services.Due to the raising omnipresence of the Web, research on traditional hypertext systems has been fading out over the past decade. This paper focuses again on hypertext infrastructures and goes beyond ongoing Web discussions. Based on lessons learned from well thought through previous work, we present a novel design for multi-structure supporting, general purpose hypertext systems that can be used in a series of application domains. The system provides intelligence analysis which is needed for sophisticated user support. We argue that this lets us use the hypertext system also as a visual analytics tool. Furthermore, for demonstration purposes we describe the use of the system in combination with a Web-based software engineering platform, which is part of the ongoing project ODIN.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {35–44},
numpages = {10},
keywords = {hypertext infrastructure, open hypermedia systems, spatial hypertext, navigational hypertext, asgard, cb-ohs, taxonomic hypertext},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078719,
author = {Poulston, Adam and Stevenson, Mark and Bontcheva, Kalina},
title = {Hyperlocal Home Location Identification of Twitter Profiles},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078719},
doi = {10.1145/3078714.3078719},
abstract = {Knowledge of user's location provides valuable information that can be used to build region-specific models (e.g. language used in a particular region and map-based visualisations of social media posts). Determining a user's home location presents a challenge. Current approaches make use of geo-located tweets or textual cues but are often only able to predict location to a coarse level of granularity (e.g. city level), while many applications require finer-grained (hyperlocal) predictions.A novel approach for hyperlocal home location identification, based on clustering of geo-located tweets, is presented. A gold-standard data set for home location identification is developed by making use of indicative phrases in geo-located tweets. We find that the cluster-based approaches outperform current techniques for hyperlocal location prediction.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {45–54},
numpages = {10},
keywords = {geographic clustering, data mining, home location identification, user geo-location},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078720,
author = {Lim, Wern Han and Carman, Mark James and Wong, Sze-Meng Jojo},
title = {Estimating Relative User Expertise for Content Quality Prediction on Reddit},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078720},
doi = {10.1145/3078714.3078720},
abstract = {Reddit as a social curation site relies on its users to curate content from the World Wide Web (WWW) for the consumption of other users. Content on the site is enriched through user comments, discussions and extensions. This additional content is of varying quality however -- ranging from meaningful information to misleading content; depending on the reliability, expertise and intention of the authors. Reddit relies on the Wisdom of the Crowd (WotC) from its community as well as selected moderators to manage its content. We argue that this approach suffers from the cold start in collecting user votes and is at risk of user bias, particularly a group-think mentality. Besides that, managing the large collection of content on Reddit is expensive. In our study, we explore the estimation of relative user expertise through various content-agnostic approaches. We show that it is possible to infer information quality on Reddit using the expertise of the authors. This prediction of content quality could lead to an improved organisation of Reddit content (re-ranking) for user consumption and future information retrieval.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {55–64},
numpages = {10},
keywords = {reddit, user expertise, information retrieval, knowledge management, information quality},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078721,
author = {Chatzakou, Despoina and Kourtellis, Nicolas and Blackburn, Jeremy and De Cristofaro, Emiliano and Stringhini, Gianluca and Vakali, Athena},
title = {Hate is Not Binary: Studying Abusive Behavior of #GamerGate on Twitter},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078721},
doi = {10.1145/3078714.3078721},
abstract = {Over the past few years, online bullying and aggression have become increasingly prominent, and manifested in many different forms on social media. However, there is little work analyzing the characteristics of abusive users and what distinguishes them from typical social media users. In this paper, we start addressing this gap by analyzing tweets containing a great amount of abusiveness. We focus on a Twitter dataset revolving around the Gamergate controversy, which led to many incidents of cyberbullying and cyberaggression on various gaming and social media platforms. We study the properties of the users tweeting about Gamergate, the content they post, and the differences in their behavior compared to typical Twitter users.We find that while their tweets are often seemingly about aggressive and hateful subjects, "Gamergaters" do not exhibit common expressions of online anger, and in fact primarily differ from typical users in that their tweets are less joyful. They are also more engaged than typical Twitter users, which is an indication as to how and why this controversy is still ongoing. Surprisingly, we find that Gamergaters are less likely to be suspended by Twitter, thus we analyze their properties to identify differences from typical users and what may have led to their suspension. We perform an unsupervised machine learning analysis to detect clusters of users who, though currently active, could be considered for suspension since they exhibit similar behaviors with suspended users. Finally, we confirm the usefulness of our analyzed features by emulating the Twitter suspension mechanism with a supervised learning method, achieving very good precision and recall.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {65–74},
numpages = {10},
keywords = {gamergate, abusive, hate, cyberbullying, twitter},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078722,
author = {Hasanuzzaman, Mohammed and Way, Andy},
title = {Place-Type Detection in Location-Based Social Networks},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078722},
doi = {10.1145/3078714.3078722},
abstract = {Determining the type of places in location-based social networks will contribute to the success of various downstream tasks such as POI recommendation, location search, automatic place name database creation, and data cleaning.In this paper, we propose a multi-objective ensemble learning framework that (i) allows the accurate tagging of places into one of the three categories: public, private, or virtual, and (ii) identifying a set of solutions thus offering a wide range of possible applications. Based on the check-in records, we compute two types of place features from (i) specific patterns of individual places and (ii) latent relatedness among similar places. The features extracted from specific patterns (SP) are derived from all check-ins at a specific place. The features from latent relatedness (LR) are computed by building a graph of related places where similar types of places are connected by virtual edges. We conduct an experimental study based on a dataset of over 2.7M check-in records collected by crawling Foursquare-tagged tweets from Twitter. Experimental results demonstrate the effectiveness of our approach to this new problem and show the strength of taking various methods into account in feature extraction. Moreover, we demonstrate how place type tagging can be beneficial for place name recommendation services.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {75–83},
numpages = {9},
keywords = {poi recommendation, location-based social networks, place-type tagging},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078723,
author = {Mondal, Mainack and Silva, Leandro Ara\'{u}jo and Benevenuto, Fabr\'{\i}cio},
title = {A Measurement Study of Hate Speech in Social Media},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078723},
doi = {10.1145/3078714.3078723},
abstract = {Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. However, this same potential of social media systems brings together an important challenge---these systems provide space for discourses that are harmful to certain groups of people. This challenge manifests itself with a number of variations, including bullying, offensive content, and hate speech. Specifically, authorities of many countries today are rapidly recognizing hate speech as a serious problem, specially because it is hard to create barriers on the Internet to prevent the dissemination of hate across countries or minorities. In this paper, we provide the first of a kind systematic large scale measurement and analysis study of hate speech in online social media. We aim to understand the abundance of hate speech in online social media, the most common hate expressions, the effect of anonymity on hate speech and the most hated groups across regions. In order to achieve our objectives, we gather traces from two social media systems: Whisper and Twitter. We then develop and validate a methodology to identify hate speech on both of these systems. Our results identify hate speech forms and unveil a set of important patterns, providing not only a broader understanding of online hate speech, but also offering directions for detection and prevention approaches.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {85–94},
numpages = {10},
keywords = {social media, anonymity, hate speech, twitter, pattern recognition, whisper},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078724,
author = {Elejalde, Erick and Ferres, Leo and Herder, Eelco},
title = {The Nature of Real and Perceived Bias in Chilean Media},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078724},
doi = {10.1145/3078714.3078724},
abstract = {News consumers expect news outlets to be objective and balanced in their reports of events. However, there is a body of evidence of bias in the media caused by underlying political and socio-economic viewpoints. Previous studies have tried to classify the partiality of the media, sometimes giving a quantitative evaluation, but there is little reported on its nature. The vast amount of content in the social media enables us to quantify the inclination of the press to either side of the political spectrum. To describe such tendencies, we use tweets to automatically compute a news outlet's political and socio-economic orientation. We show that the media have a measurable bias, and illustrate this by showing the favoritism of Chilean media for the ruling political parties in this country. We also found that the nature of the bias is reflected in the vocabulary used and the entities mentioned by different news outlets. A survey conducted among news consumers confirms that media bias has an impact on the coverage of controversial topics and that this is perceivable by the general audience. Having a more accurate method to measure and characterize media bias will clarify to the readers where outlets stand within the socio-economic landscape, even when a self-declared position is stated. This will empower readers to better reflect on the content provided by their news outlets of choice.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {95–104},
numpages = {10},
keywords = {bias characterization, political quiz, media bias},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078725,
author = {Duan, Yijun and Jatowt, Adam and Tanaka, Katsumi},
title = {Discovering Typical Histories of Entities by Multi-Timeline Summarization},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078725},
doi = {10.1145/3078714.3078725},
abstract = {Categorization is a common solution used for organizing entities. For example, there are over 1.13 million categories in Wikipedia which group various types of entities such as persons, locations, etc. What is however often lacking when it comes to understanding categories is a clear information about the common aspects of the entities in a given category, for example, information on their shared histories. We propose in this paper a novel task of automatically creating summaries of typical histories of entities within their categories (e.g., a typical history of a Japanese city). The output summary is in the form of key representative events together with the information on their average dates. We introduce 4 methods for the aforementioned task and evaluate them on Wikipedia categories containing several types of cities and persons. The summaries we generate can provide information on the common evolution of entities falling into the same category as well as they can be compared with the summaries of related categories for providing contrastive type of knowledge.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {105–114},
numpages = {10},
keywords = {wikipedia, entity summarization, digital history, typicality},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078726,
author = {Anderson, Mark and Carr, Leslie and Millard, David E.},
title = {There and Here: Patterns of Content Transclusion in Wikipedia},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078726},
doi = {10.1145/3078714.3078726},
abstract = {As large, collaboratively authored hypertexts such as Wikipedia grow so does the requirement both for organisational principles and methods to provide sustainable consistency and to ease the task of contributing editors. Large numbers of (potential) editors are not necessarily a suffcient bulwark against loss of coherence amongst a corpus of many discrete articles. The longitudinal task of curation may benefit from deliberate curatorial roles and techniques.A potentially beneficial technique for the development and maintenance of hypertext content at scale is hypertext transclusion, by offering controllable re-use of a canonical source. In considering issues of longitudinal support of web collaborative hypertexts, we investigated the current degree and manner of adoption of transclusion facilities by editors of Wikipedia articles. We sampled 20 million articles from ten discrete language wikis within Wikipedia to analyse behaviour both within and across the individual Wikipedia communities.We show that Wikipedia makes limited, inconsistent of use of transclusion (as at February 2016). Use is localised to subject areas, which differ between sampled languages. A limited number of patterns were observed including: Lists from transclusion, Lists of Lists, Episodic Media Listings, Tangles, Articles as Macros, and Self-Transclusion. We find little indication of deliberate structural maintenance of the hypertext.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {115–124},
numpages = {10},
keywords = {wikis, wikipedia, transclusion, digital curation, hypertext, collaboration},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078727,
author = {Ozer, Mert and Yildirim, Mehmet Yigit and Davulcu, Hasan},
title = {Negative Link Prediction and Its Applications in Online Political Networks},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078727},
doi = {10.1145/3078714.3078727},
abstract = {Disagreements, oppositions and negative opinions are indispensable parts of online political debates. In social media, people express their beliefs and attitudes not only on issues but also about each other through both their conversations and platform-specifc interactions such as like, share in Facebook and retweet in Twitter. While there are explicit "like" features in these platforms, there is no explicit "dislike" feature. Many network analysis tasks, such as detecting communities and monitoring their dynamics (i.e. polarization patterns) require information about both positive and negative linkages. Hence, predicting negative links between users is an important task and a challenging problem. In this study, we propose an unsupervised framework to predict the negative links between users by utilizing explicit positive interactions and sentiment cues in conversations. We show the effectiveness of the proposed framework on a political Twitter dataset annotated through Amazon MTurk crowdsourcing platform. Our experimental results show that the proposed framework outperforms other well-known methods and proposed baselines. To illustrate the contribution of the predicted negative links, we compare the community detection accuracies using signed and unsigned user networks. Experimental results using predicted negative links show superiority on three political datasets where the camps are known a priori. We also present qualitative evaluations related to the polarization patterns (i.e. rivalries and coalitions) between the detected communities which is only possible in the presence of negative links.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {125–134},
numpages = {10},
keywords = {sentiment analysis, negative link prediction, social media mining, online political networks},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078728,
author = {Candeia, David and Figueiredo, Flavio and Andrade, Nazareno and Quercia, Daniele},
title = {Multiple Images of the City: Unveiling Group-Specific Urban Perceptions through a Crowdsourcing Game},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078728},
doi = {10.1145/3078714.3078728},
abstract = {Our perceptions of public spaces are central for our experience in the city. Understanding which factors shape this perception informs both urban planners, that aim at improving city life, as well as computational models that help us navigate in urban spaces. To understand cities at scale, crowdsourcing games have been employed successfully to evaluate citizens' opinions about cities and urban scenes. By analyzing human perceptions from residents of a mid-sized Brazilian city, this work brings three novel contributions. First, we consider theories from urban design to explore through crowdsourcing which high and low level features in an urban space are linked to perceptions of safety and pleasantness. Secondly, this paper leverages theory from urban sociology and anthropology to show how the sociodemographic profile of the citizens significantly mediate their perception of safeness and pleasantness of places. Finally, we show that features of the urban form proposed by urbanists can be combined with sociodemographics to improve the accuracy of machine learning models that predict which scene a person will find more safe or pleasant. This last result paves the road for more personalized recommendations in cold-start scenarios.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {135–144},
numpages = {10},
keywords = {crowdsourcing, urban perception, urban informatics},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078729,
author = {Pang, Jun and Zhang, Yang},
title = {Quantifying Location Sociality},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078729},
doi = {10.1145/3078714.3078729},
abstract = {The emergence of location-based social networks provides an unprecedented chance to study the interaction between human mobility and social relations. This work is a step towards quantifying whether a location is suitable for conducting social activities, and the notion is named location sociality. Being able to quantify location sociality creates practical opportunities such as urban planning and location recommendation. To quantify a location's sociality, we propose a mixture model of HITS and PageRank on a heterogeneous network linking users and locations. By exploiting millions of check-in data generated by Instagram users in New York and Los Angeles, we investigate the relation between location sociality and several location properties, including location categories, rating and popularity. We further perform two case studies, i.e., friendship prediction and location recommendation, experimental results demonstrate the usefulness of our quantification.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {145–154},
numpages = {10},
keywords = {location-based social networks, friendship prediction, online social networks, location recommendation, data mining},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078730,
author = {Piao, Guangyuan and Breslin, John G.},
title = {Leveraging Followee List Memberships for Inferring User Interests for Passive Users on Twitter},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078730},
doi = {10.1145/3078714.3078730},
abstract = {User modeling for inferring user interests from Online Social Networks (OSNs) such as Twitter has received great attention in the user modeling community with the growing popularity of OSNs. The focus of previous works has been on analyzing user-generated content such as tweets to infer user interests. Therefore, these previous studies were limited to active users who have been actively generating content. On the other hand, with the percentage of passive use of OSNs on the rise, some researchers investigated different types of information about followees (i.e., people that a user is following) such as tweets, usernames, and biographies to infer user interests for passive users who use OSNs for consuming information from followees but who do not produce any content. Although different types of information about followees have been exploited, list memberships (a topical list which other Twitter users can freely add a user into) of followees have not yet been investigated extensively for inferring user interests.In this paper, we investigate list memberships of followees, to infer interest profiles for passive users. To this end, we propose user modeling strategies with two different weighting schemes as well as a refined interest propagation strategy based on previous work. In addition, we investigate whether the information from biographies and list memberships of followees can complement each other, and thus improve the quality of inferred interest profiles for passive users. Results show that leveraging list memberships of followees is useful for inferring user interests when the number of followees is relatively small compared to using biographies of followees. In addition, we found that combining the two different types of information (list memberships and biographies) of followees can improve the quality of user interest profiles significantly compared to a state-of-art method in the context of link recommendations on Twitter.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {155–164},
numpages = {10},
keywords = {personalization, user modeling, passive users, twitter},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078731,
author = {Baier, Jorge and Daroch, Dietrich and Reutter, Juan L. and Vrgo\v{c}, Domagoj},
title = {Evaluating Navigational RDF Queries over the Web},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078731},
doi = {10.1145/3078714.3078731},
abstract = {Semantic Web, and its underlying data format RDF, lend themselves naturally to navigational querying due to their graph-like structure. This is particularly evident when considering RDF data on the Web, where various separately published datasets reference each other and form a giant graph known as the Web of Linked Data. And while navigational queries over singular RDF datasets are supported through SPARQL property paths, not much is known about evaluating them over Linked Data. In this paper we propose a method for evaluating property path queries over the Web based on the classical AI search algorithm A*, show its optimality in the open world setting of the Web, and test it using real world queries which access a variety of RDF datasets available online and that are not necessarily known in advance.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {165–174},
numpages = {10},
keywords = {evaluation algorithms, property paths, rdf, linked data},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078732,
author = {Peska, Ladislav},
title = {Linking Content Information with Bayesian Personalized Ranking via Multiple Content Alignments},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078732},
doi = {10.1145/3078714.3078732},
abstract = {In many application domains of recommender systems, content-based information are available for users, objects or both. Such information can be processed during recommendation and significantly decrease the cold-start problem. However, content information may come from several, possibly external, sources. Some sources may be incomplete, less reliable or less relevant for the purpose of recommendation. Thus, each content source or attribute possess different level of informativeness, which should be taken into consideration during the process of recommendation. In this paper, we propose a multiple content alignments extension to the Bayesian Personalized Ranking Matrix Factorization (BPR-MCA). The proposed method incorporates multiple sources of content information in the form of user-to-user or object-to-object similarity matrices and aligns users' and items' latent factors ac-cording to these similarities. During the training phase, BPR-MCA also learns the relevance weight of each similarity matrix. BPR-MCA was evaluated on the MovieLens 1M dataset, extended by the content information from IMDB, DBTropes and ZIP code statistics. The experiment shows that BPR-MCA can help to significantly improve recommendation w.r.t. nDCG and AUPR over standard BPR under several cold-start scenarios.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {175–183},
numpages = {9},
keywords = {recommender systems, bpr, content alignment, cold-start problem},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078733,
author = {Liu, Zhe and Xu, Anbang and Wang, Yi and Schoudt, Jerald and Mahmud, Jalal and Akkiraju, Rama},
title = {Does Personality Matter? A Study of Personality and Situational Effects on Consumer Behavior},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078733},
doi = {10.1145/3078714.3078733},
abstract = {Personality traits have long been shown to contribute to consumer behaviors. Besides the main effect of personality, it seems also plausible that other factors may impact this relationship. To understand such situational effects, in this study we analyze two possible variables, namely, income and needs. We conduct extensive analysis on a large industry dataset across over 100 product categories. For each category, we build a prediction model for consumption decision based on the derived personality features. We experiment with our prediction models under different conditions segmented by both situational factors. Our results suggest that personality's decisive power on consumer behavior varies significantly among different income levels, but non-significantly between consumer needs. Together, income and needs also have significant effect on the association between individual's personality and consumption behavior. We conclude this work by discussing the implications of our experiments and how our finding can benefit the design of more personalized recommender systems in real-world settings.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {185–193},
numpages = {9},
keywords = {consumption behavior, big five personality, income, needs, personality traits},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078734,
author = {Reis, Julio C.S. and Kwak, Haewoon and An, Jisun and Messias, Johnnatan and Benevenuto, Fabr\'{\i}cio},
title = {Demographics of News Sharing in the U.S. Twittersphere},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078734},
doi = {10.1145/3078714.3078734},
abstract = {The widespread adoption and dissemination of online news through social media systems have been revolutionizing many segments of our society and ultimately our daily lives. In these systems, users can play a central role as they share content to their friends. Despite that, little is known about news spreaders in social media. In this paper, we provide the first of its kind in-depth characterization of news spreaders in social media. In particular, we investigate their demographics, what kind of content they share, and the audience they reach. Among our main findings, we show that males and white users tend to be more active in terms of sharing news, biasing the news audience to the interests of these demographic groups. Our results also quantify differences in interests of news sharing across demographics, which has implications for personalized news digests.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {195–204},
numpages = {10},
keywords = {demographics, twitter, social media, news sharing, online news},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078735,
author = {Recalde, Lorena and Nettleton, David F. and Baeza-Yates, Ricardo and Boratto, Ludovico},
title = {Detection of Trending Topic Communities: Bridging Content Creators and Distributors},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078735},
doi = {10.1145/3078714.3078735},
abstract = {The rise of a trending topic on Twitter or Facebook leads to the temporal emergence of a set of users currently interested in that topic. Given the temporary nature of the links between these users, being able to dynamically identify communities of users related to this trending topic would allow for a rapid spread of information. Indeed, individual users inside a community might receive recommendations of content generated by the other users, or the community as a whole could receive group recommendations, with new content related to that trending topic. In this paper, we tackle this challenge, by identifying coherent topic-dependent user groups, linking those who generate the content (creators) and those who spread this content, e.g., by retweeting/reposting it (distributors). This is a novel problem on group-to-group interactions in the context of recommender systems. Analysis on real-world Twitter data compare our proposal with a baseline approach that considers the retweeting activity, and validate it with standard metrics. Results show the effectiveness of our approach to identify communities interested in a topic where each includes content creators and content distributors, facilitating users' interactions and the spread of new information.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {205–213},
numpages = {9},
keywords = {twitter., content creators, trending topics, community detection, content distributors},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078736,
author = {Le, Huyen and Boynton, G.R. and Mejova, Yelena and Shafiq, Zubair and Srinivasan, Padmini},
title = {Bumps and Bruises: Mining Presidential Campaign Announcements on Twitter},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078736},
doi = {10.1145/3078714.3078736},
abstract = {Online social media plays an increasingly significant role in shaping the political discourse during elections worldwide. In the 2016 U.S. presidential election, political campaigns strategically designed candidacy announcements on Twitter to produce a significant increase in online social media attention. We use large-scale online social media communications to study the factors of party, personality, and policy in the Twitter discourse following six major presidential campaign announcements for the 2016 U.S. presidential election. We observe that all campaign announcements result in an instant bump in attention, with up to several orders of magnitude increase in tweets. However, we find that Twitter discourse as a result of this bump in attention has overwhelmingly negative sentiment. The bruising criticism, driven by crosstalk from Twitter users of opposite party affiliations, is organized by hashtags such as #NoMoreBushes and #WhyImNotVotingForHillary. We analyze how people take to Twitter to criticize specific personality traits and policy positions of presidential candidates.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {215–224},
numpages = {10},
keywords = {social media analysis, sentiment analysis, twitter},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078737,
author = {Panchendrarajan, Rrubaa and Ahamed, Nazick and Sivakumar, Prakhash and Murugaiah, Brunthavan and Ranathunga, Surangika and Pemasiri, Akila},
title = {Eatery: A Multi-Aspect Restaurant Rating System},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078737},
doi = {10.1145/3078714.3078737},
abstract = {This paper presents Eatery, a multi-aspect restaurant rating system that identifies rating values for different aspects of a restaurant by means of aspect-level sentiment analysis. Eatery uses a hierarchical taxonomy that represents relationships between various aspects of the restaurant domain that enables finding the sentiment score of an aspect as a composite sentiment score of its sub-aspects. The system consists of a word co-occurrence based technique to identify multiple implicit aspects appearing in a sentence of a review. An improved version of Analytic Hierarchy Process (AHP) is used to obtain weights specific to a restaurant by utilizing the relationships between aspects, which allows finding the composite sentiment score for each aspect in the taxonomy. The system also has the ability to rate individual food items and food categories. An improved version of Single Pass Partition Method (SPPM) is used to categorise food names to obtain food categories.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {225–234},
numpages = {10},
keywords = {text categorisation, implicit aspect detection, aspect-level opinion mining, rating system},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078738,
author = {Hong, Sanghyun and Chakraborty, Tanmoy and Ahn, Sungjin and Husari, Ghaith and Park, Noseong},
title = {SENA: Preserving Social Structure for Network Embedding},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078738},
doi = {10.1145/3078714.3078738},
abstract = {Network embedding transforms a network into a continuous feature space. Network augmentation, on the other hand, leverages this feature representation to obtain a more informative network by adding potentially plausible edges while removing noisy edges. Traditional network embedding methods are often inefficient in capturing - (i) the latent relationship when the network is sparse (the network sparsity problem), and (ii) the local and global neighborhood structure of vertices (structure preserving problem).We propose SENA, a structural embedding and network augmentation framework for social network analysis. Unlike other embedding methods which only generate vertex features, SENA generates features for both vertices and relations (edges) by minimizing a well-designed objective function composed of a loss function and a regularization. The loss function reduces the network-sparsity problem by learning from both the edges present (true edges) and absent (false edges) in the network; whereas the regularization term preserves the structural properties of the network by efficiently considering - (i) the local neighborhood of vertices and edges, and (ii) the network spectra, i.e., eigenvectors of a symmetric matrix representing the network.We compare SENA with four baseline network embedding methods, namely DeepWalk, SE, SME and TransE. We demonstrate the efficacy of SENA through a task-based evaluation setting on different real-world networks. We consider the state-of-the-art algorithms for (i) community detection, (ii) link prediction and (iii) knowledge graph query answering, and show that with SENA's representation, these algorithms achieve up to 10%, 9% and (surprisingly) 108% higher accuracy respectively compared to the best baseline embedding methods.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {235–244},
numpages = {10},
keywords = {community detection, network embedding, link prediction},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078739,
author = {Busson, Antonio Jos\'{e} G. and Damasceno, Andr\'{e} Luiz de B. and Azevedo, Roberto G. de A. and Neto, Carlos de Salles Soares and Lima, Thacyla de Sousa and Colcher, S\'{e}rgio},
title = {A Hypervideo Model for Learning Objects},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078739},
doi = {10.1145/3078714.3078739},
abstract = {Learning Objects (LOs) are entities that can be used, reused, or referred during the teaching process. They are commonly embedded into documents that establish spatial and temporal relationships on their contents. Hypervideos LOs allow students to individualize their learning experience with non-linear browsing mechanisms and content adaptation. This paper presents a survey of features for a set of documents representing such LOs as well as desirable aspects that should be expressed during the authoring phase. Also, this paper presents a conceptual model that fits such requirements. The model is implemented by SceneSync, a domain specific language focused on the synchronization and temporal behavior of LOs. As a result of the work, we present a set of LOs specified in SceneSync and a discussion about the identified features, which confirm the expressiveness and applicability of the model.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {245–253},
numpages = {9},
keywords = {learning objects, scenesync, hypervideos},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078740,
author = {L\'{o}pez, Claudia and Farzan, Rosta and Lin, Yu-Ru},
title = {Engaging Neighbors: The Double-Edged Sword of Mobilization Messaging in Hyper-Local Online Forums},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078740},
doi = {10.1145/3078714.3078740},
abstract = {Information technologies for local communities can augment the relationships among neighbors and reduce barriers for collective action, thus increasing social capital. However, the benefits arise only if enough residents are engaged with the technology. Based on a six-year dataset of messages among neighbors on 35 online discussion forums, we examined the relationship of different kinds of content shared on the forums and user engagement. We leveraged text analysis to automatically classify over 32,000 posts shared in these hyper-local forums. Our findings suggest that neighbors use the forums largely for social capital mobilization, requesting both active and passive actions. Nevertheless, a balance between these two kinds of content is crucial for attracting new users and retaining current ones in order to keep a thriving stream of content. These results advance the understanding of the role of content on sustainability and impact of hyper-local technologies.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {255–264},
numpages = {10},
keywords = {social capital, mobilizations, hyper-local, neighborhoods},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078741,
author = {Mutlu, Belgin and Veas, Eduardo and Trattner, Christoph},
title = {Tags, Titles or Q&amp;As? Choosing Content Descriptors for Visual Recommender Systems},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078741},
doi = {10.1145/3078714.3078741},
abstract = {In today's digital age with an increasing number of websites, social/learning platforms, and different computer-mediated communication systems, finding valuable information is a challenging and tedious task, regardless from which discipline a person is. However, visualizations have shown to be effective in dealing with huge datasets: because they are grounded on visual cognition, people understand them and can naturally perform visual operations such as clustering, filtering and comparing quantities. But, creating appropriate visual representations of data is also challenging: it requires domain knowledge, understanding of the data, and knowledge about task and user preferences. To tackle this issue, we have developed a recommender system that generates visualizations based on (i) a set of visual cognition rules/guidelines, and (ii) filters a subset considering user preferences. A user places interests on several aspects of a visualization, the task or problem it helps to solve, the operations it permits, or the features of the dataset it represents. This paper concentrates on characterizing user preferences, in particular: i) the sources of information used to describe the visualizations, the content descriptors respectively, and ii) the methods to produce the most suitable recommendations thereby. We consider three sources corresponding to different aspects of interest: a title that describes the chart, a question that can be answered with the chart (and the answer), and a collection of tags describing features of the chart. We investigate user-provided input based on these sources collected with a crowd-sourced study. Firstly, information-theoretic measures are applied to each source to determine the efficiency of the input in describing user preferences and visualization contents (user and item models). Secondly, the practicability of each input is evaluated with content-based recommender system. The overall methodology and results contribute methods for design and analysis of visual recommender systems. The findings in this paper highlight the inputs which can (i) effectively encode the content of the visualizations and user's visual preferences/interest, and (ii) are more valuable for recommending personalized visualizations.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {265–274},
numpages = {10},
keywords = {information theory, personalization, user modeling, recommending visualizations},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078742,
author = {Vikatos, Pantelis and Messias, Johnnatan and Miranda, Manoel and Benevenuto, Fabr\'{\i}cio},
title = {Linguistic Diversities of Demographic Groups in Twitter},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078742},
doi = {10.1145/3078714.3078742},
abstract = {The massive popularity of online social media provides a unique opportunity for researchers to study the linguistic characteristics and patterns of user's interactions. In this paper, we provide an in-depth characterization of language usage across demographic groups in Twitter. In particular, we extract the gender and race of Twitter users located in the U.S. using advanced image processing algorithms from Face++. Then, we investigate how demographic groups (i.e. male/female, Asian/Black/White) differ in terms of linguistic styles and also their interests. We extract linguistic features from 6 categories (affective attributes, cognitive attributes, lexical density and awareness, temporal references, social and personal concerns, and interpersonal focus), in order to identify the similarities and differences in particular writing set of attributes. In addition, we extract the absolute ranking difference of top phrases between demographic groups. As a dimension of diversity, we also use the topics of interest that we retrieve from each user. Our analysis unveils clear differences in the writing styles (and the topics of interest) of different demographic groups, with variation seen across both gender and race lines. We hope our effort can stimulate the development of new studies related to demographic information in the online space.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {275–284},
numpages = {10},
keywords = {linguistics, demographic aspects, twitter analysis},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078743,
author = {Cipriano, Raffaele},
title = {<i>Interactive Concert Programs</i> for Live Performances: A Presentation Software Integrating Slideshow and Hypertext Concepts},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078743},
doi = {10.1145/3078714.3078743},
abstract = {Concerts and live shows are usually better appreciated when additional information about the exhibition and the performers are provided. For centuries, printed pamphlets or booklets have been the common way to provide the audiences with this information. Unfortunately, printed programs are not always the most efficient solution: they typically contain too much data to be read in a few minutes preceding the show, and after the performance they are usually thrown away. More crucial, printed information cannot be synchronized with the ongoing show, and the spectator has to constantly connect the data on the paper with what is happening on the stage. Technology can overcome this problem. Interactive Concert Programs (ICP) is a software that allows the streaming of digital information (such as text, images, or links) to the mobile devices of an audience in real time. Data can be triggered at a specific moment, according to what is performed. Moreover, any spectator can autonomously navigate the information streamed, using his/her device. ICP combines the characteristics of a slideshow software such as PowerPoint, and of a hypertext, such as HTML pages. There are several advantages of using ICP instead of printed programs. The listening experience can be guided with relevant information through all the duration of the show. Multilingual translations can be easily provided, as well as explaining texts for the Deaf. Users can save and share on social media the most interesting information, thus engaging new potential public. Lastly, the editing process of concert programs would be drastically simplified, and with a remarkable saving of printed paper. In this historical moment when performing arts can be difficult to understand and be appreciated, ICP can easily and inexpensively turn any theater or stage into a big lecture room, providing a new effective way for artists to tell the audience their artistic vision and the story behind the artwork performed. The audience would assimilate information more easily, with a better understanding and appreciation of the shows.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {285–294},
numpages = {10},
keywords = {hypertext, presentation, augmented performance, theater, interaction, slideshow, concert},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078744,
author = {Prado, Thiago R.P. and Moro, Mirella M.},
title = {Review Recommendation for Points of Interest's Owners},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078744},
doi = {10.1145/3078714.3078744},
abstract = {Websites that provide reviews for services and products deal with big volumes of data (many users writing many reviews for many items). Then, recommendation algorithms come to the rescue in matching reviews to the consumers who are reading them. Such online review applications usually recommend the most useful reviews for consumers to read. In this work, we propose a new perspective to this problem: how to evaluate the helpfulness of a review from the business owner's perspective. Our solution uses the review's aspects and sentiments, and ranks the most helpful ones seeking to assist establishment owners improve their businesses. Our experimental evaluations consider experts opinion and show that our solution is very close to the ideal ranking.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {295–304},
numpages = {10},
keywords = {social networks, review recommendation},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078745,
author = {J, Ganesh and Bhatt, Himanshu Sharad and Sinha, Manjira and Roy, Shourya},
title = {Multi-Part Representation Learning For Cross-Domain Web Content Classification Using Neural Networks},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078745},
doi = {10.1145/3078714.3078745},
abstract = {Owing to the tremendous increase in the volume and variety of user generated content, train-once-apply-forever models are insufficient for supervised learning tasks. The need is to develop algorithms that can adapt across domains by leveraging labeled data from source domain(s) and efficiently perform the task in the unlabeled target domain. Towards this, we present a novel two-stage neural network learning algorithm for domain adaptation which learns a multi-part hidden layer where individual parts contribute differently to the tasks in source and target domains. The multiple parts of the representation (i.e. hidden layer) are learned while being cognizant of what characteristics to transfer across domains and what to preserve within domains for enhanced performance. The first stage embroils around learning a two-part representation i.e. source specific and common representations in a manner such that the former do not detract the ability of the later to represent the target domain. In the second stage, the generalized common representation is further iteratively extended with discriminating target specific characteristics to adapt to the target domain. We empirically demonstrate that the learned representations, in different arrangements, outperform existing domain adaptation algorithms in the source classification as well as the cross-domain classification tasks on the user generated content from different domains on the web.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {305–314},
numpages = {10},
keywords = {domain adaptation, neural networks, text classification, transfer learning},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078746,
author = {Sethi, Ricky J.},
title = {Crowdsourcing the Verification of Fake News and Alternative Facts},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078746},
doi = {10.1145/3078714.3078746},
abstract = {Fake news and alternative facts have dominated the news cycle of late. In this paper, we present a prototype system that uses social argumentation to verify the validity of proposed alternative facts and help in the detection of fake news. We utilize fundamental argumentation ideas in a graph-theoretic framework that also incorporates semantic web and linked data principles. The argumentation structure is crowdsourced and mediated by expert moderators in a virtual community.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {315–316},
numpages = {2},
keywords = {alternative facts, fake news, social argumentation},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078747,
author = {Ardissono, Liliana and Lucenteforte, Maurizio and Mauro, Noemi and Savoca, Adriano and Voghera, Angioletta and La Riccia, Luigi},
title = {OnToMap: Semantic Community Maps for Knowledge Sharing},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078747},
doi = {10.1145/3078714.3078747},
abstract = {We present the information retrieval model adopted in the OnToMap Participatory GIS. The model addresses the limitations of keyword-based and category-based search by semantically interpreting the information needs specified in free-text search queries. The model is based on an ontological representation of linguistic and encyclopaedic knowledge, which makes it possible to exploit terms and synonyms occurring in the definitions of concepts to flexibly match the user's and system's terminologies. This feature enables users to query the application using their own vocabulary.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {317–318},
numpages = {2},
keywords = {information search, ontologies, linked data, participatory gis},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078748,
author = {Mehler, Alexander and Abrami, Giuseppe and Bruendel, Steffen and Felder, Lisa and Ostertag, Thomas and Spiekermann, Christian},
title = {Stolperwege: An App for a Digital Public History of the Holocaust},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078748},
doi = {10.1145/3078714.3078748},
abstract = {We present the Stolperwege app, a web-based framework for ubiquitous modeling of historical processes. Starting from the art project Stolpersteine of Gunter Demnig, it allows for virtually connecting these stumbling blocks with information about the biographies of victims of Nazism. According to the practice of public history, the aim of Stolperwege is to deepen public knowledge of the Holocaust in the context of our everyday environment. Stolperwege uses an information model that allows for modeling social networks of agents starting from information about portions of their life. The paper exemplifies how Stolperwege is informationally enriched by means of historical maps and 3D animations of (historical) buildings.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {319–320},
numpages = {2},
keywords = {historical processes, 3d, geotagging, public history of the holocaust, geocaching, ubiquitous computing, historical maps},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inproceedings{10.1145/3078714.3078749,
author = {Wang, Yuanyuan and Mohd Pozi, Muhammad Syafiq and Kawai, Yukiko and Jatowt, Adam and Akiyama, Toyokazu},
title = {Exploring Cross-Cultural Crowd Sentiments on Twitter},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078749},
doi = {10.1145/3078714.3078749},
abstract = {Twitter is frequently used to express personal opinions and sentiments. This work presents a novel crowd sentiment analysis of Twitter for exploring cross-cultural differences. We aim to find similar meanings but different sentiments between Twitter data collected over diverse geographic places. For this, we detect sentiments and topics of each tweet and assign sentiments to each topic based on the sentiments of the corresponding tweets. This permits finding interesting cross-cultural patterns. We demonstrate a visualization system that supports the interactive analysis of two countries: France and Italy.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {321–322},
numpages = {2},
keywords = {twitter, cross-cultural study, crowd sentiment analysis},
location = {Prague, Czech Republic},
series = {HT '17}
}

