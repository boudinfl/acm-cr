@inproceedings{10.1145/2835043.2835063,
author = {Prakash, Aditya and Chaudhuri, Parag},
title = {Comparing Performance of Parallelizing Frameworks for Grid-Based Fluid Simulation on the CPU},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835063},
doi = {10.1145/2835043.2835063},
abstract = {In this paper we present a comparison study of two widely used parallelizing frameworks on the CPU, namely, OpenMP and Intel Threading Building Blocks (TBB). The particular problem domain we apply to is a grid-based fluid simulation solver. The standard Eulerian grid-based fluid solver discretizes the Navier-Stokes equation on a staggered but regular grid and computes the fluid parameters like velocity and pressure in each grid cell. We use OpenMP and TBB to parallelize this computation, and study the behaviour of our implementation on each framework, while working with different number of threads and CPU cores. We provide arguments in support of implementing a mixed solution strategy using both the parallelizing frameworks together, thus improving performance over when either is used in isolation.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {1–7},
numpages = {7},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835062,
author = {Chawla, Mandeep K. and Chhabra, Indu},
title = {SQMMA: Software Quality Model for Maintainability Analysis},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835062},
doi = {10.1145/2835043.2835062},
abstract = {Software Quality is generally characterized by several factors which reveal the degree of success of the software developed and its future maintainability. Although many existing models provide frameworks of huge potential pertaining to quality analysis, yet offer little support to make them operational and handy to use. Nonetheless, by taking ideas from existing models, new metrics, their relationships with external quality factors and associated weights can be defined and evaluated. Keeping these views in mind, this paper proposes a new quality model (SQMMA) which offers ready-to-use mathematical formulas to quantify four quality attributes namely Analyzability, Changeability, Stability and Testability as weighted sum of a set of software code metrics. These attributes further act as determinants to evaluate `Maintainability' characteristic of a software, according to ISO 9126 definition. A revised formula to compute Maintainability, according to ISO 25010, has also been derived. The designed model is then implemented on four versions of Apache tomcat and results are presented. Finally results have been validated through their trend analysis and comparison with bugs/change metrics drawn additionally.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {9–17},
numpages = {9},
keywords = {Software Metrics, Apache Tomcat, AHP, Maintainability, SQMMA, ISO/IEC 9126, Quality Attributes},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835059,
author = {Bhowmik, Biswajit and Deka, Jatindra Kumar and Biswas, Santosh},
title = {Reliability on Top of Best Effort Delivery: Maximal Connectivity Test on NoC Interconnects},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835059},
doi = {10.1145/2835043.2835059},
abstract = {A scalable, packet address driven strategy that tests an open fault on network-on-chip (NoC) interconnects and maximal connectivity between neighbor routers in presence of a short fault is proposed. The open faults and maximal connectivity are tested for data, control, and handshake interconnects by the proposed method using finite test sequence. Experiments ensure the state of faultiness/non-faultiness of an interconnect with/without an open fault and possibility of connectivity over faulty interconnects for a channel. Evaluation is done in terms of test time, testing criteria, and performance metrics. Results achieve 100% test and fault coverages when interconnects possess open faults only but nearly 100% when shorts are injected on faulty interconnects to make connectivity.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {19–28},
numpages = {10},
keywords = {permanent faults, packet missing, reliability, coverage metrics, maximal connectivity, performance metrics, diagnosable and non-diagnosable faults, packet multicasting},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835058,
author = {Vamsi, P. Raghu and Kant, Krishna},
title = {Trust Aware Resilient Geographic Routing in Wireless Ad Hoc and Sensor Networks},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835058},
doi = {10.1145/2835043.2835058},
abstract = {The objective of the paper is to propose trust aware routing method for cooperative and resilient geographic routing in Wireless Ad-hoc and Sensor Networks (WASNs). The proposed method calculates the trust value on the basis of node behavior in routing the packets. The proposed method is designed to have the features such as self-adaptability, low overhead, and dependability which are missing in the existing trust models. With the trust values, the proposed method detects and isolates the malicious nodes dynamically during the routing process. The simulation results obtained using the network simulator ns-2 shows the efficiency of the proposed trust model.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {29–35},
numpages = {7},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835057,
author = {Moharreri, Kayhan and Ramanathan, Jayashree and Ramnath, Rajiv},
title = {Recommendations for Achieving Service Levels within Large-Scale Resolution Service Networks},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835057},
doi = {10.1145/2835043.2835057},
abstract = {A new recommendation framework that addresses the correct and quick resolution of incidents that occur within the complex systems of an enterprise is introduced here. It uses statistical learning to mediate problem solving by large-scale Resolution Service Networks (with nodes as technical expert groups) that collectively resolve the incidents logged as tickets. Within the enterprise a key challenge is to resolve the tickets arising from operational big data (1) to the customers' satisfaction, and (2) within a time constraint. That is, meet the service level (SL) goals. The challenge in meeting SL is the lack of a global understanding of the types of needed problem solving expertise. Consequently, this often leads to ticket misrouting to experts that are inappropriate for solving the next increment of the problem. The solution here proposes a general two-level classification framework to recommend a SL-efficient sequence of expert groups that jointly can resolve an incoming ticket. The experimental validation shows 34% accuracy improvement over existing locally applied generative models. Additionally, recommended sequences are above 96% likely to meet the enterprise SL goals, which reduces the SL violation rate by 29%. Recommendations are suppressed in the case of non-routine content which is automatically flagged for special attention by humans, since here the humans outperform statistical models.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {37–46},
numpages = {10},
keywords = {Service Levels, Resolution Service Network, Human-in-the-loop, Knowledge Management, Complex Enterprise, Ticket Resolution Sequence, Text Mining, Classification},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835056,
author = {Chaturvedi, Pooja and Daniel, A. K.},
title = {Lifetime Optimization for Target Coverage in Wireless Sensor Networks},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835056},
doi = {10.1145/2835043.2835056},
abstract = {Maintaining the desired coverage level and reliability is a major challenge in the field of wireless sensor networks (WSNs). WSN consists of number of resource constrained and unreliable sensors. In this paper we have proposed a node scheduling protocol based on trust model, which reduces the energy consumption by putting the sensor nodes in the sleep mode. To improve the lifetime we have compared the performance of proposed protocol with Trust Based Probabilistic Coverage Algorithm (TBCA). The proposed Energy Efficient Coverage Protocol (EECP) provides the performance improvement in terms of network lifetime and reliability of the data transmitted to the base station.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {47–53},
numpages = {7},
keywords = {Lifetime, Probabilistic Coverage, Energy Efficiency, Trust, Target Coverage},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835061,
author = {Dangui, Shruti R. and Naik, Nitesh},
title = {A Lightweight Stemmer for Devanagari Script},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835061},
doi = {10.1145/2835043.2835061},
abstract = {Stemming is an operation that reduces morphological variants of words to its stem. Stemming is a pre-processing tool which is used in various natural language processing applications such as text summarization, information retrieval, word sense disambiguation, and document clustering. It improves the performance of Information Retrieval systems by increasing recall and reducing index size. The recall of the system is increased by stemming as the words present in the query are matched with their linguistic variants in the documents. It also reduces the index size which in turn leads to increase in speed and reduction in memory requirements. The different languages in Devanagari script are Hindi, Marathi, Konkani etc. The proposed idea is to develop a common stemmer for languages in Devanagari script by using supervised approach and to evaluate stemmer to measure the performance of stemmer.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {55–62},
numpages = {8},
keywords = {Stemmer, Supervised, Overstemming, Recall, Understemming, Information Retrieval System},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835060,
author = {Kumari, Sonal and Maheshwari, Anil and Goyal, Poonam and Goyal, Navneet},
title = {Parallel Framework for Efficient K-Means Clustering},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835060},
doi = {10.1145/2835043.2835060},
abstract = {Handling and processing of larger volume of data requires efficient data mining algorithms. k-means is a very popular clustering algorithm for data mining, but its performance suffers because of initial seeding problem. The computation time of k-means algorithm is directly proportional to the number of data-points, number of dimensions, and number of iterations, therefore, it is very expensive to process large data-points sequentially. We proposed an efficient parallel framework which includes dimensionality-reduction as well as data-size reduction techniques to improve k-means processing time and initial seeding problem. Our proposed parallel framework leverages the multi-node and multi-core architectures of a typical commodity cluster. We have validated our proposed approaches with real and synthetic datasets in parallel environment setup. The experimental results clearly show the significant improvements in k-means performance.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {63–71},
numpages = {9},
keywords = {initial seeding, k-means, multicore, multinode, parallel computing, cluster, dimensionality-reduction, coreset},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835048,
author = {Desai, Ankit and Jadav, Kaushik and Chaudhary, Sanjay},
title = {An Empirical Evaluation of CostBoost Extensions for Cost-Sensitive Classification},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835048},
doi = {10.1145/2835043.2835048},
abstract = {Data Mining Technique, namely Classification, is used to predict group membership for data samples. Ensemble learning, combining multiple classifiers using bagging, boosting or stacking, are proven data-mining methods, we have used boosting in this paper for combining multiple classifiers. Cost-sensitive classification is used for classification tasks under the Cost-Based Model (CBM), unlike the Error-Based Model (EBM). EBM does not incorporate the cost of misclassifying a sample in a model building phase, while CBM does. CBM techniques usually modify the weight update equation to incorporate the misclassification cost from cost-matrix. Cost-sensitive boosters are studied and three new extensions of CostBoost algorithm CBE1, CBE2 and CBE3 are proposed and compared with existing cost based boosting classifiers. CSE1, CSE2 and CSE3 outperformed the original CostBoost by 5%, 4% and 4% respectively, in terms of misclassification cost.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {73–77},
numpages = {5},
keywords = {Cost-sensitive classifiers, CBExtension1, CBExtension3, Misclassification cost, Data Mining, CBExtension2},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835044,
author = {Kanrar, Soumen and Mandal, Niranjan Kumar},
title = {Efficient Video Streaming for Interactive Session},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835044},
doi = {10.1145/2835043.2835044},
abstract = {Over the decades, researchers are trying to find an effective methodology for smooth uninterrupted multimedia data streaming through the broad band network in video on demand system. The problem is directly related to the efficiently use of methodology in the next generation network. The performance of the data streaming is largely depended upon the adaptability of the methodology to the user dynamic requirement for bandwidth in any interactive session. The users are largely interested to use interactive operation during the real-time video watching at user ends. The bandwidth utilization be good, if the data stream is served from the local site, if the local site cannot serve, then that will be served from the remotely distributed storage architecture. The submitted requests are exponentially increased with respect to the geographic location for any interactive session. In this work, we have presented the multimedia storage architecture in the distributed system environment, i.e. local proxy servers, remote data storages clusters and the role of a cluster switch. The proposed methodology is working for proxy server with a total bandwidth capacity divided into the number of sections.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {79–83},
numpages = {5},
keywords = {Stream handles, System performance, Storage cluster, Port shearing, Multimedia data stream, Modeling and simulation},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835051,
author = {Javkar, Kiran Gajanan and Mali, Pravin Kumar Ramesh and Kumar, Ashutosh and Chinnaga, Lokesh},
title = {Variable Feature Sets in Grid-Based Layouts},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835051},
doi = {10.1145/2835043.2835051},
abstract = {As the digital data continues to grow unbounded, users expect intelligent processing and accurate coverage of all its domains. Advances in display technology have led to a variety of viewing devices, each with its own characteristic sizes and resolutions. Thus, a single layout on different sized devices would degrade the user experience. Moreover, the information shown on display does not need to have same features. So, it becomes very crucial to develop a user interface which can cope up with different sized viewing devices and different data set information. To facilitate the same, we hereby present a novel approach to identify key information from various data sets and display the same on wide range of devices using comparable but different grid-based layouts.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {85–88},
numpages = {4},
keywords = {Adaptive Layout design, Graphical User Interface, Responsive Layout design, Grid based Layout, Constrained Based User Interface},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835046,
author = {Dwivedi, Shri Prakash},
title = {Computing Modular Exponentiation for Fixed-Exponent},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835046},
doi = {10.1145/2835043.2835046},
abstract = {Exponentiation is computing ge, where g is an element of a group G and e is a positive integer. In modular exponentiation the underlying group is Zn or Z*n. This paper describe the methods to compute exponentiation where a fixed-exponent e is raised to several bases g of a group G. We describe modular exponentiation based on Bernstein's algorithm for multiplication by constant. We also present a modified approach to modular exponentiation based on k-ary String Replacement (SR(k)) representation.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {89–94},
numpages = {6},
keywords = {Computational Number Theory, Exponentiation, Algorithms, Computer Arithmetic},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835045,
author = {Rodge, A. and Soni, S. K. and Chinnaga, L. and Johari, P. and Bose, J. and Pramanik, C. and Bhide, A.},
title = {Scalable and Optimal Load Generation for AWS Clients},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835045},
doi = {10.1145/2835043.2835045},
abstract = {In this paper we describe techniques to use SPDY and HTTP network resources optimally for testing purposes with limited resources such as RAM. We demonstrate how to overcome the system limitations of network analysis tools such as the 64K limit on connections. Our enhancements include modifications to the spdycat SPDY tool to generate the loads for a higher number of users. For HTTP, we describe tweaks in system settings to improve the throughput of the system. Using our techniques, the user can perform scalability testing or load testing optimally. We have performed tests on an AWS system to measure the throughput, and have obtained 1 million concurrent connections over SPDY. We also describe the experimental setup for HTTP.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {95–100},
numpages = {6},
keywords = {load generation, scalability, Cloud computing, network simulation, Amazon Web Service, testing tools, SPDY},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835054,
author = {Patil, Rupali and Manjrekar, Amrita},
title = {A Novel Filtering and Coding Method for Image Classification and Image Retrieval},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835054},
doi = {10.1145/2835043.2835054},
abstract = {The feature extraction-coding-pooling framework improves the performance of image classification because it generates robust and discriminative image representation. The proposed system uses saliency driven multi-scale nonlinear diffusion filtering with linear distance coding (LDC) method for image classification. The saliency driven multi-scale nonlinear diffusion filtering generates the images at small, mid and high scale and concatenation of information at these scales produces robust image classification using LDC. The class manifolds generated by this classification system are given as input to image retrieval system which finally retrieves all images those are relevant to supplied image.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {101–106},
numpages = {6},
keywords = {Saliency driven multi-scale nonlinear diffusion, linear distance coding (LDC), Image classification, Image retrieval},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835052,
author = {Sharma, Priyanka and Sharma, Rachana and Pilli, Emmanuel S. and Mishra, Anand Kumar},
title = {A Detection Algorithm for DoS Attack in the Cloud Environment},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835052},
doi = {10.1145/2835043.2835052},
abstract = {Cloud Computing provides an easy access to the end users i.e. users can access the services from wherever they want to without concerning about the storage, management, and cost and so on. With an increase in its number of users per day, threat for protecting the data residing in the Cloud is also increasing. The more information about individuals and companies is placed in the Cloud; more concerns are arising about how secure an environment it is. This paper focuses on security perspective of Cloud Computing. We discuss about the DoS attack in the cloud environment and propose a detection algorithm for the attack.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {107–110},
numpages = {4},
keywords = {Cloud Computing, Security, Detection Algorithm, DoS attack, Attack techniques, OpenStack},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835053,
author = {Avasthi, Vinay and Dey, Shubhamoy and Venkatagiri, Shankar and Jain, Kamal Kishore and Mishra, Rajhans},
title = {Knowledge Networks and Knowledge Adjacencies},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835053},
doi = {10.1145/2835043.2835053},
abstract = {The modern enterprise is becoming larger and geographically distributed. The structure of companies is also becoming more complicated. Oraganizations are depending on knowledge within the enterprise and outside the enterprise. More and more individuals within organizations are parts of communities of practice which at times extend the boundaries of organizations. This necessitates people in the enterprise to have access to other individuals based on their roles and expertise [12]. Individuals within teams are constantly looking for sources of expertise that they don't have. In larger organizations, it becomes extremely difficult to identify the individuals that have the relevant expertise and get in touch with the individuals.Organizations and communities of practice have deployed knowledge management system to solve this problem with the belief that better implementation of information technologies [4] would result in more knowledge sharing and this would benefit the organizations. This has resulted in knowledge management research community being too focused on IT. A significant amount of knowledge is generated within the enterprise in communities of practice that consist of individuals both from within the enterprise and external to enterprise.There is no standard way to represent and access knowledge in the enterprise. Most of the knowledge within the enterprise resides in the form of documents, communications and in the mind of people. In this paper we define a way to represent the knowledge in the form of knowledge ontology. We also define system for generating knowledge networks that exist within the organization.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {111–116},
numpages = {6},
keywords = {Knowledge Ontology, Knowledge Adjacency, Knowledge Networks, Graph Theory},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835047,
author = {Rani, Asma and Goyal, Navneet and Gadia, Shashi K.},
title = {Data Provenance for Historical Queries in Relational Database},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835047},
doi = {10.1145/2835043.2835047},
abstract = {Capturing, modeling, and querying data provenance in databases has gained considerable importance in the last decade. All kinds of applications developed on top of databases, now a days collect provenance for various purposes like trustworthiness of data, update management, quality measurement etc. For these purposes, there is a need to efficiently capture, store, and query provenance information for current as well as historical queries executed on the database. Most of the existing provenance models like DBNotes, MONDRIAN, Perm, Orchestra, TRIO, and GProM are suitable for capturing and querying provenance in relational databases. All these models can capture provenance only for currently executing queries, except for TRIO and GProM, which can capture and query provenance for historical queries also. But, the time and space complexity of these two models is very high. In this paper, we propose a framework, Data Provenance for Historical Queries (DPHQ), which is capable of efficiently capturing and querying provenance for queries, including that of historical queries. The proposed model also supports provenance for updates. In our model, we have used Zero Information Loss Database [2] to execute historical queries at any point of time, using the concept of nested relations. A graph database is used for storing and subsequent querying of provenance information.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {117–122},
numpages = {6},
keywords = {ZILD, Graph Database, Query Inversion, DPHQ, Neo4j, Data Provenance, TPC-H, Provenance Querying},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835050,
author = {Challa, Jagat Sesh and Goyal, Poonam and Nikhil, S. and Balasubramaniam, Sundar and Goyal, Navneet},
title = {A Concurrent K-NN Search Algorithm for R-Tree},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835050},
doi = {10.1145/2835043.2835050},
abstract = {k-nearest neighbor (k-NN) search is one of the commonly used query in database systems. It has its application in various domains like data mining, decision support systems, information retrieval, multimedia and spatial databases, etc. When k-NN search is performed over large data sets, spatial data indexing structures such as R-trees are commonly used to improve query efficiency. The best-first k-NN (BF-kNN) algorithm is the fastest known k-NN over R-trees. We present CBF-kNN, a concurrent BF-kNN for R-trees, which is the first concurrent version of k-NN we know of for R-trees. CBF-kNN uses one of the most efficient concurrent priority queues known as mound. CBF-kNN overcomes the concurrency limitations of priority queues by using a tree-parallel mode of execution. CBF-kNN has an estimated speedup of O(p/k) for p threads. Experimental results on various real datasets show that the speedup in practice is close to this estimate.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {123–128},
numpages = {6},
keywords = {priority queues, mounds, best first search, Data mining, k-nearest neighbor search, concurrent data structures, R-tree},
location = {Ghaziabad, India},
series = {Compute '15}
}

@inproceedings{10.1145/2835043.2835049,
author = {Chaitanya, K. and Somayajulu, D. V. L. N. and Krishna, P. Radha},
title = {A Novel Approach for Classification of E-Commerce Data},
year = {2015},
isbn = {9781450336505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835043.2835049},
doi = {10.1145/2835043.2835049},
abstract = {Classification is one of the most interesting problems in the fast evolving fields such as e-commerce and web-based businesses where the data is growing exponentially. Existing classification techniques over e-commerce data are mainly based on the users' purchasing patterns. However, gender preferences significantly improve in recommending various products, targeting customers for branding products, providing customized suggestions to the users etc. In this paper, we propose a two-phase approach for gender based classification to classify e-commerce data by exploiting hierarchical relationships among products. The first phase reduces the dimensionality of the data by identifying the features that well describes the browsing pattern of the users. The second phase classifies the data based on these features. Experiments are carried out on clickstream data (provided by FPT group) consisting of browsing logs (with list of products formed as a hierarchy), session start time and session end time. We compared our results with standard Bayesian classification model, which shows the applicability of our classification approach for e-commerce data.},
booktitle = {Proceedings of the 8th Annual ACM India Conference},
pages = {129–134},
numpages = {6},
keywords = {e-commerce, feature extraction, Gender classification},
location = {Ghaziabad, India},
series = {Compute '15}
}

