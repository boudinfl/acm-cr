@inproceedings{10.1145/2459118.2459119,
author = {Venu, M. and Kiran, R. Uday and Kiranmai, R.},
title = {A Robust Neural Network Classifier to Model the Compressive Strength of High Performance Concrete Using Feature Subset Selection},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459119},
doi = {10.1145/2459118.2459119},
abstract = {High performance concrete (HPC) is a mixture of cement, fine aggregate, coarse aggregate, water and other ingredients. Modeling the compressive strength of HPC (or concrete strength) is a difficult task in building materials because it is influenced by the proportions of various ingredients within the HPC. Researchers have tried to confront this difficulty by modeling the strength of concrete using artificial neural networks (ANN). The influence of ingredients on concrete strength still remains unknown due to the "black box" nature of ANN. This paper investigates the influence of ingredients on concrete strength modeling using feature selection. A robust ANN-model using the knowledge from feature selection has been developed to predict the strength effectively. Experimental results have shown that the proposed model is efficient with respect to runtime and prediction.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {1},
numpages = {8},
keywords = {knowledge discovery, data mining, concrete and compressive strength prediction, classifiers},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459120,
author = {Kumar, V. V. N. Pavan and Gopinath, K.},
title = {Scalable Lock-Free FIFO Queues Using Efficient Elimination Techniques},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459120},
doi = {10.1145/2459118.2459120},
abstract = {Lock-free data structures ensure system wide progress, synchronizing the operations of concurrent processes without the use of mutual exclusion. Lock-free FIFO queues are one of the most highly studied concurrent data structures. Elimination techniques have been used to improve the scalability of FIFO queues. In this paper, we study scalable lock-free FIFO queues using newer and more efficient elimination techniques. We propose four new heuristics to improves the scalability of the Lock-Free FIFO queues: Range Variation, Fixed Location, Load Adaptation and Double Array. Our empirical results shows these four heuristics perform better than existing algorithms in the literature.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {2},
numpages = {8},
keywords = {scalability, lock-free, synchronization},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459121,
author = {Dhiman, Nitin Kumar and Deodhare, Dipti and Khemani, Deepak},
title = {A Review of Path Planning and Mapping Technologies for Autonomous Mobile Robot Systems},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459121},
doi = {10.1145/2459118.2459121},
abstract = {This paper presents a review of various technologies for autonomous movement of a robot. Path planning is the process of generating a collision free path to the goal. Simultaneous Localization And Mapping (SLAM) is the process of creating a map of the environment while at same time localizing in the same map. Path planning and SLAM are critical for autonomous movement of the robot. This papers discusses different kinds of algorithms for path planning. This paper also describes the methods to incorporate the non-holomic constraints of a robot in the solution. Metrical map generating approaches, qualitative map generating approaches and hybrid map generating approaches for SLAM are also discussed.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {3},
numpages = {8},
keywords = {path planning, SLAM, anytime search algorithm, mapping, topological map, hippocampus, incremental search algorithm, localization, hybrid map},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459122,
author = {Nagasundara, K. B. and Manjunath, S. and Guru, D. S.},
title = {Multimodal Biometric System Based on Hand Geometry, Palmprint and Signature},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459122},
doi = {10.1145/2459118.2459122},
abstract = {The aim of this paper is to exploit the best possible combinations of hand geometry, palmprint and offline signatures for multimodal biometric systems by integrating the information at score level fusion. Initially, Zernike moments are extracted for each biometric trait of a person and study the identification accuracy. Subsequently, the effect of identification accuracy using score level fusion of multiple traits of a person is studied. Experiments are conducted on GPDS hand geometry database, PolyU two dimensional palmprint database and UOM offline signature database to assess the actual advantage of the fusion of multiple biometric traits performed at score level fusion, in comparison to the unimodal biometric system. The proposed methodology has shown promising results.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {4},
numpages = {6},
keywords = {hand geometry, Zernike moments, signature, score level fusion, person identification, palmprint, multimodal},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459123,
author = {Krishna, P. Radha and Indukuri, Kishore Varma and Syed, Shahanaz},
title = {A Generic Topology Discovery Approach for Huge Social Networks},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459123},
doi = {10.1145/2459118.2459123},
abstract = {Social Networks are gaining importance due to their enablement of modeling various types of interactions among individuals, communities and organizations. Network Topologies play a major role in analyzing the social networks for a variety of business application scenarios such as finding influencers in product campaigning and virtual communities to recommend music downloads. Social networks are dynamic in nature and detection of topologies from these networks presents a host of new challenges. In this paper, we present approaches for topology discovery, particularly star, ring and mesh, based on the measures of network centrality. These approaches facilitate an efficient way of discovering topologies for analyzing large social networks. We also discuss experiments on DBLP dataset to show the viability of our proposed approach.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {5},
numpages = {7},
keywords = {scoring, network measures, topology discovery, social networks},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459124,
author = {Mahalakshmi, G. S. and Sam, S. Dilip and Sendhilkumar, S.},
title = {Mining Research Abstracts for Exploration of Research Communities},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459124},
doi = {10.1145/2459118.2459124},
abstract = {Research abstracts are the 'information scents' which attract a novice researcher. To read through the entire research paper and to decide the suitability of the paper to one's research problem is a tough and abstract task. Many times, researchers do not know whether they are citing the relevant (but original?) research articles. It has been only a trial and error approach so far. To enable researchers to correctly target at the relevant and yet quality research literature, mechanisms to organise collections of research papers are essential. Though a considerable effort has been attempted earlier in this context, establishing research communities concentrated on citation based recommendations only. However, the quality and originality of research articles have not been taken into account until now. In this paper, we propose the evolution of research communities by analysing the research abstracts. We utilise Fuzzy Concept Map based approach in detecting the originality of scientific abstracts. By K-means clustering, we establish a research article hyper graph from the qualified abstracts. Later, we evolve the author clusters for every topic cluster and analyse them for redundancy. Further study on relevant bibliometrics helps us to identify a 'nucleus author' for every topic cluster.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {6},
numpages = {10},
keywords = {fuzzy cognitive maps, originality of research publications},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459125,
author = {Mynam, Mahesh and Sahasrabudhe, Nachiket and Nandgaonkar, Ajay},
title = {GPU Implementation of a Novel Hybrid Lattice Boltzmann Method for Non-Isothermal Flows},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459125},
doi = {10.1145/2459118.2459125},
abstract = {We propose a new method to simulate non-isothermal flows. This method is ideally suited for the GPU architecture. The new algorithm is derived by coupling the lattice Boltzmann formulation for the flow with the finite difference scheme for the temperature field. We apply this algorithm to solve for the flow in the well known buoyancy driven cavity problem and verify the validity of the algorithm and its GPU implementation by benchmarking the thermal flow patterns with known results. The implementation details on the GPU are discussed in detail to bring out the inherent advantage of the GPU hardware for such data parallel applications.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {7},
numpages = {7},
keywords = {non-isothermal flows, convection flows, GPU, hybrid lattice Boltzmann, LBM-FD method},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459126,
author = {Sharma, Naman and Maringanti, Hima Bindu and Asawa, Krishna},
title = {Upper Body Pose Recognition and Classifier},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459126},
doi = {10.1145/2459118.2459126},
abstract = {This paper introduces an upper body pose recognition and classifier system. Our objective is to analyze, design and implement the above mentioned system to enhance the machine's understanding of humans based upon affective behavior of humans. This work follows vision based techniques for recognition and identification of a vast range of non-overlapping body poses. The problem in body-posture identification is the inherent complexity of poses, like same pose can be present in a number of different scenarios or situations. Therefore it is inappropriate to guess the exact pose without identifying facial gestures, hand gestures and speech. Hence our approach is to identify the exact position of arms, head, shoulders and torso, so that, we can estimate the intensity of any pose and also identify possible emotion(s) under which this pose is expressed. The accuracy of this system is as good as 92%.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {8},
numpages = {5},
keywords = {pose recognition, vision based techniques, pose intensity and angle measurement},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459127,
author = {Kumar, Shiva and Singh, Vivek and Jha, Vineet and Kulkarni, Priya and Jere, Abhay},
title = {RobExT: A Tool to Customize Microarray Data for CellDesigner and Cytoscape},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459127},
doi = {10.1145/2459118.2459127},
abstract = {CellDesigner and Cytoscape are popularly used tools in systems biology studies for biological network construction. Plug-ins for these tools are also available which enable visualization of the microarray data in the context to the constructed biological networks. However, a major limitation for these tools is that they accept inputs only in a specified format and not in the format generated routinely by secondary data analysis pipeline for microarray data. Generating an input file in the format acceptable to CellDesigner and/or Cytoscape is a non-trivial task for biologists with very limited computation experience. Hence, we developed an easy to use tool, RobExT (Robust Expression parsing Tool), that empowers biologists with capabilities to select, cleanse and filter microarray data relevant to their biological networks constructed using CellDesigner/Cytoscape.Using RobExT, we extracted gene expression profile data for 100 genes constituting our biological network (could be used for any number of genes) from a normalized microarray dataset with more than 45000 gene probes. Input for RobExT was normalized microarray dataset, a text file listing 100 genes of our interest and appropriate p-value cut off (â‰¤0.05). On processing, RobExT generated output files with expression profiles only for our genes of interest based on p-value cut off and in the format acceptable to CellDesigner and Cytoscape. Further, this data was overlaid on the biological network of 100 genes under consideration for easy visualization and analysis.We have developed an easy to use tool RobExT that takes normalized microarray data, and, based on user inputs, generates output files that can be easily imported into CellDesigner and Cytoscape for easy visualization and further biological interpretation.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {9},
numpages = {5},
keywords = {CellDesigner, mRNA, DNA, expression analysis, Cytoscape, microarray, data filtering},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459128,
author = {Kulkarni, Abhinandan M. and Thirunavukkarasu, Janani and Pillai, Parvathy S. and Sulegai, Sneha Somanath and Rao, Shrisha},
title = {Insertion and Querying Mechanism for a Distributed XML Database System},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459128},
doi = {10.1145/2459118.2459128},
abstract = {XML files are ideal for describing semi structured data. The advent of native XML databases has enhanced storage of a large number of XML files preserving the hierarchical format. The challenge is to serve and access XML data from geographically distributed native XML databases. In this paper, we discuss the modus operandi for insertion and querying of data in a location transparent manner in decentralised networks. We present the design for a cluster based architecture where query processingF is achieved using distributed hash tables. A bulk insertion method has been employed for insertion of XML data. The proposed design was implemented on eXist-db, a native XML database engine. Experiments were conducted and the effectiveness of the proposed design was evaluated.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {10},
numpages = {8},
keywords = {bulk insertion, distributed query processing, distributed XML databases, native XML databases},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459129,
author = {Deepak, K. Sai and Rai, Harikrishna G. N. and Syed, Shahanaz and Krishna, P. Radha},
title = {Texture Edge Statistics for Efficient Retrieval of Biomedical Images},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459129},
doi = {10.1145/2459118.2459129},
abstract = {Adoption of Clinical Decision Support Systems in the process of clinical decision process has been gaining attention in recent times. Such intelligent decision support systems need frequent access to historic medical data such as medical images and associated reports. Content Based Image Retrieval has been preferred choice of technique for such smart retrieval of medical images based on their content. In this paper, we introduce a new approach for deriving edge based features for retrieval of medical images. Texture edges are known to represent the tissue boundaries better than intensity edges in medical images. Therefore, we use texture edges for describing image structure instead of traditional approach of using intensity edges. We demonstrate that retrieval performance at organ level in medical images using texture edges is superior to intensity edges.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {11},
numpages = {6},
keywords = {texture edge detection, CBIR, feature extraction, edge statistics},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459130,
author = {Bhalachandra, Sridutt and Thothadri, Sripriya and Rao, Pradeep},
title = {Enabling High Performance Computing Using Microsoft HPC Server},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459130},
doi = {10.1145/2459118.2459130},
abstract = {With processor speeds stagnating, most organizations are investing in multi-cores processors and clusters, in order to scale out to meet the growing computing and data demands. Traditional applications are unable to utilize the full power of this infrastructure due to their sequential design and organizations are compelled to add more and more computing infrastructure to scale out the applications. The multiplying infrastructure comes with a heavy price tag and rising space, power and infrastructure management costs. This white paper demonstrates an approach using Microsoft High Performance Computing (HPC) Server to transparently help applications utilize the full capacity of its hardware resources. The main focus of this approach is to accelerate application throughput by enabling sequential applications to exploit the maximum performance that the underlying hardware can deliver. Simplicity and minimal changes are the key objectives of our solution and we call this a HPC Black-box approach. We also show how this can help lower infrastructure investments. We believe that this approach can be used to enable HPC for existing sequential applications using Microsoft Windows HPC Server.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {12},
numpages = {6},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459131,
author = {Bihary, Sidharth and Roy, Suman and Han, Tan Zi and Sawant, Kiran Prakash},
title = {A Knowledge-Based Formalization of UBL Processes Using Hybrid Programs},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459131},
doi = {10.1145/2459118.2459131},
abstract = {In business process management, it has become necessary to semantically annotate business processes with ontology for better service provisioning, integration and composition. The OASIS has introduced Universal Business Languages (UBL) as a common format for standardizing common business documents as well as business processes. We propose a method for capturing and managing the information stored in business transactions based on the widely used UBL. We use hybrid programs as the knowledge representation formalism. The formalism of hybrid programs integrates normal clauses (using the parlance of logic programming) with ontology specified in OWL-DL (semantic web standard). This hybrid system uses XSB Prolog for rule reasoning and Pellet for ontology reasoning. We have built a tool that takes a description of a UBL process as input and produces the corresponding hybrid program as output knowledge base on which suitable queries can be fired.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {13},
numpages = {8},
keywords = {knowledge representation, case study, business documents, information retrieval, UBL, semantic web, logic programs, hybrid rules, OWL-DL, business intelligence, ontologies in software engineering},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459132,
author = {Deshmukh, Varad R. and Mhatre, Nishchay S. and Karandikar, Shrirang K.},
title = {FIRA - a Novel Method for Benchmarking the Cache Hierarchy},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459132},
doi = {10.1145/2459118.2459132},
abstract = {CPU Micro-architecture has a significant impact on performance and hence benchmarking micro-architectural performance is of utility to the High-Performance Computing industry. In lieu of conventional benchmarks, benchmarks that reflect the performance of micro-architectural features, independent of the application profile, are required. Memory hierarchy is an important part of the micro-architecture, having a major impact on performance. In order to make an application independent characterisation of the memory hierarchy, it is necessary to measure its important performance parameters, namely the penalty for a cache miss in different cache levels. The conventional program used for analysing the memory system does not provide direct and cycle-accurate measurements for all levels of the hierarchy. This work presents a novel method of benchmarking the cache. It uses a unique access pattern to generate a deterministic number of cache misses in every level and measures the access time. Using this method the access time for each cache level can be directly obtained. We describe the method in detail herein and discuss the results obtained for different micro-architecture variants. We check the results for consistency using statistics from numerous runs. We also check the results against those provided by the traditional method. Finally, we compare the estimated number of cache misses caused by our deterministic method with the actual number of misses, as measured by hardware performance counters.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {14},
numpages = {6},
keywords = {micro-architecture, cache, benchmarking},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459133,
author = {Pawar, Sachin and Srivastava, Rajiv and Palshikar, Girish Keshav},
title = {Automatic Gazette Creation for Named Entity Recognition and Application to Resume Processing},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459133},
doi = {10.1145/2459118.2459133},
abstract = {Named entities are important content-carrying units within documents. Consequently named entity recognition (NER) is an important part of information extraction. One fast and accurate approach to NER uses a list or gazette consisting of known instances. Gazette creation problem considers how to automatically create a comprehensive gazette from given unlabeled document repository. We describe an unsupervised algorithm for automatic gazette creation, which is modified from [5]. We propose a fast NER algorithm using large gazette and show that it significantly outperforms a na\"{\i}ve approach based on regular expressions. We describe experimental results obtained by using the system for gazette creation for various resume related named entities (e.g., ORG, DEGREE, EDUCATIONAL_INSTITUTE, DESIGNATION) and the associated NER on a large set of real-life resumes.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {15},
numpages = {7},
keywords = {information retrieval, gazette creation, resume processing, named entity recognition, information extraction, named entity extraction},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459134,
author = {Emeras, Joseph and Bzeznik, Bruno and Richard, Olivier and Georgiou, Yiannis and Ruiz, Cristian},
title = {Reconstructing the Software Environment of an Experiment with Kameleon},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459134},
doi = {10.1145/2459118.2459134},
abstract = {In the scientific experimentation process, an experiment result needs to be analyzed and compared with several others, potentially obtained in different conditions. Thus, the experimenter needs to be able to redo the experiment. Several tools are dedicated to the control of the experiment input parameters and the experiment replay. In parallel concurrent and distributed systems, experiment conditions are not only restricted to the input parameters, but also to the software environment in which the experiment was carried out. It is therefore essential to be able to reconstruct this type of environment. The task can quickly become complex for experimenters, particularly on research platforms dedicated to scientific experimentation, where both hardware and software are in constant rapid evolution. This article discusses the concept of the reconstructability of software environments and proposes a tool for dealing with this problem.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {16},
numpages = {8},
keywords = {data provenance, environment, scientific experimentation, reconstructability, reproducibility},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459135,
author = {Kuppusamy, Sivakumar and Vivekanadan, K. and Thiyagarajan, Ramasubramanian and Devi, T.},
title = {Email Marketing and Scalability Using Hadoop},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459135},
doi = {10.1145/2459118.2459135},
abstract = {E-Mail Marketing and Scalability application will enable large retailers to intelligently manage communication to existing potential customers. In doing so, the application will drive incremental traffic and sales to high end retailers, extends customer loyalty, enlarge marketing efforts, channelise marketing team efficiency and create a modularized scalable foundation for better response.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {17},
numpages = {4},
keywords = {prediction, optimization, email marketing, decision making, scalability},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459136,
author = {Banerjee, Ansuman},
title = {A Formal Model for Multi-Tenant Software-as-a-Service in Cloud Computing},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459136},
doi = {10.1145/2459118.2459136},
abstract = {A multi-tenant software as a service (SaaS) system has to meet the needs of several tenant organizations, which connect to the system to utilize its services. To leverage economies of scale through re-use, a SaaS vendor would, in general, like to drive commonality amongst the requirements across tenants. However, many tenants will also come with some custom requirements that may be a pre-requisite for them to adopt the SaaS system. These requirements then need to be addressed by evolving the SaaS system in a controlled manner, while still supporting the requirements of existing tenants. In this paper, we study the challenges associated with engineering multi-tenant SaaS systems and develop a framework to help evolve and validate such systems in a systematic manner. We adopt an intuitive formal model of services. We show that the proposed formalism is easily amenable to tenant requirement analysis and provides a systematic way to support multiple tenant on-boarding and diverse service management.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {18},
numpages = {6},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459137,
author = {Lakshmanan, Gayatri},
title = {HiPERS Batch.NET - a High Performance, Extensible, Reliable and Scalable Batch Framework Using Microsoft.NET},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459137},
doi = {10.1145/2459118.2459137},
abstract = {Batch jobs are the back bone of IT functionality in all industries. Typically these jobs are executed overnight, after "End of Day/Week/Month/Year" and perform business critical processing of huge amounts of data, to bring software systems up-to-date for the next day's business. Due to the huge processing requirements, batch systems have been traditionally implemented in legacy Mainframe environments. These systems are costly to develop and maintain, and require manpower skilled in what is fast becoming an obsolete platform. In this paper, I propose HiPERS Batch- a simple multi-server batch framework which: (i) is High in Performance -- can match the processing power of legacy batch systems, (ii) is Extensible - accommodates new batch business functionalities without code change, (iii) is Reliable -- recovers from failures and resumes processing from the correct point, and (iv) is Scalable -- easily handles growing volumes of business data by accommodating increasing number of servers in its configuration without performance degradation. HiPERS Batch exploits the data and task level parallelism inherent in batch functionality. A salient feature of HiPERS multi server batch framework is that the communication between the servers takes place solely through the database -- this does not impact performance as is commonly believed. As part of work done for a large Insurer, HiPERS Batch was implemented using Microsoft"s.NET framework 2.0 (HiPERS Batch.NET) with virtual servers of modest specifications (no more powerful than a modern day laptop) to replace a powerful legacy mainframe batch system; the results of this implementation, as shown in this paper, prove that HiPERS Batch is a viable framework for a modern batch system.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {19},
numpages = {8},
keywords = {scalable, task parallelism, HiPERS batch, Microsoft .NET, batch processing, data parallelism, high performance batch},
location = {Pune, India},
series = {COMPUTE '12}
}

@inproceedings{10.1145/2459118.2459138,
author = {Rajawat, Anand Singh and Dwivedi, Upendra and Jain, Dinesh Ch. and Upadhyay, Akhilesh R.},
title = {Efficient Web Data Classification Techniques Using Semi-Supervise Learning Algorithm},
year = {2012},
isbn = {9781450314404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459118.2459138},
doi = {10.1145/2459118.2459138},
abstract = {In Organization the data is very important that increase the volume of information that is available on the web and that leads to the design of efficient and accurate web data classification systems. In this paper, we define a framework to improve the performance of a base classifier, by clustering the unlabeled data with labeled data using clustering algorithm (training of samples) labeling of clusters (majority voting for each Hyperspheres) and final generated classified data. We have used construction of BNN based semi-supervised classifier while training and testing of the classifier is performed. We have studied and customized a supervised classification algorithm to form out semi-supervised classification that leads to design a multiclass semi-supervised classifier using geometrical expansion. The experimental result shows provision for the classifier designer followed by training and testing medical disease dataset using pre-decided samples. Our classification model consists of training phase that covers two process clustering and labeling to perform classification task of medical data and the binary neural network is trained. In this we used two techniques normalization and quantization for pre-processing the datasets. Pre-processing impart various outcomes after applying the classification model like number of hypersphere, confusing samples that cannot be learned, training time and label of hypersphere. Comparison has been done for implementation and design of Binary Neural Network Classifier Algorithm with the other existing traditional algorithms. Our classifier evaluates performance in terms of generalization, number of hidden neuron and accuracy etc. The BNN-CA construct three-layered binary neural network (BNN) and can solve any semi-labeled multi-class problem.},
booktitle = {Proceedings of the 5th ACM COMPUTE Conference: Intelligent &amp; Scalable System Technologies},
articleno = {20},
numpages = {8},
keywords = {supervise learning, semi-supervise learning, data pre-processing, data classification techniques, unsupervised learning and BNN, BNN-CA},
location = {Pune, India},
series = {COMPUTE '12}
}

