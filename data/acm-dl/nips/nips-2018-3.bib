@inproceedings{10.5555/3327345.3327545,
author = {Levy, Kfir Y. and Yurtsever, Alp and Cevher, Volkan},
title = {Online Adaptive Methods, Universality and Acceleration},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a novel method for convex unconstrained optimization that, without any modifications, ensures: (i) accelerated convergence rate for smooth objectives, (ii) standard convergence rate in the general (non-smooth) setting, and (iii) standard convergence rate in the stochastic optimization setting. To the best of our knowledge, this is the first method that simultaneously applies to all of the above settings.At the heart of our method is an adaptive learning rate rule that employs importance weights, in the spirit of adaptive online learning algorithms [12, 20], combined with an update that linearly couples two sequences, in the spirit of [2]. An empirical examination of our method demonstrates its applicability to the above mentioned scenarios and corroborates our theoretical findings.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6501–6510},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327544,
author = {Bailey, Bolton and Telgarsky, Matus},
title = {Size-Noise Tradeoffs in Generative Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper investigates the ability of generative networks to convert their input noise distributions into other distributions. Firstly, we demonstrate a construction that allows ReLU networks to increase the dimensionality of their noise distribution by implementing a "space-filling" function based on iterated tent maps. We show this construction is optimal by analyzing the number of affine pieces in functions computed by multivariate ReLU networks. Secondly, we provide efficient ways (using polylog(1/e) nodes) for networks to pass between univariate uniform and normal distributions, using a Taylor series approximation and a binary search gadget for computing function inverses. Lastly, we indicate how high dimensional distributions can be efficiently transformed into low dimensional distributions.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6490–6500},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327543,
author = {Smith, Edward and Fujimoto, Scott and Meger, David},
title = {Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the problem of scaling deep generative shape models to high-resolution. Drawing motivation from the canonical view representation of objects, we introduce a novel method for the fast up-sampling of 3D objects in voxel space through networks that perform super-resolution on the six orthographic depth projections. This allows us to generate high-resolution objects with more efficient scaling than methods which work directly in 3D. We decompose the problem of 2D depth super-resolution into silhouette and depth prediction to capture both structure and fine detail. This allows our method to generate sharp edges more easily than an individual network. We evaluate our work on multiple experiments concerning high-resolution 3D objects, and show our system is capable of accurately predicting novel objects at resolutions as large as 512\texttimes{}512\texttimes{}512 – the highest resolution reported for this task. We achieve state-of-the-art performance on 3D object reconstruction from RGB images on the ShapeNet dataset, and further demonstrate the first effective 3D super-resolution method.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6479–6489},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327542,
author = {Wu, Lijun and Tian, Fei and Xia, Yingce and Fan, Yang and Qin, Tao and Lai, Jianhuang and Liu, Tie-Yan},
title = {Learning to Teach with Dynamic Loss Functions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g., textbooks), but also sets up appropriate learning objectives (e.g., course projects and exams) considering different situations of a student. When it comes to artificial intelligence, treating machine learning models as students, the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work, we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed, in our framework, the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible, exempt of the ineffective solutions such as policy optimization. We name our method as "learning to teach with dynamic loss functions" (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6467–6478},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327541,
author = {Huang, Qiuyuan and Zhang, Pengchuan and Wu, Dapeng and Zhang, Lei},
title = {Turbo Learning for CaptionBot and DrawingBot},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study in this paper the problems of both image captioning and text-to-image generation, and present a novel turbo learning approach to jointly training an image-to-text generator (a.k.a. CaptionBot) and a text-to-image generator (a.k.a. DrawingBot). The key idea behind the joint training is that image-to-text generation and text-to-image generation as dual problems can form a closed loop to provide informative feedback to each other. Based on such feedback, we introduce a new loss metric by comparing the original input with the output produced by the closed loop. In addition to the old loss metrics used in CaptionBot and DrawingBot, this extra loss metric makes the jointly trained CaptionBot and DrawingBot better than the separately trained CaptionBot and DrawingBot. Furthermore, the turbo-learning approach enables semi-supervised learning since the closed loop can provide peudo-labels for unlabeled samples. Experimental results on the COCO dataset demonstrate that the proposed turbo learning can significantly improve the performance of both CaptionBot and DrawingBot by a large margin.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6456–6466},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327540,
author = {Klys, Jack and Snell, Jake and Zemel, Richard},
title = {Learning Latent Subspaces in Variational Autoencoders},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Variational autoencoders (VAEs) [10, 20] are widely used deep generative models capable of learning unsupervised latent representations of data. Such representations are often difficult to interpret or control. We consider the problem of unsupervised learning of features correlated to specific labels in a dataset. We propose a VAE-based generative model which we show is capable of extracting features correlated to binary labels in the data and structuring it in a latent subspace which is easy to interpret. Our model, the Conditional Subspace VAE (CSVAE), uses mutual information minimization to learn a low-dimensional latent subspace associated with each label that can easily be inspected and independently manipulated. We demonstrate the utility of the learned representations for attribute manipulation tasks on both the Toronto Face [23] and CelebA [15] datasets.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6445–6455},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327539,
author = {Rol\'{\i}nek, Michal and Martius, Georg},
title = {L4: Practical Loss-Based Stepsize Adaptation for Deep Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose a stepsize adaptation scheme for stochastic gradient descent. It operates directly with the loss function and rescales the gradient in order to make fixed predicted progress on the loss. We demonstrate its capabilities by conclusively improving the performance of Adam and Momentum optimizers. The enhanced optimizers with default hyperparameters consistently outperform their constant stepsize counterparts, even the best ones, without a measurable increase in computational cost. The performance is validated on multiple architectures including dense nets, CNNs, ResNets, and the recurrent Differential Neural Computer on classical datasets MNIST, fashion MNIST, CIFAR10 and others.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6434–6444},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327538,
author = {Laha, Anirban and Chemmengath, Saneem A. and Agrawal, Priyanka and Khapra, Mitesh M. and Sankaranarayanan, Karthik and Ramaswamy, Harish G.},
title = {On Controllable Sparse Alternatives to Softmax},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Converting an n-dimensional vector to a probability distribution over n objects is a commonly used component in many machine learning tasks like multiclass classification, multilabel classification, attention mechanisms etc. For this, several probability mapping functions have been proposed and employed in literature such as softmax, sum-normalization, spherical softmax, and sparsemax, but there is very little understanding in terms how they relate with each other. Further, none of the above formulations offer an explicit control over the degree of sparsity. To address this, we develop a unified framework that encompasses all these formulations as special cases. This framework ensures simple closed-form solutions and existence of sub-gradients suitable for learning via backpropagation. Within this framework, we propose two novel sparse formulations, sparsegen-lin and sparsehourglass, that seek to provide a control over the degree of desired sparsity. We further develop novel convex loss functions that help induce the behavior of aforementioned formulations in the multilabel classification setting, showing improved performance. We also demonstrate empirically that the proposed formulations, when used to compute attention weights, achieve better or comparable performance on standard seq2seq tasks like neural machine translation and abstractive summarization.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6423–6433},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327537,
author = {You, Jiaxuan and Liu, Bowen and Ying, Rex and Pande, Vijay and Leskovec, Jure},
title = {Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Generating novel graph structures that optimize given objectives while obeying some given underlying rules is fundamental for chemistry, biology and social science research. This is especially important in the task of molecular graph generation, whose goal is to discover novel molecules with desired properties such as drug-likeness and synthetic accessibility, while obeying physical laws such as chemical valency. However, designing models to find molecules that optimize desired properties while incorporating highly complex and non-differentiable rules remains to be a challenging task. Here we propose Graph Convolutional Policy Network (GCPN), a general graph convolutional network based model for goal-directed graph generation through reinforcement learning. The model is trained to optimize domain-specific rewards and adversarial loss through policy gradient, and acts in an environment that incorporates domain-specific rules. Experimental results show that GCPN can achieve 61% improvement on chemical property optimization over state-of-the-art baselines while resembling known molecules, and achieve 184% improvement on the constrained property optimization task.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6412–6422},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327536,
author = {Nissim, Kobbi and Smith, Adam and Steinke, Thomas and Stemmer, Uri and Ullman, Jonathan},
title = {The Limits of Post-Selection Generalization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {While statistics and machine learning offers numerous methods for ensuring generalization, these methods often fail in the presence of post selection—the common practice in which the choice of analysis depends on previous interactions with the same dataset. A recent line of work has introduced powerful, general purpose algorithms that ensure a property called post hoc generalization (Cummings et al., COLT'16), which says that no person when given the output of the algorithm should be able to find any statistic for which the data differs significantly from the population it came from.In this work we show several limitations on the power of algorithms satisfying post hoc generalization. First, we show a tight lower bound on the error of any algorithm that satisfies post hoc generalization and answers adaptively chosen statistical queries, showing a strong barrier to progress in post selection data analysis. Second, we show that post hoc generalization is not closed under composition, despite many examples of such algorithms exhibiting strong composition properties.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6402–6411},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327535,
author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
title = {Visualizing the Loss Landscape of Neural Nets},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural network training relies on our ability to find "good" minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and well-chosen training parameters (batch size, learning rate, optimizer) produce minimiz-ers that generalize better. However, the reasons for these differences, and their effect on the underlying loss landscape, is not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple "filter normalization" method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6391–6401},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327534,
author = {Teng, Michael and Wood, Frank},
title = {Bayesian Distributed Stochastic Gradient Descent},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce Bayesian distributed stochastic gradient descent (BDSGD), a high-throughput algorithm for training deep neural networks on parallel computing clusters. This algorithm uses amortized inference in a deep generative model to perform joint posterior predictive inference of mini-batch gradient computation times in a compute cluster specific manner. Specifically, our algorithm mitigates the straggler effect in synchronous, gradient-based optimization by choosing an optimal cutoff beyond which mini-batch gradient messages from slow workers are ignored. The principle novel contribution and finding of this work goes beyond this by demonstrating that using the predicted run-times from a generative model of cluster worker performance improves over the static-cutoff prior art, leading to higher gradient computation throughput on large compute clusters. In our experiments we show that eagerly discarding the mini-batch gradient computations of stragglers not only increases throughput but sometimes also increases the overall rate of convergence as a function of wall-clock time by virtue of eliminating idleness.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6380–6390},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327533,
author = {Wang, Shiqi and Pei, Kexin and Whitehouse, Justin and Yang, Junfeng and Jana, Suman},
title = {Efficient Formal Safety Analysis of Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural networks are increasingly deployed in real-world safety-critical domains such as autonomous driving, aircraft collision avoidance, and malware detection. However, these networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations. Consequences of such errors can be disastrous and even potentially fatal as shown by the recent Tesla autopilot crashes. Thus, there is an urgent need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations within a certain L-norm of a given image. An effective safety analysis system for a neural network must be able to either ensure that a safety property is satisfied by the network or find a counterexample, i.e., an input for which the network will violate the property. Unfortunately, most existing techniques for performing such analysis struggle to scale beyond very small networks and the ones that can scale to larger networks suffer from high false positives and cannot produce concrete counterexamples in case of a property violation. In this paper, we present a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperforms existing approaches by multiple orders of magnitude. Our approach can check different safety properties and find concrete counterexamples for networks that are 10 \texttimes{} larger than the ones supported by existing analysis techniques. We believe that our approach to estimating tight output bounds of a network for a given input range can also help improve the explainability of neural networks and guide the training process of more robust neural networks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6369–6379},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327532,
author = {Wydmuch, Marek and Jasinska, Kalina and Kuznetsov, Mikhail and Busa-Fekete, R\'{o}bert and Dembczy\'{n}ski, Krzysztof},
title = {A No-Regret Generalization of Hierarchical Softmax to Extreme Multi-Label Classification},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Extreme multi-label classification (XMLC) is a problem of tagging an instance with a small subset of relevant labels chosen from an extremely large pool of possible labels. Large label spaces can be efficiently handled by organizing labels as a tree, like in the hierarchical softmax (HSM) approach commonly used for multi-class problems. In this paper, we investigate probabilistic label trees (PLTs) that have been recently devised for tackling XMLC problems. We show that PLTs are a no-regret multi-label generalization of HSM when precision@k is used as a model evaluation metric. Critically, we prove that pick-one-label heuristic—a reduction technique from multi-label to multi-class that is routinely used along with HSM—is not consistent in general. We also show that our implementation of PLTs, referred to as EXTREMETEXT (XT), obtains significantly better results than HSM with the pick-one-label heuristic and XML-CNN, a deep network specifically designed for XMLC problems. Moreover, XT is competitive to many state-of-the-art approaches in terms of statistical performance, model size and prediction time which makes it amenable to deploy in an online system.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6358–6368},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327531,
author = {Jayaraman, Bargav and Wang, Lingxiao and Evans, David and Gu, Quanquan},
title = {Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Distributed learning allows a group of independent data owners to collaboratively learn a model over their data sets without exposing their private data. We present a distributed learning approach that combines differential privacy with secure multiparty computation. We explore two popular methods of differential privacy, output perturbation and gradient perturbation, and advance the state-of-the-art for both methods in the distributed learning setting. In our output perturbation method, the parties combine local models within a secure computation and then add the required differential privacy noise before revealing the model. In our gradient perturbation method, the data owners collaboratively train a global model via an iterative learning algorithm. At each iteration, the parties aggregate their local gradients within a secure computation, adding sufficient noise to ensure privacy before the gradient updates are revealed. For both methods, we show that the noise can be reduced in the multi-party setting by adding the noise inside the secure computation after aggregation, asymptotically improving upon the best previous results. Experiments on real world data sets demonstrate that our methods provide substantial utility gains for typical privacy requirements.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6346–6357},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327530,
author = {Kaufmann, Emilie and Koolen, Wouter M. and Garivier, Aur\'{e}lien},
title = {Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Learning the minimum/maximum mean among a finite set of distributions is a fundamental sub-task in planning, game tree search and reinforcement learning. We formalize this learning task as the problem of sequentially testing how the minimum mean among a finite set of distributions compares to a given threshold. We develop refined non-asymptotic lower bounds, which show that optimality mandates very different sampling behavior for a low vs high true minimum. We show that Thompson Sampling and the intuitive Lower Confidence Bounds policy each nail only one of these cases. We develop a novel approach that we call Murphy Sampling. Even though it entertains exclusively low true minima, we prove that MS is optimal for both possibilities. We then design advanced self-normalized deviation inequalities, fueling more aggressive stopping rules. We complement our theoretical guarantees by experiments showing that MS works best in practice.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6335–6345},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327529,
author = {Graber, Colin and Meshi, Ofer and Schwing, Alexander},
title = {Deep Structured Prediction with Nonlinear Output Transformations},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep structured models are widely used for tasks like semantic segmentation, where explicit correlations between variables provide important prior information which generally helps to reduce the data needs of deep nets. However, current deep structured models are restricted by oftentimes very local neighborhood structure, which cannot be increased for computational complexity reasons, and by the fact that the output configuration, or a representation thereof, cannot be transformed further. Very recent approaches which address those issues include graphical model inference inside deep nets so as to permit subsequent non-linear output space transformations. However, optimization of those formulations is challenging and not well understood. Here, we develop a novel model which generalizes existing approaches, such as structured prediction energy networks, and discuss a formulation which maintains applicability of existing inference techniques.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6323–6334},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327528,
author = {Zhang, Minjia and Liu, Xiaodong and Wang, Wenhan and Gao, Jianfeng and He, Yuxiong},
title = {Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural language models (NLMs) have recently gained a renewed interest by achieving state-of-the-art performance across many natural language processing (NLP) tasks. However, NLMs are very computationally demanding largely due to the computational cost of the decoding process, which consists of a softmax layer over a large vocabulary. We observe that in the decoding of many NLP tasks, only the probabilities of the top-K hypotheses need to be calculated preciously and K is often much smaller than the vocabulary size. This paper proposes a novel softmax layer approximation algorithm, called Fast Graph Decoder (FGD), which quickly identifies, for a given context, a set of K words that are most likely to occur according to a NLM. We demonstrate that FGD reduces the decoding time by an order of magnitude while attaining close to the full softmax baseline accuracy on neural machine translation and language modeling tasks. We also prove the theoretical guarantee on the softmax approximation quality.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6311–6322},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327527,
author = {Leung, Dennis and Drton, Mathias},
title = {Algebraic Tests of General Gaussian Latent Tree Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider general Gaussian latent tree models in which the observed variables are not restricted to be leaves of the tree. Extending related recent work, we give a full semi-algebraic description of the set of covariance matrices of any such model. In other words, we find polynomial constraints that characterize when a matrix is the covariance matrix of a distribution in a given latent tree model. However, leveraging these constraints to test a given such model is often complicated by the number of constraints being large and by singularities of individual polynomials, which may invalidate standard approximations to relevant probability distributions. Illustrating with the star tree, we propose a new testing methodology that circumvents singularity issues by trading off some statistical estimation efficiency and handles cases with many constraints through recent advances on Gaussian approximation for maxima of sums of high-dimensional random vectors. Our test avoids the need to maximize the possibly multimodal likelihood function of such models and is applicable to models with larger number of variables. These points are illustrated in numerical experiments.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6301–6310},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327526,
author = {Wang, Qing and Xiong, Jiechao and Han, Lei and Sun, Peng and Liu, Han and Zhang, Tong},
title = {Exponentially Weighted Imitation Learning for Batched Historical Data},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider deep policy learning with only batched historical trajectories. The main challenge of this problem is that the learner no longer has a simulator or "environment oracle" as in most reinforcement learning settings. To solve this problem, we propose a monotonic advantage reweighted imitation learning strategy that is applicable to problems with complex nonlinear function approximation and works well with hybrid (discrete and continuous) action space. The method does not rely on the knowledge of the behavior policy, thus can be used to learn from data generated by an unknown policy. Under mild conditions, our algorithm, though surprisingly simple, has a policy improvement bound and outperforms most competing methods empirically. Thorough numerical results are also provided to demonstrate the efficacy of the proposed methodology.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6291–6300},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327525,
author = {Balle, Borja and Barthe, Gilles and Gaboardi, Marco},
title = {Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Differential privacy comes equipped with multiple analytical tools for the design of private data analyses. One important tool is the so-called "privacy amplification by subsampling" principle, which ensures that a differentially private mechanism run on a random subsample of a population provides higher privacy guarantees than when run on the entire population. Several instances of this principle have been studied for different random subsampling methods, each with an ad-hoc analysis. In this paper we present a general method that recovers and improves prior analyses, yields lower bounds and derives new instances of privacy amplification by subsampling. Our method leverages a characterization of differential privacy as a divergence which emerged in the program verification community. Furthermore, it introduces new tools, including advanced joint convexity and privacy profiles, which might be of independent interest.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6280–6290},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327524,
author = {Ghassami, AmirEmad and Kiyavash, Negar and Huang, Biwei and Zhang, Kun},
title = {Multi-Domain Causal Structure Learning in Linear Systems},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study the problem of causal structure learning in linear systems from observational data given in multiple domains, across which the causal coefficients and/or the distribution of the exogenous noises may vary. The main tool used in our approach is the principle that in a causally sufficient system, the causal modules, as well as their included parameters, change independently across domains. We first introduce our approach for finding causal direction in a system comprising two variables and propose efficient methods for identifying causal direction. Then we generalize our methods to causal structure learning in networks of variables. Most of previous work in structure learning from multi-domain data assume that certain types of invariance are held in causal modules across domains. Our approach unifies the idea in those works and generalizes to the case that there is no such invariance across the domains. Our proposed methods are generally capable of identifying causal direction from fewer than ten domains. When the invariance property holds, two domains are generally sufficient.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6269–6279},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327523,
author = {Merri\"{e}nboer, Bart van and Moldovan, Dan and Wiltschko, Alexander B.},
title = {Tangent: Automatic Differentiation Using Source-Code Transformation for Dynamically Typed Array Programming},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The need to efficiently calculate first- and higher-order derivatives of increasingly complex models expressed in Python has stressed or exceeded the capabilities of available tools. In this work, we explore techniques from the field of automatic differentiation (AD) that can give researchers expressive power, performance and strong usability. These include source-code transformation (SCT), flexible gradient surgery, efficient in-place array operations, and higher-order derivatives. We implement and demonstrate these ideas in the Tangent software library for Python, the first AD framework for a dynamic language that uses SCT.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6259–6268},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327522,
author = {Mishkin, Aaron and Kunstner, Frederik and Nielsen, Didrik and Schmidt, Mark and Khan, Mohammad Emtiyaz},
title = {SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Uncertainty estimation in large deep-learning models is a computationally challenging task, where it is difficult to form even a Gaussian approximation to the posterior distribution. In such situations, existing methods usually resort to a diagonal approximation of the covariance matrix despite the fact that these matrices are known to give poor uncertainty estimates. To address this issue, we propose a new stochastic, low-rank, approximate natural-gradient (SLANG) method for variational inference in large, deep models. Our method estimates a "diagonal plus low-rank" structure based solely on back-propagated gradients of the network log-likelihood. This requires strictly less gradient computations than methods that compute the gradient of the whole variational objective. Empirical evaluations on standard benchmarks confirm that SLANG enables faster and more accurate estimation of uncertainty than mean-field methods, and performs comparably to state-of-the-art methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6248–6258},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327521,
author = {Ono, Yuki and Trulls, Eduard and Fua, Pascal and Yi, Kwang Moo},
title = {LF-Net: Learning Local Features from Images},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a novel deep architecture and a training strategy to learn a local feature pipeline from scratch, using collections of images without the need for human supervision. To do so we exploit depth and relative camera pose cues to create a virtual target that the network should achieve on one image, provided the outputs of the network for the other image. While this process is inherently non-differentiable, we show that we can optimize the network in a two-branch setup by confining it to one branch, while preserving differentiability in the other. We train our method on both indoor and outdoor datasets, with depth data from 3D sensors for the former, and depth estimates from an off-the-shelf Structure-from-Motion solution for the latter. Our models outperform the state of the art on sparse feature matching on both datasets, while running at 60+ fps for QVGA images.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6237–6247},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327520,
author = {Liu, Weiyang and Lin, Rongmei and Liu, Zhen and Liu, Lixin and Yu, Zhiding and Dai, Bo and Song, Le},
title = {Learning towards Minimum Hyperspherical Energy},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural networks are a powerful class of nonlinear functions that can be trained end-to-end on various applications. While the over-parametrization nature in many neural networks renders the ability to fit complex functions and the strong representation power to handle challenging tasks, it also leads to highly correlated neurons that can hurt the generalization ability and incur unnecessary computation cost. As a result, how to regularize the network to avoid undesired representation redundancy becomes an important issue. To this end, we draw inspiration from a well-known problem in physics – Thomson problem, where one seeks to find a state that distributes N electrons on a unit sphere as evenly as possible with minimum potential energy. In light of this intuition, we reduce the redundancy regularization problem to generic energy minimization, and propose a minimum hyperspherical energy (MHE) objective as generic regularization for neural networks. We also propose a few novel variants of MHE, and provide some insights from a theoretical point of view. Finally, we apply neural networks with MHE regularization to several challenging tasks. Extensive experiments demonstrate the effectiveness of our intuition, by showing the superior performance with MHE regularization.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6225–6236},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327519,
author = {Burkov, Egor and Lempitsky, Victor},
title = {Deep Neural Networks with Box Convolutions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Box filters computed using integral images have been part of the computer vision toolset for a long time. Here, we show that a convolutional layer that computes box filter responses in a sliding manner can be used within deep architectures, whereas the dimensions and the offsets of the sliding boxes in such a layer can be learned as a part of an end-to-end loss minimization. Crucially, the training process can make the size of the boxes in such a layer arbitrarily large without incurring extra computational cost and without the need to increase the number of learnable parameters. Due to its ability to integrate information over large boxes, the new layer facilitates long-range propagation of information and leads to the efficient increase of the receptive fields of network units. By incorporating the new layer into existing architectures for semantic segmentation, we are able to achieve both the increase in segmentation accuracy as well as the decrease in the computational cost and the number of learnable parameters.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6214–6224},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327518,
author = {Diakonikolas, Ilias and Kane, Daniel M. and Stewart, Alistair},
title = {Sharp Bounds for Generalized Uniformity Testing},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study the problem of generalized uniformity testing of a discrete probability distribution: Given samples from a probability distribution p over an unknown size discrete domain Ω, we want to distinguish, with probability at least 2/3, between the case that p is uniform on some subset of Ω versus ε-far, in total variation distance, from any such uniform distribution. We establish tight bounds on the sample complexity of generalized uniformity testing. In more detail, we present a computationally efficient tester whose sample complexity is optimal, within constant factors, and a matching worst-case information-theoretic lower bound. Specifically, we show that the sample complexity of generalized uniformity testing is Θ (1/(ε4/3||p||3) + 1/(ε2||p||2)).},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6204–6213},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327517,
author = {Davidson, Ian and Gourru, Antoine and Ravi, S. S.},
title = {The Cluster Description Problem - Complexity Results, Formulations and Approximations},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Consider the situation where you are given an existing k-way clustering π. A challenge for explainable AI is to find a compact and distinct explanation of each cluster which in this paper is assumed to use instance-level descriptors/tags from a common dictionary. Since the descriptors/tags were not given to the clustering method, this is not a semi-supervised learning situation. We show that the feasibility problem of testing whether any distinct description (not necessarily the most compact) exists is generally intractable for just two clusters. This means that unless P = NP, there cannot exist an efficient algorithm for the cluster description problem. Hence, we explore ILP formulations for smaller problems and a relaxed but restricted setting that leads to a polynomial time algorithm for larger problems. We explore several extensions to the basic setting such as the ability to ignore some instances and composition constraints on the descriptions of the clusters. We show our formulation's usefulness on Twitter data where the communities were found using social connectivity (i.e. follower relation) but the explanation of the communities is based on behavioral properties of the nodes (i.e. hashtag usage) not available to the clustering method.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6193–6203},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327516,
author = {Tirinzoni, Andrea and Sanchez, Rafael Rodriguez and Restelli, Marcello},
title = {Transfer of Value Functions via Variational Methods},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the problem of transferring value functions in reinforcement learning. We propose an approach that uses the given source tasks to learn a prior distribution over optimal value functions and provide an efficient variational approximation of the corresponding posterior in a new target task. We show our approach to be general, in the sense that it can be combined with complex parametric function approximators and distribution models, while providing two practical algorithms based on Gaussians and Gaussian mixtures. We theoretically analyze them by deriving a finite-sample analysis and provide a comprehensive empirical evaluation in four different domains.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6182–6192},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327515,
author = {Lin, Hongzhou and Jegelka, Stefanie},
title = {ResNet with One-Neuron Hidden Layers is a Universal Approximator},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We demonstrate that a very deep ResNet with stacked modules that have one neuron per hidden layer and ReLU activation functions can uniformly approximate any Lebesgue integrable function in d dimensions, i.e. ℓ1(ℝd). Due to the identity mapping inherent to ResNets, our network has alternating layers of dimension one and d. This stands in sharp contrast to fully connected networks, which are not universal approximators if their width is the input dimension d [21, 11]. Hence, our result implies an increase in representational power for narrow deep networks by the ResNet architecture.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6172–6181},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327514,
author = {Schmidt, Florian and Hofmann, Thomas},
title = {Deep State Space Models for Unconditional Word Generation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Autoregressive feedback is considered a necessity for successful unconditional text generation using stochastic sequence models. However, such feedback is known to introduce systematic biases into the training process and it obscures a principle of generation: committing to global information and forgetting local nuances. We show that a non-autoregressive deep state space model with a clear separation of global and local uncertainty can be built from only two ingredients: An independent noise source and a deterministic transition function. Recent advances on flow-based variational inference can be used to train an evidence lower-bound without resorting to annealing, auxiliary losses or similar measures. The result is a highly interpretable generative model on par with comparable auto-regressive models on the task of word generation.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6161–6171},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327513,
author = {Madras, David and Pitassi, Toniann and Zemel, Richard},
title = {Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In many machine learning applications, there are multiple decision-makers involved, both automated and human. The interaction between these agents often goes unaddressed in algorithmic development. In this work, we explore a simple version of this interaction with a two-stage framework containing an automated model and an external decision-maker. The model can choose to say PASS, and pass the decision downstream, as explored in rejection learning. We extend this concept by proposing learning to defer, which generalizes rejection learning by considering the effect of other agents in the decision-making process. We propose a learning algorithm which accounts for potential biases held by external decision-makers in a system. Experiments demonstrate that learning to defer can make systems not only more accurate but also less biased. Even when working with inconsistent or biased users, we show that deferring models still greatly improve the accuracy and/or fairness of the entire system.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6150–6160},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327512,
author = {Yuan, Jianjun and Lamperski, Andrew},
title = {Online Convex Optimization for Cumulative Constraints},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose the algorithms for online convex optimization which lead to cumulative squared constraint violations of the form ∑Tt-1 ([g(xt)]+)2 = O(T1-β), where β ∈ (0,1) . Previous literature has focused on long-term constraints of the form ∑Tt-1 g(xt). There, strictly feasible solutions can cancel out the effects of violated constraints. In contrast, the new form heavily penalizes large constraint violations and cancellation effects cannot occur. Furthermore, useful bounds on the single step constraint violation [g(xt)]+ are derived. For convex objectives, our regret bounds generalize existing bounds, and for strongly convex objectives we give improved regret bounds. In numerical experiments, we show that our algorithm closely follows the constraint boundary leading to low cumulative violation.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6140–6149},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327511,
author = {Kim, Seungryong and Lin, Stephen and Jeon, Sangryul and Min, Dongbo and Sohn, Kwanghoon},
title = {Recurrent Transformer Networks for Semantic Correspondence},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present recurrent transformer networks (RTNs) for obtaining dense correspondences between semantically similar images. Our networks accomplish this through an iterative process of estimating spatial transformations between the input images and using these transformations to generate aligned convolutional activations. By directly estimating the transformations between an image pair, rather than employing spatial transformer networks to independently normalize each individual image, we show that greater accuracy can be achieved. This process is conducted in a recursive manner to refine both the transformation estimates and the feature representations. In addition, a technique is presented for weakly-supervised training of RTNs that is based on a proposed classification loss. With RTNs, state-of-the-art performance is attained on several benchmarks for semantic correspondence.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6129–6139},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327510,
author = {Lopez, Romain and Regier, Jeffrey and Jordan, Michael I. and Yosef, Nir},
title = {Information Constraints on Auto-Encoding Variational Bayes},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Parameterizing the approximate posterior of a generative model with neural networks has become a common theme in recent machine learning research. While providing appealing flexibility, this approach makes it difficult to impose or assess structural constraints such as conditional independence. We propose a framework for learning representations that relies on auto-encoding variational Bayes, in which the search space is constrained via kernel-based measures of independence. In particular, our method employs the d-variable Hilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between the latent representations and arbitrary nuisance factors. We show how this method can be applied to a range of problems, including problems that involve learning invariant and conditionally independent representations. We also present a full-fledged application to single-cell RNA sequencing (scRNA-seq). In this setting the biological signal is mixed in complex ways with sequencing errors and sampling effects. We show that our method outperforms the state-of-the-art approach in this domain.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6117–6128},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327509,
author = {Shafahi, Ali and Huang, W. Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
title = {Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Data poisoning is an attack on machine learning models wherein the attacker adds examples to the training set to manipulate the behavior of the model at test time. This paper explores poisoning attacks on neural nets. The proposed attacks use "clean-labels"; they don't require the attacker to have any control over the labeling of training data. They are also targeted; they control the behavior of the classifier on a specific test instance without degrading overall classifier performance. For example, an attacker could add a seemingly innocuous image (that is properly labeled) to a training set for a face recognition engine, and control the identity of a chosen person at test time. Because the attacker does not need to control the labeling function, poisons could be entered into the training set simply by leaving them on the web and waiting for them to be scraped by a data collection bot.We present an optimization-based method for crafting poisons, and show that just one single poison image can control classifier behavior when transfer learning is used. For full end-to-end training, we present a "watermarking" strategy that makes poisoning reliable using multiple (≈ 50) poisoned training instances. We demonstrate our method by generating poisoned frog images from the CIFAR dataset and using them to manipulate image classifiers.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6106–6116},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327508,
author = {Pan, Boyuan and Yang, Yazheng and Li, Hao and Zhao, Zhou and Zhuang, Yueting and Cai, Deng and He, Xiaofei},
title = {MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Machine Comprehension (MC) is one of the core problems in natural language processing, requiring both understanding of the natural language and knowledge about the world. Rapid progress has been made since the release of several benchmark datasets, and recently the state-of-the-art models even surpass human performance on the well-known SQuAD evaluation. In this paper, we transfer knowledge learned from machine comprehension to the sequence-to-sequence tasks to deepen the understanding of the text. We propose MacNet: a novel encoder-decoder supplementary architecture to the widely used attention-based sequence-to-sequence models. Experiments on neural machine translation (NMT) and abstractive text summarization show that our proposed framework can significantly improve the performance of the baseline models, and our method for the abstractive text summarization achieves the state-of-the-art results on the Gigaword dataset.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6095–6105},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327507,
author = {Law, Ho Chung Leon and Sejdinovic, Dino and Cameron, Ewan and Lucas, Tim C.D. and Flaxman, Seth and Battle, Katherine and Fukumizu, Kenji},
title = {Variational Learning on Aggregate Outputs with Gaussian Processes},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {While a typical supervised learning framework assumes that the inputs and the outputs are measured at the same levels of granularity, many applications, including global mapping of disease, only have access to outputs at a much coarser level than that of the inputs. Aggregation of outputs makes generalization to new inputs much more difficult. We consider an approach to this problem based on variational learning with a model of output aggregation and Gaussian processes, where aggregation leads to intractability of the standard evidence lower bounds. We propose new bounds and tractable approximations, leading to improved prediction accuracy and scalability to large datasets, while explicitly taking uncertainty into account. We develop a framework which extends to several types of likelihoods, including the Poisson model for aggregated count data. We apply our framework to a challenging and important problem, the fine-scale spatial modelling of malaria incidence, with over 1 million observations.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6084–6094},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327506,
author = {Li, Chongxuan and Welling, Max and Zhu, Jun and Zhang, Bo},
title = {Graphical Generative Adversarial Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model structured data. Graphical-GAN conjoins the power of Bayesian networks on compactly representing the dependency structures among random variables and that of generative adversarial networks on learning expressive dependency functions. We introduce a structured recognition model to infer the posterior distribution of latent variables given observations. We generalize the Expectation Propagation (EP) algorithm to learn the generative model and recognition model jointly. Finally, we present two important instances of Graphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN), which can successfully learn the discrete and temporal structures on visual datasets, respectively.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6072–6083},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327505,
author = {Ellis, Kevin and Ritchie, Daniel and Solar-Lezama, Armando and Tenenbaum, Joshua B.},
title = {Learning to Infer Graphics Programs from Hand-Drawn Images},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce a model that learns to convert simple hand drawings into graphics programs written in a subset of LATEX. The model combines techniques from deep learning and program synthesis. We learn a convolutional neural network that proposes plausible drawing primitives that explain an image. These drawing primitives are a specification (spec) of what the graphics program needs to draw. We learn a model that uses program synthesis techniques to recover a graphics program from that spec. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network and extrapolate drawings.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6062–6071},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327504,
author = {Cui, Xiaodong and Zhang, Wei and T\"{u}ske, Zolt\'{a}n and Picheny, Michael},
title = {Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose a population-based Evolutionary Stochastic Gradient Descent (ESGD) framework for optimizing deep neural networks. ESGD combines SGD and gradient-free evolutionary algorithms as complementary algorithms in one framework in which the optimization alternates between the SGD step and evolution step to improve the average fitness of the population. With a back-off strategy in the SGD step and an elitist strategy in the evolution step, it guarantees that the best fitness in the population will never degrade. In addition, individuals in the population optimized with various SGD-based optimizers using distinct hyper-parameters in the SGD step are considered as competing species in a coevolution setting such that the complementarity of the optimizers is also taken into account. The effectiveness of ESGD is demonstrated across multiple applications including speech recognition, image recognition and language modeling, using networks with a variety of deep architectures.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6051–6061},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327503,
author = {Harris, David G. and Li, Shi and Pensyl, Thomas and Srinivasan, Aravind and Trinh, Khoa},
title = {Approximation Algorithms for Stochastic Clustering},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider stochastic settings for clustering, and develop provably-good (approximation) algorithms for a number of these notions. These algorithms allow one to obtain better approximation ratios compared to the usual deterministic clustering setting. Additionally, they offer a number of advantages including providing fairer clustering and clustering which has better long-term behavior for each user. In particular, they ensure that every user is guaranteed to get good service (on average). We also complement some of these with impossibility results. KEYWORDS: clustering, k-center, k-median, lottery, approximation algorithms},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6041–6050},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327502,
author = {Mangoubi, Oren and Vishnoi, Nisheeth K.},
title = {Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from high-dimensional distributions in Statistics and Machine learning. HMC is known to run very efficiently in practice and its popular second-order "leapfrog" implementation has long been conjectured to run in d1/4 gradient evaluations. Here we show that this conjecture is true when sampling from strongly log-concave target distributions that satisfy a weak third-order regularity property associated with the input data. Our regularity condition is weaker than the Lipschitz Hessian property and allows us to show faster convergence bounds for a much larger class of distributions than would be possible with the usual Lipschitz Hessian constant alone. Important distributions that satisfy our regularity condition include posterior distributions used in Bayesian logistic regression for which the data satisfies an "incoherence" property. Our result compares favorably with the best available bounds for the class of strongly log-concave distributions, which grow like d1/2 gradient evaluations with the dimension. Moreover, our simulations on synthetic data suggest that, when our regularity condition is satisfied, leapfrog HMC performs better than its competitors - both in terms of accuracy and in terms of the number of gradient evaluations it requires.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6030–6040},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327501,
author = {He, Xiaoxi and Zhou, Zimu and Thiele, Lothar},
title = {Multi-Task Zipping via Layer-Wise Neuron Sharing},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Future mobile devices are anticipated to perceive, understand and react to the world on their own by running multiple correlated deep neural networks on-device. Yet the complexity of these neural networks needs to be trimmed down both within-model and cross-model to fit in mobile storage and memory. Previous studies squeeze the redundancy within a single model. In this work, we aim to reduce the redundancy across multiple models. We propose Multi-Task Zipping (MTZ), a framework to automatically merge correlated, pre-trained deep neural networks for cross-model compression. Central in MTZ is a layer-wise neuron sharing and incoming weight updating scheme that induces a minimal change in the error function. MTZ inherits information from each model and demands light retraining to re-boost the accuracy of individual tasks. Evaluations show that MTZ is able to fully merge the hidden layers of two VGG-16 networks with a 3.18% increase in the test error averaged on ImageNet and CelebA, or share 39.61% parameters between the two networks with &lt; 0.5% increase in the test errors for both tasks. The number of iterations to retrain the combined network is at least 17.8 \texttimes{} lower than that of training a single VGG-16 network. Moreover, experiments show that MTZ is also able to effectively merge multiple residual networks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6019–6029},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327500,
author = {Milios, Dimitrios and Camoriano, Raffaello and Michiardi, Pietro and Rosasco, Lorenzo and Filippone, Maurizio},
title = {Dirichlet-Based Gaussian Processes for Large-Scale Calibrated Classification},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper studies the problem of deriving fast and accurate classification algorithms with uncertainty quantification. Gaussian process classification provides a principled approach, but the corresponding computational burden is hardly sustainable in large-scale problems and devising efficient alternatives is a challenge. In this work, we investigate if and how Gaussian process regression directly applied to classification labels can be used to tackle this question. While in this case training is remarkably faster, predictions need to be calibrated for classification and uncertainty estimation. To this aim, we propose a novel regression approach where the labels are obtained through the interpretation of classification labels as the coefficients of a degenerate Dirichlet distribution. Extensive experimental results show that the proposed approach provides essentially the same accuracy and uncertainty quantification as Gaussian process classification while requiring only a fraction of computational resources.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6008–6018},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327499,
author = {Yu, Yunlong and Ji, Zhong and Fu, Yanwei and Guo, Jichang and Pang, Yanwei and Zhang, Zhongfei (Mark)},
title = {Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Zero-Shot Learning (ZSL) is generally achieved via aligning the semantic relationships between the visual features and the corresponding class semantic descriptions. However, using the global features to represent fine-grained images may lead to sub-optimal results since they neglect the discriminative differences of local regions. Besides, different regions contain distinct discriminative information. The important regions should contribute more to the prediction. To this end, we propose a novel stacked semantics-guided attention (S2GA) model to obtain semantic relevant features by using individual class semantic features to progressively guide the visual features to generate an attention map for weighting the importance of different local regions. Feeding both the integrated visual features and the class semantic features into a multi-class classification architecture, the proposed framework can be trained end-to-end. Extensive experimental results on CUB and NABird datasets show that the proposed approach has a consistent improvement on both fine-grained zero-shot classification and retrieval tasks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5998–6007},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327498,
author = {Malkomes, Gustavo and Garnett, Roman},
title = {Automating Bayesian Optimization with Bayesian Optimization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Bayesian optimization is a powerful tool for global optimization of expensive functions. One of its key components is the underlying probabilistic model used for the objective function f. In practice, however, it is often unclear how one should appropriately choose a model, especially when gathering data is expensive. In this work, we introduce a novel automated Bayesian optimization approach that dynamically selects promising models for explaining the observed data using Bayesian optimization in model space. Crucially, we account for the uncertainty in the choice of model; our method is capable of using multiple models to represent its current belief about f and subsequently using this information for decision making. We argue, and demonstrate empirically, that our approach automatically finds suitable models for the objective function, which ultimately results in more-efficient optimization.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5988–5997},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327497,
author = {Alistarh, Dan and Hoefler, Torsten and Johansson, Mikael and Khirirat, Sarit and Konstantinov, Nikola and Renggli, C\'{e}dric},
title = {The Convergence of Sparsified Gradient Methods},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Stochastic Gradient Descent (SGD) has become the standard tool for distributed training of massive machine learning models, in particular deep neural networks. Several families of communication-reduction methods, such as quantization, large-batch methods, and gradient sparsification, have been proposed to reduce the overheads of distribution. To date, gradient sparsification methods–where each node sorts gradients by magnitude, and only communicates a subset of the components, accumulating the rest locally–are known to yield some of the largest practical gains. Such methods can reduce the amount of communication per step by up to three orders of magnitude, while preserving model accuracy. Yet, this family of methods currently has no theoretical justification.This is the question we address in this paper. We prove that, under analytic assumptions, sparsifying gradients by magnitude with local error correction provides convergence guarantees, for both convex and non-convex smooth objectives, for data-parallel SGD. The main insight is that sparsification methods implicitly maintain bounds on the maximum impact of stale updates, thanks to selection by magnitude. Our analysis also reveals that these methods do require analytical conditions to converge well, justifying and complementing existing heuristics.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5977–5987},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327496,
author = {Wu, Chenshen and Herranz, Luis and Liu, Xialei and Wang, Yaxing and Weijer, Joost van de and Raducanu, Bogdan},
title = {Memory Replay GANs: Learning to Generate Images from New Categories without Forgetting},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5966–5976},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327495,
author = {Jeon, Yunho and Kim, Junmo},
title = {Constructing Fast Network through Deconstruction of Convolution},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Convolutional neural networks have achieved great success in various vision tasks; however, they incur heavy resource costs. By using deeper and wider networks, network accuracy can be improved rapidly. However, in an environment with limited resources (e.g., mobile applications), heavy networks may not be usable. This study shows that naive convolution can be deconstructed into a shift operation and pointwise convolution. To cope with various convolutions, we propose a new shift operation called active shift layer (ASL) that formulates the amount of shift as a learnable function with shift parameters. This new layer can be optimized end-to-end through backpropagation and it can provide optimal shift values. Finally, we apply this layer to a light and fast network that surpasses existing state-of-the-art networks. Code is available at https://github.com/jyh2986/Active-Shift.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5955–5965},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327494,
author = {Bernacchia, Alberto and Lengyel, M\'{a}t\'{e} and Hennequin, Guillaume},
title = {Exact Natural Gradient in Deep Linear Networks and Application to the Nonlinear Case},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Stochastic gradient descent (SGD) remains the method of choice for deep learning, despite the limitations arising for ill-behaved objective functions. In cases where it could be estimated, the natural gradient has proven very effective at mitigating the catastrophic effects of pathological curvature in the objective function, but little is known theoretically about its convergence properties, and it has yet to find a practical implementation that would scale to very deep and large networks. Here, we derive an exact expression for the natural gradient in deep linear networks, which exhibit pathological curvature similar to the nonlinear case. We provide for the first time an analytical solution for its convergence rate, showing that the loss decreases exponentially to the global minimum in parameter space. Our expression for the natural gradient is surprisingly simple, computationally tractable, and explains why some approximations proposed previously work well in practice. This opens new avenues for approximating the natural gradient in the nonlinear case, and we show in preliminary experiments that our online natural gradient descent outperforms SGD on MNIST autoencoding while sharing its computational simplicity.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5945–5954},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327493,
author = {Tschannen, Michael and Agustsson, Eirikur and Lucic, Mario},
title = {Deep Generative Models for Distribution-Preserving Lossy Compression},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose and study the problem of distribution-preserving lossy compression. Motivated by recent advances in extreme image compression which allow to maintain artifact-free reconstructions even at very low bitrates, we propose to optimize the rate-distortion tradeoff under the constraint that the reconstructed samples follow the distribution of the training data. The resulting compression system recovers both ends of the spectrum: On one hand, at zero bitrate it learns a generative model of the data, and at high enough bitrates it achieves perfect reconstruction. Furthermore, for intermediate bitrates it smoothly interpolates between learning a generative model of the training data and perfectly reconstructing the training samples. We study several methods to approximately solve the proposed optimization problem, including a novel combination of Wasserstein GAN and Wasserstein Autoencoder, and present an extensive theoretical and empirical characterization of the proposed compression systems.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5933–5944},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327492,
author = {Ishida, Takashi and Niu, Gang and Sugiyama, Masashi},
title = {Binary Classification from Positive-Confidence Data},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Can we learn a binary classifier from only positive data, without any negative data or unlabeled data? We show that if one can equip positive data with confidence (positive-confidence), one can successfully learn a binary classifier, which we name positive-confidence (Pconf) classification. Our work is related to one-class classification which is aimed at "describing" the positive class by clustering-related methods, but one-class classification does not have the ability to tune hyper-parameters and their aim is not on "discriminating" positive and negative classes. For the Pconf classification problem, we provide a simple empirical risk minimization framework that is model-independent and optimization-independent. We theoretically establish the consistency and an estimation error bound, and demonstrate the usefulness of the proposed method for training deep neural networks through experiments.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5921–5932},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327491,
author = {Zhou, Tianyi and Wang, Shengjie and Bilmes, Jeff A.},
title = {Diverse Ensemble Evolution: Curriculum Data-Model Marriage},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study a new method "Diverse Ensemble Evolution (DivE2)" to train an ensemble of machine learning models that assigns data to models at each training epoch based on each model's current expertise and an intra- and inter-model diversity reward. DivE2 schedules, over the course of training epochs, the relative importance of these characteristics; it starts by selecting easy samples for each model, and then gradually adjusts towards the models having specialized and complementary expertise on subsets of the training data, thereby encouraging high accuracy of the ensemble. We utilize an intra-model diversity term on data assigned to each model, and an inter-model diversity term on data assigned to pairs of models, to penalize both within-model and cross-model redundancy. We formulate the data-model marriage problem as a generalized bipartite matching, represented as submodular maximization subject to two matroid constraints. DivE2 solves a sequence of continuous-combinatorial optimizations with slowly varying objectives and constraints. The combinatorial part handles the data-model marriage while the continuous part updates model parameters based on the assignments. In experiments, DivE2 outperforms other ensemble training methods under a variety of model aggregation techniques, while also maintaining competitive efficiency.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5909–5920},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327490,
author = {Feng, Zunlei and Wang, Xinchao and Ke, Chenglong and Zeng, Anxiang and Tao, Dacheng and Song, Mingli},
title = {Dual Swap Disentangling},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Learning interpretable disentangled representations is a crucial yet challenging task. In this paper, we propose a weakly semi-supervised method, termed as Dual Swap Disentangling (DSD), for disentangling using both labeled and unlabeled data. Unlike conventional weakly supervised methods that rely on full annotations on the group of samples, we require only limited annotations on paired samples that indicate their shared attribute like the color. Our model takes the form of a dual autoencoder structure. To achieve disentangling using the labeled pairs, we follow a "encoding-swap-decoding" process, where we first swap the parts of their encodings corresponding to the shared attribute, and then decode the obtained hybrid codes to reconstruct the original input pairs. For unlabeled pairs, we follow the "encoding-swap-decoding" process twice on designated encoding parts and enforce the final outputs to approximate the input pairs. By isolating parts of the encoding and swapping them back and forth, we impose the dimension-wise modularity and portability of the encodings of the unlabeled samples, which implicitly encourages disentangling under the guidance of labeled pairs. This dual swap mechanism, tailored for semi-supervised setting, turns out to be very effective. Experiments on image datasets from a wide domain show that our model yields state-of-the-art disentangling performances.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5898–5908},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327489,
author = {Karvonen, Toni and Oates, Chris. J. and S\"{a}rkk\"{a}, Simo},
title = {A Bayes–Sard Cubature Method},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper focusses on the formulation of numerical integration as an inferential task. To date, research effort has largely focussed on the development of Bayesian cubature, whose distributional output provides uncertainty quantification for the integral. However, the point estimators associated to Bayesian cubature can be inaccurate and acutely sensitive to the prior when the domain is high-dimensional. To address these drawbacks we introduce Bayes–Sard cubature, a probabilistic framework that combines the flexibility of Bayesian cubature with the robustness of classical cubatures which are well-established. This is achieved by considering a Gaussian process model for the integrand whose mean is a parametric regression model, with an improper prior on each regression coefficient. The features in the regression model consist of test functions which are guaranteed to be exactly integrated, with remaining degrees of freedom afforded to the non-parametric part. The asymptotic convergence of the Bayes–Sard cubature method is established and the theoretical results are numerically verified. In particular, we report two orders of magnitude reduction in error compared to Bayesian cubature in the context of a high-dimensional financial integral.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5886–5897},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327488,
author = {Tulyakov, Stepan and Ivanov, Anton and Fleuret, Francois},
title = {Practical Deep Stereo (PDS): Toward Applications-Friendly Deep Stereo Matching},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {End-to-end deep-learning networks recently demonstrated extremely good performance for stereo matching. However, existing networks are difficult to use for practical applications since (1) they are memory-hungry and unable to process even modest-size images, (2) they have to be trained for a given disparity range.The Practical Deep Stereo (PDS) network that we propose addresses both issues: First, its architecture relies on novel bottleneck modules that drastically reduce the memory footprint in inference, and additional design choices allow to handle greater image size during training. This results in a model that leverages large image context to resolve matching ambiguities. Second, a novel sub-pixel cross-entropy loss combined with a MAP estimator make this network less sensitive to ambiguous matches, and applicable to any disparity range without re-training.We compare PDS to state-of-the-art methods published over the recent months, and demonstrate its superior performance on FlyingThings3D and KITTI sets.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5875–5885},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327487,
author = {Luise, Giulia and Rudi, Alessandro and Pontil, Massimiliano and Ciliberto, Carlo},
title = {Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Applications of optimal transport have recently gained remarkable attention as a result of the computational advantages of entropic regularization. However, in most situations the Sinkhorn approximation to the Wasserstein distance is replaced by a regularized version that is less accurate but easy to differentiate. In this work we characterize the differential properties of the original Sinkhorn approximation, proving that it enjoys the same smoothness of its regularized version and we explicitly provide an efficient algorithm to compute its gradient. We show that this result benefits both theory and applications: on one hand, high order smoothness confers statistical guarantees to learning with Wasserstein approximations. On the other hand, the gradient formula is used to efficiently solve learning and optimization problems in practice. Promising preliminary experiments complement our analysis.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5864–5874},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327486,
author = {Richardson, Eitan and Weiss, Yair},
title = {On GANs and GMMs},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A longstanding problem in machine learning is to find unsupervised methods that can learn the statistical structure of high dimensional signals. In recent years, GANs have gained much attention as a possible solution to the problem, and in particular have shown the ability to generate remarkably realistic high resolution sampled images. At the same time, many authors have pointed out that GANs may fail to model the full distribution ("mode collapse") and that using the learned models for anything other than generating samples may be very difficult.In this paper, we examine the utility of GANs in learning statistical models of images by comparing them to perhaps the simplest statistical model, the Gaussian Mixture Model. First, we present a simple method to evaluate generative models based on relative proportions of samples that fall into predetermined bins. Unlike previous automatic methods for evaluating models, our method does not rely on an additional neural network nor does it require approximating intractable computations. Second, we compare the performance of GANs to GMMs trained on the same datasets. While GMMs have previously been shown to be successful in modeling small patches of images, we show how to train them on full sized images despite the high dimensionality. Our results show that GMMs can generate realistic samples (although less sharp than those of GANs) but also capture the full distribution, which GANs fail to do. Furthermore, GMMs allow efficient inference and explicit representation of the underlying statistical structure. Finally, we discuss how GMMs can be used to generate sharp images.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5852–5863},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327485,
author = {Han, Bo and Yao, Jiangchao and Niu, Gang and Zhou, Mingyuan and Tsang, Ivor W. and Zhang, Ya and Sugiyama, Masashi},
title = {Masking: A New Perspective of Noisy Supervision},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {It is important to learn various types of classifiers given training data with noisy labels. Noisy labels, in the most popular noise model hitherto, are corrupted from ground-truth labels by an unknown noise transition matrix. Thus, by estimating this matrix, classifiers can escape from overfitting those noisy labels. However, such estimation is practically difficult, due to either the indirect nature of two-step approaches, or not big enough data to afford end-to-end approaches. In this paper, we propose a human-assisted approach called "Masking" that conveys human cognition of invalid class transitions and naturally speculates the structure of the noise transition matrix. To this end, we derive a structure-aware probabilistic model incorporating a structure prior, and solve the challenges from structure extraction and structure alignment. Thanks to Masking, we only estimate unmasked noise transition probabilities and the burden of estimation is tremendously reduced. We conduct extensive experiments on CIFAR-10 and CIFAR-100 with three noise structures as well as the industrial-level Clothing1M with agnostic noise structure, and the results show that Masking can improve the robustness of classifiers significantly.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5841–5851},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327484,
author = {Do, Trong Dinh Thac and Cao, Longbing},
title = {Gamma-Poisson Dynamic Matrix Factorization Embedded with Metadata Influence},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A conjugate Gamma-Poisson model for Dynamic Matrix Factorization incorporated with metadata influence (mGDMF for short) is proposed to effectively and efficiently model massive, sparse and dynamic data in recommendations. Modeling recommendation problems with a massive number of ratings and very sparse or even no ratings on some users/items in a dynamic setting is very demanding and poses critical challenges to well-studied matrix factorization models due to the large-scale, sparse and dynamic nature of the data. Our proposed mGDMF tackles these challenges by introducing three strategies: (1) constructing a stable Gamma-Markov chain model that smoothly drifts over time by combining both static and dynamic latent features of data; (2) incorporating the user/item metadata into the model to tackle sparse ratings; and (3) undertaking stochastic variational inference to efficiently handle massive data. mGDMF is conjugate, dynamic and scalable. Experiments show that mGDMF significantly (both effectively and efficiently) outperforms the state-of-the-art static and dynamic models on large, sparse and dynamic data.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5829–5840},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327483,
author = {Zhang, Liheng and Edraki, Marzieh and Qi, Guo-Jun},
title = {CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper, we formalize the idea behind capsule nets of using a capsule vector rather than a neuron activation to predict the label of samples. To this end, we propose to learn a group of capsule subspaces onto which an input feature vector is projected. Then the lengths of resultant capsules are used to score the probability of belonging to different classes. We train such a Capsule Projection Network (CapProNet) by learning an orthogonal projection matrix for each capsule sub-space, and show that each capsule subspace is updated until it contains input feature vectors corresponding to the associated class. We will also show that the capsule projection can be viewed as normalizing the multiple columns of the weight matrix simultaneously to form an orthogonal basis, which makes it more effective in incorporating novel components of input features to update capsule representations. In other words, the capsule projection can be viewed as a multi-dimensional weight normalization in capsule subspaces, where the conventional weight normalization is simply a special case of the capsule projection onto 1D lines. Only a small negligible computing overhead is incurred to train the network in low-dimensional capsule subspaces or through an alternative hyper-power iteration to estimate the normalization matrix. Experiment results on image datasets show the presented model can greatly improve the performance of the state-of-the-art ResNet backbones by 10 - 20% and that of the Densenet by 5 - 7% respectively at the same level of computing and memory expenses. The CapProNet establishes the competitive state-of-the-art performance for the family of capsule nets by significantly reducing test errors on the benchmark datasets.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5819–5828},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327482,
author = {Tsang, Michael and Liu, Hanpeng and Purushotham, Sanjay and Murali, Pavankumar and Liu, Yan},
title = {Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural networks are known to model statistical interactions, but they entangle the interactions at intermediate hidden layers for shared representation learning. We propose a framework, Neural Interaction Transparency (NIT), that disentangles the shared learning across different interactions to obtain their intrinsic lower-order and interpretable structure. This is done through a novel regularizer that directly penalizes interaction order. We show that disentangling interactions reduces a feedforward neural network to a generalized additive model with interactions, which can lead to transparent models that perform comparably to the state-of-the-art models. NIT is also flexible and efficient; it can learn generalized additive models with maximum K-order interactions by training only O(1) models.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5809–5818},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327481,
author = {Auricchio, Gennaro and Gualandi, Stefano and Veneroni, Marco and Bassetti, Federico},
title = {Computing Kantorovich-Wasserstein Distances on <i>d</i>-Dimensional Histograms Using (<i>d</i> + 1)-Partite Graphs},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper presents a novel method to compute the exact Kantorovich-Wasserstein distance between a pair of d-dimensional histograms having n bins each. We prove that this problem is equivalent to an uncapacitated minimum cost flow problem on a (d + 1)-partite graph with (d + 1)n nodes and dnd+1/d arcs, whenever the cost is separable along the principal d-dimensional directions. We show numerically the benefits of our approach by computing the Kantorovich-Wasserstein distance of order 2 among two sets of instances: gray scale images and d-dimensional bio medical histograms. On these types of instances, our approach is competitive with state-of-the-art optimal transport algorithms.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5798–5808},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327480,
author = {Welleck, Sean and Yao, Zixin and Gai, Yu and Mao, Jialin and Zhang, Zheng and Cho, Kyunghyun},
title = {Loss Functions for Multiset Prediction},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5788–5797},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327479,
author = {Zhang, Yu and Wei, Ying and Yang, Qiang},
title = {Learning to Multitask},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Multitask learning has shown promising performance in many applications and many multitask models have been proposed. In order to identify an effective multitask model for a given multitask problem, we propose a learning framework called Learning to MultiTask (L2MT). To achieve the goal, L2MT exploits historical multitask experience which is organized as a training set consisting of several tuples, each of which contains a multitask problem with multiple tasks, a multitask model, and the relative test error. Based on such training set, L2MT first uses a proposed layerwise graph neural network to learn task embeddings for all the tasks in a multitask problem and then learns an estimation function to estimate the relative test error based on task embeddings and the representation of the multitask model based on a unified formulation. Given a new multitask problem, the estimation function is used to identify a suitable multitask model. Experiments on benchmark datasets show the effectiveness of the proposed L2MT framework.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5776–5787},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327478,
author = {Bogunovic, Ilija and Scarlett, Jonathan and Jegelka, Stefanie and Cevher, Volkan},
title = {Adversarially Robust Optimization with Gaussian Processes},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper, we consider the problem of Gaussian process (GP) optimization with an added robustness requirement: The returned point may be perturbed by an adversary, and we require the function value to remain as high as possible even after this perturbation. This problem is motivated by settings in which the underlying functions during optimization and implementation stages are different, or when one is interested in finding an entire region of good inputs rather than only a single point. We show that standard GP optimization algorithms do not exhibit the desired robustness properties, and provide a novel confidence-bound based algorithm STABLEOPT for this purpose. We rigorously establish the required number of samples for STABLEOPT to find a near-optimal point, and we complement this guarantee with an algorithm-independent lower bound. We experimentally demonstrate several potential applications of interest using real-world data sets, and we show that STABLEOPT consistently succeeds in finding a stable maximizer where several baseline methods fail.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5765–5775},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327477,
author = {Zhu, Jian-Qiao and Sanborn, Adam N. and Chater, Nick},
title = {Mental Sampling in Multimodal Representations},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Both resources in the natural environment and concepts in a semantic space are distributed "patchily", with large gaps in between the patches. To describe people's internal and external foraging behavior, various random walk models have been proposed. In particular, internal foraging has been modeled as sampling: in order to gather relevant information for making a decision, people draw samples from a mental representation using random-walk algorithms such as Markov chain Monte Carlo (MCMC). However, two common empirical observations argue against people using simple sampling algorithms such as MCMC for internal foraging. First, the distance between samples is often best described by a L\'{e}vy flight distribution: the probability of the distance between two successive locations follows a power-law on the distances. Second, humans and other animals produce long-range, slowly decaying autocorrelations characterized as 1/f-like fluctuations, instead of the 1/f2 fluctuations produced by random walks. We propose that mental sampling is not done by simple MCMC, but is instead adapted to multimodal representations and is implemented by Metropolis-coupled Markov chain Monte Carlo (MC3), one of the first algorithms developed for sampling from multimodal distributions. MC3 involves running multiple Markov chains in parallel but with target distributions of different temperatures, and it swaps the states of the chains whenever a better location is found. Heated chains more readily traverse valleys in the probability landscape to propose moves to far-away peaks, while the colder chains make the local steps that explore the current peak or patch. We show that MC3 generates distances between successive samples that follow a L\'{e}vy flight distribution and produce 1/f-like autocorrelations, providing a single mechanistic account of these two puzzling empirical phenomena of internal foraging.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5753–5764},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327476,
author = {Wang, Dilin and Liu, Hao and Liu, Qiang},
title = {Variational Inference with Tail-Adaptive <i>f</i>-Divergence},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Variational inference with α-divergences has been widely used in modern probabilistic machine learning. Compared to Kullback-Leibler (KL) divergence, a major advantage of using α-divergences (with positive α values) is their mass-covering property. However, estimating and optimizing α-divergences require to use importance sampling, which may have large or infinite variance due to heavy tails of importance weights. In this paper, we propose a new class of tail-adaptive f-divergences that adaptively change the convex function f with the tail distribution of the importance weights, in a way that theoretically guarantees finite moments, while simultaneously achieving mass-covering properties. We test our methods on Bayesian neural networks, as well as deep reinforcement learning in which our method is applied to improve a recent soft actor-critic (SAC) algorithm (Haarnoja et al., 2018). Our results show that our approach yields significant advantages compared with existing methods based on classical KL and α-divergences.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5742–5752},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327475,
author = {Morcos, Ari S. and Raghu, Maithra and Bengio, Samy},
title = {Insights on Representational Similarity in Neural Networks with Canonical Correlation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Comparing different neural network representations and determining how representations evolve over time remain challenging open questions in our understanding of the function of neural networks. Comparing representations in neural networks is fundamentally difficult as the structure of representations varies greatly, even across groups of networks trained on identical tasks, and over the course of training. Here, we develop projection weighted CCA (Canonical Correlation Analysis) as a tool for understanding neural networks, building off of SVCCA, a recently proposed method [22]. We first improve the core method, showing how to differentiate between signal and noise, and then apply this technique to compare across a group of CNNs, demonstrating that networks which generalize converge to more similar representations than networks which memorize, that wider networks converge to more similar solutions than narrow networks, and that trained networks with identical topology but different learning rates converge to distinct clusters with diverse representations. We also investigate the representational dynamics of RNNs, across both training and sequential timesteps, finding that RNNs converge in a bottom-up pattern over the course of training and that the hidden state is highly variable over the course of a sequence, even when accounting for linear transforms. Together, these results provide new insights into the function of CNNs and RNNs, and demonstrate the utility of using CCA to understand representations.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5732–5741},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327474,
author = {Pretorius, Arnu and Biljon, Elan Van and Kroon, Steve and Kamper, Herman},
title = {Critical Initialisation for Deep Signal Propagation in Noisy Rectifier Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Stochastic regularisation is an important weapon in the arsenal of a deep learning practitioner. However, despite recent theoretical advances, our understanding of how noise influences signal propagation in deep neural networks remains limited. By extending recent work based on mean field theory, we develop a new framework for signal propagation in stochastic regularised neural networks. Our noisy signal propagation theory can incorporate several common noise distributions, including additive and multiplicative Gaussian noise as well as dropout. We use this framework to investigate initialisation strategies for noisy ReLU networks. We show that no critical initialisation strategy exists using additive noise, with signal propagation exploding regardless of the selected noise distribution. For multiplicative noise (e.g. dropout), we identify alternative critical initialisation strategies that depend on the second moment of the noise distribution. Simulations and experiments on real-world data confirm that our proposed initialisation is able to stably propagate signals in deep networks, while using an initialisation disregarding noise fails to do so. Furthermore, we analyse correlation dynamics between inputs. Stronger noise regularisation is shown to reduce the depth to which discriminatory information about the inputs to a noisy ReLU network is able to propagate, even when initialised at criticality. We support our theoretical predictions for these trainable depths with simulations, as well as with experiments on MNIST and CIFAR-10.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5722–5731},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327473,
author = {Gottlieb, Lee-Ad and Kaufman, Eran and Kontorovich, Aryeh and Nivasch, Gabriel},
title = {Learning Convex Polytopes with Margin},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present an improved algorithm for properly learning convex polytopes in the realizable PAC setting from data with a margin. Our learning algorithm constructs a consistent polytope as an intersection of about t log t halfspaces with margins in time polynomial in t (where t is the number of halfspaces forming an optimal polytope).We also identify distinct generalizations of the notion of margin from hyperplanes to polytopes and investigate how they relate geometrically; this result may be of interest beyond the learning setting.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5711–5721},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327472,
author = {Roy, Nicholas A. and Bak, Ji Hyun and Akrami, Athena and Brody, Carlos D. and Pillow, Jonathan W.},
title = {Efficient Inference for Time-Varying Behavior during Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The process of learning new behaviors over time is a problem of great interest in both neuroscience and artificial intelligence. However, most standard analyses of animal training data either treat behavior as fixed or track only coarse performance statistics (e.g., accuracy, bias), providing limited insight into the evolution of the policies governing behavior. To overcome these limitations, we propose a dynamic psychophysical model that efficiently tracks trial-to-trial changes in behavior over the course of training. Our model consists of a dynamic logistic regression model, parametrized by a set of time-varying weights that express dependence on sensory stimuli as well as task-irrelevant covariates, such as stimulus, choice, and answer history. Our implementation scales to large behavioral datasets, allowing us to infer 500K parameters (e.g. 10 weights over 50K trials) in minutes on a desktop computer. We optimize hyperparameters governing how rapidly each weight evolves over time using the decoupled Laplace approximation, an efficient method for maximizing marginal likelihood in non-conjugate models. To illustrate performance, we apply our method to psychophysical data from both rats and human subjects learning a delayed sensory discrimination task. The model successfully tracks the psychophysical weights of rats over the course of training, capturing day-to-day and trial-to-trial fluctuations that underlie changes in performance, choice bias, and dependencies on task history. Finally, we investigate why rats frequently make mistakes on easy trials, and suggest that apparent lapses can be explained by sub-optimal weighting of known task covariates.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5700–5710},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327471,
author = {Goel, Vik and Weng, Jameson and Poupart, Pascal},
title = {Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a new technique for deep reinforcement learning that automatically detects moving objects and uses the relevant information for action selection. The detection of moving objects is done in an unsupervised way by exploiting structure from motion. Instead of directly learning a policy from raw images, the agent first learns to detect and segment moving objects by exploiting flow information in video sequences. The learned representation is then used to focus the policy of the agent on the moving objects. Over time, the agent identifies which objects are critical for decision making and gradually builds a policy based on relevant moving objects. This approach, which we call Motion-Oriented REinforcement Learning (MOREL), is demonstrated on a suite of Atari games where the ability to detect moving objects reduces the amount of interaction needed with the environment to obtain a good policy. Furthermore, the resulting policy is more interpretable than policies that directly map images to actions or values with a black box neural network. We can gain insight into the policy by inspecting the segmentation and motion of each object detected by the agent. This allows practitioners to confirm whether a policy is making decisions based on sensible information. Our code is available at https://github.com/vik-goel/MOREL.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5688–5699},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327470,
author = {Rudi, Alessandro and Calandriello, Daniele and Carratino, Luigi and Rosasco, Lorenzo},
title = {On Fast Leverage Score Sampling and Optimal Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Leverage score sampling provides an appealing way to perform approximate computations for large matrices. Indeed, it allows to derive faithful approximations with a complexity adapted to the problem at hand. Yet, performing leverage scores sampling is a challenge in its own right requiring further approximations. In this paper, we study the problem of leverage score sampling for positive definite matrices defined by a kernel. Our contribution is twofold. First we provide a novel algorithm for leverage score sampling and second, we exploit the proposed method in statistical learning by deriving a novel solver for kernel ridge regression. Our main technical contribution is showing that the proposed algorithms are currently the most efficient and accurate for these problems.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5677–5687},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327469,
author = {Bravo, Mario and Leslie, David and Mertikopoulos, Panayotis},
title = {Bandit Learning in Concave <i>N</i>-Person Games},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper examines the long-run behavior of learning with bandit feedback in non-cooperative concave games. The bandit framework accounts for extremely low-information environments where the agents may not even know they are playing a game; as such, the agents' most sensible choice in this setting would be to employ a no-regret learning algorithm. In general, this does not mean that the players' behavior stabilizes in the long run: no-regret learning may lead to cycles, even with perfect gradient information. However, if a standard monotonicity condition is satisfied, our analysis shows that no-regret learning based on mirror descent with bandit feedback converges to Nash equilibrium with probability 1. We also derive an upper bound for the convergence rate of the process that nearly matches the best attainable rate for single-agent bandit stochastic optimization.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5666–5676},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327468,
author = {Hazan, Elad and Hu, Wei and Li, Yuanzhi and Li, Zhiyuan},
title = {Online Improper Learning with an Approximation Oracle},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study the following question: given an efficient approximation algorithm for an optimization problem, can we learn efficiently in the same setting? We give a formal affirmative answer to this question in the form of a reduction from online learning to offline approximate optimization using an efficient algorithm that guarantees near optimal regret. The algorithm is efficient in terms of the number of oracle calls to a given approximation oracle – it makes only logarithmically many such calls per iteration. This resolves an open question by Kalai and Vempala, and by Garber. Furthermore, our result applies to the more general improper learning problems.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5657–5665},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327467,
author = {Mao, Jieming and Leme, Renato Paes and Schneider, Jon},
title = {Contextual Pricing for Lipschitz Buyers},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We investigate the problem of learning a Lipschitz function from binary feedback. In this problem, a learner is trying to learn a Lipschitz function f : [0, 1]d → [0,1] over the course of T rounds. On round t, an adversary provides the learner with an input xt, the learner submits a guess yt for f(xt), and learns whether yt &gt; f(xt) or yt ≤ f(xt). The learner's goal is to minimize their total loss ∑t ℓ(f(xt), yt) (for some loss function ℓ). The problem is motivated by contextual dynamic pricing, where a firm must sell a stream of differentiated products to a collection of buyers with non-linear valuations for the items and observes only whether the item was sold or not at the posted price.For the symmetric loss ℓ(f(xt), yt) = |f(xt) – yt|, we provide an algorithm for this problem achieving total loss O(log T) when d = 1 and O(T(d-1)/d) when d &gt; 1, and show that both bounds are tight (up to a factor of √log T). For the pricing loss function ℓ(f(xt), yt) = f(xt) — yt 1{yt ≤ f(xt)} we show a regret bound of O(Td/(d+1)) and show that this bound is tight. We present improved bounds in the special case of a population of linear buyers.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5648–5656},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327466,
author = {Han, Yanlin and Gmytrasiewicz, Piotr},
title = {Learning Others' Intentional Models in Multi-Agent Settings Using Interactive POMDPs},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Interactive partially observable Markov decision processes (I-POMDPs) provide a principled framework for planning and acting in a partially observable, stochastic and multi-agent environment. It extends POMDPs to multi-agent settings by including models of other agents in the state space and forming a hierarchical belief structure. In order to predict other agents' actions using I-POMDPs, we propose an approach that effectively uses Bayesian inference and sequential Monte Carlo sampling to learn others' intentional models which ascribe to them beliefs, preferences and rationality in action selection. Empirical results show that our algorithm accurately learns models of the other agent and has superior performance than methods that use subintentional models. Our approach serves as a generalized Bayesian learning algorithm that learns other agents' beliefs, strategy levels, and transition, observation and reward functions. It also effectively mitigates the belief space complexity due to the nested belief hierarchy.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5639–5647},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327465,
author = {Chen, Laming and Zhang, Guoxin and Zhou, Hanning},
title = {Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The determinantal point process (DPP) is an elegant probabilistic model of repulsion with applications in various machine learning tasks including summarization and search. However, the maximum a posteriori (MAP) inference for DPP which plays an important role in many applications is NP-hard, and even the popular greedy algorithm can still be too computationally expensive to be used in large-scale real-time scenarios. To overcome the computational challenge, in this paper, we propose a novel algorithm to greatly accelerate the greedy MAP inference for DPP. In addition, our algorithm also adapts to scenarios where the repulsion is only required among nearby few items in the result sequence. We apply the proposed algorithm to generate relevant and diverse recommendations. Experimental results show that our proposed algorithm is significantly faster than state-of-the-art competitors, and provides a better relevance-diversity trade-off on several public datasets, which is also confirmed in an online A/B test.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5627–5638},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327464,
author = {Rudi, Alessandro and Ciliberto, Carlo and Marconi, Gian Maria and Rosasco, Lorenzo},
title = {Manifold Structured Prediction},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Structured prediction provides a general framework to deal with supervised problems where the outputs have semantically rich structure. While classical approaches consider finite, albeit potentially huge, output spaces, in this paper we discuss how structured prediction can be extended to a continuous scenario. Specifically, we study a structured prediction approach to manifold valued regression. We characterize a class of problems for which the considered approach is statistically consistent and study how geometric optimization can be used to compute the corresponding estimator. Promising experimental results on both simulated and real data complete our study.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5615–5626},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327463,
author = {Mindermann, Soren and Armstrong, Stuart},
title = {Occam's Razor is Insufficient to Infer the Preferences of Irrational Agents},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Inverse reinforcement learning (IRL) attempts to infer human rewards or preferences from observed behavior. Since human planning systematically deviates from rationality, several approaches have been tried to account for specific human shortcomings. However, the general problem of inferring the reward function of an agent of unknown rationality has received little attention. Unlike the well-known ambiguity problems in IRL, this one is practically relevant but cannot be resolved by observing the agent's policy in enough environments. This paper shows (1) that a No Free Lunch result implies it is impossible to uniquely decompose a policy into a planning algorithm and reward function, and (2) that even with a reasonable simplicity prior/Occam's razor on the set of decompositions, we cannot distinguish between the true decomposition and others that lead to high regret. To address this, we need simple 'normative' assumptions, which cannot be deduced exclusively from observations.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5603–5614},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327462,
author = {Zhang, Richard Y. and Josz, C\'{e}dric and Sojoudi, Somayeh and Lavaei, Javad},
title = {How Much Restricted Isometry is Needed in Nonconvex Matrix Recovery?},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {When the linear measurements of an instance of low-rank matrix recovery satisfy a restricted isometry property (RIP)—i.e. they are approximately norm-preserving—the problem is known to contain no spurious local minima, so exact recovery is guaranteed. In this paper, we show that moderate RIP is not enough to eliminate spurious local minima, so existing results can only hold for near-perfect RIP. In fact, counterexamples are ubiquitous: we prove that every x is the spurious local minimum of a rank-1 instance of matrix recovery that satisfies RIP. One specific counterexample has RIP constant δ = 1/2, but causes randomly initialized stochastic gradient descent (SGD) to fail 12% of the time. SGD is frequently able to avoid and escape spurious local minima, but this empirical result shows that it can occasionally be defeated by their existence. Hence, while exact recovery guarantees will likely require a proof of no spurious local minima, arguments based solely on norm preservation will only be applicable to a narrow set of nearly-isotropic instances.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5591–5602},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327461,
author = {Wu, Mike and Goodman, Noah},
title = {Multimodal Generative Models for Scalable Weakly-Supervised Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder (MVAE) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the MVAE on four datasets and match state-of-the-art performance using many fewer parameters. In addition, we show that the MVAE is directly applicable to weakly-supervised learning, and is robust to incomplete supervision. We then consider two case studies, one of learning image transformations—edge detection, colorization, segmentation—as a set of modalities, followed by one of machine translation between two languages. We find appealing results across this range of tasks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5580–5590},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327460,
author = {Li, Zhize and Li, Jian},
title = {A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We analyze stochastic gradient algorithms for optimizing nonconvex, nonsmooth finite-sum problems. In particular, the objective function is given by the summation of a differentiable (possibly nonconvex) component, together with a possibly non-differentiable but convex component. We propose a proximal stochastic gradient algorithm based on variance reduction, called ProxSVRG+. Our main contribution lies in the analysis of ProxSVRG+. It recovers several existing convergence results and improves/generalizes them (in terms of the number of stochastic gradient oracle calls and proximal oracle calls). In particular, ProxSVRG+ generalizes the best results given by the SCSG algorithm, recently proposed by [Lei et al., 2017] for the smooth nonconvex case. ProxSVRG+ is also more straightforward than SCSG and yields simpler analysis. Moreover, ProxSVRG+ outperforms the deterministic proximal gradient descent (ProxGD) for a wide range of minibatch sizes, which partially solves an open problem proposed in [Reddi et al., 2016]. Also, ProxSVRG+ uses much less proximal oracle calls than ProxSVRG [Reddi et al., 2016]. Moreover, for nonconvex functions satisfied Polyak-undefinedojasiewicz condition, we prove that ProxSVRG+ achieves a global linear convergence rate without restart unlike ProxSVRG. Thus, it can automatically switch to the faster linear convergence in some regions as long as the objective function satisfies the PL condition locally in these regions. Finally, we conduct several experiments and the experimental results are consistent with the theoretical results.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5569–5579},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327459,
author = {Lee, Wonyeol and Yu, Hangyeol and Yang, Hongseok},
title = {Reparameterization Gradient for Non-Differentiable Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a new algorithm for stochastic variational inference that targets at models with non-differentiable densities. One of the key challenges in stochastic variational inference is to come up with a low-variance estimator of the gradient of a variational objective. We tackle the challenge by generalizing the reparameterization trick, one of the most effective techniques for addressing the variance issue for differentiable models, so that the trick works for non-differentiable models as well. Our algorithm splits the space of latent variables into regions where the density of the variables is differentiable, and their boundaries where the density may fail to be differentiable. For each differentiable region, the algorithm applies the standard reparameterization trick and estimates the gradient restricted to the region. For each potentially non-differentiable boundary, it uses a form of manifold sampling and computes the direction for variational parameters that, if followed, would increase the boundary's contribution to the variational objective. The sum of all the estimates becomes the gradient estimate of our algorithm. Our estimator enjoys the reduced variance of the reparameterization gradient while remaining unbiased even for non-differentiable models. The experiments with our preliminary implementation confirm the benefit of reduced variance and unbiasedness.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5558–5568},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327458,
author = {Jiang, Heinrich and Kim, Been and Guan, Melody Y. and Gupta, Maya},
title = {To Trust or Not to Trust a Classifier},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Knowing when a classifier's prediction can be trusted is useful in many applications and critical for safely using AI. While the bulk of the effort in machine learning research has been towards improving classifier performance, understanding when a classifier's predictions should and should not be trusted has received far less attention. The standard approach is to use the classifier's discriminant or confidence score; however, we show there exists an alternative that is more effective in many situations. We propose a new score, called the trust score, which measures the agreement between the classifier and a modified nearest-neighbor classifier on the testing example. We show empirically that high (low) trust scores produce surprisingly high precision at identifying correctly (incorrectly) classified examples, consistently outperforming the classifier's confidence score as well as many other baselines. Further, under some mild distributional assumptions, we show that if the trust score for an example is high (low), the classifier will likely agree (disagree) with the Bayes-optimal classifier. Our guarantees consist of non-asymptotic rates of statistical consistency under various nonparametric settings and build on recent developments in topological data analysis.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5546–5557},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327457,
author = {Xu, Yi and Jin, Rong and Yang, Tianbao},
title = {First-Order Stochastic Algorithms for Escaping from Saddle Points in Almost Linear Time},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper, we consider first-order methods for solving stochastic non-convex optimization problems. The key building block of the proposed algorithms is first-order procedures to extract negative curvature from the Hessian matrix through a principled sequence starting from noise, which are referred to NEgative-curvature-Originated-from-Noise or NEON and are of independent interest. Based on this building block, we design purely first-order stochastic algorithms for escaping from non-degenerate saddle points with a much better time complexity (almost linear time in the problem's dimensionality) under a bounded variance condition of stochastic gradients than previous first-order stochastic algorithms. In particular, we develop a general framework of first-order stochastic algorithms with a second-order convergence guarantee based on our new technique and existing algorithms that may only converge to a first-order stationary point. For finding a nearly second-order stationary point x such that || ∇F(x)|| ≤ ε and ∇2 F(x) ≥ – √εI (in high probability), the best time complexity of the presented algorithms is \~{O}(d/ε3.5), where F(·) denotes the objective function and d is the dimensionality of the problem. To the best of our knowledge, this is the first theoretical result of first-order stochastic algorithms with an almost linear time in terms of problem's dimensionality for finding second-order stationary points, which is even competitive with existing stochastic algorithms hinging on the second-order information.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5535–5545},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327456,
author = {Mehri, Shikib and Sigal, Leonid},
title = {Middle-out Decoding},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Despite being virtually ubiquitous, sequence-to-sequence models are challenged by their lack of diversity and inability to be externally controlled. In this paper, we speculate that a fundamental shortcoming of sequence generation models is that the decoding is done strictly from left-to-right, meaning that outputs values generated earlier have a profound effect on those generated later. To address this issue, we propose a novel middle-out decoder architecture that begins from an initial middle-word and simultaneously expands the sequence in both directions. To facilitate information flow and maintain consistent decoding, we introduce a dual self-attention mechanism that allows us to model complex dependencies between the outputs. We illustrate the performance of our model on the task of video captioning, as well as a synthetic sequence de-noising task. Our middle-out decoder achieves significant improvements on de-noising and competitive performance in the task of video captioning, while quantifiably improving the caption diversity. Furthermore, we perform a qualitative analysis that demonstrates our ability to effectively control the generation process of our decoder.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5523–5534},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327455,
author = {Hu, Zehong and Liang, Yitao and Zhang, Jie and Li, Zhao and Liu, Yang},
title = {Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Incentive mechanisms for crowdsourcing are designed to incentivize financially self-interested workers to generate and report high-quality labels. Existing mechanisms are often developed as one-shot static solutions, assuming a certain level of knowledge about worker models (expertise levels, costs of exerting efforts, etc.). In this paper, we propose a novel inference aided reinforcement mechanism that learns to incentivize high-quality data sequentially and requires no such prior assumptions. Specifically, we first design a Gibbs sampling augmented Bayesian inference algorithm to estimate workers' labeling strategies from the collected labels at each step. Then we propose a reinforcement incentive learning (RIL) method, building on top of the above estimates, to uncover how workers respond to different payments. RIL dynamically determines the payment without accessing any ground-truth labels. We theoretically prove that RIL is able to incentivize rational workers to provide high-quality labels. Empirical results show that our mechanism performs consistently well under both rational and non-fully rational (adaptive learning) worker models. Besides, the payments offered by RIL are more robust and have lower variances compared to the existing one-shot mechanisms.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5512–5522},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327454,
author = {Robin, Genevi\`{e}ve and Wai, Hoi-To and Josse, Julie and Klopp, Olga and Moulines, \'{E}ric},
title = {Low-Rank Interaction with Sparse Additive Effects Model for Large Data Frames},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Many applications of machine learning involve the analysis of large data frames – matrices collecting heterogeneous measurements (binary, numerical, counts, etc.) across samples – with missing values. Low-rank models, as studied by Udell et al. [26], are popular in this framework for tasks such as visualization, clustering and missing value imputation. Yet, available methods with statistical guarantees and efficient optimization do not allow explicit modeling of main additive effects such as row and column, or covariate effects. In this paper, we introduce a low-rank interaction and sparse additive effects (LORIS) model which combines matrix regression on a dictionary and low-rank design, to estimate main effects and interactions simultaneously. We provide statistical guarantees in the form of upper bounds on the estimation error of both components. Then, we introduce a mixed coordinate gradient descent (MCGD) method which provably converges sub-linearly to an optimal solution and is computationally efficient for large scale data sets. We show on simulated and survey data that the method has a clear advantage over current practices.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5501–5511},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327453,
author = {Nimishakavi, Madhav and Jawanpuria, Pratik and Mishra, Bamdev},
title = {A Dual Framework for Low-Rank Tensor Completion},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {One of the popular approaches for low-rank tensor completion is to use the latent trace norm regularization. However, most existing works in this direction learn a sparse combination of tensors. In this work, we fill this gap by proposing a variant of the latent trace norm that helps in learning a non-sparse combination of tensors. We develop a dual framework for solving the low-rank tensor completion problem. We first show a novel characterization of the dual solution space with an interesting factorization of the optimal solution. Overall, the optimal solution is shown to lie on a Cartesian product of Riemannian manifolds. Furthermore, we exploit the versatile Riemannian optimization framework for proposing computationally efficient trust region algorithm. The experiments illustrate the efficacy of the proposed algorithm on several real-world datasets across applications.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5489–5500},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327452,
author = {Chen, Xiaowei and Huang, Weiran and Chen, Wei and Lui, John C.S.},
title = {Community Exploration: From Offline Optimization to Online Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce the community exploration problem that has many real-world applications such as online advertising. In the problem, an explorer allocates limited budget to explore communities so as to maximize the number of members he could meet. We provide a systematic study of the community exploration problem, from offline optimization to online learning. For the offline setting where the sizes of communities are known, we prove that the greedy methods for both of non-adaptive exploration and adaptive exploration are optimal. For the online setting where the sizes of communities are not known and need to be learned from the multi-round explorations, we propose an "upper confidence" like algorithm that achieves the logarithmic regret bounds. By combining the feedback from different rounds, we can achieve a constant regret bound.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5479–5488},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327451,
author = {Gopakumar, Shivapratap and Gupta, Sunil and Rana, Santu and Nguyen, Vu and Venkatesh, Svetha},
title = {Algorithmic Assurance: An Active Approach to Algorithmic Testing Using Bayesian Optimisation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce algorithmic assurance, the problem of testing whether machine learning algorithms are conforming to their intended design goal. We address this problem by proposing an efficient framework for algorithmic testing. To provide assurance, we need to efficiently discover scenarios where an algorithm decision deviates maximally from its intended gold standard. We mathematically formulate this task as an optimisation problem of an expensive, black-box function. We use an active learning approach based on Bayesian optimisation to solve this optimisation problem. We extend this framework to algorithms with vector-valued outputs by making appropriate modification in Bayesian optimisation via the EXP3 algorithm. We theoretically analyse our methods for convergence. Using two real-world applications, we demonstrate the efficiency of our methods. The significance of our problem formulation and initial solutions is that it will serve as the foundation in assuring humans about machines making complex decisions.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5470–5478},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327450,
author = {Kong, Weihao and Valiant, Gregory},
title = {Estimating Learnability in the Sublinear Data Regime},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the problem of estimating how well a model class is capable of fitting a distribution of labeled data. We show that it is possible to accurately estimate this "learnability" even when given an amount of data that is too small to reliably learn any accurate model. Our first result applies to the setting where the data is drawn from a d-dimensional distribution with isotropic covariance, and the label of each datapoint is an arbitrary noisy function of the datapoint. In this setting, we show that with O(√d) samples, one can accurately estimate the fraction of the variance of the label that can be explained via the best linear function of the data. For comparison, even if the labels are noiseless linear functions of the data, a sample size linear in the dimension, d, is required to learn any function correlated with the underlying model. Our estimation approach also applies to the setting where the data distribution has an (unknown) arbitrary covariance matrix, allowing these techniques to be applied to settings where the model class consists of a linear function applied to a nonlinear embedding of the data. In this setting we give a consistent estimator of the fraction of explainable variance that uses o(d) samples. Finally, our techniques also extend to the setting of binary classification, where we obtain analogous results under the logistic model, for estimating the classification accuracy of the best linear classifier. We demonstrate the practical viability of our approaches on synthetic and real data. This ability to estimate the explanatory value of a set of features (or dataset), even in the regime in which there is too little data to realize that explanatory value, may be relevant to the scientific and industrial settings for which data collection is expensive and there are many potentially relevant feature sets that could be collected.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5460–5469},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327449,
author = {Metelli, Alberto Maria and Papini, Matteo and Faccio, Francesco and Restelli, Marcello},
title = {Policy Optimization via Importance Sampling},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Policy optimization is an effective reinforcement learning approach to solve continuous control tasks. Recent achievements have shown that alternating online and offline optimization is a successful choice for efficient trajectory reuse. However, deciding when to stop optimizing and collect new trajectories is non-trivial, as it requires to account for the variance of the objective function estimate. In this paper, we propose a novel, model-free, policy search algorithm, POIS, applicable in both action-based and parameter-based settings. We first derive a high-confidence bound for importance sampling estimation; then we define a surrogate objective function, which is optimized offline whenever a new batch of trajectories is collected. Finally, the algorithm is tested on a selection of continuous control tasks, with both linear and deep policies, and compared with state-of-the-art policy optimization methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5447–5459},
numpages = {13},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327448,
author = {Kaplan, Haim and Stemmer, Uri},
title = {Differentially Private <i>k</i>-Means with Constant Multiplicative Error},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We design new differentially private algorithms for the Euclidean k-means problem, both in the centralized model and in the local model of differential privacy. In both models, our algorithms achieve significantly improved error guarantees than the previous state-of-the-art. In addition, in the local model, our algorithm significantly reduces the number of interaction rounds.Although the problem has been widely studied in the context of differential privacy, all of the existing constructions achieve only super constant approximation factors. We present—for the first time—efficient private algorithms for the problem with constant multiplicative error. Furthermore, we show how to modify our algorithms so they compute private coresets for k-means clustering in both models.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5436–5446},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327447,
author = {Halloran, John T. and Rocke, David M.},
title = {Learning Concave Conditional Likelihood Models for Improved Analysis of Tandem Mass Spectra},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The most widely used technology to identify the proteins present in a complex biological sample is tandem mass spectrometry, which quickly produces a large collection of spectra representative of the peptides (i.e., protein subsequences) present in the original sample. In this work, we greatly expand the parameter learning capabilities of a dynamic Bayesian network (DBN) peptide-scoring algorithm, Didea [25], by deriving emission distributions for which its conditional log-likelihood scoring function remains concave. We show that this class of emission distributions, called Convex Virtual Emissions (CVEs), naturally generalizes the log-sum-exp function while rendering both maximum likelihood estimation and conditional maximum likelihood estimation concave for a wide range of Bayesian networks. Utilizing CVEs in Didea allows efficient learning of a large number of parameters while ensuring global convergence, in stark contrast to Didea's previous parameter learning framework (which could only learn a single parameter using a costly grid search) and other trainable models [12, 13, 14] (which only ensure convergence to local optima). The newly trained scoring function substantially outperforms the state-of-the-art in both scoring function accuracy and downstream Fisher kernel analysis. Furthermore, we significantly improve Didea's runtime performance through successive optimizations to its message passing schedule and derive explicit connections between Didea's new concave score and related MS/MS scoring functions.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5425–5435},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327446,
author = {Pennington, Jeffrey and Worah, Pratik},
title = {The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {An important factor contributing to the success of deep learning has been the remarkable ability to optimize large neural networks using simple first-order optimization algorithms like stochastic gradient descent. While the efficiency of such methods depends crucially on the local curvature of the loss surface, very little is actually known about how this geometry depends on network architecture and hyperparameters. In this work, we extend a recently-developed framework for studying spectra of nonlinear random matrices to characterize an important measure of curvature, namely the eigenvalues of the Fisher information matrix. We focus on a single-hidden-layer neural network with Gaussian data and weights and provide an exact expression for the spectrum in the limit of infinite width. We find that linear networks suffer worse conditioning than nonlinear networks and that nonlinear networks are generically non-degenerate. We also predict and demonstrate empirically that by adjusting the nonlinearity, the spectrum can be tuned so as to improve the efficiency of first-order optimization methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5415–5424},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327445,
author = {Houthooft, Rein and Chen, Richard Y. and Isola, Phillip and Stadie, Bradly C. and Wolski, Filip and Ho, Jonathan and Abbeel, Pieter},
title = {Evolved Policy Gradients},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose a metalearning approach for learning gradient-based reinforcement learning (RL) algorithms. The idea is to evolve a differentiable loss function, such that an agent, which optimizes its policy to minimize this loss, will achieve high rewards. The loss is parametrized via temporal convolutions over the agent's experience. Because this loss is highly flexible in its ability to take into account the agent's history, it enables fast task learning. Empirical results show that our evolved policy gradient algorithm (EPG) achieves faster learning on several randomized environments compared to an off-the-shelf policy gradient method. We also demonstrate that EPG's learned loss can generalize to out-of-distribution test time tasks, and exhibits qualitatively different behavior from other popular metalearning algorithms.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5405–5414},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327444,
author = {Freksen, Casper and Kamma, Lior and Larsen, Kasper Green},
title = {Fully Understanding the Hashing Trick},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Feature hashing, also known as the hashing trick, introduced by Weinberger et al. (2009), is one of the key techniques used in scaling-up machine learning algorithms. Loosely speaking, feature hashing uses a random sparse projection matrix A : ℝn → ℝm (where m ≪ n) in order to reduce the dimension of the data from n to m while approximately preserving the Euclidean norm. Every column of A contains exactly one non-zero entry, equals to either -1 or 1.Weinberger et al. showed tail bounds on ||Ax||22. Specifically they showed that for every ε, δ, if ||x||∞/||x||2 is sufficiently small, and m is sufficiently large, then Pr[| ||Ax||22 – ||x||22 &lt; ε ||x||22]≥1–δ. These bounds were later extended by Dasgupta et al. (2010) and most recently refined by Dahlgaard et al. (2017), however, the true nature of the performance of this key technique, and specifically the correct tradeoff between the pivotal parameters ||x||∞/||x||2, m, ε, δ remained an open question.We settle this question by giving tight asymptotic bounds on the exact tradeoff between the central parameters, thus providing a complete understanding of the performance of feature hashing. We complement the asymptotic bound with empirical data, which shows that the constants "hiding" in the asymptotic notation are, in fact, very close to 1, thus further illustrating the tightness of the presented bounds in practice.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5394–5404},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327443,
author = {Wu, Anqi and Pashkovski, Stan L. and Datta, Sandeep Robert and Pillow, Jonathan W.},
title = {Learning a Latent Manifold of Odor Representations from Neural Responses in Piriform Cortex},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A major difficulty in studying the neural mechanisms underlying olfactory perception is the lack of obvious structure in the relationship between odorants and the neural activity patterns they elicit. Here we use odor-evoked responses in piriform cortex to identify a latent manifold specifying latent distance relationships between olfactory stimuli. Our approach is based on the Gaussian process latent variable model, and seeks to map odorants to points in a low-dimensional embedding space, where distances between points in the embedding space relate to the similarity of population responses they elicit. The model is specified by an explicit continuous mapping from a latent embedding space to the space of high-dimensional neural population firing rates via nonlinear tuning curves, each parametrized by a Gaussian process. Population responses are then generated by the addition of correlated, odor-dependent Gaussian noise. We fit this model to large-scale calcium fluorescence imaging measurements of population activity in layers 2 and 3 of mouse piriform cortex following the presentation of a diverse set of odorants. The model identifies a low-dimensional embedding of each odor, and a smooth tuning curve over the latent embedding space that accurately captures each neuron's response to different odorants. The model captures both signal and noise correlations across more than 500 neurons. We validate the model using a cross-validation analysis known as co-smoothing to show that the model can accurately predict the responses of a population of held-out neurons to test odorants.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5383–5393},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327442,
author = {Vazquez-Chanlatte, Marcell and Jha, Susmit and Tiwari, Ashish and Ho, Mark K. and Seshia, Sanjit A.},
title = {Learning Task Specifications from Demonstrations},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Real-world applications often naturally decompose into several sub-tasks. In many settings (e.g., robotics) demonstrations provide a natural way to specify the sub-tasks. However, most methods for learning from demonstrations either do not provide guarantees that the artifacts learned for the sub-tasks can be safely recombined or limit the types of composition available. Motivated by this deficit, we consider the problem of inferring Boolean non-Markovian rewards (also known as logical trace properties or specifications) from demonstrations provided by an agent operating in an uncertain, stochastic environment. Crucially, specifications admit well-defined composition rules that are typically easy to interpret. In this paper, we formulate the specification inference task as a maximum a posteriori (MAP) probability inference problem, apply the principle of maximum entropy to derive an analytic demonstration likelihood model and give an efficient approach to search for the most likely specification in a large candidate pool of specifications. In our experiments, we demonstrate how learning specifications can help avoid common problems that often arise due to ad-hoc reward composition.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5372–5382},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327441,
author = {Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
title = {Breaking the Curse of Horizon: Infinite-Horizon off-Policy Estimation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider off-policy estimation of the expected reward of a target policy using samples collected by a different behavior policy. Importance sampling (IS) has been a key technique for deriving (nearly) unbiased estimators, but is known to suffer from an excessively high variance in long-horizon problems. In the extreme case of infinite-horizon problems, the variance of an IS-based estimator may even be unbounded. In this paper, we propose a new off-policy estimator that applies IS directly on the stationary state-visitation distributions to avoid the exploding variance faced by existing methods. Our key contribution is a novel approach to estimating the density ratio of two stationary state distributions, with trajectories sampled from only the behavior distribution. We develop a mini-max loss function for the estimation problem, and derive a closed-form solution for the case of RKHS. We support our method with both theoretical and empirical analyses.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5361–5371},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327440,
author = {Ganea, Octavian-Eugen and B\'{e}cigneul, Gary and Hofmann, Thomas},
title = {Hyperbolic Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Hyperbolic spaces have recently gained momentum in the context of machine learning due to their high capacity and tree-likeliness properties. However, the representational power of hyperbolic geometry is not yet on par with Euclidean geometry, mostly because of the absence of corresponding hyperbolic neural network layers. This makes it hard to use hyperbolic embeddings in downstream tasks. Here, we bridge this gap in a principled manner by combining the formalism of M\"{o}bius gyrovector spaces with the Riemannian geometry of the Poincar\'{e} model of hyperbolic spaces. As a result, we derive hyperbolic versions of important deep learning tools: multinomial logistic regression, feed-forward and recurrent neural networks such as gated recurrent units. This allows to embed sequential data and perform classification in the hyperbolic space. Empirically, we show that, even if hyperbolic optimization tools are limited, hyperbolic sentence embeddings either outperform or are on par with their Euclidean variants on textual entailment and noisy-prefix recognition tasks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5350–5360},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327439,
author = {Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John and Murino, Vittorio and Savarese, Silvio},
title = {Generalizing to Unseen Domains via Adversarial Data Augmentation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We are concerned with learning models that generalize well to different unseen domains. We consider a worst-case formulation over data distributions that are near the source domain in the feature space. Only using training data from a single source distribution, we propose an iterative procedure that augments the dataset with examples from a fictitious target domain that is "hard" under the current model. We show that our iterative scheme is an adaptive data augmentation method where we append adversarial examples at each iteration. For softmax losses, we show that our method is a data-dependent regularization scheme that behaves differently from classical regularizers that regularize towards zero (e.g., ridge or lasso). On digit recognition and semantic segmentation tasks, our method learns models improve performance across a range of a priori unknown target domains.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5339–5349},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327438,
author = {Jean, Neal and Xie, Sang Michael and Ermon, Stefano},
title = {Semi-Supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Large amounts of labeled data are typically required to train deep learning models. For many real-world problems, however, acquiring additional data can be expensive or even impossible. We present semi-supervised deep kernel learning (SSDKL), a semi-supervised regression model based on minimizing predictive variance in the posterior regularization framework. SSDKL combines the hierarchical representation learning of neural networks with the probabilistic modeling capabilities of Gaussian processes. By leveraging unlabeled data, we show improvements on a diverse set of real-world regression tasks over supervised deep kernel learning and semi-supervised methods such as VAT and mean teacher adapted for regression.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5327–5338},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327437,
author = {Murata, Tomoya and Suzuki, Taiji},
title = {Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We develop new stochastic gradient methods for efficiently solving sparse linear regression in a partial attribute observation setting, where learners are only allowed to observe a fixed number of actively chosen attributes per example at training and prediction times. It is shown that the methods achieve essentially a sample complexity of O (1/ε) to attain an error of ε under a variant of restricted eigenvalue condition, and the rate has better dependency on the problem dimension than existing methods. Particularly, if the smallest magnitude of the non-zero components of the optimal solution is not too small, the rate of our proposed Hybrid algorithm can be boosted to near the minimax optimal sample complexity of full information algorithms. The core ideas are (i) efficient construction of an unbiased gradient estimator by the iterative usage of the hard thresholding operator for configuring an exploration algorithm; and (ii) an adaptive combination of the exploration and an exploitation algorithms for quickly identifying the support of the optimum and efficiently searching the optimal parameter in its support. Experimental results are presented to validate our theoretical findings and the superiority of our proposed methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5317–5326},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327436,
author = {Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
title = {Meta-Reinforcement Learning of Structured Exploration Strategies},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Exploration is a fundamental challenge in reinforcement learning (RL). Many current exploration methods for deep RL use task-agnostic objectives, such as information gain or bonuses based on state visitation. However, many practical applications of RL involve learning more than a single task, and prior tasks can be used to inform how exploration should be performed in new tasks. In this work, we study how prior tasks can inform an agent about how to explore effectively in new situations. We introduce a novel gradient-based fast adaptation algorithm – model agnostic exploration with structured noise (MAESN) – to learn exploration strategies from prior experience. The prior experience is used both to initialize a policy and to acquire a latent exploration space that can inject structured stochasticity into a policy, producing exploration strategies that are informed by prior knowledge and are more effective than random action-space noise. We show that MAESN is more effective at learning exploration strategies when compared to prior meta-RL methods, RL without learned exploration strategies, and task-agnostic exploration methods. We evaluate our method on a variety of simulated tasks: locomotion with a wheeled robot, locomotion with a quadrupedal walker, and object manipulation.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5307–5316},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327435,
author = {Nayebi, Aran and Bear, Daniel and Kubilius, Jonas and Kar, Kohitij and Ganguli, Surya and Sussillo, David and DiCarlo, James J. and Yamins, Daniel L. K.},
title = {Task-Driven Convolutional Recurrent Models of the Visual System},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Feed-forward convolutional neural networks (CNNs) are currently state-of-the-art for object classification tasks such as ImageNet. Further, they are quantitatively accurate models of temporally-averaged responses of neurons in the primate brain's visual system. However, biological visual systems have two ubiquitous architectural features not shared with typical CNNs: local recurrence within cortical areas, and long-range feedback from downstream areas to upstream areas. Here we explored the role of recurrence in improving classification performance. We found that standard forms of recurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the ImageNet task. In contrast, novel cells that incorporated two structural features, bypassing and gating, were able to boost task accuracy substantially. We extended these design principles in an automated search over thousands of model architectures, which identified novel local recurrent cells and long-range feedback connections useful for object recognition. Moreover, these task-optimized ConvRNNs matched the dynamics of neural activity in the primate visual system better than feedforward networks, suggesting a role for the brain's recurrent connections in performing difficult visual behaviors.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5295–5306},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327434,
author = {Lindgren, Erik M. and Kocaoglu, Murat and Dimakis, Alexandros G. and Vishwanath, Sriram},
title = {Experimental Design for Cost-Aware Learning of Causal Graphs},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the minimum cost intervention design problem: Given the essential graph of a causal graph and a cost to intervene on a variable, identify the set of interventions with minimum total cost that can learn any causal graph with the given essential graph. We first show that this problem is NP-hard. We then prove that we can achieve a constant factor approximation to this problem with a greedy algorithm. We then constrain the sparsity of each intervention. We develop an algorithm that returns an intervention design that is nearly optimal in terms of size for sparse graphs with sparse interventions and we discuss how to use it when there are costs on the vertices.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5284–5294},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327433,
author = {Gupta, Neha and Sidford, Aaron},
title = {Exploiting Numerical Sparsity for Efficient Learning: Faster Eigenvector Computation and Regression},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper, we obtain improved running times for regression and top eigenvector computation for numerically sparse matrices. Given a data matrix A ∈ ℝn\texttimes{}d where every row α ∈ ℝd has || ε||22 ≤ L and numerical sparsity at most s, i.e. ||α||21/||α||22 ≤ s, we provide faster algorithms for these problems in many parameter settings.For top eigenvector computation, we obtain a running time of \~{O}(nd + r(s + √rs)/gap2) where gap &gt; 0 is the relative gap between the top two eigenvectors of AΤ A and r is the stable rank of A. This running time improves upon the previous best unaccelerated running time of O(nd + rd/gap2) as r ≤ d and s ≤ d.For regression, we obtain a running time of \~{O}(nd + (nL/µ) √snL/µ) where µ &gt; 0 is the smallest eigenvalue of AΤ A. This running time improves upon the previous best unaccelerated running time of \~{O}(nd + nLd/µ). This result expands the regimes where regression can be solved in nearly linear time from when L/µ = \~{O}(1) to when L/µ = \~{O}(d2/3/(sn)1/3).Furthermore, we obtain similar improvements even when row norms and numerical sparsities are non-uniform and we show how to achieve even faster running times by accelerating using approximate proximal point [9] / catalyst [15]. Our running times depend only on the size of the input and natural numerical measures of the matrix, i.e. eigenvalues and ℓp norms, making progress on a key open problem regarding optimal running times for efficient large-scale learning.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5274–5283},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327432,
author = {Malek, Alan and Bartlett, Peter L.},
title = {Horizon-Independent Minimax Linear Regression},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider online linear regression: at each round, an adversary reveals a covariate vector, the learner predicts a real value, the adversary reveals a label, and the learner suffers the squared prediction error. The aim is to minimize the difference between the cumulative loss and that of the linear predictor that is best in hindsight. Previous work demonstrated that the minimax optimal strategy is easy to compute recursively from the end of the game; this requires the entire sequence of covariate vectors in advance. We show that, once provided with a measure of the scale of the problem, we can invert the recursion and play the minimax strategy without knowing the future covariates. Further, we show that this forward recursion remains optimal even against adaptively chosen labels and covariates, provided that the adversary adheres to a set of constraints that prevent misrepresentation of the scale of the problem. This strategy is horizon-independent in that the regret and minimax strategies depend on the size of the constraint set and not on the time-horizon, and hence it incurs no more regret than the optimal strategy that knows in advance the number of rounds of the game. We also provide an interpretation of the minimax algorithm as a follow-the-regularized-leader strategy with a data-dependent regularizer and obtain an explicit expression for the minimax regret.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5264–5273},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327431,
author = {Farnia, Farzan and Tse, David},
title = {A Convex Duality Framework for GANs},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Generative adversarial network (GAN) is a minimax game between a generator mimicking the true model and a discriminator distinguishing the samples produced by the generator from the real training samples. Given an unconstrained discriminator able to approximate any function, this game reduces to finding the generative model minimizing a divergence measure, e.g. the Jensen-Shannon (JS) divergence, to the data distribution. However, in practice the discriminator is constrained to be in a smaller class undefined such as neural nets. Then, a natural question is how the divergence minimization interpretation changes as we constrain undefined. In this work, we address this question by developing a convex duality framework for analyzing GANs. For a convex set undefined, this duality framework interprets the original GAN formulation as finding the generative model with minimum JS-divergence to the distributions penalized to match the moments of the data distribution, with the moments specified by the discriminators in F. We show that this interpretation more generally holds for f-GAN and Wasserstein GAN. As a byproduct, we apply the duality framework to a hybrid of f-divergence and Wasserstein distance. Unlike the f-divergence, we prove that the proposed hybrid divergence changes continuously with the generative model, which suggests regularizing the discriminator's Lips-chitz constant in f-GAN and vanilla GAN. We numerically evaluate the power of the suggested regularization schemes for improving GAN's training performance.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5254–5263},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327430,
author = {Efroni, Yonathan and Dalal, Gal and Scherrer, Bruno and Mannor, Shie},
title = {Multiple-Step Greedy Policies in Online and Approximate Reinforcement Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Multiple-step lookahead policies have demonstrated high empirical competence in Reinforcement Learning, via the use of Monte Carlo Tree Search or Model Predictive Control. In a recent work [5], multiple-step greedy policies and their use in vanilla Policy Iteration algorithms were proposed and analyzed. In this work, we study multiple-step greedy algorithms in more practical setups. We begin by highlighting a counter-intuitive difficulty, arising with soft-policy updates: even in the absence of approximations, and contrary to the 1-step-greedy case, monotonic policy improvement is not guaranteed unless the update stepsize is sufficiently large. Taking particular care about this difficulty, we formulate and analyze online and approximate algorithms that use such a multi-step greedy operator.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5244–5253},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327429,
author = {Sajjadi, Mehdi S. M. and Bachem, Olivier and Lucic, Mario and Bousquet, Olivier and Gelly, Sylvain},
title = {Assessing Generative Models via Precision and Recall},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recent advances in generative modeling have led to an increased interest in the study of statistical divergences as means of model comparison. Commonly used evaluation methods, such as the Fr\'{e}chet Inception Distance (FID), correlate well with the perceived quality of samples and are sensitive to mode dropping. However, these metrics are unable to distinguish between different failure cases since they only yield one-dimensional scores. We propose a novel definition of precision and recall for distributions which disentangles the divergence into two separate dimensions. The proposed notion is intuitive, retains desirable properties, and naturally leads to an efficient algorithm that can be used to evaluate generative models. We relate this notion to total variation as well as to recent evaluation metrics such as Inception Score and FID. To demonstrate the practical utility of the proposed approach we perform an empirical study on several variants of Generative Adversarial Networks and Variational Autoencoders. In an extensive set of experiments we show that the proposed metric is able to disentangle the quality of generated samples from the coverage of the target distribution.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5234–5243},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327428,
author = {Marques, Alexandre N. and Lam, Remi R. and Willcox, Karen E.},
title = {Contour Location via Entropy Reduction Leveraging Multiple Information Sources},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce an algorithm to locate contours of functions that are expensive to evaluate. The problem of locating contours arises in many applications, including classification, constrained optimization, and performance analysis of mechanical and dynamical systems (reliability, probability of failure, stability, etc.). Our algorithm locates contours using information from multiple sources, which are available in the form of relatively inexpensive, biased, and possibly noisy approximations to the original function. Considering multiple information sources can lead to significant cost savings. We also introduce the concept of contour entropy, a formal measure of uncertainty about the location of the zero contour of a function approximated by a statistical surrogate model. Our algorithm locates contours efficiently by maximizing the reduction of contour entropy per unit cost.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5223–5233},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327427,
author = {Hu, Shoubo and Chen, Zhitang and Nia, Vahid Partovi and Chan, Laiwan and Geng, Yanhui},
title = {Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The inference of the causal relationship between a pair of observed variables is a fundamental problem in science, and most existing approaches are based on one single causal model. In practice, however, observations are often collected from multiple sources with heterogeneous causal models due to certain uncontrollable factors, which renders causal analysis results obtained by a single model skeptical. In this paper, we generalize the Additive Noise Model (ANM) to a mixture model, which consists of a finite number of ANMs, and provide the condition of its causal identifiability. To conduct model estimation, we propose Gaussian Process Partially Observable Model (GPPOM), and incorporate independence enforcement into it to learn latent parameter associated with each observation. Causal inference and clustering according to the underlying generating mechanisms of the mixture model are addressed in this work. Experiments on synthetic and real data demonstrate the effectiveness of our proposed approach.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5212–5222},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327426,
author = {Gao, Hongyang and Wang, Zhengyang and Ji, Shuiwang},
title = {ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Convolutional neural networks (CNNs) have shown great capability of solving various artificial intelligence tasks. However, the increasing model size has raised challenges in employing them in resource-limited applications. In this work, we propose to compress deep models by using channel-wise convolutions, which replace dense connections among feature maps with sparse ones in CNNs. Based on this novel operation, we build light-weight CNNs known as ChannelNets. Channel-Nets use three instances of channel-wise convolutions; namely group channel-wise convolutions, depth-wise separable channel-wise convolutions, and the convolu-tional classification layer. Compared to prior CNNs designed for mobile devices, ChannelNets achieve a significant reduction in terms of the number of parameters and computational cost without loss in accuracy. Notably, our work represents the first attempt to compress the fully-connected classification layer, which usually accounts for about 25% of total parameters in compact CNNs. Experimental results on the ImageNet dataset demonstrate that ChannelNets achieve consistently better performance compared to prior methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5203–5211},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327425,
author = {Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin F. and Ye, Yinyu},
title = {Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper we consider the problem of computing an e-optimal policy of a discounted Markov Decision Process (DMDP) provided we can only access its transition function through a generative sampling model that given any state-action pair samples from the transition function in O(1) time. Given such a DMDP with states S, actions A, discount factor γ ∈ (0,1), and rewards in range [0,1] we provide an algorithm which computes an ε-optimal policy with probability 1 – δ where both the time spent and number of sample taken are upper bounded by [Oleft[frac{|cS||cA|}{(1-gamma)^3 epsilon^2} log left(frac{|cS||cA|}{(1-gamma)delta epsilon} right) logleft(frac{1}{(1-gamma)epsilon}right)right] ~.] For fixed values of ε, this improves upon the previous best known bounds by a factor of (1 – γ)-1 and matches the sample complexity lower bounds proved in [AMK13] up to logarithmic factors. We also extend our method to computing ε-optimal policies for finite-horizon MDP with a generative model and provide a nearly matching sample complexity lower bound.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5192–5202},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327424,
author = {Guo, Dalin and Yu, Angela J.},
title = {Why so Gloomy? A Bayesian Explanation of Human Pessimism Bias in the Multi-Armed Bandit Task},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {How humans make repeated choices among options with imperfectly known reward outcomes is an important problem in psychology and neuroscience. This is often studied using multi-armed bandits, which is also frequently studied in machine learning. We present data from a human stationary bandit experiment, in which we vary the average abundance and variability of reward availability (mean and variance of reward rate distributions). Surprisingly, we find subjects significantly underestimate prior mean of reward rates – based on their self-report, at the end of a game, on their reward expectation of non-chosen arms. Previously, human learning in the bandit task was found to be well captured by a Bayesian ideal learning model, the Dynamic Belief Model (DBM), albeit under an incorrect generative assumption of the temporal structure – humans assume reward rates can change over time even though they are truly fixed. We find that the "pessimism bias" in the bandit task is well captured by the prior mean of DBM when fitted to human choices; but it is poorly captured by the prior mean of the Fixed Belief Model (FBM), an alternative Bayesian model that (correctly) assumes reward rates to be constants. This pessimism bias is also incompletely captured by a simple reinforcement learning model (RL) commonly used in neuroscience and psychology, in terms of fitted initial Q-values. While it seems sub-optimal, and thus mysterious, that humans have an underestimated prior reward expectation, our simulations show that an underestimated prior mean helps to maximize long-term gain, if the observer assumes volatility when reward rates are stable and utilizes a softmax decision policy instead of the optimal one (obtainable by dynamic programming). This raises the intriguing possibility that the brain underestimates reward rates to compensate for the incorrect non-stationarity assumption in the generative model and a simplified decision policy.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5182–5191},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327423,
author = {Zhang, Muhan and Chen, Yixin},
title = {Link Prediction Based on Graph Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a "heuristic" that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel γ-decaying heuristic theory. The theory unifies a wide range of heuristics in a single framework, and proves that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. Second, based on the γ-decaying theory, we propose a new method to learn heuristics from local subgraphs using a graph neural network (GNN). Its experimental results show unprecedented performance, working consistently well on a wide range of problems.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5171–5181},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327422,
author = {Zhu, Zhihui and Li, Xiao and Liu, Kai and Li, Qiuwei},
title = {Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Symmetric nonnegative matrix factorization (NMF)—a special but important class of the general NMF—is demonstrated to be useful for data analysis and in particular for various clustering tasks. Unfortunately, designing fast algorithms for Symmetric NMF is not as easy as for the nonsymmetric counterpart, the later admitting the splitting property that allows efficient alternating-type algorithms. To overcome this issue, we transfer the symmetric NMF to a nonsymmetric one, then we can adopt the idea from the state-of-the-art algorithms for nonsymmetric NMF to design fast algorithms solving symmetric NMF. We rigorously establish that solving nonsymmetric reformulation returns a solution for symmetric NMF and then apply fast alternating based algorithms for the corresponding reformulated problem. Furthermore, we show these fast algorithms admit strong convergence guarantee in the sense that the generated sequence is convergent at least at a sublinear rate and it converges globally to a critical point of the symmetric NMF. We conduct experiments on both synthetic data and image clustering to support our result.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5160–5170},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327421,
author = {Banner, Ron and Hubara, Itay and Hoffer, Elad and Soudry, Daniel},
title = {Scalable Methods for 8-Bit Training of Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Quantized Neural Networks (QNNs) are often used to improve network efficiency during the inference phase, i.e. after the network has been trained. Extensive research in the field suggests many different quantization schemes. Still, the number of bits required, as well as the best quantization scheme, are yet unknown. Our theoretical analysis suggests that most of the training process is robust to substantial precision reduction, and points to only a few specific operations that require higher precision. Armed with this knowledge, we quantize the model parameters, activations and layer gradients to 8-bit, leaving at a higher precision only the final step in the computation of the weight gradients. Additionally, as QNNs require batch-normalization to be trained at high precision, we introduce Range Batch-Normalization (BN) which has significantly higher tolerance to quantization noise and improved computational complexity. Our simulations show that Range BN is equivalent to the traditional batch norm if a precise scale adjustment, which can be approximated analytically, is applied. To the best of the authors' knowledge, this work is the first to quantize the weights, activations, as well as a substantial volume of the gradients stream, in all layers (including batch normalization) to 8-bit while showing state-of-the-art results over the ImageNet-1K dataset.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5151–5159},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327420,
author = {Zhou, Zhengyuan and Mertikopoulos, Panayotis and Athey, Susan and Bambos, Nicholas and Glynn, Peter and Ye, Yinyu},
title = {Learning in Games with Lossy Feedback},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider a game-theoretical multi-agent learning problem where the feedback information can be lost during the learning process and rewards are given by a broad class of games known as variationally stable games. We propose a simple variant of the classical online gradient descent algorithm, called reweighted online gradient descent (ROGD) and show that in variationally stable games, if each agent adopts ROGD, then almost sure convergence to the set of Nash equilibria is guaranteed, even when the feedback loss is asynchronous and arbitrarily corrrelated among agents. We then extend the framework to deal with unknown feedback loss probabilities by using an estimator (constructed from past data) in its replacement. Finally, we further extend the framework to accomodate both asynchronous loss and stochastic rewards and establish that multi-agent ROGD learning still converges to the set of Nash equilibria in such settings. Together, these results contribute to the broad lanscape of multi-agent online learning by significantly relaxing the feedback information that is required to achieve desirable outcomes.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5140–5150},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327419,
author = {Yu, Mingchao and Lin, Zhifeng and Narra, Krishna and Li, Songze and Li, Youjie and Kim, Nam Sung and Schwing, Alexander and Annavaram, Murali and Avestimehr, Salman},
title = {GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Data parallelism can boost the training speed of convolutional neural networks (CNN), but could suffer from significant communication costs caused by gradient aggregation. To alleviate this problem, several scalar quantization techniques have been developed to compress the gradients. But these techniques could perform poorly when used together with decentralized aggregation protocols like ring all-reduce (RAR), mainly due to their inability to directly aggregate compressed gradients. In this paper, we empirically demonstrate the strong linear correlations between CNN gradients, and propose a gradient vector quantization technique, named GradiVeQ, to exploit these correlations through principal component analysis (PCA) for substantial gradient dimension reduction. Gradi-VeQ enables direct aggregation of compressed gradients, hence allows us to build a distributed learning system that parallelizes GradiVeQ gradient compression and RAR communications. Extensive experiments on popular CNNs demonstrate that applying GradiVeQ slashes the wall-clock gradient aggregation time of the original RAR by more than 5X without noticeable accuracy loss, and reduces the end-to-end training time by almost 50%. The results also show that GradiVeQ is compatible with scalar quantization techniques such as QSGD (Quantized SGD), and achieves a much higher speed-up gain under the same compression ratio.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5129–5139},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327418,
author = {Wang, Siwei and Huang, Longbo},
title = {Multi-Armed Bandits with Compensation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose and study the known-compensation multi-arm bandit (KCMAB) problem, where a system controller offers a set of arms to many short-term players for T steps. In each step, one short-term player arrives to the system. Upon arrival, the player aims to select an arm with the current best average reward and receives a stochastic reward associated with the arm. In order to incentivize players to explore other arms, the controller provides a proper payment compensation to players. The objective of the controller is to maximize the total reward collected by players while minimizing the compensation. We first provide a compensation lower bound Θ(∑i Δi log T/KLi), where Δi and KLi are the expected reward gap and Kullback-Leibler (KL) divergence between distributions of arm i and the best arm, respectively. We then analyze three algorithms to solve the KCMAB problem, and obtain their regrets and compensations. We show that the algorithms all achieve O(log T) regret and O(log T) compensation that match the theoretical lower bound. Finally, we present experimental results to demonstrate the performance of the algorithms.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5119–5128},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327417,
author = {Logeswaran, Lajanugen and Lee, Honglak and Bengio, Samy},
title = {Content Preserving Text Generation with Attribute Controls},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this work, we address the problem of modifying textual attributes of sentences. Given an input sentence and a set of attribute labels, we attempt to generate sentences that are compatible with the conditioning information. To ensure that the model generates content compatible sentences, we introduce a reconstruction loss which interpolates between auto-encoding and back-translation loss components. We propose an adversarial loss to enforce generated samples to be attribute compatible and realistic. Through quantitative, qualitative and human evaluations we demonstrate that our model is capable of generating fluent sentences that better reflect the conditioning information compared to prior methods. We further demonstrate that the model is capable of simultaneously controlling multiple attributes.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5108–5118},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327416,
author = {Jaiswal, Ayush and Wu, Yue and Almageed, Wael Abd and Natarajan, Premkumar},
title = {Unsupervised Adversarial Invariance},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Data representations that contain all the information about target variables but are invariant to nuisance factors benefit supervised learning algorithms by preventing them from learning associations between these factors and the targets, thus reducing overfitting. We present a novel unsupervised invariance induction framework for neural networks that learns a split representation of data through competitive training between the prediction task and a reconstruction task coupled with disentanglement, without needing any labeled information about nuisance factors or domain knowledge. We describe an adversarial instantiation of this framework and provide analysis of its working. Our unsupervised model outperforms state-of-the-art methods, which are supervised, at inducing invariance to inherent nuisance factors, effectively using synthetic data augmentation to learn invariance, and domain adaptation. Our method can be applied to any prediction task, eg., binary/multi-class classification or regression, without loss of generality.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5097–5107},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327415,
author = {Cheng, Ricson and Wang, Ziyan and Fragkiadaki, Katerina},
title = {Geometry-Aware Recurrent Neural Networks for Active Visual Recognition},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present recurrent geometry-aware neural networks that integrate visual information across multiple views of a scene into 3D latent feature tensors, while maintaining an one-to-one mapping between 3D physical locations in the world scene and latent feature locations. Object detection, object segmentation, and 3D reconstruction is then carried out directly using the constructed 3D feature memory, as opposed to any of the input 2D images. The proposed models are equipped with differentiable egomotion-aware feature warping and (learned) depth-aware unprojection operations to achieve geometrically consistent mapping between the features in the input frame and the constructed latent model of the scene. We empirically show the proposed model generalizes much better than geometry-unaware LSTM/GRU networks, especially under the presence of multiple objects and cross-object occlusions. Combined with active view selection policies, our model learns to select informative viewpoints to integrate information from by "undoing" cross-object occlusions, seamlessly combining geometry with learning from experience.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5086–5096},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327414,
author = {Morais, Michael J. and Pillow, Jonathan W.},
title = {Power-Law Efficient Neural Codes Provide General Link between Perceptual Bias and Discriminability},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recent work in theoretical neuroscience has shown that efficient neural codes, which allocate neural resources to maximize the mutual information between stimuli and neural responses, give rise to a lawful relationship between perceptual bias and discriminability in psychophysical measurements (Wei &amp; Stocker 2017, [1]). Here we generalize these results to show that the same law arises under a much larger family of optimal neural codes, which we call power-law efficient codes. These codes provide a unifying framework for understanding the relationship between perceptual bias and discriminability, and how it depends on the allocation of neural resources. Specifically, we show that the same lawful relationship between bias and discriminability arises whenever Fisher information is allocated proportional to any power of the prior distribution. This family includes neural codes that are optimal for minimizing Lp error for any p, indicating that the lawful relationship observed in human psychophysical data does not require information-theoretically optimal neural codes. Furthermore, we derive the exact constant of proportionality governing the relationship between bias and discriminability for different choices of power law exponent q, which includes information-theoretic (q = 2) as well as "discrimax" (q = 1/2) neural codes, and different choices of decoder. As a bonus, our framework provides new insights into "anti-Bayesian" perceptual biases, in which percepts are biased away from the center of mass of the prior. We derive an explicit formula that clarifies precisely which combinations of neural encoder and decoder can give rise to such biases.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5076–5085},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327413,
author = {Yao, Quanming and Kwok, James T.},
title = {Scalable Robust Matrix Factorization with Nonconvex Loss},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Matrix factorization (MF), which uses the ℓ2-loss, and robust matrix factorization (RMF), which uses the ℓ1-loss, are sometimes not robust enough for outliers. Moreover, even the state-of-the-art RMF solver (RMF-MM) is slow and cannot utilize data sparsity. In this paper, we propose to improve robustness by using nonconvex loss functions. The resultant optimization problem is difficult. To improve efficiency and scalability, we use majorization-minimization (MM) and optimize the MM surrogate by using the accelerated proximal gradient algorithm on its dual problem. Data sparsity can also be exploited. The resultant algorithm has low time and space complexities, and is guaranteed to converge to a critical point. Extensive experiments show that it outperforms the state-of-the-art in terms of both accuracy and speed.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5066–5075},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327412,
author = {Chen, Tianyi and Giannakis, Georgios B. and Sun, Tao and Yin, Wotao},
title = {LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper presents a new class of gradient methods for distributed machine learning that adaptively skip the gradient calculations to learn with reduced communication and computation. Simple rules are designed to detect slowly-varying gradients and, therefore, trigger the reuse of outdated gradients. The resultant gradient-based algorithms are termed Lazily Aggregated Gradient — justifying our acronym LAG used henceforth. Theoretically, the merits of this contribution are: i) the convergence rate is the same as batch gradient descent in strongly-convex, convex, and nonconvex cases; and, ii) if the distributed datasets are heterogeneous (quantified by certain measurable constants), the communication rounds needed to achieve a targeted accuracy are reduced thanks to the adaptive reuse of lagged gradients. Numerical experiments on both synthetic and real data corroborate a significant communication reduction compared to alternatives.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5055–5065},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327411,
author = {Farina, Gabriele and Gatti, Nicola and Sandholm, Tuomas},
title = {Practical Exact Algorithm for Trembling-Hand Equilibrium Refinements in Games},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Nash equilibrium strategies have the known weakness that they do not prescribe rational play in situations that are reached with zero probability according to the strategies themselves, for example, if players have made mistakes. Trembling-hand refinements—such as extensive-form perfect equilibria and quasi-perfect equilibria—remedy this problem in sound ways. Despite their appeal, they have not received attention in practice since no known algorithm for computing them scales beyond toy instances. In this paper, we design an exact polynomial-time algorithm for finding trembling-hand equilibria in zero-sum extensive-form games. It is several orders of magnitude faster than the best prior ones, numerically stable, and quickly solves game instances with tens of thousands of nodes in the game tree. It enables, for the first time, the use of trembling-hand refinements in practice.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5044–5054},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327410,
author = {Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
title = {Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Evolution strategies (ES) are a family of black-box optimization algorithms able to train deep neural networks roughly as well as Q-learning and policy gradient methods on challenging deep reinforcement learning (RL) problems, but are much faster (e.g. hours vs. days) because they parallelize better. However, many RL problems require directed exploration because they have reward functions that are sparse or deceptive (i.e. contain local optima), and it is unknown how to encourage such exploration with ES. Here we show that algorithms that have been invented to promote directed exploration in small-scale evolved neural networks via populations of exploring agents, specifically novelty search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to improve its performance on sparse or deceptive deep RL tasks, while retaining scalability. Our experiments confirm that the resultant new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES to achieve higher performance on Atari and simulated robots learning to walk around a deceptive trap. This paper thus introduces a family of fast, scalable algorithms for reinforcement learning that are capable of directed exploration. It also adds this new family of exploration algorithms to the RL toolbox and raises the interesting possibility that analogous algorithms with multiple simultaneous paths of exploration might also combine well with existing RL algorithms outside ES.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5032–5043},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327409,
author = {Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Madry, Aleksander},
title = {Adversarially Robust Generalization Requires More Data},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Machine learning models are often susceptible to adversarial perturbations of their inputs. Even small perturbations can cause state-of-the-art classifiers with high "standard" accuracy to produce an incorrect prediction with high confidence. To better understand this phenomenon, we study adversarially robust learning from the viewpoint of generalization. We show that already in a simple natural data model, the sample complexity of robust learning can be significantly larger than that of "standard" learning. This gap is information theoretic and holds irrespective of the training algorithm or the model family. We complement our theoretical results with experiments on popular image classification datasets and show that a similar gap exists here as well. We postulate that the difficulty of training robust classifiers stems, at least partially, from this inherently larger sample complexity.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5019–5031},
numpages = {13},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327408,
author = {Zhang, Quan and Zhou, Mingyuan},
title = {Nonparametric Bayesian Lomax Delegate Racing for Survival Analysis with Competing Risks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose Lomax delegate racing (LDR) to explicitly model the mechanism of survival under competing risks and to interpret how the covariates accelerate or decelerate the time to event. LDR explains non-monotonic covariate effects by racing a potentially infinite number of sub-risks, and consequently relaxes the ubiquitous proportional-hazards assumption which may be too restrictive. Moreover, LDR is naturally able to model not only censoring, but also missing event times or event types. For inference, we develop a Gibbs sampler under data augmentation for moderately sized data, along with a stochastic gradient descent maximum a posteriori inference algorithm for big data applications. Illustrative experiments are provided on both synthetic and real datasets, and comparison with various benchmark algorithms for survival analysis with competing risks demonstrates distinguished performance of LDR.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5007–5018},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327407,
author = {Garg, Vikas K. and Kalai, Adam},
title = {Supervising Unsupervised Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce a framework to transfer knowledge acquired from a repository of (heterogeneous) supervised datasets to new unsupervised datasets. Our perspective avoids the subjectivity inherent in unsupervised learning by reducing it to supervised learning, and provides a principled way to evaluate unsupervised algorithms. We demonstrate the versatility of our framework via rigorous agnostic bounds on a variety of unsupervised problems. In the context of clustering, our approach helps choose the number of clusters and the clustering algorithm, remove the outliers, and provably circumvent Kleinberg's impossibility result. Experiments across hundreds of problems demonstrate improvements in performance on unsupervised data with simple algorithms despite the fact our problems come from heterogeneous domains. Additionally, our framework lets us leverage deep networks to learn common features across many small datasets, and perform zero shot learning.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4996–5006},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327406,
author = {Li, Yao and Cheng, Minhao and Fujii, Kevin and Hsieh, Fushing and Hsieh, Cho-Jui},
title = {Learning from Group Comparisons: Exploiting Higher Order Interactions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study the problem of learning from group comparisons, with applications in predicting outcomes of sports and online games. Most of the previous works in this area focus on learning individual effects—they assume each player has an underlying score, and the "ability" of the team is modeled by the sum of team members' scores. Therefore, current approaches cannot model deeper interaction between team members: some players perform much better if they play together, while some players perform poorly together. In this paper, we propose a new model that takes the player-interaction effects into consideration. However, under certain circumstances, the total number of individuals can be very large, and number of player interactions grows quadratically, which makes learning intractable. In this case, we propose a latent factor model, and show that the sample complexity of our model is bounded under mild assumptions. Finally, we show that our proposed models have much better prediction power on several E-sports datasets, and furthermore can be used to reveal interesting patterns that cannot be discovered by previous methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4986–4995},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327405,
author = {Terada, Yu and Obuchi, Tomoyuki and Isomura, Takuya and Kabashima, Yoshiyuki},
title = {Objective and Efficient Inference for Couplings in Neuronal Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Inferring directional couplings from the spike data of networks is desired in various scientific fields such as neuroscience. Here, we apply a recently proposed objective procedure to the spike data obtained from the Hodgkin–Huxley type models and in vitro neuronal networks cultured in a circular structure. As a result, we succeed in reconstructing synaptic connections accurately from the evoked activity as well as the spontaneous one. To obtain the results, we invent an analytic formula approximately implementing a method of screening relevant couplings. This significantly reduces the computational cost of the screening method employed in the proposed objective procedure, making it possible to treat large-size systems as in this study.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4976–4985},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327404,
author = {Koide, Satoshi and Kawano, Keisuke and Kutsuna, Takuro},
title = {Neural Edit Operations for Biological Sequences},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The evolution of biological sequences, such as proteins or DNAs, is driven by the three basic edit operations: substitution, insertion, and deletion. Motivated by the recent progress of neural network models for biological tasks, we implement two neural network architectures that can treat such edit operations. The first proposal is the edit invariant neural networks, based on differentiable Needleman-Wunsch algorithms. The second is the use of deep CNNs with concatenations. Our analysis shows that CNNs can recognize star-free regular expressions, and that deeper CNNs can recognize more complex regular expressions including the insertion/deletion of characters. The experimental results for the protein secondary structure prediction task suggest the importance of insertion/deletion. The test accuracy on the widely-used CB513 dataset is 71.5%, which is 1.2-points better than the current best result on non-ensemble models.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4965–4975},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327403,
author = {Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W.},
title = {Hessian-Based Analysis of Large Batch Training and Robustness to Adversaries},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Large batch size training of Neural Networks has been shown to incur accuracy loss when trained with the current methods. The exact underlying reasons for this are still not completely understood. Here, we study large batch size training through the lens of the Hessian operator and robust optimization. In particular, we perform a Hessian based study to analyze exactly how the landscape of the loss function changes when training with large batch size. We compute the true Hessian spectrum, without approximation, by back-propagating the second derivative. Extensive experiments on multiple networks show that saddle-points are not the cause for generalization gap of large batch size training, and the results consistently show that large batch converges to points with noticeably higher Hessian spectrum. Furthermore, we show that robust training allows one to favor flat areas, as points with large Hessian spectrum show poor robustness to adversarial perturbation. We further study this relationship, and provide empirical and theoretical proof that the inner loop for robust training is a saddle-free optimization problem almost everywhere. We present detailed experiments with five different network architectures, including a residual network, tested on MNIST, CIFAR-10/100 datasets.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4954–4964},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327402,
author = {Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and Daniel, Luca},
title = {Efficient Neural Network Robustness Certification with General Activation Functions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Finding minimum distortion of adversarial examples and thus certifying robustness in neural network classifiers for given data points is known to be a challenging problem. Nevertheless, recently it has been shown to be possible to give a non-trivial certified lower bound of minimum adversarial distortion, and some recent progress has been made towards this direction by exploiting the piece-wise linear nature of ReLU activations. However, a generic robustness certification for general activation functions still remains largely unexplored. To address this issue, in this paper we introduce CROWN, a general framework to certify robustness of neural networks with general activation functions for given input data points. The novelty in our algorithm consists of bounding a given activation function with linear and quadratic functions, hence allowing it to tackle general activation functions including but not limited to four popular choices: ReLU, tanh, sigmoid and arctan. In addition, we facilitate the search for a tighter certified lower bound by adaptively selecting appropriate surrogates for each neuron activation. Experimental results show that CROWN on ReLU networks can notably improve the certified lower bounds compared to the current state-of-the-art algorithm Fast-Lin, while having comparable computational efficiency. Furthermore, CROWN also demonstrates its effectiveness and flexibility on networks with general activation functions, including tanh, sigmoid and arctan.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4944–4953},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327401,
author = {Wang, Wenbo and Qiao, Xingye},
title = {Learning Confidence Sets Using Support Vector Machines},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The goal of confidence-set learning in the binary classification setting [14] is to construct two sets, each with a specific probability guarantee to cover a class. An observation outside the overlap of the two sets is deemed to be from one of the two classes, while the overlap is an ambiguity region which could belong to either class. Instead of plug-in approaches, we propose a support vector classifier to construct confidence sets in a flexible manner. Theoretically, we show that the proposed learner can control the non-coverage rates and minimize the ambiguity with high probability. Efficient algorithms are developed and numerical studies illustrate the effectiveness of the proposed method.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4934–4943},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327400,
author = {Shah, Virag and Blanchet, Jose and Johari, Ramesh},
title = {Bandit Learning with Positive Externalities},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In many platforms, user arrivals exhibit a self-reinforcing behavior: future user arrivals are likely to have preferences similar to users who were satisfied in the past. In other words, arrivals exhibit positive externalities. We study multiarmed bandit (MAB) problems with positive externalities. We show that the self-reinforcing preferences may lead standard benchmark algorithms such as UCB to exhibit linear regret. We develop a new algorithm, Balanced Exploration (BE), which explores arms carefully to avoid suboptimal convergence of arrivals before sufficient evidence is gathered. We also introduce an adaptive variant of BE which successively eliminates suboptimal arms. We analyze their asymptotic regret, and establish optimality by showing that no algorithm can perform better.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4923–4933},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327399,
author = {Tay, Yi and Tuan, Luu Anh and Hui, Siu Cheung and Su, Jian},
title = {Densely Connected Attention Propagation for Reading Comprehension},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose DECAPROP (Densely Connected Attention Propagation), a new densely connected neural architecture for reading comprehension (RC). There are two distinct characteristics of our model. Firstly, our model densely connects all pairwise layers of the network, modeling relationships between passage and query across all hierarchical levels. Secondly, the dense connectors in our network are learned via attention instead of standard residual skip-connectors. To this end, we propose novel Bidirectional Attention Connectors (BAC) for efficiently forging connections throughout the network. We conduct extensive experiments on four challenging RC benchmarks. Our proposed approach achieves state-of-the-art results on all four, outperforming existing baselines by up to 2.6% - 14.2% in absolute F1 score.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4911–4922},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327398,
author = {Jin, Chi and Liu, Lydia T. and Ge, Rong and Jordan, Michael I.},
title = {On the Local Minima of the Empirical Risk},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Population risk is always of primary interest in machine learning; however, learning algorithms only have access to the empirical risk. Even for applications with nonconvex nonsmooth losses (such as modern deep networks), the population risk is generally significantly more well-behaved from an optimization point of view than the empirical risk. In particular, sampling can create many spurious local minima. We consider a general framework which aims to optimize a smooth nonconvex function F (population risk) given only access to an approximation f (empirical risk) that is pointwise close to F (i.e., ||F – f||∞ ≤ ν). Our objective is to find the ε-approximate local minima of the underlying function F while avoiding the shallow local minima—arising because of the tolerance ν—which exist only in f. We propose a simple algorithm based on stochastic gradient descent (SGD) on a smoothed version of f that is guaranteed to achieve our goal as long as ν ≤ O(ε1.5/d). We also provide an almost matching lower bound showing that our algorithm achieves optimal error tolerance ν among all algorithms making a polynomial number of queries of f. As a concrete example, we show that our results can be directly used to give sample complexities for learning a ReLU unit.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4901–4910},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327397,
author = {Vankadara, Leena Chennuru and von Luxburg, Ulrike},
title = {Measures of Distortion for Machine Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Given data from a general metric space, one of the standard machine learning pipelines is to first embed the data into a Euclidean space and subsequently apply machine learning algorithms to analyze the data. The quality of such an embedding is typically described in terms of a distortion measure. In this paper, we show that many of the existing distortion measures behave in an undesired way, when considered from a machine learning point of view. We investigate desirable properties of distortion measures and formally prove that most of the existing measures fail to satisfy these properties. These theoretical findings are supported by simulations, which for example demonstrate that existing distortion measures are not robust to noise or outliers and cannot serve as good indicators for classification accuracy. As an alternative, we suggest a new measure of distortion, called σ-distortion. We can show both in theory and in experiments that it satisfies all desirable properties and is a better candidate to evaluate distortion in the context of machine learning.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4891–4900},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327396,
author = {Zhang, Xin and Solar-Lezama, Armando and Singh, Rishabh},
title = {Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a new algorithm to generate minimal, stable, and symbolic corrections to an input that will cause a neural network with ReLU activations to change its output. We argue that such a correction is a useful way to provide feedback to a user when the network's output is different from a desired output. Our algorithm generates such a correction by solving a series of linear constraint satisfaction problems. The technique is evaluated on three neural network models: one predicting whether an applicant will pay a mortgage, one predicting whether a first-order theorem can be proved efficiently by a solver using certain heuristics, and the final one judging whether a drawing is an accurate rendition of a canonical drawing of a cat.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4879–4890},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327395,
author = {Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I.},
title = {Is Q-Learning Provably Efficient?},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Model-free reinforcement learning (RL) algorithms, such as Q-learning, directly parameterize and update value functions or policies without explicitly modeling the environment. They are typically simpler, more flexible to use, and thus more prevalent in modern deep RL than model-based approaches. However, empirical work has suggested that model-free algorithms may require more samples to learn [7, 22]. The theoretical question of "whether model-free algorithms can be made sample efficient" is one of the most fundamental questions in RL, and remains unsolved even in the basic scenario with finitely many states and actions. We prove that, in an episodic MDP setting, Q-learning with UCB exploration achieves regret \~{O}(√H3SAT), where S and A are the numbers of states and actions, H is the number of steps per episode, and T is the total number of steps. This sample efficiency matches the optimal regret that can be achieved by any model-based approach, up to a single √H factor. To the best of our knowledge, this is the first analysis in the model-free setting that establishes √T regret without requiring access to a "simulator."},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4868–4878},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327394,
author = {Liu, Mingrui and Li, Zhe and Wang, Xiaoyu and Yi, Jinfeng and Yang, Tianbao},
title = {Adaptive Negative Curvature Descent with Applications in Non-Convex Optimization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Negative curvature descent (NCD) method has been utilized to design deterministic or stochastic algorithms for non-convex optimization aiming at finding second-order stationary points or local minima. In existing studies, NCD needs to approximate the smallest eigen-value of the Hessian matrix with a sufficient precision (e.g., ε2 ≪ 1) in order to achieve a sufficiently accurate second-order stationary solution (i.e., λmin(∇2f(x)) ≥ – ε2). One issue with this approach is that the target precision ε2 is usually set to be very small in order to find a high quality solution, which increases the complexity for computing a negative curvature. To address this issue, we propose an adaptive NCD to allow an adaptive error dependent on the current gradient's magnitude in approximating the smallest eigen-value of the Hessian, and to encourage competition between a noisy NCD step and gradient descent step. We consider the applications of the proposed adaptive NCD for both deterministic and stochastic non-convex optimization, and demonstrate that it can help reduce the the overall complexity in computing the negative curvatures during the course of optimization without sacrificing the iteration complexity.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4858–4867},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327393,
author = {Kim, Michael P. and Reingold, Omer and Rothblum, Guy N.},
title = {Fairness through Computationally-Bounded Awareness},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We study the problem of fair classification within the versatile framework of Dwork et al. [6], which assumes the existence of a metric that measures similarity between pairs of individuals. Unlike earlier work, we do not assume that the entire metric is known to the learning algorithm; instead, the learner can query this arbitrary metric a bounded number of times. We propose a new notion of fairness called metric multifairness and show how to achieve this notion in our setting. Metric multifairness is parameterized by a similarity metric d on pairs of individuals to classify and a rich collection C of (possibly overlapping) "comparison sets" over pairs of individuals. At a high level, metric multifairness guarantees that similar subpopulations are treated similarly, as long as these subpopulations are identified within the class C.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4847–4857},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327392,
author = {Feizi, Soheil and Javadi, Hamid and Zhang, Jesse and Tse, David},
title = {Porcupine Neural Networks: Approximating Neural Network Landscapes},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural networks have been used prominently in several machine learning and statistics applications. In general, the underlying optimization of neural networks is non-convex which makes analyzing their performance challenging. In this paper, we take another approach to this problem by constraining the network such that the corresponding optimization landscape has good theoretical properties without significantly compromising performance. In particular, for two-layer neural networks we introduce Porcupine Neural Networks (PNNs) whose weight vectors are constrained to lie over a finite set of lines. We show that most local optima of PNN optimizations are global while we have a characterization of regions where bad local optimizers may exist. Moreover, our theoretical and empirical results suggest that an unconstrained neural network can be approximated using a polynomially-large PNN.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4836–4846},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327391,
author = {Mainsah, Boyla O. and Kalika, Dmitry and Collins, Leslie M. and Liu, Siyuan and Throckmorton, Chandra S.},
title = {Information-Based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Stimulus-driven brain-computer interfaces (BCIs), such as the P300 speller, rely on using a sequence of sensory stimuli to elicit specific neural responses as control signals, while a user attends to relevant target stimuli that occur within the sequence. In current BCIs, the stimulus presentation schedule is typically generated in a pseudo-random fashion. Given the non-stationarity of brain electrical signals, a better strategy could be to adapt the stimulus presentation schedule in real-time by selecting the optimal stimuli that will maximize the signal-to-noise ratios of the elicited neural responses and provide the most information about the user's intent based on the uncertainties of the data being measured. However, the high-dimensional stimulus space limits the development of algorithms with tractable solutions for optimized stimulus selection to allow for real-time decision-making within the stringent time requirements of BCI processing. We derive a simple analytical solution of an information-based objective function for BCI stimulus selection by transforming the high-dimensional stimulus space into a one-dimensional space that parameterizes the objective function - the prior probability mass of the stimulus under consideration, irrespective of its contents. We demonstrate the utility of our adaptive stimulus selection algorithm in improving BCI performance with results from simulation and real-time human experiments.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4825–4835},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327390,
author = {Tran-Dinh, Quoc},
title = {Non-Ergodic Alternating Proximal Augmented Lagrangian Algorithms with Optimal Rates},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We develop two new non-ergodic alternating proximal augmented Lagrangian algorithms (NEAPAL) to solve a class of nonsmooth constrained convex optimization problems. Our approach relies on a novel combination of the augmented Lagrangian framework, alternating/linearization scheme, Nesterov's acceleration techniques, and adaptive strategy for parameters. Our algorithms have several new features compared to existing methods. Firstly, they have a Nesterov's acceleration step on the primal variables compared to the dual one in several methods in the literature. Secondly, they achieve non-ergodic optimal convergence rates under standard assumptions, i.e. an O(1/k) rate without any smoothness or strong convexity-type assumption, or an O(1/k2) rate under only semi-strong convexity, where k is the iteration counter. Thirdly, they preserve or have better per-iteration complexity compared to existing algorithms. Fourthly, they can be implemented in a parallel fashion. Finally, all the parameters are adaptively updated without heuristic tuning. We verify our algorithms on different numerical examples and compare them with some state-of-the-art methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4816–4824},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327389,
author = {Ying, Rex and You, Jiaxuan and Morris, Christopher and Ren, Xiang and Hamilton, William L. and Leskovec, Jure},
title = {Hierarchical Graph Representation Learning with Differentiable Pooling},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs—a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DIFFPOOL, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DIFFPOOL learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DIFFPOOL yields an average improvement of 5-10% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark data sets.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4805–4815},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327388,
author = {Bunel, Rudy and Turkaslan, Ilker and Torr, Philip H.S. and Kohli, Pushmeet and Kumar, M. Pawan},
title = {A Unified View of Piecewise Linear Neural Network Verification},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The success of Deep Learning and its potential use in many safety-critical applications has motivated research on formal verification of Neural Network (NN) models. Despite the reputation of learned NN models to behave as black boxes and the theoretical hardness of proving their properties, researchers have been successful in verifying some classes of models by exploiting their piecewise linear structure and taking insights from formal methods such as Satisifiability Modulo Theory. These methods are however still far from scaling to realistic neural networks. To facilitate progress on this crucial area, we make two key contributions. First, we present a unified framework that encompasses previous methods. This analysis results in the identification of new methods that combine the strengths of multiple existing approaches, accomplishing a speedup of two orders of magnitude compared to the previous state of the art. Second, we propose a new data set of benchmarks which includes a collection of previously released testcases. We use the benchmark to provide the first experimental comparison of existing algorithms and identify the factors impacting the hardness of verification problems.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4795–4804},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327387,
author = {Kumaraswamy, Raksha and Schlegel, Matthew and White, Adam and White, Martha},
title = {Context-Dependent Upper-Confidence Bounds for Directed Exploration},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Directed exploration strategies for reinforcement learning are critical for learning an optimal policy in a minimal number of interactions with the environment. Many algorithms use optimism to direct exploration, either through visitation estimates or upper confidence bounds, as opposed to data-inefficient strategies like ε-greedy that use random, undirected exploration. Most data-efficient exploration methods require significant computation, typically relying on a learned model to guide exploration. Least-squares methods have the potential to provide some of the data-efficiency benefits of model-based approaches—because they summarize past interactions—with the computation closer to that of model-free approaches. In this work, we provide a novel, computationally efficient, incremental exploration strategy, leveraging this property of least-squares temporal difference learning (LSTD). We derive upper confidence bounds on the action-values learned by LSTD, with context-dependent (or state-dependent) noise variance. Such context-dependent noise focuses exploration on a subset of variable states, and allows for reduced exploration in other states. We empirically demonstrate that our algorithm can converge more quickly than other incremental exploration strategies using confidence estimates on action-values.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4784–4794},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327386,
author = {Pillutla, Krishna and Roulet, Vincent and Kakade, Sham M. and Harchaoui, Zaid},
title = {A Smoother Way to Train Structured Prediction Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a framework to train a structured prediction model by performing smoothing on the inference algorithm it builds upon. Smoothing overcomes the non-smoothness inherent to the maximum margin structured prediction objective, and paves the way for the use of fast primal gradient-based optimization algorithms. We illustrate the proposed framework by developing a novel primal incremental optimization algorithm for the structural support vector machine. The proposed algorithm blends an extrapolation scheme for acceleration and an adaptive smoothing scheme and builds upon the stochastic variance-reduced gradient algorithm. We establish its worst-case global complexity bound and study several practical variants. We present experimental results on two real-world problems, namely named entity recognition and visual object localization. The experimental results show that the proposed framework allows us to build upon efficient inference algorithms to develop large-scale optimization algorithms for structured prediction which can achieve competitive performance on the two real-world problems.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4771–4783},
numpages = {13},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327385,
author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
title = {Deep Reinforcement Learning in a Handful of Trials Using Probabilistic Dynamics Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g. 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4759–4770},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327384,
author = {Fujii, Kaito and Soma, Tasuku},
title = {Fast Greedy Algorithms for Dictionary Selection with Generalized Sparsity Constraints},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In dictionary selection, several atoms are selected from finite candidates that successfully approximate given data points in the sparse representation. We propose a novel efficient greedy algorithm for dictionary selection. Not only does our algorithm work much faster than the known methods, but it can also handle more complex sparsity constraints, such as average sparsity. Using numerical experiments, we show that our algorithm outperforms the known methods for dictionary selection, achieving competitive performances with dictionary learning algorithms in a smaller running time.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4749–4758},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327383,
author = {Tay, Yi and Tuan, Luu Anh and Hui, Siu Cheung},
title = {Recurrently Controlled Recurrent Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recurrent neural networks (RNNs) such as long short-term memory and gated recurrent units are pivotal building blocks across a broad spectrum of sequence modeling problems. This paper proposes a recurrently controlled recurrent network (RCRN) for expressive and powerful sequence encoding. More concretely, the key idea behind our approach is to learn the recurrent gating functions using recurrent networks. Our architecture is split into two components - a controller cell and a listener cell whereby the recurrent controller actively influences the compositionality of the listener cell. We conduct extensive experiments on a myriad of tasks in the NLP domain such as sentiment analysis (SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment classification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading comprehension (NarrativeQA). Across all 26 datasets, our results demonstrate that RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs, suggesting that our controller architecture might be a suitable replacement for the widely adopted stacked architecture.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4736–4748},
numpages = {13},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327382,
author = {Morozov, Stanislav and Babenko, Artem},
title = {Non-Metric Similarity Graphs for Maximum Inner Product Search},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper we address the problem of Maximum Inner Product Search (MIPS) that is currently the computational bottleneck in a large number of machine learning applications. While being similar to the nearest neighbor search (NNS), the MIPS problem was shown to be more challenging, as the inner product is not a proper metric function. We propose to solve the MIPS problem with the usage of similarity graphs, i.e., graphs where each vertex is connected to the vertices that are the most similar in terms of some similarity function. Originally, the framework of similarity graphs was proposed for metric spaces and in this paper we naturally extend it to the non-metric MIPS scenario. We demonstrate that, unlike existing approaches, similarity graphs do not require any data transformation to reduce MIPS to the NNS problem and should be used for the original data. Moreover, we explain why such a reduction is detrimental for similarity graphs. By an extensive comparison to the existing approaches, we show that the proposed method is a game-changer in terms of the runtime/accuracy trade-off for the MIPS problem.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4726–4735},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327381,
author = {Desai, Nishant and Critch, Andrew and Russell, Stuart},
title = {Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {It is commonly believed that an agent making decisions on behalf of two or more principals who have different utility functions should adopt a Pareto optimal policy, i.e. a policy that cannot be improved upon for one principal without making sacrifices for another. Harsanyi's theorem shows that when the principals have a common prior on the outcome distributions of all policies, a Pareto optimal policy for the agent is one that maximizes a fixed, weighted linear combination of the principals' utilities. In this paper, we derive a more precise generalization for the sequential decision setting in the case of principals with different priors on the dynamics of the environment. We refer to this generalization as the Negotiable Reinforcement Learning (NRL) framework. In this more general case, the relative weight given to each principal's utility should evolve over time according to how well the agent's observations conform with that principal's prior. To gain insight into the dynamics of this new framework, we implement a simple NRL agent and empirically examine its behavior in a simple environment.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4717–4725},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327380,
author = {Magdon-Ismail, Malik and Xia, Lirong},
title = {A Mathematical Model for Optimal Decisions In a Representative Democracy},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Direct democracy, where each voter casts one vote, fails when the average voter competence falls below 50%. This happens in noisy settings when voters have limited information. Representative democracy, where voters choose representatives to vote, can be an elixir in both these situations. We introduce a mathematical model for studying representative democracy, in particular understanding the parameters of a representative democracy that gives maximum decision making capability. Our main result states that under general and natural conditions1. for fixed voting cost, the optimal number of representatives is linear;2. for polynomial cost, the optimal number of representatives is logarithmic.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4707–4716},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327379,
author = {Shahrampour, Shahin and Tarokh, Vahid},
title = {Learning Bounds for Greedy Approximation with Explicit Feature Maps from Multiple Kernels},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Nonlinear kernels can be approximated using finite-dimensional feature maps for efficient risk minimization. Due to the inherent trade-off between the dimension of the (mapped) feature space and the approximation accuracy, the key problem is to identify promising (explicit) features leading to a satisfactory out-of-sample performance. In this work, we tackle this problem by efficiently choosing such features from multiple kernels in a greedy fashion. Our method sequentially selects these explicit features from a set of candidate features using a correlation metric. We establish an out-of-sample error bound capturing the trade-off between the error in terms of explicit features (approximation error) and the error due to spectral properties of the best model in the Hilbert space associated to the combined kernel (spectral error). The result verifies that when the (best) underlying data model is sparse enough, i.e., the spectral error is negligible, one can control the test error with a small number of explicit features, that can scale poly-logarithmically with data. Our empirical results show that given a fixed number of explicit features, the method can achieve a lower test error with a smaller time cost, compared to the state-of-the-art in data-dependent random features.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4695–4706},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327378,
author = {Liu, Mingrui and Zhang, Xiaoxuan and Zhang, Lijun and Jin, Rong and Yang, Tianbao},
title = {Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Error bound conditions (EBC) are properties that characterize the growth of an objective function when a point is moved away from the optimal set. They have recently received increasing attention for developing optimization algorithms with fast convergence. However, the studies of EBC in statistical learning are hitherto still limited. The main contributions of this paper are two-fold. First, we develop fast and intermediate rates of empirical risk minimization (ERM) under EBC for risk minimization with Lipschitz continuous, and smooth convex random functions. Second, we establish fast and intermediate rates of an efficient stochastic approximation (SA) algorithm for risk minimization with Lipschitz continuous random functions, which requires only one pass of n samples and adapts to EBC. For both approaches, the convergence rates span a full spectrum between \~{O}(1/√n) and \~{O}(1/√n) depending on the power constant in EBC, and could be even faster than O(1/√n) in special cases for ERM. Moreover, these convergence rates are automatically adaptive without using any knowledge of EBC.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4683–4694},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327377,
author = {Chen, Liqun and Dai, Shuyang and Tao, Chenyang and Shen, Dinghan and Gan, Zhe and Zhang, Haichao and Zhang, Yizhe and Zhang, Ruiyi and Wang, Guoyin and Carin, Lawrence},
title = {Adversarial Text Generation via Feature-Mover's Distance},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Generative adversarial networks (GANs) have achieved significant success in generating real-valued data. However, the discrete nature of text hinders the application of GAN to text-generation tasks. Instead of using the standard GAN objective, we propose to improve text-generation GAN via a novel approach inspired by optimal transport. Specifically, we consider matching the latent feature distributions of real and synthetic sentences using a novel metric, termed the feature-mover's distance (FMD). This formulation leads to a highly discriminative critic and easy-to-optimize objective, overcoming the mode-collapsing and brittle-training problems in existing methods. Extensive experiments are conducted on a variety of tasks to evaluate the proposed model empirically, including unconditional text generation, style transfer from non-parallel text, and unsupervised cipher cracking. The proposed model yields superior performance, demonstrating wide applicability and effectiveness.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4671–4682},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327376,
author = {Dash, Sanjeeb and G\"{u}nl\"{u}k, Oktay and Wei, Dennis},
title = {Boolean Decision Rules via Column Generation},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper considers the learning of Boolean rules in either disjunctive normal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive normal form (CNF, AND-of-ORs) as an interpretable model for classification. An integer program is formulated to optimally trade classification accuracy for rule simplicity. Column generation (CG) is used to efficiently search over an exponential number of candidate clauses (conjunctions or disjunctions) without the need for heuristic rule mining. This approach also bounds the gap between the selected rule set and the best possible rule set on the training data. To handle large datasets, we propose an approximate CG algorithm using randomization. Compared to three recently proposed alternatives, the CG algorithm dominates the accuracy-simplicity tradeoff in 8 out of 16 datasets. When maximized for accuracy, CG is competitive with rule learners designed for this purpose, sometimes finding significantly simpler solutions that are no less accurate.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4660–4670},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327375,
author = {Zheng, Zeyu and Oh, Junhyuk and Singh, Satinder},
title = {On Learning Intrinsic Rewards for Policy Gradient Methods},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In many sequential decision making tasks, it is challenging to design reward functions that help an RL agent efficiently learn behavior that is considered good by the agent designer. A number of different formulations of the reward-design problem have been proposed in the literature. In this paper we build on the Optimal Rewards Framework of Singh et al. [2010] that defines the optimal intrinsic reward function as one that when used by an RL agent achieves behavior that optimizes the task-specifying or extrinsic reward function. Previous work in this framework has shown how good intrinsic reward functions can be learned for lookahead search based planning agents. Whether it is possible to learn intrinsic reward functions for learning agents remains an open problem. In this paper we derive a novel algorithm for learning intrinsic rewards for policy-gradient based learning agents. We compare the performance of an augmented agent that uses our algorithm to provide additive intrinsic rewards to an A2C-based policy learner (for Atari games) and a PPO-based policy learner (for Mujoco domains) with a baseline agent that uses the same policy learners but with only extrinsic rewards. We also compare our method with using a constant "live bonus" and with using a count-based exploration bonus (i.e., pixel-SimHash). Our results show improved performance on most but not all of the domains.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4649–4659},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327374,
author = {Hazan, Elad and Lee, Holden and Singh, Karan and Zhang, Cyril and Zhang, Yi},
title = {Spectral Filtering for General Linear Dynamical Systems},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We give a polynomial-time algorithm for learning latent-state linear dynamical systems without system identification, and without assumptions on the spectral radius of the system's transition matrix. The algorithm extends the recently introduced technique of spectral filtering, previously applied only to systems with a symmetric transition matrix, using a novel convex relaxation to allow for the efficient identification of phases.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4639–4648},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327373,
author = {Dumitrascu, Bianca and Feng, Karen and Engelhardt, Barbara E.},
title = {PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We address the problem of regret minimization in logistic contextual bandits, where a learner decides among sequential actions or arms given their respective contexts to maximize binary rewards. Using a fast inference procedure with P\'{o}lya-Gamma distributed augmentation variables, we propose an improved version of Thompson Sampling, a Bayesian formulation of contextual bandits with near-optimal performance. Our approach, P\'{o}lya-Gamma augmented Thompson Sampling (PG-TS), achieves state-of-the-art performance on simulated and real data. PG-TS explores the action space efficiently and exploits high-reward arms, quickly converging to solutions of low regret. Its explicit estimation of the posterior distribution of the context feature covariance leads to substantial empirical gains over approximate approaches. PG-TS is the first approach to demonstrate the benefits of P\'{o}lya-Gamma augmentation in bandits and to propose an efficient Gibbs sampler for approximating the analytically unsolvable integral of logistic contextual bandits.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4629–4638},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327372,
author = {Alistarh, Dan and Allen-Zhu, Zeyuan and Li, Jerry},
title = {Byzantine Stochastic Gradient Descent},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper studies the problem of distributed stochastic optimization in an adversarial setting where, out of m machines which allegedly compute stochastic gradients every iteration, an α-fraction are Byzantine, and may behave adversari-ally. Our main result is a variant of stochastic gradient descent (SGD) which finds ε-approximate minimizers of convex functions in T = \~{O}(1/εm + α2/ε2) iterations. In contrast, traditional mini-batch SGD needs T = O(1/ε2m) iterations, but cannot tolerate Byzantine failures. Further, we provide a lower bound showing that, up to logarithmic factors, our algorithm is information-theoretically optimal both in terms of sample complexity and time complexity.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4618–4628},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327371,
author = {Khan, Haidar and Yener, B\"{u}lent},
title = {Learning Filter Widths of Spectral Decompositions with Wavelets},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Time series classification using deep neural networks, such as convolutional neural networks (CNN), operate on the spectral decomposition of the time series computed using a preprocessing step. This step can include a large number of hyperparameters, such as window length, filter widths, and filter shapes, each with a range of possible values that must be chosen using time and data intensive cross-validation procedures. We propose the wavelet deconvolution (WD) layer as an efficient alternative to this preprocessing step that eliminates a significant number of hyperparameters. The WD layer uses wavelet functions with adjustable scale parameters to learn the spectral decomposition directly from the signal. Using backpropagation, we show the scale parameters can be optimized with gradient descent. Furthermore, the WD layer adds interpretability to the learned time series classifier by exploiting the properties of the wavelet transform. In our experiments, we show that the WD layer can automatically extract the frequency content used to generate a dataset. The WD layer combined with a CNN applied to the phone recognition task on the TIMIT database achieves a phone error rate of 18.1%, a relative improvement of 4% over the baseline CNN. Experiments on a dataset where engineered features are not available showed WD+CNN is the best performing method. Our results show that the WD layer can improve neural network based time series classifiers both in accuracy and interpretability by learning directly from the input signal.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4606–4617},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327370,
author = {Yang, Xin and Xu, Ke and Chen, Shaozhe and He, Shengfeng and Yin, Baocai and Lau, Rynson W.H.},
title = {Active Matting},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Image matting is an ill-posed problem. It requires a user input trimap or some strokes to obtain an alpha matte of the foreground object. A fine user input is essential to obtain a good result, which is either time consuming or suitable for experienced users who know where to place the strokes. In this paper, we explore the intrinsic relationship between the user input and the matting algorithm to address the problem of where and when the user should provide the input. Our aim is to discover the most informative sequence of regions for user input in order to produce a good alpha matte with minimum labeling efforts. To this end, we propose an active matting method with recurrent reinforcement learning. The proposed framework involves human in the loop by sequentially detecting informative regions for trivial human judgement. Comparing to traditional matting algorithms, the proposed framework requires much less efforts, and can produce satisfactory results with just 10 regions. Through extensive experiments, we show that the proposed model reduces user efforts significantly and achieves comparable performance to dense trimaps in a user-friendly manner. We further show that the learned informative knowledge can be generalized across different matting algorithms.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4595–4605},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327369,
author = {Pang, Tianyu and Du, Chao and Dong, Yinpeng and Zhu, Jun},
title = {Towards Robust Detection of Adversarial Examples},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Although the recent progress is substantial, deep learning methods can be vulnerable to the maliciously generated adversarial examples. In this paper, we present a novel training procedure and a thresholding test strategy, towards robust detection of adversarial examples. In training, we propose to minimize the reverse cross-entropy (RCE), which encourages a deep network to learn latent representations that better distinguish adversarial examples from normal ones. In testing, we propose to use a thresholding strategy as the detector to filter out adversarial examples for reliable predictions. Our method is simple to implement using standard algorithms, with little extra training cost compared to the common cross-entropy minimization. We apply our method to defend various attacking methods on the widely used MNIST and CIFAR-10 datasets, and achieve significant improvements on robust predictions under all the threat models in the adversarial setting.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4584–4594},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327368,
author = {Yeom, Samuel and Datta, Anupam and Fredrikson, Matt},
title = {Hunting for Discriminatory Proxies in Linear Regression Models},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A machine learning model may exhibit discrimination when used to make decisions involving people. One potential cause for such outcomes is that the model uses a statistical proxy for a protected demographic attribute. In this paper we formulate a definition of proxy use for the setting of linear regression and present algorithms for detecting proxies. Our definition follows recent work on proxies in classification models, and characterizes a model's constituent behavior that: 1) correlates closely with a protected random variable, and 2) is causally influential in the overall behavior of the model. We show that proxies in linear regression models can be efficiently identified by solving a second-order cone program, and further extend this result to account for situations where the use of a certain input variable is justified as a "business necessity". Finally, we present empirical results on two law enforcement datasets that exhibit varying degrees of racial disparity in prediction outcomes, demonstrating that proxies shed useful light on the causes of discriminatory behavior in models.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4573–4583},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327367,
author = {Huang, Wenbing and Zhang, Tong and Rong, Yu and Huang, Junzhou},
title = {Adaptive Sampling towards Fast Graph Representation Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Graph Convolutional Networks (GCNs) have become a crucial tool on learning representations of graph vertices. The main challenge of adapting GCNs on large-scale graphs is the scalability issue that it incurs heavy cost both in computation and memory due to the uncontrollable neighborhood expansion across layers. In this paper, we accelerate the training of GCNs through developing an adaptive layer-wise sampling method. By constructing the network layer by layer in a top-down passway, we sample the lower layer conditioned on the top one, where the sampled neighborhoods are shared by different parent nodes and the over expansion is avoided owing to the fixed-size sampling. More importantly, the proposed sampler is adaptive and applicable for explicit variance reduction, which in turn enhances the training of our method. Furthermore, we propose a novel and economical approach to promote the message passing over distant nodes by applying skip connections. Intensive experiments on several benchmarks verify the effectiveness of our method regarding the classification accuracy while enjoying faster convergence speed.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4563–4572},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327366,
author = {Choi, Edward and Xiao, Cao and Stewart, Walter F. and Sun, Jimeng},
title = {MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep learning models exhibit state-of-the-art performance for many predictive healthcare tasks using electronic health records (EHR) data, but these models typically require training data volume that exceeds the capacity of most healthcare systems. External resources such as medical ontologies are used to bridge the data volume constraint, but this approach is often not directly applicable or useful because of inconsistencies with terminology. To solve the data insufficiency challenge, we leverage the inherent multilevel structure of EHR data and, in particular, the encoded relationships among medical codes. We propose Multilevel Medical Embedding (MiME) which learns the multilevel embedding of EHR data while jointly performing auxiliary prediction tasks that rely on this inherent EHR structure without the need for external labels. We conducted two prediction tasks, heart failure prediction and sequential disease prediction, where MiME outperformed baseline methods in diverse evaluation settings. In particular, MiME consistently outperformed all baselines when predicting heart failure on datasets of different volumes, especially demonstrating the greatest performance improvement (15% relative gain in PR-AUC over the best baseline) on the smallest dataset, demonstrating its ability to effectively model the multilevel structure of EHR data.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4552–4562},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327365,
author = {He, Lie and Bian, An and Jaggi, Martin},
title = {COLA: Decentralized Linear Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Decentralized machine learning is a promising emerging paradigm in view of global challenges of data ownership and privacy. We consider learning of linear classification and regression models, in the setting where the training data is decentralized over many user devices, and the learning algorithm must run on-device, on an arbitrary communication network, without a central coordinator. We propose COLA, a new decentralized training algorithm with strong theoretical guarantees and superior practical performance. Our framework overcomes many limitations of existing methods, and achieves communication efficiency, scalability, elasticity as well as resilience to changes in data and allows for unreliable and heterogeneous participating devices.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4541–4551},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327364,
author = {Yu, Yaodong and Xu, Pan and Gu, Quanquan},
title = {Third-Order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose stochastic optimization algorithms that can find local minima faster than existing algorithms for nonconvex optimization problems, by exploiting the third-order smoothness to escape non-degenerate saddle points more efficiently. More specifically, the proposed algorithm only needs \~{O}(ε-10/3) stochastic gradient evaluations to converge to an approximate local minimum x, which satisfies ||∇f(x)||2 ≤ ε and λmin(∇2 f(x)) ≥ –√ε in unconstrained stochastic optimization, where \~{O}(·) hides logarithm polynomial terms and constants. This improves upon the \~{O}(ε-7/2) gradient complexity achieved by the state-of-the-art stochastic local minima finding algorithms by a factor of \~{O}(ε-1/6). Experiments on two nonconvex optimization problems demonstrate the effectiveness of our algorithm and corroborate our theory.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4530–4540},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327363,
author = {Guo, Wenbo and Huang, Sui and Tao, Yunzhe and Xing, Xinyu and Lin, Lin},
title = {Explaining Deep Learning Models – a Bayesian Non-Parametric Approach},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Understanding and interpreting how machine learning (ML) models make decisions have been a big challenge. While recent research has proposed various technical approaches to provide some clues as to how an ML model makes individual predictions, they cannot provide users with an ability to inspect a model as a complete entity. In this work, we propose a novel technical approach that augments a Bayesian non-parametric regression mixture model with multiple elastic nets. Using the enhanced mixture model, we can extract generalizable insights for a target model through a global approximation. To demonstrate the utility of our approach, we evaluate it on different ML models in the context of image recognition. The empirical results indicate that our proposed approach not only outperforms the state-of-the-art techniques in explaining individual decisions but also provides users with an ability to discover the vulnerabilities of the target ML models.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4519–4529},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327362,
author = {Mendez, Jorge A. and Shivkumar, Shashank and Eaton, Eric},
title = {Lifelong Inverse Reinforcement Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Methods for learning from demonstration (LfD) have shown success in acquiring behavior policies by imitating a user. However, even for a single task, LfD may require numerous demonstrations. For versatile agents that must learn many tasks via demonstration, this process would substantially burden the user if each task were learned in isolation. To address this challenge, we introduce the novel problem of lifelong learning from demonstration, which allows the agent to continually build upon knowledge learned from previously demonstrated tasks to accelerate the learning of new tasks, reducing the amount of demonstrations required. As one solution to this problem, we propose the first lifelong learning approach to inverse reinforcement learning, which learns consecutive tasks via demonstration, continually transferring knowledge between tasks to improve performance.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4507–4518},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327361,
author = {Xue, Yexiang and Yuan, Yang and Xu, Zhitian and Sabharwal, Ashish},
title = {Expanding Holographic Embeddings for Knowledge Completion},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural models operating over structured spaces such as knowledge graphs require a continuous embedding of the discrete elements of this space (such as entities) as well as the relationships between them. Relational embeddings with high expressivity, however, have high model complexity, making them computationally difficult to train. We propose a new family of embeddings for knowledge graphs that interpolate between a method with high model complexity and one, namely Holographic embeddings (HOLE), with low dimensionality and high training efficiency. This interpolation, termed HOLEX, is achieved by concatenating several linearly perturbed copies of original HOLE. We formally characterize the number of perturbed copies needed to provably recover the full entity-entity or entity-relation interaction matrix, leveraging ideas from Haar wavelets and compressed sensing. In practice, using just a handful of Haar-based or random perturbation vectors results in a much stronger knowledge completion system. On the Freebase FB15K dataset, HOLEX outperforms originally reported HOLE by 14.7% on the HITS@10 metric, and the current path-based state-of-the-art method, PTransE, by 4% (absolute).},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4496–4506},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327360,
author = {Jia, Ye and Zhang, Yu and Weiss, Ron J. and Wang, Quan and Shen, Jonathan and Ren, Fei and Chen, Zhifeng and Nguyen, Patrick and Pang, Ruoming and Moreno, Ignacio Lopez and Wu, Yonghui},
title = {Transfer Learning from Speaker Verification to Multispeaker Text-to-Speech Synthesis},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We describe a neural network-based system for text-to-speech (TTS) synthesis that is able to generate speech audio in the voice of different speakers, including those unseen during training. Our system consists of three independently trained components: (1) a speaker encoder network, trained on a speaker verification task using an independent dataset of noisy speech without transcripts from thousands of speakers, to generate a fixed-dimensional embedding vector from only seconds of reference speech from a target speaker; (2) a sequence-to-sequence synthesis network based on Tacotron 2 that generates a mel spectrogram from text, conditioned on the speaker embedding; (3) an auto-regressive WaveNet-based vocoder network that converts the mel spectrogram into time domain waveform samples. We demonstrate that the proposed model is able to transfer the knowledge of speaker variability learned by the discriminatively-trained speaker encoder to the multispeaker TTS task, and is able to synthesize natural speech from speakers unseen during training. We quantify the importance of training the speaker encoder on a large and diverse speaker set in order to obtain the best generalization performance. Finally, we show that randomly sampled speaker embeddings can be used to synthesize speech in the voice of novel speakers dissimilar from those used in training, indicating that the model has learned a high quality speaker representation.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4485–4495},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327359,
author = {Domke, Justin and Sheldon, Daniel},
title = {Importance Weighting and Variational Inference},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recent work used importance sampling ideas for better variational bounds on likelihoods. We clarify the applicability of these ideas to pure probabilistic inference, by showing the resulting Importance Weighted Variational Inference (IWVI) technique is an instance of augmented variational inference, thus identifying the looseness in previous work. Experiments confirm IWVI's practicality for probabilistic inference. As a second contribution, we investigate inference with elliptical distributions, which improves accuracy in low dimensions, and convergence in high dimensions.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4475–4484},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327358,
author = {Mariet, Zelda and Sra, Suvrit and Jegelka, Stefanie},
title = {Exponentiated Strongly Rayleigh Distributions},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Strongly Rayleigh (SR) measures are discrete probability distributions over the subsets of a ground set. They enjoy strong negative dependence properties, as a result of which they assign higher probability to subsets of diverse elements. We introduce in this paper Exponentiated Strongly Rayleigh (ESR) measures, which sharpen (or smoothen) the negative dependence property of SR measures via a single parameter (the exponent) that can be intuitively understood as an inverse temperature. We develop efficient MCMC procedures for approximate sampling from ESRs, and obtain explicit mixing time bounds for two concrete instances: exponentiated versions of Determinantal Point Processes and Dual Volume Sampling. We illustrate some of the potential of ESRs, by applying them to a few machine learning problems; empirical results confirm that beyond their theoretical appeal, ESR-based models hold significant promise for these tasks.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4464–4474},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327357,
author = {Stich, Sebastian U. and Cordonnier, Jean-Baptiste and Jaggi, Martin},
title = {Sparsified SGD with Memory},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Huge scale machine learning problems are nowadays tackled by distributed optimization algorithms, i.e. algorithms that leverage the compute power of many devices for training. The communication overhead is a key bottleneck that hinders perfect scalability. Various recent works proposed to use quantization or sparsification techniques to reduce the amount of data that needs to be communicated, for instance by only sending the most significant entries of the stochastic gradient (top-k sparsification). Whilst such schemes showed very promising performance in practice, they have eluded theoretical analysis so far.In this work we analyze Stochastic Gradient Descent (SGD) with k-sparsification or compression (for instance top-k or random-k) and show that this scheme converges at the same rate as vanilla SGD when equipped with error compensation (keeping track of accumulated errors in memory). That is, communication can be reduced by a factor of the dimension of the problem (sometimes even more) whilst still converging at the same rate. We present numerical experiments to illustrate the theoretical findings and the good scalability for distributed applications.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4452–4463},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327356,
author = {Zhang, Linfeng and Han, Jiequn and Wang, Han and Saidi, Wissam A. and Car, Roberto and Weinan, E.},
title = {End-to-End Symmetry Preserving Inter-Atomic Potential Energy Model for Finite and Extended Systems},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Machine learning models are changing the paradigm of molecular modeling, which is a fundamental tool for material science, chemistry, and computational biology. Of particular interest is the inter-atomic potential energy surface (PES). Here we develop Deep Potential - Smooth Edition (DeepPot-SE), an end-to-end machine learning-based PES model, which is able to efficiently represent the PES of a wide variety of systems with the accuracy of ab initio quantum mechanics models. By construction, DeepPot-SE is extensive and continuously differentiable, scales linearly with system size, and preserves all the natural symmetries of the system. Further, we show that DeepPot-SE describes finite and extended systems including organic molecules, metals, semiconductors, and insulators with high fidelity.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4441–4451},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327355,
author = {Sun, Haitian and Bing, Lidong and Cohen, William W.},
title = {Semi-Supervised Learning with Declaratively Specified Entropy Constraints},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We propose a technique for declaratively specifying strategies for semi-supervised learning (SSL). SSL methods based on different assumptions perform differently on different tasks, which leads to difficulties applying them in practice. In this paper, we propose to use entropy to unify many types of constraints. Our method can be used to easily specify ensembles of semi-supervised learners, as well as agreement constraints and entropic regularization constraints between these learners, and can be used to model both well-known heuristics such as co-training, and novel domain-specific heuristics. Besides, our model is flexible as to the underlying learning mechanism. Compared to prior frameworks for specifying SSL techniques, our technique achieves consistent improvements on a suite of well-studied SSL benchmarks, and obtains a new state-of-the-art result on a difficult relation extraction task.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4430–4440},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327354,
author = {Zhou, Song and Gupta, Swati and Udell, Madeleine},
title = {Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The original simplicial method (OSM), a variant of the classic Kelley's cutting plane method, has been shown to converge to the minimizer of a composite convex and submodular objective, though no rate of convergence for this method was known. Moreover, OSM is required to solve subproblems in each iteration whose size grows linearly in the number of iterations. We propose a limited memory version of Kelley's method (L-KM) and of OSM that requires limited memory (at most n + 1 constraints for an n-dimensional problem) independent of the iteration. We prove convergence for L-KM when the convex part of the objective g is strongly convex and show it converges linearly when g is also smooth. Our analysis relies on duality between minimization of the composite convex and submodular objective and minimization of a convex function over the submodular base polytope. We introduce a limited memory version, L-FCFW, of the Fully-Corrective Frank-Wolfe (FCFW) method with approximate correction, to solve the dual problem. We show that L-FCFW and L-KM are dual algorithms that produce the same sequence of iterates; hence both converge linearly (when g is smooth and strongly convex) and with limited memory. We propose L-KM to minimize composite convex and submodular objectives; however, our results on L-FCFW hold for general polytopes and may be of independent interest.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4419–4429},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327353,
author = {Lee, Kyungjae and Choi, Sungjoon and Oh, Songhwai},
title = {Maximum Causal Tsallis Entropy Imitation Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In this paper, we propose a novel maximum causal Tsallis entropy (MCTE) framework for imitation learning which can efficiently learn a sparse multi-modal policy distribution from demonstrations. We provide the full mathematical analysis of the proposed framework. First, the optimal solution of an MCTE problem is shown to be a sparsemax distribution, whose supporting set can be adjusted. The proposed method has advantages over a softmax distribution in that it can exclude unnecessary actions by assigning zero probability. Second, we prove that an MCTE problem is equivalent to robust Bayes estimation in the sense of the Brier score. Third, we propose a maximum causal Tsallis entropy imitation learning (MCTEIL) algorithm with a sparse mixture density network (sparse MDN) by modeling mixture weights using a sparsemax distribution. In particular, we show that the causal Tsallis entropy of an MDN encourages exploration and efficient mixture utilization while Shannon entropy is less effective.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4408–4418},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327352,
author = {Shu, Rui and Bui, Hung H. and Zhao, Shengjia and Kochenderfer, Mykel J. and Ermon, Stefano},
title = {Amortized Inference Regularization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The variational autoencoder (VAE) is a popular model for density estimation and representation learning. Canonically, the variational principle suggests to prefer an expressive inference model so that the variational approximation is accurate. However, it is often overlooked that an overly-expressive inference model can be detrimental to the test set performance of both the amortized posterior approximator and, more importantly, the generative density estimator. In this paper, we leverage the fact that VAEs rely on amortized inference and propose techniques for amortized inference regularization (AIR) that control the smoothness of the inference model. We demonstrate that, by applying AIR, it is possible to improve VAE generalization on both inference and generative performance. Our paper challenges the belief that amortized inference is simply a mechanism for approximating maximum likelihood training and illustrates that regularization of the amortization family provides a new direction for understanding and improving generalization in VAEs.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4398–4407},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327351,
author = {Chierichetti, Flavio and Dasgupta, Anirban and Haddadan, Shahrzad and Kumar, Ravi and Lattanzi, Silvio},
title = {Mallows Models for Top-<i>k</i> Lists},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The classic Mallows model is a widely-used tool to realize distributions on permutations. Motivated by common practical situations, in this paper, we generalize Mallows to model distributions on top-k lists by using a suitable distance measure between top-k lists. Unlike many earlier works, our model is both analytically tractable and computationally efficient. We demonstrate this by studying two basic problems in this model, namely, sampling and reconstruction, from both algorithmic and experimental points of view.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4387–4397},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327350,
author = {Yang, Lin F. and Arora, Raman and Braverman, Vladimir and Zhao, Tuo},
title = {The Physical Systems behind Optimization Algorithms},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We use differential equations based approaches to provide some physics insights into analyzing the dynamics of popular optimization algorithms in machine learning. In particular, we study gradient descent, proximal gradient descent, coordinate gradient descent, proximal coordinate gradient, and Newton's methods as well as their Nesterov's accelerated variants in a unified framework motivated by a natural connection of optimization algorithms to physical systems. Our analysis is applicable to more general algorithms and optimization problems beyond convexity and strong convexity, e.g. Polyak-undefinedojasiewicz and error bound conditions (possibly nonconvex).},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4377–4386},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327349,
author = {Kawamoto, Tatsuro and Tsubaki, Masashi and Obuchi, Tomoyuki},
title = {Mean-Field Theory of Graph Neural Networks in Graph Partitioning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A theoretical performance analysis of the graph neural network (GNN) is presented. For classification tasks, the neural network approach has the advantage in terms of flexibility that it can be employed in a data-driven manner, whereas Bayesian inference requires the assumption of a specific model. A fundamental question is then whether GNN has a high accuracy in addition to this flexibility. Moreover, whether the achieved performance is predominately a result of the backpropagation or the architecture itself is a matter of considerable interest. To gain a better insight into these questions, a mean-field theory of a minimal GNN architecture is developed for the graph partitioning problem. This demonstrates a good agreement with numerical experiments.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4366–4376},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327348,
author = {Liang, Shiyu and Sun, Ruoyu and Lee, Jason D. and Srikant, R.},
title = {Adding One Neuron Can Eliminate All Bad Local Minima},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {One of the main difficulties in analyzing neural networks is the non-convexity of the loss function which may have many bad local minima. In this paper, we study the landscape of neural networks for binary classification tasks. Under mild assumptions, we prove that after adding one special neuron with a skip connection to the output, or one special neuron per layer, every local minimum is a global minimum.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4355–4365},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327347,
author = {Wang, Yining and Balakrishnan, Sivaraman and Singh, Aarti},
title = {Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the problem of global optimization of an unknown non-convex smooth function with noisy zeroth-order feedback. We propose a local minimax framework to study the fundamental difficulty of optimizing smooth functions with adaptive function evaluations. We show that for functions with fast growth around their global minima, carefully designed optimization algorithms can identify a near global minimizer with many fewer queries than worst-case global minimax theory predicts. For the special case of strongly convex and smooth functions, our implied convergence rates match the ones developed for zeroth-order convex optimization problems. On the other hand, we show that in the worst case no algorithm can converge faster than the minimax rate of estimating an unknown functions in ^-norm. Finally, we show that non-adaptive algorithms, although optimal in a global minimax sense, do not attain the optimal local minimax rate.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4343–4354},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{10.5555/3327345.3327346,
author = {Jiang, Nan and Kulesza, Alex and Singh, Satinder},
title = {Completing State Representations Using Spectral Learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A central problem in dynamical system modeling is state discovery—that is, finding a compact summary of the past that captures the information needed to predict the future. Predictive State Representations (PSRs) enable clever spectral methods for state discovery; however, while consistent in the limit of infinite data, these methods often suffer from poor performance in the low data regime. In this paper we develop a novel algorithm for incorporating domain knowledge, in the form of an imperfect state representation, as side information to speed spectral learning for PSRs. We prove theoretical results characterizing the relevance of a user-provided state representation, and design spectral algorithms that can take advantage of a relevant representation. Our algorithm utilizes principal angles to extract the relevant components of the representation, and is robust to mis-specification. Empirical evaluation on synthetic HMMs, an aircraft identification domain, and a gene splice dataset shows that, even with weak domain knowledge, the algorithm can significantly outperform standard PSR learning.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4333–4342},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@proceedings{10.5555/3327345,
title = {NIPS'18: Proceedings of the 32nd International Conference on Neural Information Processing Systems},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
location = {Montr\'{e}al, Canada}
}

