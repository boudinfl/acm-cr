@inproceedings{10.1145/2750858.2815826,
author = {Kawato, Mitsuo},
title = {Visualizing and Manipulating Brain Dynamics},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2815826},
doi = {10.1145/2750858.2815826},
abstract = {Brain is not a mere input-output information transformation system, but a dynamical system that generates spontaneous spatiotemporal patterns even without sensory inputs, executed movements, or cognitive tasks. These spontaneously generated patterns by brain dynamics are called spontaneous brain activities for experimental animals, and resting state brain activities for humans. The resting state brain activity of an individual contains much information about age, cognitive capability, mental disorder etc. By combining information decoding from brain activity and its neurofeedback in reinforcement learning paradigms, we can unconsciously control brain activity patterns corresponding to specific information. This leads to therapies of psychiatric disorders, unconscious manipulation of facial preferences, color qualia, confidence in decision making, increase of cognitive capability, etc. Ubicomp community can expect this technology will soon be available in much cheaper and lighter devices such as EEG and near infrared spectroscopy instead of heavy and expensive fMRI or MEG.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1},
numpages = {1},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2815827,
author = {Manabe, Daito},
title = {Behind the Scenes},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2815827},
doi = {10.1145/2750858.2815827},
abstract = {Here is the real background to the stage show created by a team of Rhizomatiks Research engineers and director/choreographer MIKIKO of ELEVENPLAY.For the live production of an entertainment show, we can rarely expect favorable conditions in an environment like a museum, cozy hall or a laboratory. Even for a live show that rallies hundreds of thousands of people or a TV program watched by more than a hundred million people, there are barriers different from those found in art and research projects---e.g. there is only one minute available for a conversion process or insufficient time for rehearsals. Therefore, there is still a very limited number of cases in which a risky system is adopted, using real-time image analyses and/or image processing. In most productions, a performer moves, adjusting to the pre-rendered images.The topics to be covered in this lecture include how the producer realizes an ideal world based on such conditions as the size of a venue or the available time for setting up, how to use image recognition, image processing techniques, control techniques, and data analysis techniques at a huge arena for a live performance or on a live broadcast program, while actual software and data used in the production process are introduced.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {2},
numpages = {1},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804264,
author = {Fan, Mingming and Truong, Khai N.},
title = {SoQr: Sonically Quantifying the Content Level inside Containers},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804264},
doi = {10.1145/2750858.2804264},
abstract = {In this paper, we present SoQr, a sensor that can be attached to an external surface of a household item to estimate the amount of content inside it. The sensor consists of a speaker and a microphone. It outputs a short duration sine wave probing sound to excite a container and its content, and then records the container's impulse response. SoQr then extracts Mean Mel-Frequency Cepstral Coefficients from impulse response recordings of a container with different content levels and learns a support vector machine classifier. Results from a 10-fold cross validation of the prediction models on 19 common household items demonstrate that SoQr can correctly estimate the content level for these products with an average overall F-Measure above 0.96. We then further evaluated SoQr's robustness in different usage scenarios to gain an understanding of how the system performs and specific challenges that might arise when users interact with these products and the sensor.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {3–14},
numpages = {12},
keywords = {container, content level measurement, active probing, impulse response},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804271,
author = {Wang, Edward J. and Lee, Tien-Jui and Mariakakis, Alex and Goel, Mayank and Gupta, Sidhant and Patel, Shwetak N.},
title = {MagnifiSense: Inferring Device Interaction Using Wrist-Worn Passive Magneto-Inductive Sensors},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804271},
doi = {10.1145/2750858.2804271},
abstract = {The different electronic devices we use on a daily basis produce distinct electromagnetic radiation due to differences in their underlying electrical components. We present MagnifiSense, a low-power wearable system that uses three passive magneto-inductive sensors and a minimal ADC setup to identify the device a person is operating. MagnifiSense achieves this by analyzing near-field electromagnetic radiation from common components such as the motors, rectifiers, and modulators. We conducted a staged, in-the-wild evaluation where an instrumented participant used a set of devices in a variety of settings in the home such as cooking and outdoors such as commuting in a vehicle. MagnifiSense achieves a classification accuracy of 82.6% using a model-agnostic classifier and 94.0% using a model-specific classifier. In a 24-hour naturalistic deployment, MagnifiSense correctly identified 25 of the total 29 events, while achieving a low false positive rate of 0.65% during 20.5 hours of non-activity.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {15–26},
numpages = {12},
keywords = {magnetic, wearable device, activity recognition, sensor},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804258,
author = {Mokaya, Frank and Lucas, Roland and Noh, Hae Young and Zhang, Pei},
title = {MyoVibe: Vibration Based Wearable Muscle Activation Detection in High Mobility Exercises},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804258},
doi = {10.1145/2750858.2804258},
abstract = {Skeletal muscles are activated to generate the force needed for movement in most high motion sports and exercises. However, incorrect skeletal muscle activation during these sports and exercises, can lead to sub-optimal performance and injury. Existing techniques are susceptible to motion artifacts, particularly when used in high motion sports (e.g. jumping, cycling, etc.). They require limited body movement, or experts to manually interpret results, making them unsuitable in sports scenarios.This paper presents MyoVibe, a wearable system for determining muscle activation in high motion exercise scenarios. MyoVibe senses muscle vibration signals obtained from a wearable network of accelerometers to determine muscle activation. By modeling the characteristics of muscles and high motion noise using extreme value analysis, MyoVibe can reduce noise due to high mobility exercises. Our system can predict muscle activation with greater than 97% accuracy in isometric low motion exercise cases, up to 90% accuracy in high motion exercises.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {27–38},
numpages = {12},
keywords = {MMG, wearable sensing, vibration, muscle activation},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804280,
author = {Rahman, Tauhidur and Adams, Alexander T. and Ravichandran, Ruth Vinisha and Zhang, Mi and Patel, Shwetak N. and Kientz, Julie A. and Choudhury, Tanzeem},
title = {DoppleSleep: A Contactless Unobtrusive Sleep Sensing System Using Short-Range Doppler Radar},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804280},
doi = {10.1145/2750858.2804280},
abstract = {In this paper, we present DoppleSleep -- a contactless sleep sensing system that continuously and unobtrusively tracks sleep quality using commercial off-the-shelf radar modules. DoppleSleep provides a single sensor solution to track sleep-related physical and physiological variables including coarse body movements and subtle and fine-grained chest, heart movements due to breathing and heartbeat. By integrating vital signals and body movement sensing, DoppleSleep achieves 89.6% recall with Sleep vs. Wake classification and 80.2% recall with REM vs. Non-REM classification compared to EEG-based sleep sensing. Lastly, it provides several objective sleep quality measurements including sleep onset latency, number of awakenings, and sleep efficiency. The contactless nature of DoppleSleep obviates the need to instrument the user's body with sensors. Lastly, DoppleSleep is implemented on an ARM microcontroller and a smartphone application that are benchmarked in terms of power and resource usage.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {39–50},
numpages = {12},
keywords = {vital sign monitoring, Doppler radar, algorithm, sleep sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804263,
author = {Ranjan, Juhi and Whitehouse, Kamin},
title = {Object Hallmarks: Identifying Object Users Using Wearable Wrist Sensors},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804263},
doi = {10.1145/2750858.2804263},
abstract = {In order for objects to perform personalized or contextual functions based on identity, they must solve what we call the object user identification problem: understanding who is actually using them. In this paper, we propose a new technique that uses data from wearable wrist sensors to perform object user identification. We hypothesize that objects have unique hallmarks that are imprinted in the hand gestures of its users. By detecting the presence of an object's hallmark in the wrist sensor data, we can identify who used the object. We evaluate this concept with a smart home application: recognizing who is using an object or appliance in a multi-person home by combining smart meter data and wearables. We conduct three different studies with 10 participants: 1) a study with scripted object use 2) a study with high-level tasked activities and unscripted object use, and 3) a 5-day in-situ study. These studies indicate that our approach performs object user identification with an average accuracy of 85--90%.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {51–61},
numpages = {11},
keywords = {wearable devices, smart watch, energy apportionment, object user identification, fitness tracker},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807541,
author = {Ugulino, Wallace and Fuks, Hugo},
title = {Landmark Identification with Wearables for Supporting Spatial Awareness by Blind Persons},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807541},
doi = {10.1145/2750858.2807541},
abstract = {This paper describes our research on feedback mechanisms of wearables for supporting indoor landmark identification in the context of blind pedestrians' mobility. It contributes with a promising alternative to audible patterns, which are consistently related to the 'masking phenomenon'. It also contributes with many lessons and insights that could benefit the designer of wearables for blind users. We started from an observational study followed by co-creation workshops with designers and potential users. The resulting prototypes were used in two Case Studies. The first study investigated the occurrence of 'masking', a problem caused by technology that affects negatively the sensorial perception of the wearer. The second study investigated the usefulness of the wearables for the identification of landmarks. The wearable succeeded in both tests for the particular context in which it was used.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {63–74},
numpages = {12},
keywords = {landmark identification, spatial awareness, blind mobility, wearable computing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807520,
author = {Steil, Julian and Bulling, Andreas},
title = {Discovery of Everyday Human Activities from Long-Term Visual Behaviour Using Topic Models},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807520},
doi = {10.1145/2750858.2807520},
abstract = {Human visual behaviour has significant potential for activity recognition and computational behaviour analysis, but previous works focused on supervised methods and recognition of predefined activity classes based on short-term eye movement recordings. We propose a fully unsupervised method to discover users' everyday activities from their long-term visual behaviour. Our method combines a bag-of-words representation of visual behaviour that encodes saccades, fixations, and blinks with a latent Dirichlet allocation (LDA) topic model. We further propose different methods to encode saccades for their use in the topic model. We evaluate our method on a novel long-term gaze dataset that contains full-day recordings of natural visual behaviour of 10 participants (more than 80 hours in total). We also provide annotations for eight sample activity classes (outdoor, social interaction, focused work, travel, reading, computer work, watching media, eating) and periods with no specific activity. We show the ability of our method to discover these activities with performance competitive with that of previously published supervised methods.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {75–85},
numpages = {11},
keywords = {bag-of-words, eye movement analysis, latent dirichlet allocation (LDA), activity recognition, topic models},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804278,
author = {Kunze, Kai and Masai, Katsutoshi and Inami, Masahiko and Sacakli, \"{O}mer and Liwicki, Marcus and Dengel, Andreas and Ishimaru, Shoya and Kise, Koichi},
title = {Quantifying Reading Habits: Counting How Many Words You Read},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804278},
doi = {10.1145/2750858.2804278},
abstract = {Reading is a very common learning activity, a lot of people perform it everyday even while standing in the subway or waiting in the doctors office. However, we know little about our everyday reading habits, quantifying them enables us to get more insights about better language skills, more effective learning and ultimately critical thinking. This paper presents a first contribution towards establishing a reading log, tracking how much reading you are doing at what time. We present an approach capable of estimating the words read by a user, evaluate it in an user independent approach over 3 experiments with 24 users over 5 different devices (e-ink reader, smartphone, tablet, paper, computer screen). We achieve an error rate as low as 5% (using a medical electrooculography system) or 15% (based on eye movements captured by optical eye tracking) over a total of 30 hours of recording. Our method works for both an optical eye tracking and an Electrooculography system. We provide first indications that the method works also on soon commercially available smart glasses.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {87–96},
numpages = {10},
keywords = {eye movement analysis, mobile eye tracking, electrooculography, quantifying reading, reading behavior},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805826,
author = {Sun, Xiao and Lu, Zongqing and Hu, Wenjie and Cao, Guohong},
title = {SymDetector: Detecting Sound-Related Respiratory Symptoms Using Smartphones},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805826},
doi = {10.1145/2750858.2805826},
abstract = {This paper proposes SymDetector, a smartphone based application to unobtrusively detect the sound-related respiratory symptoms occurred in a user's daily life, including sneeze, cough, sniffle and throat clearing. SymDetector uses the built-in microphone on the smartphone to continuously monitor a user's acoustic data and uses multi-level processes to detect and classify the respiratory symptoms. Several practical issues are considered in developing SymDetector, such as users' privacy concerns about their acoustic data, resource constraints of the smartphone and different contexts of the smartphone. We have implemented SymDetector on Galaxy S3 and evaluated its performance in real experiments involving 16 users and 204 days. The experimental results show that SymDetector can detect these four types of respiratory symptoms with high accuracy under various conditions.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {97–108},
numpages = {12},
keywords = {microphone, feature extraction, smartphone, respiratory symptom detection},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804259,
author = {Korpela, Joseph and Miyaji, Ryosuke and Maekawa, Takuya and Nozaki, Kazunori and Tamagawa, Hiroo},
title = {Evaluating Tooth Brushing Performance with Smartphone Sound Data},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804259},
doi = {10.1145/2750858.2804259},
abstract = {This paper presents a new method for evaluating tooth brushing performance using audio collected from a smartphone. To do this, we use hidden Markov models (HMMs) to recognize audio data that include various types of tooth brushing actions, such as brushing the outer surface of the front teeth and brushing the inner surface of the back teeth. We then use the output of the HMMs to build regression models to estimate tooth brushing performance scores, such as stroke quality of brushing for the back inner teeth and duration of brushing for the front teeth. The scores used to train these regression models are obtained from a dentist who specializes in dental care instruction, with the resulting regression models estimating performance scores that closely correspond to the scores assigned by the dentist.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {109–120},
numpages = {12},
keywords = {tooth brushing, smartphone, healthcare, sound},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804266,
author = {Choe, Eun Kyoung and Lee, Bongshin and Kay, Matthew and Pratt, Wanda and Kientz, Julie A.},
title = {SleepTight: Low-Burden, Self-Monitoring Technology for Capturing and Reflecting on Sleep Behaviors},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804266},
doi = {10.1145/2750858.2804266},
abstract = {Manual tracking of health behaviors affords many benefits, including increased awareness and engagement. However, the capture burden makes long-term manual tracking challenging. In this study on sleep tracking, we examine ways to reduce the capture burden of manual tracking while leveraging its benefits. We report on the design and evaluation of SleepTight, a low-burden, self-monitoring tool that leverages the Android's widgets both to reduce the capture burden and to improve access to information. Through a four-week deployment study (N = 22), we found that participants who used SleepTight with the widgets enabled had a higher sleep diary compliance rate (92%) than participants who used SleepTight without the widgets (73%). In addition, the widgets improved information access and encouraged self-reflection. We discuss how to leverage widgets to help people collect more data and improve access to information, and more broadly, how to design successful manual self-monitoring tools that support self-reflection.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {121–132},
numpages = {12},
keywords = {self-awareness, self-tracking, quantified self, self-reflection, personal informatics, self-monitoring, manual tracking, health, sleep},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804293,
author = {Hao, Tian and Xing, Guoliang and Zhou, Gang},
title = {RunBuddy: A Smartphone System for Running Rhythm Monitoring},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804293},
doi = {10.1145/2750858.2804293},
abstract = {As one of the most popular exercises, running is accomplished through a tight cooperation between the respiratory and locomotor systems. Research has suggested that a proper running rhythm -- the coordination between breathing and strides -- helps improve exercise efficiency and postpone fatigue. This paper presents RunBuddy -- the first smartphone-based system for continuous running rhythm monitoring. RunBuddy is designed to be a convenient and unobtrusive exercise feedback system, and only utilizes commodity devices including smartphone and Bluetooth headset. A key challenge in designing RunBuddy is that the sound of breathing typically has very low intensity and is susceptible to interference. To reliably measure running rhythm, we propose a novel approach that integrates ambient sensing based on accelerometer and microphone, and a physiological model called Locomotor Respiratory Coupling (LRC), which indicates possible ratios between the stride and breathing frequencies. We evaluate RunBuddy through experiments involving 13 subjects and 39 runs. Our results show that, by leveraging the LRC model, RunBuddy correctly measures the running rhythm for indoor/outdoor running 92:7% of the time. Moreover, RunBuddy also provides detailed physiological profile of running that can help users better understand their running process and improve exercise self-efficacy.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {133–144},
numpages = {12},
keywords = {running rhythm, smartphones, exercise monitoring},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804282,
author = {Goel, Mayank and Whitmire, Eric and Mariakakis, Alex and Saponas, T. Scott and Joshi, Neel and Morris, Dan and Guenter, Brian and Gavriliu, Marcel and Borriello, Gaetano and Patel, Shwetak N.},
title = {HyperCam: Hyperspectral Imaging for Ubiquitous Computing Applications},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804282},
doi = {10.1145/2750858.2804282},
abstract = {Emerging uses of imaging technology for consumers cover a wide range of application areas from health to interaction techniques; however, typical cameras primarily transduce light from the visible spectrum into only three overlapping components of the spectrum: red, blue, and green. In contrast, hyperspectral imaging breaks down the electromagnetic spectrum into more narrow components and expands coverage beyond the visible spectrum. While hyperspectral imaging has proven useful as an industrial technology, its use as a sensing approach has been fragmented and largely neglected by the UbiComp community. We explore an approach to make hyperspectral imaging easier and bring it closer to the end-users. HyperCam provides a low-cost implementation of a multispectral camera and a software approach that automatically analyzes the scene and provides a user with an optimal set of images that try to capture the salient information of the scene. We present a number of use-cases that demonstrate HyperCam's usefulness and effectiveness.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {145–156},
numpages = {12},
keywords = {computer vision, multispectral imaging, sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805824,
author = {Shi, Shuyu and Chen, Lin and Hu, Wenjun and Gruteser, Marco},
title = {Reading between Lines: High-Rate, Non-Intrusive Visual Codes within Regular Videos via ImplicitCode},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805824},
doi = {10.1145/2750858.2805824},
abstract = {Given the penetration of mobile devices equipped with cameras, there has been increasing interest in enabling user interaction via visual codes. Simple examples like QR Codes abound. Since many codes like QR Codes are visually intrusive, various mechanisms have been explored to design visual codes that can be hidden inside regular images or videos, though the capacity of these codes remains low to ensure invisibility. We argue, however, that high capacity while maintaining invisibility would enable a vast range of applications that embed rich contextual information in video screens.To this end, we propose ImplicitCode, a high-rate visual codes that can be hidden inside regular videos. Our scheme combines existing techniques to achieve invisibility. However, we show that these techniques, when employed individually, are too constraining to deliver a high capacity. Experiment results show that ImplicitCode can deliver a significant capacity boost over two recent schemes, up to 12x that of HiLight [19] and 6x or 7x that of InFrame [32], while maintaining a similar or better level of invisibility.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {157–168},
numpages = {12},
keywords = {non-intrusive visual codes, screen-camera communication, flicker fusion},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804285,
author = {Karata\c{s}, \c{C}a\u{g}da\c{s} and Gruteser, Marco},
title = {Printing Multi-Key Touch Interfaces},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804285},
doi = {10.1145/2750858.2804285},
abstract = {We present a technique for creating multi-key conductive ink touch user interfaces that can be printed on paper in a single pass. While 3D printing and open-source electronics platforms have led to enormous creativity in creating smart objects, the means for user interaction with such objects are often limited and require remote interaction through a smartphone app. Paper-based touch circuits are a convenient medium for exploring custom touch sensors that can be attached to numerous objects in our environment. The challenge lies in creating a reliable and customizable touch circuit that is easy to produce. Specifically, it should not require assembly of multiple layers and it should support multiple touch points without needing separate connections to a microcontroller for each touch point.We address this through a resistive touch sensor that exploits the inherently high resistance of printed traces to create multiple detectable touch points. The finger closes the circuit when in contact with the touch point and the sensor uses a polarity-switching technique to cancel out the effect of the unknown skin resistance. We evaluated the touch sensor using keypads with 10, 15 and 20 touch points and achieved 99.6%, 93.5%, and 91% touch detection accuracy, respectively. We also observed touch detection rates of up to 154 touches per minute.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {169–179},
numpages = {11},
keywords = {paper keyboard, flexible input interfaces, conductive ink circuits},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804276,
author = {Ta, Tung and Fukumoto, Masaaki and Narumi, Koya and Shino, Shigeki and Kawahara, Yoshihiro and Asami, Tohru},
title = {Interconnection and Double Layer for Flexible Electronic Circuit with Instant Inkjet Circuits},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804276},
doi = {10.1145/2750858.2804276},
abstract = {Instant Inkjet Circuits by silver nano-particle ink realized home-brew electric circuit fabrication. However, current method can support only single-layered patterns, and conventional inter-layer connection methods are not suitable. In this paper, we will evaluate various easy-to-use inter-layer connection methods by making via holes, especially the ones made by different drilling mechanisms. We show that the felting needle is the best candidate as it can establish good conductivity immediately after nano-particle ink is printed into the hole, without using any curing process.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {181–190},
numpages = {10},
keywords = {via hole, instant inkjet circuits, drill/needle, inkjet-printing, conductive ink, double sided circuit},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807531,
author = {Lee, Seokjun and Jung, Wonwoo and Chon, Yohan and Cha, Hojung},
title = {EnTrack: A System Facility for Analyzing Energy Consumption of Android System Services},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807531},
doi = {10.1145/2750858.2807531},
abstract = {Energy accounting is an essential requirement for optimizing energy consumption on mobile devices. State-of-the-art approaches consider application processes and threads as the sole components of energy consumption. In this framework, the energy consumption of system services is unclear and has not been comprehensively studied. In this paper, we suggest that the energy consumption of system services should be investigated to understand the behavior of applications. We propose a fine-grained energy tracing scheme, EnTrack, to enhance the accuracy of energy tracing by identifying and incorporating the energy portions consumed by system services. We implemented EnTrack on the Android platform and validated its functionality and usefulness. In addition, practical usage cases of EnTrack, which uses it as an energy behavior analysis tool, were introduced. The case studies demonstrated that EnTrack enables an understanding of fine-grained energy consumption, especially in system services, which have previously been concealed.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {191–202},
numpages = {12},
keywords = {mobile systems, energy consumption tracing, energy optimization},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2806062,
author = {Chu, David and Zhang, Zengbin and Wolman, Alec and Lane, Nicholas},
title = {Prime: A Framework for Co-Located Multi-Device Apps},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2806062},
doi = {10.1145/2750858.2806062},
abstract = {Even though mobile devices are ubiquitous, the conceptually simple endeavor of using co-located devices for multi-user experiences is cumbersome. It may not even be possible when certain apps are not widely available.We introduce Prime, a thin-client framework for co-located multi-device apps (MDAs). It leverages well-established remote display protocols to enable spontaneous use of MDAs. One device acts as a host, executing the app on behalf of connected clients.The key challenges is dynamic scalability: providing high framerates, low latency and fairness across clients. Therefore, we have developed: an online scheduling algorithm that provides frame rate, latency and fairness guarantees; a modified 802.11 MAC protocol that provides low-latency and fairness; and an efficient video encoder pipeline that offers up to fourteen times higher framerates. We show that Prime can scale a host up to seven concurrent players for a commercially released open source action game, achieving touch-to-pixel latency below 100ms for all clients.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {203–214},
numpages = {12},
keywords = {thin client computing, mobile resource scheduling},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805830,
author = {Huang, Justin and Cakmak, Maya},
title = {Supporting Mental Model Accuracy in Trigger-Action Programming},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805830},
doi = {10.1145/2750858.2805830},
abstract = {Trigger-action programming is a simple programming model that enables users to create rules that automate behavior of smart homes, devices, and online services. Existing trigger-action programming systems, such as if-this-then-that (IFTTT), already have millions of users worldwide; however, their oversimplification limits the expressivity of the programs that can be created. While extensions of IFTTT to allow more complex programs have been proposed, previous work neglects a key distinction between different trigger types (states and events) and action types (instantaneous, extended, and sustained actions). In this paper, we systematically study the impact of these differences through two user studies that reveal: (i) inconsistencies in interpreting the behavior of trigger-action programs and (ii) errors made in creating programs with a desired behavior. Based on a characterization of these issues, we offer recommendations for improving the IFTTT interface so as to mitigate issues that arise from mental model inaccuracies.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {215–225},
numpages = {11},
keywords = {IFTTT, smart homes, trigger-action programming},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804260,
author = {Shen, Haichen and Balasubramanian, Aruna and LaMarca, Anthony and Wetherall, David},
title = {Enhancing Mobile Apps to Use Sensor Hubs without Programmer Effort},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804260},
doi = {10.1145/2750858.2804260},
abstract = {Always-on continuous sensing apps drain the battery quickly because they prevent the main processor from sleeping. Instead, sensor hub hardware, available in many smartphones today, can run continuous sensing at lower power while keeping the main processor idle. However, developers have to divide functionality between the main processor and the sensor hub. We implement MobileHub, a system that automatically rewrites applications to leverage the sensor hub without additional programming effort. MobileHub uses a combination of dynamic taint tracking and machine learning to learn when it is safe to leverage the sensor hub without affecting application semantics. We implement MobileHub in Android and prototype a sensor hub on a 8-bit AVR micro-controller. We experiment with 20 applications from Google Play. Our evaluation shows that MobileHub significantly reduces power consumption for continuous sensing apps.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {227–238},
numpages = {12},
keywords = {sensor hub, machine learning, mobile sensing, dynamic taint tracking, energy-efficiency},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804261,
author = {Rode, Jennifer A. and Weibert, Anne and Marshall, Andrea and Aal, Konstantin and von Rekowski, Thomas and El Mimouni, Houda and Booker, Jennifer},
title = {From Computational Thinking to Computational Making},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804261},
doi = {10.1145/2750858.2804261},
abstract = {Computational thinking is considered best practice for teaching computing and more broadly to solve problems and design systems, however as computing extends beyond the desktop (for instance increased integration of ubicomp technologies) so too must our educational methods. Exposure to ubicomp technologies is most accessible through the maker movement. With this in mind we argue we must move from computational thinking to computational making as an educational framework. Here we present a case study of children's making to support our vision for a broader conception of computational making.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {239–250},
numpages = {12},
keywords = {computational making, maker culture, computational thinking},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804294,
author = {Dong, Tao and Newman, Mark W. and Ackerman, Mark S. and Schoenebeck, Sarita},
title = {Supporting Reflection through Play: Field Testing the Home Trivia System},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804294},
doi = {10.1145/2750858.2804294},
abstract = {In this work, we designed and field-tested a system called Home Trivia to explore how we can use activity traces captured in the home to allow household members to reflect on how they use technology, which has become an issue of increasing concern among families that have seen their home lives intertwined with Internet-enabled devices. Home Trivia captures traces of using technology at home and then shows those traces to family members as content of a puzzle game they can play together. The results of testing Home Trivia in the field show that the design of the game allows engagement and reflection to reinforce each other. Moreover, our work enriches and further develops the idea of using ambiguity as a resource for design with the insight that allowing users to reduce ambiguity through recollecting past events and communicating with others can help trigger reflection.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {251–262},
numpages = {12},
keywords = {games, activity traces, family, domestic sensing, home, reflection},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807529,
author = {Gallacher, Sarah and Golsteijn, Connie and Wall, Lorna and Koeman, Lisa and Andberg, Sami and Capra, Licia and Rogers, Yvonne},
title = {Getting Quizzical about Physical: Observing Experiences with a Tangible Questionnaire},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807529},
doi = {10.1145/2750858.2807529},
abstract = {Organizers regularly want to understand the experiences of event goers and typically use survey methods, with researchers and clipboards. However, gathering opinions in such ways is difficult to do without disrupting the event goers' experience. In place of clipboard surveys, we developed a quite different form of tangible questionnaire, called VoxBox, which uses physical interactions to transform feedback giving into a playful and engaging experience that fits much more with the event itself. Here we question if such a device can successfully draw a diverse representation of event attendees to voice relevant opinions during the event. We describe an observational study of VoxBox based on two real-world deployments, and present findings on (1) the experiences VoxBox provides to facilitators and users; and (2) its capabilities as a means for opinion gathering. We conclude by discussing lessons learned, design implications, and the wide potential for tangible questionnaires in other application areas.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {263–273},
numpages = {11},
keywords = {in the wild, questionnaires, tangible interaction, crowd engagement, internet of things, public opinion, playful},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805851,
author = {Ugur, Muhsin and Shastri, Dvijesh and Tsiamyrtzis, Panagiotis and Dcosta, Malcolm and Kalpakci, Allison and Sharp, Carla and Pavlidis, Ioannis},
title = {Evaluating Smartphone-Based User Interface Designs for a 2D Psychological Questionnaire},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805851},
doi = {10.1145/2750858.2805851},
abstract = {This study explored various user interface designs to transition a two dimensional (2D) questionnaire from its paper-and-pencil testing format to the mobile platform. The current administration of the test limits its usage beyond the lab environment. Creating a mobile version would facilitate ubiquitous administration of the test. Yet, the mobile design must be at least as good as its paper-based counterpart in terms of input accuracy and user interaction efforts. We developed four user interface designs, each of which featured a specific interaction approach. These approaches included displaying the 2D space of the questionnaire in its original form (M1), inputting one variable at a time on the 2D space (M2), dissolving the 2D space into two one-dimensional ordinal scales (M3), and orienting the input selections to the diagonal axes (M4). The designs were tested by a total of 34 participants, aged 18 to 52 years. The study results find the first three interaction approaches (M1-M3) effective but the fourth approach inefficient. Furthermore, the results indicate that the two-tap designs (M2 and M3) are equally as good as the one-tap design (M1).},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {275–282},
numpages = {8},
keywords = {2D questionnaires, online questionnaires, user interface design, mobile devices, mobile health care},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804262,
author = {Lane, Nicholas D. and Georgiev, Petko and Qendro, Lorena},
title = {DeepEar: Robust Smartphone Audio Sensing in Unconstrained Acoustic Environments Using Deep Learning},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804262},
doi = {10.1145/2750858.2804262},
abstract = {Microphones are remarkably powerful sensors of human behavior and context. However, audio sensing is highly susceptible to wild fluctuations in accuracy when used in diverse acoustic environments (such as, bedrooms, vehicles, or cafes), that users encounter on a daily basis. Towards addressing this challenge, we turn to the field of deep learning; an area of machine learning that has radically changed related audio modeling domains like speech recognition. In this paper, we present DeepEar -- the first mobile audio sensing framework built from coupled Deep Neural Networks (DNNs) that simultaneously perform common audio sensing tasks. We train DeepEar with a large-scale dataset including unlabeled data from 168 place visits. The resulting learned model, involving 2.3M parameters, enables DeepEar to significantly increase inference robustness to background noise beyond conventional approaches present in mobile devices. Finally, we show DeepEar is feasible for smartphones by building a cloud-free DSP-based prototype that runs continuously, using only 6% of the smartphone's battery daily.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {283–294},
numpages = {12},
keywords = {audio sensing, mobile sensing, deep learning},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804251,
author = {Wang, Rui and Harari, Gabriella and Hao, Peilin and Zhou, Xia and Campbell, Andrew T.},
title = {SmartGPA: How Smartphones Can Assess and Predict Academic Performance of College Students},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804251},
doi = {10.1145/2750858.2804251},
abstract = {Many cognitive, behavioral, and environmental factors impact student learning during college. The SmartGPA study uses passive sensing data and self-reports from students' smartphones to understand individual behavioral differences between high and low performers during a single 10-week term. We propose new methods for better understanding study (e.g., study duration) and social (e.g., partying) behavior of a group of undergraduates. We show that there are a number of important behavioral factors automatically inferred from smartphones that significantly correlate with term and cumulative GPA, including time series analysis of activity, conversational interaction, mobility, class attendance, studying, and partying. We propose a simple model based on linear regression with lasso regularization that can accurately predict cumulative GPA. The predicted GPA strongly correlates with the ground truth from students' transcripts (r = 0:81 and p &lt; 0:001) and predicts GPA within ±0:179 of the reported grades. Our results open the way for novel interventions to improve academic performance.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {295–306},
numpages = {12},
keywords = {data analysis, academic performance, behavioral trends, smartphone sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807540,
author = {Xu, Qiang and Zheng, Rong and Hranilovic, Steve},
title = {IDyLL: Indoor Localization Using Inertial and Light Sensors on Smartphones},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807540},
doi = {10.1145/2750858.2807540},
abstract = {Location-based services have experienced substantial growth in the last decade. However, despite extensive research efforts, sub-meter location accuracy with low-cost infrastructure continues to be elusive. In this paper, we propose IDyLL -- an indoor localization system using inertial measurement units (IMU) and photodiode sensors on smartphones. Using a novel illumination peak detection algorithm, IDyLL augments IMU-based pedestrian dead reckoning with location fixes. We devise a robust particle filter framework to mitigate identity ambiguity due to the lack of communication capability of conventional luminaries and sensing errors. Experimental study using data collected from smartphones shows that IDyLL is able to achieve high localization accuracy at low costs. Mean location errors of 0.38 m, 0.42 m, and 0.74 m are reported from multiple walks in three buildings with different luminary arrangements, respectively.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {307–318},
numpages = {12},
keywords = {peak detection, particle filter, indoor localization, conventional luminary},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804257,
author = {Wu, Muchen and Pathak, Parth H. and Mohapatra, Prasant},
title = {Monitoring Building Door Events Using Barometer Sensor in Smartphones},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804257},
doi = {10.1145/2750858.2804257},
abstract = {Building security systems are commonly deployed to detect intrusion and burglary in home and business structures. Such systems can accurately detect door open/close events, but their high-cost of installation and maintenance makes them unsuitable for certain building monitoring applications, such as times of high/low entrance traffic, estimating building occupancy, etc. In this paper, we show that barometer sensors found in latest smartphones can directly detect the building door open/close events anywhere inside an insulated building. The sudden pressure change observed by barometers is sufficient to detect events even in presence of user mobility (e.g. climbing stairs). We study various characteristics of the pressure variation due to door events, and demonstrate that door open/close events can be recognized with an accuracy range of 99.34% -- 99.81% based on the data collected from 3 different buildings. Such a low-cost ubiquitous solution of door event detection enables many monitoring applications without any infrastructure integration, and it can also work as an augmentation to the existing expensive security systems.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {319–323},
numpages = {5},
keywords = {mobile computing, building monitoring, barometer},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807536,
author = {Thompson, Robin and Kyriazakis, Ilias and Holden, Amey and Olivier, Patrick and Pl\"{o}tz, Thomas},
title = {Dancing with Horses: Automated Quality Feedback for Dressage Riders},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807536},
doi = {10.1145/2750858.2807536},
abstract = {The sport of dressage has become very popular not only amongst professional athletes but increasingly also for private horse owners. In well-defined tests, rider and horse execute movements, which demonstrate the strength, endurance, and dexterity of the animal as well as the quality of the interaction between rider and horse. Whilst at a professional level intensive expert coaching to refine the skill set of horse and rider is standard, such an approach to progression is not usually viable for the large amateur population. In this paper we present a framework for automated generation of quality feedback in dressage tests. Using on-body sensing and automated measurement of key performance attributes we are able to monitor the quality of horse movements in an objective way. We validated the developed framework in a large-scale deployment study and report on the practical usefulness of automatically generated quality feedback in amateur dressage.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {325–336},
numpages = {12},
keywords = {horses, skill assessment, activity recognition, dressage, wearable sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805849,
author = {Robinson, Charlotte and Mancini, Clara and van der Linden, Janet and Guest, Claire and Swanson, Lydia and Marsden, Helen and Valencia, Jose and Aengenheister, Brendan},
title = {Designing an Emergency Communication System for Human and Assistance Dog Partnerships},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805849},
doi = {10.1145/2750858.2805849},
abstract = {In this research we developed an alarm system that enables assistance dogs to call for help on behalf of their vulnerable owners in an emergency, involving the end users (both assistance dogs and their owners) directly in the entire design process. Here we present a high-fidelity prototype of a user-friendly canine alarm system. In developing the system, we sought to understand the level of support required for a canine user to successfully interact with an interface, finding that the type of emergency a dog is faced with may vary widely and that consequently dogs may have to act on behalf of their assisted owners with varying degrees of autonomy. We also explored the process of conducting usability testing with both canine and human participants, seeking to identify where requirements of one species may overlap with, or diverge from, the other.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {337–347},
numpages = {11},
keywords = {user-centred design, animal-computer interaction, assistive technologies, assistance dogs, canine design},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805825,
author = {Nowacka, Diana and Hammerla, Nils Y. and Elsden, Chris and Pl\"{o}tz, Thomas and Kirk, David},
title = {Diri - the Actuated Helium Balloon: A Study of Autonomous Behaviour in Interfaces},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805825},
doi = {10.1145/2750858.2805825},
abstract = {Research on actuated interfaces has shown that people respond in certain socialized ways to interfaces that exhibit autonomous behaviours. We wished to explore the elements of design that drive people to regard an autonomous, interactive system as a social agent. To explore perceptions of autonomous behaviour in interfaces we created Diri - an autonomous helium balloon, used to document activity in spaces. We implemented two different technological sophistications of Diri, to compare the outcomes of our design decisions. We present our design process, technical details and evaluation workshops, concluding with implications for designing for autonomous behaviour in interfaces.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {349–360},
numpages = {12},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805823,
author = {Cauchard, Jessica R. and E, Jane L. and Zhai, Kevin Y. and Landay, James A.},
title = {Drone &amp; Me: An Exploration into Natural Human-Drone Interaction},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805823},
doi = {10.1145/2750858.2805823},
abstract = {Personal drones are becoming popular. It is challenging to design how to interact with these flying robots. We present a Wizard-of-Oz (WoZ) elicitation study that informs how to naturally interact with drones. Results show strong agreement between participants for many interaction techniques, as when gesturing for the drone to stop. We discovered that people interact with drones as with a person or a pet, using interpersonal gestures, such as beckoning the drone closer. We detail the interaction metaphors observed and offer design insights for human-drone interactions.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {361–365},
numpages = {5},
keywords = {elicitation study, UAV, drone, quadcopter, Wizard-of-Oz},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804253,
author = {Novak, Ed and Tang, Yutao and Hao, Zijiang and Li, Qun and Zhang, Yifan},
title = {Physical Media Covert Channels on Smart Mobile Devices},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804253},
doi = {10.1145/2750858.2804253},
abstract = {In recent years mobile smart devices such as tablets and smartphones have exploded in popularity. We are now in a world of ubiquitous smart devices that people rely on daily and carry everywhere. This is a fundamental shift for computing in two ways. Firstly, users increasingly place unprecedented amounts of sensitive information on these devices, which paints a precarious picture. Secondly, these devices commonly carry many physical world interfaces. In this paper, we propose information leakage malware, specifically designed for mobile devices, which uses covert channels over physical "real-world" media, such as sound or light. This malware is stealthy; able to circumvent current, and even state-of-the-art defenses to enable attacks including privilege escalation, and information leakage. We go on to present a defense mechanism, which balances security with usability to stop these attacks.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {367–378},
numpages = {12},
keywords = {covert channel, sensors, security, privacy, physical media, smart mobile device},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804279,
author = {Hayashi, Eiji and Hong, Jason I.},
title = {Knock x Knock: The Design and Evaluation of a Unified Authentication Management System},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804279},
doi = {10.1145/2750858.2804279},
abstract = {We introduce UniAuth, a set of mechanisms for streamlining authentication to devices and web services. With UniAuth, a user first authenticates himself to his UniAuth client, typically his smartphone or wearable device. His client can then authenticate to other services on his behalf. In this paper, we focus on exploring the user experiences with an early iPhone prototype called Knock x Knock. To manage a variety of accounts securely in a usable way, Knock x Knock incorporates features not supported in existing password managers, such as tiered and location-aware lock control, authentication to laptops via knocking, and storing credentials locally while working with laptops seamlessly. In two field studies, 19 participants used Knock x Knock for one to three weeks with their own devices and accounts. Our participants were highly positive about Knock x Knock, demonstrating the desirability of our approach. We also discuss interesting edge cases and design implications.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {379–389},
numpages = {11},
keywords = {authentication, usable security, password},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807521,
author = {Ahmed, Imtiaj and Ye, Yina and Bhattacharya, Sourav and Asokan, N. and Jacucci, Giulio and Nurmi, Petteri and Tarkoma, Sasu},
title = {Checksum Gestures: Continuous Gestures as an out-of-Band Channel for Secure Pairing},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807521},
doi = {10.1145/2750858.2807521},
abstract = {We propose the use of a single continuous gesture as a novel, intuitive, and efficient mechanism to authenticate a secure communication channel. Our approach builds on a novel algorithm for encoding (at least 20-bits) authentication information as a single continuous gesture, referred to as a checksum gesture. By asking the user to perform the generated gesture, a secure channel can be authenticated. Results from a controlled user experiment (N = 13 participants, 1022 trials) demonstrate the feasibility of our technique, showing over 90% success rate in establishing a secure communication channel despite relying on complex gesture patterns. The authentication times of our method are over three-folds faster than with previous gesture-based solutions. The average execution time of a gesture is 5:7 seconds in our study, which is comparable to the input time of conventional text input based PIN authentication. Our approach is particularly well-suited for scenarios involving wearable devices that lack conventional input capabilities, e.g., pairing a smartwatch with an interactive display.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {391–401},
numpages = {11},
keywords = {usable security, device association, authentication, gesture encoding, gesture interaction},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804270,
author = {Pohl, Henning and Krause, Markus and Rohs, Michael},
title = {One-Button Recognizer: Exploiting Button Pressing Behavior for User Differentiation},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804270},
doi = {10.1145/2750858.2804270},
abstract = {We present a novel way to recognize users by the way they press a button. Our approach allows low-effort and fast interaction without the need for augmenting the user or controlling the environment. It eschews privacy concerns of methods such as fingerprint scanning. Button pressing behavior is sufficiently discriminative to allow distinguishing users within small groups. This approach combines recognition and action in a single step, e.g., getting and tallying a coffee can be done with one button press. We deployed our system for 5 users over a period of 4 weeks and achieved recognition rates of 95% in the last week. We also ran a larger scale but short-term evaluation to investigate effects of group size and found that our method degrades gracefully for larger groups.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {403–407},
numpages = {5},
keywords = {adaptive user interfaces, user recognition, context recognition, lightweight interaction, physical interaction, sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807515,
author = {Li, Tianxing and An, Chuankai and Chandra, Ranveer and Campbell, Andrew T. and Zhou, Xia},
title = {Low-Power Pervasive Wi-Fi Connectivity Using WiScan},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807515},
doi = {10.1145/2750858.2807515},
abstract = {Pervasive Wi-Fi connectivity is attractive for users in places not covered by cellular services (e.g., when traveling abroad). However, the power drain of frequent Wi-Fi scans undermines the device's battery life, preventing users from staying always connected and fetching synced emails and instant message notifications (e.g., WhatsApp). We study the energy overhead of scan and roaming in detail and refer to it as the scan tax problem. Our findings show that the main processor is the primary culprit of the energy overhead. We propose a simple and effective architectural change of offloading scans to the Wi-Fi radio. We design and build WiScan to fully exploit the gain of scan offloading. Our experiments demonstrate that WiScan achieves 90%+ of the maximal connectivity, while saving 50-62% energy for seeking connectivity.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {409–420},
numpages = {12},
keywords = {wi-fi scans, wi-fi connectivity, energy efficiency},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807553,
author = {Min, Chulhong and Yoo, Chungkuk and Hwang, Inseok and Kang, Seungwoo and Lee, Youngki and Lee, Seungchul and Park, Pillsoon and Lee, Changhun and Choi, Seungpyo and Song, Junehwa},
title = {Sandra Helps You Learn: The More You Walk, the More Battery Your Phone Drains},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807553},
doi = {10.1145/2750858.2807553},
abstract = {Emerging continuous sensing apps introduce new major factors governing phones' overall battery consumption behaviors: (1) added nontrivial persistent battery drain, and more importantly (2) different battery drain rate depending on the user's different mobility condition. In this paper, we address the new battery impacting factors significant enough to outdate users' existing battery model in real life. We explore an initial approach to help users understand the cause and effect between their physical activity and phones' battery life. To this end, we present Sandra, a novel mobility-aware smartphone battery information advisor, and study its potential to help users redevelop their battery model. We perform an extensive explorative study and deployment for 30 days with 24 users. Our findings reveal what they essentially learned, and in which situations they found Sandra very helpful. We share the lessons learned to help in the design of future mobility-aware battery advisors.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {421–432},
numpages = {12},
keywords = {battery, smartphone, user perception, continuous sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804287,
author = {Hu, Shaohan and Su, Lu and Li, Shen and Wang, Shiguang and Pan, Chenji and Gu, Siyu and Al Amin, Md Tanvir and Liu, Hengchang and Nath, Suman and Choudhury, Romit Roy and Abdelzaher, Tarek F.},
title = {Experiences with ENav: A Low-Power Vehicular Navigation System},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804287},
doi = {10.1145/2750858.2804287},
abstract = {This paper presents experiences with eNav, a smartphone-based vehicular GPS navigation system that has an energy-saving location sensing mode capable of drastically reducing navigation energy needs. Traditional navigation systems sample the phone's GPS at a fixed rate (usually around 1Hz), regardless of factors such as current vehicle speed and distance from the next navigation waypoint. This practice results in a large energy consumption and unnecessarily reduces the attainable length of a navigation session, if the phone is left unplugged. The paper investigates two questions. First, would drivers be willing to sacrifice some of the affordances of modern navigation systems in order to prolong battery life? Second, how much energy could be saved using straightforward alternative localization mechanisms, applied to complement GPS for vehicular navigation? According to a survey we conducted of 500 drivers, as much as 91% of drivers said they would like to have a vehicular navigation application with an energy saving mode. To meet this need, eNav exploits on-board accelerometers for approximate location sensing when the vehicle is sufficiently far from the next navigation waypoint (or is stopped). A user test-study of eNav shows that it results in roughly the same user experience as standard GPS navigation systems, while reducing navigation energy consumption by almost 80%. We conclude that drivers find an energy-saving mode on phone-based vehicular navigation applications desirable, even at the expense of some loss of functionality, and that significant savings can be achieved using straightforward location sensing mechanisms that avoid frequent GPS sampling.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {433–444},
numpages = {12},
keywords = {smartphone, dead-reckoning, low-power, GPS, navigation},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805846,
author = {Naderiparizi, Saman and Zhao, Yi and Youngquist, James and Sample, Alanson P. and Smith, Joshua R.},
title = {Self-Localizing Battery-Free Cameras},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805846},
doi = {10.1145/2750858.2805846},
abstract = {RFID sensor networks perpetually stream sensor data without batteries. Cameras are power hungry but provide richer information than conventional sensor network nodes. Battery-free, RF-powered camera sensor nodes combine many of the attractive features of RFID sensor networks with those of cameras. However, prior battery-free cameras have no notion of 3D location, which is desirable for creating large scale networks of battery free cameras.In this work we propose using battery-free RFID sensor tags enhanced with on-board cameras to enable a network of distributed tags to optically determine the 3D location and pose of each camera tag given known reference tags enhanced with LEDs. Experimental results show that the camera tags are capable of determining their position with an average accuracy of [x, y, z] = [15:92cm, 4:39cm, 1:03cm] at an LEDs-to-Camera range within 3.6m.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {445–449},
numpages = {5},
keywords = {sensor networks, camera, RFID, self-localization, battery-free},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807519,
author = {Beattie, David and Baillie, Lynne and Halvey, Martin},
title = {A Comparison of Artificial Driving Sounds for Automated Vehicles},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807519},
doi = {10.1145/2750858.2807519},
abstract = {As automated vehicles currently do not provide sufficient feedback relating to the primary driving task, drivers have no assurance that an automated vehicle has understood and can cope with upcoming traffic situations [16]. To address this we conducted two user evaluations to investigate auditory displays in automated vehicles using different types of sound cues related to the primary driving sounds: acceleration, deceleration/braking, gear changing and indicating. Our first study compared earcons, speech and auditory icons with existing vehicle sounds. Our findings suggested that earcons were an effective alternative to existing vehicle sounds for presenting information related to the primary driving task. Based on these findings a second study was conducted to further investigate earcons modulated by different sonic parameters to present primary driving sounds. We discovered that earcons containing naturally mapped sonic parameters such as pitch and timbre were as effective as existing sounds in a simulated automated vehicle.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {451–462},
numpages = {12},
keywords = {auditory icons, earcons, driving simulator, auditory displays, speech, automated vehicles},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804249,
author = {Wyche, Susan and Dillahunt, Tawanna R. and Simiyu, Nightingale and Alaka, Sharon},
title = {"If God Gives Me the Chance i Will Design My Own Phone": Exploring Mobile Phone Repair and Postcolonial Approaches to Design in Rural Kenya},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804249},
doi = {10.1145/2750858.2804249},
abstract = {This article focuses on "fundi wa simu," (mobile phone repairers) in rural Kenya and their ideas about mobile phone design. Our study design and analysis were guided by ideas from postcolonial computing; we use our qualitative findings, and outcomes from a drawing exercise, to show existing flaws in mobile phone design, and to explore how repairers' knowledge can lead to handsets that are better suited for rural Kenyans. Our argument is that, by engaging with repairers "[on] their own terms," technologists can expand conversations around designing for the 'developing' world that go beyond building novel smartphone applications. In fact, such conversations can also include reimagining mobile phones, and supporting local repairers' efforts to manufacture them. We conclude by discussing ways to improve upon postcolonial approaches to technology design.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {463–473},
numpages = {11},
keywords = {mobile phones, design, repair, Kenya, HCI, ICTD, postcolonial computing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807517,
author = {Okoshi, Tadashi and Ramos, Julian and Nozaki, Hiroki and Nakazawa, Jin and Dey, Anind K. and Tokuda, Hideyuki},
title = {Reducing Users' Perceived Mental Effort Due to Interruptive Notifications in Multi-Device Mobile Environments},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807517},
doi = {10.1145/2750858.2807517},
abstract = {In today's ubiquitous computing environment where users carry, manipulate, and interact with an increasing number of networked devices, applications and web services, human attention is the new bottleneck in computing. It is therefore important to minimize a user's mental effort due to notifications, especially in situations where users are mobile and using multiple wearable and mobile devices. To this end, we propose Attelia II, a novel middleware that identifies breakpoints in users' lives while using those devices, and delivers notifications at these moments. Attelia II works in real-time and uses only the mobile and wearable devices that users naturally use and wear, without any modifications to applications, and without any dedicated psycho-physiological sensors. Our in-the-wild evaluation in users' multi-device environment (smart phones and smart watches) with 41 participants for 1 month validated the effectiveness of Attelia. Our new physical activity-based breakpoint detection, in addition to the UI Event-based breakpoint detection, resulted in a 71.8% greater reduction of users' perception of workload, compared with our previous system that used UI events only. Adding this functionality to a smart watch reduced workload perception by 19.4% compared to random timing of notification deliveries. Our multi-device breakpoint detection across smart phones and watches resulted in about 3 times greater reduction in workload perception than our previous system.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {475–486},
numpages = {12},
keywords = {interruptibility, interruption overload, mobile sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805850,
author = {Agrawal, Harshit and Leigh, Sang-won and Maes, Pattie},
title = {L'evolved: Autonomous and Ubiquitous Utilities as Smart Agents},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805850},
doi = {10.1145/2750858.2805850},
abstract = {Ubiquitous computing has been focusing on creating smart agents that are submerged into everyday environments, however, recent development on physical computing is demanding a shift from calm computing to a physically engaging form. Computing is no more limited to increasing our comfort through passive and pervasive deployment, they can now be created as being more actively and physically intermeshed into our tasks. We present L'evolved, autonomous ubiquitous utilities that assist in user tasks through active physical participation. They not only dynamically adapt to individual user needs and actions, but also work in close tandem with the users. Among explorations on potential applications, we harness drone technology to realize the design and implementation of example utilities that afford free motions and computational controls. Through various use scenarios of those exemplary utilities, we show how this new form of smart agents promises new ways of interacting with our physical environments. We also discuss design implications and technical details of our implementations.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {487–491},
numpages = {5},
keywords = {ubiquitous computing, actuated environments, actuated furniture},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807526,
author = {Hovsepian, Karen and al'Absi, Mustafa and Ertin, Emre and Kamarck, Thomas and Nakajima, Motohiro and Kumar, Santosh},
title = {CStress: Towards a Gold Standard for Continuous Stress Assessment in the Mobile Environment},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807526},
doi = {10.1145/2750858.2807526},
abstract = {Recent advances in mobile health have produced several new models for inferring stress from wearable sensors. But, the lack of a gold standard is a major hurdle in making clinical use of continuous stress measurements derived from wearable sensors. In this paper, we present a stress model (called cStress) that has been carefully developed with attention to every step of computational modeling including data collection, screening, cleaning, filtering, feature computation, normalization, and model training. More importantly, cStress was trained using data collected from a rigorous lab study with 21 participants and validated on two independently collected data sets --- in a lab study on 26 participants and in a week-long field study with 20 participants. In testing, the model obtains a recall of 89% and a false positive rate of 5% on lab data. On field data, the model is able to predict each instantaneous self-report with an accuracy of 72%.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {493–504},
numpages = {12},
keywords = {wearable sensors, mobile health (mHealth), modeling, stress},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807537,
author = {Sharmin, Moushumi and Raij, Andrew and Epstien, David and Nahum-Shani, Inbal and Beck, J. Gayle and Vhaduri, Sudip and Preston, Kenzie and Kumar, Santosh},
title = {Visualization of Time-Series Sensor Data to Inform the Design of Just-in-Time Adaptive Stress Interventions},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807537},
doi = {10.1145/2750858.2807537},
abstract = {We investigate needs, challenges, and opportunities in visualizing time-series sensor data on stress to inform the design of just-in-time adaptive interventions (JITAIs). We identify seven key challenges: massive volume and variety of data, complexity in identifying stressors, scalability of space, multifaceted relationship between stress and time, a need for representation at multiple granularities, inter-person variability, and limited understanding of JITAI design requirements due to its novelty. We propose four new visualizations based on one million minutes of sensor data (n=70). We evaluate our visualizations with stress researchers (n=6) to gain first insights into its usability and usefulness in JITAI design. Our results indicate that spatio-temporal visualizations help identify and explain between- and within-person variability in stress patterns and contextual visualizations enable decisions regarding the timing, content, and modality of intervention. Interestingly, a granular representation is considered informative but noise-prone; an abstract representation is the preferred starting point for designing JITAIs.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {505–516},
numpages = {12},
keywords = {visualization, stress, just-in-time adaptive interventions (JITAIs), stress management},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805847,
author = {Taylor, Brandon and Dey, Anind and Siewiorek, Daniel and Smailagic, Asim},
title = {Using Physiological Sensors to Detect Levels of User Frustration Induced by System Delays},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805847},
doi = {10.1145/2750858.2805847},
abstract = {In mobile computing, varying access to resources makes it difficult for developers to ensure that satisfactory system response times will be maintained at all times. Wearable physiological sensors offer a way to dynamically detect user frustration in response to increased system delays. However, most prior efforts have focused on binary classifiers designed to detect the presence or absence of a task-specific stimulus. In this paper, we make two contributions. Our first contribution is in identifying the use of variable length system response delays, a universal and task-independent feature of computing, as a stimulus for driving different levels of frustration. By doing so, we are able to make our second and primary contribution, which is the development of models that predict multiple levels of user frustration from psycho-physiological responses caused by system response delays. We investigate how incorporating different sensor features, application settings, and timing constraints impact the performance of our models. We demonstrate that our models of physiological responses can be used to classify five levels of frustration in near real-time with over 80% accuracy, which is comparable to the accuracy of binary classifiers.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {517–528},
numpages = {12},
keywords = {system response delays, emotion recognition, sensors},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805834,
author = {Rubin, Jonathan and Eldardiry, Hoda and Abreu, Rui and Ahern, Shane and Du, Honglu and Pattekar, Ashish and Bobrow, Daniel G.},
title = {Towards a Mobile and Wearable System for Predicting Panic Attacks},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805834},
doi = {10.1145/2750858.2805834},
abstract = {In this paper, we present first steps towards a mobile and wearable system intended to help people who experience regular and spontaneous panic attacks due to panic disorder. The goal of the system is to predict oncoming panic attacks and to deliver in-the-moment interventions on a smartphone device. Interventions are intended to reduce symptom severity by enabling a user to respond to approaching panic episodes. An initial feasibility study is described where a small real-world data set was collected. Personalized prediction models were trained which take, as input, physiological data and output a binary classification of either pre-panic or non-panic. We demonstrate proof-of-concept of episode prediction on this small dataset.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {529–533},
numpages = {5},
keywords = {physiological monitoring, mHealth, affective computing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807527,
author = {Shimosaka, Masamichi and Maeda, Keisuke and Tsukiji, Takeshi and Tsubouchi, Kota},
title = {Forecasting Urban Dynamics with Mobility Logs by Bilinear Poisson Regression},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807527},
doi = {10.1145/2750858.2807527},
abstract = {Understanding people flow in a city (urban dynamics) is of great importance in urban planning, emergency management, and commercial activity. With the spread of smart devices, many studies on urban dynamics modeling with mobility logs have been conducted. It is predictive analysis, not analysis of the past, that enables various applications contributing to a more prosperous society. To deal with the non-linear effects on urban dynamics from external factors, such as day of the week, national holiday, or weather, we propose a low-rank bilinear Poisson regression model, for a novel and flexible representation of urban dynamics predictive analysis. The results obtained from an experiment with one year's worth of mobility records suggest the high prediction accuracy of the proposed model. We also introduce the following applications: regional event detection via irregularities, visualization of urban dynamics corresponding to urban demographics, and extraction of urban demographics of unknown point of interests.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {535–546},
numpages = {12},
keywords = {matrix factorization, Poisson regression, multi-task learning, bilinear model, urban dynamics},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807548,
author = {Jamil, Shuja and Basalamah, Anas and Lbath, Ahmed and Youssef, Moustafa},
title = {Hybrid Participatory Sensing for Analyzing Group Dynamics in the Largest Annual Religious Gathering},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807548},
doi = {10.1145/2750858.2807548},
abstract = {Understanding crowd dynamics of large-scale events is crucial to deliver a pleasant experience for the participants. In this paper, we propose a novel hybrid participatory sensing approach to capture large group dynamics. Specifically, our approach is based on distributing a large number of tiny, wearable Bluetooth Low Energy (BLE) tags and few smartphones among the group members. We start by identifying the best configuration; in terms of transmit power and beaconing interval; for detecting BLE tags in indoor and outdoor environments. Then, as a case study, we deploy the system during the six main days of the Hajj pilgrimage in 2014, which is the world's largest annual religious gathering. We used the proposed hybrid participatory approach to collect the mobility data of pilgrim groups based on GPS location and co-occurring BLE tag detections. Our system provided up to 80% group-wise detectability in a single scan event. Moreover, 98% cumulative unique tags detectability is achieved in the whole event, leading to 0.74 million records. Analysis of the group dynamics revealed unexpected behavior and interesting findings. In particular, regional variations are found among different groups in the entry or exit times, duration of stay, and group cohesion; which are attributed to congestion, improper arrangements, or the nature of activities. Furthermore, we show sub-community clusters could be identified revealing clear biases based on the demographic characteristics. Based on this case study, we also give suggestions on using the proposed system for other large-scale events.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {547–558},
numpages = {12},
keywords = {crowd sensing, bluetooth low energy-based data collection, group dynamics analysis, Hajj pilgrimage},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804277,
author = {Fan, Zipei and Song, Xuan and Shibasaki, Ryosuke and Adachi, Ryutaro},
title = {CityMomentum: An Online Approach for Crowd Behavior Prediction at a Citywide Level},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804277},
doi = {10.1145/2750858.2804277},
abstract = {Human movements are difficult to predict, especially, when we consider rare behaviors that deviate from normal daily routines. By tracing the behavior of a person over a long period, we can model their daily routines and predict periodical behaviors, whereas rare behaviors, such as participating in the New Year's Eve countdown, can hardly be predicted readily and thus they have usually been treated as outliers of the daily routines in most existing studies. However, for scenarios such as emergency management or intelligent traffic regulation, we are more interested in rare behaviors than daily routines. Using human mobility Big Data, the rare behavior of each individual in a social crowd is no longer rare and thus it may be predicted when we analyze the crowd behavior at a citywide level. Therefore in this study, instead of predicting movement based on daily routines, we make short-term predictions based on the recent movement observations. We propose a novel model called CityMomentum as a predicting-by-clustering framework for sampling future movement using a mixture of multiple random Markov chains, each of which is a Naive Movement Predictive model trained with the movements of the subjects that belong to each cluster. We apply our approach to a big mobile phone GPS log dataset and predict the short-term future movements, especially during the Comiket 80 and New Year's Eve celebration. We evaluate our prediction by a Earth Mover Distance (EMD) based metric, and show our approach accurately predicts the crowd behavior during the rare crowd events, which makes an early crowd event warning and regulation possible in the emergent situations.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {559–569},
numpages = {11},
keywords = {human mobility, urban computing, emergency management, big data},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804291,
author = {Chen, Longbiao and Zhang, Daqing and Pan, Gang and Ma, Xiaojuan and Yang, Dingqi and Kushlev, Kostadin and Zhang, Wangsheng and Li, Shijian},
title = {Bike Sharing Station Placement Leveraging Heterogeneous Urban Open Data},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804291},
doi = {10.1145/2750858.2804291},
abstract = {Bike sharing systems have been deployed in many cities to promote green transportation and a healthy lifestyle. One of the key factors for maximizing the utility of such systems is placing bike stations at locations that can best meet users' trip demand. Traditionally, urban planners rely on dedicated surveys to understand the local bike trip demand, which is costly in time and labor, especially when they need to compare many possible places. In this paper, we formulate the bike station placement issue as a bike trip demand prediction problem. We propose a semi-supervised feature selection method to extract customized features from the highly variant, heterogeneous urban open data to predict bike trip demand. Evaluation using real-world open data from Washington, D.C. and Hangzhou shows that our method can be applied to different cities to effectively recommend places with higher potential bike trip demand for placing future bike stations.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {571–575},
numpages = {5},
keywords = {bike sharing system, open data, urban computing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807528,
author = {Mathur, Akhil and Van den Broeck, Marc and Vanderhulst, Geert and Mashhadi, Afra and Kawsar, Fahim},
title = {Tiny Habits in the Giant Enterprise: Understanding the Dynamics of a Quantified Workplace},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807528},
doi = {10.1145/2750858.2807528},
abstract = {We offer a reflection on the technology usage for workplace quantification through an in the wild study. Using a prototype Quantified Workplace system equipped with passive and participatory sensing modalities, we collected and visualized different workplace metrics (noise, color, air quality, self reported mood, and self reported activity) in two European offices of a research organization for a period of 4 months. Next we surveyed 70 employees to understand their engagement experience with the system. We then conducted semi-structured interviews with 20 employees in which they explained which workplace metrics are useful and why, how they engage with the system and what privacy concerns they have. Our findings suggest that sense of inclusion acts as the initial incentive for engagement which gradually translates into a habitual routine. We found that incorporation of an anonymous participatory sensing aspect into the system could lead to sustained user engagement. Compared to past studies we observed a shift in the privacy concerns, due to the trust and transparency of our prototype system. We conclude by providing a set of design principles for building future Quantified Workplace systems.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {577–588},
numpages = {12},
keywords = {social sensing, quantified workplace, empirical study},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807547,
author = {Scholl, Philipp M. and Wille, Matthias and Van Laerhoven, Kristof},
title = {Wearables in the Wet Lab: A Laboratory System for Capturing and Guiding Experiments},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807547},
doi = {10.1145/2750858.2807547},
abstract = {Wet Laboratories are highly dynamic, shared environments full of tubes, racks, compounds, and dedicated machinery. The recording of experiments, despite the fact that several ubiquitous computing systems have been suggested in the past decades, still relies predominantly on hand-written notes. Similarly, the information retrieval capabilities inside a laboratory are limited to traditional computing interfaces, which due to safety regulations are sometimes not usable at all. In this paper, Google Glass is combined with a wrist-worn gesture sensor to support Wetlab experimenters. Taking "in-situ" documentation while an experiment is performed, as well as contextualizing the protocol at hand can be implemented on top of the proposed system. After an analysis of current practices and needs through a series of explorative deployments in wet labs, we motivate the need for a wearable hands-free system, and introduce our specific design to guide experimenters. Finally, using a study with 22 participants evaluating the system on a benchmark DNA extraction experiment, we explore the use of gesture recognition for enabling the system to track where the user might be in the experiment.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {589–599},
numpages = {11},
keywords = {Google Glass, hands-free documentation, life science, activity recognition, wet lab, wrist-worn inertial sensors},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804268,
author = {Funk, Markus and Shirazi, Alireza Sahami and Mayer, Sven and Lischke, Lars and Schmidt, Albrecht},
title = {Pick from Here! An Interactive Mobile Cart Using in-Situ Projection for Order Picking},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804268},
doi = {10.1145/2750858.2804268},
abstract = {Order Picking is not only one of the most important but also most mentally demanding and error-prone tasks in the industry. Both stationary and wearable systems have been introduced to facilitate this task. Existing stationary systems are not scalable because of the high cost and wearable systems have issues being accepted by the workers. In this paper, we introduce a mobile camera-projector cart called OrderPickAR, which combines the benefits of both stationary and mobile systems to support order picking through Augmented Reality. Our system dynamically projects in-situ picking information into the storage system and automatically detects when a picking task is done. In a lab study, we compare our system to existing approaches, i.e, Pick-by-Paper, Pick-by-Voice, and Pick-by-Vision. The results show that using the proposed system, order picking is almost twice as fast as other approaches, the error rate is decreased up to 9 times, and mental demands are reduced up to 50%.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {601–609},
numpages = {9},
keywords = {projected displays, industrial augmented reality, order picking},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805841,
author = {Narzt, Wolfgang and Pomberger, Gustav and Weichselbaum, Otto and Draxler, Reinhard and Welser, Markus},
title = {From Research to Industry: Interactive Mobile Services for Accelerating Logistics Processes},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805841},
doi = {10.1145/2750858.2805841},
abstract = {Whenever attentiveness for direct human computer interaction is unavailable, i.e., when a person must not be distracted from performing a task or is handicapped through wearable limitations (e.g., by protective clothing), mobile location-based systems offer implicit, hands-free interaction mechanisms enabling users to trigger actions by the physical presence of an (authorized) traceable mobile device at a predefined location. This paper utilizes the basic idea of this well-proven interaction principle, presents its successful industrial application at Austria's largest car logistics company (H\"{o}dlmayr International) and demonstrates its potential savings for the logistics domain in the course of a perennial observation of production figures.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {611–615},
numpages = {5},
keywords = {mobile computing, location-triggered code execution, mobile interaction services, logistics processes},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805832,
author = {Harrison, Daniel and Marshall, Paul and Bianchi-Berthouze, Nadia and Bird, Jon},
title = {Activity Tracking: Barriers, Workarounds and Customisation},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805832},
doi = {10.1145/2750858.2805832},
abstract = {Activity trackers are increasingly popular, but they have high levels of abandonment and little evidence exists to suggest why this is. This paper explores barriers to engagement with activity trackers. We extend previous research by not only characterising the barriers users experienced, such as tracking accuracy and device aesthetics, but also by reporting the workarounds they created. We discuss implications for the design of activity tracking systems by reflecting on these workarounds, the potential for activity tracker design to help overcome existing barriers, and how customisation could play a role.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {617–621},
numpages = {5},
keywords = {behaviour change, activity tracking, personal informatics, fitness, quantified self, health, physical activity},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804269,
author = {Yang, Rayoung and Shin, Eunice and Newman, Mark W. and Ackerman, Mark S.},
title = {When Fitness Trackers Don't 'Fit': End-User Difficulties in the Assessment of Personal Tracking Device Accuracy},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804269},
doi = {10.1145/2750858.2804269},
abstract = {Personal tracking technologies allow users to monitor and reflect on their physical activities and fitness. However, users are uncertain about how accurately their devices track their data. In order to better understand this challenge, we analyzed 600 product reviews and conducted 24 interviews with tracking device users. In this paper, we describe what methods users used to assess accuracy of their tracking devices and identify seven problems they encountered. We found that differences in users' expectations, physical characteristics, types of activities and lifestyle led them to have different perceptions of the accuracy of their devices. With the absence of sound mental models and unclear understanding of the concepts of accuracy and experimental controls, users designed faulty tests and came to incorrect conclusions. We propose design recommendations to better support end-users' efforts to assess and improve the accuracy of their tracking devices as required to suit their individual characteristics and purposes.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {623–634},
numpages = {12},
keywords = {activity, fitness tracker, accuracy, sensor-based tracking},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804288,
author = {Lazar, Amanda and Koehler, Christian and Tanenbaum, Theresa Jean and Nguyen, David H.},
title = {Why We Use and Abandon Smart Devices},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804288},
doi = {10.1145/2750858.2804288},
abstract = {Smart devices are becoming increasingly commercially available. However, uptake of these devices has been slow and abandonment swift, which indicates that smart devices may not currently meet the needs of users. To advance an understanding of the ways users benefit from, are challenged by, and abandon smart devices, we asked a group of users to purchase smart sensing devices to advance themselves towards a personal, self-defined goal. We found that participants abandoned devices because they did not fit with the their conceptions of themselves, the data collected by devices were perceived to not be useful, and device maintenance became unmanageable. Participants used devices because they had developed routines and because devices were useful, satisfied curiosity, and held hope for potential benefit to them. We propose ways to reduce barriers, motivate use, and argue for envisioning an additional function of these devices for short-term interventions, in addition to standard long-term use.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {635–646},
numpages = {12},
keywords = {personal informatics systems, smart devices, self tracking, wearable devices},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807554,
author = {Clawson, James and Pater, Jessica A. and Miller, Andrew D. and Mynatt, Elizabeth D. and Mamykina, Lena},
title = {No Longer Wearing: Investigating the Abandonment of Personal Health-Tracking Technologies on Craigslist},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807554},
doi = {10.1145/2750858.2807554},
abstract = {Personal health-tracking technologies have become a part of mainstream culture. Their growing popularity and widespread adoption present an opportunity for the design of new interventions to improve wellness and health. However, there is an increasing concern that these technologies are failing to inspire long-term adoption. In order to understand why users abandon personal health-tracking technologies, we analyzed advertisements of secondary sales of such technologies on Craigslist. We conducted iterative inductive and deductive analyses of approximately 1600 advertisements of personal health-tracking technologies posted over the course of one month across the US. We identify health motivations and rationales for abandonment and present a set of design implications. We call for improved theories that help translate between existing theories designed to explain psychological effects of health behavior change and the technologies that help people make those changes.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {647–658},
numpages = {12},
keywords = {health-tracking, self-monitoring, technology abandonment},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807523,
author = {Xu, Liwen and Hao, Xiaohong and Lane, Nicholas D. and Liu, Xin and Moscibroda, Thomas},
title = {More with Less: Lowering User Burden in Mobile Crowdsourcing through Compressive Sensing},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807523},
doi = {10.1145/2750858.2807523},
abstract = {Mobile crowdsourcing is a powerful tool for collecting data of various types. The primary bottleneck in such systems is the high burden placed on the user who must manually collect sensor data or respond in-situ to simple queries (e.g., experience sampling studies). In this work, we present Compressive CrowdSensing (CCS) -- a framework that enables compressive sensing techniques to be applied to mobile crowdsourcing scenarios. CCS enables each user to provide significantly reduced amounts of manually collected data, while still maintaining acceptable levels of overall accuracy for the target crowd-based system. Na\"{\i}ve applications of compressive sensing do not work well for common types of crowdsourcing data (e.g., user survey responses) because the necessary correlations that are exploited by a sparsifying base are hidden and non-trivial to identify. CCS comprises a series of novel techniques that enable such challenges to be overcome. We evaluate CCS with four representative large-scale datasets and find that it is able to outperform standard uses of compressive sensing, as well as conventional approaches to lowering the quantity of user data needed by crowd systems.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {659–670},
numpages = {12},
keywords = {compressive sensing, mobile crowdsensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807524,
author = {Chang, Yung-Ju and Paruthi, Gaurav and Newman, Mark W.},
title = {A Field Study Comparing Approaches to Collecting Annotated Activity Data in Real-World Settings},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807524},
doi = {10.1145/2750858.2807524},
abstract = {Collecting ground-truth annotations for contextual data is vital to context-aware system development. However, current research lacks a systematic analysis of different approaches to collecting such data. We present a field experiment comparing three approaches: Participatory, Context-Triggered In Situ, and Context-Triggered Post Hoc, which involved users in recording and annotating activity data in real-world settings. We compared the quantity and quality of collected data using each approach, as well as the participant experience. We found Context-Triggered approaches produced more recordings, whereas the Participatory approach produced a greater amount of data with higher completeness and precision. Moreover, while participants appreciated automated recording and reminders for convenience, they highly valued having control over what and when to record and annotate. We conclude that user burden and user control are key aspects to consider when collecting and annotating contextual data with participants, and suggest features for a future tool focused on these two aspects.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {671–682},
numpages = {12},
keywords = {wearable camera, label, transportation, field experiment, activity data collection, ground truth, annotation},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807513,
author = {Wang, Leye and Zhang, Daqing and Pathak, Animesh and Chen, Chao and Xiong, Haoyi and Yang, Dingqi and Wang, Yasha},
title = {CCS-TA: Quality-Guaranteed Online Task Allocation in Compressive Crowdsensing},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807513},
doi = {10.1145/2750858.2807513},
abstract = {Data quality and budget are two primary concerns in urban-scale mobile crowdsensing applications. In this paper, we leverage the spatial and temporal correlation among the data sensed in different sub-areas to significantly reduce the required number of sensing tasks allocated (corresponding to budget), yet ensuring the data quality. Specifically, we propose a novel framework called CCS-TA, combining the state-of-the-art compressive sensing, Bayesian inference, and active learning techniques, to dynamically select a minimum number of sub-areas for sensing task allocation in each sensing cycle, while deducing the missing data of unallocated sub-areas under a probabilistic data accuracy guarantee. Evaluations on real-life temperature and air quality monitoring datasets show the effectiveness of CCS-TA. In the case of temperature monitoring, CCS-TA allocates 18.0-26.5% fewer tasks than baseline approaches, allocating tasks to only 15.5% of the sub-areas on average while keeping overall sensing error below 0.25°C in 95% of the cycles.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {683–694},
numpages = {12},
keywords = {crowdsensing, task allocation, data quality},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804273,
author = {Morishita, Shigeya and Maenaka, Shogo and Nagata, Daichi and Tamai, Morihiko and Yasumoto, Keiichi and Fukukura, Toshinobu and Sato, Keita},
title = {SakuraSensor: Quasi-Realtime Cherry-Lined Roads Detection through Participatory Video Sensing by Cars},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804273},
doi = {10.1145/2750858.2804273},
abstract = {In this paper, we propose SakuraSensor, a participatory sensing system which automatically extracts scenic routes information from videos recorded by car-mounted smart-phones and shares the information among users in quasirealtime. As scenic routes information, we target flowering cherries along roads since the best period of flowering cherries is rather short and uncertain from year to year and from place to place. To realize SakuraSensor, we face two technical challenges: (1) how to accurately detect flowering cherries and its degree, and (2) how to efficiently find good places of flowering cherries (PoIs) using the participatory sensing technique. For the first challenge, we develop an image analysis method for detecting image pixels that belong to flowering cherries. To exclude artificial objects with similar color to flowering cherries, we also employ fractal dimension analysis to filter out unnecessary image areas. For the second challenge, we propose a method called k-stage sensing. In this method, the interval for sensing (taking a still image and applying the image analysis) by each car is dynamically shortened so that the roads near the already found PoIs are more densely sensed. We implemented SakuraSensor consisting of client-side software for iOS devices and server-side software for a cloud server and conducted experiments to travel cherry-lined roads and record videos by several cars. As a result, we confirmed that our method can identify flowering cherries at about 74 % precision and 84 % recall. We also confirmed that our k-stage sensing method could achieve the comparable PoI detection rate with half sensing times compared to a conventional method.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {695–705},
numpages = {11},
keywords = {participatory sensing, flowering cherries detection, image analysis, k-stage sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805840,
author = {Rabbi, Mashfiqui and Aung, Min Hane and Zhang, Mi and Choudhury, Tanzeem},
title = {MyBehavior: Automatic Personalized Health Feedback from User Behaviors and Preferences Using Smartphones},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805840},
doi = {10.1145/2750858.2805840},
abstract = {Mobile sensing systems have made significant advances in tracking human behavior. However, the development of personalized mobile health feedback systems is still in its infancy. This paper introduces MyBehavior, a smartphone application that takes a novel approach to generate deeply personalized health feedback. It combines state-of-the-art behavior tracking with algorithms that are used in recommendation systems. MyBehavior automatically learns a user's physical activity and dietary behavior and strategically suggests changes to those behaviors for a healthier lifestyle. The system uses a sequential decision making algorithm, Multi-armed Bandit, to generate suggestions that maximize calorie loss and are easy for the user to adopt. In addition, the system takes into account user's preferences to encourage adoption using the pareto-frontier algorithm. In a 14-week study, results show statistically significant increases in physical activity and decreases in food calorie when using MyBehavior compared to a control condition.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {707–718},
numpages = {12},
keywords = {machine learning, systems, mobile phone sensing, health feedback, scalibility, mobile health},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805843,
author = {Adams, Alexander T. and Costa, Jean and Jung, Malte F. and Choudhury, Tanzeem},
title = {Mindless Computing: Designing Technologies to Subtly Influence Behavior},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805843},
doi = {10.1145/2750858.2805843},
abstract = {Persuasive technologies aim to influence user's behaviors. In order to be effective, many of the persuasive technologies developed so far relies on user's motivation and ability, which is highly variable and often the reason behind the failure of such technology. In this paper, we present the concept of Mindless Computing, which is a new approach to persuasive technology design. Mindless Computing leverages theories and concepts from psychology and behavioral economics into the design of technologies for behavior change. We show through a systematic review that most of the current persuasive technologies do not utilize the fast and automatic mental processes for behavioral change and there is an opportunity for persuasive technology designers to develop systems that are less reliant on user's motivation and ability. We describe two examples of mindless technologies and present pilot studies with encouraging results. Finally, we discuss design guidelines and considerations for developing this type of persuasive technology.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {719–730},
numpages = {12},
keywords = {subconscious, behavior change, nudging, mindless, subliminal, system 1, persuasive technology, system 2},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804250,
author = {Epstein, Daniel A. and Ping, An and Fogarty, James and Munson, Sean A.},
title = {A Lived Informatics Model of Personal Informatics},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804250},
doi = {10.1145/2750858.2804250},
abstract = {Current models of how people use personal informatics systems are largely based in behavior change goals. They do not adequately characterize the integration of self-tracking into everyday life by people with varying goals. We build upon prior work by embracing the perspective of lived informatics to propose a new model of personal informatics. We examine how lived informatics manifests in the habits of self-trackers across a variety of domains, first by surveying 105, 99, and 83 past and present trackers of physical activity, finances, and location and then by interviewing 22 trackers regarding their lived informatics experiences. We develop a model characterizing tracker processes of deciding to track and selecting a tool, elaborate on tool usage during collection, integration, and reflection as components of tracking and acting, and discuss the lapsing and potential resuming of tracking. We use our model to surface underexplored challenges in lived informatics, thus identifying future directions for personal informatics design and research.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {731–742},
numpages = {12},
keywords = {location, finances, lived informatics, physical activity, personal informatics, lapsing, self-tracking},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807552,
author = {Lee, Min Kyung and Kim, Junsung and Forlizzi, Jodi and Kiesler, Sara},
title = {Personalization Revisited: A Reflective Approach Helps People Better Personalize Health Services and Motivates Them to Increase Physical Activity},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807552},
doi = {10.1145/2750858.2807552},
abstract = {Current approaches to personalization either presuppose people's needs and automatically tailor services or provide formulaic options for people to customize. We propose a complementary approach to personalization: a reflective strategy that helps people realize what matters to them and enables them to better personalize services themselves. To design this strategy, we first studied the practices of eight personal health service providers. We then tested the strategy's efficacy by building a Fitbit Plan website that encouraged Fitbit users to customize a plan or accept an automatically tailored plan. For one group of users, the website used the reflective strategy to assist in the plan setup process. A two-week between-subjects field experiment showed that the reflective strategy helped motivate users to carry out their plans, increasing their average daily steps by 2,425 steps. Without the reflective strategy, users either set easy goals or failed to carry out system-created plans, ultimately showing no change in their average daily steps. This work suggests that helping people reflect on and connect with their own goals in using a personalized service could advance the effectiveness of the service.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {743–754},
numpages = {12},
keywords = {reflective personalization, personal informatics, fitness, activity tracker, health, service, behavior change},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805838,
author = {Bedwell, Ben and Slack, Peter and Greenhalgh, Chris},
title = {Learning from the Experts: Enabling and Studying DIY Development of Location-Based Visitor Experiences},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805838},
doi = {10.1145/2750858.2805838},
abstract = {In this paper we show how -- with the aid of enabling technology -- creative Location Based Experiences can be developed for visitors by non-technical professionals from the cultural heritage sector. We look at how these "Place Experts" approach and adopt web technologies to create and publish experiences including the roles they take on, the processes they adopt, and the way they appropriate the technology. We describe our short and long-term research engagements with the cultural heritage sector over the last three years and introduce Wander Anywhere, the website developed to enable this research. We find that place experts typically follow a four stage process in their engagement with location-based experiences, moving from comprehension to translation, development and finally approval. We suggest implications for the processes and technologies that might be employed by others seeking to support a similar type of engagement.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {755–766},
numpages = {12},
keywords = {cultural heritage, location, user studies, location based experience, mobile, authoring},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807535,
author = {Jewell, Michael O. and Costanza, Enrico and Kittley-Davies, Jacob},
title = {Connecting the Things to the Internet: An Evaluation of Four Configuration Strategies for Wi-Fi Devices with Minimal User Interfaces},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807535},
doi = {10.1145/2750858.2807535},
abstract = {The availability of low-power Wi-Fi radio modules opens up opportunities to leverage the existing prevalent Wi-Fi infrastructure for large-scale trials and deployments of Ubicomp technology. In this paper we address the challenge of supporting end-users, especially when they are not technical experts, in connecting new low-power, low-cost Wi-Fi devices with very minimal UIs to an existing, secure Wi-Fi infrastructure. We report two usability studies through which 30 participants, with no formal technical training, compared 4 alternative configuration techniques, selected based on cost and consumption constraints, and on adoption in off-the-shelf products. Through an analysis of success rate and causes of failure, our results indicate that two techniques are noticeably more usable than others. These are a web-based configuration mechanism, where users connect to an access point on the Wi-Fi device, and one that makes use of a standard audio cable to connect a smartphone to the device to be configured.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {767–778},
numpages = {12},
keywords = {internet-of-things, deployment, configuration, 802.11, user study},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2806063,
author = {Woo, Jong-bum and Lim, Youn-kyung},
title = {User Experience in Do-It-Yourself-Style Smart Homes},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2806063},
doi = {10.1145/2750858.2806063},
abstract = {Do-it-yourself (DIY)-style smart home products enable users to create their own smart homes by installing sensors and actuators. DIY smart home products are a potential solution to current problems related to home automation products, such as inflexible user controls and high costs of installation. Although the expected user experience of DIY smart home products is different from that of previous home automation products, research on DIY smart home products is still in its early stages. In this paper, we report a 3-week in situ observational study involving eight households. The results suggest six stages of the DIY smart home usage cycle and design implications for improving the user experience of DIY smart home products.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {779–790},
numpages = {12},
keywords = {design, domestic technology, do-it-yourself, end-user programming, smart home},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804267,
author = {Narumi, Koya and Hodges, Steve and Kawahara, Yoshihiro},
title = {ConductAR: An Augmented Reality Based Tool for Iterative Design of Conductive Ink Circuits},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804267},
doi = {10.1145/2750858.2804267},
abstract = {Recent advances in materials science have resulted in a range of commercially viable and easy-to-use conductive inks which novices, hobbyists, educators, students and researchers are now using to design and build interactive circuits quickly. Despite the ease with which practitioners can construct working circuits, one of the major limitations of designing circuits on-the-fly is the difficulty of detecting and understanding errors in prototype circuits. As well as short- and open-circuits, which often prevent a circuit from working at all, more subtle issues like high resistance traces can result in poor performance. Many users can't readily work out how to successfully modify their circuits, and they often don't have the tools or expertise to measure the relevant circuit parameters. In this paper we present ConductAR, a tool which can recognize and analyze hand-drawn, printed and hybrid conductive ink patterns. An on-screen augmented reality style interaction helps users to understand and enhance circuit operation. A key element of ConductAR is its ability to calculate the resistance of a circuit using a camera attached to an off-the-shelf PC or tablet. Our sparse coding technique is fast enough to support rapid iterative prototyping on real circuits using a conductive ink marker and/or eraser as shown in Figure 1. The system thereby enhances the feasibility of circuit prototyping with conductive ink.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {791–800},
numpages = {10},
keywords = {conductive ink, rapid prototyping, makers, education},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807514,
author = {Turner, Liam D. and Allen, Stuart M. and Whitaker, Roger M.},
title = {Interruptibility Prediction for Ubiquitous Systems: Conventions and New Directions from a Growing Field},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807514},
doi = {10.1145/2750858.2807514},
abstract = {When should a machine attempt to communicate with a user? This is a historical problem that has been studied since the rise of personal computing. More recently, the emergence of pervasive technologies such as the smartphone have extended the problem to be ever-present in our daily lives, opening up new opportunities for context awareness through data collection and reasoning. Complementary to this there has been increasing interest in techniques to intelligently synchronise interruptions with human behaviour and cognition. However, it is increasingly challenging to categorise new developments, which are often scenario specific or scope a problem with particular unique features. In this paper we present a meta-analysis of this area, decomposing and comparing historical and recent works that seek to understand and predict how users will perceive and respond to interruptions. In doing so we identify research gaps, questions and opportunities that characterise this important emerging field for pervasive technology.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {801–812},
numpages = {12},
keywords = {meta-analysis, context-aware computing, interruptibility, ubiquitous computing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807544,
author = {Mehrotra, Abhinav and Musolesi, Mirco and Hendley, Robert and Pejovic, Veljko},
title = {Designing Content-Driven Intelligent Notification Mechanisms for Mobile Applications},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807544},
doi = {10.1145/2750858.2807544},
abstract = {An increasing number of notifications demanding the smartphone user's attention, often arrive at an inappropriate moment, or carry irrelevant content. In this paper we present a study of mobile user interruptibility with respect to notification content, its sender, and the context in which a notification is received. In a real-world study we collect around 70,000 instances of notifications from 35 users. We group notifications according to the applications that initiated them, and the social relationship between the sender and the receiver. Then, by considering both content and context information, such as the current activity of a user, we discuss the design of classifiers for learning the most opportune moment for the delivery of a notification carrying a specific type of information. Our results show that such classifiers lead to a more accurate prediction of users' interruptibility than an alternative approach based on user-defined rules of their own interruptibility.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {813–824},
numpages = {12},
keywords = {mobile sensing, notifications, context-aware computing, interruptibility},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804252,
author = {Pielot, Martin and Dingler, Tilman and Pedro, Jose San and Oliver, Nuria},
title = {When Attention is Not Scarce - Detecting Boredom from Mobile Phone Usage},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804252},
doi = {10.1145/2750858.2804252},
abstract = {Boredom is a common human emotion which may lead to an active search for stimulation. People often turn to their mobile phones to seek that stimulation. In this paper, we tackle the challenge of automatically inferring boredom from mobile phone usage. In a two-week in-the-wild study, we collected over 40,000,000 usage logs and 4398 boredom self-reports of 54 mobile phone users. We show that a user-independent machine-learning model of boredom --leveraging features related to recency of communication, usage intensity, time of day, and demographics-- can infer boredom with an accuracy (AUCROC) of up to 82.9%. Results from a second field study with 16 participants suggest that people are more likely to engage with recommended content when they are bored, as inferred by our boredom-detection model. These findings enable boredom-triggered proactive recommender systems that attune their users' level of attention and need for stimulation.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {825–836},
numpages = {12},
keywords = {attention, mobile devices, boredom, killing time, attention economy},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807530,
author = {Matic, Aleksandar and Pielot, Martin and Oliver, Nuria},
title = {Boredom-Computer Interaction: Boredom Proneness and the Use of Smartphone},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807530},
doi = {10.1145/2750858.2807530},
abstract = {Mobile technology is becoming a loyal companion in our lives. It is used for increasing amounts of time during the day and night, enabling the development of intelligent user interfaces that characterize their users' traits and adapt to them. In this paper, we show how an individual's tendency to experience boredom, i.e. the personal trait called boredom proneness, affects the use of technology -- specifically a smartphone. We develop machine learning models to automatically classify individuals into high/low boredom proneness from their typical daily patterns of smartphone use. We thus propose boredom proneness as a trait with high potential to enable the design of personalized mobile services that are more meaningful to their users.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {837–841},
numpages = {5},
keywords = {user modeling, mobile devices, boredom proneness},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807522,
author = {Murnane, Elizabeth L. and Abdullah, Saeed and Matthews, Mark and Choudhury, Tanzeem and Gay, Geri},
title = {Social (Media) Jet Lag: How Usage of Social Technology Can Modulate and Reflect Circadian Rhythms},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807522},
doi = {10.1145/2750858.2807522},
abstract = {By nature, we are circadian creatures whose bodies' biological clocks drive numerous physiological, mental, and behavioral rhythms. Simultaneously, we are social beings. Accordingly, our internal circadian timings experience interference from externally determined factors such as work schedules and social engagements, and digital connectivity imports additional social constraints that can further misalign our individual body clocks. Misalignment between biological and social time causes social jet lag [50], which has serious physical and mental health consequences. It particularly impacts our sleep processes and neurobehavioral functioning. Examining the interplay between biological rhythms and technology-mediated social interactions, we find that technology may both modulate and reflect circadian rhythms. We also leverage such social-sensor data to infer sleep-related behaviors and disruptions and to analyze variations in attention, cognitive performance, and mood following (in)adequate sleep. We conclude with recommendations for designing technologies attuned to our innate biological traits.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {843–854},
numpages = {12},
keywords = {circadian rhythms, sleep, social computing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804289,
author = {Jayarajah, Kasthuri and Lee, Youngki and Misra, Archan and Balan, Rajesh Krishna},
title = {Need Accurate User Behaviour? Pay Attention to Groups!},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804289},
doi = {10.1145/2750858.2804289},
abstract = {In this paper, we show that characterizing user behaviour from location or smartphone usage traces, without accounting for the interaction of individuals in physical-world groups, can lead to erroneous results. We conducted one of the largest studies in the UbiComp domain thus far, involving indoor location traces of more than 6,000 users, collected over a 4-month period at our university campus, and further studied fine-grained App usage of a subset of 156 Android users. We apply a state-of-the-art group detection algorithm to annotate such location traces with group vs. individual context, and then show that individuals vs. groups exhibit significant differences along three behavioural traits: (1) the mobility pattern, (2) the responsiveness to calls / SMSs and (3) application usage. We show that these significant differences are robust to underlying errors in the group detection technique and that the use of such group context leads to behavioural results that differ from those reported in prior popular work.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {855–866},
numpages = {12},
keywords = {location, app usage, user behaviour, interruptibility, groups},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804283,
author = {Ko, Minsam and Choi, Seungwoo and Yang, Subin and Lee, Joonwon and Lee, Uichin},
title = {FamiLync: Facilitating Participatory Parental Mediation of Adolescents' Smartphone Use},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804283},
doi = {10.1145/2750858.2804283},
abstract = {We consider participatory parental mediation in which children engage with their parents in activities that encourage both parents and children to participate in co-learning of digital media use. To this end, we developed FamiLync, a mobile service that treats use-limiting as a family activity and provides the family with a virtual public space to foster social awareness and improve self-regulation. A three-week user study conducted with twelve families in Korea (17 parents and 18 teenagers) showed that FamiLync improves mutual understanding of usage behavior, thereby providing common grounds for parental mediation. Further, parents actively participated in use-limiting with their children, which significantly increased the children's desire to participate. As a consequence, parental mediation methods and parent-child interaction in relation to smartphone usage changed appreciably, and the participants smartphone usage amount significantly decreased.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {867–878},
numpages = {12},
keywords = {adolescents' smartphone overuse, participatory learning, parental mediation},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805839,
author = {Yu, Zhiwen and Du, Rong and Guo, Bin and Xu, Huang and Gu, Tao and Wang, Zhu and Zhang, Daqing},
title = {Who Should I Invite for My Party? Combining User Preference and Influence Maximization for Social Events},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805839},
doi = {10.1145/2750858.2805839},
abstract = {The newly emerging event-based social networks (EBSNs) extend social interaction from online to offline, providing an appealing platform for people to organize and participate realworld social events. In this paper, we investigate how to select potential participants in EBSNs from an event host's point of view. We formulate the problem as mining influential and preferable invitee set, considering from two complementary aspects. The first aspect concerns users' preference with respect to the event. The second aspect is influence maximization, which aims to influence the largest number of users to participate the event. In particular, we propose a novel Credit Distribution-User Influence Preference (CD-UIP) algorithm to find the most influential and preferable followers as the invitees. We collect a real-world dataset from a popular EBSNs called "Douban Events", and the experimental results on the dataset demonstrate the proposed algorithm outperforms the state-of-the-art prediction methods.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {879–883},
numpages = {5},
keywords = {invitee set, influence maximization, event-based social networks, user preference, CD-UIP},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2806061,
author = {Ohara, Kazuya and Maekawa, Takuya and Kishino, Yasue and Shirai, Yoshinari and Naya, Futoshi},
title = {Transferring Positioning Model for Device-Free Passive Indoor Localization},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2806061},
doi = {10.1145/2750858.2806061},
abstract = {This paper proposes a new method that makes it easy for us to construct a positioning model for device-free passive indoor localization by using model transfer techniques. With device-free passive indoor positioning, a wireless sensor network is used to detect the movement of a person based on the fact that RF signals transmitted between a transmitter and a receiver are affected by human movement. However, because device-free passive indoor positioning relies on machine learning techniques, we must collect labeled training data at many training points in an end user's environment. This paper proposes a method that transfers a signal strength model used for locating a person obtained in another environment (source environment) to the end user environment. With the transferred models, we can construct a positioning model for the end user environment inexpensively. Our evaluation showed that our method achieved almost the same positioning performance as a supervised method that requires labeled training data obtained in an end user's environment.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {885–896},
numpages = {12},
keywords = {model transfer, device-free passive positioning, indoor positioning},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804254,
author = {He, Suining and Chan, S.-H. Gary and Yu, Lei and Liu, Ning},
title = {Calibration-Free Fusion of Step Counter and Wireless Fingerprints for Indoor Localization},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804254},
doi = {10.1145/2750858.2804254},
abstract = {In order to improve the accuracy of fingerprint-based localization, one may fuse step counter measurement with location estimation. Previous works on this often require a pre-calibrating the step counter with training sequence or explicit user input, which is inconvenient for practical deployment. Some assume conditional independence on successive sensor readings, which achieves unsatisfactory accuracy in complex and noisy environment. Some other works need a calibration process for RSSI measurement consistency if different devices are used for offline fingerprint collection and online location query.We propose SLAC, a fingerprint positioning framework which simultaneously localizes the target and calibrates the system. SLAC is calibration-free, and works transparently for heterogeneous devices and users. It is based on a novel formulation embedded with a specialized particle filter, where location estimations, wireless signals and user motion are jointly optimized with resultant consistent and correct model parameters. Extensive experimental trials at HKUST campus and Hong Kong International Airport further confirm that SLAC accommodates device heterogeneity, and achieves significantly lower errors compared with other state-of-the-art algorithms.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {897–908},
numpages = {12},
keywords = {joint optimization, fusion, fingerprinting, indoor localization, device RSSI dependency, step counter calibration},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804284,
author = {Biehl, Jacob T. and Lee, Adam J. and Filby, Gerry and Cooper, Matthew},
title = {You're Where? Prove It! Towards Trusted Indoor Location Estimation of Mobile Devices},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804284},
doi = {10.1145/2750858.2804284},
abstract = {Location-enabled applications now permeate the mobile computing landscape. As technologies like Bluetooth Low Energy (BLE) and Apple's iBeacon protocols begin to see widespread adoption, we will no doubt see a proliferation of indoor location enabled application experiences. While not essential to each of these applications, many will require that the location of the device be true and verifiable. In this paper, we present LocAssure, a new framework for trusted indoor location estimation. The system leverages existing technologies like BLE and iBeacons, making the solution practical and compatible with technologies that are already in use today. In this work, we describe our system, situate it within a broad location assurance taxonomy, describe the protocols that enable trusted localization in our system, and provide an analysis of early deployment and use characteristics. Through developer APIs, LocAssure can provide critical security support for a broad range of indoor location applications.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {909–919},
numpages = {11},
keywords = {location services, secure location, indoor location, location-based access control},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807543,
author = {Bao, Xuan and Liu, Bin and Tang, Bo and Hu, Bing and Kong, Deguang and Jin, Hongxia},
title = {PinPlace: Associate Semantic Meanings with Indoor Locations without Active Fingerprinting},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807543},
doi = {10.1145/2750858.2807543},
abstract = {Web map services today, such as Google and Bing maps, have digitalized a great portion of the physical world into easily accessible location databases. After the industry invested huge efforts in gathering related information, a user now can search a physical location on the map and know what kind of place it is, known as reverse geo-coding. However, this functionality is mostly limited to public outdoor locations and to building level granularity. We believe that many services can benefit from knowing the semantic meanings of fine-grained locations including indoor places. For example, the phone can mute and delay incoming calls when a user enters a meeting room. Cameras can be disabled in bathrooms to protect users' privacy. In this paper, we present PinPlace, an on-device service that can automatically associate semantic meanings with outdoor and indoor locations using the activity, transit, and time related features.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {921–925},
numpages = {5},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804286,
author = {Shan, Zhangqing and Wu, Hao and Sun, Weiwei and Zheng, Baihua},
title = {COBWEB: A Robust Map Update System Using GPS Trajectories},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804286},
doi = {10.1145/2750858.2804286},
abstract = {The accuracy and completeness of a digital map plays a critical role in determining the quality of most location-based services. Unfortunately, road networks change frequently. Consequently, we study the issue of automatic map update in this paper. We propose a system called COBWEB which takes all the unmatched trajectories as input and generates the missing road segments with both the geometry properties and topology features well preserved. We conduct a comprehensive experimental study via real trajectory data generated by roughly 15,000 taxis in Singapore within a 5-month period. Compared with existing work, COBWEB demonstrates a better and more stable performance and a stronger resilience to various sampling rates and data sizes.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {927–937},
numpages = {11},
keywords = {map update, map inference, GPS noise, GPS trajectories, map matching, low sampling rate},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804272,
author = {Lee, Seungwoo and Kim, Yungeun and Ahn, Daye and Ha, Rhan and Lee, Kyoungwoo and Cha, Hojung},
title = {Non-Obstructive Room-Level Locating System in Home Environments Using Activity Fingerprints from Smartwatch},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804272},
doi = {10.1145/2750858.2804272},
abstract = {Many smart home applications, such as monitoring for the elderly and home automation, require location information for individual occupants. Several techniques have been proposed for tracking occupants in a home environment. However, the current techniques do not provide a seamless in-home locating system owing to the occupants' device-free movement and the lack of cost-effective infrastructure for home location tracking. In this paper, we propose a home occupant tracking system that uses a smartphone and an off-the-shelf smartwatch without additional infrastructure. In our system, activity fingerprints are automatically generated from the microphone and the inertial sensors of the smartwatch, and location information is periodically obtained from the smartphone. We designed a hidden Markov model using the relationship between home activities and the room's location. Extensive experiments showed that our system tracks the location of users with 87% accuracy, even when there is no manual training for activities.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {939–950},
numpages = {12},
keywords = {machine learning, context-aware computing, in-home locating system, occupant tracking, mobile sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804275,
author = {Wang, Shuai and Yu, Xiaofeng and Xie, Junqing},
title = {WISDOM: An Efficient Framework of Predicting WLAN Availability with Cellular Fingerprints},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804275},
doi = {10.1145/2750858.2804275},
abstract = {Mobile devices with both WLAN adapter and cellular capability, which are also known as dual-mode mobile terminals, are facing various challenges and problems in conventional WLAN discovery mechanisms, including inefficiency in network discovery, unavoidable energy consumption for frequent WLAN scanning, and privacy information leaking in network probing. In this paper, we propose a novel framework called WISDOM (Wireless Indicator Supervised Data Offloading Manipulation), which can efficiently predict the availability of appropriate WLAN access points (APs) for mobile device without the need of turning on its WLAN adapter in advance. WISDOM takes advantage of historical cellular fingerprints (i.e., the pairs of Cell-ID and Received Signal Strength Indicator) to directly model the WLAN coverage, and perform WLAN availability prediction based on the models given a query cellular fingerprint. Similarity and Classification methods are introduced to work in the framework as prediction methods. We have developed a WISDOM prototype and performed simulation and real field tests under various situations. The results showed WISDOM along with the proposed predication methods could reach at least an average of 80% in accuracy and saving 60% of power consumption on average for mobile devices.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {951–962},
numpages = {12},
keywords = {cellular fingerprints, machine learning, WLAN availability prediction},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807516,
author = {Xu, Han and Yang, Zheng and Zhou, Zimu and Shangguan, Longfei and Yi, Ke and Liu, Yunhao},
title = {Enhancing Wifi-Based Localization with Visual Clues},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807516},
doi = {10.1145/2750858.2807516},
abstract = {Indoor localization is of great importance to a wide range of applications in the era of mobile computing. Current mainstream solutions rely on Received Signal Strength (RSS) of wireless signals as fingerprints to distinguish and infer locations. However, those methods suffer from fingerprint ambiguity that roots in multipath fading and temporal dynamics of wireless signals. Though pioneer efforts have resorted to motion-assisted or peer-assisted localization, they neither work in real time nor work without the help of peer users, which introduces extra costs and constraints, and thus degrades their practicality. To get over these limitations, we propose Argus, an image-assisted localization system for mobile devices. The basic idea of Argus is to extract geometric constraints from crowdsourced photos, and to reduce fingerprint ambiguity by mapping the constraints jointly against the fingerprint space. We devise techniques for photo selection, geometric constraint extraction, joint location estimation, and build a prototype that runs on commodity phones. Extensive experiments show that Argus triples the localization accuracy of classic RSS-based method, in time no longer than normal WiFi scanning, with negligible energy consumption.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {963–974},
numpages = {12},
keywords = {photogrammetry, smart phone, indoor localization},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807538,
author = {Kleiminger, Wilhelm and Beckel, Christian and Santini, Silvia},
title = {Household Occupancy Monitoring Using Electricity Meters},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807538},
doi = {10.1145/2750858.2807538},
abstract = {Occupancy monitoring (i.e. sensing whether a building or room is currently occupied) is required by many building automation systems. An automatic heating system may, for example, use occupancy data to regulate the indoor temperature. Occupancy data is often obtained through dedicated hardware such as passive infrared sensors and magnetic reed switches. In this paper, we derive occupancy information from electric load curves measured by off-the-shelf smart electricity meters. Using the publicly available ECO dataset, we show that supervised machine learning algorithms can extract occupancy information with an accuracy between 83% and 94%. To this end we use a comprehensive feature set containing 35 features. Thereby we found that the inclusion of features that capture changes in the activation state of appliances provides the best occupancy detection accuracy.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {975–986},
numpages = {12},
keywords = {smart meter, opportunistic sensing, electricity consumption, occupancy detection},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807525,
author = {Basu, Chandrayee and Koehler, Christian and Das, Kamalika and Dey, Anind K.},
title = {PerCCS: Person-Count from Carbon Dioxide Using Sparse Non-Negative Matrix Factorization},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807525},
doi = {10.1145/2750858.2807525},
abstract = {Occupancy count in rooms is valuable for applications such as room utilization, opportunistic meeting support, and efficient heating-cooling operations. Few buildings, however, have the means of knowing occupancy beyond simple binary presence-absence. In this paper we present the PerCCS algorithm that explores the possibility of estimating person count from CO2 sensors already integrated in everyday room air-conditioning infrastructure. PerCSS uses task-driven Sparse Non-negative Matrix Factorization (SNMF) to learn a nonnegative low-dimensional representation of the CO2 data in the preprocessing stage. This denoised CO2 acts as the predictor variable for estimating occupancy count using Ensemble Least Square Regression. We tested the algorithm to estimate 15 minutes average occupancy count from a classroom of capacity 42 and compared its performance against existing methods from the literature. PerCSS estimates occupancy with a normalized mean squared error (NMSE) of 0.075 and outperformed our comparative methods in predicting occupancy count with 91 % and 15 % for exact occupancy estimation, when the room was unoccupied and occupied respectively, whereas the competing methods failed mostly.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {987–998},
numpages = {12},
keywords = {machine learning, building energy efficiency},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2806897,
author = {Saleheen, Nazir and Ali, Amin Ahsan and Hossain, Syed Monowar and Sarker, Hillol and Chatterjee, Soujanya and Marlin, Benjamin and Ertin, Emre and al'Absi, Mustafa and Kumar, Santosh},
title = {PuffMarker: A Multi-Sensor Approach for Pinpointing the Timing of First Lapse in Smoking Cessation},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2806897},
doi = {10.1145/2750858.2806897},
abstract = {Recent researches have demonstrated the feasibility of detecting smoking from wearable sensors, but their performance on real-life smoking lapse detection is unknown. In this paper, we propose a new model and evaluate its performance on 61 newly abstinent smokers for detecting a first lapse. We use two wearable sensors --- breathing pattern from respiration and arm movements from 6-axis inertial sensors worn on wrists. In 10-fold cross-validation on 40 hours of training data from 6 daily smokers, our model achieves a recall rate of 96.9%, for a false positive rate of 1.1%. When our model is applied to 3 days of post-quit data from 32 lapsers, it correctly pinpoints the timing of first lapse in 28 participants. Only 2 false episodes are detected on 20 abstinent days of these participants. When tested on 84 abstinent days from 28 abstainers, the false episode per day is limited to 1/6.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {999–1010},
numpages = {12},
keywords = {smoking detection, smoking cessation, wearable sensors, smartwatch, mobile health (mHealth)},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805844,
author = {Suarez, Isabel and Jahn, Andreas and Anderson, Christoph and David, Klaus},
title = {Improved Activity Recognition by Using Enriched Acceleration Data},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805844},
doi = {10.1145/2750858.2805844},
abstract = {Sensors embedded in smartphones are an essential component for activity recognition. Even though the accelerometer is the most widely used sensor, the highest recognition accuracies are obtained when using data collected from multiple sensors. However, the use of multiple sensors has an adverse impact on the energy consumption of power-limited devices such as smartphones. In this paper, we present a new method to improve the recognition accuracy of physical activities by using only the accelerometer. We utilize a low-pass filter to split the acceleration data into a low- and a high-frequency component. These components provide a new set of features, which can be used as a complement to the raw acceleration to reduce the number of sensors needed to recognize physical activities. After evaluating our method for a public dataset, we found that our approach represents an average of up to 16% increase in the recognition accuracy over the raw acceleration data, outperforming even widely used combinations such as the raw acceleration plus the gyroscope. The highest accuracies are obtained when using a cut-off frequency in the interval [0:001--0:05] Hz as well as a combination of the acceleration with its low-frequency component.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1011–1015},
numpages = {5},
keywords = {low-pass filter, activity recognition, acceleration},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2806064,
author = {Sleeper, Manya and Schnorf, Sebastian and Kemler, Brian and Consolvo, Sunny},
title = {Attitudes toward Vehicle-Based Sensing and Recording},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2806064},
doi = {10.1145/2750858.2806064},
abstract = {Vehicles increasingly include features that rely on hi-tech sensors and recording; however, little is known of public attitudes toward such recording. We use two studies, an online survey (n=349) and an interview-based study (n=15), to examine perceptions of vehicle-based sensing and recording. We focus on: 1) how vehicle-based recording and sensing may differ from perceptions of current recording; 2) factors that impact comfort with vehicle-based recording for hypothetical drivers versus bystanders; and 3) perceptions of potential privacy-preserving techniques. We find that vehicle-based recording challenges current mental models of recording awareness. Comfort tends to depend on perceived benefits, which can vary by stakeholder type. Perceived privacy in spaces near cars can also impact comfort and reflect mental models of private spaces as well as the range of potentially sensitive activities people perform in and near cars. Privacy-preserving techniques may increase perceived comfort but may require addressing trust and usability issues.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1017–1028},
numpages = {12},
keywords = {privacy, vehicles, perceived benefits, privacy-preserving mechanisms, sensors, cars, attitudes, recording, cameras},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807545,
author = {Thomaz, Edison and Essa, Irfan and Abowd, Gregory D.},
title = {A Practical Approach for Recognizing Eating Moments with Wrist-Mounted Inertial Sensing},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807545},
doi = {10.1145/2750858.2807545},
abstract = {Recognizing when eating activities take place is one of the key challenges in automated food intake monitoring. Despite progress over the years, most proposed approaches have been largely impractical for everyday usage, requiring multiple on-body sensors or specialized devices such as neck collars for swallow detection. In this paper, we describe the implementation and evaluation of an approach for inferring eating moments based on 3-axis accelerometry collected with a popular off-the-shelf smartwatch. Trained with data collected in a semi-controlled laboratory setting with 20 subjects, our system recognized eating moments in two free-living condition studies (7 participants, 1 day; 1 participant, 31 days), with F-scores of 76.1% (66.7% Precision, 88.8% Recall), and 71.3% (65.2% Precision, 78.6% Recall). This work represents a contribution towards the implementation of a practical, automated system for everyday food intake monitoring, with applicability in areas ranging from health research and food journaling.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1029–1040},
numpages = {12},
keywords = {dietary intake, activity recognition, automated dietary assessment, inertial sensors, food journaling},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807551,
author = {Hammerla, Nils Y. and Pl\"{o}tz, Thomas},
title = {Let's (Not) Stick Together: Pairwise Similarity Biases Cross-Validation in Activity Recognition},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807551},
doi = {10.1145/2750858.2807551},
abstract = {The ability to generalise towards either new users or unforeseen behaviours is a key requirement for activity recognition systems in ubiquitous computing. Differences in recognition performance for the two application cases can be significant, and user-dependent performance is typically assumed to be an upper bound on performance. We demonstrate that this assumption does not hold for the widely used cross-validation evaluation scheme that is typically employed both during system bootstrapping and for reporting results. We describe how the characteristics of segmented time-series data render random cross-validation a poor fit, as adjacent segments are not statistically independent. We develop an alternative approach -- meta-segmented cross validation -- that explicitly circumvents this issue and evaluate it on two data-sets. Results indicate a significant drop in performance across a variety of feature extraction and classification methods if this bias is removed, and that prolonged, repetitive activities are particularly affected.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1041–1051},
numpages = {11},
keywords = {cross validation, evaluation, activity recognition, model selection},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804256,
author = {Nguyen, Le T. and Zeng, Ming and Tague, Patrick and Zhang, Joy},
title = {I Did Not Smoke 100 Cigarettes Today! Avoiding False Positives in Real-World Activity Recognition},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804256},
doi = {10.1145/2750858.2804256},
abstract = {Activity recognition (AR) systems are typically built and evaluated on a predefined set of activities. AR systems work best if the test data contains and only contains these predefined activities. In real world applications, AR systems trained in this manner generate serious false positives, for example if "smoking" is one of the activities in the training data but "lifting weights" is not. Due to the similarity of two activities, an AR system may report a user smoking 100 times a day but he actually did a bicep workout 100 times. In this work, we propose a new approach to train an AR system leveraging the large quantity of unlabeled data which reflects activities users perform in real life. The proposed mPUL (Multi-class Positive and Unlabeled Learning) approach significantly reduces the false positives. We argue that mPUL is a much more effective training method for real-world AR applications.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1053–1063},
numpages = {11},
keywords = {semi-supervised learning, open-world, multi-class positive and unlabeled learning, activity recognition},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807546,
author = {Bourgeois, Jacky and Foell, Stefan and Kortuem, Gerd and Price, Blaine A. and van der Linden, Janet and Elbanhawy, Eiman Y. and Rimmer, Christopher},
title = {Harvesting Green Miles from My Roof: An Investigation into Self-Sufficient Mobility with Electric Vehicles},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807546},
doi = {10.1145/2750858.2807546},
abstract = {Electric vehicles are an increasingly attractive option for households to reduce carbon emissions, especially when they are powered by renewable energy. In this paper we report the results of an 18-month field trial investigating the desirability and feasibility of powering electric vehicles (EVs) with domestic solar electricity. Based on extensive collection of data from 7 households including over 75,000 miles of daily EV use, home electricity consumption and generation, and in-depth interviews with householders we develop a detailed understanding of what drives EV decisions in households, quantify to what extent our participating households currently power their EVs with solar electricity, and investigate how feasible the vision of "self-sustaining electric mobility" is. We use this understanding to draw implications for future research into supporting emerging practices of EV drivers.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1065–1076},
numpages = {12},
keywords = {sustainability, data mining, electric vehicle, solar electricity, microgeneration, user study, domestic charging},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804274,
author = {Brush, A. J. Bernheim and Krumm, John and Gupta, Sidhant and Patel, Shwetak},
title = {EVHomeShifter: Evaluating Intelligent Techniques for Using Electrical Vehicle Batteries to Shift When Homes Draw Energy from the Grid},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804274},
doi = {10.1145/2750858.2804274},
abstract = {Time of use tiered pricing schedules encourage shifting electricity demand from peak to off-peak hours. Charging times for electric vehicles (EV) can be shifted into overnight hours, which are usually off-peak. EVs can also be used as energy storage devices, available during certain peak hours to power a house with electricity stored during off-peak hours. Studies suggest both techniques are practical, but were based on simulated demand patterns or large commercial fleets. To investigate feasibility on a per home basis, we collected data from 15 EV homes using the Lab of Things sensing infrastructure. We evaluate a scheme that powers homes with their car battery during expensive electricity periods and then charges the battery during cheaper periods. We show an average potential savings of $10.91/month for shifting charging times, and an additional $13.58/month for powering the home from the EV, even accounting for the inefficiencies of electric conversion.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1077–1088},
numpages = {12},
keywords = {load leveling, home energy use, sustainability, residential, sensing, lab of things, electric vehicles},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805831,
author = {Huang, Chuan-Che (Jeff) and Yang, Rayoung and Newman, Mark W.},
title = {The Potential and Challenges of Inferring Thermal Comfort at Home Using Commodity Sensors},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805831},
doi = {10.1145/2750858.2805831},
abstract = {For decades, researchers have investigated ways to infer human thermal comfort. Studies have usually required cumbersome sensors and human observers, making them inappropriate for use in naturalistic settings such as the home. Emerging wearable and smart home sensing devices offer the opportunity to develop new models of thermal comfort based on data collected in-situ. To explore this opportunity, we deployed a sensing system in seven homes and collected self-report data from 11 participants for four weeks. Our system captures many factors employed in previous thermal comfort research, as well as new factors (e.g., activity level, sweat level). Machine learning-based models derived from the collected data show improvement over previous techniques, however significant prediction errors remain. In analyzing these errors we identify six problems that pose challenges for inferring comfort in the wild. Based on our findings, we suggest techniques to improve future in-situ thermal comfort modeling efforts.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1089–1100},
numpages = {12},
keywords = {smart home, thermal comfort, wearable sensors},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805835,
author = {Nakamura, Shoko and Shigaki, Saeko and Hiromori, Akihito and Yamaguchi, Hirozumi and Higashino, Teruo},
title = {A Model-Based Approach to Support Smart and Social Home Living},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805835},
doi = {10.1145/2750858.2805835},
abstract = {A system to improve the quality of human life is developed and proposed. A model-based approach is used where smart home residents, appliances, energy sources and correlations among them are comprehensively modeled. The model was integrated with activity recognition information that enables the system to suggest smart life tips that provide advice to residents in a non-intrusive way. A crowd-sourced large-scale survey of 1,000 subjects was conducted that enabled important tips for improving the quality of human life to be quantified. On the basis of the survey results, quantitative metrics and strategies were designed for presenting suitable tips in a timely manner depending on the lifestyle of subjects. The system was evaluated by (1) 34 actual subjects in virtual smart homes and (2) family members in an actual house in an experiment lasting more than one month in which actual sensors were deployed.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1101–1105},
numpages = {5},
keywords = {crowdsourcing, smart home, smart life support},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805833,
author = {Wang, Haoyu and Hong, Jason and Guo, Yao},
title = {Using Text Mining to Infer the Purpose of Permission Use in Mobile Apps},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805833},
doi = {10.1145/2750858.2805833},
abstract = {Understanding the purpose of why sensitive data is used could help improve privacy as well as enable new kinds of access control. In this paper, we introduce a new technique for inferring the purpose of sensitive data usage in the context of Android smartphone apps. We extract multiple kinds of features from decompiled code, focusing on app-specific features and text-based features. These features are then used to train a machine learning classifier. We have evaluated our approach in the context of two sensitive permissions, namely ACCESS_FINE_LOCATION and READ_CONTACT_LIST, and achieved an accuracy of about 85% and 94% respectively in inferring purposes. We have also found that text-based features alone are highly effective in inferring purposes.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1107–1118},
numpages = {12},
keywords = {permission, purpose, mobile applications, privacy, Android},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805827,
author = {Higuchi, Takamasa and Martin, Paul and Chakraborty, Supriyo and Srivastava, Mani},
title = {AnonyCast: Privacy-Preserving Location Distribution for Anonymous Crowd Tracking Systems},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805827},
doi = {10.1145/2750858.2805827},
abstract = {Fusion of infrastructure-based pedestrian tracking systems and embedded sensors on mobile devices holds promise for providing accurate positioning in large public buildings. However, privacy concerns regarding handling of sensitive user location data potentially disrupt the adoption of such systems. This paper presents AnonyCast, a novel privacy-aware mechanism for delivering precise location information measured by crowd-tracking systems to individual pedestrians' smartphones. AnonyCast uses sparsely placed Bluetooth Low Energy transmitters to advertise location-dependent, time-varying keys. Using location measurements, AnonyCast estimates a subset of keys that each pedestrian's phone receives along its path. By combining a cryptography scheme called CP-ABE with a novel greedy algorithm for key selection, it encrypts each path before publishing, allowing users to decrypt only their own trajectories. The results from field experiments show that AnonyCast delivers accurate locations over 84% of time, bounding probability of unauthorized access to one's location below 1%.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1119–1130},
numpages = {12},
keywords = {crowd tracking, location privacy, trajectory identification, ciphertext-policy attribute-based encryption},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804281,
author = {Guha, Shion and Wicker, Stephen B.},
title = {Spatial Subterfuge: An Experience Sampling Study to Predict Deceptive Location Disclosures},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804281},
doi = {10.1145/2750858.2804281},
abstract = {Prior research shows that people often engage in deception when sharing location. Privacy concerns, social surveillance and impression management are the primary drivers of these types of behaviors. One methodological question that arises in this research context is the problem of reliable measurement to study predictors of deceptive location disclosure from usage data. In this note, we propose a simple experience sampling method (ESM) approach that is useful for studying this phenomenon. We describe our ESM deployment and report the results of a long term, quantitative study of 204 foursquare users over 1 year. Results indicate that physical distance, tie strength and order of visibility on the foursquare feed are significant predictors (with moderate to high effect sizes) of deceptive location disclosure. We connect these findings to the rich tradition of location disclosure behavior research in ubiquitous computing.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1131–1135},
numpages = {5},
keywords = {ESM, foursquare, privacy, impressions, deception, visibility},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805836,
author = {Naghizade, Elham and Bailey, James and Kulik, Lars and Tanin, Egemen},
title = {How Private Can i Be among Public Users?},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805836},
doi = {10.1145/2750858.2805836},
abstract = {People are increasingly volunteering personal data. Services based on this data rely on a high number of participants and high data quality. Personal data is often seen as private and individuals are more likely to provide such data if they can choose its granularity, e.g., instead of an exact value, they may provide a range. Focusing on spatial crowdsourced data, this work aims to determine whether the common method of coarsening location data of privacy-conscious individuals is an effective approach if fine-grained location data has also been submitted by privacy-apathetic users. We propose a novel inference attack to refine the location of privacy-conscious individuals. Our experiments suggest that even with a dataset that is mostly populated with privacy-conscious users, our technique succeeds with high precision and recall.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1137–1141},
numpages = {5},
keywords = {matrix factorization, crowdsourced trajectory database, privacy},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2806060,
author = {Chollet, Mathieu and W\"{o}rtwein, Torsten and Morency, Louis-Philippe and Shapiro, Ari and Scherer, Stefan},
title = {Exploring Feedback Strategies to Improve Public Speaking: An Interactive Virtual Audience Framework},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2806060},
doi = {10.1145/2750858.2806060},
abstract = {Good public speaking skills convey strong and effective communication, which is critical in many professions and used in everyday life. The ability to speak publicly requires a lot of training and practice. Recent technological developments enable new approaches for public speaking training that allow users to practice in a safe and engaging environment. We explore feedback strategies for public speaking training that are based on an interactive virtual audience paradigm. We investigate three study conditions: (1) a non-interactive virtual audience (control condition), (2) direct visual feedback, and (3) nonverbal feedback from an interactive virtual audience. We perform a threefold evaluation based on self-assessment questionnaires, expert assessments, and two objectively annotated measures of eye-contact and avoidance of pause fillers. Our experiments show that the interactive virtual audience brings together the best of both worlds: increased engagement and challenge as well as improved public speaking skills as judged by experts.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1143–1154},
numpages = {12},
keywords = {virtual reality, public speaking, multimodal interfaces, training},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807534,
author = {Khan, Aftab and Mellor, Sebastian and Berlin, Eugen and Thompson, Robin and McNaney, Roisin and Olivier, Patrick and Pl\"{o}tz, Thomas},
title = {Beyond Activity Recognition: Skill Assessment from Accelerometer Data},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807534},
doi = {10.1145/2750858.2807534},
abstract = {The next generation of human activity recognition applications in ubiquitous computing scenarios focuses on assessing the quality of activities, which goes beyond mere identification of activities of interest. Objective quality assessments are often difficult to achieve, hard to quantify, and typically require domain specific background information that bias the overall judgement and limit generalisation. In this paper we propose a framework for skill assessment in activity recognition that enables automatic quality analysis of human activities. Our approach is based on a hierarchical rule induction technique that effectively abstracts from noise-prone activity data and assesses activity data at different temporal contexts. Our approach requires minimal domain specific knowledge about the activities of interest, which makes it largely generalisable. By means of an extensive case study we demonstrate the effectiveness of the proposed framework in the context of dexterity training of 15 medical students engaging in 50 attempts of surgical activities.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1155–1166},
numpages = {12},
keywords = {classification, rule induction, accelerometer, activity recognition, skill assessment},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804265,
author = {Fung, Michelle and Jin, Yina and Zhao, RuJie and Hoque, Mohammed (Ehsan)},
title = {ROC Speak: Semi-Automated Personalized Feedback on Nonverbal Behavior from Recorded Videos},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804265},
doi = {10.1145/2750858.2804265},
abstract = {We present a framework that couples computer algorithms with human intelligence in order to automatically sense and interpret nonverbal behavior. The framework is cloud-enabled and ubiquitously available via a web browser, and has been validated in the context of public speaking. The system automatically captures audio and video data in-browser through the user's webcam, and then analyzes the data for smiles, movement, and volume modulation. Our framework allows users to opt in and receive subjective feedback from Mechanical Turk workers ("Turkers"). Our system synthesizes the Turkers' interpretations, ratings, and comment rankings with the machine-sensed data and enables users to interact with, explore, and visualize personalized and presentational feedback. Our results provide quantitative and qualitative evidence in support of our proposed synthesized feedback, relative to video-only playback with impersonal tips. Our interface can be seen here: http://tinyurl.com/feedback-ui (Supported in Google Chrome.)},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1167–1178},
numpages = {12},
keywords = {automated feedback, nonverbal behavior interpretation, public speaking, automated multimodal affect sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805829,
author = {Ryan, Cynthia and Ciesinski, Katherine and Hoque, Mohammed (Ehsan)},
title = {Vowel Shapes: An Open-Source, Interactive Tool to Assist Singers with Learning Vowels},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805829},
doi = {10.1145/2750858.2805829},
abstract = {The mastery of vowel production is central to developing vocal technique and may be influenced by language, musical context or a coach's direction. Currently, students learn through verbal descriptions, demonstration of correct vowel sounds, and customized exercises. Vowel Shapes is an interactive practice tool that automatically captures and visualizes vowel sounds in real time to assist singers in correctly producing target vowels. The system may be used during a lesson or as a practice tool when an instructor is not present. Our system's design was informed by iterative evaluations with 14 students and their vocal professor from the Eastman School of Music, University of Rochester. Results from an exploratory evaluation of the system with 10 students indicated that 70% of the participants improved their time to reach an instructor-defined target. 90% of the students in the evaluation would use this system during practice sessions.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1179–1183},
numpages = {5},
keywords = {singing, vowels, visualization, interdisciplinary design, auditory I/O and sound in the UI, interactive},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807550,
author = {Singh, Indrajeet and Krishnamurthy, Srikanth V. and Madhyastha, Harsha V. and Neamtiu, Iulian},
title = {ZapDroid: Managing Infrequently Used Applications on Smartphones},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807550},
doi = {10.1145/2750858.2807550},
abstract = {User surveys have shown that a typical user has over a hundred apps on her smartphone [1], but stops using many of them. We conduct a user study to identify such unused apps, which we call zombies, and show via experiments that zombie apps consume significant resources on a user's smartphone and access her private information. We then design and build ZapDroid, which enables users to detect and silo zombie apps in an effective way to prevent their undesired activities. If and when the user wishes to resume using such an app, ZapDroid restores the app quickly and effectively. Our evaluations show that: (i) ZapDroid saves twice the energy from unwanted zombie app behaviors as compared to apps from the Play Store that kill background unwanted processes, and (ii) it effectively prevents zombie apps from using undesired permissions. In addition, ZapDroid is energ-efficient, consuming &lt; 4% of the battery per day.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1185–1196},
numpages = {12},
keywords = {energy, smartphones, privacy},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807542,
author = {Jones, Simon L. and Ferreira, Denzil and Hosio, Simo and Goncalves, Jorge and Kostakos, Vassilis},
title = {Revisitation Analysis of Smartphone App Use},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807542},
doi = {10.1145/2750858.2807542},
abstract = {We present a revisitation analysis of smartphone use to investigate the question: do smartphones induce usage habits? We analysed three months of application launch logs from 165 users in naturalistic settings. Our analysis reveals distinct clusters of applications and users which share similar revisitation patterns. However, we show that much of smartphone usage on a macro-level is very similar to web browsing on desktops, and thus argue that smartphone usage is driven by innate service needs rather than technology characteristics. On the other hand, on a micro-level we identify unique characteristics in smartphone usage, and we present a rudimentary model that accounts for 92% in the variability of our smartphone use.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1197–1208},
numpages = {12},
keywords = {habits, revisitation, user behaviour, smartphone use},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804292,
author = {Mathur, Arunesh and Schlotfeldt, Brent and Chetty, Marshini},
title = {A Mixed-Methods Study of Mobile Users' Data Usage Practices in South Africa},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804292},
doi = {10.1145/2750858.2804292},
abstract = {With a shift towards usage-based billing, the questions of how data costs affect mobile Internet use and how users manage mobile data arise. In this paper, we describe a mixed-methods study of mobile phone users' data usage practices in South Africa, a country where usage-based billing is prevalent and where data costs are high, to answer these questions. We do so using a large scale survey, in-depth interviews, and logs of actual data usage over time. Our findings suggest that unlike in more developed settings, when data is limited or expensive, mobile Internet users are extremely cost-conscious, and employ various strategies to optimize mobile data usage such as actively disconnecting from the mobile Internet to save data. Based on these findings, we suggest how the Ubicomp and related research communities can better support users that need to carefully manage their data to optimize costs.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1209–1220},
numpages = {12},
keywords = {mobile data costs, mobile data tracking, mobile data},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805837,
author = {Jesdabodi, Chakajkla and Maalej, Walid},
title = {Understanding Usage States on Mobile Devices},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805837},
doi = {10.1145/2750858.2805837},
abstract = {Nowadays, mobile apps are used for nearly every situation: for planning the day, communicating with colleagues, ordering goods, or entertaining and socializing. To understand users expectations in each situation and to provide context-aware services, researchers and app vendors started to capture users' interaction with the smartphone and to model user's behavior. This paper reports on a behavioral study based on app usage data logged over one year and the corresponding apps descriptions from the app store. Using Topic Modeling and clustering techniques, we segmented the usage data into meaningful clusters that correspond to different "states", in which users normally use their smartphone, e.g. socializing or consuming media. Researchers and app-vendors can use the insights from our work to improve their contextual recommendation techniques and the overall usage experience.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1221–1225},
numpages = {5},
keywords = {behavioral profiles, apps, usage data, intent identification},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807532,
author = {Ackad, Christopher and Clayphan, Andrew and Tomitsch, Martin and Kay, Judy},
title = {An In-the-Wild Study of Learning Mid-Air Gestures to Browse Hierarchical Information at a Large Interactive Public Display},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807532},
doi = {10.1145/2750858.2807532},
abstract = {This paper describes the design and evaluation of our Media Ribbon, a large public interactive display for browsing hierarchical information, with mid-air gestures. Browsing a hierarchical information space is a fundamental form of interaction. Designing learnable mid-air gestures is a current challenge for large display interaction. Our in-the-wild evaluation draws on 41 days of quantitative log data, with 4484 gestures detected, and qualitative data from 15 interviews, and associated video. We explored: whether our design enabled people to learn the gestures; how our tutorial and feedback mechanisms supported learning; and the effectiveness of support for browsing hierarchical information. Our contributions are: (1) design of large public display for browsing of hierarchical information; (2) with its gesture set; (3) insights into the ways people learn and use this interface in our context; and (4) guidelines for designing learnable mid-air gestures.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1227–1238},
numpages = {12},
keywords = {user centred design and pervasive computing, gestural interaction, interactive public information displays},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805842,
author = {Cheung, Victor and Scott, Stacey D.},
title = {A Laboratory-Based Study Methodology to Investigate Attraction Power of Large Public Interactive Displays},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805842},
doi = {10.1145/2750858.2805842},
abstract = {A known challenge of designing large public interactive displays is to create an interface that attracts a passerby's attention and communicates its interactivity. However, typical "in-the-wild" field study methods of assessing public display design solutions require costly system implementation and deployment, creating challenges for assessing early stage design concepts. Such studies also limit the amount of experimental control researchers have over the environment, limiting the precision of results. To address these issues, we developed a complementary laboratory-based study methodology that employs experimental deception to assess the ability of an interface design solution to attract a passerby's attention. Our methodology enables more rigorous control of confounding factors, study of early-stage prototypes, and requires minimal setup. We used this methodology to assess existing visual design solutions for drawing attention and enticing interaction, compare our results to previous studies, and reflect on the benefits and limitations of this assessment approach.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1239–1250},
numpages = {12},
keywords = {large interactive displays, public space, experimental design, laboratory study},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807518,
author = {Williamson, Julie R. and Sund\'{e}n, Daniel and Bradley, Jay},
title = {GlobalFestival: Evaluating Real World Interaction on a Spherical Display},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807518},
doi = {10.1145/2750858.2807518},
abstract = {Spherical displays present compelling opportunities for interaction in public spaces. However, there is little research into how touch interaction should control a spherical surface or how these displays are used in real world settings. This paper presents an in the wild deployment of an application for a spherical display called GlobalFestival that utilises two different touch interaction techniques. The first version of the application allows users to spin and tilt content on the display, while the second version only allows spinning the content. During the 4-day deployment, we collected overhead video data and on-display interaction logs. The analysis brings together quantitative and qualitative methods to understand how users approach and move around the display, how on screen interaction compares in the two versions of the application, and how the display supports social interaction given its novel form factor.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1251–1261},
numpages = {11},
keywords = {spherical displays, human computer interaction, multi-touch interaction, in the wild evaluation},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804255,
author = {Walter, Robert and Bulling, Andreas and Lindlbauer, David and Schuessler, Martin and M\"{u}ller, J\"{o}rg},
title = {Analyzing Visual Attention during Whole Body Interaction with Public Displays},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804255},
doi = {10.1145/2750858.2804255},
abstract = {While whole body interaction can enrich user experience on public displays, it remains unclear how common visualizations of user representations impact users' ability to perceive content on the display. In this work we use a head-mounted eye tracker to record visual behavior of 25 users interacting with a public display game that uses a silhouette user representation, mirroring the users' movements. Results from visual attention analysis as well as post-hoc recall and recognition tasks on display contents reveal that visual attention is mostly on users' silhouette while peripheral screen elements remain largely unattended. In our experiment, content attached to the user representation attracted significantly more attention than other screen contents, while content placed at the top and bottom of the screen attracted significantly less. Screen contents attached to the user representation were also significantly better remembered than those at the top and bottom of the screen.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1263–1267},
numpages = {5},
keywords = {public displays, mobile eye tracking, visual attention, user representation, whole body interaction},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2807533,
author = {Inoue, Sozo and Ueda, Naonori and Nohara, Yasunobu and Nakashima, Naoki},
title = {Mobile Activity Recognition for a Whole Day: Recognizing Real Nursing Activities with Big Dataset},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2807533},
doi = {10.1145/2750858.2807533},
abstract = {In this paper, we provide a real nursing data set for mobile activity recognition that can be used for supervised machine learning, and big data combined the patient medical records and sensors attempted for 2 years, and also propose a method for recognizing activities for a whole day utilizing prior knowledge about the activity segments in a day. Furthermore, we demonstrate data mining by applying our method to the bigger data with additional hospital data. In the proposed method, we 1) convert a set of segment timestamps into a prior probability of the activity segment by exploiting the concept of importance sampling, 2) obtain the likelihood of traditional recognition methods for each local time window within the segment range, and, 3) apply Bayesian estimation by marginalizing the conditional probability of estimating the activities for the segment samples. By evaluating with the dataset, the proposed method outperformed the traditional method without using the prior knowledge by 25.81% at maximum by balanced classification rate. Moreover, the proposed method significantly reduces duration errors of activity segments from 324.2 seconds of the traditional method to 74.6 seconds at maximum. We also demonstrate the data mining by applying our method to bigger data in a hospital.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1269–1280},
numpages = {12},
keywords = {mobile activity recognition, dataset, domain-specific activity recognition, nursing activity},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805828,
author = {Zhang, Fuzheng and Yuan, Nicholas Jing and Zheng, Kai and Lian, Defu and Xie, Xing and Rui, Yong},
title = {Mining Consumer Impulsivity from Offline and Online Behavior},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805828},
doi = {10.1145/2750858.2805828},
abstract = {Consumer impulsivity is a psychological feature characterizing the impulsive buying tendency. In this paper, by bridging consumer behavior with perceived stimuli on social networks, we present a computational framework, termed Consumer Impulsivity Model (CIM), for exploring a consumer's impulsivity in both offline and online context: consumption-related location visit indicating consumption patterns in the physical realm, and online shopping behavior indicating economic activities on the Internet. To demonstrate the effectiveness of CIM, we conduct extensive experiments, with a large dataset we have collected from thousands of consumers. The results show that 1) for 103 subjects, the inferred consumer impulsivity has a positive Pearson correlation with survey results in the situation of product and product category, respectively. 2) females inferred impulsivity is higher than males on average in the situation of product and product category, respectively. Age has a negative Pearson correlation with inferred impulsivity in the situation of POI, POI category and product category, respectively. 3) for next behavior prediction, our model defeats several presented baselines. These results suggest that our framework CIM offers a powerful paradigm for 1) presenting an effective measurement for consumer impulsivity. 2) uncovering the correlation between consumer impulsivity and demographic factors and 3) revealing that the introduction of impulsivity is effective in predicting consumer behavior.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1281–1292},
numpages = {12},
keywords = {consumer impulsivity, online shopping, check-in},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2805845,
author = {Canzian, Luca and Musolesi, Mirco},
title = {Trajectories of Depression: Unobtrusive Monitoring of Depressive States by Means of Smartphone Mobility Traces Analysis},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2805845},
doi = {10.1145/2750858.2805845},
abstract = {One of the most interesting applications of mobile sensing is monitoring of individual behavior, especially in the area of mental health care. Most existing systems require an interaction with the device, for example they may require the user to input his/her mood state at regular intervals. In this paper we seek to answer whether mobile phones can be used to unobtrusively monitor individuals affected by depressive mood disorders by analyzing only their mobility patterns from GPS traces. In order to get ground-truth measurements, we have developed a smartphone application that periodically collects the locations of the users and the answers to daily questionnaires that quantify their depressive mood. We demonstrate that there exists a significant correlation between mobility trace characteristics and the depressive moods. Finally, we present the design of models that are able to successfully predict changes in the depressive mood of individuals by analyzing their movements.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1293–1304},
numpages = {12},
keywords = {spatial statistics, GPS traces, depression, mobile sensing},
location = {Osaka, Japan},
series = {UbiComp '15}
}

@inproceedings{10.1145/2750858.2804290,
author = {Gouveia, R\'{u}ben and Karapanos, Evangelos and Hassenzahl, Marc},
title = {How Do We Engage with Activity Trackers? A Longitudinal Study of Habito},
year = {2015},
isbn = {9781450335744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2750858.2804290},
doi = {10.1145/2750858.2804290},
abstract = {We report on a 10-month in-the-wild study of the adoption, engagement and discontinuation of an activity tracker called Habito, by a sample of 256 users who installed the tracker on their own volition. We found 'readiness' to behavior change to be a strong predictor of adoption (which ranged from 56% to 20%). Among adopters, only a third updated their daily goal, which in turn impacted their physical activity levels. The use of the tracker was dominated by glances -- brief, 5-sec sessions where users called the app to check their current activity levels with no further interaction, while users displayed true lack of interest in historical data. Textual feedback proved highly effective in fueling further engagement with the tracker as well as inducing physical activity. We propose three directions for design: designing for different levels of 'readiness', designing for multilayered and playful goal setting, and designing for sustained engagement.},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1305–1316},
numpages = {12},
keywords = {personal informatics, persuasive technologies, behavior change technologies, physical activity trackers},
location = {Osaka, Japan},
series = {UbiComp '15}
}

