@inproceedings{10.1145/2971648.2990469,
author = {Picard, Rosalind},
title = {Emotion Technology, Wearables, and Surprises},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2990469},
doi = {10.1145/2971648.2990469},
abstract = {Could we help people have healthier lives and better experiences if computers could measure and help communicate our emotion? Years ago, my students at MIT and I began to design, build, and test both wearable and other sensors for recognizing emotion. We designed studies, gathered data, and developed signal processing and machine learning techniques to see what could be reliably extracted. In this talk I will highlight several of the most surprising findings during this adventure. These include new insights about the "true smile of happiness," discovering that regular cameras (and your smartphone, even in your handbag) can compute some of your biosignals, finding electrical signals on the wrist that give insight into deep brain activity, and learning surprising implications of wearable sensing for autism, anxiety, depression, sleep-memory consolidation, epilepsy, and more.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
articleno = {1},
numpages = {1},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971691,
author = {Riboni, Daniele and Sztyler, Timo and Civitarese, Gabriele and Stuckenschmidt, Heiner},
title = {Unsupervised Recognition of Interleaved Activities of Daily Living through Ontological and Probabilistic Reasoning},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971691},
doi = {10.1145/2971648.2971691},
abstract = {Recognition of activities of daily living (ADLs) is an enabling technology for several ubiquitous computing applications. In this field, most activity recognition systems rely on supervised learning methods to extract activity models from labeled datasets. An inherent problem of that approach consists in the acquisition of comprehensive activity datasets, which is expensive and may violate individuals' privacy. The problem is particularly challenging when focusing on complex ADLs, which are characterized by large intra- and inter-personal variability of execution. In this paper, we propose an unsupervised method to recognize complex ADLs exploiting the semantics of activities, context data, and sensing devices. Through ontological reasoning, we derive semantic correlations among activities and sensor events. By matching observed sensor events with semantic correlations, a statistical reasoner formulates initial hypotheses about the occurred activities. Those hypotheses are refined through probabilistic reasoning, exploiting semantic constraints derived from the ontology. Extensive experiments with real-world datasets show that the accuracy of our unsupervised method is comparable to the one of state of the art supervised approaches.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1–12},
numpages = {12},
keywords = {activity recognition, probabilistic reasoning, ontological reasoning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971701,
author = {Yao, Lina and Nie, Feiping and Sheng, Quan Z. and Gu, Tao and Li, Xue and Wang, Sen},
title = {Learning from Less for Better: Semi-Supervised Activity Recognition via Shared Structure Discovery},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971701},
doi = {10.1145/2971648.2971701},
abstract = {Despite the active research into, and the development of, human activity recognition over the decades, existing techniques still have several limitations, in particular, poor performance due to insufficient ground-truth data and little support of intra-class variability of activities (i.e., the same activity may be performed in different ways by different individuals, or even by the same individuals with different time frames). Aiming to tackle these two issues, in this paper, we present a robust activity recognition approach by extracting the intrinsic shared structures from activities to handle intra-class variability, and the approach is embedded into a semi-supervised learning framework by utilizing the learned correlations from both labeled and easily-obtained unlabeled data simultaneously. We use l2,1 minimization on both loss function and regularizations to effectively resist outliers in noisy sensor data and improve recognition accuracy by discerning underlying commonalities from activities. Extensive experimental evaluations on four community-contributed public datasets indicate that with little training samples, our proposed approach outperforms a set of classical supervised learning methods as well as those recently proposed semi-supervised approaches.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {13–24},
numpages = {12},
keywords = {optimization, semi-supervised learning, shared structure analysis, activity recognition},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971744,
author = {Wang, Hao and Zhang, Daqing and Ma, Junyi and Wang, Yasha and Wang, Yuxiang and Wu, Dan and Gu, Tao and Xie, Bing},
title = {Human Respiration Detection with Commodity Wifi Devices: Do User Location and Body Orientation Matter?},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971744},
doi = {10.1145/2971648.2971744},
abstract = {Recent research has demonstrated the feasibility of detecting human respiration rate non-intrusively leveraging commodity WiFi devices. However, is it always possible to sense human respiration no matter where the subject stays and faces? What affects human respiration sensing and what's the theory behind? In this paper, we first introduce the Fresnel model in free space, then verify the Fresnel model for WiFi radio propagation in indoor environment. Leveraging the Fresnel model and WiFi radio propagation properties derived, we investigate the impact of human respiration on the receiving RF signals and develop the theory to relate one's breathing depth, location and orientation to the detectability of respiration. With the developed theory, not only when and why human respiration is detectable using WiFi devices become clear, it also sheds lights on understanding the physical limit and foundation of WiFi-based sensing systems. Intensive evaluations validate the developed theory and case studies demonstrate how to apply the theory to the respiration monitoring system design.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {25–36},
numpages = {12},
keywords = {wifi, channel state information (csi), the fresnel zone},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971716,
author = {Lavania, Chandrashekhar and Thulasidasan, Sunil and LaMarca, Anthony and Scofield, Jeffrey and Bilmes, Jeff},
title = {A Weakly Supervised Activity Recognition Framework for Real-Time Synthetic Biology Laboratory Assistance},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971716},
doi = {10.1145/2971648.2971716},
abstract = {We describe the design of a hybrid system -- a combination of a Dynamic Graphical Model (DGM) with a Deep Neural Network (DNN) -- to identify activities performed during synthetic biology experiments. The purpose is to provide real-time feedback to experimenters, thus helping to reduce human errors and improve experimental reproducibility. The data consists of unlabeled videos of recorded experiments and "weakly supervised" information (i.e., "theoretical" and asynchronous knowledge of sets of high level activity sequences in the experiment) used to train the system. Multiple activity sequences are modeled using a trellis, and deep features are extracted from video images. Model performance is accessed using real-time online statistical inference. The trellis incorporates variations during experiment execution, making our model very general and capable of high performance.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {37–48},
numpages = {12},
keywords = {synthetic biology, activity recognition, dynamic graphical models, deep learning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971722,
author = {Barbosa, Nat\~{a} M. and Hayes, Jordan and Wang, Yang},
title = {UniPass: Design and Evaluation of a Smart Device-Based Password Manager for Visually Impaired Users},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971722},
doi = {10.1145/2971648.2971722},
abstract = {Visually impaired users face various challenges in web authentication. We designed UniPass, an accessible password manager for visually impaired users based on a smart device. To evaluate UniPass, we tested and compared UniPass with two commercial password managers: LastPass, a popular password manager and StrongPass, a smart device-based password manager. Our study results of ten users, six blind and four with low vision, suggest that password managers are a promising authentication approach for visually impaired users. Participants using UniPass had the highest task completion rate and took the shortest time to complete an authentication related task. Furthermore, the majority (seven out of ten) of our participants preferred UniPass over LastPass and StrongPass.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {49–60},
numpages = {12},
keywords = {password manager, accessibility, visual impairments, smart device, authentication},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971723,
author = {Szpiro, Sarit and Zhao, Yuhang and Azenkot, Shiri},
title = {Finding a Store, Searching for a Product: A Study of Daily Challenges of Low Vision People},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971723},
doi = {10.1145/2971648.2971723},
abstract = {Visual impairments encompass a range of visual abilities. People with low vision have functional vision and thus their experiences are likely to be different from people with no vision. We sought to answer two research questions: (1) what challenges do low vision people face when performing daily activities and (2) what aids (high- and low-tech) do low vision people use to alleviate these challenges? Our goal was to reveal gaps in current technologies that can be addressed by the UbiComp community. Using contextual inquiry, we observed 11 low vision people perform a wayfinding and shopping task in an unfamiliar environment. The task involved wayfinding and searching and purchasing a product. We found that, although there are low vision aids on the market, participants mostly used their smartphones, despite interface accessibility challenges. While smartphones helped them outdoors, participants were overwhelmed and frustrated when shopping in a store. We discuss the inadequacies of existing aids and highlight the need for systems that enhance visual information, rather than convert it to audio or tactile.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {61–72},
numpages = {12},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971730,
author = {Zhao, Yuhang and Szpiro, Sarit and Knighten, Jonathan and Azenkot, Shiri},
title = {CueSee: Exploring Visual Cues for People with Low Vision to Facilitate a Visual Search Task},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971730},
doi = {10.1145/2971648.2971730},
abstract = {Visual search is a major challenge for low vision people. Conventional vision enhancements like magnification help low vision people see more details, but cannot indicate the location of a target in a visual search task. In this paper, we explore visual cues---a new approach to facilitate visual search tasks for low vision people. We focus on product search and present CueSee, an augmented reality application on a head-mounted display (HMD) that facilitates product search by recognizing the product automatically and using visual cues to direct the user's attention to the product. We designed five visual cues that users can combine to suit their visual condition. We evaluated the visual cues with 12 low vision participants and found that participants preferred using our cues to conventional enhancements for product search. We also found that CueSee outperformed participants' best-corrected vision in both time and accuracy.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {73–84},
numpages = {12},
keywords = {low vision, head-mounted systems, augmented reality},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971734,
author = {Sarsenbayeva, Zhanna and Goncalves, Jorge and Garc\'{\i}a, Juan and Klakegg, Simon and Rissanen, Sirkka and Rintam\"{a}ki, Hannu and Hannu, Jari and Kostakos, Vassilis},
title = {Situational Impairments to Mobile Interaction in Cold Environments},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971734},
doi = {10.1145/2971648.2971734},
abstract = {We evaluate the situational impairments caused by cold ambient temperature on fine-motor movement and vigilance during mobile interaction. For this purpose, we tested two mobile phone applications that measure fine motor skills and vigilance in controlled temperature settings. Our results show that cold adversely affected participants' fine-motor skills performance, but not vigilance. Based on our results we highlight the importance of correcting measurements when investigating performance of cognitive tasks to take into account the physical element of the tasks. Finally, we identify a number of design recommendations from literature that can mitigate the adverse effect of cold ambiance on interaction with mobile devices.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {85–96},
numpages = {12},
keywords = {fine-motor movements, cold temperature, vigilance, offset, smartphones, ubiquitous computing, situational impairments},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971651,
author = {Kong, Quan and Maekawa, Takuya and Miyanishi, Taiki and Suyama, Takayuki},
title = {Selecting Home Appliances with Smart Glass Based on Contextual Information},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971651},
doi = {10.1145/2971648.2971651},
abstract = {We propose a method for selecting home appliances using a smart glass, which facilitates the control of network-connected appliances in a smart house. Our proposed method is image-based appliance selection and enables smart glass users to easily select a particular appliance by just looking at it. The main feature of our method is that it achieves high precision appliance selection using user contextual information such as position and activity, inferred from various sensor data in addition to camera images captured by the glass because such contextual information is greatly related in the home appliance that a user wants to control in her daily life. We design a state-of-the-art appliance selection method by fusing image features extracted by deep learning techniques and context information estimated by non-parametric Bayesian techniques within a framework of multiple kernel learning. Our experimental results, which use sensor data obtained in an actual house equipped with many network-connected appliances, show the effectiveness of our method.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {97–108},
numpages = {12},
keywords = {home appliances, smart glass, wearable computers},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971720,
author = {Fang, Biyi and Xu, Qiumin and Park, Taiwoo and Zhang, Mi},
title = {AirSense: An Intelligent Home-Based Sensing System for Indoor Air Quality Analytics},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971720},
doi = {10.1145/2971648.2971720},
abstract = {In the U.S., people spend approximately 90 percent of their time indoors. Unfortunately, indoor air quality (IAQ) may be two to five times worse than the air outdoors, and is often overlooked. Existing IAQ monitoring technologies focus on IAQ measurements and visualization. However, the lack of information about the pollution sources as well as the seriousness of the pollution makes people feel powerless and frustrated, resulting in the ignorance of the polluted air at their homes. In this work, we fill this critical gap by presenting AirSense, an intelligent home-based IAQ sensing system that is able to automatically detect pollution events, identify pollution sources, estimate personal exposure to indoor air pollution, and provide actionable suggestions to help people improve IAQ. We have deployed AirSense at five homes to evaluate its performance and investigate how users interact with it. We demonstrate that AirSense can accurately detect pollution events, identify pollution sources, and forecast IAQ information within five minutes in both controlled and real-world settings. We further show the great potential of AirSense in increasing users' awareness of IAQ and helping them better manage IAQ at their homes.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {109–119},
numpages = {11},
keywords = {behavior change technology, IAQ, smart home, indoor air quality, internet of things, IoT, human factors},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971757,
author = {Mennicken, Sarah and Zihler, Oliver and Juldaschewa, Frida and Molnar, Veronika and Aggeler, David and Huang, Elaine May},
title = {"It's like Living with a Friendly Stranger": Perceptions of Personality Traits in a Smart Home},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971757},
doi = {10.1145/2971648.2971757},
abstract = {Interacting with smart homes and Internet of Things devices is still far from being a seamless experience as there are often many different interfaces involved. Due to the improvements of speech recognition and synthesis, voice-based agents are becoming more common to give users a unified interface to different individual systems. These agents often exhibit human-like personality traits, such as responding in a humorous way or showing caring behavior in reminders. We are exploring this approach in the context of smart homes and home automation. Should a smart home have a proactive or passive personality? Should it try to socialize with inhabitants? What personality traits do people consider desirable or undesirable? To learn more about this design space, we created two variants of a usage scenario of a domestic routine in a smart home to demonstrate different personality trait combinations. Forty-one participants experienced the scenario and provided feedback about the designs. In this paper, we report findings about participants' preferences, how they responded to the proactive and social behavior our prototype demonstrated and implications for the design of agent-based interfaces in the home.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {120–131},
numpages = {12},
keywords = {home automation, personality, smart home, agent-based interface, internet of things},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971715,
author = {Ferdous, Hasan Shahid and Ploderer, Bernd and Davis, Hilary and Vetere, Frank and O'Hara, Kenton and Farr-Wharton, Geremy and Comber, Rob},
title = {TableTalk: Integrating Personal Devices and Content for Commensal Experiences at the Family Dinner Table},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971715},
doi = {10.1145/2971648.2971715},
abstract = {This paper joins the ubiquitous computing scholarship that investigates the use of technologies in collocated shared settings like family mealtime. Family mealtimes are an important site for fostering togetherness, sharing everyday experiences, and nurturing familial ties. While technologies, especially television and personal devices are often criticized for disrupting the social aspects of mealtimes, they are widely available and commonly used nevertheless. In this paper, we explore this tension and present a novel system TableTalk, which transforms personal devices into a communal shared display on the table to enrich mealtime interactions and experience. Our field study shows that TableTalk does not undermine togetherness, but supports familial expectations and experiences by stimulating conversation, reminiscing, bonding, education, and socializing. We discuss how technology that is sensitive to the needs of family interactions can augment the commensal experience and reflect on design choices and opportunities that contribute, rather than disrupt, family mealtimes.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {132–143},
numpages = {12},
keywords = {family mealtime, commensality, smartphone, food},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971754,
author = {Gouveia, R\'{u}ben and Pereira, F\'{a}bio and Karapanos, Evangelos and Munson, Sean A. and Hassenzahl, Marc},
title = {Exploring the Design Space of Glanceable Feedback for Physical Activity Trackers},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971754},
doi = {10.1145/2971648.2971754},
abstract = {Recent research reveals over 70% of the usage of physical activity trackers to be driven by glances -- brief, 5-second sessions where individuals check ongoing activity levels with no further interaction. This raises a question as to how to best design glanceable behavioral feedback. We first set out to explore the design space of glanceable feedback in physical activity trackers, which resulted in 21 unique concepts and 6 design qualities: being abstract, integrating with existing activities, supporting comparisons to targets and norms, being actionable, having the capacity to lead to checking habits and to act as a proxy to further engagement. Second, we prototyped four of the concepts and deployed them in the wild to better understand how different types of glanceable behavioral feedback affect user engagement and physical activity. We found significant differences among the prototypes, all in all, highlighting the surprisingly strong effect glanceable feedback has on individuals' behaviors.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {144–155},
numpages = {12},
keywords = {personal informatics, physical activity tracking, glanceable displays, behavioral feedback interfaces},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971692,
author = {Wang, Ge and Qian, Chen and Han, Jinsong and Xi, Wei and Ding, Han and Jiang, Zhiping and Zhao, Jizhong},
title = {Verifiable Smart Packaging with Passive RFID},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971692},
doi = {10.1145/2971648.2971692},
abstract = {Smart packaging adds sensing abilities to traditional packages. This paper investigates the possibility of using RF signals to test the internal status of packages and detect abnormal internal changes. Towards this goal, we design and implement a nondestructive package testing and verification system using commodity passive RFID systems, called Echoscope. Echoscope extracts unique features from the backscatter signals penetrating the internal space of a package and compares them with the previously collected features during the check-in phase. The use of backscatter signals guarantees that there is no difference in RF sources and the features reflecting the internal status will not be affected. Compared to other nondestructive testing methods such as X-ray and ultrasound, Echoscope is much cheaper and provides ubiquitous usage. Our experiments in practical environments show that Echoscope can achieve very high accuracy and is very sensitive to various types abnormal changes.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {156–166},
numpages = {11},
keywords = {wireless sensing, smart packaging, RFID},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971699,
author = {Ding, Han and Qian, Chen and Han, Jinsong and Wang, Ge and Jiang, Zhiping and Zhao, Jizhong and Xi, Wei},
title = {Device-Free Detection of Approach and Departure Behaviors Using Backscatter Communication},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971699},
doi = {10.1145/2971648.2971699},
abstract = {Smart environments and security systems require automatic detection of human behaviors including approaching to or departing from an object. Existing human motion detection systems usually require human beings to carry special devices, which limits their applications. In this paper, we present a system called APID to detect arm reaching by analyzing backscatter communication signals from a passive RFID tag on the object. APID does not require human beings to carry any device. The idea is based on the influence of human movements to the vibration of backscattered tag signals. APID is compatible with commodity off-the-shelf devices and the EPCglobal Class-1 Generation-2 protocol. In APID an commercial RFID reader continuously queries tags through emitting RF signals and tags simply respond with their IDs. A USRP monitor passively analyzes the communication signals and reports the approach and departure behaviors. We have implemented the APID system for both single-object and multi-object scenarios in both horizontal and vertical deployment modes. The experimental results show that APID can achieve high detection accuracy.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {167–177},
numpages = {11},
keywords = {wireless sensing, RFID},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971712,
author = {Abdullah, Saeed and Murnane, Elizabeth L. and Matthews, Mark and Kay, Matthew and Kientz, Julie A. and Gay, Geri and Choudhury, Tanzeem},
title = {Cognitive Rhythms: Unobtrusive and Continuous Sensing of Alertness Using a Mobile Phone},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971712},
doi = {10.1145/2971648.2971712},
abstract = {Throughout the day, our alertness levels change and our cognitive performance fluctuates. The creation of technology that can adapt to such variations requires reliable measurement with ecological validity. Our study is the first to collect alertness data in the wild using the clinically validated Psychomotor Vigilance Test. With 20 participants over 40 days, we find that alertness can oscillate approximately 30% depending on time and body clock type and that Daylight Savings Time, hours slept, and stimulant intake can influence alertness as well. Based on these findings, we develop novel methods for unobtrusively and continuously assessing alertness. In estimating response time, our model achieves a root-mean-square error of 80.64 milliseconds, which is significantly lower than the 500ms threshold used as a standard indicator of impaired cognitive ability. Finally, we discuss how such real-time detection of alertness is a key first step towards developing systems that are sensitive to our biological variations.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {178–189},
numpages = {12},
keywords = {sleep, performance, alertness, circadian rhythms},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971705,
author = {Hashizume, Takahiro and Sasatani, Takuya and Narumi, Koya and Narusue, Yoshiaki and Kawahara, Yoshihiro and Asami, Tohru},
title = {Passive and Contactless Epidermal Pressure Sensor Printed with Silver Nano-Particle Ink},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971705},
doi = {10.1145/2971648.2971705},
abstract = {In this paper, we propose a passive and contactless epidermal pressure sensor patch printed on a paper substrate with silver nano-particle ink. This disposable patch can be used to measure the pressure between the clothes and the human body. Different from the conventional pressure sensors, the pressure can be measured wirelessly without disturbing the motion of the users. The sensor circuit pattern is printed by a conductive inkjet printer and the sensor's pressure value is detected by a reader coil through the change of the capacitance of an LC resonant circuit. We propose a sensor design method that minimizes the effect of the human body. We demonstrate our sensor patch by measuring the pressure exerted by compression garments whose pressure distribution is important for the wearer's health.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {190–195},
numpages = {6},
keywords = {inductive coupling, conductive ink, resonance circuit, pressure sensor},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971665,
author = {Li, Xiang and Li, Shengjie and Zhang, Daqing and Xiong, Jie and Wang, Yasha and Mei, Hong},
title = {Dynamic-MUSIC: Accurate Device-Free Indoor Localization},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971665},
doi = {10.1145/2971648.2971665},
abstract = {Device-free passive indoor localization is playing a critical role in many applications such as elderly care, intrusion detection, smart home, etc. However, existing device-free localization systems either suffer from labor-intensive offline training or require dedicated special-purpose devices. To address the challenges, we present our system named MaTrack, which is implemented on commodity off-the-shelf Intel 5300 Wi-Fi cards. MaTrack proposes a novel Dynamic-MUSIC method to detect the subtle reflection signals from human body and further differentiate them from those reflected signals from static objects (furniture, walls, etc.) to identify the human target's angle for localization. MaTrack does not require any offline training compared to existing signature-based systems and is insensitive to changes in environment. With just two receivers, MaTrack is able to achieve a median localization accuracy below 0.6 m when the human is walking, outperforming the state-of-the-art schemes.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {196–207},
numpages = {12},
keywords = {angle-of-arrival, indoor localization, device-free},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971668,
author = {Xu, Han and Yang, Zheng and Zhou, Zimu and Shangguan, Longfei and Yi, Ke and Liu, Yunhao},
title = {Indoor Localization via Multi-Modal Sensing on Smartphones},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971668},
doi = {10.1145/2971648.2971668},
abstract = {Indoor localization is of great importance to a wide range of applications in shopping malls, office buildings and public places. The maturity of computer vision (CV) techniques and the ubiquity of smartphone cameras hold promise for offering sub-meter accuracy localization services. However, pure CV-based solutions usually involve hundreds of photos and pre-calibration to construct image database, a labor-intensive overhead for practical deployment. We present ClickLoc, an accurate, easy-to-deploy, sensor-enriched, image-based indoor localization system. With core techniques rooted in semantic information extraction and optimization-based sensor data fusion, ClickLoc is able to bootstrap with few images. Leveraging sensor-enriched photos, ClickLoc also enables user localization with a single photo of the surrounding place of interest (POI) with high accuracy and short delay. Incorporating multi-modal localization with Manifold Alignment and Trapezoid Representation, ClickLoc not only localizes efficiently, but also provides image-assisted navigation. Extensive experiments in various environments show that the 80-percentile error is within 0.26m for POIs on the floor plan, which sheds light on sub-meter level indoor localization.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {208–219},
numpages = {12},
keywords = {multi-modal data, indoor localization, smart phone},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971684,
author = {Tachikawa, Masaya and Maekawa, Takuya and Matsushita, Yasuyuki},
title = {Predicting Location Semantics Combining Active and Passive Sensing with Environment-Independent Classifier},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971684},
doi = {10.1145/2971648.2971684},
abstract = {This paper presents a method for estimating a user's indoor location without using training data collected by the user in his/her environment. Specifically, we attempt to predict the user's location semantics, i.e., location classes such as restroom and meeting room. While indoor location information can be used in many real-world services, e.g., context-aware systems, lifelogging, and monitoring the elderly, estimating the location information requires training data collected in an environment of interest. In this study, we combine passive sensing and active sound probing to capture and learn inherent sensor data features for each location class using labeled training data collected in other environments. In addition, this study modifies the random forest algorithm to effectively extract inherent sensor data features for each location class. Our evaluation showed that our method achieved about 85% accuracy without using training data collected in test environments.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {220–231},
numpages = {12},
keywords = {indoor positioning, passive sensing, active probing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971689,
author = {He, Suining and Tan, Jiajie and Chan, S.-H. Gary},
title = {Towards Area Classification for Large-Scale Fingerprint-Based System},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971689},
doi = {10.1145/2971648.2971689},
abstract = {In spacious and multi-area buildings, fingerprint-based localization often suffers from expensive location search. Besides, context knowledge like inside/outside-region and floor area is important for complete location service. To address above issues, beyond the algorithms finding the exact location point, we study accurate and efficient indoor area classification for large-scale fingerprint-based system. We first study leveraging the one-class classification to conduct inside/outside-region detection given only the inside fingerprints. Then we discuss different area determination algorithms, and compare their detection accuracy and deployment efficiency. To further enhance accuracy, we also discuss rejecting unclassifiable signals and calibrating heterogeneous devices. We have implemented different algorithms on Android platforms. Experimental trials (totally over 30,000 fingerprints and 15,000 test data) at an international airport, a business building, a premium shopping mall and a university campus have evaluated practicability and deployability of different classification schemes. Our studies can also serve as design guidelines for area classification.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {232–243},
numpages = {12},
keywords = {context-awareness, experiment, area classification, inside/outside-region detection, system, experimental comparison, fingerprinting},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971710,
author = {Shimosaka, Masamichi and Saisho, Osamu},
title = {Efficient Calibration for Rssi-Based Indoor Localization by Bayesian Experimental Design on Multi-Task Classification},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971710},
doi = {10.1145/2971648.2971710},
abstract = {RSSI-based indoor localization is getting much attention. Thanks to a number of researchers, the localization accuracy has already reached a sufficient level. However, it is still not easy-to-use technology because of its heavy installation cost. When an indoor localization system is installed, it needs to collect RSSI data for training classifiers. Existing techniques need to collect enough data at each location. This is why the installation cost is very heavy. We propose a technique to gather data efficiently by using machine learning techniques. Our proposed algorithm is based on multi-task learning and Bayesian optimization. This algorithm can remove the need to collect data of all location labels and select location labels to acquire new data efficiently. We verify this algorithm by using a Wi-Fi RSSI dataset collected in a building. The empirical results suggest that the algorithm is superior to an existing algorithm applying single-task learning and Active Class Selection.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {244–249},
numpages = {6},
keywords = {RSSI, indoor localization, information gathering, bayesian optimization, multi-task learning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971738,
author = {Li, Hong and Yang, Wei and Wang, Jianxin and Xu, Yang and Huang, Liusheng},
title = {WiFinger: Talk to Your Smart Devices with Finger-Grained Gesture},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971738},
doi = {10.1145/2971648.2971738},
abstract = {In recent literatures, WiFi signals have been widely used to "sense" people's locations and activities. Researchers have exploited the characteristics of wireless signals to "hear" people's talk and "see" keystrokes by human users. Inspired by the excellent work of relevant scholars, we turn to explore the field of human-computer interaction using finger-grained gestures under WiFi environment. In this paper, we present Wi-Finger - the first solution using ubiquitous wireless signals to achieve number text input in WiFi devices. We implement a prototype of WiFinger on a commercial Wi-Fi infrastructure. Our scheme is based on the key intuition that while performing a certain gesture, the fingers of a user move in a unique formation and direction and thus generate a unique pattern in the time series of Channel State Information (CSI) values. WiFinger is deigned to recognize a set of finger-grained gestures, which are further used to realize continuous text input in off-the-shelf WiFi devices. As the results show, WiFinger achieves up to 90.4% average classification accuracy for recognizing 9 digits finger-grained gestures from American Sign Language (ASL), and its average accuracy for single individual number text input in desktop reaches 82.67% within 90 digits.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {250–261},
numpages = {12},
keywords = {wireless, channel state information, micro-motion recognition},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971687,
author = {Akkil, Deepak and Isokoski, Poika},
title = {Accuracy of Interpreting Pointing Gestures in Egocentric View},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971687},
doi = {10.1145/2971648.2971687},
abstract = {Communicating spatial information by pointing is ubiquitous in human interactions. With the growing use of head-mounted cameras for collaborative purposes, it is important to assess how accurately viewers of the resulting egocentric videos can interpret pointing acts. We conducted an experiment to compare the accuracy of interpreting four different pointing techniques: hand pointing, head pointing, gaze pointing and hand+gaze pointing. Our results suggest that superimposing the gaze information on the egocentric video can enable viewers to determine pointing targets more accurately and more confidently. Hand pointing performed best when the pointing target was straight ahead and head pointing was the least preferred in terms of ease of interpretation. Our results can inform the design of collaborative applications that make use of the egocentric view.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {262–273},
numpages = {12},
keywords = {egocentric video, gaze augmentation, accuracy of spatial referencing, pointing, collaboration},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971679,
author = {Khamis, Mohamed and Saltuk, Ozan and Hang, Alina and Stolz, Katharina and Bulling, Andreas and Alt, Florian},
title = {TextPursuits: Using Text for Pursuits-Based Interaction and Calibration on Public Displays},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971679},
doi = {10.1145/2971648.2971679},
abstract = {In this paper we show how reading text on large display can be used to enable gaze interaction in public space. Our research is motivated by the fact that much of the content on public displays includes text. Hence, researchers and practitioners could greatly benefit from users being able to spontaneously interact as well as to implicitly calibrate an eye tracker while simply reading this text. In particular, we adapt Pursuits, a technique that correlates users' eye movements with moving on-screen targets. While prior work used abstract objects or dots as targets, we explore the use of Pursuits with text (read-and-pursue). Thereby we address the challenge that eye movements performed while reading interfere with the pursuit movements. Results from two user studies (N=37) show that Pursuits with text is feasible and can achieve similar accuracy as non text-based pursuit approaches. While calibration is less accurate, it integrates smoothly with reading and allows areas of the display the user is looking at to be identified.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {274–285},
numpages = {12},
keywords = {smooth pursuit, public displays, gaze interaction, text},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971678,
author = {Wen, Elliott and Seah, Winston and Ng, Bryan and Liu, Xuefeng and Cao, Jiannong},
title = {UbiTouch: Ubiquitous Smartphone Touchpads Using Built-in Proximity and Ambient Light Sensors},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971678},
doi = {10.1145/2971648.2971678},
abstract = {Smart devices are increasingly shrinking in size, which results in new challenges for user-mobile interaction through minuscule touchscreens. Existing works to explore alternative interaction technologies mainly rely on external devices which degrade portability. In this paper, we propose UbiTouch, a novel system that extends smartphones with virtual touchpads on desktops using built-in smartphone sensors. It senses a user's finger movement with a proximity and ambient light sensor whose raw sensory data from underlying hardware are strongly dependent on the finger's locations. UbiTouch maps the raw data into the finger's positions by utilizing Curvilinear Component Analysis and improve tracking accuracy via a particle filter. We have evaluate our system in three scenarios with different lighting conditions by five users. The results show that UbiTouch achieves centimetre-level localization accuracy and poses no significant impact on the battery life. We envisage that UbiTouch could support applications such as text-writing and drawing.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {286–297},
numpages = {12},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971714,
author = {Clarke, Christopher and Bellino, Alessio and Esteves, Augusto and Velloso, Eduardo and Gellersen, Hans},
title = {TraceMatch: A Computer Vision Technique for User Input by Tracing of Animated Controls},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971714},
doi = {10.1145/2971648.2971714},
abstract = {Recent works have explored the concept of movement correlation interfaces, in which moving objects can be selected by matching the movement of the input device to that of the desired object. Previous techniques relied on a single modality (e.g. gaze or mid-air gestures) and specific hardware to issue commands. TraceMatch is a computer vision technique that enables input by movement correlation while abstracting from any particular input modality. The technique relies only on a conventional webcam to enable users to produce matching gestures with any given body parts, even whilst holding objects. We describe an implementation of the technique for acquisition of orbiting targets, evaluate algorithm performance for different target sizes and frequencies, and demonstrate use of the technique for remote control of graphical as well as physical objects with different body parts.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {298–303},
numpages = {6},
keywords = {remote control, motion matching, computer vision, vision-based interfaces, user input, gesture input, path mimicry, input techniques, ubiquitous computing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971650,
author = {Song, Seokwoo and Kim, Seungho and Kim, John and Park, Wonjeong and Yim, Dongsun},
title = {TalkLIME: Mobile System Intervention to Improve Parent-Child Interaction for Children with Language Delay},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971650},
doi = {10.1145/2971648.2971650},
abstract = {Parent-training is commonly used to support intervention of children with language delay. Unfortunately, parents find it difficult to apply the training to their child in everyday life and often give up on their parent-child interaction. In this work, we propose and evaluate TalkLIME -- a mobile system that provides real-time feedback to improve the parent-child interaction and reinforce parent-training intervention. We first conduct a survey to understand parents' feedback preference for the mobile system and determine that a non-invasive feedback using the mobile phones screen is preferable. TalkLIME was developed to provide real-time feedback through the mobile phone screen while also providing motivation to the parents to consistently continue parent-child interaction through both short-term and long-term goals. A six-weeks user study was conducted with eight parents and their children with language delay. Our results show that the experimental group who used TalkLIME showed a significant improvement in the child's initiation ratio, an important metric in the language development of children.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {304–315},
numpages = {12},
keywords = {smartphone intervention, everyday treatment, language therapy, children, language delay, parental education},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971657,
author = {Zhou, Mengyu and Ma, Minghua and Zhang, Yangkun and SuiA, Kaixin and Pei, Dan and Moscibroda, Thomas},
title = {EDUM: Classroom Education Measurements via Large-Scale WiFi Networks},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971657},
doi = {10.1145/2971648.2971657},
abstract = {Behavior in classroom-based courses is hard to measure at large-scale. In this paper, we propose the EDUM (EDUcation Measurement) system to help characterize educational behavior through data collected from WLANs (WiFi networks) on campuses. EDUM characterizes students' punctuality (attendances, late arrivals, and early departures) for lectures using longitudinal WLAN data, and further characterizes the attractiveness of lectures using mobile phone's interactive states at minute-scale granularity. EDUM is easy to deploy and extensible for new types of data. We deploy EDUM at Tsinghua University where ~700 volunteer students' data are measured during a 9-week period by ~2,800 APs and two popular mobile apps. Our results show that EDUM makes it possible to obtain large-scale observations on punctuality, distraction and study performance, and quantitatively confirm or disprove numerous assumptions about educational behavior.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {316–327},
numpages = {12},
keywords = {course attractiveness, lecture punctuality, wifi networks, mobile devices, classroom education measurements},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971695,
author = {Cibrian, Franceli L. and Weibel, Nadir and Tentori, Monica},
title = {Collective Use of a Fabric-Based Interactive Surface to Support Early Development in Toddler Classrooms},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971695},
doi = {10.1145/2971648.2971695},
abstract = {Early instruction plays a crucial role in allowing toddlers to develop social, cognitive, and sensory-motor skills. Free play is important in any early development program, but designing activities for free play is challenging. In this paper, we investigate the use of an interactive surface, BendableSound, a fabric-based interactive surface that enables young children to play piano sounds when touching the fabric, and its potential value in early education classrooms. We conducted a 9-week exploratory study in which 22 toddlers and 5 teachers used BendableSound during free play activities inside their classroom. Our qualitative results indicate that BendableSound was successfully adopted and integrated in toddler classrooms and could positively impact cognitive, social, and physical development. These results offer implications for the design of deformable surfaces and for their integration in activities to support the early development of toddlers.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {328–339},
numpages = {12},
keywords = {toddlers, early development, interactive surfaces, kinect-based interfaces},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971739,
author = {Singh, Bhanu Pratap and Aggarwal, Varun},
title = {Apps to Measure Motor Skills of Vocational Workers},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971739},
doi = {10.1145/2971648.2971739},
abstract = {Motor skills are required in a large number of vocational jobs today. However, no automated means exist to test and provide feedback on these skills. In this paper, we explore the use of touch-screen surfaces and tablet-apps to measure these skills. We design novel gamified apps to predict the performance of candidates in doing manual tasks in the industry. We demonstrate two important results - we use the information captured on a touch-screen device to successfully predict the scores of traditional, non-automated motor skill tests. Further, we show that this information successfully predicts the performance of workers in their respective jobs. The results presented in this work make a strong case for using such automated, touchscreen based apps in job selection and to provide automatic feedback. To the best of the authors' knowledge, this is the first attempt at using touch-screen devices to scalably and reliably measure motor skills.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {340–350},
numpages = {11},
keywords = {psychomotor skills, blue collar jobs, touch-screen devices, tablets, assessments},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971658,
author = {Wu, Dan and Zhang, Daqing and Xu, Chenren and Wang, Yasha and Wang, Hao},
title = {WiDir: Walking Direction Estimation Using Wireless Signals},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971658},
doi = {10.1145/2971648.2971658},
abstract = {Despite its importance, walking direction is still a key context lacking a cost-effective and continuous solution that people can access in indoor environments. Recently, device-free sensing has attracted great attention because these techniques do not require the user to carry any device and hence could enable many applications in smart homes and offices. In this paper, we present WiDir, the first system that leverages WiFi wireless signals to estimate a human's walking direction, in a device-free manner. Human motion changes the multipath distribution and thus WiFi Channel State Information at the receiver end. WiDir analyzes the phase change dynamics from multiple WiFi subcarriers based on Fresnel zone model and infers the walking direction. We implement a proof-of-concept prototype using commercial WiFi devices and evaluate it in both home and office environments. Experimental results show that WiDir can estimate human walking direction with a median error of less than 10 degrees.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {351–362},
numpages = {12},
keywords = {channel state information (csi), fresnel zone, direction estimation, wifi},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971670,
author = {Wang, Wei and Liu, Alex X. and Shahzad, Muhammad},
title = {Gait Recognition Using Wifi Signals},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971670},
doi = {10.1145/2971648.2971670},
abstract = {In this paper, we propose WifiU, which uses commercial WiFi devices to capture fine-grained gait patterns to recognize humans. The intuition is that due to the differences in gaits of different people, the WiFi signal reflected by a walking human generates unique variations in the Channel State Information (CSI) on the WiFi receiver. To profile human movement using CSI, we use signal processing techniques to generate spectrograms from CSI measurements so that the resulting spectrograms are similar to those generated by specifically designed Doppler radars. To extract features from spectrograms that best characterize the walking pattern, we perform autocorrelation on the torso reflection to remove imperfection in spectrograms. We evaluated WifiU on a dataset with 2,800 gait instances collected from 50 human subjects walking in a room with an area of 50 square meters. Experimental results show that WifiU achieves top-1, top-2, and top-3 recognition accuracies of 79.28%, 89.52%, and 93.05%, respectively.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {363–373},
numpages = {11},
keywords = {device-free sensing, gait recognition},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971742,
author = {Huang, Baoqi and Qi, Guodong and Yang, Xiaokun and Zhao, Long and Zou, Han},
title = {Exploiting Cyclic Features of Walking for Pedestrian Dead Reckoning with Unconstrained Smartphones},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971742},
doi = {10.1145/2971648.2971742},
abstract = {Pedestrian dead reckoning (PDR) is a promising complementary technique to balance the requirements on both accuracy and costs in outdoor and indoor positioning systems. In this paper, we propose a unified framework to comprehensively tackle the three sub problems involved in PDR, including step detection and counting, heading estimation and step length estimation, based on sequentially rotating the device (reference) frame to the Earth (reference) frame through sensor fusion. To be specific, a robust step detection and counting algorithm is devised according to vertical angular velocities and turns out to be tolerant of various smartphone placements; then, a zero velocity update (ZUPT) based algorithm is leveraged to calibrate the measurements in the Earth frame; on these grounds, the heading and step length are further estimated by exploiting the cyclic features of walking. A thorough and extensive experimental analysis is conducted and confirms the effectiveness and advantages of the proposed PDR framework as well as the corresponding algorithms.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {374–385},
numpages = {12},
keywords = {indoor positioning, PDR, smartphone, ZUPT},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971675,
author = {Tsai, Hsin-Ruey and Wei, Shih-Yao and Hsiao, Jui-Chun and Chiu, Ting-Wei and Lo, Yi-Ping and Keng, Chi-Feng and Hung, Yi-Ping and Chen, Jin-Jong},
title = {IKneeBraces: Knee Adduction Moment Evaluation Measured by Motion Sensors in Gait Detection},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971675},
doi = {10.1145/2971648.2971675},
abstract = {We propose light-weight wearable devices, iKneeBraces, to prevent knee osteoarthritis (OA) using knee adduction moment (KAM) evaluation. iKneeBrace consists of two inertial measurement units (IMUs) to measure shin and thigh angles. KAM is estimated by ground force reaction (GRF), knee position and center of pressure position. Instead of heavy and bulky 3DoF force plates conventionally used, we propose to build a 2D input regression model using shin and thigh angles from iKneeBrace as input to infer GRF direction and further estimate KAM. We perform an experiment to evaluate the method. The results show that iKneeBrace can infer KAM similar to the ground truth in the first peak, the most important part to prevent knee OA. Furthermore, the proposed method can infer KAM in all parts if better IMUs used in iKneeBrace in the future. The proposed method not only makes KAM evaluation portable but also requires only light-weight devices.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {386–391},
numpages = {6},
keywords = {knee adduction moment, measurement system, knee osteoarthritis, inertial measurement unit, gait},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971690,
author = {Kandappu, Thivya and Jaiman, Nikita and Tandriansyah, Randy and Misra, Archan and Cheng, Shih-Fen and Chen, Cen and Lau, Hoong Chuin and Chander, Deepthi and Dasgupta, Koustuv},
title = {TASKer: Behavioral Insights via Campus-Based Experimental Mobile Crowd-Sourcing},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971690},
doi = {10.1145/2971648.2971690},
abstract = {While mobile crowd-sourcing has become a game-changer for many urban operations, such as last mile logistics and municipal monitoring, we believe that the design of such crowd-sourcing strategies must better accommodate the real-world behavioral preferences and characteristics of users. To provide a real-world testbed to study the impact of novel mobile crowd-sourcing strategies, we have designed, developed and experimented with a real-world mobile crowd-tasking platform on the SMU campus, called TA&amp;Sslash;Ker. We enhanced the TA$Ker platform to support several new features (e.g., task bundling, differential pricing and cheating analytics) and experimentally investigated these features via a two-month deployment of TA$Ker, involving 900 real users on the SMU campus who performed over 30,000 tasks. Our studies (i) show the benefits of bundling tasks as a combined package, (ii) reveal the effectiveness of differential pricing strategies and (iii) illustrate key aspects of cheating (false reporting) behavior observed among workers.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {392–402},
numpages = {11},
keywords = {context-aware, user behaviour, crowd-sourcing, empirical study},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971709,
author = {Liu, Yan and Guo, Bin and Wang, Yang and Wu, Wenle and Yu, Zhiwen and Zhang, Daqing},
title = {TaskMe: Multi-Task Allocation in Mobile Crowd Sensing},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971709},
doi = {10.1145/2971648.2971709},
abstract = {Task allocation or participant selection is a key issue in Mobile Crowd Sensing (MCS). While previous participant selection approaches mainly focus on selecting a proper subset of users for a single MCS task, multi-task-oriented participant selection is essential and useful for the efficiency of large-scale MCS platforms. This paper proposes TaskMe, a participant selection framework for multi-task MCS environments. In particular, two typical multi-task allocation situations with bi-objective optimization goals are studied: (1) For FPMT (few participants, more tasks), each participant is required to complete multiple tasks and the optimization goal is to maximize the total number of accomplished tasks while minimizing the total movement distance. (2) For MPFT (more participants, few tasks), each participant is selected to perform one task based on pre-registered working areas in view of privacy, and the optimization objective is to minimize total incentive payments while minimizing the total traveling distance. Two optimal algorithms based on the Minimum Cost Maximum Flow theory are proposed for FPMT, and two algorithms based on the multi-objective optimization theory are proposed for MPFT. Experiments verify that the proposed algorithms outperform baselines based on a large-scale real-word dataset under different experiment settings (the number of tasks, various task distributions, etc.).},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {403–414},
numpages = {12},
keywords = {multi-task allocation, participant selection, bi-objective optimization, mobile crowd sensing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971711,
author = {Xiong, Haoyi and Huang, Yu and Barnes, Laura E. and Gerber, Matthew S.},
title = {Sensus: A Cross-Platform, General-Purpose System for Mobile Crowdsensing in Human-Subject Studies},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971711},
doi = {10.1145/2971648.2971711},
abstract = {The burden of entry into mobile crowdsensing (MCS) is prohibitively high for human-subject researchers who lack a technical orientation. As a result, the benefits of MCS remain beyond the reach of research communities (e.g., psychologists) whose expertise in the study of human behavior might advance applications and understanding of MCS systems. This paper presents Sensus, a new MCS system for human-subject studies that bridges the gap between human-subject researchers and MCS methods. Sensus alleviates technical burdens with on-device, GUI-based design of sensing plans, simple and efficient distribution of sensing plans to study participants, and uniform participant experience across iOS and Android devices. Sensing plans support many hardware and software sensors, automatic deployment of sensor-triggered surveys, and double-blind assignment of participants within randomized controlled trials. Sensus offers these features to study designers without requiring knowledge of markup and programming languages. We demonstrate the feasibility of using Sensus within two human-subject studies, one in psychology and one in engineering. Feedback from non-technical users indicates that Sensus is an effective and low-burden system for MCS-based data collection and analysis.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {415–426},
numpages = {12},
keywords = {crowdsensing, participatory sensing, programmable platform, human factors},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971713,
author = {Santani, Darshan and Biel, Joan-Isaac and Labhart, Florian and Truong, Jasmine and Landolt, Sara and Kuntsche, Emmanuel and Gatica-Perez, Daniel},
title = {The Night is Young: Urban Crowdsourcing of Nightlife Patterns},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971713},
doi = {10.1145/2971648.2971713},
abstract = {We present a mobile crowdsourcing study to capture and examine the nightlife patterns of two youth populations in Switzerland. Our contributions are three fold. First, we developed a smartphone application to capture data on places, social context and nightlife activities, and to record mobile videos capturing the ambiance of places. Second, we conducted an "in-the-wild" study with more than 200 participants over a period of three months in two Swiss cities, resulting in a total of 1,394 unique place visits and 843 videos that spread across place categories (including personal homes and public parks), social and ambiance variables. Finally, we investigated the use of automatic ambiance features to estimate the loudness and brightness of places at scale, and found that while features are reliable with respect to video content, videos do not always reflect the place ambiance reported by people in-situ. We believe that the developed methodology provides an opportunity to understand the physical mobility, activities, and social context of youth as they experience different aspects of nightlife.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {427–438},
numpages = {12},
keywords = {nightlife, youth, mobile crowdsensing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971655,
author = {Huang, Wenchao and Li, Xiang-Yang and Xiong, Yan and Yang, Panlong and Hu, Yiqing and Mao, Xufei and Miao, Fuyou and Zhao, Baohua and Zhao, Jumin},
title = {WalkieLokie: Sensing Relative Positions of Surrounding Presenters by Acoustic Signals},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971655},
doi = {10.1145/2971648.2971655},
abstract = {In this paper, we propose and implement WalkieLokie, a novel acoustic-based relative positioning system. WalkieLokie facilitates a multitude of Augmented Reality (AR) applications: users with smart devices can passively acquire surrounding information in real time, similar to the commercial AR system Wikitude; the surrounding presenters, who want to share information or introduce themselves, can actively launch the function on demand. The key rational of WalkieLokie is that a user can perceive a series of spatial-related acoustic signals emitted from a presenter, which depicts the relation position between the user and the presenter. The proliferation of smart devices, together with the cheap accessory (e.g., dummy speaker) embedded in daily used items (e.g., smart clothes), paves the way for WalkieLokie applications. We design a novel algorithm to estimate the position and signal processing methods to support accurate positioning. The experiment results show that the mean error of ranging and direction estimation is 0.63m and 2.46 degrees respectively. Extensive experiments conducted in noisy environments validate the robustness of WalkieLokie.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {439–450},
numpages = {12},
keywords = {acoustic signaling, augmented reality, direction finding, ranging},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971677,
author = {Mirtchouk, Mark and Merck, Christopher and Kleinberg, Samantha},
title = {Automated Estimation of Food Type and Amount Consumed from Body-Worn Audio and Motion Sensors},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971677},
doi = {10.1145/2971648.2971677},
abstract = {Determining when an individual is eating can be useful for tracking behavior and identifying patterns, but to create nutrition logs automatically or provide real-time feedback to people with chronic disease, we need to identify both what they are consuming and in what quantity. However, food type and amount have mainly been estimated using image data (requiring user involvement) or acoustic sensors (tested with a restricted set of foods rather than representative meals). As a result, there is not yet a highly accurate automated nutrition monitoring method that can be used with a variety of foods. We propose that multi-modal sensing (in-ear audio plus head and wrist motion) can be used to more accurately classify food type, as audio and motion features provide complementary information. Further, we propose that knowing food type is critical for estimating amount consumed in combination with sensor data. To test this we use data from people wearing audio and motion sensors, with ground truth annotated from video and continuous scale data. With data from 40 unique foods we achieve a classification accuracy of 82.7% with a combination of sensors (versus 67.8% for audio alone and 76.2% for head and wrist motion). Weight estimation error was reduced from a baseline of 127.3% to 35.4% absolute relative error. Ultimately, our estimates of food type and amount can be linked to food databases to provide automated calorie estimates from continuously-collected data.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {451–462},
numpages = {12},
keywords = {nutrition, acoustic and motion sensing, eating recognition},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971681,
author = {Yu, Tuo and Jin, Haiming and Nahrstedt, Klara},
title = {WritingHacker: Audio Based Eavesdropping of Handwriting via Mobile Devices},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971681},
doi = {10.1145/2971648.2971681},
abstract = {When filling out privacy-related forms in public places such as hospitals or clinics, people usually are not aware that the sound of their handwriting leaks personal information. In this paper, we explore the possibility of eavesdropping on handwriting via nearby mobile devices based on audio signal processing and machine learning. By presenting a proof-of-concept system, WritingHacker, we show the usage of mobile devices to collect the sound of victims' handwriting, and to extract handwriting-specific features for machine learning based analysis. WritingHacker focuses on the situation where the victim's handwriting follows certain print style. An attacker can keep a mobile device, such as a common smart-phone, touching the desk used by the victim to record the audio signals of handwriting. Then the system can provide a word-level estimate for the content of the handwriting. To reduce the impacts of various writing habits and writing locations, the system utilizes the methods of letter clustering and dictionary filtering. Our prototype system's experimental results show that the accuracy of word recognition reaches around 50% - 60% under certain conditions, which reveals the danger of privacy leakage through the sound of handwriting.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {463–473},
numpages = {11},
keywords = {audio signals, handwriting, eavesdropping},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971736,
author = {Ruan, Wenjie and Sheng, Quan Z. and Yang, Lei and Gu, Tao and Xu, Peipei and Shangguan, Longfei},
title = {AudioGest: Enabling Fine-Grained Hand Gesture Detection by Decoding Echo Signal},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971736},
doi = {10.1145/2971648.2971736},
abstract = {Hand gesture is becoming an increasingly popular means of interacting with consumer electronic devices, such as mobile phones, tablets and laptops. In this paper, we present AudioGest, a device-free gesture recognition system that can accurately sense the hand in-air movement around user's devices. Compared to the state-of-the-art, AudioGest is superior in using only one pair of built-in speaker and microphone, without any extra hardware or infrastructure support and with no training, to achieve fine-grained hand detection. Our system is able to accurately recognize various hand gestures, estimate the hand in-air time, as well as average moving speed and waving range. We achieve this by transforming the device into an active sonar system that transmits inaudible audio signal and decodes the echoes of hand at its microphone. We address various challenges including cleaning the noisy reflected sound signal, interpreting the echo spectrogram into hand gestures, decoding the Doppler frequency shifts into the hand waving speed and range, as well as being robust to the environmental motion and signal drifting. We implement the proof-of-concept prototype in three different electronic devices and extensively evaluate the system in four real-world scenarios using 3,900 hand gestures that collected by five users for more than two weeks. Our results show that AudioGest can detect six hand gestures with an accuracy up to 96%, and by distinguishing the gesture attributions, it can provide up to 162 control commands for various applications.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {474–485},
numpages = {12},
keywords = {hand gestures, doppler effect, audio, FFT, microphone},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971669,
author = {Kostakos, Vassilis and Ferreira, Denzil and Goncalves, Jorge and Hosio, Simo},
title = {Modelling Smartphone Usage: A Markov State Transition Model},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971669},
doi = {10.1145/2971648.2971669},
abstract = {We develop a Markov state transition model of smartphone screen use. We collected use traces from real-world users during a 3-month naturalistic deployment via an app-store. These traces were used to develop an analytical model which can be used to probabilistically model or predict, at runtime, how a user interacts with their mobile phone, and for how long. Unlike classification-driven machine learning approaches, our analytical model can be interrogated under unlimited conditions, making it suitable for a wide range of applications including more realistic automated testing and improving operating system management of resources.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {486–497},
numpages = {12},
keywords = {prediction, model, markov chains, smartphone},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971696,
author = {Zhao, Sha and Ramos, Julian and Tao, Jianrong and Jiang, Ziwen and Li, Shijian and Wu, Zhaohui and Pan, Gang and Dey, Anind K.},
title = {Discovering Different Kinds of Smartphone Users through Their Application Usage Behaviors},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971696},
doi = {10.1145/2971648.2971696},
abstract = {Understanding smartphone users is fundamental for creating better smartphones, and improving the smartphone usage experience and generating generalizable and reproducible research. However, smartphone manufacturers and most of the mobile computing research community make a simplifying assumption that all smartphone users are similar or, at best, constitute a small number of user types, based on their behaviors. Manufacturers design phones for the broadest audience and hope they work for all users. Researchers mostly analyze data from smartphone-based user studies and report results without accounting for the many different groups of people that make up the user base of smartphones. In this work, we challenge these elementary characterizations of smartphone users and show evidence of the existence of a much more diverse set of users. We analyzed one month of application usage from 106,762 Android users and discovered 382 distinct types of users based on their application usage behaviors, using our own two-step clustering and feature ranking selection approach. Our results have profound implications on the reproducibility and reliability of mobile computing studies, design and development of applications, determination of which apps should be pre-installed on a smartphone and, in general, on the smartphone usage experience for different types of users.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {498–509},
numpages = {12},
keywords = {clustering, user groups},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971697,
author = {Garcia, Pedro Garcia and Costanza, Enrico and Ramchurn, Sarvapali D. and Verame, Jhim Kiel M.},
title = {The Potential of Physical Motion Cues: Changing People's Perception of Robots' Performance},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971697},
doi = {10.1145/2971648.2971697},
abstract = {Autonomous robotic systems can automatically perform actions on behalf of users in the domestic environment to help people in their daily activities. Such systems aim to reduce users' cognitive and physical workload, and improve well-being. While the benefits of these systems are clear, recent studies suggest that users may misconstrue their performance of tasks. We see an opportunity in designing interaction techniques that improve how users perceive the performance of such systems. We report two lab studies (N=16 each) designed to investigate whether showing physical motion, which is showing the process of a system through movement (that is intrinsic to the system's task), of an autonomous system as it completes its task, affects how users perceive its performance. To ensure our studies are ecologically valid and to motivate participants to provide thoughtful responses we adopted consensus-oriented financial incentives. Our results suggest that physical presence does yield higher performance ratings.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {510–518},
numpages = {9},
keywords = {cognitive psychology, automated systems, visualisation of automation, robots, perception, user experience},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971707,
author = {Welke, Pascal and Andone, Ionut and Blaszkiewicz, Konrad and Markowetz, Alexander},
title = {Differentiating Smartphone Users by App Usage},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971707},
doi = {10.1145/2971648.2971707},
abstract = {Tracking users across websites and apps is as desirable to the marketing industry as it is unalluring to users. The central challenge lies in identifying users from the perspective of different apps/sites. While there are methods to identify users via technical settings of their phones, these are prone to countermeasures. Yet, in this paper, we show that it is possible to differentiate users via their set of used apps, their app signature. To this end, we investigate the app usage of 46726 participants from the Menthal project. Even limiting our observation to the 500 globally most frequent apps results in unique signatures for 99.67% of users. Furthermore, even under this restriction, the average minimum Hamming distance to the closest other user is 25.93. Avoiding identification would thus require a massive change in the behavior of a user. Indeed, 99.4% of all users have unique usage patterns among the top 60 globally used apps. In contrast to previous work, this paper differentiates between users based on behavior instead of technical parameters. It thus opens an entirely new discussion regarding privacy.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {519–523},
numpages = {5},
keywords = {usage patterns, mobile devices, privacy},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971662,
author = {Zhang, Lan and Liu, Kebin and Li, Xiang-Yang and Liu, Cihang and Ding, Xuan and Liu, Yunhao},
title = {Privacy-Friendly Photo Capturing and Sharing System},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971662},
doi = {10.1145/2971648.2971662},
abstract = {The wide adoption of smart devices with onboard cameras facilitates photo capturing and sharing, but greatly increases people's concern on privacy infringement. Here we seek a solution to respect the privacy of persons being photographed in a smarter way that they can be automatically erased from photos captured by smart devices according to their requirements. To make this work, we need to address three challenges: 1) how to enable users explicitly express their privacy protection intentions without wearing any visible specialized tag, and 2) how to associate the intentions with persons in captured photos accurately and efficiently. Furthermore, 3) the association process itself should not cause portrait information leakage and should be accomplished in a privacy-preserving way. In this work, we design, develop, and evaluate a system, called COIN (Cloak Of INvisibility), that enables a user to flexibly express her privacy requirement and empowers the photo service provider (or image taker) to exert the privacy protection policy. Leveraging the visual distinguishability of people in the field-of-view and the dimension-order-independent property of vector similarity measurement, COIN achieves high accuracy and low overhead. We implement a prototype system, and our evaluation results on both the trace-driven and real-life experiments confirm the feasibility and efficiency of our system.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {524–534},
numpages = {11},
keywords = {photo capturing and sharing, smart camera, portrait privacy},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971663,
author = {Pasqua, Roberto and Roy, Matthieu and Tredan, Gilles},
title = {Loca: A Location-Oblivious Co-Location Attack in Crowds},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971663},
doi = {10.1145/2971648.2971663},
abstract = {Recent studies have introduced co-location attacks as a powerful way to extract social information from location traces. However, these attacks all rely by some means on the position of targeted users. This requires the attacker to be able to locate either the user or the sensors detecting the user. Implicitly, it also forbids the use of these attacks on devices whose location is unknown.In this paper, we consider attack scenarios where the attacker has no position information on users and devices sensing users. Such attack scenarios typically fit Internet of Things use-cases, where low-end devices are scattered in an environment that is unknown to the attacker: the sole source of information is a set of timestamped user/sensor proximity logs.To exploit proximity logs, we describe Loca, a location-oblivious co-location attack. Our approach exploits location-oblivious logs in two steps: i) we exploit users' flows between sensors to construct a virtual map of the sensors, and ii) we conduct a co-location attack based on that virtual map. Our tests on both synthetic and real datasets match up to 90% of the targeted social network with a surprisingly low number of sensors. These results greatly extend the scope of such co-location attacks, and hopefully awareness about their threat.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {535–544},
numpages = {10},
keywords = {privacy, colocation attack, crowd sensing, ubiquitous systems},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971685,
author = {Yang, Dingqi and Zhang, Daqing and Qu, Bingqing and Cudr\'{e}-Mauroux, Philippe},
title = {PrivCheck: Privacy-Preserving Check-in Data Publishing for Personalized Location Based Services},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971685},
doi = {10.1145/2971648.2971685},
abstract = {With the widespread adoption of smartphones, we have observed an increasing popularity of Location-Based Services (LBSs) in the past decade. To improve user experience, LBSs often provide personalized recommendations to users by mining their activity (i.e., check-in) data from location-based social networks. However, releasing user check-in data makes users vulnerable to inference attacks, as private data (e.g., gender) can often be inferred from the users' check-in data. In this paper, we propose PrivCheck, a customizable and continuous privacy-preserving check-in data publishing framework providing users with continuous privacy protection against inference attacks. The key idea of PrivCheck is to obfuscate user check-in data such that the privacy leakage of user-specified private data is minimized under a given data distortion budget, which ensures the utility of the obfuscated data to empower personalized LBSs. Since users often give LBS providers access to both their historical check-in data and future check-in streams, we develop two data obfuscation methods for historical and online check-in publishing, respectively. An empirical evaluation on two real-world datasets shows that our framework can efficiently provide effective and continuous protection of user-specified private data, while still preserving the utility of the obfuscated data for personalized LBSs.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {545–556},
numpages = {12},
keywords = {location based services, privacy},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971686,
author = {Luo, Chu and Fylakis, Angelos and Partala, Juha and Klakegg, Simon and Goncalves, Jorge and Liang, Kaitai and Sepp\"{a}nen, Tapio and Kostakos, Vassilis},
title = {A Data Hiding Approach for Sensitive Smartphone Data},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971686},
doi = {10.1145/2971648.2971686},
abstract = {We develop and evaluate a data hiding method that enables smartphones to encrypt and embed sensitive information into carrier streams of sensor data. Our evaluation considers multiple handsets and a variety of data types, and we demonstrate that our method has a computational cost that allows real-time data hiding on smartphones with negligible distortion of the carrier stream. These characteristics make it suitable for smartphone applications involving privacy-sensitive data such as medical monitoring systems and digital forensics tools.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {557–568},
numpages = {12},
keywords = {smartphones, privacy protections, ubiquitous computing, mobile and wireless security, digital signal processing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971726,
author = {Kaiser, Spencer and Parks, Ashley and Leopard, Patrick and Albright, Charlie and Carlson, Jake and Goel, Mayank and Nassehi, Damoun and Larson, Eric C.},
title = {Design and Learnability of Vortex Whistles for Managing Chronic Lung Function via Smartphones},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971726},
doi = {10.1145/2971648.2971726},
abstract = {Spirometry is the gold standard for managing and diagnosing obstructive lung diseases. Clinical spirometers, however, are expensive and have limited portability. Vortex whistles have shown promise as a potential substitute for clinical spirometers. While vortex whistles are low-cost and are highly portable, only a subset of common spirometry measurements can be measured reliably. Moreover, no research studies have evaluated characteristics of human interaction with vortex whistles, such as maneuver learnability and mental effort. We present a modified 3D-printed vortex whistle design that enables estimation of spirometry measures not previously attainable with traditional vortex whistles. We evaluate the whistle using a pulmonary waveform generator (a commercial standard) and map parameters of the whistle construction to spirometry test endpoints. Through a human subjects trial we evaluate how to personalize whistle parameters for different subjects and assess cognitive workload while using a vortex whistle. We show that, with personalization, vortex whistles are as effective as clinical spirometers for identifying moderate airway obstruction and require similar cognitive load to use.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {569–580},
numpages = {12},
keywords = {spirometry, cognitive load, vortex whistle, 3d printing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971671,
author = {Templeman, Charles and Ord\'{o}\~{n}ez, Francisco Javier and Symes, Andrew and Roggen, Daniel},
title = {Exploring Glass as a Novel Method for Hands-Free Data Entry in Flexible Cystoscopy},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971671},
doi = {10.1145/2971648.2971671},
abstract = {We present a way to annotate cystoscopy finding on Google Glass in a reproducible and hands free manner for use by surgeons during operations in the sterile environment inspired by the current practice of hand-drawn sketches. We developed three data entry variants based on speech and head movements. We assessed the feasibility, benefits and drawbacks of the system with 8 surgeons and Foundation Doctors having up to 30 years' cystoscopy experience at a UK hospital in laboratory trials. We report data entry speed and error rate of input modalities and contrast it with the participants' feedback on their perception of usability, acceptance, and suitability for deployment. The results are supportive of new data entry technologies and point out directions for future improvement of eyewear computers. The findings can be generalised to other endoscopic procedures (e.g. OGD/laryngoscopy) and could be included within hospital IT in the future.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {581–592},
numpages = {12},
keywords = {clinical data entry, human-computer interaction, eyewear computing, wearable computing, input modalities},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971653,
author = {Wang, Edward Jay and Li, William and Hawkins, Doug and Gernsheimer, Terry and Norby-Slycord, Colette and Patel, Shwetak N.},
title = {HemaApp: Noninvasive Blood Screening of Hemoglobin Using Smartphone Cameras},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971653},
doi = {10.1145/2971648.2971653},
abstract = {We present HemaApp, a smartphone application that noninvasively monitors blood hemoglobin concentration using the smartphone's camera and various lighting sources. Hemoglobin measurement is a standard clinical tool commonly used for screening anemia and assessing a patient's response to iron supplement treatments. Given a light source shining through a patient's finger, we perform a chromatic analysis, analyzing the color of their blood to estimate hemoglobin level. We evaluate HemaApp on 31 patients ranging from 6 -- 77 years of age, yielding a 0.82 rank order correlation with the gold standard blood test. In screening for anemia, HemaApp achieve a sensitivity and precision of 85.7% and 76.5%. Both the regression and classification performance compares favorably with our control, an FDA-approved noninvasive hemoglobin measurement device. We also evaluate and discuss the effect of using different kinds of lighting sources.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {593–604},
numpages = {12},
keywords = {mobile health, photoplethysmography, blood screening, camera, hemoglobin, anemia},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971704,
author = {Yoshitani, Takuma and Ogata, Masa and Yatani, Koji},
title = {LumiO: A Plaque-Aware Toothbrush},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971704},
doi = {10.1145/2971648.2971704},
abstract = {Toothbrushing plays an important role in daily dental plaque removal for preventive dentistry. Prior work has investigated improvements on toothbrushing with sensing technologies. But existing toothbrushing support focuses mostly on estimating brushing coverage. Users thus only have indirect information about how well their toothbrushing removes dental plaque. We present LumiO, a toothbrush that offers users continuous feedback on the amount of plaque on teeth. Lumio uses a well-known method for plaque detection, called Quantitative Light-induced Fluorescence (QLF). QLF exploits a red fluorescence property that bacterium in the plaque demonstrates when a blue-violet ray is cast. Blue-violet light excites this fluorescence property, and a camera with an optical filter can capture plaque in pink. We incorporate this technology into an electric toothbrush to achieve improvements in performance on plaque removal in daily dental care. This paper first discusses related work in sensing for oral activities and interaction as well as dental care with technologies. We then describe the principles of QLF, the hardware design of LumiO, and our vision-based plaque detection method. Our evaluations show that the vision-based plaque detection method with three machine learning techniques can achieve F-measures of 0.68 -- 0.92 under user-dependent training. Qualitative evidence also suggests that study participants were able to have improved awareness of plaque and build confidence on their toothbrushing.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {605–615},
numpages = {11},
keywords = {quantitative light-induced fluorescence, toothbrush, healthcare application, oral care, plaque detection},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971750,
author = {Bae, Sangwon and Dey, Anind K. and Low, Carissa A.},
title = {Using Passively Collected Sedentary Behavior to Predict Hospital Readmission},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971750},
doi = {10.1145/2971648.2971750},
abstract = {Hospital readmissions are a major problem facing health care systems today, costing Medicare alone US$26 billion each year. Being readmitted is associated with significantly shorter survival, and is often preventable. Predictors of readmission are still not well understood, particularly those under the patient's control: behavioral risk factors. Our work evaluates the ability of behavioral risk factors, specifically Fitbit-assessed behavior, to predict readmission for 25 postsurgical cancer inpatients. Our results show that sum of steps, maximum sedentary bouts, frequency, and low breaks in sedentary times during waking hours are strong predictors of readmission. We built two models for predicting readmissions: Steps-only and Behavioral model that adds information about sedentary behaviors. The Behavioral model (88.3%) outperforms the Steps-only model (67.1%), illustrating the value of passively collected information about sedentary behaviors. Indeed, passive monitoring of behavior data, i.e., mobility, after major surgery creates an opportunity for early risk assessment and timely interventions.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {616–621},
numpages = {6},
keywords = {sedentary behavior, healthcare outcomes, physical activity, colorectal cancer surgery, wearable tracker},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971760,
author = {Mathur, Akhil and Lane, Nicholas D. and Kawsar, Fahim},
title = {Engagement-Aware Computing: Modelling User Engagement from Mobile Contexts},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971760},
doi = {10.1145/2971648.2971760},
abstract = {In this paper, we examine the potential of using mobile context to model user engagement. Taking an experimental approach, we systematically explore the dynamics of user engagement with a smartphone through three different studies. Specifically, to understand the feasibility of detecting user engagement from mobile context, we first assess an EEG artifact with 10 users and observe a strong correlation between automatically detected engagement scores and user's subjective perception of engagement. Grounded on this result, we model a set of application level features derived from smartphone usage of 10 users to detect engagement of a usage session using a Random Forest classifier. Finally, we apply this model to train a variety of contextual factors acquired from smartphone usage logs of 130 users to predict user engagement using an SVM classifier with a F1-Score of 0.82. Our experimental results highlight the potential of mobile contexts in designing engagement-aware applications and provide guidance to future explorations.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {622–633},
numpages = {12},
keywords = {mobile sensing, eeg, engagement, behaviour modelling},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971762,
author = {Hiniker, Alexis and Patel, Shwetak N. and Kohno, Tadayoshi and Kientz, Julie A.},
title = {Why Would You Do That? Predicting the Uses and Gratifications behind Smartphone-Usage Behaviors},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971762},
doi = {10.1145/2971648.2971762},
abstract = {While people often use smartphones to achieve specific goals, at other times they use them out of habit or to pass the time. Uses and Gratifications Theory explains that users' motivations for engaging with technology can be divided into instrumental and ritualistic purposes. Instrumental uses of technology are goal-directed and purposeful, while ritualistic uses are habitual and diversionary. In this paper, we provide an empirical account of the nature of instrumental vs. ritualistic use of smartphones based on data collected from 43 Android users over 2 weeks through logging application use and collecting ESM survey data about the purpose of use. We describe the phone-use behaviors users exhibit when seeking instrumental and ritualistic gratifications, and we develop a classification scheme for predicting ritualistic vs. instrumental use with an accuracy of 77% for a general model, increasing to more than 97% with a sliding confidence threshold. We discuss how such a model might be used to improve the experience of smartphone users in application areas such as recommender systems and social media.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {634–645},
numpages = {12},
keywords = {mobile phones, uses and gratifications, smartphones, machine learning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971755,
author = {Singh, Vivek K. and Agarwal, Rishav R.},
title = {Cooperative <i>Phoneotypes</i>: Exploring Phone-Based Behavioral Markers of Cooperation},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971755},
doi = {10.1145/2971648.2971755},
abstract = {Cooperation is a fundamental human concept studied across multiple social and biological disciplines. Traditional methods for eliciting an individual's propensity to cooperate have included surveys and laboratory experiments and multiple such studies have connected an individual's cooperation level with her social behavior. We describe a novel approach to model an individual's cooperation level based on her phoneotype i.e. a composite of an individual's traits as observable via a mobile phone. This phone sensing-based method can potentially complement surveys, thus providing a cheaper, faster, automated method for generating insights into cooperation levels of users. Based on a 10-week field study involving 54 participants, we report that: (1) multiple phone-based signals were significantly associated with participant's cooperation attitudes; and (2) combining phone-based signals yielded a predictive model with AUCROC of 0.945 that performed significantly better than a comparable demography-based model at predicting individual cooperation propensities. The results pave the way for individuals and organizations to identify more cooperative peers in personal, social, and commerce related settings.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {646–657},
numpages = {12},
keywords = {mobile sensing, phoneotype, mobile supported cooperation, behavioral sensing, cooperation},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971745,
author = {Mashhadi, Afra and Acer, Utku G\"{u}nay and Boran, Aidan and Scholl, Philipp M. and Forlivesi, Claudio and Vanderhulst, Geert and Kawsar, Fahim},
title = {Exploring Space Syntax on Entrepreneurial Opportunities with Wi-Fi Analytics},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971745},
doi = {10.1145/2971648.2971745},
abstract = {Industrial events and exhibitions play a powerful role in creating social relations amongst individuals and firms, enabling them to expand their social network so to acquire resources. However, often these events impose a spatial structure which impacts encounter opportunities. In this paper, we study the impact that the spatial configuration has on the formation of network relations. We designed, developed and deployed a Wi-Fi analytics solution comprising of wearable Wi-Fi badges and gateways in a large scale industrial exhibition event to study the spatio-temporal trajectories of the 2.5K+ attendees including two special groups: 34 investors and 27 entrepreneurs. Our results suggest that certain zones with designated functionalities play a key role in forming social ties across attendees and the different behavioural properties of investors and entrepreneurs can be explained through a spatial lens. Based on our findings we offer three concrete recommendations for future organisers of networking events.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {658–669},
numpages = {12},
keywords = {network sensing, people analytics, space syntax},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971688,
author = {Wang, Wei and Yang, Lin and Zhang, Qian},
title = {Touch-and-Guard: Secure Pairing through Hand Resonance},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971688},
doi = {10.1145/2971648.2971688},
abstract = {Securely pairing wearables with another device is the key to many promising applications, such as mobile payment, sensitive data transfer and secure interactions with smart home devices. This paper presents Touch-And-Guard (TAG), a system that uses hand touch as an intuitive manner to establish a secure connection between a wristband wearable and the touched device. It generates secret bits from hand resonant properties, which are obtained using accelerometers and vibration motors. The extracted secret bits are used by both sides to authenticate each other and then communicate confidentially. The ubiquity of accelerometers and motors presents an immediate market for our system. We demonstrate the feasibility of our system using an experimental prototype and conduct experiments involving 12 participants with 1440 trials. The results indicate that we can generate secret bits at a rate of 7.84 bit/s, which is 58% faster than conventional text input PIN authentication. We also show that our system is resistant to acoustic eavesdroppers in proximity.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {670–681},
numpages = {12},
keywords = {modal analysis, secure piaring, resonance, wearable},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971693,
author = {Li, Yuanchun and Guo, Yao and Chen, Xiangqun},
title = {PERUIM: Understanding Mobile Application Privacy with Permission-UI Mapping},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971693},
doi = {10.1145/2971648.2971693},
abstract = {Current mobile operating systems such as Android employ the permission-based access control mechanism, but it is difficult for users to understand how and why the permissions are used within a particular application. This paper introduces permission-UI mapping as an easy-to-understand representation to illustrate how permissions are used by different UI components within a given application. Connecting UI components to permissions helps users to understand the purpose of permission requests and also makes it possible to illustrate permission requests in a fine-grained manner. We propose PERUIM to extract the permission-UI mapping from an application based on both dynamic and static analysis, and represent the analysis results with a graphical representation. Experiments on popular mobile applications demonstrate the accuracy and applicability of the proposed approach.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {682–693},
numpages = {12},
keywords = {mobile applications, permission, user interface (UI), android, functionality},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971741,
author = {Boutsis, Ioannis and Kalogeraki, Vana},
title = {Location Privacy for Crowdsourcing Applications},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971741},
doi = {10.1145/2971648.2971741},
abstract = {This paper contributes to mobile crowdsourcing applications by developing a privacy preserving framework that enables users to contribute content to the community while controlling their privacy exposure. One fundamental challenge in such applications is how to preserve user privacy, as participants may end up revealing a great deal of user-identified, geo-located data, which can easily unfold user trajectories or sensitive locations (e.g., user's home or work location). In this paper we develop PROMPT, a highly efficient privacy preserving framework that runs locally on mobile devices. PROMPT relies on a novel geometric approximation approach to preserve user privacy, by evaluating the privacy exposure of users before sharing their geo-located data. Our detailed experimental evaluation using real-world datasets illustrates that our approach is effective, practical and has low overhead on smartphones.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {694–705},
numpages = {12},
keywords = {coresets, location sharing, privacy preservation},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971753,
author = {Saleheen, Nazir and Chakraborty, Supriyo and Ali, Nasir and Rahman, Md Mahbubur and Hossain, Syed Monowar and Bari, Rummana and Buder, Eugene and Srivastava, Mani and Kumar, Santosh},
title = {MSieve: Differential Behavioral Privacy in Time Series of Mobile Sensor Data},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971753},
doi = {10.1145/2971648.2971753},
abstract = {Differential privacy concepts have been successfully used to protect anonymity of individuals in population-scale analysis. Sharing of mobile sensor data, especially physiological data, raise different privacy challenges, that of protecting private behaviors that can be revealed from time series of sensor data. Existing privacy mechanisms rely on noise addition and data perturbation. But the accuracy requirement on inferences drawn from physiological data, together with well-established limits within which these data values occur, render traditional privacy mechanisms inapplicable. In this work, we define a new behavioral privacy metric based on differential privacy and propose a novel data substitution mechanism to protect behavioral privacy. We evaluate the efficacy of our scheme using 660 hours of ECG, respiration, and activity data collected from 43 participants and demonstrate that it is possible to retain meaningful utility, in terms of inference accuracy (90%), while simultaneously preserving the privacy of sensitive behaviors.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {706–717},
numpages = {12},
keywords = {mobile health, differential privacy, behavioral privacy},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971737,
author = {Fan, Zipei and Song, Xuan and Shibasaki, Ryosuke and Li, Tao and Kaneda, Hodaka},
title = {CityCoupling: Bridging Intercity Human Mobility},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971737},
doi = {10.1145/2971648.2971737},
abstract = {There are two broad categories of citywide human mobility, routine, composed of daily or periodic travel, and rare, which occurs during events such as the Olympic Games or natural disasters. State-of-the-art studies have shown that routine mobility patterns can be modeled stochastically, while rare human mobility modeling, essential to a variety of urban computing scenarios, such as emergency management and traffic regulation, is a much more challenging and understudied problem. Instead of training a rare-event-specific human mobility model, which suffers from the particularity of the rare events, in this paper we provide a new insight into rare events and propose a novel algorithm, CityCoupling, which establishes an intercity spatial mapping that uses human mobility in one city as input and reproduces human mobility in another city. More intuitively, we attempt to answer the question "What if this rare event happened in another city?". To find the optimal intercity spatial mapping, we utilize an expectation-maximization algorithm to estimate a probabilistic geographical correspondence matrix by regarding intercity trajectory matching as latent variables. Thereafter, a Gibbs sampling-based multiple hidden Markov model generates simulated trajectories. We apply our approach to a large mobile phone GPS dataset in Japan and determine the spatial mapping between Tokyo and Osaka to transfer the human mobility at the Great Eastern Japan Earthquake in Tokyo, which was heavily affected, to simulate what might have occurred if Osaka had been struck by the earthquake. We conduct the evaluation by assuming that New Year's Countdown is a rare event that occurs simultaneously in both Tokyo and Osaka, and thus we quantitatively compare our simulation with the ground truth in Osaka.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {718–728},
numpages = {11},
keywords = {emergency management, urban computing, big data, human mobility},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971664,
author = {Xu, Mengwen and Wang, Dong and Li, Jian},
title = {DESTPRE: A Data-Driven Approach to Destination Prediction for Taxi Rides},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971664},
doi = {10.1145/2971648.2971664},
abstract = {With the wide use of mobile devices, predicting the destination of moving vehicles has become an increasingly important problem for location based recommendation systems and destination-based advertising. Most existing approaches are based on various Markov chain models, in which the historical trajectories are used to train the model and the top-k most probable destinations are returned. We identify certain limitations of the previous approaches. Instead, we propose a new data-driven framework, called DestPre, which is not based on a probabilistic model, but directly operates on the trajectories and makes the prediction. We make use of only historic trajectories, without individual identity information. Our design of DestPre, although simple, is a result of several useful observations from the real trajectory data. DestPre involves an index based on Bucket PR Quadtree and Minwise hashing, for efficiently retrieving similar trajectories, and a clustering on destinations for predictions. By incorporating some additional ideas, we show that the prediction accuracy can be further improved. We have conducted extensive experiments on real Beijing Taxi dataset. The experimental results demonstrate the effectiveness of DestPre.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {729–739},
numpages = {11},
keywords = {quadtree, historical trajectories, minhash, destination prediction},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971702,
author = {Wu, Hao and Sun, Weiwei and Zheng, Baihua},
title = {Is Only One Gps Position Sufficient to Locate You to the Road Network Accurately?},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971702},
doi = {10.1145/2971648.2971702},
abstract = {Locating only one GPS position to a road segment accurately is crucial to many location-based services such as mobile taxi-hailing service, geo-tagging, POI check-in, etc. This problem is challenging because of errors including the GPS errors and the digital map errors (misalignment and the same representation of bidirectional roads) and a lack of context information. To the best of our knowledge, no existing work studies this problem directly and the work to reduce GPS signal errors by considering hardware aspect is the most relevant. Consequently, this work is the first attempt to solve the problem of locating one GPS position to a road segment. We study the problem in a data-driven view to make this process ubiquitous by proposing a tractable, efficient and robust generative model. In addition, we extend our solution to the real application scenario, i.e., taxi-hailing service, and propose an approach to further improve the result accuracy by considering destination information. We use the real taxi GPS data to evaluate our approach. The results show that our approach outperforms all the existing approaches significantly while maintaining robustness, and it can achieve an accuracy as high as 90% in some situations.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {740–751},
numpages = {12},
keywords = {GPS, positioning, location-based services, map matching},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971718,
author = {Konishi, Tatsuya and Maruyama, Mikiya and Tsubouchi, Kota and Shimosaka, Masamichi},
title = {CityProphet: City-Scale Irregularity Prediction Using Transit App Logs},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971718},
doi = {10.1145/2971648.2971718},
abstract = {Thanks to the recent popularity of GPS-enabled mobile phones, modeling people flow or population dynamics is attracting a great deal of attention. Advances in methods where regular population patterns with respect to factors such as holidays or weekdays are extracted have provided successful results in irregularity detection. With large-scale crowded events such as fireworks, it is crucial that there be enough time to take countermeasures against the irregular congestion, i.e., irregularity prediction. It remains a tough challenge to predict population from GPS trace logs with existing methods.To tackle this problem, we focus here on route search logs, since aggregation of the location-oriented queries of individual plans serves as a mirror of short-term city-scale events, in contrast to GPS mobility logs. This paper presents a brand new framework for city-scale event prediction: CityProphet. By our observation of data where the route search logs related to a future event are in most cases repeatable and accumulated in proportion as the event draws near, we are able to leverage the divergence between the above two properties to predict city-scale irregular events. We demonstrate through experiments using the transit app logs of over 370 million queries that our approach can successfully predict city-scale crowded events one week in advance.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {752–757},
numpages = {6},
keywords = {urban computing, transit app logs, city-scale irregularity prediction, user schedule information},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971752,
author = {Costa, Jean and Adams, Alexander T. and Jung, Malte F. and Guimbreti\`{e}re, Fran\c{c}ois and Choudhury, Tanzeem},
title = {EmotionCheck: Leveraging Bodily Signals and False Feedback to Regulate Our Emotions},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971752},
doi = {10.1145/2971648.2971752},
abstract = {In this paper we demonstrate that it is possible to help individuals regulate their emotions with mobile interventions that leverage the way we naturally react to our bodily signals. Previous studies demonstrate that the awareness of our bodily signals, such as our heart rate, directly influences the way we feel. By leveraging these findings we designed a wearable device to regulate user's anxiety by providing a false feedback of a slow heart rate. The results of an experiment with 67 participants show that the device kept the anxiety of the individuals in low levels when compared to the control group and the other conditions. We discuss the implications of our findings and present some promising directions for designing and developing this type of intervention for emotion regulation.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {758–769},
numpages = {12},
keywords = {false feedback, emotion, emotion regulation, anxiety, interoceptive, stress, intervention, heart rate, feedback},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971724,
author = {Lu, Xuan and Ai, Wei and Liu, Xuanzhe and Li, Qian and Wang, Ning and Huang, Gang and Mei, Qiaozhu},
title = {Learning from the Ubiquitous Language: An Empirical Analysis of Emoji Usage of Smartphone Users},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971724},
doi = {10.1145/2971648.2971724},
abstract = {Emojis have been widely used to simplify emotional expression and enrich user experience. As an interesting practice of ubiquitous computing, emojis are adopted by Internet users from many different countries, on many devices (particularly popular on smartphones), and in many applications. The "ubiquitous" usage of emojis enables us to study and compare user behaviors and preferences across countries and cultures. We present an analysis on how smartphone users use emojis based on a very large data set collected from a popular emoji keyboard. The data set contains a complete month of emoji usage of 3.88 million active users from 212 countries and regions. We demonstrate that the categories and frequencies of emojis used by these users provide rich signals for the identification and the understanding of cultural differences of smartphone users. Users from different countries present significantly different preferences on emojis, which complies with the well-known Hofstede's cultural dimensions model.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {770–780},
numpages = {11},
keywords = {data mining, cultural difference, emoji},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971654,
author = {Mottelson, Aske and Hornb\ae{}k, Kasper},
title = {An Affect Detection Technique Using Mobile Commodity Sensors in the Wild},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971654},
doi = {10.1145/2971648.2971654},
abstract = {Current techniques to computationally detect human affect often depend on specialized hardware, work only in laboratory settings, or require substantial individual training. We use sensors in commodity smartphones to estimate affect in the wild with no training time based on a link between affect and movement. The first experiment had 55 participants do touch interactions after exposure to positive or neutral emotion-eliciting films; negative affect resulted in faster but less precise interactions, in addition to differences in rotation and acceleration. Using off-the-shelf machine learning algorithms we report 89.1% accuracy in binary affective classification, grouping participants by their self-assessments. A follow up experiment validated findings from the first experiment; the experiment collected naturally occurring affect of 127 participants, who again did touch interactions. Results demonstrate that affect has direct behavioral effect on mobile interaction and that affect detection using common smartphone sensors is feasible.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {781–792},
numpages = {12},
keywords = {touch, affective computing, affect detection, smartphone, crowdsourcing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971751,
author = {Abdullah, Saeed and Czerwinski, Mary and Mark, Gloria and Johns, Paul},
title = {Shining (Blue) Light on Creative Ability},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971751},
doi = {10.1145/2971648.2971751},
abstract = {Given the importance of creativity for both personal and societal achievements, there have been consistent efforts to stimulate creative ability. But an important environmental factor --- blue (i.e., short wavelength) light --- has been relatively unexplored to date. Blue light improves a number of cognitive processes (e.g., attention, working memory and sleep) known to influence our creative abilities. In this study, we investigate the effects of blue light on enhancing creativity in tasks and compare it to the effects of walking, which has been shown to stimulate creative ability. Based on data from 21 participants over 2 weeks, we found that blue light resulted in a 24.3% increase in convergent thinking ability, while walking improved divergent thinking by 18%. We discuss the implications of the findings within the context of UbiComp research. To the best of our knowledge, this is the first systematic examination of the impact of blue light on convergent and divergent thinking ability.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {793–804},
numpages = {12},
keywords = {convergent thinking, creativity, performance, divergent thinking, circadian rhythms},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971756,
author = {Choi, Woohyeok and Song, Aejin and Edge, Darren and Fukumoto, Masaaki and Lee, Uichin},
title = {Exploring User Experiences of Active Workstations: A Case Study of under Desk Elliptical Trainers},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971756},
doi = {10.1145/2971648.2971756},
abstract = {Prolonged inactivity in office workers is a well-known contributor to various diseases, such as obesity, diabetes, and cardiovascular dysfunction. In recent years, active workstations that incorporate physical activities such as walking and cycling into the workplace have gained significant popularity, owing to the accessibility of the workouts they offer. While their efficacy is well documented in medical and physiological literature, research regarding the user experience of such systems has rarely been performed, despite its importance for interactive systems design. As a case study, we focus on active workstations that incorporate under desk elliptical trainers, and conduct controlled experiments regarding work performance and a four week long field deployment to explore user experience with 13 participants. We investigate how such workouts influence work performance, when and why workers work out during working hours, and the general feelings of workers regarding usage. Our experimental results indicate that while work performance is not influenced, the cognitive load of tasks critically influences workout decisions. Active workstations were alternatively used as mood enhancers, footrests, and for fidgeting, and there exist unique social and technical aspects to be addressed, such as noise issues and space constraints. Our results provide significant implications for the design of active workstations and interactive workplaces in general.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {805–816},
numpages = {12},
keywords = {office furniture, health intervention, active workstations, exercise equipment},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971683,
author = {Mueller, Florian 'Floyd' and Pell, Sarah Jane},
title = {Technology Meets Adventure: Learnings from an Earthquake-Interrupted Mt. Everest Expedition},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971683},
doi = {10.1145/2971648.2971683},
abstract = {HCI is increasingly interested in supporting people's physically active lifestyle. Adventure is part of this lifestyle, and to contribute an HCI perspective on adventure, we present an autoethnographical account of an expedition via Nepal to Mt. Everest. During this expedition, on the 25th and 26th April 2015, two devastating earthquakes struck the region. We believe we can learn from such extreme experiences and therefore reflect on this epic adventure through a set of themes to articulate two dimensions (expected-unexpected and instrumental-experiential) in order to identify four roles for adventure-technology: as coach, rescuer, documentarian and mentor. Our work aims to provide HCI designers with an initial conceptual lens to embrace adventure, and more generally, to expand our knowledge of supporting people's physically active lifestyle.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {817–828},
numpages = {12},
keywords = {whole-body interaction, climbing, trekking, adventure, extreme sports, physical activity, exertion},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971656,
author = {Epstein, Daniel A. and Kang, Jennifer H. and Pina, Laura R. and Fogarty, James and Munson, Sean A.},
title = {Reconsidering the Device in the Drawer: Lapses as a Design Opportunity in Personal Informatics},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971656},
doi = {10.1145/2971648.2971656},
abstract = {People stop using personal tracking tools over time, referred to as the lapsing stage of their tool use. We explore how designs can support people when they lapse in tracking, considering how to design data representations for a person who lapses in Fitbit use. Through a survey of 141 people who had lapsed in using Fitbit, we identified three use patterns and four perspectives on tracking. Participants then viewed seven visual representations of their Fitbit data and seven approaches to framing this data. Participant Fitbit use and perspective on tracking influenced their preference, which we surface in a series of contrasts. Specifically, our findings guide selecting appropriate aggregations from Fitbit use (e.g., aggregate more when someone has less data), choosing an appropriate framing technique from tracking perspective (e.g., ensure framing aligns with how the person feels about tracking), and creating appropriate social comparisons (e.g., portray the person positively compared to peers). We conclude by discussing how these contrasts suggest new designs and opportunities in other tracking domains.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {829–840},
numpages = {12},
keywords = {abandonment, personal informatics, lapsing, re-engagement},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971652,
author = {Chen, Longbiao and Zhang, Daqing and Wang, Leye and Yang, Dingqi and Ma, Xiaojuan and Li, Shijian and Wu, Zhaohui and Pan, Gang and Nguyen, Thi-Mai-Trang and Jakubowicz, J\'{e}r\'{e}mie},
title = {Dynamic Cluster-Based over-Demand Prediction in Bike Sharing Systems},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971652},
doi = {10.1145/2971648.2971652},
abstract = {Bike sharing is booming globally as a green transportation mode, but the occurrence of over-demand stations that have no bikes or docks available greatly affects user experiences. Directly predicting individual over-demand stations to carry out preventive measures is difficult, since the bike usage pattern of a station is highly dynamic and context dependent. In addition, the fact that bike usage pattern is affected not only by common contextual factors (e.g., time and weather) but also by opportunistic contextual factors (e.g., social and traffic events) poses a great challenge. To address these issues, we propose a dynamic cluster-based framework for over-demand prediction. Depending on the context, we construct a weighted correlation network to model the relationship among bike stations, and dynamically group neighboring stations with similar bike usage patterns into clusters. We then adopt Monte Carlo simulation to predict the over-demand probability of each cluster. Evaluation results using real-world data from New York City and Washington, D.C. show that our framework accurately predicts over-demand clusters and outperforms the baseline methods significantly.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {841–852},
numpages = {12},
keywords = {over-demand prediction, bike sharing system, urban data},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971703,
author = {Palazzi, Andrea and Calderara, Simone and Bicocchi, Nicola and Vezzali, Loris and di Bernardo, Gian Antonio and Zambonelli, Franco and Cucchiara, Rita},
title = {Spotting Prejudice with Nonverbal Behaviours},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971703},
doi = {10.1145/2971648.2971703},
abstract = {Despite prejudice cannot be directly observed, nonverbal behaviours provide profound hints on people inclinations. In this paper, we use recent sensing technologies and machine learning techniques to automatically infer the results of psychological questionnaires frequently used to assess implicit prejudice. In particular, we recorded 32 students discussing with both white and black collaborators. Then, we identified a set of features allowing automatic extraction and measured their degree of correlation with psychological scores. Results confirmed that automated analysis of nonverbal behaviour is actually possible thus paving the way for innovative clinical tools and eventually more secure societies.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {853–862},
numpages = {10},
keywords = {nonverbal behaviours, prejudice, social interactions},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971672,
author = {Chatterjee, Soujanya and Hovsepian, Karen and Sarker, Hillol and Saleheen, Nazir and al'Absi, Mustafa and Atluri, Gowtham and Ertin, Emre and Lam, Cho and Lemieux, Andrine and Nakajima, Motohiro and Spring, Bonnie and Wetter, David W. and Kumar, Santosh},
title = {MCrave: Continuous Estimation of Craving during Smoking Cessation},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971672},
doi = {10.1145/2971648.2971672},
abstract = {Craving usually precedes a lapse for impulsive behaviors such as overeating, drinking, smoking, and drug use. Passive estimation of craving from sensor data in the natural environment can be used to assist users in coping with craving. In this paper, we take the first steps towards developing a computational model to estimate cigarette craving (during smoking abstinence) at the minute-level using mobile sensor data. We use 2,012 hours of sensor data and 1,812 craving self-reports from 61 participants in a smoking cessation study. To estimate craving, we first obtain a continuous measure of stress from sensor data. We find that during hours of day when craving is high, stress associated with self-reported high craving is greater than stress associated with low craving. We use this and other insights to develop feature functions, and encode them as pattern detectors in a Conditional Random Field (CRF) based model to infer craving probabilities.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {863–874},
numpages = {12},
keywords = {craving, mobile health, smoking cessation, stress},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971666,
author = {Natarajan, Annamalai and Angarita, Gustavo and Gaiser, Edward and Malison, Robert and Ganesan, Deepak and Marlin, Benjamin M.},
title = {Domain Adaptation Methods for Improving Lab-to-Field Generalization of Cocaine Detection Using Wearable ECG},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971666},
doi = {10.1145/2971648.2971666},
abstract = {Mobile health research on illicit drug use detection typically involves a two-stage study design where data to learn detectors is first collected in lab-based trials, followed by a deployment to subjects in a free-living environment to assess detector performance. While recent work has demonstrated the feasibility of wearable sensors for illicit drug use detection in the lab setting, several key problems can limit lab-to-field generalization performance. For example, lab-based data collection often has low ecological validity, the ground-truth event labels collected in the lab may not be available at the same level of temporal granularity in the field, and there can be significant variability between subjects. In this paper, we present domain adaptation methods for assessing and mitigating potential sources of performance loss in lab-to-field generalization and apply them to the problem of cocaine use detection from wearable electrocardiogram sensor data.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {875–885},
numpages = {11},
keywords = {prior probability shift, cocaine detection, covariate shift, wearable sensors, classification, domain adaptation},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971740,
author = {Wang, Rui and Aung, Min S. H. and Abdullah, Saeed and Brian, Rachel and Campbell, Andrew T. and Choudhury, Tanzeem and Hauser, Marta and Kane, John and Merrill, Michael and Scherer, Emily A. and Tseng, Vincent W. S. and Ben-Zeev, Dror},
title = {CrossCheck: Toward Passive Sensing and Detection of Mental Health Changes in People with Schizophrenia},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971740},
doi = {10.1145/2971648.2971740},
abstract = {Early detection of mental health changes in individuals with serious mental illness is critical for effective intervention. CrossCheck is the first step towards the passive monitoring of mental health indicators in patients with schizophrenia and paves the way towards relapse prediction and early intervention. In this paper, we present initial results from an ongoing randomized control trial, where passive smartphone sensor data is collected from 21 outpatients with schizophrenia recently discharged from hospital over a period ranging from 2-8.5 months. Our results indicate that there are statistically significant associations between automatically tracked behavioral features related to sleep, mobility, conversations, smart-phone usage and self-reported indicators of mental health in schizophrenia. Using these features we build inference models capable of accurately predicting aggregated scores of mental health indicators in schizophrenia with a mean error of 7.6% of the score range. Finally, we discuss results on the level of personalization that is needed to account for the known variations within people. We show that by leveraging knowledge from a population with schizophrenia, it is possible to train accurate personalized models that require fewer individual-specific data to quickly adapt to new users.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {886–897},
numpages = {12},
keywords = {mobile sensing, mental health},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971761,
author = {Huang, Yu and Xiong, Haoyi and Leach, Kevin and Zhang, Yuyan and Chow, Philip and Fua, Karl and Teachman, Bethany A. and Barnes, Laura E.},
title = {Assessing Social Anxiety Using Gps Trajectories and Point-of-Interest Data},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971761},
doi = {10.1145/2971648.2971761},
abstract = {Mental health problems are highly prevalent and appear to be increasing in frequency and severity among the college student population. The upsurge in mobile and wearable wireless technologies capable of intense, longitudinal tracking of individuals, provide valuable opportunities to examine temporal patterns and dynamic interactions of key variables in mental health research. In this paper, we present a feasibility study leveraging non-invasive mobile sensing technology to passively assess college students' social anxiety, one of the most common disorders in the college student population. We have first developed a smartphone application to continuously track GPS locations of college students, then we built an analytic infrastructure to collect the GPS trajectories and finally we analyzed student behaviors (e.g. studying or staying at home) using Point-Of-Interest (POI). The whole framework supports intense, longitudinal, dynamic tracking of college students to evaluate how their anxiety and behaviors change in the college campus environment. The collected data provides critical information about how students' social anxiety levels and their mobility patterns are correlated. Our primary analysis based on 18 college students demonstrated that social anxiety level is significantly correlated with places students' visited and location transitions.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {898–903},
numpages = {6},
keywords = {social anxiety, location semantics, GPS, mobile sensing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971733,
author = {Yang, Zhe and Bao, Yuting and Luo, Chuhao and Zhao, Xingya and Zhu, Siyu and Peng, Chunyi and Liu, Yunxin and Wang, Xinbing},
title = {ARTcode: Preserve Art and Code in Any Image},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971733},
doi = {10.1145/2971648.2971733},
abstract = {The ubiquitous QR codes and some similar barcodes are becoming a convenient and popular approach to impromptu communication between mobile devices and their surrounding cyber-physical world. However, such codes suffer from two common drawbacks: poor viewing experience and inability to be identified through itself. In this work, we propose ART-code-- Adaptive Robust doT matrix barcode, which aims to preserve ART and CODE features in one visual pattern. It works on any surface (paper or electronic displays) and is able to convert any image or any form of human-readable contents (e.g., a picture, a logo, a slogan) into an ARTcode. It looks like an image which retains human-readable and aesthetically pleasant contents, and in the meanwhile, it acts as a QR code which conveys data bits over the visual channel. The core enablers in ARTcode are (1) the design of the colored dot matrix for data embedding with little distortion from the original image and (2) a comprehensive error correction scheme which enhances decoding robustness against noises and interferences from the original image in ARTcode. We implement ARTcode with the receiver on Android phones and the sender from a PC or a phone (it can be printed in paper). We conduct extensive user survey and experiments for evaluation. It validates the effectiveness and wide applicability of ARTcode: It works well with all of 197 images randomly downloaded, covering representative categories of the gray-scale images, logos, colored ones with low/medium/strong contrasts. The image quality is quite acceptable in a subjective user-perception survey with 50 participants and data communication accuracy achieves as high as 99% in almost all the cases (&gt; 96% raw accuracy in ARTcode without error detection and other schemes).},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {904–915},
numpages = {12},
keywords = {ARTcode, data hiding, visualization barcode, screen-camera communication},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971661,
author = {Xie, Lei and Sun, Jianqiang and Cai, Qingliang and Wang, Chuyu and Wu, Jie and Lu, Sanglu},
title = {Tell Me What i See: Recognize RFID Tagged Objects in Augmented Reality Systems},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971661},
doi = {10.1145/2971648.2971661},
abstract = {Nowadays, people usually depend on augmented reality (AR) systems to obtain an augmented view in a real-world environment. With the help of advanced AR technology (e.g. object recognition), users can effectively distinguish multiple objects of different types. However, these techniques can only offer limited degrees of distinctions among different objects and cannot provide more inherent information about these objects. In this paper, we leverage RFID technology to further label different objects with RFID tags. We deploy additional RFID antennas to the COTS depth camera and propose a continuous scanning-based scheme to scan the objects, i.e., the system continuously rotates and samples the depth of field and RF-signals from these tagged objects. In this way, by pairing the tags with the objects according to the correlations between the depth of field and RF-signals, we can accurately identify and distinguish multiple tagged objects to realize the vision of "tell me what I see" from the augmented reality system. For example, in front of multiple unknown people wearing RFID tagged badges in public events, our system can identify these people and further show their inherent information from the RFID tags, such as their names, jobs, titles, etc. We have implemented a prototype system to evaluate the actual performance. The experiment results show that our solution achieves an average match ratio of 91% in distinguishing up to dozens of tagged objects with a high deployment density.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {916–927},
numpages = {12},
keywords = {RFID, prototype design, augmented reality system},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971743,
author = {Ali, Mohammad Rafayet and Ciancio, Facundo and Zhao, Ru and Naim, Iftekhar and Hoque, Mohammed (Ehsan)},
title = {ROC Comment: Automated Descriptive and Subjective Captioning of Behavioral Videos},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971743},
doi = {10.1145/2971648.2971743},
abstract = {We present an automated interface, ROC Comment, for generating natural language comments on behavioral videos. We focus on the domain of public speaking, which many people consider their greatest fear. We collect a dataset of 196 public speaking videos from 49 individuals and gather 12,173 comments, generated by more than 500 independent human judges. We then train a k-Nearest-Neighbor (k-NN) based model by extracting prosodic (e.g., volume) and facial (e.g., smiles) features. Given a new video, we extract features and select the closest comments using k-NN model. We further filter the comments by clustering them using DBScan, and eliminating the outliers. Evaluation of our system with 30 participants conclude that while the generated comments are helpful, there is room for improvement in further personalizing them. Our model has been deployed online, allowing individuals to upload their videos and receive open-ended and interpretative comments. Our system is available at http://tinyurl.com/roccomment.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {928–933},
numpages = {6},
keywords = {automated video captioning, public speaking, comment generation, objective feedback},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971706,
author = {Funk, Markus and Kosch, Thomas and Schmidt, Albrecht},
title = {Interactive Worker Assistance: Comparing the Effects of in-Situ Projection, Head-Mounted Displays, Tablet, and Paper Instructions},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971706},
doi = {10.1145/2971648.2971706},
abstract = {With increasing complexity of assembly tasks and an increasing number of product variants, instruction systems providing cognitive support at the workplace are becoming more important. Different instruction systems for the workplace provide instructions on phones, tablets, and head-mounted displays (HMDs). Recently, many systems using in-situ projection for providing assembly instructions at the workplace have been proposed and became commercially available. Although comprehensive studies comparing HMD and tablet-based systems have been presented, in-situ projection has not been scientifically compared against state-of-the-art approaches yet. In this paper, we aim to close this gap by comparing HMD instructions, tablet instructions, and baseline paper instructions to in-situ projected instructions using an abstract Lego Duplo assembly task. Our results show that assembling parts is significantly faster using in-situ projection and locating positions is significantly slower using HMDs. Further, participants make less errors and have less perceived cognitive load using in-situ instructions compared to HMD instructions.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {934–939},
numpages = {6},
keywords = {assistive systems, providing instructions, task guidance, in-situ projection, head-mounted displays, augmented reality},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971731,
author = {Mittal, Gaurav and Yagnik, Kaushal B. and Garg, Mohit and Krishnan, Narayanan C.},
title = {SpotGarbage: Smartphone App to Detect Garbage Using Deep Learning},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971731},
doi = {10.1145/2971648.2971731},
abstract = {Maintaining a clean and hygienic civic environment is an indispensable yet formidable task, especially in developing countries. With the aim of engaging citizens to track and report on their neighborhoods, this paper presents a novel smartphone app, called SpotGarbage, which detects and coarsely segments garbage regions in a user-clicked geo-tagged image. The app utilizes the proposed deep architecture of fully convolutional networks for detecting garbage in images. The model has been trained on a newly introduced Garbage In Images (GINI) dataset, achieving a mean accuracy of 87.69%. The paper also proposes optimizations in the network architecture resulting in a reduction of 87.9% in memory usage and 96.8% in prediction time with no loss in accuracy, facilitating its usage in resource constrained smartphones.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {940–945},
numpages = {6},
keywords = {garbage detection, computer vision, deep learning, smartphone, android, fully convolutional neural networks},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971676,
author = {Min, Chulhong and Lee, Seungchul and Lee, Changhun and Lee, Youngki and Kang, Seungwoo and Choi, Seungpyo and Kim, Wonjung and Song, Junehwa},
title = {PADA: Power-Aware Development Assistant for Mobile Sensing Applications},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971676},
doi = {10.1145/2971648.2971676},
abstract = {We propose PADA, a new power evaluation tool to measure and optimize power use of mobile sensing applications. Our motivational study with 53 professional developers shows they face huge challenges in meeting power requirements. The key challenges are from the significant time and effort for repetitive power measurements since the power use of sensing applications needs to be evaluated under various real-world usage scenarios and sensing parameters. PADA enables developers to obtain enriched power information under diverse usage scenarios in development environments without deploying and testing applications on real phones in real-life situations. We conducted two user studies with 19 developers to evaluate the usability of PADA. We show that developers benefit from using PADA in the implementation and power tuning of mobile sensing applications.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {946–957},
numpages = {12},
keywords = {mobile sensing applications, power-aware development},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971728,
author = {Chon, Yohan and Lee, GwangMin and Ha, Rhan and Cha, Hojung},
title = {Crowdsensing-Based Smartphone Use Guide for Battery Life Extension},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971728},
doi = {10.1145/2971648.2971728},
abstract = {With the increasing popularity of smartphones, battery life is among the most crucial issues for mobile users. This paper presents a crowdsensing-based use guide to extend the lifetime of smartphones. The system answers a question raised by phone usage: Why is my phone battery draining quickly compared to others phones despite running the same applications? The proposed system pinpoints the major causes of battery drain in terms of both hardware and software aspects. In relation to the hardware aspect, the system quantifies degree of battery aging as a ratio metric; an estimate of 50% indicates that the battery is at half of full capacity, meaning that battery usage time is approximately half that of a new battery. The system automatically profiles battery age based on charging duration data collected by crowdsensing. In its software aspect, the system guides phone configuration to extend application usage times. The system mines large-scale usage data to infer the major energy holes in a user's phone usage. The scheme works autonomously without user intervention and does not require any external equipment. Extensive evaluation with 3,000 users demonstrated that the proposed scheme successfully extends battery life for typical mobile users.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {958–969},
numpages = {12},
keywords = {smartphone sensing, mobile crowdsourcing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971660,
author = {Aras, Shravan and Gniady, Chris},
title = {GreenTouch: Transparent Energy Management for Cellular Data Radios},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971660},
doi = {10.1145/2971648.2971660},
abstract = {Smartphones come equipped with multiple radios for cellular data communication such as 4G LTE, 3G, and 2G, that offer different bandwidths and power profiles. 4G LTE offers the highest bandwidth and is desired by users as it offers quick response while browsing the Internet, streaming media, or utilizing numerous network aware applications available to users. However, majority of the time this high bandwidth level is unnecessary, and the bandwidth demand can be easily met by 3G radios at a reduced power level. While 2G radios demand even lower power, they do not offer adequate bandwidth to meet the demand of interactive applications; however, the 2G radio may be utilized to provide connectivity when the phone is in the standby mode. To address different demands for bandwidth, we propose GreenTouch, a system that dynamically adapts to the bandwidth demand and system state by switching between 4G LTE, 3G, and 2G with the goal of minimizing delays and maximizing energy efficiency. GreenTouch associates users' behavior to network activity through capturing and correlating user interactions with the touch display. We have used top applications on the Google play store to show the potential of GreenTouch to reduce energy consumption of the radios by 10%, on average, compared to running the applications in the standard Android. This translates to an overall energy savings of 7.5% for the entire smartphone.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {970–980},
numpages = {11},
keywords = {energy saving, dynamic interface switching, 3G, greentouch, 4G, LTE},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971727,
author = {Kolamunna, Harini and Hu, Yining and Perino, Diego and Thilakarathna, Kanchana and Makaroff, Dwight and Guan, Xinlong and Seneviratne, Aruna},
title = {AFV: Enabling Application Function Virtualization and Scheduling in Wearable Networks},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971727},
doi = {10.1145/2971648.2971727},
abstract = {Smart wearable devices are widely available today and changing the way mobile applications are being developed. Applications can dynamically leverage the capabilities of wearable devices worn by the user for optimal resource usage and information accuracy, depending on the user/device context and application requirements. However, application developers are not yet taking advantage of these cross-device capabilities.We thus design AFV (Application Function Virtualization), a framework enabling automated dynamic function virtualization/scheduling across devices, simplifying context-aware application development. AFV provides a simple set of APIs hiding complex framework tasks and continuously monitors context/application requirements, to enable the dynamic invocation of functions across devices. We show the feasibility of our design by implementing AFV on Android, and the benefits for the user in terms of resource efficiency and quality of experience with relevant use cases.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {981–991},
numpages = {11},
keywords = {smart wearable devices, middleware frameworks, context monitoring, energy utilization, adaptation},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971748,
author = {Early, Kirstin and Fienberg, Stephen E. and Mankoff, Jennifer},
title = {Test Time Feature Ordering with FOCUS: Interactive Predictions with Minimal User Burden},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971748},
doi = {10.1145/2971648.2971748},
abstract = {Predictive algorithms are a critical part of the ubiquitous computing vision, enabling appropriate action on behalf of users. A common class of algorithms, which has seen uptake in ubiquitous computing, is supervised machine learning algorithms. Such algorithms are trained to make predictions based on a set of features (selected at training time). However, features needed at prediction time (such as mobile information that impacts battery life, or information collected from users via experience sampling) may be costly to collect. In addition, both cost and value of a feature may change dynamically based on real-world context (such as battery life or user location) and prediction context (what features are already known, and what their values are). We contribute a framework for dynamically trading off feature cost against prediction quality at prediction time. We demonstrate this work in the context of three prediction tasks: providing prospective tenants estimates for energy costs in potential homes, estimating momentary stress levels from both sensed and user-provided mobile data, and classifying images to facilitate opportunistic device interactions. Our results show that while our approach to cost-sensitive feature selection is up to 45% less costly than competing approaches, error rates are equivalent or better.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {992–1003},
numpages = {12},
keywords = {online data collection, cost-based dynamic question ordering, interactive machine learning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971649,
author = {Choy, Minsoo and Kim, Daehoon and Lee, Jae-Gil and Kim, Heeyoung and Motoda, Hiroshi},
title = {Looking Back on the Current Day: Interruptibility Prediction Using Daily Behavioral Features},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971649},
doi = {10.1145/2971648.2971649},
abstract = {When a person seeks another person's attention, it is of prime importance to assess how interruptible the other person is. Since smartphones are ubiquitously used as communication media these days, interruptibility prediction on smartphones has started to attract great interest from both academia and industry. Previous studies, in general, attempted to model interruptibility using the behaviors at the current moment and in the immediate past (e.g., 5 minutes before). However, a person's interruptibility at a certain moment is indeed affected by his/her preceding behaviors for several reasons. Motivated by this long-term effect, in this paper we propose a novel methodology of extracting features based on past behaviors from smartphone sensor data. The primary difference from previous studies is that we systematically consider a longer history of up to a day in addition to the current point and the immediate past. To represent behaviors in a day accurately and compactly, our methodology divides a day into multiple timeslots and then, for each timeslot, derives relevant features such as the temporal shapes of the time series of the sensor data. In order to verify the advantage of our methodology, we collected a data set of smartphone usage from 25 participants for four weeks and obtained a license to a large-scale public data set constructed from 907 users over approximately nine months. The experimental results on the two data sets show that looking back to the beginning of the current day improves prediction accuracy by up to 16% and 7%, respectively, compared with the baseline and state-of-the-art methods.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1004–1015},
numpages = {12},
keywords = {prediction, availability, sensor, mobile phone, machine learning, human interruptibility, data mining},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971746,
author = {Raykov, Yordan P. and Ozer, Emre and Dasika, Ganesh and Boukouvalas, Alexis and Little, Max A.},
title = {Predicting Room Occupancy with a Single Passive Infrared (PIR) Sensor through Behavior Extraction},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971746},
doi = {10.1145/2971648.2971746},
abstract = {Passive infrared sensors have widespread use in many applications, including motion detectors for alarms, lighting systems and hand dryers. Combinations of multiple PIR sensors have also been used to count the number of humans passing through doorways. In this paper, we demonstrate the potential of the PIR sensor as a tool for occupancy estimation inside of a monitored environment. Our approach shows how flexible nonparametric machine learning algorithms extract useful information about the occupancy from a single PIR sensor. The approach allows us to understand and make use of the motion patterns generated by people within the monitored environment. The proposed counting system uses information about those patterns to provide an accurate estimate of room occupancy which can be updated every 30 seconds. The system was successfully tested on data from more than 50 real office meetings consisting of at most 14 room occupants.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1016–1027},
numpages = {12},
keywords = {behavior extraction, occupancy estimation, PIR sensors, monitoring},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971667,
author = {Halbr\"{u}gge, Marc and Quade, Michael and Engelbrecht, Klaus-Peter and M\"{o}ller, Sebastian and Albayrak, Sahin},
title = {Predicting User Error for Ambient Systems by Integrating Model-Based UI Development and Cognitive Modeling},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971667},
doi = {10.1145/2971648.2971667},
abstract = {With the move to ubiquitous computing, user interfaces (UI) are no longer bound to specific devices. While this problem can be tackled using the model-based UI development (MBUID) process, the usability of the device-specific interfaces is still an open question. We are presenting a combined system that integrates MBUID with a cognitive modeling framework in order to provide usability predictions at development time. Because of their potential impact, our focus within usability problems lies on user errors. These are captured in a cognitive model that capitalizes on meta-information provided by the MBUID system such as the abstract role of a UI element within a task sequence (e.g., input, output, command). The free parameters of the cognitive model were constrained using data from two previous studies. A validation experiment featuring a new application and UI yielded an unexpected error pattern that was nonetheless consistent with the model predictions.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1028–1039},
numpages = {12},
keywords = {smart home, automated usability evaluation, model-based engineering, human error, cognitive user model},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971735,
author = {Ji, Shenggong and Zheng, Yu and Li, Tianrui},
title = {Urban Sensing Based on Human Mobility},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971735},
doi = {10.1145/2971648.2971735},
abstract = {Urban sensing is a foundation of urban computing, collecting data in cities through ubiquitous computing techniques, e.g. using humans as sensors. In this paper, we propose a crowd-based urban sensing framework that maximizes the coverage of collected data in a spatio-temporal space, based on human mobility of participants recruited by a given budget. This framework provides participants with unobstructed tasks that do not break their original commuting plans, while ensuring a sensing program balanced coverage of data that better supports upper-level applications. The framework consists of three components: 1) an objective function to measure data coverage based on the entropy of data with different spatio-temporal granularities; 2) a graph-based task design algorithm to compute a near-optimal task for each participant, using a dynamic programming strategy; 3) a participant recruitment mechanism to find a portion of participants from candidates for a given budget. We evaluate our framework based on a field study and simulations, finding its advantages beyond baselines.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1040–1051},
numpages = {12},
keywords = {urban sensing, urban computing, crowdsensing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971749,
author = {Lu, Xinjiang and Yu, Zhiwen and Sun, Leilei and Liu, Chuanren and Xiong, Hui and Guan, Chu},
title = {Characterizing the Life Cycle of Point of Interests Using Human Mobility Patterns},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971749},
doi = {10.1145/2971648.2971749},
abstract = {A Point of Interest (POI) refers to a specific location that people may find useful or interesting. While a large body of research has been focused on identifying and recommending POIs, there are few studies on characterizing the life cycle of POIs. Indeed, a comprehensive understanding of POI life cycle can be helpful for various tasks, such as urban planning, business site selection, and real estate evaluation. In this paper, we develop a framework, named POLIP, for characterizing the POI life cycle with multiple data sources. Specifically, to investigate the POI evolution process over time, we first formulate a serial classification problem to predict the life status of POIs. The prediction approach is designed to integrate two important perspectives: 1) the spatial-temporal dependencies associated with the prosperity of POIs, and 2) the human mobility dynamics hidden in the citywide taxicab data related to the POIs at multiple granularity levels. In addition, based on the predicted life statuses in successive time windows for a given POI, we design an algorithm to characterize its life cycle. Finally, we performed extensive experiments using large-scale and real-world datasets. The results demonstrate the feasibility in automatic characterizing POI life cycle and shed important light on future research directions.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1052–1063},
numpages = {12},
keywords = {human mobility, POI life cycle prediction, urban planning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971673,
author = {Xu, Fengli and Zhang, Pengyu and Li, Yong},
title = {Context-Aware Real-Time Population Estimation for Metropolis},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971673},
doi = {10.1145/2971648.2971673},
abstract = {Achieving accurate, real-time, and spatially fine-grained population estimation for a metropolitan city is extremely valuable for a variety of applications. Previous solutions look at data generated by human activities, such as night time lights and phone calls, for population estimation. However, these mechanisms cannot achieve both real-time and fine-grained population estimation because the data sampling rate is low and spatial granularity chosen is improper. We address these two problems by leveraging a key insight --- people frequently use data plan on cellphones and leave mobility signatures on cellular networks. Therefore, we are able to exploit these cellular signatures for real-time population estimation.Extracting population information from cellular data records is not easy because the number of users recorded by a cellular tower is not equal to the population covered by the tower, and mobile users' behavior is spatially and temporally different, where static estimating model does not work. We exploit context-aware city segmentation and dynamic population estimation model to address these challenges. We show that the population estimation error is reduced by 22.5% on a cellular dataset that includes 1 million users.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1064–1075},
numpages = {12},
keywords = {big data, context aware computing, population estimation, mobile sensing, urban computing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971725,
author = {Chen, Ling and Cai, Yaya and Ding, Yifang and Lv, Mingqi and Yuan, Cuili and Chen, Gencai},
title = {Spatially Fine-Grained Urban Air Quality Estimation Using Ensemble Semi-Supervised Learning and Pruning},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971725},
doi = {10.1145/2971648.2971725},
abstract = {Air pollution has adverse effects on humans and ecosystem, and spatially fine-grained air quality information (i.e., the air quality information of every fine-grained area) can help people to avoid unhealthy outdoor activities. However, the number of air quality monitoring stations is usually limited, and thus spatially fine-grained air quality estimation is a challenging task. This paper proposes a method for inferring spatially fine-grained air quality information throughout a city. On one hand, since air quality is affected by multiple factors (e.g., factory waste gases and automobile exhaust fumes), this method employs various data sources, including traffic, road network, point of interests (POIs), and check-ins from social network services, which are related to air quality, to conduct the estimation. On the other hand, since the labeled data are highly limited due to the sparseness of monitoring stations, this method uses an improved ensemble semi-supervised learning (Semi-EP) to establish the relationship between the various data sources and urban air quality. Semi-EP firstly generates multiple classifiers from the original labeled data set and these classifiers are retrained in the iterative co-training process. Then, ensemble pruning technique is used to select the most-diverse subset from these multiple classifiers. This method is evaluated on the real-world dataset of Hangzhou city, China, and the experimental results have demonstrated its advantages over state-of-the-art methods.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1076–1087},
numpages = {12},
keywords = {data mining, semi-supervised learning, air quality estimation, ensemble learning, urban computing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971721,
author = {Maekawa, Takuya and Nakai, Daisuke and Ohara, Kazuya and Namioka, Yasuo},
title = {Toward Practical Factory Activity Recognition: Unsupervised Understanding of Repetitive Assembly Work in a Factory},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971721},
doi = {10.1145/2971648.2971721},
abstract = {In a line production system of a factory, a worker repetitively performs predefined operation processes. This paper tries to recognize work by factory workers in an unsupervised manner. Specifically, we propose an unsupervised measurement method for estimating lead time (duration) of each period of an operation process using a wrist-worn accelerometer because the lead time greatly affects productivity of the line production system. Our proposed method automatically finds a frequent sensor data segment as a "motif" that occurs once in each operation period using only prior knowledge about predefined standard lead time of the operation process, and uses the occurrence intervals of the motif to estimate the lead time. We evaluated our method using real factory data and the estimation error was only about 3.5%.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1088–1099},
numpages = {12},
keywords = {wearable sensors, factory worker, activity recognition, unsupervised method},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971682,
author = {Hessar, Mehrdad and Iyer, Vikram and Gollakota, Shyamnath},
title = {Enabling On-Body Transmissions with Commodity Devices},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971682},
doi = {10.1145/2971648.2971682},
abstract = {We show for the first time that commodity devices can be used to generate wireless data transmissions that are confined to the human body. Specifically, we show that commodity input devices such as fingerprint sensors and touchpads can be used to transmit information to only wireless receivers that are in contact with the body. We characterize the propagation of the resulting transmissions across the whole body and run experiments with ten subjects to demonstrate that our approach generalizes across different body types and postures. We also evaluate our communication system in the presence of interference from other wearable devices such as smartwatches and nearby metallic surfaces. Finally, by modulating the operations of these input devices, we demonstrate bit rates of up to 50 bits per second over the human body.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1100–1111},
numpages = {12},
keywords = {physical layer security, capacitive coupling, on-body communication, fingerprint sensor, touchpad},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971708,
author = {Guo, Haodong and Chen, Ling and Peng, Liangying and Chen, Gencai},
title = {Wearable Sensor Based Multimodal Human Activity Recognition Exploiting the Diversity of Classifier Ensemble},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971708},
doi = {10.1145/2971648.2971708},
abstract = {Effectively utilizing multimodal information (e.g., heart rate and acceleration) is a promising way to achieve wearable sensor based human activity recognition (HAR). In this paper, an activity recognition approach MARCEL (<u>M</u>ultimodal <u>A</u>ctivity <u>R</u>ecognition with <u>C</u>lassifier <u>E</u>nsemble) is proposed, which exploits the diversity of base classifiers to construct a good ensemble for multimodal HAR, and the diversity measure is obtained from both labeled and unlabeled data. MARCEL uses neural network (NN) as base classifiers to construct the HAR model, and the diversity of classifier ensemble is embedded in the error function of the model. In each iteration, the error of the model is decomposed and back-propagated to base classifiers. To ensure the overall accuracy of the model, the weights of base classifiers are learnt in the classifier fusion process with sparse group lasso. Extensive experiments show that MARCEL is able to yield a competitive HAR performance, and has its superiority on exploiting multimodal signals.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1112–1123},
numpages = {12},
keywords = {diversity, classifier ensemble, activity recognition},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971717,
author = {Intille, Stephen and Haynes, Caitlin and Maniar, Dharam and Ponnada, Aditya and Manjourides, Justin},
title = {μEMA: Microinteraction-Based Ecological Momentary Assessment (EMA) Using a Smartwatch},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971717},
doi = {10.1145/2971648.2971717},
abstract = {Ecological Momentary Assessment (EMA) is a method of in situ data collection for assessment of behaviors, states, and contexts. Questions are prompted during everyday life using an individual's mobile device, thereby reducing recall bias and increasing validity over other self-report methods such as retrospective recall. We describe a microinteraction-based EMA method ("micro" EMA, or μEMA) using smartwatches, where all EMA questions can be answered with a quick glance and a tap -- nearly as quickly as checking the time on a watch. A between-subjects, 4-week pilot study was conducted where μEMA on a smartwatch (n=19) was compared with EMA on a phone (n=14). Despite an =8 times increase in the number of interruptions, μEMA had a significantly higher compliance rate, completion rate, and first prompt response rate, and μEMA was perceived as less distracting. The temporal density of data collection possible with μEMA could prove useful in ubiquitous computing studies.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1124–1128},
numpages = {5},
keywords = {experience sampling, compliance, smartwatch, microinteractions, ecological momentary assessment},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971758,
author = {Wakamiya, Shoko and Kawasaki, Hiroshi and Kawai, Yukiko and Jatowt, Adam and Aramaki, Eiji and Akiyama, Toyokazu},
title = {Lets Not Stare at Smartphones While Walking: Memorable Route Recommendation by Detecting Effective Landmarks},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971758},
doi = {10.1145/2971648.2971758},
abstract = {Navigation in unfamiliar cities often requires frequent map checking, which is troublesome for wayfinders. We propose a novel approach for improving real-world navigation by generating short, memorable and intuitive routes. To do so we detect useful landmarks for effective route navigation. This is done by exploiting not only geographic data but also crowd footprints in Social Network Services (SNS) and Location Based Social Networks (LBSN). Specifically, we detect point, area, and line landmarks by using three indicators to measure landmark's utility: visit popularity, direct visibility, and indirect visibility. We then construct an effective route graph based on the extracted landmarks, which facilitates optimal path search. In the experiments, we show that landmark-based routes out-perform the ones created by baseline from the perspectives of the lap time and the number of references necessary to check self-positions for adjusting route directions.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1136–1146},
numpages = {11},
keywords = {visibility, location-based social networks, route search},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971674,
author = {Hu, Yitao and Liu, Xiaochen and Nath, Suman and Govindan, Ramesh},
title = {ALPS: Accurate Landmark Positioning at City Scales},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971674},
doi = {10.1145/2971648.2971674},
abstract = {Context awareness is crucial for ubiquitous computing, and position is an important aspect of context. In an ideal world, every stationary object or entity in the built environment would be associated with position, so that applications can have precise spatial context about the environment surrounding a human. In this paper, we take a step towards this ideal: by analyzing images from Google Street View that cover different perspectives of a given object and triangulating the location of the object, our system, ALPS, can discover and localize common landmarks at the scale of a city accurately and with high coverage. ALPS contains several novel techniques that help improve the accuracy, coverage, and scalability of localization. Evaluations of ALPS on many cities in the United States show that it can localize storefronts with a coverage higher than 90% and a median error of 5 meters.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1147–1158},
numpages = {12},
keywords = {landmark localization system, context-aware computing, machine/deep learning},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971759,
author = {Meng, Rufeng and Shen, Sheng and Choudhury, Romit Roy and Nelakuditi, Srihari},
title = {AutoLabel: Labeling Places from Pictures and Websites},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971759},
doi = {10.1145/2971648.2971759},
abstract = {Most location based services require semantic place names such as Staples, rather than physical coordinates. Past work has mostly focussed on achieving localization accuracy, while assuming that the translation of physical coordinates to semantic names will be done manually. This paper makes an effort to automate this step, by leveraging the presence of a website corresponding to each store and the availability of a repository of WiFi-tagged pictures from different stores. By correlating the text inside the pictures, against the text extracted from store websites, our proposed system, called AutoLabel, can automatically label clusters of pictures, and the corresponding WiFi APs, with store names. Later, when a user enters a store, her mobile device scans the WiFi APs and consults a lookup table to recognize the store she is in. Experiment results from 40 different stores show recognition accuracy upwards of 87%, even with as few as 10 pictures from a store, offering hope that automatic large-scale semantic labeling may indeed be possible from pictures and websites of stores.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1159–1169},
numpages = {11},
keywords = {semantic localization, smartphone, text, wifi},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971694,
author = {Choi, Dongho and Shah, Chirag and Singh, Vivek},
title = {Probing the Interconnections between Geo-Exploration and Information Exploration Behavior},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971694},
doi = {10.1145/2971648.2971694},
abstract = {As increasingly diverse facets of human life - including socializing, exercising, and information-seeking - are mediated by ubiquitous technology, they open the doors for the study of the hitherto under-explored interconnections between them. This work motivates and grounds the use of geo-exploration data to predict the information exploration behavior of users and to support their search. Based on a two-week field study involving 35 participants, we have identified multiple geo-exploration features that have significant associations with a user's information exploration behavior. We also found that the same geo-exploration features could be combined to build predictive models for various facets of an individual's information exploration behavior, and these models performed significantly better than comparable personality-based models.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1170–1175},
numpages = {6},
keywords = {exploratory search, information exploration, geo-exploration},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971698,
author = {Yang, Rayoung and Pisharoty, Devika and Montazeri, Soodeh and Whitehouse, Kamin and Newman, Mark W.},
title = {How Does Eco-Coaching Help to Save Energy? Assessing a Recommendation System for Energy-Efficient Thermostat Scheduling},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971698},
doi = {10.1145/2971648.2971698},
abstract = {This paper presents findings from a field deployment that explored a design approach we call eco-coaching: giving personalized suggestions for specific actions that would reduce wasted energy. We studied ThermoCoach, which performs eco-coaching for thermostat scheduling. It senses and models occupancy patterns in a home, and provides occupants alternative suggestions for configuring their thermostat. Our study shows that eco-coaching accomplished four things. First, it made it easier for users to implement an effective thermostat schedule. Second, it supported user agency in negotiating energy savings and comfort goals. Third, it facilitated learning different scheduling strategies as well as weighing different options. Finally, it challenged users' beliefs about how well they were doing. These outcomes, in turn, were successful in getting users to employ and experiment with more efficient setback strategies. Going forward, we propose ways that eco-coaching systems could better support users in customizing and assessing the systems' recommendations.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1176–1187},
numpages = {12},
keywords = {thermostat, energy savings, sustainability, eco-coaching},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971700,
author = {Winkler, Daniel A. and Beltran, Alex and Esfahani, Niloufar P. and Maglio, Paul P. and Cerpa, Alberto E.},
title = {FORCES: Feedback and Control for Occupants to Refine Comfort and Energy Savings},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971700},
doi = {10.1145/2971648.2971700},
abstract = {Humans spend 90% of their lives inside buildings, but often the Heating, Ventilation, and Air Conditioning (HVAC) systems of commercial buildings do not properly maintain occupant comfort. Use of feedback through comfort voting applications has been shown to improve the quality of service, but the effects of application feedback and user interface design has not been investigated. In this work, we present several methods of feedback that use data presentation and environmental interaction in comfort voting applications. Through a 40 week user study of 61 University employees across 3 buildings, we show that feedback systems can be used to increase user satisfaction with thermal conditions from 33.9% to 93.3% and reduce energy consumption up to 18.99% compared to a system without voting. In addition, we find that by including a drifting control strategy, we find energy savings up to 37% can be realized without a significant reduction in satisfaction.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1188–1199},
numpages = {12},
keywords = {HVAC efficiency, thermal comfort},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971719,
author = {Balaji, Bharathan and Koh, Jason and Weibel, Nadir and Agarwal, Yuvraj},
title = {Genie: A Longitudinal Study Comparing Physical and Software Thermostats in Office Buildings},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971719},
doi = {10.1145/2971648.2971719},
abstract = {Thermostats are the primary interface for occupants of office buildings to express their thermal comfort preferences. However, traditional thermostats are often ineffective due to physical inaccessibility, lack of information or limited responsiveness, which lead to occupant discomfort. Modern thermostat designs do overcome some of these limitations, but retrofitting them to existing buildings is prohibitively expensive. Software thermostats based on web or smartphone apps provide an alternate interaction mechanism with minimal deployment cost. However, their usage and effectiveness have not been studied extensively in real settings. We present Genie, a novel software thermostat that we designed and deployed in our university for over 21 months. We compare the use of Genie to traditional thermostats. Our data and user study show that due to the clarity of information and wider thermal control provided by Genie, users feel more comfortable in their offices. Furthermore, the improved comfort did not affect the overall energy consumption or lead to misuse of HVAC controls.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1200–1211},
numpages = {12},
keywords = {thermostat design, thermal comfort, software thermostat, hvac energy efficiency, smart buildings},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971659,
author = {Ranjan, Juhi and Scott, James},
title = {ThermalSense: Determining Dynamic Thermal Comfort Preferences Using Thermographic Imaging},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971659},
doi = {10.1145/2971648.2971659},
abstract = {We present ThermalSense, a method for dynamically detecting and predicting thermal comfort by using thermographic imaging to look for the physiological markers of vasodilation or vasoconstriction. We describe how ThermalSense can be used to infer how to control heating and cooling systems and reduce energy use while maintaining comfort.We evaluate ThermalSense using a study involving thirty individuals over five weeks in an office building. Our study shows that, on around 40% of occasions, the HVAC system could have expended less energy to achieve comfort. It further demonstrates that thermographic imaging can be used to infer whether heating or cooling must be activated to maintain comfort, with an accuracy of 94-95%.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1212–1222},
numpages = {11},
keywords = {energy, HVAC, thermographic imaging, thermal comfort},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971747,
author = {Mehrotra, Abhinav and Hendley, Robert and Musolesi, Mirco},
title = {PrefMiner: Mining User's Preferences for Intelligent Mobile Notification Management},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971747},
doi = {10.1145/2971648.2971747},
abstract = {Mobile notifications are increasingly used by a variety of applications to inform users about events, news or just to send alerts and reminders to them. However, many notifications are neither useful nor relevant to users' interests and, also for this reason, they are considered disruptive and potentially annoying.In this paper we present the design, implementation and evaluation of PrefMiner, a novel interruptibility management solution that learns users' preferences for receiving notifications based on automatic extraction of rules by mining their interaction with mobile phones. The goal is to build a system that is intelligible for users, i.e., not just a "black-box" solution. Rules are shown to users who might decide to accept or discard them at run-time. The design of PrefMiner is based on a large scale mobile notification dataset and its effectiveness is evaluated by means of an in-the-wild deployment.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1223–1234},
numpages = {12},
keywords = {context-aware computing, interruptibility, notifications},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971680,
author = {Lee, Joohyun and Lee, Kyunghan and Jeong, Euijin and Jo, Jaemin and Shroff, Ness B.},
title = {Context-Aware Application Scheduling in Mobile Systems: What Will Users Do and Not Do Next?},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971680},
doi = {10.1145/2971648.2971680},
abstract = {Usage patterns of mobile devices depend on a variety of factors such as time, location, and previous actions. Hence, context-awareness can be the key to make mobile systems to become personalized and situation dependent in managing their resources. We first reveal new findings from our own Android user experiment: (i) the launching probabilities of applications follow Zipf's law, and (ii) inter-running and running times of applications conform to log-normal distributions. We also find context-dependency in application usage patterns, for which we classify contexts in a personalized manner with unsupervised learning methods. Using the knowledge acquired, we develop a novel context-aware application scheduling framework, CAS that adaptively unloads and preloads background applications in a timely manner. Our trace-driven simulations with 96 user traces demonstrate the benefits of CAS over existing algorithms. We also verify the practicality of CAS by implementing it on the Android platform.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1235–1246},
numpages = {12},
keywords = {context-aware computing, application unloading/preloading, start-up latency, energy minimization},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971729,
author = {Wang, Yingzi and Yuan, Nicholas Jing and Sun, Yu and Zhang, Fuzheng and Xie, Xing and Liu, Qi and Chen, Enhong},
title = {A Contextual Collaborative Approach for App Usage Forecasting},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971729},
doi = {10.1145/2971648.2971729},
abstract = {Fine-grained long-term forecasting enables many emerging recommendation applications such as forecasting the usage amounts of various apps to guide future investments, and forecasting users' seasonal demands for a certain commodity to find potential repeat buyers. For these applications, there often exists certain homogeneity in terms of similar users and items (e.g., apps), which also correlates with various contexts like users' spatial movements and physical environments. Most existing works only focus on predicting the upcoming situation such as the next used app or next online purchase, without considering the long-term temporal co-evolution of items and contexts and the homogeneity among all dimensions. In this paper, we propose a contextual collaborative forecasting (CCF) model to address the above issues. The model integrates contextual collaborative filtering with time series analysis, and simultaneously captures various components of temporal patterns, including trend, seasonality, and stationarity. The approach models the temporal homogeneity of similar users, items, and contexts. We evaluate the model on a large real-world app usage dataset, which validates that CCF outperforms state-of-the-art methods in terms of both accuracy and efficiency for long-term app usage forecasting.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1247–1258},
numpages = {12},
keywords = {collabotative filtering, app usage forecasting, tensor decomposition, seasonal time series},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2971648.2971732,
author = {Weber, Dominik and Voit, Alexandra and Kratzer, Philipp and Henze, Niels},
title = {In-Situ Investigation of Notifications in Multi-Device Environments},
year = {2016},
isbn = {9781450344616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2971648.2971732},
doi = {10.1145/2971648.2971732},
abstract = {Smart devices have arrived in our everyday lives. Being able to notify the user about events is a core feature of these devices. Related work investigated interruptions caused by notifications on single devices. In this paper, we investigate notifications in multi-device environments by analyzing the results of a week-long in-situ study with 16 participants. We used the Experience Sampling Method (ESM) and recorded the participants' interaction with smartphones, smartwatches, tablets and PCs. Disregarding the type or content of notifications, we found that the smartphone is the preferred device on which to be notified. Further, we found that the proximity to the device, whether it is currently being used and the user's current location can be used to predict if the user wants to receive notifications on a device. The findings can be used to design future multi-device aware smart notification systems.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1259–1264},
numpages = {6},
keywords = {notifications, experience sampling method, context-awareness, multi-device, in-situ},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

