@inproceedings{10.1007/11551201_1,
author = {Fukumoto, Masaaki and Shinagawa, Mitsuru},
title = {CarpetLAN: A Novel Indoor Wireless(-like) Networking and Positioning System},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_1},
doi = {10.1007/11551201_1},
abstract = {CarpetLAN is a novel indoor wireless(-like) broad-band networking and positioning system. It uses the floor surface and the human body as an Ethernet-cable, and weak electric fields as the transmission media. Portable and wearable devices can connect to the network while the user stands or walks on the floor; connection speed is 10Mbps. Home and office appliances can also access the network if they are just put on the floor. CarpetLAN also provides an indoor positioning function, which is urgently needed for realizing “ubiquitous” communication. This electric field based transmission system yields ultra-micro communication cells, so the positions of humans and appliances can be detected with about 1 meter accuracy.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {1–18},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_2,
author = {Kohtake, Naohiko and Ohsawa, Ryo and Yonezawa, Takuro and Matsukura, Yuki and Iwai, Masayuki and Takashio, Kazunori and Tokuda, Hideyuki},
title = {U-Texture: Self-Organizable Universal Panels for Creating Smart Surroundings},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_2},
doi = {10.1007/11551201_2},
abstract = {This paper introduces a novel way to allow non-expert users to create smart surroundings. Non-smart everyday objects such as furniture and appliances found in homes and offices can be converted to smart ones by attaching computers, sensors, and devices. In this way, non-smart components that form non-smart objects are made smart in advance. For our first prototype, we have developed u-Texture, a self-organizable universal panel that works as a building block. The u-Texture can change its own behavior autonomously through recognition of its location, its inclination, and surrounding environment by assembling these factors physically. We have demonstrated several applications to confirm that u-Textures can create smart surroundings easily without expert users.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {19–36},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_3,
author = {Gajos, Krzysztof and Christianson, David and Hoffmann, Raphael and Shaked, Tal and Henning, Kiera and Long, Jing Jing and Weld, Daniel S.},
title = {Fast and Robust Interface Generation for Ubiquitous Applications},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_3},
doi = {10.1007/11551201_3},
abstract = {We present Supple, a novel toolkit which automatically generates interfaces for ubiquitous applications. Designers need only specify declarative models of the interface and desired hardware device and Supple uses decision-theoretic optimization to automatically generate a concrete rendering for that device. This paper provides an overview of our system and describes key extensions that barred the previous version (reported in [3]) from practical application. Specifically, we describe a functional modeling language capable of representing complex applications. We propose a new adaptation strategy, split interfaces, which speeds access to common interface features without disorienting the user. We present a customization facility that allows designers and end users to override Supple's automatic rendering decisions. We describe a distributed architecture which enables computationally-impoverished devices to benefit from Supple interfaces. Finally, we present experiments and a preliminary user-study that demonstrate the practicality of our approach.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {37–55},
numpages = {19},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_4,
author = {Amft, Oliver and St\"{a}ger, Mathias and Lukowicz, Paul and Tr\"{o}ster, Gerhard},
title = {Analysis of Chewing Sounds for Dietary Monitoring},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_4},
doi = {10.1007/11551201_4},
abstract = {The paper reports the results of the first stage of our work on an automatic dietary monitoring system. The work is part of a large European project on using ubiquitous systems to support healthy lifestyle and cardiovascular disease prevention. We demonstrate that sound from the user's mouth can be used to detect that he/she is eating. The paper also shows how different kinds of food can be recognized by analyzing chewing sounds. The sounds are acquired with a microphone located inside the ear canal. This is an unobtrusive location widely accepted in other applications (hearing aids, headsets). To validate our method we present experimental results containing 3500 seconds of chewing data from four subjects on four different food types typically found in a meal. Up to 99% accuracy is achieved on eating recognition and between 80% to 100% on food type classification.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {56–72},
numpages = {17},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_5,
author = {Truong, Khai N. and Patel, Shwetak N. and Summet, Jay W. and Abowd, Gregory D.},
title = {Preventing Camera Recording by Designing a Capture-Resistant Environment},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_5},
doi = {10.1007/11551201_5},
abstract = {With the ubiquity of camera phones, it is now possible to capture digital still and moving images anywhere, raising a legitimate concern for many organizations and individuals. Although legal and social boundaries can curb the capture of sensitive information, it sometimes is neither practical nor desirable to follow the option of confiscating the capture device from an individual. We present the design and proof of concept implementation of a capture-resistant environment that prevents the recording of still and moving images without requiring any cooperation on the part of the capturing device or its operator. Our solution involves a tracking system that uses computer vision for locating any number of retro-reflective CCD or CMOS camera sensors in a protected area. A pulsing light is then directed at the lens, distorting any imagery the camera records. Although the directed light interferes with the camera's operation, it can be designed to minimally impact the sight of other humans in the environment.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {73–86},
numpages = {14},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_6,
author = {LaMarca, Anthony and Hightower, Jeff and Smith, Ian and Consolvo, Sunny},
title = {Self-Mapping in 802.11 Location Systems},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_6},
doi = {10.1007/11551201_6},
abstract = {Location systems that are based on scanning for nearby radio sources can estimate the position of a mobile device with reasonable accuracy and high coverage. These systems require a calibration step in which a map is built from radio-readings taken on a location-aware device. War driving, for example, calibrates the positions of WiFi access points using a GPS-equipped laptop. In this paper we introduce an algorithm for self-mapping that minimizes or even eliminates explicit calibration by allowing the location system to build this radio map as the system is used. Using nearly 100 days of trace data, we evaluate self-mapping's accuracy when the map is seeded by three realistic data sources: public war-driving databases, WiFi hotspot finders, and sporadic GPS connectivity. On average, accuracy and coverage are shown to be comparable to those achieved with an explicit war-driven radio map.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {87–104},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_7,
author = {Madhavapeddy, Anil and Tse, Alastair},
title = {A Study of Bluetooth Propagation Using Accurate Indoor Location Mapping},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_7},
doi = {10.1007/11551201_7},
abstract = {The ubiquitous computing community has widely researched the use of 802.11 for the purpose of location inference. Meanwhile, Bluetooth is increasingly widely deployed due to its low power consumption and cost. This paper describes a study of Bluetooth radio propagation using an accurate indoor location system to conduct fine-grained signal strength surveys. We discuss practical problems and requirements encountered setting up the infrastructure using the ultrasonic Active Bat indoor location system, and limitations of the commodity Bluetooth devices used. We conclude that Bluetooth is poorly suited to the purpose of fine-grained, low latency location inference due to specification and hardware limitations, and note that the movement speed of mobile devices is an important factor in calculating available bandwidth. We publish our data sets of signal strength samples for the community to freely use in future research.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {105–122},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_8,
author = {Duff, Paul and McCarthy, Michael and Clark, Angus and Muller, Henk and Randell, Cliff and Izadi, Shahram and Boucher, Andy and Law, Andy and Pennington, Sarah and Swinford, Richard},
title = {A New Method for Auto-Calibrated Object Tracking},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_8},
doi = {10.1007/11551201_8},
abstract = {Ubiquitous computing technologies which are cheap and easy to use are more likely to be adopted by users beyond the ubiquitous computing community. We present an ultrasonic-only tracking system that is cheap to build, self-calibrating and self-orientating, and has a convenient form factor. The system tracks low-power tags in three dimensions. The tags are smaller than AAA batteries and last up to several years on their power source. The system can be configured to track either multiple near-stationary objects or a single fast moving object. Full test results are provided and use of the system within a home application is discussed.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {123–140},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_9,
author = {Otsason, Veljo and Varshavsky, Alex and LaMarca, Anthony and de Lara, Eyal},
title = {Accurate GSM Indoor Localization},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_9},
doi = {10.1007/11551201_9},
abstract = {Accurate indoor localization has long been an objective of the ubiquitous computing research community, and numerous indoor localization solutions based on 802.11, Bluetooth, ultrasound and infrared technologies have been proposed. This paper presents the first accurate GSM indoor localization system that achieves median accuracy of 5 meters in large multi-floor buildings. The key idea that makes accurate GSM-based indoor localization possible is the use of wide signal-strength fingerprints. In addition to the 6-strongest cells traditionally used in the GSM standard, the wide fingerprint includes readings from additional cells that are strong enough to be detected, but too weak to be used for efficient communication. Experiments conducted on three multi-floor buildings show that our system achieves accuracy comparable to an 802.11-based implementation, and can accurately differentiate between floors in both wooden and steel-reinforced concrete structures.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {141–158},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_10,
author = {Hightower, Jeffrey and Consolvo, Sunny and LaMarca, Anthony and Smith, Ian and Hughes, Jeff},
title = {Learning and Recognizing the Places We Go},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_10},
doi = {10.1007/11551201_10},
abstract = {Location-enhanced mobile devices are becoming common, but applications built for these devices find themselves suffering a mismatch between the latitude and longitude that location sensors provide and the colloquial place label that applications need. Conveying my location to my spouse, for example as (48.13641N, 11.57471E), is less informative than saying “at home.” We introduce an algorithm called BeaconPrint that uses WiFi and GSM radio fingerprints collected by someone's personal mobile device to automatically learn the places they go and then detect when they return to those places. BeaconPrint does not automatically assign names or semantics to places. Rather, it provides the technological foundation to support this task. We compare BeaconPrint to three existing algorithms using month-long trace logs from each of three people. Algorithmic results are supplemented with a survey study about the places people go. BeaconPrint is over 90% accurate in learning and recognizing places. Additionally, it improves accuracy in recognizing places visited infrequently or for short durations—a category where previous approaches have fared poorly. BeaconPrint demonstrates 63% accuracy for places someone returns to only once or visits for less than 10 minutes, increasing to 80% accuracy for places visited twice.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {159–176},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_11,
author = {Rehman, Kasim and Stajano, Frank and Coulouris, George},
title = {Visually Interactive Location-Aware Computing},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_11},
doi = {10.1007/11551201_11},
abstract = {The physical disappearance of the computer, associated with Ubicomp, has led to a number of interaction challenges. Due to the lack of an interface users are losing control over applications running in Ubicomp environments. Furthermore, the limited ability for these applications to provide feedback makes it difficult for users to understand their workings and dependencies. We investigate whether an interaction paradigm, based on the visualising location-aware applications on a head-mounted display, is feasible and whether it has the potential to improve the user experience in the same way graphical user interfaces did for the desktop. We show the feasibility of the idea by building an Augmented Reality interface to a location-aware environment. Initial user trials indicate that the user experience can be improved through in-situ visualisation.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {177–194},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_12,
author = {Persson, Per and Blom, Jan and Jung, Younghee},
title = {DigiDress: A Field Trial of an Expressive Social Proximity Application},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_12},
doi = {10.1007/11551201_12},
abstract = {In May 2005 Nokia Sensor application (www.nokia.com/sensor) was launched, allowing mobile phone users to create digital identity expressions, seen by other users within Bluetooth range. This paper describes the design and mass-scale longitudinal field trial of a precursor prototype called DigiDress. 618 participants voluntarily used the application for an average of 25 days. The identity expressions created were both serious and playful, revealing and non-revealing. Factors influencing the identity expression included strategies for personal impression management, privacy concerns, and social feedback. The application was used with both acquainted and unacquainted people, and viewing the identity expression of people nearby was one major motivation for continued use. Direct communication features such as Bluetooth messages were not commonly adopted. DigiDress acted as a facilitator for 'real' social interaction between previously unacquainted users. Privacy concerns and their alleviations, as well as use barriers, were identified.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {195–212},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_13,
author = {Iachello, Giovanni and Smith, Ian and Consolvo, Sunny and Abowd, Gregory D. and Hughes, Jeff and Howard, James and Potter, Fred and Scott, James and Sohn, Timothy and Hightower, Jeffrey and LaMarca, Anthony},
title = {Control, Deception, and Communication: Evaluating the Deployment of a Location-Enhanced Messaging Service},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_13},
doi = {10.1007/11551201_13},
abstract = {We report on a two-week deployment of a peer-to-peer, mobile, location-enhanced messaging service. This study is specifically aimed at investigating the need for and effectiveness of automatic location disclosure mechanisms, the emerging strategies to achieve plausible deniability, and at understanding how place and activity are used to communicate plans, intentions and provide awareness. We outline the research that motivated this study, briefly describe the application we designed, and provide details of the evaluation process. The results show a lack of value of automatic messaging functions, confirm the need for supporting plausible deniability in communications, and highlight the prominent use of activity instead of place to indicate one's location. Finally, we offer suggestions for the development of social mobile applications.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {213–231},
numpages = {19},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_14,
author = {Sohn, Timothy and Li, Kevin A. and Lee, Gunny and Smith, Ian and Scott, James and Griswold, William G.},
title = {Place-Its: A Study of Location-Based Reminders on Mobile Phones},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_14},
doi = {10.1007/11551201_14},
abstract = {Context-awareness can improve the usefulness of automated reminders. However, context-aware reminder applications have yet to be evaluated throughout a person's daily life. Mobile phones provide a potentially convenient and truly ubiquitous platform for the detection of personal context such as location, as well as the delivery of reminders. We designed Place-Its, a location-based reminder application that runs on mobile phones, to study people using location-aware reminders throughout their daily lives. We describe the de-sign of Place-Its and a two-week exploratory user study. The study reveals that location-based reminders are useful, in large part because people use location in nuanced ways.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {232–250},
numpages = {19},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_15,
author = {Elliot, Kathryn and Neustaedter, Carman and Greenberg, Saul},
title = {Time, Ownership and Awareness: The Value of Contextual Locations in the Home},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_15},
doi = {10.1007/11551201_15},
abstract = {Our goal in this paper is to clearly delineate how households currently manage communication and coordination information; this will provide practitioners and designers with a more complete view of information in the home, and how technology embedded within the home can augment communication and coordination of home inhabitants. Through contextual interviews, we identify five types of communicative information: reminders and alerts, awareness and scheduling, notices, visual displays, and resource coordination. These information types are created and understood by home inhabitants as a function of contextual locations within the home. The choice of location is important to the functioning of the home, and is highly nuanced. Location helps home inhabitants understand time: when others need to interact with that information, as well as ownership: who this information belongs to and who should receive it. It also provides them with awareness of the actions and locations of others. These findings resonate and further elaborate on work by other researchers.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {251–268},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_16,
author = {Mainwaring, Scott D. and Anderson, Ken and Chang, Michele F.},
title = {Living for the Global City: Mobile Kits, Urban Interfaces, and Ubicomp},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_16},
doi = {10.1007/11551201_16},
abstract = {Using ethnographic methods, 28 young professionals across the global cities of London, Los Angeles, and Tokyo were studied to understand in some detail what items they carried with them (their mobile kits) and how they used these items to access people, places, and services (through various urban interfaces). The findings are analyzed in terms of these cities as existing sites of ubiquitous information and communication technology (ICT) use. More specifically, findings are considered with respect to the prospects in these cities for ubicomp as a paradigm of trusted, environmentally embedded computing, as opposed to a wearable computing paradigm of individual self-sufficiency. Overall, at least for the young professional class studied, practices of urban interfacing were remarkably similar across all three cities studied, suggesting that ubicomp systems might be developed to address the range of urban concerns and to unburden and empower urbanites.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {269–286},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_17,
author = {Williams, Amanda and Kabisch, Eric and Dourish, Paul},
title = {From Interaction to Participation: Configuring Space through Embodied Interaction},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_17},
doi = {10.1007/11551201_17},
abstract = {When computation moves off the desktop, how will it transform the new spaces that it comes to occupy? How will people encounter and understand these spaces, and how will they interact with each other through the augmented capabilities of such spaces? We have been exploring these questions through a prototype system in which augmented objects are used to control a complex audio 'soundscape.' The system involves a range of objects distributed through a space, supporting simultaneous use by many participants. We have deployed this system at a number of settings in which groups of people have explored it collaboratively. Our initial explorations of the use of this system reveal a number of important considerations for how we design for the interrelationships between people, objects, and spaces.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {287–304},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_18,
author = {Bernheim Brush, A. J. and Combs Turner, Tammara and Smith, Marc A. and Gupta, Neeti},
title = {Scanning Objects in the Wild: Assessing an Object Triggered Information System},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_18},
doi = {10.1007/11551201_18},
abstract = {We describe the results of a field deployment of the AURA system which links online content to physical objects through machine readable tags. AURA runs on commercially available pocket computers using integrated bar-code scanners, wireless networks, and web services. We conducted a real world deployment with twenty participants over five weeks. The results from our field study illustrate the importance of moving beyond demonstrations and testing system design assumptions in the real world, as our field study highlighted several places that our seemingly reasonable design assumption did not match with real usage. Our experience deploying AURA highlighted several key features for mobile object triggered information systems including handling groups of items and a robust offline experience.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {305–322},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_19,
author = {Kientz, Julie A. and Boring, Sebastian and Abowd, Gregory D. and Hayes, Gillian R.},
title = {Abaris: Evaluating Automated Capture Applied to Structured Autism Interventions},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_19},
doi = {10.1007/11551201_19},
abstract = {We present an example of an automated capture application which provides access to details of discrete trial training, a highly structured intervention therapy often used with developmentally disabled children. This domain presents an interesting case study for capture technology, because of the well-defined practices and the tradition of manual recording and review of materials. There is a strong motivation for therapists to review the rich record of therapy sessions that is made possible by recorded video, but acceptance hinges on minimal intrusion upon the human activities. To achieve that, we leverage several perception technologies that fit with the natural activities of the live experience and allow the creation of meaningful indices. We also critically explore the contribution various perception technologies have on the overall utility of the capture system.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {323–339},
numpages = {17},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_20,
author = {Pinhanez, Claudio and Podlaseck, Mark},
title = {To Frame or Not to Frame: The Role and Design of Frameless Displays in Ubiquitous Applications},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_20},
doi = {10.1007/11551201_20},
abstract = {A frameless display is a display with no perceptible boundaries; it appears to be embodied in the physical world. Frameless displays are created by projecting visual elements on a black background into a physical environment. By considering visual arts and design theory together with our own experience building about a dozen applications, we argue the importance of this technique in creating ubiquitous computer applications that are truly contextualized in the physical world. Nine different examples using frameless displays are described, providing the background for a systematization of frameless displays pros and cons, together with a basic set of usage guidelines. The paper also discusses the differences and constraints on user interaction with visual elements in a frameless display.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {340–357},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_21,
author = {Barkhuus, Louise and Chalmers, Matthew and Tennent, Paul and Hall, Malcolm and Bell, Marek and Sherwood, Scott and Brown, Barry},
title = {Picking Pockets on the Lawn: The Development of Tactics and Strategies in a Mobile Game},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_21},
doi = {10.1007/11551201_21},
abstract = {This paper presents Treasure, an outdoor mobile multiplayer game inspired by Weiser's notion of seams, gaps and breaks in different media. Playing Treasure involves movement in and out of a wi-fi network, using PDAs to pick up virtual 'coins' that may be scattered outside network coverage. Coins have to be uploaded to a server to gain game points, and players can collaborate with teammates to double the points given for an upload. Players can also steal coins from opponents. As they move around, players' PDAs sample network signal strength and update coverage maps. Reporting on a study of players taking part in multiple games, we discuss how their tactics and strategies developed as their experience grew with successive games. We suggest that meaningful play arises in just this way, and that repeated play is vital when evaluating such games.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {358–374},
numpages = {17},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

@inproceedings{10.1007/11551201_22,
author = {Riisgaard Hansen, Thomas and Bardram, Jakob E.},
title = {ActiveTheatre: A Collaborative, Event-Based Capture and Access System for the Operating Theatre},
year = {2005},
isbn = {9783540287605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11551201_22},
doi = {10.1007/11551201_22},
abstract = {Building capture and access (C&amp;A) applications for use in the operation theatre differs greatly from C&amp;A applications built to support other settings e.g. meeting rooms or classrooms. Based on field studies of surgical operations, this paper explores how to design C&amp;A applications for the operation theatre. Based on the findings from our field work, we have built the ActiveTheatre, a C&amp;A prototype. ActiveTheatre is built to support collaboration in and around the operating theatre, to capture events instead of automatically capturing everything, and to be integrated with existing applications already present in the operation theatre. The ActiveTheatre prototype has been developed in close co-operation with surgeons and nurses at a local hospital. The work on the prototype and our initial evaluations have provided an insight into how to design, capture and access applications that are going to be used in other settings than the meeting room.},
booktitle = {Proceedings of the 7th International Conference on Ubiquitous Computing},
pages = {375–392},
numpages = {18},
location = {Tokyo, Japan},
series = {UbiComp'05}
}

