@inproceedings{10.1145/3410530.3414414,
author = {Adhikary, Rishiraj and Batra, Nipun},
title = {Do We Breathe the Same Air?},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414414},
doi = {10.1145/3410530.3414414},
abstract = {91% of the world's population lives in areas where air pollution exceeds safety limits1. Research has focused on monitoring ambient air pollution, but individual exposure to air pollution is not equal to ambient and is thus important to measure. Our work (in progress) measures individual exposures of different categories of people on an academic campus. We highlight some anecdotal findings and surprising insights from monitoring, such as a) Indoor CO2 concentration of 1.8 times higher than the permissible limit. Over 10 times the WHO limit of PM2.5 exposure during b) construction-related activities, and c) cooking (despite the use of exhaust). We also found that during transit, the PM2.5 exposure is at least two times higher than indoor. Our current work though in progress, already shows important findings affecting different people associated with an academic campus. In the future, we plan to do a more exhaustive study and reduce the form factor and energy needs for our sensors to scale the study.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {1–4},
numpages = {4},
keywords = {air pollution wearable, blue-collar, air pollution},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414403,
author = {Adhikary, Rishiraj and Srivastava, Tanmay and Khanna, Prerna and Senapati, Aabhas Asit and Batra, Nipun},
title = {Naqaab: Towards Health Sensing and Persuasion via Masks},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414403},
doi = {10.1145/3410530.3414403},
abstract = {Given the pandemic and the high air pollution in large parts of the world, masks have become ubiquitous. In this poster, we present our vision and work-in-progress (WIP) towards leveraging the ubiquity of masks for health sensing and persuasion. We envision masks to monitor health-related parameters such as i) temperature; ii) lung activity, among others. We also envision that retrofitting masks with sensors and display to show localized pollution can create awareness about air pollution. In this WIP, we present a smart mask, Naqaab1, that measures forced vital capacity (FVC) of the lung using a retrofitted microphone. We evaluated the measured lung parameter on eight persons using an Incentive Spirometer2 and found that our smart mask accurately measures incentive lung capacity. Naqaab also measures pollution exposure and indicates via different LED colours. We envision using such a system for eco feedback.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {5–8},
numpages = {4},
keywords = {smart mask, air pollution wearable, air pollution},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414415,
author = {Bao, Jie and Han, Jiawen and Kato, Akira and Kunze, Kai},
title = {Sleepy Watch: Towards Predicting Daytime Sleepiness Based on Body Temperature},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414415},
doi = {10.1145/3410530.3414415},
abstract = {Daytime sleepiness, the difficulty to maintain an alert waking state during the day, is a serious problem causing vehicle accidents and adverse effects on well-being, health, and productivity. Our research aims at predicting daytime sleepiness using wearable sensing in everyday life to raise awareness and help people to manage their energy better. This study presents a first exploration of comparing body temperature (wrist, forehead, in-ear) with users alertness, measured over a reaction test: Psychomotor vigilance task (PVT) in 7 participants over 2 days in real-life conditions (168 hours in total). The results indicate a weak correlation between some body temperature measures and the PVT scores for certain subjects. This underlines that unobtrusive on-body temperature sensing can be an interesting modality to understand and explore daytime sleepiness.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {9–12},
numpages = {4},
keywords = {daytime sleepiness, body temperature, wrist temperature, objective sleepiness},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414390,
author = {Chang, Tang-Jie and Chen, Jian-Hua Jiang and Lee, Hao-Ping and Chang, Yung-Ju},
title = {A Preliminary Attempt of an Intelligent System Predicting Users' Correctness of Notifications' Sender Speculation},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414390},
doi = {10.1145/3410530.3414390},
abstract = {Prior interruptibility research has focused on identifying interruptible or opportune moments for users to handle notifications. Yet, users may not want to attend to all notifications even at these moments. Research has shown that users' current practices for selective attendance are through speculating about notification sources. Yet, sometimes the above information is insufficient, making speculations difficult. This paper describes the first research attempt to examine how well a machine learning model can predict the moments when users would incorrectly speculate the sender of a notification. We built a machine learning model that can achieve an recall: 84.39%, precision: 56.78%, and F1-score of 0.68. We also show that important features for predicting these moments.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {13–16},
numpages = {4},
keywords = {intelligent system, notification source, receptivity},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414407,
author = {Chee, Grace and Cobb, Trevor and Richter-Lunn, Katarina and Wicaksono, Irmandy and Freedman, Benjamin R.},
title = {Doze: Hydrogel-Based Epidermal Platform for Personalized Scent Diffusion},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414407},
doi = {10.1145/3410530.3414407},
abstract = {Doze is an on-skin, hydrogel-based sleep mask which seeks to improve, enhance, and augment sleep through the use of programmed scent diffusion in tune with the user's cortical rhythms. Taking advantage of hydrogels' unique properties, the Doze mask encapsulates and emits therapeutic scents at a regulated pace. The release of scent is controlled by an embedded heater within the layers of the mask and communicates remotely to a smart device. This communication allows for a personalized dosage release based on the user's biometric or contextual data. Investigating both the pervasive power of smell in enhancing sleep as well as natural topical remedies, this personalized mask explores the potential for unintrusive solutions to the evergrowing rarity of a good night's sleep.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {17–20},
numpages = {4},
keywords = {hydrogels, scent diffusion, drug delivery, wearable technology, sleep mask},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414409,
author = {Chiang, Chia-En and Chang, Yung-Ju and Feng, Felicia},
title = {Effects of Activity Breakpoints on Mobile Crowdsourcing Task Performance},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414409},
doi = {10.1145/3410530.3414409},
abstract = {Mobile phones have become a new means of accessing and executing crowdsourcing tasks in a variety of situations. Yet, while it is commonly assumed that people are likely to perform these tasks during activity breakpoints, it remains unclear whether different types of such breakpoints affect the likelihood that crowdsourcing tasks will be performed. To explore this question, we classified breakpoints into five types, according to phone users' preceding, current, and upcoming activities, and conducted a six-week experience sampling method study of 30 users' breakpoint-type-specific crowdsourcing-task performance behavior. We found that these participants tended to engage in crowdsourcing tasks when they were at breakpoints between two different activities, rather than within an activity, and also when breakpoints were long. Additionally, the higher the complexity of their previous activity, the lower the crowdsourcing-task execution rate. However, high complexity of the post-crowdsourcing task activity had no obvious impact on execution rate.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {21–24},
numpages = {4},
keywords = {ESM, mobile receptivity, task performance, mobile notifications, interruptibility, breakpoints, mobile crowdsourcing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414399,
author = {Fedorin, Illia and Slyusarenko, Kostyantyn and Nastenko, Margaryta},
title = {Respiratory Events Screening Using Consumer Smartwatches},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414399},
doi = {10.1145/3410530.3414399},
abstract = {Respiratory related events (RE) during nocturnal sleep disturb the natural physiological pattern of sleep. This events may include all types of apnea and hypopnea, respiratory-event-related arousals and snoring. The particular importance of breath analysis is currently associated with the COVID-19 pandemic. The proposed algorithm is a deep learning model with long short-term memory cells for RE detection for each 1 minute epoch during nocturnal sleep. Our approach provides the basis for a smartwatch based respiratory-related sleep pattern analysis (accuracy of epoch-by-epoch classification is greater than 80 %), can be applied for a potential risk of respiratory-related diseases screening (mean absolute error of AHI estimation is about 6.5 events/h on the test set, which includes participants with all types of apnea severity; two class screening accuracy (AHI threshold is 15 events/h) is greater than 90 %).},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {25–28},
numpages = {4},
keywords = {sleep apnea, sleep stages, neural networks, heart rate, respiration rate},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414398,
author = {Guo, Mingzhe and Ni, Hongbo and Chen, Alex Q.},
title = {OfficeBP: Noninvasive Continuous Blood Pressure Monitoring Based on PPT in Office Environment},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414398},
doi = {10.1145/3410530.3414398},
abstract = {Blood pressure (BP), as a crucial vital sign of human beings, reflects the physical state of the cardiovascular system. Currently, blood pressure is mainly measured by collecting the changes in pressure in the vessel using cuff-sensors. It is a manual operation and cannot achieve continuous BP monitoring. In this work, we developed OfficeBP, a novel non-intrusive BP monitoring system for a typical office environment. OfficeBP relies on measuring the pulse transit time (PTT) between the pulse propagate from arterial proximal to the distal site on once heartbeat. For calculating the PTT, the user's face and thumb fingertip are regarded as the start and end points respectively. A twin-channel PPG sensing system is presented, that is, the fingertip pulse recording photoplethysmography (PPG) is obtained by a low-cost photoelectric sensor integrated with a mouse. Using image processing the face pulse is acquired by remote-PPG (rPPG) that based on a commercial off-the-shelf camera collecting facial video frames. OfficeBP was evaluated on 11 participants in different working conditions including the external illumination factor and personal internal factors, and achieved RMSE result of diastolic blood pressure 4.81 mmHg, systolic blood pressure 5.35 mmHg, demonstrate the feasibility of the system in an office environment.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {29–32},
numpages = {4},
keywords = {physiological sensing, remote-photoplethysmography (rPPG), noninvasive blood pressure, pulse transit time},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414391,
author = {Hung, Min-Wei and Yuan, Chien Wen (Tina) and Chen, Yi-Chao and Bi, Nanyi and Lee, Wan-Chen and Huang, Ming-Chyi and You, Chuang-Wen},
title = {Leveraging Family Force to Assist Adolescent Patients in the Treatment of Technology Abuse},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414391},
doi = {10.1145/3410530.3414391},
abstract = {Technology abuse refers to the excessive use of personal technology devices, which can have a negative impact on adolescent patients' lifestyles and might lead to negative physical and mental health outcomes. This study conducted a needs assessment study to gain guidelines for the development of assistive systems to help adolescents deal with technology abuse issues. Our results identify current difficulties to depict screen use on multiple devices for the recording of device usage data as well as behavioral data related to lifestyles (e.g., sleep conditions). We also proposed a preliminary design of technology solutions to make the information sharing among patients and parents possible for constructive communication between them and provide treatment teams with the data necessary for diagnosis and the formulation of treatment plans.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {33–37},
numpages = {5},
keywords = {screen time, family support, technology abuse among adolescents},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414376,
author = {Jones, Luke and Perera, Charith},
title = {PizzaBox: Studying Physical Object Manipulation Based Fast Food Ordering},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414376},
doi = {10.1145/3410530.3414376},
abstract = {This paper presents the designing and evaluation of PizzaBox, a 3D printed, tangible food ordering system that aims to differ from conventional food ordering systems and provide an unique experience when ordering a pizza by incorporating underlying technologies that support ubiquitous computing. The PizzaBox has gone through both low and medium fidelity testing while working collaboratively with participants to co-design and refine a product that is approachable to all age groups while maintaining a simple process for ordering food from start to finish. We utilised this artefact to conduct an user study at an independent pizzeria to uncover potential opportunities. We present two of the main themes identified through the discussions: 1) end user engagement (from entertainment to education), and 2) healthy eating and living. We found that our approach could potentially utilise towards promoting a healthier lifestyle as well as an educational tool.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {38–41},
numpages = {4},
keywords = {internet connected objects, human-food interaction, physical objects interaction},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414412,
author = {Karimi, Pegah and Martin-Hammond, Aqueasha},
title = {Understanding Barriers to Medical Instruction Access for Older Adults: Implications for AI-Assisted Tools},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414412},
doi = {10.1145/3410530.3414412},
abstract = {Recalling medical instructions provided during a doctor's visit can be difficult due to access barriers, primarily for older adults who visit doctors multiple times per year and rely on their memory to act on doctor's recommendations. There are several interventions that aid patients in recalling information after doctors' visits; however, some have been proven ineffective, and those that are effective can present additional challenges for older adults. In this paper, we explore the challenges that older adults with chronic illnesses face when collecting and recalling medical instructions from multiple doctors' visits and discuss implications for AI-assisted tools to enable older adults better access medical instructions. We interviewed 12 older adults to understand their strategies for gathering and recalling information, the challenges they face, and their opinions about automatic transcription of their conversations with doctors to help them recall information after a visit. We found that participants face accessibility challenges such as hearing information and recalling medical instructions that require additional time or follow-up with the doctor. Therefore, patients saw potential value for a tool that automatically transcribes and helps with recall of medical instructions, but desired additional features to summarize, categorize, and highlight critical information from the conversations with their doctors.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {42–45},
numpages = {4},
keywords = {AI, older adults, recall, patient-physician communication},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414421,
author = {Katsumi, Hisao and Yamada, Wataru and Ochiai, Keiichi},
title = {Generic POI Recommendation},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414421},
doi = {10.1145/3410530.3414421},
abstract = {For avoiding excessive congestion of tourists that causes overtourism, we propose a Generic Point of Interest (POI), which is an alternative sightseeing spot potentially attractive enough for tourists to replace a well-known sightseeing spot. We also propose a method to discover generic POIs and evaluate it. While the rapid spread of social networking services (SNSs) and social media makes tourism more familiar to people, it is further aggravating overtoursim around the world due to the nature of SNSs and social media, where users simultaneously find the same posts or articles recommending specific tourist spots and are attracted to the same destinations at the same time. As overtourism has severe influences on both visitors and local residents, it is essential to solve this problem. Although there are many studies providing ways of recommending less crowded tourist spots or mining less-known spots in a famous sightseeing area, we cannot apply those methods as a fundamental solution for overtourism for two reasons: 1) in many cases, the number of tourists already exceeds the touring area's total capacity; and 2) many approaches relying on a number of user-generated data points cannot discover unbusy sightseeing spots since users hardly post reviews nor images. To address these challenges, we propose a novel concept of generic POIs, alternative sightseeing spots to famous spots, and we propose a method to discover generic POIs, whose images are similar to those of existing famous sightseeing spots. We also evaluate our method with collected examples of generic POIs. We hope that the proposed method will help alleviate the overtourism problem in the real world as a first step.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {46–49},
numpages = {4},
keywords = {sightseeing spot recommendation, POI, social media photographs},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414386,
author = {Kawamura, Ryosuke and Shirai, Shizuka and Aizadeh, Mehrasa and Takemura, Noriko and Nagahara, Hajime},
title = {Estimation of Wakefulness in Video-Based Lectures Based on Multimodal Data Fusion},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414386},
doi = {10.1145/3410530.3414386},
abstract = {In distance learning contexts, drowsiness is a major factor which disturbs learning. However, it is not easy for instructors to monitor students' wakefulness. In order to improve learning efficacy, accurate estimation of wakefulness is needed. In this study, we propose a multimodal wakefulness estimation method based on face and body movement information. We utilize web-cameras to obtain facial and head (face-head) movements and pressure mats for body movements, the latter of which can record the distribution of upper body pressure while watching video lectures. To confirm the effectiveness of multimodal data for wakefulness estimation, we conducted an experiment to collect data from students as they engaged in e-learning and their level of wakefulness was annotated in one-second windows. We extracted 45 features from face-head movements, and 80 features from seat pressure data. Two types of fusion methods, early and decision level fusion were applied, and the late fusion approach achieved an average F1-macro score of 0.70 in three levels of wakefulness estimation, which is higher than the unimodal approach. This result indicates that fusion of facial images and seat pressure features can be effective for learner wakefulness estimation.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {50–53},
numpages = {4},
keywords = {facial expression, wakefulness, e-learning, pressure sensor},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414400,
author = {Kim, Wonjung and Lee, Seungchul and Kim, Seonghoon and Jo, Sungbin and Yoo, Chungkuk and Hwang, Inseok and Kang, Seungwoo and Song, Junehwa},
title = {Computational Support for Facilitating Parental Reflective Functioning in Everyday Parent-Child Interaction},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414400},
doi = {10.1145/3410530.3414400},
abstract = {A parent's capacity to understand the mental states of both him/herself and the child is regarded as important in the parent-child relationship. We propose Dyadic Mirror, a wearable smart mirror that is designed to foster this parental capacity in everyday parent-child interactions. Its key feature is to provide a parent with a second-person live-view from the child, i.e., the parent's own face as seen by the child, during their face-to-face interaction. Dyadic Mirror serves as an intuitive cue that helps the parent be aware of (1) his/her emotional state, and (2) the way he/she would be now being seen by the child, thereby facilitating to infer the child's mental state.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {54–58},
numpages = {5},
keywords = {reflective functioning, self-awareness, wearable service, second-person live-view, perspective-taking, parent-child interaction},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414420,
author = {Kotlinski†, Piotr and Chang, Xi-Jing and Chih-Yun, Yang and Chiu, Wei-Chen and Chang, Yung-Ju},
title = {Using Gamification to Create and Label Photos That Are Challenging for Computer Vision and People},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414420},
doi = {10.1145/3410530.3414420},
abstract = {It would be hard to overstate the importance of Computer Vision (CV), applications of which can be found from self-driving cars, through facial recognition to augmented reality and the healthcare industry. Recent years have witnessed dramatic progress in visual-object recognition, partially ascribable to the availability of labeled data. Unfortunately, recognition of obscure, unclear and ambiguous photos that are taken from unusual angles or distances remains a major challenge, as recently shown by the creation of the ObjectNet [1]. This paper complements that work via a game in which obscure, unclear and ambiguous photos are collaboratively created and labeled by the players, who adopt the role of detectives collecting evidence against in-game criminals. The game rules enforce the creation of images that are challenging to identify for CV and people alike, as a means of ensuring the high quality of players' input.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {59–62},
numpages = {4},
keywords = {human-computer interactions, gamification, mobile crowdsourcing, computer vision},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414424,
author = {Kuo, Ting-Yu and Chu, Hung-Kuo and Chang, Yung-Ju},
title = {Comparing the Effects of Reference-Based, Orientation-Based, and Turn-by-Turn Navigation Guidance on Users' Independent Navigation},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414424},
doi = {10.1145/3410530.3414424},
abstract = {Research has shown that turn-by-turn navigation guidance has made users overly reliant on such guidance, impairing their independent wayfinding ability. This paper compares the impacts of two new types of navigation guidance - reference-based and orientation-based - on their users' ability to independently navigate to the same destinations, both as compared to each other, and as compared to two types of traditional turn-by-turn guidance, i.e., map-based and augmented-reality (AR) based. The results of our within-subjects experiment indicate that, while the use of reference-based guidance led to users taking more time to navigate when first receiving it, it boosted their subsequent ability to independently navigate to the same destination in less time, via more efficient routes, and with less assistance-seeking from their phones than either map-based or AR-based turn-by-turn navigation guidance did.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {63–66},
numpages = {4},
keywords = {spatial knowledge, pedestrian navigation, wayfinding performance, navigational guidance, mobile navigation systems},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414402,
author = {Lee, Jae-Jun and Choi, Jong-Hyeok and Chuluunsaikhan, Tserenpurev and Nasridinov, Aziz},
title = {Pose Evaluation for Dance Learning Application Using Joint Position and Angular Similarity},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414402},
doi = {10.1145/3410530.3414402},
abstract = {In this paper, we propose a dance pose evaluation method for a dance learning application using a smartphone. In the past, methods for classifying and comparing dance gestures through 3-D joint information obtained through a 3-D camera have been proposed, but there is a problem in using them for accurate dance pose evaluation. That is, these methods simply compare the similarity between the dance gestures without evaluation of the exact dance pose. To solve this problem, we propose a new method that can be operated on a smartphone for exact dance pose evaluation that simultaneously performs an affine transformation and an evaluation method to compare the joint position and joint angle information. In addition, we prove that the proposed method is suitable for dance learning applications through comparative experiments on a smartphone with real-world datasets.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {67–70},
numpages = {4},
keywords = {pose evaluation, e-learning, dance learning, smartphone application},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414384,
author = {Lin, Tzu-Chieh and Su, Yu-Shao and Yang, Emily and Chen, Yun Han and Lee, Hao-Ping and Chang, Yung-Ju},
title = {A Preliminary Investigation of the Mismatch between Attendance Order and Desired Display Order of Smartphone Notifications},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414384},
doi = {10.1145/3410530.3414384},
abstract = {Research shows that smartphone users often attend to phone notifications that are in the middle of the notification list. This suggests a mismatch between the display order and the users' attendance order on the notifications. Yet, we know little about how users would like their notifications to be sorted and presented. This paper presents the preliminary results of a mixed-methods study of the difference between smartphone users' attendance order and their desired display order of smartphone notifications. Our preliminary results show that a mismatch between attendance order and desired display order existed in nearly half of cases. Specifically, many users desired certain categories of notifications to be placed higher in their notification drawers than their actual notification-attendance behaviors would tend to suggest. Additionally, while our participants felt that some notifications have low-attractiveness senders or content, such as shopping-related ones, they would want the system to give them a higher priority.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {71–74},
numpages = {4},
keywords = {experience sampling method, notification order, notification management, mobile receptivity, display order, attentiveness},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414422,
author = {Ma, Ge and Gu, Weixi and Huang, Qiyang and Zhu, Guowei and Lv, Kan and Li, Yujia},
title = {Anomaly Detection for Mobile Devices in Industrial Internet},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414422},
doi = {10.1145/3410530.3414422},
abstract = {The concept of "Industrial Internet" was first proposed by General Electric in 2012. It aims to promote the intellectualization of the whole service system. However, with the development of the Industrial Internet, some criminals launch attacks on industrial control terminals (such as computers and mobile devices), causing the failure of industrial control terminals or wrong instructions, which resulting in factory losses. Therefore, there is an immediate need to extract valuable information from mobile network streaming, accurately detect abnormal behaviors and timely raise the alarm.In this paper, we propose a method of anomaly detection for mobile devices in Industrial Internet based on knowledge graph and demonstrate the results by using visualization technology. First, we use the optimized data mining algorithm based on frequent item sets to analyse the data, so that our method can accurately detect different kinds of concurrent attacks. Second, this method is able to locate the IP addresses of the attacker and the victim accurately. Third, we design an anomaly alarm module, which can visualize the results in multiple dimensions and assist security administrators to understand complex network situation in real time and take corresponding measures according to the network anomaly.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {75–77},
numpages = {3},
keywords = {knowledge graph, anomaly detection, industrial internet},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414383,
author = {Maruichi, Takanori and Uragami, Taichi and Vargo, Andrew and Kise, Koichi},
title = {Handwriting Behavior as a Self-Confidence Discriminator},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414383},
doi = {10.1145/3410530.3414383},
abstract = {Receiving feedback based on the combination of self-confidence and correctness of an answer can help learners to improve learning efficiency. In this study, we propose a self-confidence estimation method using a simple touch up/move/down events that can be measured in a classroom environment. We recorded handwriting behavior during the answering vocabulary questions with a tablet and a stylus pen, estimating self-reported confidence. We successfully built a method that can predict the user's self-confidence with a maximum of 73% accuracy.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {78–81},
numpages = {4},
keywords = {handwriting behavior analysis, self-confidence estimation, quantified learning, mobile computing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414381,
author = {Mazurek, Mariusz and Rymarczyk, Tomasz and Kania, Konrad and K\l{}osowski, Grzegorz},
title = {Dedicated Algorithm Based on Discrete Cosine Transform for the Analysis of Industrial Processes Using Ultrasound Tomography},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414381},
doi = {10.1145/3410530.3414381},
abstract = {The article presents a cyber-physical system for acquiring, processing and reconstructing images from measurement data. The technology is based on process tomography, intelligent sensors, machine learning, Big Data, Cloud Computing, as well as Internet of Things as a solution for industry 4.0. Industrial tomography allows observation of physical and chemical phenomena without the need for internal penetration, in a non-destructive way and allows monitoring of manufacturing processes in real time. The application contains a dedicated algorithm based on discrete cosine transformation to solve the inverse problem and a specialized intelligent system for tomographic measurements.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {82–85},
numpages = {4},
keywords = {industry 4.0, machine learning, inverse problem, cyber-physical system, sensors, discrete cosine transformation, ultrasound tomography},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414418,
author = {McLeod, Amanda and Nabil, Sara and Jones, Lee and Girouard, Audrey},
title = {SMAller Aid: Exploring Shape-Changing Assistive Wearables for People with Mobility Impairment},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414418},
doi = {10.1145/3410530.3414418},
abstract = {Individuals with mobility impairments often discuss the challenges associated with donning and doffing shirts (i.e. putting them on and taking them off). Limited previous work has tackled this issue, but the comfort and aesthetic integrity of the shirt is often forgotten. In this paper, we co-designed an adaptive shirt with individuals with mobility impairments and personal support workers. With the insights from these discussions, we developed an augmented top that transforms wide sizes (for the easy donning and doffing) into their preferred fit. The study resulted in the design of SMAller Aid, which uses Shape Memory Alloy (SMA) springs to retract to a smaller size. The shirt adapts to their needs while retaining its aesthetic integrity to empower them with independence and no required assistance.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {86–89},
numpages = {4},
keywords = {wearables, doffing, shape memory alloy, mobility impairments, donning, soft actuation, shape-changing interfaces},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414401,
author = {Monarca, Ivonne and Cibrian, Franceli L. and Mendoza, Angel and Hayes, Gillian and Tentori, Monica},
title = {Why Doesn't the Conversational Agent Understand Me? A Language Analysis of Children Speech},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414401},
doi = {10.1145/3410530.3414401},
abstract = {Conversation agents have shifted the way we communicate with ubiquitous services by enabling the use of natural language communication and the analysis of acoustic and linguistic language patterns. Speech skills of children are not yet fully developed; therefore, most conversational agents frequently misunderstand them. In this research, we examined if conversational agents can uncover instances of language discrimination in children. We developed Bolita, a conversational agent using a Google Home and a Sphero Robot to encourage children to practice how to tell a joke. The results of a two week study of the use of Bolita by 37 Mexican children showed a conversational agent is more likely to misunderstand children with speech skills below average. Our results indicate that they speak less, use fewer words, and need more time to answer when interacting with a conversational agent, which may explain the challenges with the conversational agent understanding them. We close discussing the potential of conversational agents to uncover digital markers in children with language differences and suggest ways that conversational agents could be built to be more inclusive.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {90–93},
numpages = {4},
keywords = {joke-telling, children, conversational agents},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414377,
author = {Okuno, Akane and Sumi, Yasuyuki},
title = {Lifelog Visualization Based on Social and Physical Activities},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414377},
doi = {10.1145/3410530.3414377},
abstract = {This paper presents the visualization of lifelog based on the amount of social and physical activities for well-being. The motivation is that enables users to aware their social, physical, and moderate activities for behavioral change aiming a comfortable how to spend life for individuals. In this paper, three experiments were conducted to examine the feasibility of measuring and visualizing daily activities. We classified the one student's various daily activities to see the tendency of activity levels and classes. Also, we examined individual differences of three people in the same spatiotemporal space. Finally, we examined how the one student's activity changes of half-day can be visualized.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {94–97},
numpages = {4},
keywords = {social and physical activity, lifelog, visualization, well-being},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414417,
author = {Park, Jaejun and Pushp, Saumay and Chang, Youngjae and Kahsay, Hailu Belay and Won, Jeongho and Kang, Seungwoo and Song, Junehwa},
title = {IMception: Camouflaging Sensitive-Apps' Chat-Screens with Deceptive UIs},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414417},
doi = {10.1145/3410530.3414417},
abstract = {Several privacy sensitive apps, e.g., dating apps, and medical counselling apps are equipped with Instant Messaging (IM) features. Messenger features in such apps, let users to chat romantically or as a part of getting personal counselling. However, frequently interacting with the app's messenger service privately, is difficult in public spaces. We term such public spaces as Casual Acquaintance-prone Spaces (CAS). To overcome the limitations associated with interacting with sensitive apps, we propose IMception, a design solution to camouflage sensitive apps' messenger-feature within another app's UI. To conceptualize the design of IMception, we conducted a two-week long survey. Our key findings include that participants felt concerned not only with the content (text messages) from their sensitive apps but also with the appearance of the app from its UI. At last, we explore and discuss the design of IMception and highlight its important design considerations.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {98–101},
numpages = {4},
keywords = {deception, privacy, mobile computing, shoulder surfing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414378,
author = {Peng, Youhong (Friendred) and Tanaka, Atau and Ward, Jamie A.},
title = {The Light: Exploring Socially Improvised Movements Using Wearable Sensors in a Performative Installation},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414378},
doi = {10.1145/3410530.3414378},
abstract = {This work explores the potential of a set comprised of wearable sensors, a performative lighting installation, and a public museum space, to inspire performative and collaborative social behavior among members of the public. Our installation, The Light, was first exhibited as part of the Late at Tate Britain event in 2019. In this paper we discuss the concept and technological implementation behind the work, and present an initial qualitative study of observations made of the people who interacted with it. The study provides a subjective evaluation based on people's facial expressions and body language as they improvise and coordinate their movements with one another and with the installation.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {102–105},
numpages = {4},
keywords = {body movement, installation, motion sensors, wearable computing, data embodiment},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414416,
author = {Regouga, Miguel and Ashby, Simone and Nunes, Nuno Jardim},
title = {The Future of Radio: Combining Music Streaming with Traditional Terrestrial Radio Services},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414416},
doi = {10.1145/3410530.3414416},
abstract = {Audio streaming services are used daily by millions worldwide, enabling on-demand listening and the discovery of songs, artists and podcasts that closely align with the listener's preferences. Meanwhile, traditional terrestrial radio persists as another ubiquitous and still viable mode of accessing more pre-programmed music and news content, including traffic reports and weather information. While both media services offer listeners a distinct set of value propositions, efforts to combine the 'best of both worlds' have been few and far between. Towards this objective, we describe our preliminary efforts to understand audio media consumers' music streaming and traditional radio listening habits and preferences as part of a project aimed at creating an integrated experience for individual listeners and their close networks of family and friends. Through rapid prototyping, and the speed dating method, we explore the design implications for creating and validating radio-like experiences that are at once personal, customizable and shareable.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {106–109},
numpages = {4},
keywords = {music technology, human-computer interaction, music, user-centered design, interactive radio, terrestrial radio, music streaming services},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414382,
author = {Rukasha, Tendai and Woolley, Sandra I and Collins, Tim},
title = {Wearable Epilepsy Seizure Monitor User Interface Evaluation: An Evaluation of the Empatica 'embrace' Interface},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414382},
doi = {10.1145/3410530.3414382},
abstract = {Wearable health devices have the potential to incentivize individuals in health-promoting behaviors and to assist in the monitoring of health conditions. Wearable epilepsy seizure monitoring devices are now evolving that can support individuals and their caregivers via the automated sensing, reporting and logging of epileptic seizures. This work contributes a novel reflection on the interface requirements of wearer users and non-wearer stakeholder users. We evaluate the "guessability" of the light pattern interface of the Empatica Embrace wrist-worn epileptic seizure monitor and provide box plot results for eight interface indications. We also report summarised feedback from a heuristic analysis with fourteen participant evaluators. The results indicate some satisfaction with the minimal aesthetic of a simple light pattern interface as well as some concerns about confusion between different indications, accessibility and reliance on recall.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {110–114},
numpages = {5},
keywords = {wearable computing, epilepsy monitoring, health technology, interface evaluation, heuristic evaluation, usability},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414419,
author = {Ryokai, Kimiko and Park, Julia and Deng, Wesley},
title = {Personal Laughter Archives: Reflection through Visualization and Interaction},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414419},
doi = {10.1145/3410530.3414419},
abstract = {We present our ongoing effort to capture, represent, and interact with the sounds of our loved ones' laughter in order to offer unique opportunities for us to celebrate the positive affect in our shared lived experiences. We present our informal evaluation of laughter visualizations and argue for applications in ubiquitous computing scenarios including Mobile Augmented Reality (MAR).},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {115–118},
numpages = {4},
keywords = {reflection, visualization, laughter, mobile augmented reality},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414413,
author = {Saisho, Osamu and Kashiwagi, Keiichiro and Saito, Yui and Fujino, Tomoyuki},
title = {Adaptive Biosignal Data Gathering for Distributed and Continual Remote Monitoring},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414413},
doi = {10.1145/3410530.3414413},
abstract = {Long-term biosignal monitoring should adopt continual learning models considering past and current temporal traits. Continual monitoring requires both high quality data that capture each user's temporal traits and high performance models. Thanks to the latest sensing and device technology, user-local continual data acquisition has become easier. However, the data of many users distributed remotely need to be gathered to label data, train models, and analyze them in a real system. The biggest problems are the communication volume and the cloud capacity with uploading and storing raw biosignal data of all users. We, therefore, propose a distributed active sampling method for continual learning. Our method adaptively enables both a model to be efficiently trained and temporal traits to be extracted for each user at each time adaptively. We also verify our method in a use case of arrhythmia observation with ECG. The experimental results indicate its effectiveness in terms of efficiency for model training, graspability for temporal traits, and adaptability.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {119–122},
numpages = {4},
keywords = {edge computing, biosignal, continual learning, remote monitoring, distributed active sampling},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414410,
author = {Scott, Kristen M. and Ashby, Simone and Cibin, Roberto},
title = {Implementing Text-to-Speech Tools for Community Radio in Remote Regions of Romania},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414410},
doi = {10.1145/3410530.3414410},
abstract = {The use of text-to-speech (TTS) technology to generate radio content is largely unexplored, despite the importance of radio, in particular in remote parts of the world where TTS offers a robust means of transforming existing data into media for low-literate audiences and those without regular internet access. Is synthetic speech able to meet the expectations of radio listeners and add value to community radio stations in remote areas? We present a preliminary analysis of the design and use of TTS applications in the context of two emerging community radio stations in rural Romania. We find that while the applications developed so far are generally perceived as useful for the running of the station, future work should focus on identifying additional use cases that add value beyond that of 'filling time' or simply replacing the need for a human voice.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {123–126},
numpages = {4},
keywords = {community radio, accessibility, text to speech},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414388,
author = {Senaratne, Hashini and Ellis, Kisrten and Oviatt, Sharon and Melvin, Glenn},
title = {Detecting and Differentiating Leg Bouncing Behaviour from Everyday Movements Using Tri-Axial Accelerometer Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414388},
doi = {10.1145/3410530.3414388},
abstract = {Leg bouncing is assumed to be related to anxiety, engrossment, boredom, excitement, fatigue, impatience, and disinterest. Objective detection of this behaviour would enable researching its relation to different mental and emotional states. However, differentiating this behaviour from other movements is less studied. Also, it is less known which sensor placements are best for such detection. We collected recordings of everyday movements, including leg bouncing, from six leg bouncers using tri-axial accelerometers at three leg positions. Using a Random Forest Classifier and data collected at the ankle, we could obtain a 90% accuracy in the classification of the recorded everyday movements. Further, we obtained a 94% accuracy in classifying four types of leg bouncing. Based on the subjects' opinion on leg bouncing patterns and experience with wearables, we discuss future research opportunities in this domain.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {127–130},
numpages = {4},
keywords = {behavioural markers, leg shaking, leg bouncing, classification, machine learning, fidget, accelerometer},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414411,
author = {Sewak, Mohit and Sahay, Sanjay K. and Rathore, Hemant},
title = {DOOM: A Novel Adversarial-DRL-Based Op-Code Level Metamorphic Malware Obfuscator for the Enhancement of IDS},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414411},
doi = {10.1145/3410530.3414411},
abstract = {We designed and developed DOOM (Adversarial-DRL based Opcode level Obfuscator to generate Metamorphic malware), a novel system that uses adversarial deep reinforcement learning to obfuscate malware at the op-code level for the enhancement of IDS. The ultimate goal of DOOM is not to give a potent weapon in the hands of cyber-attackers, but to create defensive-mechanisms against advanced zero-day attacks. Experimental results indicate that the obfuscated malware created by DOOM could effectively mimic multiple-simultaneous zero-day attacks. To the best of our knowledge, DOOM is the first system that could generate obfuscated malware detailed to individual op-code level. DOOM is also the first-ever system to use efficient continuous action control based deep reinforcement learning in the area of malware generation and defense. Experimental results indicate that over 67% of the metamorphic malware generated by DOOM could easily evade detection from even the most potent IDS. This achievement gains significance, as with this, even IDS augment with advanced routing sub-system can be easily evaded by the malware generated by DOOM.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {131–134},
numpages = {4},
keywords = {op-code, deep reinforcement learning, obfuscation, metamorphic malware},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414395,
author = {Torkamaan, Helma and Ziegler, J\"{u}rgen},
title = {Exploring Chatbot User Interfaces for Mood Measurement: A Study of Validity and User Experience},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414395},
doi = {10.1145/3410530.3414395},
abstract = {With the growth of interactive text or voice-enabled systems, such as intelligent personal assistants and chatbots, it is now possible to easily measure a user's mood using a conversation-based interaction instead of traditional questionnaires. However, it is still unclear if such mood measurements would be valid, akin to traditional measures, and user-engaging. Using smartphones, we compare in this paper two of the most popular traditional measures of mood: International PANAS-Short Form (I-PANAS-SF) and Affect Grid. For each of these measures, we then investigate the validity of mood measurement with a modified, chatbot-based user interface design. Our preliminary results suggest that some mood measures may not be resilient to modifications and that their alteration could lead to invalid, if not meaningless results. This exploratory paper then presents and discusses four voice-based mood tracker designs and summarizes user perception of and satisfaction with these tools.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {135–138},
numpages = {4},
keywords = {chatbot, conversational ESM, affect grid, PANAS, mood tracking},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414408,
author = {van den Heuvel, Roy and Driesse, Emma and Dekker, Minne and Calota, Mihnea},
title = {Understanding Routines around Medicine Intake through a Data-Enabled Design Approach},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414408},
doi = {10.1145/3410530.3414408},
abstract = {Adhering to the prescribed medication schedule is one of the crucial steps that lead to successful recovery or treatment for chronic diseases. However, more than 50% of prescription medicine is not taken as instructed. Existing interventions that focus on reminders often lack detailed insights into people's daily intake routines. Ubiquitous sensor systems in combination with qualitative data can facilitate detailed insights into medication routines. We draw on the Data-Enabled Design framework to gain a better understanding of behaviors around medicine intake. This study implements the contextual step by collecting data with a sensor module as an attachment to an existing pillbox. The resulting data is then discussed with the participant to reveal novel insights into medication non-adherence. We show the first promising results from a one-week user-test with one participant and discuss the next steps in the Data-Enabled Design process.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {139–142},
numpages = {4},
keywords = {sensors, medication non-adherence, data-enabled design},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414379,
author = {Vishkaie, Rojin},
title = {Designing the Catbus: Interactive Support for Early Childhood Emotional Well-Being in Education},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414379},
doi = {10.1145/3410530.3414379},
abstract = {There is a relative lack of affective technology to support young children in communicating their emotions, particularly in educational contexts. This paper is concerned with discussing prior design challenges and vision for creating an emotion-communication technology for young children. We describe a system - the Catbus - which conceptualizes a digital and interactive storytelling of children's emotions fed through their wristbands, as well as online resources to support adoption by educators and students.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {143–146},
numpages = {4},
keywords = {educational technology, emotions in education, children's well-being, interactive emotional support},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414380,
author = {Weigel, Martin and Sch\"{o}n, Oliver and Janssen, Herbert},
title = {Evaluation of Body-Worn FPCBs with Bluetooth Low Energy, Capacitive Touch, and Resistive Flex Sensing},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414380},
doi = {10.1145/3410530.3414380},
abstract = {Commercially available flexible printed circuit boards (FPCBs) have the potential to embed electronics, connectivity, and interactivity into the same surface. This makes them an ideal platform for untethered and interactive wearable devices. However, we lack an understanding how well FPCB-based antennas and sensors perform when worn directly on the body. This work contributes an understanding by studying body-worn FPCBs in three technical evaluations: First, we study the integration of Bluetooth Low Energy and compare the signal strength of our body-worn FPCB with a rigid BLE developer board. Second, we study the accuracy of capacitive touch sensing with two electrode sizes. Finally, we develop a resistive flex sensor based on commercially available FPCB materials and compare its accuracy with a state-of-the-art flex sensor. Taken together, our results demonstrate a high usability of FPCB-based wearable devices.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {147–150},
numpages = {4},
keywords = {touch input, flexible, wireless, wearables, flex sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414404,
author = {W\'{o}jcik, Dariusz and Koz\l{}owski, Edward and Woundefined, Micha\l{} and Rymarczyk, Tomasz and Woundefinedko, Elundefinedbieta},
title = {Machine Learning Pathology Detection with a Body Surface Potential Mapping},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414404},
doi = {10.1145/3410530.3414404},
abstract = {The development of technology has enabled the construction of various expert systems that can now assist experts in disease recognition. Nowadays, most of the expert systems are based on decision trees. The parameters inside a decision tree are based on experts' knowledge and scientific data which vary slightly depending on the expert and source. To deal with this problem, we developed a complete medical system in which electrical impedance tomography and body surface potential mapping are used to measure the patient biosignals. The system focuses on the cardiorespiratory biosignals. With the use of machine learning, we analyze each measured channel and show which channel should be taken into account in the detection of pathologies. We show that the channels that are important for machine learning are different from those used by experts in 12-channel ECG.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {151–155},
numpages = {5},
keywords = {machine learning, BSPM, wearables, ECG},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414406,
author = {Yamaguchi, Kohei and Iwata, Motoi and Vargo, Andrew and Kise, Koichi},
title = {Mobile Vocabulometer: A Context-Based Learning Mobile Application to Enhance English Vocabulary Acquisition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414406},
doi = {10.1145/3410530.3414406},
abstract = {Vocabulary acquisition is the basis of learning a language, and using flashcards applications is a popular method for learners to memorize the meaning of unknown words. Unfortunately, this method alone is not effective for learners to remember the meaning of words when they appear in sentences. To solve this, we developed the Mobile Vocabulometer which allows users to acquire new vocabulary with context-based learning. Based on the correlation between comprehension and interests, we use the learning materials that adapt to users' interests and language skills. This system harnesses the power of the original Vocabulometer, and modifies it to be effective for mobile learning. An experiment on Japanese university students showed that, overall, learners achieved better results compared to using a simple flashcard application. This result indicates that this system provides a significant advantage over context-free learning systems.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {156–159},
numpages = {4},
keywords = {context-based learning, mobile learning, vocabulary acquisition, education, language learning, learning system},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414385,
author = {Yang, Lanqing and Li, Honglu and Chen, Zhaoxi and Ji, Xiaoyu and Chen, Yi-Chao and Xue, Guangtao and You, Chuang-Wen},
title = {Appliance Fingerprinting Using Sound from Power Supply},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414385},
doi = {10.1145/3410530.3414385},
abstract = {Recognizing the working appliances is of great importance for smart environment to provide services including energy conservation, user activity recognition, fire hazard prevention, etc. There have been many methods proposed to recognize appliances by analyzing the power voltage, current, electromagnetic emissions, vibration, light, and sound from appliances. Among these methods, measuring the power voltage and current requires installing intrusive sensors to each appliance. Measuring the electromagnetic emissions and vibration requires sensors to be attached or close (e.g., &lt; 15cm) to the appliances. Methods relying on light are not universally applicable since only part of appliances generate light. Similarly, methods using sound relying on the sound from motor vibration or mechanical collision so are not applicable for many appliances. As a result, existing methods for appliance fingerprinting are intrusive, have high deployment cost, or only work for part of appliances. In this work, we proposed to use the inaudible high-frequency sound generated by the switching-mode power supply (SMPS) of the appliances as fingerprints to recognize appliances. Since SMPS is widely adopted in home appliances, the proposed method can work for most appliances. Our preliminary experiments on 18 household appliances (where 10 are of the same models) showed that the recognition accuracy achieves 97.6%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {160–163},
numpages = {4},
keywords = {acoustic signals, appliance fingerprinting, SMPS},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414423,
author = {Yu, Yang and Weis, Torben},
title = {A Privacy-Protecting Indoor Emergency Monitoring System Based on Floor Vibration},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414423},
doi = {10.1145/3410530.3414423},
abstract = {In this work we present an indoor emergency context monitoring system based on ground vibration caused by persons in the target area. The system is designed for production plants and large buildings to perceive the safety status of this area. Our approach is privacy-protecting, because it requires neither video nor sound. Instead, piezo sensors on the floor measure vibrations, which are analyzed with machine learning to compute the safety status of the covered area. This way our system can determine whether an emergency occurred, but it is not straight forward possible to attach names to the detected persons. We compare the impact of different feature extraction methods and different types of classifiers on the classification results. Our experiments show that we can determine an emergency event with an average F1 score of 0.97.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {164–167},
numpages = {4},
keywords = {emergency detecton, deep learning, pattern recognition, ontext recognition, vibration signal, piezo sensor, privacy protection},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414387,
author = {Zhang, Hao and Yin, Yafeng and Xie, Lei and Lu, Sanglu},
title = {AirTyping: A Mid-Air Typing Scheme Based on Leap Motion},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414387},
doi = {10.1145/3410530.3414387},
abstract = {In Human-Computer Interactions (HCI), to reduce the dependency of bulky devices like physical keyboards and joysticks, many gesture-based HCI schemes are adopted. As a typical HCI technology, text input has aroused much concern and many virtual or wearable keyboards have been proposed. To further remove the keyboard and allow people to type in a device-free way, we propose AirTyping, i.e., a mid-air typing scheme based on Leap Motion. During the typing process, the Leap Motion Controller captures the typing gestures with cameras and provides the coordinates of finger joints. Then, AirTyping detects the possible keystrokes, infers the typed words based on Bayesian method, and outputs the inputted word sequence. The experiment results show that our system can detect the keystrokes and infer the typed text efficiently, i.e., the true positive rate of keystroke detection is 92.2%, while the accuracy that the top-1 inferred word is the typed word achieves 90.2%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {168–171},
numpages = {4},
keywords = {human-computer interaction, leap motion, mid-air typing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414393,
author = {Zhang, Lingyu and Yin, Yafeng and Xie, Lei and Lu, Sanglu},
title = {HmwkCheck: A Homework Auto-Checking System Based on Arithmetic Operation Recognition Using Smartphones},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414393},
doi = {10.1145/3410530.3414393},
abstract = {The homework for low-grade pupils often contains simple arithmetic problems, i.e., four arithmetic operations. To evaluate the learning quality of pupils, teachers and parents often need to check the homework manually, which is time and labor consuming. In this paper, we propose a homework auto-checking system HmwkCheck, which checks the four arithmetic operations automatically. Specifically, HmwkCheck utilizes the embedded camera of a smartphone to capture the homework as an image, and then processes the image in the smartphone to detect, segment and recognize both printed characters and handwritten characters. We implement HmwkCheck in an Android smartphone. The experiment results show that HmwkCheck can check homework efficiently, i.e., the average precision, recall and F1-score of character recognition achieve 94.03%, 93.41% and 93.72%, respectively.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {172–175},
numpages = {4},
keywords = {smartphone, homework auto-checking, image processing, arithmetic operation recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414397,
author = {Zhang, Shibo and Xu, Qiuyang and Sen, Sougata and Alshurafa, Nabil},
title = {VibroScale: Turning Your Smartphone into a Weighing Scale},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414397},
doi = {10.1145/3410530.3414397},
abstract = {Smartphones, with their ubiquity and plethora of embedded sensors enable on-the-go measurement. Here, we describe one novel measurement potential, weight measurement, by turning an everyday smartphone into a weighing scale. We describe VibroScale, our vibration-based approach to measuring the weight of objects that are small in size. Being able to objectively measure the weight of objects in free-living settings, without the burden of carrying a scale, has several possible uses, particularly in weighing small food items. We designed a smartphone app and regression algorithm, which we termed VibroScale, that estimates the relative induced intensity of an object placed on the smartphone. We tested our proposed method using more than 50 fruits and other everyday objects of different sizes and weights. Our smartphone-based method can measure the weight of fruit without relying on an actual scale. Overall, we observed that VibroScale can measure one type of object with a mean absolute error of 12.4 grams and a mean absolute percentage error of 7.7%. We believe that in future this approach can be generalized to estimate calories and measure the weight of various types of objects.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {176–179},
numpages = {4},
keywords = {vibration, mobile application, smartphone, accelerometer, automatic measurement, food weight estimation, fruit calorie estimation, ubiquitous computing, weighing scale},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414405,
author = {Zhang, Yiyi and Nakajima, Tatsuo},
title = {Gamified Navigation System: Enhancing Resident User Experience in City Exploration},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414405},
doi = {10.1145/3410530.3414405},
abstract = {A memorable city exploration experience requires some unexpected surprises. For pedestrians exploring in city blocks, ordinary route planning and navigation system cannot meet the need of interesting exploration and would even miss the possible surprises on the way. In order to enhance resident user experience in city exploration, we designed a gamified exploratory navigation system. Our system would engage the user when they are close to a point of interest (POI) by proposing interactive activities and "conversing" with them. We conducted preliminary field experiment with 5 participants to evaluate our system and observe how mobile technology and navigation system are practical used in city exploration. We hope our study could provide some reflecting for the further design of these kinds of services and systems which would engage residents in exploring the city and strengthen the connection with the city.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {180–183},
numpages = {4},
keywords = {gamification, augmented reality, city exploration navigation, user experience, location-based service},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414326,
author = {Aliyev, Anar and Zhou, Bo and Hevesi, Peter and Hirsch, Marco and Lukowicz, Paul},
title = {HeadgearX: A Connected Smart Helmet for Construction Sites},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414326},
doi = {10.1145/3410530.3414326},
abstract = {This work demonstrates a connected smart helmet platform, HeadgearX, aimed at improving personnel safety and real-time monitoring of construction sites. The smart helmet hardware design is driven by flexible and expandable sensing and actuating capabilities to adapt to various workplace requirements and functionalities. In our demonstrator, the system consists of ten different sensors, visual and haptic feedback mechanism, and Bluetooth connectivity. A companion Android application is also developed to add further functionalities including those configurable over-the-air. The construction project supervisors can monitor all on-site personnel's real-time statuses from a central web server which communicates to individual HeadgearX helmets via the companion app. Several use case scenarios are demonstrated as examples, while further specific functionalities can be added into HeadgearX by either software re-configurations with the existing system or hardware modifications.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {184–187},
numpages = {4},
keywords = {user experience, smart construction, sensors and actuators},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414324,
author = {Li, Hanchuan and Capone, Tony and Lymberopoulos, Dimitrios},
title = {DeviceAR: Techniques for Device-Oriented Augmented Reality Interactions},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414324},
doi = {10.1145/3410530.3414324},
abstract = {We present DeviceAR, a set of techniques to facilitate AR-based interactions with connected devices. These techniques allow HoloLens to discover and establish communication with devices, control them, and seamlessly exchange digital information using holographic interfaces.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {188–190},
numpages = {3},
keywords = {augmented reality, internet of things, interactive control},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414323,
author = {Odoemelem, Henry Ugochukwu and Van Laerhoven, Kristof},
title = {A Low-Cost Prototyping Framework for Human-Robot Desk Interaction},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414323},
doi = {10.1145/3410530.3414323},
abstract = {Many current human-robot interactive systems tend to use accurate and fast - but also costly - actuators and tracking systems to establish working prototypes that are safe to use and deploy for user studies. This paper presents an embedded framework to build a desktop space for human-robot interaction, using an open-source robot arm, as well as two RGB cameras connected to a Raspberry Pi-based controller that allow a fast yet low-cost object tracking and manipulation in 3D. We show in our evaluations that this facilitates prototyping a number of systems in which user and robot arm can commonly interact with physical objects.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {191–194},
numpages = {4},
keywords = {human-robot interaction, tangible computing, object tracking},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414325,
author = {Zeng, Youwei and Liu, Zhaopeng and Wu, Dan and Liu, Jinyi and Zhang, Jie and Zhang, Daqing},
title = {A Multi-Person Respiration Monitoring System Using COTS Wifi Devices},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414325},
doi = {10.1145/3410530.3414325},
abstract = {In recent years, we have seen efforts made to simultaneously monitor the respiration of multiple persons based on the channel state information (CSI) retrieved from commodity WiFi devices. However, existing approaches only work when multiple persons exhibit dramatically different respiration rates and the performance degrades significantly when the targeted subjects have similar rates. What's more, they can only obtain the average respiration rate over a period of time and fail to capture the detailed rate change over time. These two constraints greatly limit the application of the proposed approaches in real life. Different from the existing approaches that apply spectral analysis to the CSI amplitude (or phase difference) to obtain respiration rate information, we leverage the multiple antennas provided by the commodity WiFi hardware and model the multi-person respiration sensing as a blind source separation (BSS) problem. Then, we solve it using independent component analysis (ICA) to obtain the reparation information of each person. In this demo, we will demonstrate MultiSense - a multi-person respiration monitoring system using COTS WiFi devices.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {195–198},
numpages = {4},
keywords = {wifi sensing, multi-person respiration sensing, channel state information (CSI), blind source separation},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414327,
author = {Adhikary, Rishiraj and Batra, Nipun},
title = {Computational Tools for Understanding Air Pollution},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414327},
doi = {10.1145/3410530.3414327},
abstract = {Ambient fine particulate (PM2.5) is the most significant risk factor for premature death, shortening life expectancy at birth by 1.5 to 1.9 years [2]. 91% of the world's population lives in areas where air pollution exceeds safety limits1. 99% of the people in countries like India, Pakistan, Nepal, and Bangladesh experience ambient exposures of PM2.5 exceeding 75 μg/m3 to 100 μg/m3 [3]. My Ph.D. thesis will be on understanding the perception of air pollution among people using social media data. I also intend to develop a wearable air pollution exposure monitor and design an air pollution visualisation tool to reduce the entry barrier for air pollution research.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {199–203},
numpages = {5},
keywords = {air pollution wearable, visualisation, social media, air pollution perception},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414332,
author = {Bandukda, Maryam and Holloway, Catherine},
title = {Audio AR to Support Nature Connectedness in People with Visual Disabilities},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414332},
doi = {10.1145/3410530.3414332},
abstract = {Nature and outdoor open spaces are good for our mental and physical health; providing space for exercise, relaxation, socializing and exploring nature. Technology plays an important role in how people explore the outdoors, however, despite the prevalence of mobile technologies that promote outdoor mobility, they are often not accessible to people with disabilities. This PhD project explores technologies to promote nature connectedness in blind and partially sighted people. We have conducted formative studies exploring the needs of blind and partially sighted people and barriers that limit their experiences. The next phase of my research will focus on designing auditory augmented reality systems to augment the natural elements in open spaces which are presented to the user in real-time as they navigate the space. We aim to design, implement, and evaluate pervasive auditory augmented reality systems that enhance people's immersive experience and engagement with nature.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {204–207},
numpages = {4},
keywords = {auditory augmented reality, nature, accessibility, blind and partially sighted, spatial audio},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414331,
author = {Boateng, George},
title = {Towards a Wearable System for Assessing Couples' Dyadic Interactions in Daily Life},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414331},
doi = {10.1145/3410530.3414331},
abstract = {Researchers are interested in understanding the dyadic interactions of couples as they relate to relationship quality and chronic disease management. Currently, ambulatory assessment of couples' interactions entail collecting data at random times in the day. There is no ubiquitous system that leverages the dyadic nature of couples' interactions (eg. collecting data when partners are interacting) and also performs real-time inference relevant for relationship quality and chronic disease management. In this work, we seek to develop a smartwatch system that can collect data about couples' dyadic interactions, and infer and track indicators of relationship quality and chronic disease management. We plan to collect data from couples in the field and use the data to develop methods to detect the indicators. Then, we plan to implement these methods as a smartwatch system and evaluate its performance in real-time and everyday life through another field study. Such a system can be used by social psychology researchers to understand the social dynamics of couples in everyday life and their impact on relationship quality, and also by health psychology researchers for developing and delivering behavioral interventions for couples who are managing chronic diseases.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {208–211},
numpages = {4},
keywords = {CNN, wearable computing, couples, social support, multimodal fusion, machine learning, smartwatches, BERT, mobile health, deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414328,
author = {Jin, Haojian and Kumar, Swarun and Hong, Jason},
title = {Providing Architectural Support for Building Privacy-Sensitive Smart Home Applications},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414328},
doi = {10.1145/3410530.3414328},
abstract = {In this thesis, we plan to introduce a new IoT app development framework named Peekaboo, which aims to make it much easier for developers to get the granularity of data they actually need rather than always requesting raw data, while also offering architecture support for building privacy features across all the apps. Peekaboo's architectural design philosophy is to factor out repetitive data pre-processing tasks (e.g., face detection, frequency spectrum extraction) from the cloud side onto a user-controlled hub, and support them as a fixed set of open source, reusable, and chainable operators. These operators pre-process raw data to remove unneeded sensitive user information before the data flow to the cloud (and out of the users' control), thus reducing data egress and many potential privacy risks for users. Further, all the IoT apps built with Peekaboo share a common structure of the chainable operators, making it possible to build consistent privacy features beyond individual apps.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {212–217},
numpages = {6},
keywords = {ubiquitous computing, smart home, toolkit, privacy, software architecture, IoT app development},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414330,
author = {Stojko, Laura},
title = {Intercultural Usability of Large Public Displays},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414330},
doi = {10.1145/3410530.3414330},
abstract = {One component of smart or major cities are large public displays that are used for many purposes - advertising, warning, informing. These devices appeal to a large heterogeneous user group as especially in major cities people from many countries and cultures live together. Even though, researchers have identified intercultural usability recommendations for general and private devices - mobile phones, websites, etc. -, there is still a gap of information about how to design large non-personal, public displays for intercultural user groups. This dissertation explores the challenges and opportunities within the intercultural design space of large public displays. The expected results are design recommendations and guidelines regarding relevant aspects for intercultural usability of large public displays. Further, these results can be used by user interface designers and researchers that want to design, improve, evaluate or further explore large public displays for intercultural settings.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {218–222},
numpages = {5},
keywords = {design guidelines, large public displays, intercultural design, human computer interaction, intercultural usability},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414329,
author = {Zhang, Shibo and Alshurafa, Nabil},
title = {Deep Generative Cross-Modal on-Body Accelerometer Data Synthesis from Videos},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414329},
doi = {10.1145/3410530.3414329},
abstract = {Human activity recognition (HAR) based on wearable sensors has brought tremendous benefit to several industries ranging from healthcare to entertainment. However, to build reliable machine-learned models from wearables, labeled on-body sensor datasets obtained from real-world settings are needed. It is often prohibitively expensive to obtain large-scale, labeled on-body sensor datasets from real-world deployments. The lack of labeled datasets is a major obstacle in the wearable sensor-based activity recognition community. To overcome this problem, I aim to develop two deep generative cross-modal architectures to synthesize accelerometer data streams from video data streams. In the proposed approach, a conditional generative adversarial network (cGAN) is first used to generate sensor data conditioned on video data. Then, a conditional variational autoencoder (cVAE)-cGAN is proposed to further improve representation of the data. The effectiveness and efficacy of the proposed methods will be evaluated through two popular applications in HAR: eating recognition and physical activity recognition. Extensive experiments will be conducted on public sensor-based activity recognition datasets by building models with synthetic data and comparing the models against those trained from real sensor data. This work aims to expand labeled on-body sensor data, by generating synthetic on-body sensor data from video, which will equip the community with methods to transfer labels from video to on-body sensors.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {223–227},
numpages = {5},
keywords = {data augmentation, deep generative model, accelerometer data synthesis, video-sensor data representation learning, deep multi-modal learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414612,
author = {Murao, Kazuya and Enokibori, Yu and Gjoreski, Hristijan and Lago, Paula and Okita, Tsuyoshi and Siirtola, Pekka and Hiroi, Kei and Scholl, Philipp M. and Ciliberto, Mathias},
title = {8th International Workshop on Human Activity Sensing Corpus and Applications (HASCA)},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414612},
doi = {10.1145/3410530.3414612},
abstract = {The recognition of complex and subtle human behaviors from wearable sensors will enable next-generation human-oriented computing in scenarios of high societal value (e.g., dementia care). This will require large-scale human activity corpus and much improved methods to recognize activities and the context in which they occur. This workshop deals with the challenges of designing reproducible experimental setups, running large-scale dataset collection campaigns, designing activity and context recognition methods that are robust and adaptive, and evaluating systems in the real world. We wish to reflect on future methods, such as lifelong learning approaches that allow open-ended activity recognition. This year HASCA will welcome papers from participants to the Third Sussex-Huawei Locomotion and Transportation Recognition Challenge and Second Nursing Activity Recognition Challenge in special sessions.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {228–231},
numpages = {4},
keywords = {open lab nursing activity recognition challenge, mobile sensors, SHL activity recognition challenge, participatory sensing, open-ended activity/context recognition, smartphones, large scale human activity sensing corpus, wearable computing, activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414364,
author = {Alia, Sayeda Shamma and Lago, Paula and Inoue, Sozo},
title = {MCoMat: A New Performance Metric for Imbalanced Multi-Layer Activity Recognition Dataset},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414364},
doi = {10.1145/3410530.3414364},
abstract = {Existing performance metrics assess classifiers on single granularity layer. Having multi-layer labels is also possible such as activity recognition datasets. Semantic annotations could be given with multiple granularity layers in these datasets e.g., activity and the current step within that activity like: cooking and taking ingredients from fridge. Recognizing both layers is important i.e., remote monitoring of patients with dementia. To evaluate a classifier for both layers concurrently, a new performance metric is required. However, it is not easy to design as there are many underlying issues: the relation between the layers and the impact of class imbalance. This work proposes a new metric for evaluating multi-layer labeled dataset considering the mentioned factors and is applied on two datasets. It is found that it can assess the performance of a model classifying activities at two different granularity layers and give more insightful results i.e. reflecting performance for each layer.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {232–237},
numpages = {6},
keywords = {evaluation, multi-layer label, machine learning, performance metric},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414366,
author = {Atkinson, Gentry and Metsis, Vangelis},
title = {Identifying Label Noise in Time-Series Datasets},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414366},
doi = {10.1145/3410530.3414366},
abstract = {Reliably labeled datasets are crucial to the performance of supervised learning methods. Time-series data pose additional challenges. Data points lying on borders between classes can be mislabeled due to perception limitations of human labelers. Sensor measurements may not be directly interpretable by humans. Thus label noise cannot be manually removed. As a result, time-series datasets often contain a significant amount of label noise that can degrade the performance of machine learning models. This work focuses on label noise identification and removal by extending previous methods developed for static instances to the domain of time-series data. We use a combination of deep learning and visualization algorithms to facilitate automatic noise removal. We show that our approach can identify mislabeled instances, which results in improved classification accuracy on four synthetic and two real publicly available human activity datasets.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {238–243},
numpages = {6},
keywords = {human activity recognition, label noise, accelerometer, time-series data, label cleaning, CNN, neural networks},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414360,
author = {Kalatzis, Apostolos and Stanley, Laura and Karthikeyan, Rohith and Mehta, Ranjana K.},
title = {Mental Stress Classification during a Motor Task in Older Adults Using an Artificial Neural Network},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414360},
doi = {10.1145/3410530.3414360},
abstract = {All people cope with mental stress from time to time. Stress can affect our emotional and physical health, which can lead to physical and/or mental health issues. Our experiment aimed to derive the stress levels of 57 older adults from the electrocardiogram (ECG) signal during a lab study that involved a hang-grip strength task. This experiment bridges the gap between previous studies by classifying the mental stress state of older adults while performing a motor task before and after the stressor was induced. In this study heart rate and heart rate variability multi-dimensional features in the time-, and frequency-domain are extracted and an optimized Artificial Neural Network (ANN) created to identify two states --- stress, or no-stress. We achieved accuracy of 90.83%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {244–248},
numpages = {5},
keywords = {machine learning, stress detection, artificial neural network, elderly population, ECG signal},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414367,
author = {Li, Xi'ang and Luo, Jinqi and Younes, Rabih},
title = {ActivityGAN: Generative Adversarial Networks for Data Augmentation in Sensor-Based Human Activity Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414367},
doi = {10.1145/3410530.3414367},
abstract = {Label Scarcity and Data Augmentation have long been challenging problems in the research of Human-oriented Artificial Intelligence. Following the trends of Deep Learning, Human Activity Recognition (HAR) tasks have been significantly optimized in the recent decade with handful of industrial applications on health evaluation and security monitoring. Nevertheless, data acquisition on human activities has been increasingly problematic considering the limited sensor resources and high cost of investment on labor of human volunteers. In this paper, we propose a pioneering unified architecture of convolutional generative adversarial networks, namely ActivityGAN, to effectively generate sensor-based data simulating human physical activities. This architecture comprises of a generation model which is a stack of one-dimensional convolution (1D-convolution) and transposed convolution (1D-transposed convolution) layers, and a discrimination model which employs two-dimensional convolution networks (2D-convolution) with reshaped input of time series. We train the proposed architecture on a collection of activity data and evaluate the generator's output, namely synthetic data, with three approaches of visualization. We then assess the usability of synthetic data by evaluating the test accuracy of models trained with mixed real and synthetic data or with synthetic data that substitutes real data. The study's results show that our proposed architecture is able to generate sufficient synthetic data which are distinguishable by visualization techniques and trainable for HAR machine learning models.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {249–254},
numpages = {6},
keywords = {GAN, data augmentation, activity recognition, neural networks, machine learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414370,
author = {Mairittha, Nattaya and Mairittha, Tittaya and Inoue, Sozo},
title = {Improving Activity Data Collection with On-Device Personalization Using Fine-Tuning},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414370},
doi = {10.1145/3410530.3414370},
abstract = {One of the biggest challenges of activity data collection is the unavoidability of relying on users and keep them engaged to provide labels consistently. Recent breakthroughs in mobile platforms have proven effective in bringing deep neural networks powered intelligence into mobile devices. In this study, we propose on-device personalization using fine-tuning convolutional neural networks as a mechanism in optimizing human effort in data labeling. First, we transfer the knowledge gained by on-cloud pre-training based on crowdsourced data to mobile devices. Second, we incrementally fine-tune a personalized model on every individual device using its locally accumulated input. Then, we utilize estimated activities customized according to the on-device model inference as feedback to motivate participants to improve data labeling. We conducted a verification study and gathered activity labels with smartphone sensors. Our preliminary evaluation results indicate that the proposed method outperformed the baseline method by approximately 8% regarding accuracy recognition.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {255–260},
numpages = {6},
keywords = {activity recognition, data collection, fine-tuning, on-device deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414369,
author = {Nishiyama, Yuuki and Ferreira, Denzil and Sasaki, Wataru and Okoshi, Tadashi and Nakazawa, Jin and Dey, Anind K. and Sezaki, Kaoru},
title = {Using IOS for Inconspicuous Data Collection: A Real-World Assessment},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414369},
doi = {10.1145/3410530.3414369},
abstract = {Mobile Crowd Sensing (MCS) is a method for collecting multiple sensor data from distributed mobile devices for understanding social and behavioral phenomena. The method requires collecting the sensor data 24/7, ideally inconspicuously to minimize bias. Although several MCS tools for collecting the sensor data from an off-the-shelf smartphone are proposed and evaluated under controlled conditions as a benchmark, the performance in a practical sensing study condition is scarce, especially on iOS. In this paper, we assess the data collection quality of AWARE iOS, installed on off-the-shelf iOS smartphones with 9 participants for a week. Our analysis shows that more than 97% of sensor data, provided by hardware sensors (i.e., accelerometer, location, and pedometer sensor), is successfully collected in real-world conditions, unless a user explicitly quits our data collection application.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {261–266},
numpages = {6},
keywords = {iOS, mobile sensing toolkit, effective data collection, real-world assessment, mobile crowd sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414361,
author = {Oransirikul, Thongtat and Takada, Hideyuki},
title = {Social Distancing Warning System at Public Transportation by Analyzing Wi-Fi Signal from Mobile Devices},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414361},
doi = {10.1145/3410530.3414361},
abstract = {A novel coronavirus (nCov) is a new strain that has not been previously identified in humans. The disease caused by this new virus was subsequently named the 'COVID-19'. The outbreak of COVID-19 around the world urges or forces people to isolate themselves, and now social distancing is a part of a new normal to measures taken to increase the distance between individuals to prevent people from being infected the virus. Public transportation is a necessary facility in a city used by many people every day, at the same time is a higher risk place to be infected by COVID-19. Sometime people will forget to keep the distance between nearby persons, that can be a cause of mass infection.In this paper, we propose a social distancing warning system which is implemented by a method to separate passing- by people from waiting people by passively monitoring the activity of Wi-Fi signals from mobile devices. When the number of people in that area exceeds the allowable density, the system will warn the people to keep the distance from other people.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {267–271},
numpages = {5},
keywords = {mobile networking, wi-fi monitoring, social distancing, congestion, COVID-19},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414365,
author = {Pellatt, Lloyd and Roggen, Daniel},
title = {CausalBatch: Solving Complexity/Performance Tradeoffs for Deep Convolutional and LSTM Networks for Wearable Activity Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414365},
doi = {10.1145/3410530.3414365},
abstract = {Deep neural networks consisting of a combination of convolutional feature extractor layers and Long Short Term Memory (LSTM) recurrent layers are widely used models for activity recognition from wearable sensors ---referred to as DeepConvLSTM architectures hereafter. However, the subtleties of training these models on sequential time series data is not often discussed in the literature. Continuous sensor data must be segmented into temporal 'windows', and fed through the network to produce a loss which is used to update the parameters of the network. If trained naively using batches of randomly selected data as commonly reported, then the temporal horizon (the maximum delay at which input samples can effect the output of the model) of the network is limited to the length of the window. An alternative approach, which we will call CausalBatch training, is to construct batches deliberately such that each consecutive batch contains windows which are contiguous in time with the windows of the previous batch, with only the first batch in the CausalBatch consisting of randomly selected windows. After a given number of consecutive batches (referred to as the CausalBatch duration τ), the LSTM states are reset, new random starting points are chosen from the dataset and a new CausalBatch is started. This approach allows us to increase the temporal horizon of the network without increasing the window size, which enables networks to learn data dependencies on a longer timescale without increasing computational complexity.We evaluate these two approaches on the Opportunity dataset. We find that using the CausalBatch method we can reduce the training time of DeepConvLSTM by up to 90%, while increasing the user-independent accuracy by up to 6.3% and the class weighted F1 score by up to 5.9% compared to the same model trained by random batch training with the best performing choice of window size for the latter. Compared to the same model trained using the same window length, and therefore the same computational complexity and almost identical training time, we observe an 8.4% increase in accuracy and 14.3% increase in weighted F1 score. We provide the source code for all experiments as well as a Pytorch reference implementation of DeepConvLSTM in a public github repository.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {272–277},
numpages = {6},
keywords = {best practices, LSTM, batch training, activity recognition, wearable computing, neural networks, deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414362,
author = {Rani, Smriti and Chowdhury, Arijit and Gigie, Andrew and Chakravarty, Tapas and Pal, Arpan},
title = {Action Recognition Using Spatially Distributed Radar Setup through Microdoppler Signature},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414362},
doi = {10.1145/3410530.3414362},
abstract = {Small form factor off-the shelf radar sensor nodes are being investigated for various privacy preserving non-contact sensing applications. This paper, presents a novel method, based on a system of spatially distributed radar setup(panel radar), for real time action recognition. Proposed method uses spatially distributed two single channel Continuous Wave (CW) radars to classify actions. For classification, a unique two layered classifier, is employed on novel features. Layer I performs coarse limb level classification followed by finer action detection in Layer II. For validation of the proposed system, 7 actions were targeted and data was collected for 20 people. Accuracy of 88.6 % was obtained, with a precision and recall of 0.9 and 0.89 respectively, hence proving the efficacy of this novel approach.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {278–253},
keywords = {micro-doppler, action detection, spectrogram, radar, time domain analysis},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414368,
author = {Roggen, Daniel},
title = {ARM Cortex M4-Based Extensible Multimodal Wearable Platform for Sensor Research and Context Sensing from Motion &amp; Sound},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414368},
doi = {10.1145/3410530.3414368},
abstract = {We present an extensible sensor research platform suitable for motion- and sound-based activity and context recognition in wearable and ubiquitous computing applications. The 30x30mm platform is extensible through plug-in boards, which makes it well suited to explore novel sensor technologies. Its firmware can acquire 9-axis inertial measurement unit (IMU) data and device orientation in quaternions at up to 565Hz, sound at 16KHz and external analog inputs, without any programming, allowing for use by non-experts.The data of distinct modalities can be acquired in isolation or simultaneously for multimodal sensing, and can be streamed over Bluetooth or stored locally. The platform has a real-time clock, which enables the acquisition of the data from multiple nodes with a ±10ppm frequency tolerance, without requiring inter-node connectivity. This is useful to collect data from multiple people.Acquiring multimodal data, the measured power consumption is 222mW when streaming and 67mW when logging to an SD card. With a 165mAh battery, this leads to 2h15mn and 9h of operation, respectively, with a weight of 10.8g (6.75g without battery).},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {284–289},
numpages = {6},
keywords = {embedded systems, inertial measurement unit, ubiquitous computing, microphone, sensor research, wearable computing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414363,
author = {Toyosaka, Yuki and Okita, Tsuyoshi},
title = {Perception of Interaction between Hand and Object},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414363},
doi = {10.1145/3410530.3414363},
abstract = {Action knowledge graphs can play a central role in smart cities, smart homes, robot planning, and so on. This is since both of the subject and the object of the actions can add more meaningful information for the higher-level application than the action alone as a predicate. We built a system that generates the action knowledge graphs from video using deep learning. Especially, we propose an algorithm which perceives the interaction between hand and object by measuring the proximity between them with considering the direction of fingers. We showed that this approach achieves the performance of 83% in accuracy using the Stair Lab data.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {290–295},
numpages = {6},
keywords = {knowledge graph, object detection, interaction, centernet, pose estimation, openpose},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414352,
author = {Brajesh, Sunidhi and Ray, Indraneel},
title = {Ensemble Approach for Sensor-Based Human Activity Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414352},
doi = {10.1145/3410530.3414352},
abstract = {This paper discusses in detail our (Team:AISA) ensemble based approach to detect Human Activity for the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge. The SHL recognition challenge is an open competition wherein the participants are tasked with recognizing 8 different types of activities based on smartphone data collected from multiple positions - Hand, Hips, Torso, Bag. On the magnitude of sensor data, time and frequency domain features were calculated to achieve position independence. To make the model robust, we trained it with a random shuffle of the training and validation data provided. To find the optimal hyper-parameters, we parallely executed randomized search to choose the best performing model from about 200 models. We set aside 30% of this combined dataset for internal testing and the model predicted human activities with an F1-Score of 86% on this test dataset.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {296–300},
numpages = {5},
keywords = {random forest, randomizedsearchcv, SHL recognition challenge 2020, activity recognition, parallel computation},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414354,
author = {Dogan, Gulustan and Cay, Iremnaz and Ertas, Sinem Sena and Keskin, \c{S}eref Recep and Alotaibi, Nouran and Sahin, Elif},
title = {Where Are You? Human Activity Recognition with Smartphone Sensor Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414354},
doi = {10.1145/3410530.3414354},
abstract = {This paper describes our submission as Team-Petrichor to the competition that was organized by the SHL recognition challenge dataset authors. We compared multiple machine learning approach for classifying eight different activities (Still, Walk, Run, Bike, Car, Bus, Train, Subway). The first step was feature engineering, a wide set of statistical domain features were computed and their quality was evaluated. Finally, the appropriate machine learning model was chosen. The recognition result for the testing dataset will be presented in the summary paper of the SHL recognition challenge.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {301–304},
numpages = {4},
keywords = {machine learning, locomotion classification, activity recognition, transportation mode prediction},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414350,
author = {Friedrich, Bj\"{o}rn and L\"{u}bbe, Carolin and Hein, Andreas},
title = {Combining LSTM and CNN for Mode of Transportation Classification from Smartphone Sensors},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414350},
doi = {10.1145/3410530.3414350},
abstract = {The broad availability of smartphones and Inertial Measurement Units in particular brings them into focus of recent research. Inertial Measurement Unit data is used for a variety of tasks. One important task is the classification of the mode of transportation. In this paper, we present a deep-learning-based algorithm, that combines long-short-term-memory (LSTM) layer and convolutional layer to classify eight different modes of transportation on the Sussex-Huawei Locomotion-Transportation (SHL) dataset. The inputs of our model are the accelerometer, gyroscope, linear acceleration, magnetometer, gravity and pressure values as well as the orientation information. We achieve a F1 score of 98.96 % on our private test set. We participated as team 103114102106|8 in the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {305–310},
numpages = {6},
keywords = {SHL dataset, classification, convolutional neural networks, mode of transportation, supervised learning, IMU},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414353,
author = {G\"{u}nthermann, Lukas and Simpson, Ivor and Roggen, Daniel},
title = {Smartphone Location Identification and Transport Mode Recognition Using an Ensemble of Generative Adversarial Networks},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414353},
doi = {10.1145/3410530.3414353},
abstract = {We present a generative adversarial network (GAN) approach to recognising modes of transportation from smartphone motion sensor data, as part of our contribution to the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge 2020 as team noname. Our approach identifies the location where the smartphone of the test dataset is carried on the body through heuristics, after which a location-specific model is trained based on the available published data at this location. Performance on the validation data is 0.95, which we expect to be very similar on the test set, if our estimation of the location of the phone on the test set is correct. We are highly confident in this location estimation. If however it were wrong, an accuracy as low as 30% could be expected.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {311–316},
numpages = {6},
keywords = {human activity recognition, generative adversarial networks, mobile computing, deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414351,
author = {Hamidi, Massinissa and Osmani, Aomar and Alizadeh, Pegah},
title = {A Multi-View Architecture for the SHL Challenge},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414351},
doi = {10.1145/3410530.3414351},
abstract = {To recognize locomotion and transportation modes in a user-independent manner with an unknown target phone position, we (team Eagles) propose an approach based on two main steps: reduction of the impact of regular effects that stem from each phone position, followed by the recognition of the appropriate activity. The general architecture is composed of three groups of neural networks organized in the following order. The first group allows the recognition of the source, the second group allows the normalization of data to neutralize the impact of the source on the activity learning process, and the last group allows the recognition of the activity itself. We perform extensive experiments and the preliminary results encourage us to follow this direction, including the source learning to reduce the phone position's biases and activity separately.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {317–322},
numpages = {6},
keywords = {neural architecture search, multi-view learning, SHL challenge, human activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414848,
author = {Kalabakov, Stefan and Stankoski, Simon and Re\v{s}\v{c}i\v{c}, Nina and Kiprijanovska, Ivana and Andova, Andrejaana and Picard, Clement and Janko, Vito and Gjoreski, Martin and Lu\v{s}trek, Mitja},
title = {Tackling the SHL Challenge 2020 with Person-Specific Classifiers and Semi-Supervised Learning},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414848},
doi = {10.1145/3410530.3414848},
abstract = {The SHL recognition challenge 2020 was an open competition in activity recognition where the participants were tasked with recognizing eight different modes of locomotion and transportation with smartphone sensors. The main challenges were that the training data was recorded by a different person than the validation and test data, and that the smartphone location in the test data was unknown to the participants. We, team "Third time's a charm", tackled the first challenge by attempting to identify the persons with clustering, and then performed cluster/person-specific feature selection to build a separate classifier for each person. The smartphone location appears not to make much difference. We also used semi-supervised learning to classify the test data. Internal tests using this methodology yielded an accuracy of 81.01%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {323–328},
numpages = {6},
keywords = {smartphone, competition, semi-supervised learning, machine learning, clustering, activity recognition, feature extraction},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414348,
author = {Naseeb, Chan and Saeedi, Bilal Al},
title = {Activity Recognition for Locomotion and Transportation Dataset Using Deep Learning},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414348},
doi = {10.1145/3410530.3414348},
abstract = {Team "DL_Lock": The Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge 2020 poses a unique opportunity to work on a broad, real-life dataset to classify transport-related activities in a user and location-independent manner. Since deep learning architectures have now received great attention on achieving promising results on time series classification tasks, we focused our experiments on some recent state-of-the-art deep learning architectures such as CNN, Resnet, and InceptionTime. A considerable amount of time was spent on the preprocessing pipeline, which turned out to be a critical phase that impacted most of the results. At the end and after many experiments and hyperparameter tuning, we were able to achieve a 79% F1 score on the validation dataset using InceptionTime architecture. The objective of this paper is to present the technical description of the Machine Learning processing pipeline, the algorithms used, and the results achieved during the development/training phase.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {329–334},
numpages = {6},
keywords = {transportation, time series classification, locomotion, deep learning, activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414346,
author = {Sekiguchi, Ryoichi and Abe, Kenji and Yokoyama, Takumi and Kumano, Masayasu and Kawakatsu, Masaki},
title = {Ensemble Learning for Human Activity Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414346},
doi = {10.1145/3410530.3414346},
abstract = {This paper describes a activity recognition method for Sussex-Huawei Locomotion (SHL) Challenge 2020 by team TDU_BSA. The use of ensemble learning, which combines the outputs of multiple classifiers to produce a single estimation result, improved the accuracy of activity recognition. The ensemble model consists of CNN models and a gradient-boosting model. The objective of SHL Challenge 2020 is that the users of SHL test-set are two different from SHL training-set, and the phone location of SHL test-set is not known to the SHL's participants. Therefore, estimating phone location and the user improved accuracy. SHL test-set's phone location was estimated to be Hips. The user can be estimated from SHL validation-set. The ensemble model was made with all SHL training-set (Only Hips) and 70% of SHL validation-set (Only Hips). In the submission phase, the best F-measure obtained for last 30% SHL validation-set was 84.8%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {335–339},
numpages = {5},
keywords = {phone location estimation, CNN, ensemble learning, time-frequency analysis, user estimation},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414343,
author = {Siraj, Md Sadman and Faisal, Md Ahasan Atick and Shahid, Omar and Abir, Farhan Fuad and Hossain, Tahera and Inoue, Sozo and Ahad, Md Atiqur Rahman},
title = {UPIC: User and Position Independent Classical Approach for Locomotion and Transportation Modes Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414343},
doi = {10.1145/3410530.3414343},
abstract = {The Sussex-Huawei Locomotion-Transportation (SHL) Challenge 2020 was an open competition of recognizing eight different activities that had been performed by three individual users and participants of this competition were tasked to classify these eight different activities with modes of locomotion and transportation. This year's data was recorded with a smartphone which was located in four different body positions. The primary challenge was to make a user-invariant as well as position-invariant classification model. The train set consisted of data from only user-1 with all positions whereas the test set consisted of data from user 2 and 3 with unspeicified sensor position. Moreover, a small validation with the same charecteristics of the test set was given to validate the classifier. In this paper, we have described our (Team Red Circle) approach in which we have used previous year's challenge data as well as this year's provided data to make our training dataset and validation set that have helped us to make our model generative. In our approach, we have extracted various types of features to make our model user independent and position invariant, we have applied Random Forest classifier which is a classical machine learning algorithm and achieved 92.69% accuracy on our customized train set and 77.04% accuracy on our customized validation set.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {340–345},
numpages = {6},
keywords = {classifier, user invariant, SHL recognition challenge, classical approach, feature extraction, position independent, feature selection},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414347,
author = {Tseng, Yi-Ting and Lin, Hsien-Ting and Lin, Yi-Hao and Chen, Jyh-Cheng},
title = {Hierarchical Classification Using ML/DL for Sussex-Huawei Locomotion-Transportation (SHL) Recognition Challenge},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414347},
doi = {10.1145/3410530.3414347},
abstract = {In this paper, our team, SensingGO, presents a hierarchical classifier for Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge. We first separate the original data into motorized activities and non-motorized activities in the first layer of the classifier by using accelerometer data. For the non-motorized activities, we calculate auto-correlation values with accelerometer data as input features. For the motorized activities, we take magnetometer and barometer with mean, maximum, standard deviation values as input features. Finally, we integrate the recognition results of each layer of the classifier, and the average F1-score is 50% to the validation data.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {346–350},
numpages = {5},
keywords = {activity recognition, neural networks, machine learning, datasets},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414341,
author = {Wang, Lin and Gjoreski, Hristijan and Ciliberto, Mathias and Lago, Paula and Murao, Kazuya and Okita, Tsuyoshi and Roggen, Daniel},
title = {Summary of the Sussex-Huawei Locomotion-Transportation Recognition Challenge 2020},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414341},
doi = {10.1145/3410530.3414341},
abstract = {In this paper we summarize the contributions of participants to the third Sussex-Huawei Locomotion-Transportation (SHL) Recognition Challenge organized at the HASCA Workshop of UbiComp/ISWC 2020. The goal of this machine learning/data science challenge is to recognize eight locomotion and transportation activities (Still, Walk, Run, Bike, Bus, Car, Train, Subway) from the inertial sensor data of a smartphone in a user-independent manner with an unknown target phone position. The training data of a "train" user is available from smartphones placed at four body positions (Hand, Torso, Bag and Hips). The testing data originates from "test" users with a smartphone placed at one, but unknown, body position. We introduce the dataset used in the challenge and the protocol of the competition. We present a meta-analysis of the contributions from 15 submissions, their approaches, the software tools used, computational cost and the achieved results. Overall, one submission achieved F1 scores above 80%, three with F1 scores between 70% and 80%, seven between 50% and 70%, and four below 50%, with a latency of maximum of 5 seconds.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {351–358},
numpages = {8},
keywords = {machine learning, activity recognition, mobile sensing, transportation mode recognition, deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414344,
author = {Widhalm, Peter and Merz, Philipp and Coconu, Liviu and Br\"{a}ndle, Norbert},
title = {Tackling the SHL Recognition Challenge with Phone Position Detection and Nearest Neighbour Smoothing},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414344},
doi = {10.1145/3410530.3414344},
abstract = {We present the solution of team MDCA to the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge 2020. The task is to recognize the mode of transportation from 5-second frames of smartphone sensor data from two users, who wore the phone in a constant but unknown position. The training data were collected by a different user with four phones simultaneously worn at four different positions. Only a small labelled dataset from the two "target" users was provided. Our solution consists of three steps: 1) detecting the phone wearing position, 2) selecting training data to create a user and position-specific classification model, and 3) "smoothing" the predictions by identifying groups of similar data frames in the test set, which probably belong to the same class. We demonstrate the effectiveness of the processing pipeline by comparison to baseline models. Using 4-fold cross-validation our approach achieves an average F1 score of 75.3%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {359–363},
numpages = {5},
keywords = {transport mode recognition, signal processing, neural networks, activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414342,
author = {Yaguchi, Kei and Ikarigawa, Kazukiyo and Kawasaki, Ryo and Miyazaki, Wataru and Morikawa, Yuki and Ito, Chihiro and Shuzo, Masaki and Maeda, Eisaku},
title = {Human Activity Recognition Using Multi-Input CNN Model with FFT Spectrograms},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414342},
doi = {10.1145/3410530.3414342},
abstract = {An activity recognition method developed by Team DSML-TDU for the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge was descrived. Since the 2018 challenge, our team has been developing human activity recognition models based on a convolutional neural network (CNN) using Fast Fourier Transform (FFT) spectrograms from mobile sensors. In the 2020 challenge, we developed our model to fit various users equipped with sensors in specific positions. Nine modalities of FFT spectrograms generated from the three axes of the linear accelerometer, gyroscope, and magnetic sensor data were used as input data for our model. First, we created a CNN model to estimate four retention positions (Bag, Hand, Hips, and Torso) from the training data and validation data. The provided test data was expected to from Hips. Next, we created another (pre-trained) CNN model to estimate eight activities from a large amount of user 1 training data (Hips). Then, this model was fine-tuned for different users by using the small amount of validation data for users 2 and 3 (Hips). Finally, an F-measure of 96.7% was obtained as a result of 5-fold-cross validation.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {364–367},
numpages = {4},
keywords = {SHL dataset, FFT spectrogram, CNN, human activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414355,
author = {Zhao, Beidi and Li, Shuai and Gao, Yanbo},
title = {IndRNN Based Long-Term Temporal Recognition in the Spatial and Frequency Domain},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414355},
doi = {10.1145/3410530.3414355},
abstract = {This paper targets the SHL recognition challenge, which focuses on the location-independent and user-independent activity recognition using smartphone sensors. To address this long-range temporal problem with periodic nature, we propose a new approach (team IndRNN), an Independently Recurrent Neural Network (IndRNN) based long-term temporal activity recognition with spatial and frequency domain features. The data is first segmented into one second sliding windows, then temporal and frequency domain features are extracted as short-term temporal features. A deep IndRNN model is used to predict the unknown test dataset location. Under the predicted location, a deep IndRNN model is further used to classify the 8 activities with best performed features. Finally, transfer learning and model fusion are used to improve the result under the user-independence case. The proposed method achieves 86.94% accuracy on the validation set at the predicted location.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {368–372},
numpages = {5},
keywords = {smartphone, IndRNN, SHL dataset, activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414349,
author = {Zhu, Yida and Luo, Haiyong and Chen, Runze and Zhao, Fang and Su, Lin},
title = {DenseNetX and GRU for the Sussex-Huawei Locomotion-Transportation Recognition Challenge},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414349},
doi = {10.1145/3410530.3414349},
abstract = {The Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge organized at the HASCA Workshop of UbiComp 2020 presents a large and realistic dataset with different activities and transportation. The goal of this human activity recognition challenge is to recognize eight modes of locomotion and transportation from 5-second frames of sensor data of a smartphone carried in the unknown position. In this paper, our team (We can fly) summarize our submission to the competition. We proposed a one-dimensional (1D) DenseNetX model, a deep learning method for transportation mode classification. We first convert sensor readings from the phone coordinate system to the navigation coordinate system. Then, we normalized each sensor using different maximums and minimums and construct multi-channel sensor input. Finally, 1D DenseNetX with the Gated Recurrent Unit (GRU) model output the predictions. In the experiment, we utilized four internal datasets for training our model and achieved averaged F1 score of 0.7848 on four valid datasets.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {373–377},
numpages = {5},
keywords = {DenseNet, activity recognition, GRU, transportation mode recognition, smartphone, deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414611,
author = {Alia, Sayeda Shamma and Lago, Paula and Adachi, Kohei and Hossain, Tahera and Goto, Hiroki and Okita, Tsuyoshi and Inoue, Sozo},
title = {Summary of the 2<sup><i>nd</i></sup> Nurse Care Activity Recognition Challenge Using Lab and Field Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414611},
doi = {10.1145/3410530.3414611},
abstract = {2nd Nurse Care Activity Recognition Challenge using Lab and Field Data is organized as a part of HASCA workshop and is continuation of Nurse Care Activity Recognition Challenge [7]. We give the description of the dataset and summarize the approaches used by the teams in this Challenge. In this challenge, data collected in both lab and real-world setting is provided to the challenge participants with an aim to bridge the gap between lab and practical field to reduce the workload of the nurses. The challenge was started on May 1, 2020 and continued until July 9, 2020. Accuracy is used as performance metric to evaluate the submissions. The winning team used k-NN classifier and achieved about 22.35% accuracy.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {378–383},
numpages = {6},
keywords = {summary, nurse care, challenge, activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414338,
author = {Basak, Promit and Tasin, Shahamat Mustavi and Tapotee, Malisha Islam and Sheikh, Md. Mamun and Sakib, A. H. M. Nazmus and Baray, Sriman Bidhan and Ahad, M. A. R.},
title = {Complex Nurse Care Activity Recognition Using Statistical Features},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414338},
doi = {10.1145/3410530.3414338},
abstract = {Human activity recognition has important applications in healthcare, human-computer interactions and other arenas. The direct interaction between the nurse and patient can play a pivotal role in healthcare. Recognizing various activities of nurses can improve healthcare in many ways. However, it is a very daunting task due to the complexities of the activities. "The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data'' provides sensor-based accelerometer data to predict 12 activities conducted by the nurses in both the lab and real-life settings. The main difficulty of this dataset is to process the raw data because of a high imbalance among different classes. Besides, all activities have not been performed by all subjects. Our team, 'Team Apophis' has processed the data by filtering noise, applying windowing technique on time and frequency domain to extract various features from lab and field data distinctly. After merging lab and field data, the 10-fold cross-validation technique has been applied to find out the model of best performance. We have obtained a promising accuracy of 65% with an F1 score of 40% on this challenging dataset by using the Random Forest classifier.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {384–389},
numpages = {6},
keywords = {activity recognition, nurse care, healthcare, random forest, statistical features},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414336,
author = {Dong, Yiwen and Liu, Jingxiao and Gao, Yitao and Sarkar, Sulagna and Hu, Zhizhang and Fagert, Jonathon and Pan, Shijia and Zhang, Pei and Noh, Hae Young and Mirshekari, Mostafa},
title = {A Window-Based Sequence-to-One Approach with Dynamic Voting for Nurse Care Activity Recognition Using Acceleration-Based Wearable Sensor},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414336},
doi = {10.1145/3410530.3414336},
abstract = {This paper introduces a window-based sequence-to-one approach with dynamic voting for nurse care activity recognition using acceleration-based wearable sensors. Nurse care activity recognition is an essential part of ensuring high quality patient care and providing constructive and concrete feedback to the care team. Some of the current sensing approaches for activity recognition include vision-based sensing and non-wearable RF sensing. However, their application is limited in real-life scenarios due to restrictive factors such as perceived privacy and sensitivity to specific occupant paths. To overcome these limitations, acceleration-based wearable sensing have been introduced in recent works. However, the duration distribution of nursing activity instances are biased and skewed. This skewness leads to imbalanced datasets which will result in low performance for the common predictive models. Further, uncertainties such as ambient noise and environmental factors affect the signals and thus can potentially reduce the activity recognition performance. To overcome the first challenge, we separate the signals into short windows with adaptive overlapping ratios for activity instances having different lengths, which balances the label distribution due to event length variations. Further, we use a multi-layer Long Short-Term Memory (LSTM) model to predict nursing activities of each sliding window and introduce a voting-based scheme for complementing the predictions across the signal windows and addressing the uncertainty challenge. We validate our approach through participation in "The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data" as team HealthyVibes. On the challenge dataset our model achieves 97.4% and 43.9% accuracy for training and validation, respectively.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {390–395},
numpages = {6},
keywords = {sequence model, activity recognition, wearable sensors, nurse care},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414337,
author = {Faisal, Md. Ahasan Atick and Siraj, Md. Sadman and Abdullah, Md. Tahmeed and Shahid, Omar and Abir, Farhan Fuad and Ahad, M. A. R.},
title = {A Pragmatic Signal Processing Approach for Nurse Care Activity Recognition Using Classical Machine Learning},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414337},
doi = {10.1145/3410530.3414337},
abstract = {Nursing activity recognition adds a new dimension to the healthcare automation system. But nursing activity recognition is very challenging than identifying simple human activities like walking, cycling, swimming, etc. due to intra-class variability between activities. Besides, the lack of proper dataset does not allow researchers to develop a generalized method for nursing activity or comparing baseline methods on different datasets. Nurse Care Activity Recognition Challenge 2020 provides a dataset of twelve nursing activities. In this paper, we have described our (Team Hex Code) approach where we have emphasized on developing method, which can cope up with real-world data with noise and uncertainty. In our method, we have resampled our data to deal with a variable sample frequency of dataset and we have also applied feature selection method on the extracted feature to have the best combination of feature set for classification. We have used random forest classifier which is a classical machine learning algorithm. Applying our methodology, we have got 78% validation accuracy on the dataset. We have trained our model on the lab dataset and validate them on the field dataset.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {396–401},
numpages = {6},
keywords = {nurse care, activity recognition, accelerometer, smart hospital},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414339,
author = {Irbaz, Mohammad Sabik and Azad, Abir and Sathi, Tanjila Alam and Lota, Lutfun Nahar},
title = {Nurse Care Activity Recognition Based on Machine Learning Techniques Using Accelerometer Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414339},
doi = {10.1145/3410530.3414339},
abstract = {Sensor-based human activity recognition has become one of the challenging and emerging research areas. Several machine learning algorithm with appropriate feature extraction has been used to solve human activity recognition task. However, recent research mainly focused on various deep learning algorithms, our focus of this study is measuring the performance of traditional machine learning algorithms with the incorporation of frequency-domain features. Because deep learning methods require a high computational cost. In this paper, we used Naive Bayes, K-Nearest Neighbour, SVM, Random Forest and Multilayer Perceptron with necessary feature extraction for our experimentation. We achieved best performance for K-Nearest Neighbour. Our experiment was a part of "The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data" followed by the team MoonShot_BD. We concluded that with proper feature extraction, machine learning techniques may be useful to solve activity recognition with a low computational cost.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {402–407},
numpages = {6},
keywords = {KNN, nurse care activity recognition, neural network, machine learning, activity recognition},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414340,
author = {L\"{u}bbe, Carolin and Friedrich, Bj\"{o}rn and Fudickar, Sebastian and Hellmers, Sandra and Hein, Andreas},
title = {Feature Based Random Forest Nurse Care Activity Recognition Using Accelerometer Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414340},
doi = {10.1145/3410530.3414340},
abstract = {The The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data addresses the important issue about care and the need for assistance systems in the nursing profession like automatic documentation systems. Data of 12 different care activities were recorded with an accelerometer attached to the right arm of the nurses. Both, laboratory and field data were taken into account. The task was to classify each activity based on the accelerometer data. We participated as team Gudetama in the challenge. We trained a Random Forest classifier and achieved an accuracy of 61.11% on our internal test set.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {408–413},
numpages = {6},
keywords = {IMU, activity recognition, classification, nurse activity recognition challenge, random forest, supervised learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414333,
author = {Matsuyama, Hitoshi and Yoshida, Takuto and Hayashida, Nozomi and Fukushima, Yuto and Yonezawa, Takuro and Kawaguchi, Nobuo},
title = {Nurse Care Activity Recognition Challenge: A Comparative Verification of Multiple Preprocessing Approaches},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414333},
doi = {10.1145/3410530.3414333},
abstract = {Although activity recognition has been studied considerably for the last two decades, it is still not so easy to handle complicated activity classes in a specific domain. The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data aims to explore a part of those complicated activities by focusing on the nurse caring. Our team, "UCLab", found that the main problem in the challenge is the imbalance and unevenness of the dataset, each of which often happens in real-field data. Considering the problem, we approached the challenge using a Random Forest-based method with multiple preprocessing to classify 12 activity modes. Our approach consists of the following steps: We first preprocessed the acceleration data to obtain uniformly sampled signals. Then we extracted acceleration data with respect to each row of the given label data and extracted feature values. We adopted Random Forest for classification and performed post-processing to the predicted data obtained from the classifier. As a result, we obtained 51.5% accuracy with the trial-based evaluation.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {414–418},
numpages = {5},
keywords = {datasets, activity recognition, nurse care, signal processing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414334,
author = {Rahman, Arafat and Nahid, Nazmun and Hassan, Iqbal and Ahad, M. A. R.},
title = {Nurse Care Activity Recognition: Using Random Forest to Handle Imbalanced Class Problem},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414334},
doi = {10.1145/3410530.3414334},
abstract = {Nurse care activity recognition is a new challenging research field in human activity recognition (HAR) because unlike other activity recognition, it has severe class imbalance problem and intra-class variability depending on both the subject and the receiver. In this paper, we applied the Random Forest-based resampling method to solve the class imbalance problem in the Heiseikai data, nurse care activity dataset. This method consists of resampling, feature selection based on Gini impurity, and model training and validation with Stratified KFold cross-validation. By implementing the Random Forest classifier, we achieved 65.9% average cross-validation accuracy in classifying 12 activities conducted by nurses in both lab and real-life settings. Our team, "Britter Baire" developed this algorithmic pipeline for "The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data".},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {419–424},
numpages = {6},
keywords = {random forest, accelerometer, activity recognition, feature selection, nurse care, stratified KFold cross-validation},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414335,
author = {Rasul, Md. Golam and Khan, Mashrur Hossain and Lota, Lutfun Nahar},
title = {Nurse Care Activity Recognition Based on Convolution Neural Network for Accelerometer Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414335},
doi = {10.1145/3410530.3414335},
abstract = {Human activity recognition on sensor data plays a vital role in health monitoring and elderly care service monitoring. Although tremendous progress has been noticed to the use of sensor technology to collect activity recognition data, recognition still remains challenging due to the pervasive nature of the activities. In this paper, we present a Convolution Neural Network (CNN) model by our team DataDrivers_BD in "The 2nd Nurse Care Activity Recognition Challenge Using Lab and Field Data" which is quite challenging because of the similarity among the tasks. On the other hand, the dissimilarity among the users patterns of working for a particular task. Since CNN can retrieve informative features automatically, it has become one of the most prominent methods in activity recognition. Our extensive experiment on nurse care activity recognition challenge dataset also achieved significant accuracy of 91.59% outperforming the existing state of the art algorithms.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {425–430},
numpages = {6},
keywords = {nurse care activity recognition, activity recognition, convolution neural network, deep learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414616,
author = {van Berkel, Niels and Exler, Anja and Gjoreski, Martin and Kolenik, Tine and Okoshi, Tadashi and Pejovic, Veljko and Visuri, Aku and Voit, Alexandra},
title = {UbiTtention 2020: 5th International Workshop on Smart &amp; Ambient Notification and Attention Management},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414616},
doi = {10.1145/3410530.3414616},
abstract = {Users are increasingly confronted with a tremendous amount of information proactively and without explicit consent through notifications from a variety of applications and services. This information load is increased due to the ubiquity of end-user (mobile) devices. Novel computing paradigms such as IoT and smart cities may further overload end-users, despite the clear indication from literature that human attention is limited. To counter this challenge, "attention management", including attention representation, sensing, prediction, analysis, personalization, and adaptive behavior is needed in our computing systems. Following the successful UbiTtention workshop series as organised from 2016 on-wards, the UbiTtention 2020 workshop brings together researchers and practitioners from academia and industry to explore the management of human attention and notifications across versatile devices and contexts. UbiTtention presents and elicits research to overcome information overload and overchoice - tailoring device or application behavior to user needs.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {431–435},
numpages = {5},
keywords = {interruption management, notifications, smart cities, internet of things, attention management, ambient interfaces},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414429,
author = {Cuculoski, Aleksandar and Pejovi\'{c}, Veljko},
title = {Trading Energy for Accuracy in Mobile Interruptiblity Inference},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414429},
doi = {10.1145/3410530.3414429},
abstract = {Untimely interruptions from our mobile devices may have a significant impact on our work performance, stress and well-being, and in critical situations, such as when driving, can even have fatal consequences. State of the art approaches to inferring interruptiblity of mobile users harness an array of sensors available on our devices. Yet, the energy consumption of these sensors clashes with the need to preserve the most precious of the device's resources - its battery charge. In this work we revisit the sensor-based approach to interruptiblity inference and examine the trade-off between a sensor's energy use and its contribution to interruptiblity modelling. Our findings, based on a two week long field study with 14 users demonstrate that turning on additional sensors indeed improves interruptiblity inference, but at a cost of increased energy consumption. We then propose an interruptiblity management systems that uses the classifier confidence as a knob allowing fine-grain tuning along the trade-off front, thus enabling user- and application- specific energy-optimal interruptiblity management.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {436–443},
numpages = {8},
keywords = {approximate mobile computing, interruptiblity, mobile sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414430,
author = {Fraser, Kieran and Conlan, Owen},
title = {Enticing Notification Text &amp; the Impact on Engagement},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414430},
doi = {10.1145/3410530.3414430},
abstract = {Push-notifications are a design tool used by mobile and web apps to alert subscribers to new information. In recent years, due to widespread adoption of the technology and the shrinking level of user attention available, marketing techniques have been deployed to persuade subscribers to engage positively with notifications. One such technique, known as the curiosity gap, exploits Lowenstein's Information-Gap theory. This paper explores the impact of enticing notification text, instilled by the curiosity gap, on subsequent engagement actions. A classifier was defined to identify enticing language in notifications. Features commonly paired with enticing text were identified. Intelligent notification delivery agents, trained using data captured in-the-wild, were evaluated using enticing and non-enticing notifications to demonstrate the influence of enticing text. Additionally, a solution was proposed and briefly evaluated for limiting subscriber susceptibility to enticing notifications.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {444–449},
numpages = {6},
keywords = {NLP, information-gap, reinforcement learning, push-notifications},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414431,
author = {Gavas, Rahul and S, Mithun B and Chatterjee, Debatri and Ramakrishnan, Ramesh Kumar and Viraraghavan, Venkata Subramanian and Kumar, Achanna Anil and Chandra, M Girish},
title = {Blink Rate Variability: A Marker of Sustained Attention during a Visual Task},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414431},
doi = {10.1145/3410530.3414431},
abstract = {Eye blinks are vital components of human gaze which are used for assessing human behaviour. We have analyzed the variability of the inter-blink durations, termed as blink rate variability (BRV), for analysing sustained attention for visual tasks. Uniformly sampled BRV series is reconstructed from the gaze data recorded using an eye tracker. A number of features are extracted from this series. We proposed a new feature based on pareto principle. Results show that skewness, kurtosis, mean frequency and pareto frequency are good indicators of sustained attention. We observed that with increase in attention level, the power of BRV series tends to have a normal distribution whereas the mean and pareto frequency decreases. Results were generated on a small dataset as a proof of concept of our hypothesis that BRV is a potential bio-marker of sustained attention in a visual task.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {450–455},
numpages = {6},
keywords = {sustained attention, blink rate variability, eye tracking},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414428,
author = {Li, Xiling and De Cock, Martine},
title = {Cognitive Load Detection from Wrist-Band Sensors},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414428},
doi = {10.1145/3410530.3414428},
abstract = {In this work, we use machine learning (ML) to detect the cognitive load of a user based on sensor data from a smart wrist-band, sampled during 30 seconds. The data is provided by a challenge at the UbiTtention 2020 workshop of UbiComp 2020; in this paper we describe UW's participation (team Lynx). The defining characteristic of our approach is in the custom features that we extract from the time series. While we do not have any labeled instances for the test users, the fact that we do have multiple time series for each test user, allows us to extract features that measure how much individual time series deviate from the user's average. We combine this extracted information with other time series' features from the literature. We further use feature selection based on Gini impurity and state-of-the-art techniques for training ML models such as Logistic Regression, (Boosted) Decision Trees, Random Forests, and Support Vector Machines, yielding~63% accuracy by 6-fold cross-validation.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {456–461},
numpages = {6},
keywords = {time series analysis, cognitive load, feature engineering, attention management, machine learning, binary classification},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414433,
author = {Salfinger, Andrea},
title = {Deep Learning for Cognitive Load Monitoring: A Comparative Evaluation},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414433},
doi = {10.1145/3410530.3414433},
abstract = {The Cognitive Load Monitoring Challenge organized in the UbiTtention 2020 workshop tasked the research community with the problem of inferring a user's cognitive load from physiological measurements recorded by a low-cost wearable. This is challenging due to the subjective nature of these physiological characteristics: In contrast to related problems involving objective measurements of physical phenomena (e.g., Activity Recognition from smartphone sensors), subjects' physiological response patterns under cognitive load may be highly individual, i.e., expose significant inter-subject variance. However, models trained on datasets compiled in laboratory settings should also deliver accurate classifications when applied to measurements from novel subjects. In this work, we study the applicability of established Deep Learning models for time series classification on this challenging problem. We examine different kinds of data normalization and investigate a variant of data augmentation.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {462–467},
numpages = {6},
keywords = {time series, cognitive load, deep learning, wearable sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414432,
author = {Shih, Yi-Hao and Chang, Tang-Jie and Chen, Jian-Hua Jiang and Lee, Hao-Ping and Chang, Yung-Ju},
title = {A Preliminary Study of an Intelligent System Facilitating Selective Notification Attendance on Smartphones via Alert Assistance},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414432},
doi = {10.1145/3410530.3414432},
abstract = {A large body of interruptibility research has attempted to minimize disruptions caused by smartphone notifications. Yet, little research has explored ways to enable users to selectively attend to notifications, which can occur as early as users first notice the notification alert and start to speculate about its source. Nevertheless, users' speculation may not be always accurate. We took the first step in helping users make speculations about notifications to facilitate selective attendance. We developed Notiware, an Android app that helps users speculate about notifications by generating alert assistance when it detects that the app of an arriving notification cannot be correctly speculated. An ESM study with 30 users who used Notiware for 4 weeks shows that, overall, Notiware increased the accuracy of participants' speculation of notification app by 28%. Moreover, Notiware helped the participants skipped irrelevant notifications 1.21 times more often than without the assistance.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {468–473},
numpages = {6},
keywords = {receptivity, notification source, intelligent system},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414615,
author = {Mishra, Varun and Sano, Akane and Abdullah, Saeed and Bardram, Jakob E. and Servia, Sandra and Murnane, Elizabeth L. and Choudhury, Tanzeem and Musolesi, Mirco and Vilaza, Giovanna Nunes and Nandakumar, Rajalakshmi and Rahman, Tauhidur},
title = {5<sup><i>th</i></sup> International Workshop on Mental Health and Well-Being: Sensing and Intervention},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414615},
doi = {10.1145/3410530.3414615},
abstract = {Mental health issues affect a significant portion of the world's population and can result in debilitating and life-threatening outcomes. To address this increasingly pressing healthcare challenge, there is a need to research novel approaches for early detection and prevention. Toward this, ubiquitous systems can play a central role in revealing and tracking clinically relevant behaviors, contexts, and symptoms. Further, such systems can passively detect relapse onset and enable the opportune delivery of effective intervention strategies. However, despite their clear potential, the uptake of ubiquitous technologies into clinical mental healthcare is slow, and a number of challenges still face the overall efficacy of such technology-based solutions. The goal of this workshop is to bring together researchers interested in identifying, articulating, and addressing such issues and opportunities. Following the success of this workshop for the last four years, we aim to continue facilitating the UbiComp community in developing a holistic approach for sensing and intervention in the context of mental health.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {474–476},
numpages = {3},
keywords = {predictive modeling, mobile sensing, mental health, mHealth, behavioral intervention},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414371,
author = {Ardelean, Alexandru and Ben\c{t}a, Kuderna-Iulian},
title = {The Affinity Platform: Service-Oriented Architecture Based on Abstraction of Connection},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414371},
doi = {10.1145/3410530.3414371},
abstract = {The Affinity Platform is an innovative Software as a Service orchestration system designed for building Service-Oriented software solutions. It challenges the modularity of regular software frameworks and microservice architectures by abstracting the connectivity layer between two services.The main benefit of utilizing this approach is that components designed to communicate through a specific interface can be easily routed to handle this communication over a different medium. A service could extract health data from a smartwatch, use Bluetooth connectivity to send it to a smartphone for pre-processing, and the result can then be transmitted over HTTP to a server for centralization (Figure 1). All this would be possible without requiring services to agree on a specific communication protocol or data format.The capabilities of the platform were enhanced to assist the development of a multi-modal solution for monitoring patients in a constantly changing environment.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {477–482},
numpages = {6},
keywords = {software platform, automatic programming, dataflow programming, service-oriented architecture, visual development platform, language agnostic},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414372,
author = {Chlebek, Piotr and Shriberg, Elizabeth and Lu, Yang and Rutowski, Tomasz and Harati, Amir and Oliveira, Ricardo},
title = {Comparing Speech Recognition Services for HCI Applications in Behavioral Health},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414372},
doi = {10.1145/3410530.3414372},
abstract = {Behavioral health conditions such as depression and anxiety are a global concern, and there is growing interest in employing speech technology to screen and monitor patients remotely. Language modeling approaches require automatic speech recognition (ASR) and multiple privacy-compliant ASR services are commercially available. We use a corpus of over 60 hours of speech from a behavioral health task, and compare ASR performance for four commercial vendors. We expected similar performance, but found large differences between the top and next-best performer, for both mobile (48% relative WER increase) and laptop (67% relative WER increase) data. Results suggest the importance of benchmarking ASR systems in this domain. Additionally we find that WER is not systematically related to depression itself. Performance is however affected by diverse audio quality from users' personal devices, and possibly from the overall style of speech in this domain.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {483–487},
numpages = {5},
keywords = {digital health, depression, speech recognition, behavioral health, anxiety, word error rate, telehealth, natural language processing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414373,
author = {Kunchay, Sahiti and Abdullah, Saeed},
title = {WatchOver: Using Apple Watches to Assess and Predict Substance Co-Use in Young Adults},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414373},
doi = {10.1145/3410530.3414373},
abstract = {Simultaneous alcohol and marijuana (SAM) use can significantly impact young adults' physical and mental well-being. While SAM use is becoming increasingly prevalent in this population, there has not been much work to monitor and understand related behaviors and contexts. We aim to address this gap by using smartwatches to collect ecological momentary assessments (EMAs) and sensor data. In this paper, we describe the design and development of the smartwatch framework focusing on SAM use. We also collected pilot data from an n=1 deployment over 7 days using the framework. Our findings indicate that EMAs on smartwatches can be completed with lower perceived burden, which is important for longitudinal SAM use data collection. We also provide design guidelines and rationale for future work aiming to use smartwatches.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {488–493},
numpages = {6},
keywords = {mental health, substance use, smartwatches},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414374,
author = {Quiroz, Juan C. and Bongolan, Tristan and Ijaz, Kiran},
title = {Alexa Depression and Anxiety Self-Tests: A Preliminary Analysis of User Experience and Trust},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414374},
doi = {10.1145/3410530.3414374},
abstract = {Mental health resources available via websites and mobile apps provide support such as advice, journaling, and elements from cognitive behavioral therapy. The proliferation of spoken conversational agents, such as Alexa, Siri, and Google Home, has led to an increasing interest in developing mental health apps for these devices. We present the pilot study outcomes of an Alexa Skill that allows users to conduct depression and anxiety self-tests. Ten participants were given access to the Alexa Skill for two-weeks, followed by an online evaluation of the Skill's usability and trust. Our preliminary evaluation suggests that participants trusted the Skill and scored the usability and user experience as average. Usage of the Skill was low, with most participants using the Skill only once. In view of work-in-progress, we also present a discussion of implementation and study design challenges to guide the current literature on designing spoken conversational agents for mental health applications.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {494–496},
numpages = {3},
keywords = {depression, conversational agent, anxiety, alexa, mental health},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414375,
author = {Woodward, Kieran and Kanjo, Eiman and Brown, David J and Inkster, Becky},
title = {TangToys: Smart Toys to Communicate and Improve Children's Wellbeing},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414375},
doi = {10.1145/3410530.3414375},
abstract = {Children can find it challenging to communicate their emotions especially when experiencing mental health challenges. Technological solutions may help children communicate digitally and receive support from one another as advances in networking and sensors enable the real-time transmission of physical interactions. In this work, we pursue the design of multiple tangible user interfaces designed for children containing multiple sensors and feedback actuators. Bluetooth is used to provide communication between Tangible Toys (TangToys) enabling peer to peer support groups to be developed and allowing feedback to be issued whenever other children are nearby. TangToys can provide a non-intrusive means for children to communicate their wellbeing through play.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {497–449},
keywords = {communication, tangible user interfaces, emotion, mental well-being, children, sensors},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414617,
author = {Chen, Xinlei and Pan, Shijia and Amini, M. Hadi},
title = {CPD 2020: The 3rd International Workshop on Combining Physical and Data-Driven Knowledge in Ubiquitous Computing},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414617},
doi = {10.1145/3410530.3414617},
abstract = {In the real-world ubiquitous computing systems, it is difficult to require a significant amount of data to obtain accurate information through pure data-driven methods. The performance of data-driven methods relies on the quantity and 'quality' of data. They perform well when a sufficient amount of data is available, which is regarded as ideal conditions. However, in real-world systems, collecting data can be costly or impossible due to practical limitations. On the other hand, it is promising to utilize physical knowledge to alleviate these issues of data limitation. The physical knowledge includes domain knowledge from experts, heuristics from experiences, analytic models of the physical phenomena and etc.The goal of the workshop is to explore the intersection between (and the combination of) data and physical knowledge. The workshop aims to bring together domain experts that explore the physical understanding of the data, practitioners that develop systems and the researchers in traditional data-driven domains. The workshop welcomes papers, which focuses on addressing these issues in different applications/domains as well as algorithmic and systematic approaches to applying physical knowledge. Therefore, we further seek to develop a community that systematically analyzes the data quality regarding inference and evaluates the improvements from physical knowledge. Preliminary and on-going work is welcomed.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {500–502},
numpages = {3},
keywords = {physical knowledge, data-driven, cyber-physical system, ubiquitous computing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414599,
author = {Chandel, Vivek and Banerjee, Snehasis and Ghose, Avik},
title = {ProxiTrak: A Robust Solution to Enforce Real-Time Social Distancing &amp; Contact Tracing in Enterprise Scenario},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414599},
doi = {10.1145/3410530.3414599},
abstract = {In the wake of recent COVID-19 pandemic, contact tracing has turned out to be an indispensable technique to help administrative authorities contain localized infections efficiently. In the absence of a definitive and an official vaccine for the infection, practicing social distancing has proved to be an effective norm to prevent the risk of infection. In this paper, we present 'ProxiTrak', a smartphone based solution for an enterprise scenario capable of not only tracing the chain of possible infection transmission among a set of population, but also guiding the users towards following social distancing norms by alerting them in real-time about any possible violation of proximity norms on their smartphones. We devise an effective classification model to make proximity decisions on the smartphone itself using Received Signal Strength Indicator (RSSI) data of on-board Bluetooth Low Energy (BLE) module using multiple mobile devices in different environments, with novel addition of using temporal features from BLE data to boost the model's accuracy. We briefly discuss ProxiTrak's corresponding server-side framework for tracing a possible chain of infection and analysing social connectivities graphically. We also propose on-device decision aggregation and server-side pruning of proximity events to lower the false positive events. Our model is capable of making strong proximity decisions to an accuracy of up to 94% on the devices trained with the model.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {503–511},
numpages = {9},
keywords = {data model, COVID-19, contact tracing, smartphone, BLE, social distancing, machine learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414597,
author = {Das, Anooshmita and Kolvig-Raun, Emil Stubbe and Sangogboye, Fisayo Caleb and Kj\ae{}rgaard, Mikkel Baun},
title = {Occu-Track: Occupant Presence Sensing and Trajectory Detection Using Non-Intrusive Sensors in Buildings},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414597},
doi = {10.1145/3410530.3414597},
abstract = {Sensing occupant presence and their trajectories of movement in buildings enable new types of analysis and building operation strategies. However, obtaining such information in a cost-efficient and non-intrusive manner is a challenge. This paper proposes the Occu-track method for how inexpensive battery-powered sensors can be used at scale to estimate occupant presence and movement trajectories. The technique combines graph analysis and advanced clustering to produce accurate estimates. This paper validates the efficiency of Occu-track in two different settings; a music room and a private office. The experimental results from two room-level deployments demonstrate the benefits of the approach obtaining an average Root Mean Squared Error of 1.19 meters for case 1 and 0.88 meters for case 2 for trajectory estimation. The results can contribute to new dimensions of research associated with the generation of metadata from non-intrusive sensors to make informed decisions about efficient space utilization and floor plans, intelligent building operations, crowd management, comfortable indoor environment, or managing personnel.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {512–524},
numpages = {13},
keywords = {building performance, trajectory detection, occupant presence, sensors, occupant behavior},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414610,
author = {Dong, Yiwen and Zou, Joanna Jiaqi and Liu, Jingxiao and Fagert, Jonathon and Mirshekari, Mostafa and Lowes, Linda and Iammarino, Megan and Zhang, Pei and Noh, Hae Young},
title = {MD-Vibe: Physics-Informed Analysis of Patient-Induced Structural Vibration Data for Monitoring Gait Health in Individuals with Muscular Dystrophy},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414610},
doi = {10.1145/3410530.3414610},
abstract = {We introduce a footstep-induced floor vibration sensing system that enables us to quantify the gait pattern of individuals with Muscular Dystrophy (MD) in non-clinical settings. MD is a neuromuscular disorder causing progressive loss of muscle, which leads to symptoms in gait patterns such as toe-walking, frequent falls, balance difficulty, etc. Existing systems that are used for progressive tracking include pressure mats, wearable devices, or direct observation by healthcare professionals. However, they are limited by operational requirements including dense deployment, users' device carrying, special training, etc. To overcome these limitations, we introduce a new approach that senses floor vibrations induced by human footsteps. Gait symptoms in these footsteps are reflected by the vibration signals, which enables monitoring of gait health for individuals with MD. Our approach is non-intrusive, unrestricted by line-of-sight, and thus suitable for in-home deployment. To develop our approach, we characterize the gait pattern of individuals with MD using vibration signals, and infer the health state of the patients based on both symptom-based and signal-based features. However, there are two main challenges: 1) different aspects of human gaits are mixed up in footstep-induced floor vibrations; and 2) structural heterogeneity distorts vibration propagation and attenuation through the floor medium. To overcome the first challenge, we characterize the symptom-based gait features of the footstep-induced floor vibration specific to MD. To minimize the performance inconsistency across different sensing locations in the building, we reduce the structural effects by removing the free-vibration phase due to structural damping. With these two challenges addressed, we evaluate our system performance by conducting a real-world experiment with six patients with MD and seven healthy participants. Our approach achieved 96% accuracy in predicting whether the footstep was from a patient with MD.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {525–531},
numpages = {7},
keywords = {muscular dystrophy, gait health monitoring, structural vibration, floor vibration sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414586,
author = {He, Lixing and Ruiz, Carlos and Mirshekari, Mostafa and Pan, Shijia},
title = {SCSV<sup>2</sup>: Physics-Informed Self-Configuration Sensing through Vision and Vibration Context Modeling},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414586},
doi = {10.1145/3410530.3414586},
abstract = {Structural vibration sensing has been explored to acquire indoor human information. This non-intrusive sensing modality enables various smart building applications such as long-term in-home elderly monitoring, ubiquitous gait analysis, etc. However, for applications that utilize multiple sensors to collaboratively infer this information (e.g., localization, activities of daily living recognition), the system configuration requires the location of the anchor sensor, which are usually acquired manually. This labor-intensive manual system configuration limited the scalability of the system.In this paper, we propose SCSV2, a self-configuration scheme to compute these vibration sensor locations utilizing shared context information acquired from complementary sensing modalities - vibration sensor itself and co-located cameras. SCSV2 combines 1) the physics models of wave propagation together with structural element effects and 2) the data-driven model from the multimodal data to infer the vibration sensor's location. We conducted real-world experiments to verify our proposed method and achieved an up to 7cm anchor sensor localization accuracy.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {532–537},
numpages = {6},
keywords = {structural vibration, physics-informed, computer vision, sensor localization estimation, system self-configuration, heterogeneous sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414594,
author = {Jens, Krister and Das, Anooshmita and Kj\ae{}rgaard, Mikkel Baun},
title = {Detecting Group Sizes and Human-Centered Interaction Using 3D Stereo Vision Cameras},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414594},
doi = {10.1145/3410530.3414594},
abstract = {Extracting valuable information from sensor data concerning group sizes and human-centered interactions will play a crucial role in balancing building functions according to user needs and preferences. Based on a newly constructed university building in Cincinnati, Ohio, USA, this paper combines data-driven methods and contextual knowledge about spatial design features using 3D stereo vision cameras to implement the detection algorithms on three different real-world case settings. By using human-proximity distances and the dynamic change in the position of an occupant over time (x- and y- coordinates) in an indoor crowded environment, this research successfully applies annotated data to detect and classify group sizes and human interaction using Machine Learning (ML) techniques. Ground-truth labels were collected manually to validate the performances, which was tedious and manually expensive. We have applied popular ML algorithms for detecting the group sizes and classifying the human interactions, with average F1-scores ranging from 79 to 87% for single, paired and group occupancy. A significant challenge is the dependency on prior knowledge about physical conditions in order to detect occupant seating and orientation in crowded environments. Here, additional features such as directions and space layouts would help mitigating this issue. The results however can contribute to new dimensions of research associated with the automatic generation of metadata from data-driven systems to make informed decisions about space design, space-use relationships and management.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {538–546},
numpages = {9},
keywords = {machine learning, stereo vision camera, activity recognition, knowledge discovery},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414596,
author = {Khakifirooz, Marzieh and Fathi, Mahdi},
title = {How Particle Detector Can Aid Visual Inspection for Defect Detection of TFT-LCD Manufacturing},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414596},
doi = {10.1145/3410530.3414596},
abstract = {Traditional defect classification of TFT-LCD array processing leaned on human decision-maker in which visual inspection used to categorize defects and consequently identify the rout-causes of defects. In practice, the main sources of defects in the TFT-LCD array process are particles. Due to the huge size of the machinery and production tools in the TFT-LCD array process, the sensor allocation for particle detection plays a critical role in the inadequacy and quality of sensor data. Therefore, where the adequacy and efficiency of human performance depend on human factors, emotion, and level of attention, this study aims to design a semi-automatic defect detection and classification method based on information capture by particle detector sensors to reduce the cognitive load devaluation and proceed with the process of defect classification.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {547–552},
numpages = {6},
keywords = {visual defect classification, TFT-LCD array process, sensor allocation, particle detector},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414592,
author = {Liu, Tianyu and Kou, Li and Yang, Le and Fan, Wenhui and Wu, Cheng},
title = {A Physical Knowledge-Based Extreme Learning Machine Approach to Fault Diagnosis of Rolling Element Bearing from Small Datasets},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414592},
doi = {10.1145/3410530.3414592},
abstract = {The learning-based methods have been widely applied to design a fault diagnosis model for rolling element bearing. However, the mainstream methods can only deal with the large training dataset, which is always violated in practical application. In this paper, we propose a physical knowledge-based hierarchical extreme learning machine(H-ELM) approach to adapt the problem of fault diagnosis for bearing with the small and imbalanced dataset. First, the proposed method uses the simple feature extraction algorithm to build a knowledge base for sample selection from the historical database, and the given training dataset is augmented with knowledge base. Second, a modified H-ELM algorithm is developed to identify fault location and recognize fault severity ranking based on the augmented dataset. Third, we design a self-optimizing module to optimize the sample selection and improve the performance of the H-ELM network. To evaluate the effectiveness of the proposed approach, the H-ELM without knowledge base and data augmentation-based support vector machine(SVM), back propagation neuron networks(BPNN) and deep belief networks(DBN) are tested in the numerical experiments to present a comprehensive comparison. The experimental results demonstrate that our approach outperforms in accuracy than other counterparts when dealing with the small and imbalanced datasets.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {553–559},
numpages = {7},
keywords = {fault diagnosis, extreme learning machine, rolling element bearing, self-optimizing framework},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414593,
author = {Ma, Ge and Huang, Qiyang and Gu, Weixi},
title = {Collaborative Edge-Network Content Replication: A Joint User Preference and Mobility Approach},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414593},
doi = {10.1145/3410530.3414593},
abstract = {Today's mobile video users have unsatisfactory quality of experience mainly due to the large network distance to the centralized infrastructure. To improve users' quality of experience, content providers are pushing content distribution capacity to the edge-networks. However, existing content replication approaches cannot provide sufficient quality of experience for mobile video delivery. Because they fail to consider the knowledge of user-behavior such as user preference and mobility, which can capture the dynamically changing content popularity. To address the problem, we propose a user-behavior driven collaborative edge-network content replication solution in which user preference and mobility are jointly considered. More specifically, using user-bahavior driven measurement studies of videos and trajectories, we first reveal that both users' intrinsic preferences and mobility patterns play a significant role in edge-network content delivery. Second, based on the measurement insights, it is proposed that a joint user preference- and mobility-based collaborative edge-network content replication solution, namely APRank. It is comprised of preference-based demand prediction to predict the requests of video content, mobility-based collaboration to predict the movement of users across edge access points (APs), and workload-based collaboration to enables collaborative replication across adjacent APs. APRank is able to predict the fine-grained content popularity distribution of each AP, handle the trajectory data sparseness problem, and make dynamic and collaborative content replication for edge APs. Finally, through extensive trace-driven experiments, we demonstrate the effectiveness of our design: APRank achieves 20% less content access latency and 32% less workload against traditional approaches.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {560–567},
numpages = {8},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414598,
author = {Mohammadi, Farid Ghareh and Shenavarmasouleh, Farzan and Amini, M. Hadi and Arabnia, Hamid R.},
title = {Malware Detection Using Artificial Bee Colony Algorithm},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414598},
doi = {10.1145/3410530.3414598},
abstract = {Malware detection has become a challenging task due to the increase in the number of malware families. Universal malware detection algorithms that can detect all the malware families are needed to make the whole process feasible. However, the more universal an algorithm is, the higher number of feature dimensions it needs to work with, and that inevitably causes the emerging problem of Curse of Dimensionality (CoD). Besides, it is also difficult to make this solution work due to the real-time behavior of malware analysis. In this paper, we address this problem and aim to propose a feature selection based malware detection algorithm using an evolutionary algorithm that is referred to as Artificial Bee Colony (ABC). The proposed algorithm enables researchers to decrease the feature dimension and as a result, boost the process of malware detection. The experimental results reveal that the proposed method outperforms the state-of-the-art.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {568–572},
numpages = {5},
keywords = {machine learning, feature selection, artificial bee colony, evolutionary algorithms, malware detection, supervised learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414591,
author = {von Frankenberg, Nadine and Ruoff, Patrick and Bruegge, Bernd and Loftness, Vivian},
title = {LATEST: A Learning-Based Automated Thermal Environment Control System},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414591},
doi = {10.1145/3410530.3414591},
abstract = {Thermal comfort has a significant influence on a building occupant's overall well-being, productivity, and satisfaction. Due to its subjectivity, thermal comfort cannot be achieved with common building control strategies, such as defining temperature set-points or averaging across all occupants. Personal control models allow occupants to influence their task environments based on their own preferences and the use of machine learning methods. In this paper, we present LATEST, a system that collects thermal comfort-related data, preprocesses it, and generates a personal temperature control model that controls occupant-specific thermal actuators. We conducted an empirical field study with three human subjects operating task heaters over a period of six weeks to collect data and generate personal thermal control models. These thermal control models were then used to compare the performance of the models with the manual actuation of the task heaters. The evaluation showed that LATEST can reduce occupant command frequency by 79%, while increasing thermal comfort by 9%, compared with manual control. We make the data set and source code available to the public.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {573–579},
numpages = {7},
keywords = {building control, personalized control, data set, thermal comfort modeling},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414590,
author = {Wu, Zhengwei and Zhang, Xiaoxi and Xu, Susu and Chen, Xinlei and Zhang, Pei and Noh, Hae Young and Joe-Wong, Carlee},
title = {A Generative Simulation Platform for Multi-Agent Systems with Incentives},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414590},
doi = {10.1145/3410530.3414590},
abstract = {Multi-agent systems have attracted much attention in the recent years due to their capabilities to handle complex and computation-heavy tasks and compatibility with incentive schemes. Considering the difficulty of creating an actual prototype and environment for evaluation, a simulation platform is a cheap and efficient way in analyzing and testing, prior to real environmental implementations. Existing simulators for multi-agent systems are inadequate to analyze the effects of different customized incentive schemes on agents' behavior patterns due to two reasons: 1) They lack the functionality to support various types of complex incentives, e.g., mixture of monetary incentives and non-monetary incentives, which influences agents' behaviors explicitly and implicitly; 2) They are not able to emulate heterogeneous agents' realtime behaviors that are influenced by complex incentives and deviate from their original behavior patterns shown in historical traces. In this paper, we focus on mobile agents that can move in a patio-temporal space, and we present a physical knowledge aided multi-agent simulation platform considering the influence of both direct and indirect incentives unified through a general utility-driven agent reaction function. The behaviors of agents are then emulated in three behavioral models: myopic, semi-myopic, and farsighted, by varying the assumption of agents in maximizing their utilities and integrating the physical knowledge and historical mobility patterns. We finally examine the effectiveness of the platform in incentivizing vehicle agents to optimize the final distribution of the agents through a ride-sharing vehicle experimental scenario. The emulated agents' behaviors can also be collected into data traces for analyzing other patterns of the agents.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {580–587},
numpages = {8},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414587,
author = {Zhao, Pengfei and Gu, Chenghong and Cao, Zhidong and Xiang, Yue and Yan, Xiaohe and Huo, Da},
title = {A Two-Stage Data-Driven Multi-Energy Management Considering Demand Response},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414587},
doi = {10.1145/3410530.3414587},
abstract = {This paper proposes an innovative two-stage data-driven optimization framework for a multi-energy system. Enormous energy conversion technologies are incorporated in the system to enhance the overall energy utilization efficiency, i.e., combined heat and power, power-to-gas, gas furnace, and ground source heat pump. Furthermore, a demand response program is adopted for stimulating the load shift of customers. Accordingly, both the economic performance and system reliability can be improved. The endogenous solar generation brings about high uncertainty and variability, which affects the decision making of the system operator. Therefore, a two-stage data-driven distributionally robust optimization (TSDRO) method is utilized to capture the uncertainty. A tractable semidefinite programming reformulation is obtained based on the duality theory. Case studies are implemented to demonstrate the effectiveness of applying the TSDRO on energy management.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {588–595},
numpages = {8},
keywords = {energy hub systems, demand response, multi-energy systems},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414588,
author = {Zhu, Xin and Wang, Shuai and Guo, Baoshen and Ling, Taiwei and Zhou, Ziyi and Tu, Lai and He, Tian},
title = {SParking: A Win-Win Data-Driven Contract Parking Sharing System},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414588},
doi = {10.1145/3410530.3414588},
abstract = {With a rapid growth of vehicles in modern cities, searching for a parking space becomes difficult for drivers especially in rush hours. To alleviate parking difficulties and make the most of urban parking resources, contract parking sharing services allow drivers to pay for parking under the consent of owners, reaching a win-win situation. Contract parking sharing services, however, have not yet been prevailingly adopted due to the dynamic parking time which leads to uncertainties for sharing. Thanks to the Internet of things technique, most of modern parking lots record vehicles' fine-grained parking data including entry and exit timestamps for billing purposes. Leveraging the parking data, we analyze and exploit available vacant contract parking spaces. We propose SParking, a <u>s</u>hared contract <u>parking</u> system with a win-win data-driven scheduling. SParking consists of (i) a parking time prediction model to exploit reliable periods of free parking spaces and (ii) an optimal scheduling model to allocate free parking spaces to drivers. To verify the effectiveness of SParking, we evaluate our design on seven-month real-world parking data involved with 368 parking lots and 14,704 parking spaces in Wuhan, China. The experimental results show that SParking achieves more than 90% of accuracy in parking time prediction and the average utilization rate of contract parking spaces is improved by 35%.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {596–604},
numpages = {9},
keywords = {usage prediction, parking sharing, online scheduling},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414595,
author = {Zhu, Guowei and Lv, Kan and Ma, Ge and Gu, Weixi},
title = {Relay Strategy in Online Mobile Games: A Data-Driven Approach},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414595},
doi = {10.1145/3410530.3414595},
abstract = {With the booming of online mobile games (OMGs), game operators need to provide high-quality game service for users. Using relay has become the de factor approach for game streaming today, because it is easy to use (e.g., game sessions can be redirected via CDN servers) and has good scalability. Today, it has become the norm rather than the exception for game operators to hire CDN servers for their game services in a pay-per-use manner to serve massive users. Given the limited resource, selecting game sessions which are relayed has become a critical decision that can significantly affect users' quality of experience (QoE). Conventional strategies are generally rule-based, e.g., assigning game sessions to relay paths according to their past network performance, but cannot guarantee any particular QoE level because network performance dynamically changes. In this paper, we propose using data-driven approach to study network performance of game sessions in temporal and spatial patterns. Our findings indicate that there is obvious regularity for network performance of game sessions in temporal and spatial patterns. We design a machine learning-based predictive model to capture the quality of a game session given particular network performance metrics. Based on that, we strategically assign game sessions to relay paths to maximize the overall QoE. Trace-driven experiments are used to demonstrate the effectiveness and efficiency of our design.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {605–615},
numpages = {11},
keywords = {online mobile games, relay network, network measurement, quality of experience},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414613,
author = {Xu, Susu and Pan, Shijia and Yu, Tong},
title = {CML-IOT 2020: The Second Workshop on Continual and Multimodal Learning for Internet of Things},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414613},
doi = {10.1145/3410530.3414613},
abstract = {With the deployment of Internet of Things (IoT), large amount of sensors are connected into the Internet, providing large-amount, streaming, and multimodal data. These data have distinct statistical characteristics over time and sensing modalities, which are hardly captured by traditional learning methods. Continual and multimodal learning allows integration, adaptation, and generalization of the knowledge learned from experiential data collected with heterogeneity to new situations. Therefore, continual and multimodal learning is an important step to enable efficient ubiquitous computing on IoT devices. The major challenges to combine continual learning and multimodal learning with real-world data include 1) how to fuse and transfer knowledge between the multimodal data under constrained computational resources, 2) how to learn continually despite the missing, imbalanced or noisy data under constrained computational resources, 3) how to effectively reserve privacy and retain security when learning knowledge from streaming and multimodal data collected by multiple stakeholders, and 4) how to develop large-scale distributed learning systems to efficiently learn from continual and multimodal data.We organize this workshop to bring people working on different disciplines together to tackle these challenges in this topic. This workshop aims to explore the intersection and combination of continual machine learning and multimodal modeling with applications in the Internet of Things. The workshop welcomes works addressing these issues in different applications/domains as well as algorithmic and systematic approaches to leverage continual learning on multimodal data. We further seek to develop a community that systematically handles the streaming multimodal data widely available in real-world ubiquitous computing systems. In 2019, we held the First Workshop on Continual and Multimodal Learning for Internet of Things (https://cmliot2019.github.io/) with Ubicomp 2019, London, UK. The First workshop accepted 12 papers from 17 submissions. The one-day agenda included 3 sessions and attracted around 20 attendees from academia and industries to discuss and share visions.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {616–618},
numpages = {3},
keywords = {multimodal learning, ubiquitous computing, internet of things, continual learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414319,
author = {Das, Anooshmita and Kolvig-Raun, Emil Stubbe and Kj\ae{}rgaard, Mikkel Baun},
title = {Accurate Trajectory Prediction in a Smart Building Using Recurrent Neural Networks},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414319},
doi = {10.1145/3410530.3414319},
abstract = {Occupant behavioral patterns, once extracted, could reveal cues about activities and space usage that could effectively get used for building systems to achieve energy savings. The ability to accurately predict the trajectories of occupants inside a room branched into different zones has many notable and compelling applications. For example - efficient space utilization and floor plans, intelligent building operations, crowd management, comfortable indoor environment, security, and evacuation or managing personnel. This paper proposes future occupant trajectory prediction using state-of-the-art time series prediction methods, i.e., Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) models. These models are being implemented and compared to forecast occupant trajectories at a given time and location in a non-intrusive and reliable manner. The considered test-space for the collection of the dataset is a multi-utility area in an instrumented public building. The deployed 3D Stereo Vision Cameras capture the spatial location coordinates (x- and y- coordinates) from a bird's view angle without eliciting any other information that could reveal confidential data or uniquely identify a person. Our results showed that the GRU model forecasts were considerably more accurate than the LSTM model for the trajectory prediction. GRU prediction model achieved a Mean Squared Error (MSE) of 30.72 cm between actual and predicted location coordinates, and LSTM achieved an MSE of 47.13 cm, respectively, for multiple occupant trajectories within the monitored area. Another evaluation metric Mean Absolute Error (MAE) is used, and the GRU prediction model achieved an MAE of 3.14 cm, and the LSTM model achieved an MAE of 4.07 cm. The GRU model guarantees a high-fidelity occupant trajectory prediction for any given case with higher accuracy when compared to the baseline LSTM model.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {619–628},
numpages = {10},
keywords = {deep learning, GRU, prediction models, LSTM, occupant behavior, pattern recognition, trajectory prediction, knowledge discovery},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414318,
author = {Das, Anooshmita and Jens, Krister and Kj\ae{}rgaard, Mikkel Baun},
title = {Space Utilization and Activity Recognition Using 3D Stereo Vision Camera inside an Educational Building},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414318},
doi = {10.1145/3410530.3414318},
abstract = {Accurate occupancy information is imperative for the optimization of built-in environments to achieve energy savings and user comfort. Comprehending the occupancy information provides an opportunity to interpret movement patterns, circulation-flow, space usage patterns inside the building. In this paper, we designed a case study that includes experimental testbeds from the HL Linder Hall Cafeteria; a public shared space at the University of Cincinnati College of Business, United States. Based on the time-series data collected from 3D Stereo Vision Camera, an algorithm is proposed for the removal of redundant occupant IDs to overcome inconsistencies in the Field of View (FoV) of the camera and ensure accurate estimates and consistent data. Another algorithm for data annotation in activity recognition is proposed for the binary class classification of activity with sitting and moving labels. The data obtained can be used for inspecting various types of open and shared spaces available for work and quotidian interactions among occupants. The seats and space utilization patterns extracted from the camera within the monitored area are validated using a digitally advanced tool, known as ArcGIS Pro. For the experiment, prior permission was granted by the Building Management System (BMS) authorities, and occupants' confidentiality is preserved. The space usage patterns extracted can grant access to the new dimension of investigation associated with the space selection and occupant behavior inside the buildings. This paper also discusses the challenges faced during the design phase for the deployment, and it summarizes the potential improvements in the field of occupancy sensing for energy-efficient buildings.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {629–637},
numpages = {9},
keywords = {activity recognition, knowledge discovery, machine learning, occupant behavior, space utilization, ArcGIS pro, stereo vision camera},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414321,
author = {Ek, Sannara and Portet, Fran\c{c}ois and Lalanda, Philippe and Vega, German},
title = {Evaluation of Federated Learning Aggregation Algorithms: Application to Human Activity Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414321},
doi = {10.1145/3410530.3414321},
abstract = {Pervasive computing promotes the integration of connected electronic devices in our living spaces in order to assist us through appropriate services. Two major developments have gained significant momentum recently: a better use of fog resources and the use of AI techniques. Specifically, interest in machine learning approaches for engineering applications has increased rapidly.  This paradigm seems to fit the pervasive environment well. However, federated learning has been applied so far to specific services and remains largely conceptual. It needs to be tested extensively on pervasive services partially located in the fog. In this paper, we present experiments performed in the domain of Human Activity Recognition on smartphones in order to evaluate existing algorithms.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {638–643},
numpages = {6},
keywords = {federated learning, human activity recognition, edge computing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414320,
author = {Hu, Zhizhang and Yu, Tong and Zhang, Yue and Pan, Shijia},
title = {Fine-Grained Activities Recognition with Coarse-Grained Labeled Multi-Modal Data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414320},
doi = {10.1145/3410530.3414320},
abstract = {Fine-grained human activities recognition focuses on recognizing event- or action-level activities, which enables a new set of Internet-of-Things (IoT) applications such as behavior analysis. Prior work on fine-grained human activities recognition relies on supervised sensing, which makes the fine-grained labeling labor-intensive and difficult to scale up. On the other hand, it is much more practical to collect coarse-grained label at the level of activity of daily living (e.g., cooking, working), especially for real-world IoT systems. In this paper, we present a framework that learns fine-grained human activities recognition with coarse-grained labeled and a small amount of fine-grained labeled multi-modal data. Our system leverages the implicit physical knowledge on the hierarchy of the coarse- and fine-grained labels and conducts data-driven hierarchical learning that take into account the coarse-grained supervised prediction for fine-grained semi-supervised learning. We evaluated our framework and CFR-TSVM algorithm on the data gathered from real-world experiments. Results show that our CFR-TSVM achieved an 81% recognition accuracy over 10 fine-grained activities, which reduces the prediction error of the semi-supervised learning baseline TSVM by half.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {644–649},
numpages = {6},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414322,
author = {Li, Guodong and Ma, Rui and Liu, Xinyu and Wang, Yue and Zhang, Lin},
title = {RCH: Robust Calibration Based on Historical Data for Low-Cost Air Quality Sensor Deployments},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414322},
doi = {10.1145/3410530.3414322},
abstract = {Air pollution has become one of the major threats to human health. Conventional approaches for air pollution monitoring use precise professional devices, but cannot achieve dense deployment due to high cost. Therefore, systems consisting of low-cost sensors are applied as a supplement to obtain fine-grained pollution information. In order to maintain the accuracy of these low-cost sensors, it is essential to calibrate them to minimize the impact from sensor drifts. Existing field calibration methods utilize the real-time data from spatially-adjacent official air quality stations as reference. However, the real-time reference is not always accessible under existing station deployment. In this paper, we propose the Robust Calibration approach using Historical data (RCH) for low-cost air quality sensors. Our method corrects the sensor drift by adapting sensitivity and offset based on pollutant's concentration distribution. Experiments on NO2 data from real-world deployment in Foshan, China show that RCH has the similar performance compared with existing field calibration methods using real-time and spatially-adjacent references. It demonstrates that RCH can improve the accuracy and consistency of low-cost air quality sensors without the help of real-time and nearby reference data.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {650–656},
numpages = {7},
keywords = {air quality sensors, low-cost sensors, air pollution, robust calibration},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414316,
author = {Scheuermann, Constantin and Binderberger, Thomas and von Frankenberg, Nadine and Werner, Andreas},
title = {Digital Twin: A Machine Learning Approach to Predict Individual Stress Levels in Extreme Environments},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414316},
doi = {10.1145/3410530.3414316},
abstract = {Remote Health Monitoring (RHM) has the potential to increase operational safety in extreme environments. Negative stress exposure influences mission success or the short- and long-term health conditions of deployed personnel. To quantify negative stress, we introduce a washable smart textile with integrated sensors. Analyzing the transmitted sensor values, medical advisors monitor up to 72 sensor values in parallel in case of an average group size of eight people. In order to aggregate the amount of data, we propose a stress level scale that includes stress trends. To predict individual stress levels based on sensor data, environmental quantities and the individual physiological fingerprint, we train different machine learning models. To evaluate such models, we implement a data acquisition environment to label data snapshots. Therefore, we do not need to collect in-field data and expose humans to negative stress. Moreover, we can mock sensor failures and rare, but relevant, sensor value combinations that are difficult to acquire in real-world scenarios. Our evaluation environment identifies Random Forest Regressor from a set of 25 models to perform best to predict individual stress levels. This model performs 23.19 times better than a zero rule classifier to distinguish among nine stress levels for mission goal health condition and 10.50 times better for mission goal mission success. Finally, we present our current RHM user interface design. It addresses issues such as information overload, avatar sympathy and unnecessary navigation paths.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {657–664},
numpages = {8},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414317,
author = {Liu, Tianyu and Yang, Yukang and Wang, Yu and Sun, Ming and Fan, Wenhui and Wu, Cheng and Bunger, Cody},
title = {Spinal Curve Assessment of Idiopathic Scoliosis with a Small Dataset via a Multi-Scale Keypoint Estimation Approach},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414317},
doi = {10.1145/3410530.3414317},
abstract = {Idiopathic scoliosis (IS) is the most common type of spinal deformity, which leads to severe pain and potential heart and lung damage. The clinical diagnosis and treatment strategies for IS highly depend on the radiographic assessment of spinal curve. With improvements in image recognition via deep learning, learning-based methods can be applied to facilitate clinical decision-making. However, these methods usually require sufficiently large training datasets with precise annotation, which are very laborious and time-consuming especially for medical images. Moreover, the medical images of serious IS always contain the blurry and occlusive parts, which would make the strict annotation of the spinal curve more difficult. To address these challenges, we utilize the dot annotations approach to simply annotate the medical images instead of precise annotation. Then, we design a multi-scale keypoint estimation approach that incorporates Squeeze-and-Excitation(SE) blocks to improve the representational capacity of the model, achieving the assessment of spinal curve without large-size dataset. The proposed approach uses pose estimation framework to detect keypoints of spine with simple annotation and small-size dataset for the first time. Finally, we conduct experiments on a collected clinical dataset, and results illustrate that our approach outperforms the mainstream approaches.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {665–670},
numpages = {6},
keywords = {spinal curve assessment, small-size dataset, keypoint estimation},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414614,
author = {Okoshi, Tadashi and Nakazawa, Jin and Ko, JeongGil and Kawsar, Fahim and Pirttikangas, Susanna},
title = {WellComp 2020: Third International Workshop on Computing for Well-Being},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414614},
doi = {10.1145/3410530.3414614},
abstract = {With the advancements in ubiquitous computing, ubicomp technology has deeply spread into our daily lives, including office work, home and house-keeping, health management, transportation, or even urban living environments. Furthermore, beyond the initial metric of computing, such as "efficiency" and "productivity", the benefits that people (users) benefit on a well-being perspective based on such ubiquitous technology has been greatly paid attention in the recent years. In our third "WellComp" (Computing for Well-being) workshop, we intensively discuss about the contribution of ubiquitous computing towards users' well-being that covers physical, mental, and social wellness (and their combinations), from the viewpoints of various different layers of computing. After big success of two previous workshops WellComp 2018 and 2019, with strong international organization members in various ubicomp research domains, WellComp 2020 will bring together researchers and practitioners from the academia and industry to explore versatile topics related to well-being and ubiquitous computing.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {671–674},
numpages = {4},
keywords = {well-being, mental health, social good, physical wellness},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414441,
author = {Ahmed, Md. Sabbir and Rony, Rahat Jahangir and Hasan, Tanvir and Ahmed, Nova},
title = {Smartphone Usage Behavior between Depressed and Non-Depressed Students: An Exploratory Study in the Context of Bangladesh},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414441},
doi = {10.1145/3410530.3414441},
abstract = {Increasing smartphone usage has received much scholarly attention to investigate its impact on mental health. To our best knowledge, none of the previous studies have explored smartphone usage behavior of depressed students. In this study, using 7 days' actual smartphone usage data of 44 students, we present the smartphone usage behavior that varies between depressed and non-depressed students. Our findings show that in terms of aggregated smartphone usage data, these two groups of students use similar number of apps. However, depressed students' frequency of launch per app is significantly higher. Moreover, they use Communication category apps more and their diurnal usage pattern is also significantly different. Therefore, our findings show the possibility to differentiate depressed and non-depressed students based on their smartphone usage data.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {675–679},
numpages = {5},
keywords = {smartphone, depression, communication, students, social media},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414437,
author = {Chowdhury, Fatema Sultana and Lov\'{e}n, Lauri and Cort\'{e}s, Marta and halkola, eija and Sepp\"{a}nen, Tapio and Pirttikangas, Susanna},
title = {Emotional Well-Being in Smart Environments: An Experiment with EEG},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414437},
doi = {10.1145/3410530.3414437},
abstract = {Well-being in smart environments refers to the mental, physiological and emotional states of people passing through environments where sensors, actuators and computers are intertwined with everyday tasks. In that context, well-being must be measurable and, to some extent, susceptible to external influence within the short time-spans that people spend in those environments. Continuing our previous studies, we evaluate an experiment for well-being measurement and control, introducing EEG observations in the experiment. EEG, as an immediate and objective proxy of one's mental, physiological and emotional state, provides ground truth for comparisons between sensors in the smart environment. We concentrate on the test subject's emotional state, observed by way of comparing changes in the alpha frequency power levels in the left and right frontal cortical areas, respectively corresponding to positive and negative emotions. The results show that our experimental set-up induces significant changes in the test subject's emotional state, paving the way for further studies on influencing personal well-being.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {680–683},
numpages = {4},
keywords = {well-being, smart environment, ICA, EEG, measurement, affective computing, sensoring},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414434,
author = {Higuma, Soichiro and Nishiyama, Yuuki and Sezaki, Kaoru},
title = {Towards Estimating UV Light Intensity Using GPS Signal Strength},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414434},
doi = {10.1145/3410530.3414434},
abstract = {Due to recent urbanization and changing lifestyles, many people have been spending more time indoors. Hence, they tend to receive less direct sunlight than ever before. Although excessive/inadequate UV exposure can be harmful to human health leading to illnesses such as skin cancer, spots, or depression, moderate UV exposure is necessary for vitamin D production in the body. Therefore, estimating UV exposure with a commonly used device is useful for maintaining a healthy lifestyle from excessive/inadequate UV exposure in our daily life. In this study, we aim to estimate UV exposure, and to this end, we used the GPS signal strength (C/No) collected from an off-the-shelf smartphone for exploring the relationship between UV values and C/No. We conducted an experiment and measured UV values and C/No from 10 places in two different situations. From the results, we observed a significant correlation (R2 more than 0.87) between UV values and C/No when all the data were divided by the sun/shade condition. This result supports the fact that UV values potentially can be inferred from C/No to some degree if the sun/shade condition can be detected.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {684–687},
numpages = {4},
keywords = {GPS signal reception, UV, estimation, mobile sensing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414436,
author = {Mairittha, Tittaya and Mairittha, Nattaya and Inoue, Sozo},
title = {Improving Fine-Tuned Question Answering Models for Electronic Health Records},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414436},
doi = {10.1145/3410530.3414436},
abstract = {The prevalence of voice assistants has strengthened the interest in a question answering for the medical domain, allowing both patients and healthcare providers to enter a question naturally and pinpoint useful information quickly. However, a large number of medical terms make the creation of such a system a demanding task. To address this challenge, we explore transfer learning techniques for constructing a personalized EHR-QA system. The goal is to answer questions regarding a discharge summary in an electronic health record (EHR). We present the experiments with a pre-trained BERT (Bidirectional Encoder Representations from Transformers) model fine-tuned on different tasks and show the results obtained to provide insights into learning effects and training effectiveness.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {688–691},
numpages = {4},
keywords = {question answering, transfer learning, electronic health records},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414439,
author = {Okoshi, Tadashi and Sasaki, Wataru and Nakazawa, Jin},
title = {Behavification: Bypassing Human's Attentional and Cognitive Systems for Automated Behavior Change},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414439},
doi = {10.1145/3410530.3414439},
abstract = {To achieve behavior change in our lives for several specific goals towards better well-being, various types intervention systems have been proposed. However, because of humans' bounded rationality, such explicit information provision for the users do not always reach their attention, thus fails the needed information for the behavior change. This paper propose new concepts "behavification" with which information system bypasses the user's cognitive, attentional and perceptive system by not notifying him/her and modifies the system behavior to directly influence the user's behavior under user's explicit advance permission. Through a series of group discussion and survey sessions with 19 participants, we investigated how the potential behavification users see its appropriateness to different application categories, killer application scenarios, and design guidelines and rationales for a behavification system to support such scenarios. We found total 58 application scenarios and propose 3 guidelines "advance user permission", "multi-modality" and "integration with real-world action/actuation."},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {692–695},
numpages = {4},
keywords = {behavior change, cognitive resource, attention resource, automation, behavification},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414435,
author = {Sasaki, Wataru and Ozawa, Ryo and Okoshi, Tadashi and Nakazawa, Jin and Yagasaki, Kaori and Komatsu, Hiroko},
title = {Estimating Symptoms Caused by CIPN Using Mobile and Wearable Devices},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414435},
doi = {10.1145/3410530.3414435},
abstract = {Chemotherapy-induced peripheral neuropathy (CIPN) is a common side effect of anticancer drugs that causes muscle weakness in the cancer patients, causing them to fall. Therefore, we constructed "FD-AWARE", a system to understand the users' fall context and users' CIPN symptoms as the first step in preventing these falls. This system can collect the various sensor data from the iPhone and the Apple Watch, self-reported fall information data, self-reported user status data of CIPN symptoms, and their physical condition. We conducted a 2-week in-the-wild experiment with 8 patients who were actually suffering from CIPN. We constructed the machine learning models for estimating the users' status of CIPN symptoms and successfully achieved high accuracy of performance for several estimating models.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {696–699},
numpages = {4},
keywords = {mobile sensing, machine learning, fall detection, CIPN},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414442,
author = {Sharmila, Parsa and Schroderus, Vappu and Lagerspetz, Eemil and Peltonen, Ella},
title = {Towards Understanding Smartphone Usage and Sleep with a Crowdsensing Approach},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414442},
doi = {10.1145/3410530.3414442},
abstract = {Smartphone usage and sleep quality have established connections in psychological research, but in the HCI context, the topic is still understudied. In this paper, we present preliminary insights into behavioral patterns between smartphone usage and sleep quality by using crowdsensed data. We utilize a large-scale mobile usage dataset and a PHQ-8 depression questionnaire answered by 743 participants from varying age groups and socioeconomic backgrounds. Based on our preliminary results, we provide a methodological pipeline for future work towards understanding the relationship between daily smartphone usage patterns and sleep quality in the wild.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {700–703},
numpages = {4},
keywords = {sleep, crowdsensing, smartphones},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414443,
author = {Sohrab, Fahad and Raitoharju, Jenni and Gabbouj, Moncef},
title = {Facial Expression Based Satisfaction Index for Empathic Buildings},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414443},
doi = {10.1145/3410530.3414443},
abstract = {In this work, we examine the suitability of automatic facial expression recognition to be used for satisfaction analysis in an Empathic Building environment. We use machine learning based facial expression recognition on the working stations to integrate an online satisfaction index into Empathic Building platform. To analyze the suitability of facial expression recognition to reflect longer-term satisfaction, we examine the changes and trends in the happiness curves of our test users. We also correlate the happiness curve with temperature, humidity, and light intensity of the test users' local city (Tampere Finland). The results indicate that the proposed analysis indeed shows some trends that may be used for long-term satisfaction analysis in different kinds of intelligent buildings.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {704–707},
numpages = {4},
keywords = {facial expressions, satisfaction index, empathic building, machine learning},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414440,
author = {Tailor, Shyam A. and Chauhan, Jagmohan and Mascolo, Cecilia},
title = {A First Step towards On-Device Monitoring of Body Sounds in the Wild},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414440},
doi = {10.1145/3410530.3414440},
abstract = {Body sounds provide rich information about the state of the human body and can be useful in many medical applications. Auscultation, the practice of listening to body sounds, has been used for centuries in respiratory and cardiac medicine to diagnose or track disease progression. To date, however, its use has been confined to clinical and highly controlled settings. Our work addresses this limitation: we devise a chest-mounted wearable for continuous monitoring of body sounds, that leverages data processing algorithms that run on-device. We concentrate on the detection of heart sounds to perform heart rate monitoring. To improve robustness to ambient noise and motion artefacts, our device uses an algorithm that explicitly segments the collected audio into the phases of the cardiac cycle. Our study with 9 users demonstrates that it is possible to obtain heart rate estimates that are competitive with commercial devices, with low enough power consumption for continuous use.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {708–712},
numpages = {5},
keywords = {audio, mobile health, wearables},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3410530.3414438,
author = {Tsurugasaki, Yuma and Shimoda, Koichi and Hefenbrock, Michael and Taya, Akihito and Song, Sejun and Tobe, Yoshito},
title = {Scalable Selection of EEG Features for Compression},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414438},
doi = {10.1145/3410530.3414438},
abstract = {Telemedicine using information technology (IT) and communication networks is becoming common. Often, the medical doctor and the patient can discuss the problem by video teleconference and, if necessary, the patient's physiological data can be sent to the doctor. As part of this trend, we believe that brain waves can be used for telemedicine in the future. We expect that the diagnosis of remote patients will be realized by transferring electroencephalogram (EEG) data to a server or cloud. However, if EEG data are sent as they are, the data size will be significantly large. Thus, the compression of EEG data is desirable. Furthermore, should not affect the accuracy of diagnosis if data compression is performed. In this study, the relationship between the selected EEG signal features and the accuracy is investigated.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {712–715},
numpages = {4},
keywords = {electroencephalogram, machine learning, telemedicine, features},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

