@inproceedings{10.1145/3259615,
title = {Session Details: Invited Talks},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259615},
doi = {10.1145/3259615},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111451,
author = {Ishiguro, Hiroshi},
title = {Interactive Humanoids and Androids as Ideal Interfaces for Humans},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111451},
doi = {10.1145/1111449.1111451},
abstract = {We, humans, anthropomorphize targets of communication. In this sense, humanoids or androids can have ideal interface for humans. This paper focuses on two new fundamental issues in the human interface studies. There are two relationships between robots and humans: one is inter-personal and the other is social. In the inter-personal relationships, the appearance of the robot is a new and important research issues. In the social relationships, a function to recognize human relationships through interaction is needed for robots of the next generation. These two issues explore new possibilities of androids and humanoids. Especially, the appearance problem bridges between science and engineering. The approach from robotics tries to build very humanlike robots based on knowledge from cognitive science. The approach from cognitive science uses the robot for verifying hypotheses for understanding humans. We call this cross-interdisciplinary framework android science.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {2–9},
numpages = {8},
keywords = {sociogram, android science, interactive robot, android, human interface, humanoid, social robot},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111452,
author = {Shaw, Jeffrey},
title = {Meaningful Interfaces in Immersive Environments},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111452},
doi = {10.1145/1111449.1111452},
abstract = {While generic user interfaces are ubiquitous and customarily bland, the idiosyncratic interfaces developed in art practice over the last decades are significant because of their ability to embody meaning.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {10–11},
numpages = {2},
keywords = {embodying meaning, idiosyncratic interfaces, immersive environments, interactive art},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/3259616,
title = {Session Details: Workshops},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259616},
doi = {10.1145/3259616},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111454,
author = {Alm, Norman and Abe, Shinji and Kuwahara, Noriaki},
title = {Cognitive Prostheses and Assisted Communication},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111454},
doi = {10.1145/1111449.1111454},
abstract = {This workshop offers the opportunity for researchers in the fields of assistive technology, cognitive psychology, user interface design and context-awareness to present the state of the art in each field and to discuss an approach and a research agenda for realizing effective cognitive prostheses.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {14},
numpages = {1},
keywords = {cognitive prostheses},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111455,
author = {Butz, Andreas and Kray, Christian and Kr\"{u}ger, Antonio and Schwesig, Carsten},
title = {Workshop W2: Multi-User and Ubiquitous User Interfaces (MU3I 2006)},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111455},
doi = {10.1145/1111449.1111455},
abstract = {The main objective of the third workshop on Multi-User and Ubiquitous User Interfaces (MU3I 2006) is to bring people with relevant backgrounds (e.g. interface design, CSCW, ubiquitous computing) together to discuss two key questions in this field: How can we build interfaces, which span multiple devices so that the user knows that they can be used to control a specific application? How can we build interfaces for public displays? Therefore, the main outcome of the workshop is expected to consists of further insights into those problems, potential solutions and a research agenda to investigate these further.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {15},
numpages = {1},
keywords = {ubiquitous interfaces, multi-user interfaces},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111456,
author = {Zhou, Michelle X. and Maybury, Mark},
title = {Intelligent User Interfaces for Intelligence Analysis},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111456},
doi = {10.1145/1111449.1111456},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {16},
numpages = {1},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111457,
author = {Cavedon, Lawrence and Dale, Robert and Chen, Fang and Traum, David},
title = {Workshop on Effective Multimodal Dialogue Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111457},
doi = {10.1145/1111449.1111457},
abstract = {This workshop addresses the issue of evaluating multimodal dialogue systems, and in particular the characteristics and interaction styles that are particularly effective for human-machine collaborative task performance.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {17},
numpages = {1},
keywords = {human-computer collaboration, multimodal dialogue, evaluation},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/3259617,
title = {Session Details: Tutorials},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259617},
doi = {10.1145/3259617},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111459,
author = {Scholtz, Jean and Yanco, Holly A. and Drury, Jill L.},
title = {Introduction to Human-Robot Interaction},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111459},
doi = {10.1145/1111449.1111459},
abstract = {This tutorial presents the current status of research in interactions with robots, including adaptive robots/interfaces, speech, gestures, virtual reality, and social interactions. Different user interface designs will be shown and discussed during the tutorial. Human-robot interaction (HRI) guidelines, evaluation methodologies and metrics currently used by the community will be presented. Research needs will also be discussed. Participants will work in small groups to design a robotic application as well as an evaluation plan.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {20},
numpages = {1},
keywords = {adaptive user interfaces, human-robot interaction},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111460,
author = {Ferscha, Alois and Holzmann, Clemens and Leitner, Michael},
title = {Interfaces Everywhere: Interacting with the Pervasive Computer},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111460},
doi = {10.1145/1111449.1111460},
abstract = {Due to recent technological advances, it has become possible to integrate sensor and actuator technologies as well as wireless communication in everyday objects and environments. These developments open up a huge amount of innovative interaction scenarios, involving new forms of user interfaces. This half day tutorial gives an overview of the emerging field of everywhere interfaces, referring to computing devices that disappear within objects of everyday life and thus enable omnipresent physical interfaces to the digital world, describes the state of the art of sensor and actuator technologies and demonstrates the development of a smart artefact for controlling everyday environments.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {21},
numpages = {1},
keywords = {everywhere interfaces, tangible interaction, smart artefacts},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111461,
author = {Jokinen, Kristiina},
title = {Constructive Dialogue Management for Speech-Based Interaction Systems},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111461},
doi = {10.1145/1111449.1111461},
abstract = {The tutorial will introduce the major topics, established practices and methodologies in dialogue management research. Evaluation criteria and usability aspects for useful and enjoyable interactive systems will also be discussed. The tutorial is based on the framework of Constructive Dialogue Management, and focuses especially on the technological and theoretical challenges in designing adaptive and intelligent conversational systems.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {22},
numpages = {1},
keywords = {dialogue management, intelligent interfaces, speech-based interactive systems, adaptation},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/3259618,
title = {Session Details: Gestural Input},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259618},
doi = {10.1145/3259618},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111463,
author = {Jaimes, Alejandro},
title = {Posture and Activity Silhouettes for Self-Reporting, Interruption Management, and Attentive Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111463},
doi = {10.1145/1111449.1111463},
abstract = {In this paper we present a novel system for monitoring a computer user's posture and activities in front of the computer (e.g., reading, speaking on the phone, etc.) for self-reporting. In our system, a camera and a microphone are placed in front of a computer work area (e.g., on top of the computer screen). The system can be used as a component in an attentive interface, or for giving the user real time feedback on the goodness of his current posture, and generating summaries of postures and activities over a specified period of time (e.g., hours, days, months, etc.). All elements of the system are highly customizable: the user decides what "good" postures are, what alarms and interruptions are triggered, if any, and what activity and posture summaries are generated. We present novel algorithms for posture measurement (using geometric features of the user's silhouette), and activity classification (using machine learning). Finally, we present experiments that show the feasibility of our approach.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {24–31},
numpages = {8},
keywords = {posture, ergonomics, computer vision},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111464,
author = {Morency, Louis-Philippe and Darrell, Trevor},
title = {Head Gesture Recognition in Intelligent Interfaces: The Role of Context in Improving Recognition},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111464},
doi = {10.1145/1111449.1111464},
abstract = {Acknowledging an interruption with a nod of the head is a natural and intuitive communication gesture which can be performed without significantly disturbing a primary interface activity. In this paper we describe vision-based head gesture recognition techniques and their use for common user interface commands. We explore two prototype perceptual interface components which use detected head gestures for dialog box confirmation and document browsing, respectively. Tracking is performed using stereo-based alignment, and recognition proceeds using a trained discriminative classifier. An additional context learning component is described, which exploits interface context to obtain robust performance. User studies with prototype recognition components indicate quantitative and qualitative benefits of gesture-based confirmation over conventional alternatives.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {32–38},
numpages = {7},
keywords = {nodding, context-based recognition, nod recognition, user study, IUI design, head gesture, multi-modal input},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111465,
author = {Merten, Christina and Conati, Cristina},
title = {Eye-Tracking to Model and Adapt to User Meta-Cognition in Intelligent Learning Environments},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111465},
doi = {10.1145/1111449.1111465},
abstract = {In this paper we describe research on using eye-tracking data for on-line assessment of user meta-cognitive behavior during the interaction with an intelligent learning environment. We describe the probabilistic user model that processes this information, and its formal evaluation. We show that adding eye-tracker information significantly improves the model accuracy on assessing user exploration and self-explanation behaviors.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {39–46},
numpages = {8},
keywords = {adaptive interfaces, intelligent assistance for complex tasks, meta-cognitive skills, eye-tracking, intelligent learning environments, user modeling},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111467,
author = {Fleischman, Michael and Hovy, Eduard},
title = {Taking Advantage of the Situation: Non-Linguistic Context for Natural Language Interfaces to Interactive Virtual Environments},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111467},
doi = {10.1145/1111449.1111467},
abstract = {We introduce a framework for learning situated Natural Language Interfaces (NLIs) to interactive virtual environments. The framework exploits the non-linguistic context, or situation, explicitly modeled in such interactive applications. This situation model is integrated with a model of word meaning in a principled manner using a noisy channel approach to language understanding. Preliminary experimentation in an independently designed interactive application, i.e. the Mission Rehearsal Exercise (MRE), shows that this situated NLI outperforms a state of the art NLI on both whole frame accuracy and F-Score metrics. Further, use of the situation model in the situated NLI is shown to increase robustness to the noise introduced by the use of automatic speech recognition.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {47–54},
numpages = {8},
keywords = {situation models, mission rehearsal exercise, interactive virtual environments, situated NLI, non-linguistic context, plan recognition, natural language interfaces/understanding},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111468,
author = {Jung, Sangkeun and Lee, Cheongjae and Lee, Gary Geunbae},
title = {Three Phase Verification for Spoken Dialog Clarification},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111468},
doi = {10.1145/1111449.1111468},
abstract = {Spoken dialog tasks incur many errors including speech recognition errors, understanding errors, and even dialog management errors. These errors create a big gap between user's will and the system's understanding, and eventually result in a misinterpretation. To fill in the gap, people in human-to-human dialog try to clarify the major causes of the misunderstanding and selectively correct them. This paper presents a method for applying the human's clarification techniques to human-machine spoken dialog systems. To increase the error detection precision and error recovery efficiency for the clarification dialogs, error detection phase is organized into three systematic phases and a clarification expert is devised for recovering the errors using the three phase verification. The experiment results demonstrate that the three phase verification could effectively catch the word and utterance-level errors in order to increase the SLU (spoken language understanding) performance and the clarification experts can actually increase the dialog success rate and the dialog efficiency.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {55–61},
numpages = {7},
keywords = {three phase verification, clarification dialog, clarification expert, spoken language understanding, dialog management},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111469,
author = {Yamashita, Naomi and Ishida, Toru},
title = {Automatic Prediction of Misconceptions in Multilingual Computer-Mediated Communication},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111469},
doi = {10.1145/1111449.1111469},
abstract = {Multilingual communities using machine translation to overcome language barriers are showing up with increasing frequency. However, when a large number of translation errors get mixed into conversations, users have difficulty completely understanding each other. In this paper, we focus on misconceptions found in high volume in actual online conversations using machine translation. We first examine the response patterns in machine translation-mediated communication and associate them with misconceptions. Analysis results indicate that response messages to include misconceptions posted via machine translation tend to be incoherent, often focusing on short phrases of the original message. Next, based on the analysis results, we propose a method that automatically predicts the occurrence of misconceptions in each dialogue. The proposed method assesses the tendency of each dialogue including misconceptions by calculating the gaps between the regular discussion thread (syntactic thread) and the discussion thread based on lexical cohesion (semantic thread). Verification results show significant positive correlation between actual misconception frequency and gaps between syntactic and semantic threads, which indicate the validity of the method.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {62–69},
numpages = {8},
keywords = {machine translation, misconception, multilingual groups, computer-mediated communication},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111471,
author = {Dredze, Mark and Lau, Tessa and Kushmerick, Nicholas},
title = {Automatically Classifying Emails into Activities},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111471},
doi = {10.1145/1111449.1111471},
abstract = {Email-based activity management systems promise to give users better tools for managing increasing volumes of email, by organizing email according to a user's activities. Current activity management systems do not automatically classify incoming messages by the activity to which they belong, instead relying on simple heuristics (such as message threads), or asking the user to manually classify incoming messages as belonging to an activity. This paper presents several algorithms for automatically recognizing emails as part of an ongoing activity. Our baseline methods are the use of message reply-to threads to determine activity membership and a na\"{\i}ve Bayes classifier. Our SimSubset and SimOverlap algorithms compare the people involved in an activity against the recipients of each incoming message. Our SimContent algorithm uses IRR (a variant of latent semantic indexing) to classify emails into activities using similarity based on message contents. An empirical evaluation shows that each of these methods provide a significant improvement to the baseline methods. In addition, we show that a combined approach that votes the predictions of the individual methods performs better than each individual method alone.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {70–77},
numpages = {8},
keywords = {machine learning, text classification, activity management, email},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111472,
author = {Tomasic, Anthony and Zimmerman, John and Simmons, Isaac},
title = {Linking Messages and Form Requests},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111472},
doi = {10.1145/1111449.1111472},
abstract = {Large organizations with sophisticated infrastructures have large form-based systems that manage the interaction between the user community and the infrastructure. In many cases, when a user needs to complete a form to accomplish a task, the user e-mails a description of the task to the appropriate form expert. In many cases this description is incomplete and the expert engages in a clarification dialog to determine the details of the task. Since many tasks and descriptions are routine, this e-mail dialog can be replaced with an intelligent user interface. The interface proactively reads e-mail (or IM) messages and assists the user in completing the associated task without involving the expert. To ground our vision in a specific application, we have built an agent that functions as a webmaster assistant. For example, a user emails the request: "Change John Doe's home phone number to 800-555-1212" to the agent. The webmaster agent then replies with the biographical data form displaying information about John Doe with the new phone number pre-filled in the form. The user then simply approves the change.In this paper we describe a prototype website maintenance agent that (i) allows users to express the updates they want to make in human terms (free text input expression of intent), and (ii) allows users to quickly repair any inference errors the agent makes. In addition, we present the results of a proof of concept study that details how interacting with a webmaster agent that makes inference errors is both more efficient (faster) and more effective (errors made to site) than sending a request to a human webmaster. We conclude the paper with a discussion of the application of our work to any form-based system.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {78–85},
numpages = {8},
keywords = {forms, information extraction, microforms, virtual information officer, machine learning, VIO, natural language analysis},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111473,
author = {Shen, Jianqiang and Li, Lida and Dietterich, Thomas G. and Herlocker, Jonathan L.},
title = {A Hybrid Learning System for Recognizing User Tasks from Desktop Activities and Email Messages},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111473},
doi = {10.1145/1111449.1111473},
abstract = {The TaskTracer system seeks to help multi-tasking users manage the resources that they create and access while carrying out their work activities. It does this by associating with each user-defined activity the set of files, folders, email messages, contacts, and web pages that the user accesses when performing that activity. The initial TaskTracer system relies on the user to notify the system each time the user changes activities. However, this is burdensome, and users often forget to tell TaskTracer what activity they are working on. This paper introduces TaskPredictor, a machine learning system that attempts to predict the user's current activity. TaskPredictor has two components: one for general desktop activity and another specifically for email. TaskPredictor achieves high prediction precision by combining three techniques: (a) feature selection via mutual information, (b) classification based on a confidence threshold, and (c) a hybrid design in which a Naive Bayes classifier estimates the classification confidence but where the actual classification decision is made by a support vector machine. This paper provides experimental results on data collected from TaskTracer users.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {86–92},
numpages = {7},
keywords = {machine learning, support vector machines, naive Bayes, intelligent interfaces},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111475,
author = {Pu, Pearl and Chen, Li},
title = {Trust Building with Explanation Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111475},
doi = {10.1145/1111449.1111475},
abstract = {Based on our recent work on the development of a trust model for recommender agents and a qualitative survey, we explore the potential of building users' trust with explanation interfaces. We present the major results from the survey, which provided a roadmap identifying the most promising areas for investigating design issues for trust-inducing interfaces. We then describe a set of general principles derived from an in-depth examination of various design dimensions for constructing explanation interfaces, which most contribute to trust formation. We present results of a significant-scale user study, which indicate that the organization-based explanation is highly effective in building users' trust in the recommendation interface, with the benefit of increasing users' intention to return to the agent and save cognitive effort.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {93–100},
numpages = {8},
keywords = {recommender agents, explanation interfaces, trust building, tradeoff assistance},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111476,
author = {O'Donovan, John and Smyth, Barry},
title = {Is Trust Robust? An Analysis of Trust-Based Recommendation},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111476},
doi = {10.1145/1111449.1111476},
abstract = {Systems that adapt to input from users are susceptible to attacks from those same users. Recommender systems are common targets for such attacks since there are financial, political and many other motivations for influencing the promotion or demotion of recommendable items [2].Recent research has shown that incorporating trust and reputation models into the recommendation process can have a positive impact on the accuracy and robustness of recommendations. In this paper we examine the effect of using five different trust models in the recommendation process on the robustness of collaborative filtering in an attack situation. In our analysis we also consider the quality and accuracy of recommendations. Our results caution that including trust models in recommendation can either reduce or increase prediction shift for an attacked item depending on the model-building process used, while highlighting approaches that appear to be more robust.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {101–108},
numpages = {8},
keywords = {recommender systems, trust, collaborative filtering, robustness},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111477,
author = {O'Mahony, Michael P. and Hurley, Neil J. and Silvestre, Gu\'{e}nol\'{e} C.M.},
title = {Detecting Noise in Recommender System Databases},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111477},
doi = {10.1145/1111449.1111477},
abstract = {In this paper, we propose a framework that enables the detection of noise in recommender system databases. We consider two classes of noise: natural and malicious noise. The issue of natural noise arises from imperfect user behaviour (e.g. erroneous/careless preference selection) and the various rating collection processes that are employed. Malicious noise concerns the deliberate attempt to bias system output in some particular manner. We argue that both classes of noise are important and can adversely effect recommendation performance. Our objective is to devise techniques that enable system administrators to identify and remove from the recommendation process any such noise that is present in the data. We provide an empirical evaluation of our approach and demonstrate that it is successful with respect to key performance indicators.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {109–115},
numpages = {7},
keywords = {performance measures, collaborative recommender systems, noise detection, malicious attacks, robustness},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111479,
author = {Zhou, Michelle X. and Houck, Keith and Pan, Shimei and Shaw, James and Aggarwal, Vikram and Wen, Zhen},
title = {Enabling Context-Sensitive Information Seeking},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111479},
doi = {10.1145/1111449.1111479},
abstract = {Information seeking is an important but often difficult task, especially when it involves large and complex data sets. We hypothesize that a context-sensitive interaction paradigm would greatly assist users in their information seeking. Such a paradigm would allow users to both express their requests and receive requested information in context. Driven by this hypothesis, we have taken rigorous steps to design, develop, and evaluate a full-fledged, context-sensitive information system. We started with a Wizard-of-OZ (WOZ) study to verify the effectiveness of our envi-sioned system. We then built a fully automated system based on the findings from our WOZ study. We targeted the development and integration of two sets of technologies: context-sensitive mul-timodal input interpretation and multimedia output generation. Finally, we formally evaluated the usability of our system in real world conditions. The results show that our system greatly improves the users' ability to perform practical information-seek-ing tasks. These results not only confirm our initial hypothesis, but they also indicate the practicality of our approaches.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {116–123},
numpages = {8},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111480,
author = {Carenini, Giuseppe and Ng, Raymond T. and Pauls, Adam},
title = {Interactive Multimedia Summaries of Evaluative Text},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111480},
doi = {10.1145/1111449.1111480},
abstract = {We present an interactive multimedia interface for automatically summarizing large corpora of evaluative text (e.g. online product reviews). We rely on existing techniques for extracting knowledge from the corpora but present a novel approach for conveying that knowledge to the user. Our system presents the extracted knowledge in a hierarchical visualization mode as well as in a natural language summary. We propose a method for reasoning about the extracted knowledge so that the natural language summary can include only the most important information from the corpus. Our approach is interactive in that it allows the user to explore in the original dataset through intuitive visual and textual methods. Results of a formative evaluation of our interface show general satisfaction among users with our approach.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {124–131},
numpages = {8},
keywords = {automatic summarization, natural language generation},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111481,
author = {Duarte, Carlos and Carri\c{c}o, Lu\'{\i}s},
title = {A Conceptual Framework for Developing Adaptive Multimodal Applications},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111481},
doi = {10.1145/1111449.1111481},
abstract = {This article presents FAME, a model-based Framework for Adaptive Multimodal Environments. FAME proposes an architecture for adaptive multimodal applications, a new way to represent adaptation rules - the behavioral matrix - and a set of guidelines to assist the design process of adaptive multimodal applications. To demonstrate FAME's validity, the development process of an adaptive Digital Talking Book player is summarized.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {132–139},
numpages = {8},
keywords = {IUI design, adaptive multimodal interfaces, behavioral matrix, digital talking books},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111483,
author = {Mass\'{o}, Jos\'{e} Pascual Molina and Vanderdonckt, Jean and L\'{o}pez, Pascual Gonz\'{a}lez},
title = {Direct Manipulation of User Interfaces for Migration},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111483},
doi = {10.1145/1111449.1111483},
abstract = {From a topological model of a working environment, MigriXML automatically generates a virtual reality environment for controlling the run-time migration of a graphical user interface from one computing platform to another one (e.g., from a desktop to a pocket computer), from one interaction surface to another (e.g., from a laptop to a wall screen) at run-time. For this purpose, any user interface subject to migration is described in USer Interface eXtensible Markup Language regarding its look &amp; feel as well as the platforms and the surfaces involved in the migration. Each interface, in part or in whole, can be attached to a platform or a surface, detached from it, and migrated across platforms or interaction surfaces. Instead of communicating data and code during the migration, the description of the user interface of concern is wirelessly passed from one platform to another one to be regenerated on the target platform. To ensure a continuous control of the run-time migration, MigriXML automatically generates a world model representing the context of use where the source/target platforms/interaction surfaces are represented. Finally, migrating a user interface becomes as natural as its direct manipulation from one platform to another exactly in the same way as it is done on a single platform.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {140–147},
numpages = {8},
keywords = {virtual environment, migration},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111484,
author = {Ao, Xiang and Li, Junfeng and Wang, Xugang and Dai, Guozhong},
title = {Structuralizing Digital Ink for Efficient Selection},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111484},
doi = {10.1145/1111449.1111484},
abstract = {Raw digital ink is informal and unstructured. Its editing, especially its selection, is often inefficient. In this paper, we present approaches to structuralize raw digital ink as multiple hierarchies to facilitate its selection. First a link model is built to organize ink as a mesh-like structure. Based on the link model, the isolated stroke groups form patches. In each patch, textual and graphical areas are separated. Then, each textual area is segmented into text lines, and each text line is partitioned to words. We also design gestures for selecting structured ink. Experiments showed that our ink-structuralizing approaches are effective and selecting structured ink by our gestures considerably outperforms selecting raw ink.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {148–154},
numpages = {7},
keywords = {structuralizing, selection gesture, digital ink, text line extraction, text/graph separation},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111486,
author = {Chklovski, Timothy},
title = {Deriving Quantitative Overviews of Free Text Assessments on the Web},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111486},
doi = {10.1145/1111449.1111486},
abstract = {Many research efforts are addressing the problem of enabling automatic summarization of opinions and assessments stated on the web in product reviews, discussion forums, and blogs. One key difficulty is that relevant assessments scattered throughout web pages are obscured by variations in natural language. In this paper, we focus on a novel aspect of enabling aggregations of assessments of degree to which a given property holds for a given entity (for instance, how touristy is Boston). We present GrainPile, a user interface for extracting from the web, aggregating and quantifying degree assessments of unconstrained topics. The interface provides a variety of functions: a) identification of dimensions of comparison (properties) relevant to a particular entity or set of entities, b) comparisons of like entities on user-specified properties (for example, which university is more prestigious, Yale or Cornell), c) tracing the derived opinions back to their sources (so that the reasons for the opinions can be found). A central contribution in GrainPile is the evaluated demonstration of feasibility of mapping the recognized expressions (such as fairly, very, extremely, and so on) to a common scale of numerical values and aggregating across all the extracted assessments to derive an overall assessment of degree. GrainPile's novel assessment and aggregation of degree expressions is shown to strongly outperform an interpretation-free, co-occurrence based method.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {155–162},
numpages = {8},
keywords = {text extraction, sentiment analysis, question answering},
location = {Sydney, Australia},
series = {IUI '06}
}

@dataset{10.1145/review-1111449.1111486_R40948,
author = {Ibrahim, Rosziati},
title = {Review ID:R40948 for DOI: 10.1145/1111449.1111486},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1111449.1111486_R40948}
}

@inproceedings{10.1145/1111449.1111487,
author = {Sun, Mingyu and Chai, Joyce Y.},
title = {Towards Intelligent QA Interfaces: Discourse Processing for Context Questions},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111487},
doi = {10.1145/1111449.1111487},
abstract = {Question answering (QA) systems take users' natural language questions and retrieve relevant answers from large repositories of free texts. Despite recent progress in QA research, most work on question answering is still focused on isolated questions. In a real-world information seeking scenario, questions are not asked in isolation, but rather in a coherent manner that involves a sequence of related questions to meet users' information needs. Therefore, to support coherent information seeking, intelligent QA interfaces will inevitably require techniques to support context question answering. To address this problem, this paper investigates approaches to discourse processing of a sequence of coherent questions and their implications on query expansion. In particular, we examine three models for query expansion that are motivated by Centering Theory. Our empirical results indicate that more sophisticated processing based on discourse transitions and centers can significantly improve the performance of document retrieval compared to models that only resolve references.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {163–170},
numpages = {8},
keywords = {discourse processing, context management, question answering, QA interfaces},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111488,
author = {Feng, Donghui and Shaw, Erin and Kim, Jihie and Hovy, Eduard},
title = {An Intelligent Discussion-Bot for Answering Student Queries in Threaded Discussions},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111488},
doi = {10.1145/1111449.1111488},
abstract = {This paper describes a discussion-bot that provides answers to students' discussion board questions in an unobtrusive and human-like way. Using information retrieval and natural language processing techniques, the discussion-bot identifies the questioner's interest, mines suitable answers from an annotated corpus of 1236 archived threaded discussions and 279 course documents and chooses an appropriate response. A novel modeling approach was designed for the analysis of archived threaded discussions to facilitate answer extraction. We compare a self-out and an all-in evaluation of the mined answers. The results show that the discussion-bot can begin to meet students' learning requests. We discuss directions that might be taken to increase the effectiveness of the question matching and answer extraction algorithms. The research takes place in the context of an undergraduate computer science course.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {171–177},
numpages = {7},
keywords = {threaded discussion, discussion-bot, online learning environment, natural language processing},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111490,
author = {Bao, Xinlong and Herlocker, Jonathan L. and Dietterich, Thomas G.},
title = {Fewer Clicks and Less Frustration: Reducing the Cost of Reaching the Right Folder},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111490},
doi = {10.1145/1111449.1111490},
abstract = {Helping computer users rapidly locate files in their folder hierarchies has become an important research topic in today's intelligent user interface design. This paper reports on FolderPredictor, a software system that can reduce the cost of locating files in hierarchical folders. FolderPredictor applies a cost-sensitive prediction algorithm to the user's previous file access information to predict the next folder that will be accessed. Experimental results show that, on average, FolderPredictor reduces the cost of locating a file by 50%. Another advantage of FolderPredictor is that it does not require users to adapt to a new interface, but rather meshes with the existing interface for opening files on the Windows platform.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {178–185},
numpages = {8},
keywords = {prediction, directories, tasks, shortcuts, activities, recommendation, machine learning, user interface, folders, intelligent user interfaces},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111491,
author = {Hui, Bowen and Boutilier, Craig},
title = {Who's Asking for Help? A Bayesian Approach to Intelligent Assistance},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111491},
doi = {10.1145/1111449.1111491},
abstract = {Automated software customization is drawing increasing attention as a means to help users deal with the scope, complexity, potential intrusiveness, and ever-changing nature of modern software. The ability to automatically customize functionality, interfaces, and advice to specific users is made more difficult by the uncertainty about the needs of specific individuals and their preferences for interaction. Following recent probabilistic techniques in user modeling, we model our user with a dynamic Bayesian network (DBN) and propose to explicitly infer the "user's type" --- a composite of personality and affect variables --- in real time. We design the system to reason about the impact of its actions given the user's current attitudes. To illustrate the benefits of this approach, we describe a DBN model for a text-editing help task. We show, through simulations, that user types can be inferred quickly, and that a myopic policy offers considerable benefit by adapting to both different types and changing attitudes. We then develop a more realistic user model, using behavioural data from 45 users to learn model parameters and the topology of our proposed user types. With the new model, we conduct a usability experiment with 4 users and 4 different policies. These experiments, while preliminary, show encouraging results for our adaptive policy.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {186–193},
numpages = {8},
keywords = {dynamic Bayesian networks, user modeling, intelligent assistance},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111492,
author = {Oliver, Nuria and Smith, Greg and Thakkar, Chintan and Surendran, Arun C.},
title = {SWISH: Semantic Analysis of Window Titles and Switching History},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111492},
doi = {10.1145/1111449.1111492},
abstract = {Information workers are often involved in multiple tasks and activities that they must perform in parallel or in rapid succession. In consequence, task management itself becomes yet another task that information workers need to perform in order to get the rest of their work done. Recognition of this problem has led to research on task management systems, which can help by allowing fast task switching, fast task resumption, and automatic task identification. In this paper we focus on the latter: we tackle the problem of automatically detecting the tasks that the user is involved in, by identifying which of the windows on the user's desktop are related to each other. The underlying assumption is that windows that belong to the same task share some common properties with one another that we can detect from data. We will refer to this problem as the task assignment problem.To address this problem, we have built a prototype named Swish that: (1) constantly monitors users' desktop activities using a stream of windows events; (2) logs and processes this raw event stream, and (3) implements two criteria of window "relatedness", namely the semantic similarity of their titles, and the temporal closeness in their access patterns.In addition to describing the Swish prototype in detail, we validate it with 4 hours of user data, obtaining task classification accuracies of about 70%. We also discuss our plans on including Swish in a number of intelligent user interfaces and future lines of research.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {194–201},
numpages = {8},
keywords = {automatic task identification, clustering, user task modeling, user activity monitoring},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111494,
author = {Oblinger, Daniel and Castelli, Vittorio and Bergman, Lawrence},
title = {Augmentation-Based Learning: Combining Observations and User Edits for Programming-by-Demonstration},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111494},
doi = {10.1145/1111449.1111494},
abstract = {In this paper we introduce a new approach to Programming-by-Demonstration in which the user is allowed to explicitly edit the procedure model produced by the learning algorithm while demonstrating the task. We describe a new algorithm, Augmentation-Based Learning, that supports this approach by considering both demonstrations and edits as constraints on the hypothesis space, and resolving con icts in favor of edits.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {202–209},
numpages = {8},
keywords = {artificial intelligence, programming-by-demonstration, example-and demonstration-based interfaces},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111495,
author = {Hammond, Tracy and Davis, Randall},
title = {Interactive Learning of Structural Shape Descriptions from Automatically Generated Near-Miss Examples},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111495},
doi = {10.1145/1111449.1111495},
abstract = {Sketch interfaces provide more natural interaction than the traditional mouse and palette tool, but can be time consuming to build if they have to be built anew for each new domain. A shape description language, such as the LADDER language we created, can significantly reduce the time necessary to create a sketch interface by enabling automatic generation of the interface from a domain description. However, structural shape descriptions, whether written by users or created automatically by the computer, are frequently over- or under- constrained. We present a technique to debug over- and under-constrained shapes using a novel form of active learning that generates its own suspected near-miss examples. Using this technique we implemented a graphical debugging tool for use by sketch interface developers.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {210–217},
numpages = {8},
keywords = {shape description, user interfaces, ladder, sketch recognition, near-miss, active learning, structural description},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111496,
author = {Badi, Rajiv and Bae, Soonil and Moore, J. Michael and Meintanis, Konstantinos and Zacchi, Anna and Hsieh, Haowei and Shipman, Frank and Marshall, Catherine C.},
title = {Recognizing User Interest and Document Value from Reading and Organizing Activities in Document Triage},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111496},
doi = {10.1145/1111449.1111496},
abstract = {People frequently must sort through large sets of documents to identify useful materials, for example, when they look through web search results. This document triage process may involve both reading and organizing, possibly using different applications for each activity. Users' interests may be inferred from what they read and how they interact with individual documents; these interests may in turn be used as a basis for identifying other documents or document elements of potential interest within the set. To most effectively identify related documents of interest, activity data must be collected from all applications used in document triage. In this paper we present a common framework (the Interest Profile Manager) for collecting and analyzing user interest. We also present models for detecting user interest based on reading activity alone, on organizing activity alone, and on combined reading and organizing activity. A study comparing document value calculated using the different models shows that incorporating interest information from both reading and organizing activity better predicted users' valuation of documents. This difference was statistically significant when compared to using reading activity alone.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {218–225},
numpages = {8},
keywords = {information triage, visual knowledge builder, user interest recognition, document triage, user interest modeling, sensemaking},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111497,
author = {Lieberman, Henry and Espinosa, Jos\'{e}},
title = {A Goal-Oriented Interface to Consumer Electronics Using Planning and Commonsense Reasoning},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111497},
doi = {10.1145/1111449.1111497},
abstract = {We are reaching a crisis with design of user interfaces for consumer electronics. Flashing 12:00 time indicators, push-and-hold buttons, and interminable modes and menus are all symptoms of trying to maintain a one-to-one correspondence between functions and physical controls, which becomes hopeless as the number of capabilities of devices grows. We propose instead to orient interfaces around the goals that users have for the use of devices.We present Roadie, a user interface agent that provides intelligent context-sensitive help and assistance for a network of consumer devices. Roadie uses a Commonsense knowledge base to map between user goals and functions of the devices, and an AI partial-order planner to provide mixed-initiative assistance with executing multi-step procedures and debugging help when things go wrong.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {226–233},
numpages = {8},
keywords = {consumer electronics, goal-oriented interfaces, planning, commonsense reasoning},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111499,
author = {Felfernig, Alexander and Shchekotykhin, Kostyantyn},
title = {Debugging User Interface Descriptions of Knowledge-Based Recommender Applications},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111499},
doi = {10.1145/1111449.1111499},
abstract = {The complexity of product assortments offered by e-Commerce platforms requires intelligent sales assistance systems alleviating the retrieval of solutions fitting to the wishes and needs of a customer. Knowledge-based recommender applications meet these requirements by allowing the calculation of personalized solutions based on an explicit representation of product, marketing and sales knowledge stored in an underlying recommender knowledge base. Unfortunately, in many cases faulty models of recommender user interfaces are defined by knowledge engineers and no automated support for debugging such process designs is available. This paper presents an approach to automated debugging of faulty process designs of knowledge-based recommenders which increases the productivity of user interface development and maintenance. The approach has been implemented for a knowledge-based recommender environment within the scope of the Koba4MS project.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {234–241},
numpages = {8},
keywords = {knowledge-based recommenders, knowledge acquisition, personalization, diagnosis},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111500,
author = {Hijikata, Yoshinori and Ohno, Hanako and Kusumura, Yukitaka and Nishida, Shogo},
title = {Social Summarization of Text Feedback for Online Auctions and Interactive Presentation of the Summary},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111500},
doi = {10.1145/1111449.1111500},
abstract = {Buyers in online auctions write feedback comments to the sellers from whom the buyers have bought the items. Other bidders read them to determine which item to bid for. In this research, we aim at helping bidders by summarizing the feedback comments. Firstly, we examine feedback comments in online auctions. From the results of the examination, we propose a method called social summarization method, which uses social relationships in online auctions for summarizing feedback comments. We implement a system based on our method and evaluate its effectiveness. Finally, we propose an interactive presentation method of the summaries based on the result of the evaluation.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {242–249},
numpages = {8},
keywords = {social summarization method, feedback comments, text summarization, online auction, social relationship},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111501,
author = {Price, Bob and Greiner, Russ and H\"{a}ubl, Gerald and Flatt, Alden},
title = {Automatic Construction of Personalized Customer Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111501},
doi = {10.1145/1111449.1111501},
abstract = {Interface personalization can improve a user's performance and subjective impression of interface quality and responsiveness. Personalization is difficult to implement as it requires an accurate model of a user's intentions and a formal model of how an interface meets a user's need. We present a novel model for tractable inference of consumer intentions in the context of grocery shopping. The model makes unique use of a priori temporal relations to simplify inference. We then present a simple interface generation framework that was inspired by viewing user interface interaction as a channel coding problem. The resulting model defines a simplified but clear notion of a user's utility for an interface. We demonstrate the effectiveness of the research prototype on some simple data, and explain how the model can be augmented with richer user modeling to create a deployable application.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {250–257},
numpages = {8},
keywords = {e-commerce, interface cost models, interface personalization, online grocery shopping, particle filters, temporal demand models},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/3259619,
title = {Session Details: Short Papers},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259619},
doi = {10.1145/3259619},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111503,
author = {Ludwig, Bernd and Mandl, Stefan and von Mammen, Sebastian},
title = {What's on Tonight: User-Centered and Situation-Aware Proposals for TV Programmes},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111503},
doi = {10.1145/1111449.1111503},
abstract = {This paper presents an approach to exploit free text descriptions of TV programmes as available from EPG data sets for a TV recommender system that takes the content of programmes into account. The paper focuses on the natural language understanding problem underlying the analysis of free text descriptions and on methods of classifying free text descriptions with respect to a natural language user query. We close with an evaluation of user acceptance and a discussion of future work.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {258–260},
numpages = {3},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111504,
author = {Dragone, Mauro and Holz, Thomas and O'Hare, Gregory M.P.},
title = {Mixing Robotic Realities},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111504},
doi = {10.1145/1111449.1111504},
abstract = {This paper contests that Mixed Reality (MR) offers a potential solution in achieving transferability between Human Computer Interaction (HCI) and Human Robot Interaction (HRI). Virtual characters (possibly of a robotic genre) can offer highly expressive interfaces that are as convincing as a human, are comparably cheap and can be easily adapted and personalized. We introduce the notion of a mixed reality agent, i.e. an agent consisting of a physical robotic body and a virtual avatar displayed upon it. We realized an augmented reality interface with a Head-Mounted Display (HMD) in order to interact with such systems and conducted a pilot study to demonstrate the usefulness of mixed reality agents in human-robot collaborative tasks.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {261–263},
numpages = {3},
keywords = {autonomous agents, mixed reality agents, augmented reality, human-robot interaction, intelligent user interface},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111505,
author = {Florins, Murielle and Simarro, Francisco Montero and Vanderdonckt, Jean and Michotte, Benjamin},
title = {Splitting Rules for Graceful Degradation of User Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111505},
doi = {10.1145/1111449.1111505},
abstract = {This paper addresses the problem of the graceful degradation of user interfaces where an initial interface is transferred to a smaller platform. It presents a technique for pagination of interaction spaces (e.g., windows, dialog boxes, web pages) based on a multi-layer specification in the user interface description language UsiXML. We first describe how an interaction space can be split using information from the presentation layer (Concrete User Interface). We then show how information from higher abstraction levels (Abstract user Interface, Task model) can be used to refine the process. This technique belongs to a collection of transformation rules that have been developed to adapt a user interface to smaller, more constrained displays.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {264–266},
numpages = {3},
keywords = {multiplatform systems, design, splitting rules, graceful degradation, pagination, user interface extensible markup language},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111506,
author = {McCarthy, Kevin and Salam\'{o}, Maria and Coyle, Lorcan and McGinty, Lorraine and Smyth, Barry and Nixon, Paddy},
title = {Group Recommender Systems: A Critiquing Based Approach},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111506},
doi = {10.1145/1111449.1111506},
abstract = {Group recommender systems introduce a whole set of new challenges for recommender systems research. The notion of generating a set of recommendations that will satisfy a group of users, with potentially competing interests, is challenging in itself. In addition to this we must consider how to record and combine the preferences of many different users as they engage in simultaneous recommendation dialogs. In this paper we introduce a group recommender system that is designed to provide assistance to a group of friends trying to plan a skiing vacation.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {267–269},
numpages = {3},
keywords = {group recommendation, critiquing, preference harvesting},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111507,
author = {Ding, Yun and Litz, Heiner},
title = {Creating Multiplatform User Interfaces by Annotation and Adaptation},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111507},
doi = {10.1145/1111449.1111507},
abstract = {This paper presents our novel framework, which creates user interfaces (UIs) for a variety of devices by annotating and reusing an existing one originally designed for large devices. It distinguishes itself from previous work by the unique combination of reusing existing UIs, intuitive graphical support and adaptation-based approach. It is extensible by supporting UI developers to build and integrate their customized transformation strategies into our framework.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {270–272},
numpages = {3},
keywords = {single-authoring techniques, multiplatform user interface development tool},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111508,
author = {Gon\c{c}alves, Daniel and Jorge, Joaquim A.},
title = {Evaluating Stories in Narrative-Based Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111508},
doi = {10.1145/1111449.1111508},
abstract = {Traditional ways to help users organize and retrieve their documents don't scale well, nor do they properly handle non-textual documents. This paper evaluates narrative-based interfaces as a natural and effective alternative for document retrieval. We have identified what shape document-describing stories take, and what contents to expect. This led to an interface that is able to capture stories, and a knowledge-based infrastructure to understand them. A prototype of the interface was used to validate narrative-based interfaces, with emphasis on story accuracy. To this end, we collected thirty stories whose contents were then compared to the documents they portrayed. Results allow us to conclude that, for the most part, such stories are trustworthy enough to allow humans to retrieve documents reliably (81%-91% of all information is correct). We also confirmed that stories told to a computer are similar to those told to human interviewers.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {273–275},
numpages = {3},
keywords = {personal information management, knowledge-based interfaces, narrative-based document retrieval},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111509,
author = {Trnka, Keith and Yarrington, Debra and McCoy, Kathleen and Pennington, Christopher},
title = {Topic Modeling in Fringe Word Prediction for AAC},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111509},
doi = {10.1145/1111449.1111509},
abstract = {Word prediction can be used for enhancing the communication ability of persons with speech and language impairments. In this work, we explore two methods of adapting a language model to the topic of conversation, and apply these methods to the prediction of fringe words.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {276–278},
numpages = {3},
keywords = {AAC, language modeling, topic modeling, word prediction},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111510,
author = {Colineau, Nathalie and Phalip, Julien and Lampert, Andrew},
title = {The Delivery of Multimedia Presentations in a Graphical User Interface Environment},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111510},
doi = {10.1145/1111449.1111510},
abstract = {A major issue in many domains is to present information to people that is tailored to their need, in such a way that it supports them in their tasks. In this paper, we present the Virtual Document Planner (VDP), a platform we developed for generating tailored interactive multimedia presentations in the surveillance domain. Integrated with the surveillance operators' graphical interface, the VDP provides tailored information delivery mechanisms that adapt the operators' information rich environment to their tasks and information needs.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {279–281},
numpages = {3},
keywords = {tailored information delivery, discourse approach, multimedia presentation generation, task-sensitive user interface},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111511,
author = {Costello, Edwin and Doody, John and McGinty, Lorraine and Smyth, Barry},
title = {<i>I</i>CARE: Intelligent Customer Assistance for Recommending Eyewear},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111511},
doi = {10.1145/1111449.1111511},
abstract = {Consumers are often overwhelmed by the range of product choices available, especially online, and recommender systems have emerged as an important tool for helping users to navigate through complex product spaces based on their preferences. In this paper we describe work that concentrates on how research ideas from two complimentary research communities (recommender systems and intelligent user interfaces) can be married to improve online recommender systems. In particular, we are interested in content-based recommendation domains that rely heavily on explicit feature-level feedback from users. Oftentimes this type of feedback is difficult for users to provide and we look at how this might be addressed through product visualization techniques in this paper, focusing on the iCARE System for recommending suitable eyeglasses to individual users.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {282–284},
numpages = {3},
keywords = {e-Commerce applications, intelligent user interfaces, preference elicitation, conversational recommendation},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111512,
author = {Hilliges, Otmar and Sandor, Christian and Klinker, Gudrun},
title = {Interactive Prototyping for Ubiquitous Augmented Reality User Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111512},
doi = {10.1145/1111449.1111512},
abstract = {User interfaces for ubiquitous augmented reality incorporate a wide variety of concepts such as multi-modal, multi-user, multi-device aspects and new input/output devices. In this paper we present a twofold approach that consists of an execution engine for ubiquitous augmented reality user interfaces and a runtime development environment that enables rapid prototyping and live system adaption for such advanced user interfaces.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {285–287},
numpages = {3},
keywords = {augmented reality, tangible user interfaces, multi-modal, ubiquitous computing, software architectures, multi-user, visual programming},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111513,
author = {Szilas, Nicolas and Kavakli, Manolya},
title = {PastMaster@storytelling: A Controlled Interface for Interactive Drama},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111513},
doi = {10.1145/1111449.1111513},
abstract = {In this paper, we describe a controlled interface for Interactive Drama, PastMaster@Storytelling. PastMaster is used for interacting with an Interactive Drama engine. The paper discusses the test results regarding the usability of the interface.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {288–290},
numpages = {3},
keywords = {usability study, interaction history, interactive drama, adaptive interfaces, interactive narrative},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111514,
author = {Jacobsson, Mattias and Rost, Mattias and Holmquist, Lars Erik},
title = {When Media Gets Wise: Collaborative Filtering with Mobile Media Agents},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111514},
doi = {10.1145/1111449.1111514},
abstract = {We present a mode where media (e.g.music files) are autonomous entities that carry their own individua information. Our goal is to turn such files into autonomous, rule-following agents capable of building their own identities from interactions with other agents and users. We are exploring how collaborative filtering-like behaviour could emerge out of large ensembles of interacting agents, which are distributed over mobile devices in socia networks. We have implemented a first version of the mode in the form of a music player application for mobile devices, called Push!Music. This system takes advantage of active recommendations as we as implicit user activity to build a profile for each media file.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {291–293},
numpages = {3},
keywords = {media ecologies, active recommendation, distributed collaborative filtering, emergence, media agents},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111515,
author = {Yang, Fan and Baber, Christopher},
title = {MapTable: A Tactical Command and Control Interface},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111515},
doi = {10.1145/1111449.1111515},
abstract = {This paper describes a novel tabletop interface, MapTable, which can be used as a tactical command and control interface. It is designed and implemented to explore more intelligent and intuitive interaction in a distributed environment that can support remote collaboration. MapTable offers a common space for planners to work, which retains the intuitive feel of a "sandbox" around which discussion can take place and plans easily displayed, whilst the automated navigation command system means that both planning and the issuing of directions can effectively be merged into a single activity using a single user interface that embeds the tasks into the interaction. Empirical studies were conducted to test this tactical interface in a remote searching task environment. Compared to the traditional desktop command and control interface, MapTable can lead to significant differences in performance. This fusion of planning, command and control means that planners can be expected have a high level of situational awareness with regard to where those they are directing are, where they will be and what others in the team are doing.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {294–296},
numpages = {3},
keywords = {distributed collaboration, command and control},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111516,
author = {Errico, James H. and Sezan, Ibrahim},
title = {Presence Based Collaborative Recommender for Networked Audiovisual Displays},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111516},
doi = {10.1145/1111449.1111516},
abstract = {In this paper, we describe a presence based collaborative recommender (PBCR) system for networked audiovisual (AV) displays such as Internet connected TV sets with access to broadcast TV programs over traditional channels, video on demand, and Internet Protocol (IP) AV programs. The proposed PBCR system is based on presence technology and provides viewers with collaborative recommendations on AV programs based on presence or ratings of users within viewer's community.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {297–299},
numpages = {3},
keywords = {recommender, presence, collaboration},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111517,
author = {Goto, Jun and Miyazaki, Masaru and Kobayakawa, Takeshi and Hiruma, Nobuyuki and Uratani, Noriyoshi},
title = {A TV Agent System That Integrates Knowledge and Answers Users' Questions},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111517},
doi = {10.1145/1111449.1111517},
abstract = {Aiming to close the digital divide in the television viewing environment, we are developing a TV system with an agent that controls the TV and peripherals on behalf of the user and provides information to the user. We propose a TV system function that answers viewers' questions about TV programs by calling upon multiple question-answering agents that search for relevant information.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {300–302},
numpages = {3},
keywords = {TV, agent, question answering},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111518,
author = {Shaikh, Mostafa Al Masum and Helmut, Prendinger and Ishizuka, Mitsuru},
title = {A Cognitively Based Approach to Affect Sensing from Text},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111518},
doi = {10.1145/1111449.1111518},
abstract = {Studying the relationship between natural language and affective information as well as assessing the underpinned affective qualities of natural language are becoming crucial for improving human computer interaction. Different approaches have already been employed to "sense" affective information from text but none of those considered the cognitive structure of individual emotions and appraisal structure of those emotions adopted by emotion sensing programs. It has also been observed that previous attempts for textual affect sensing have categorized texts into a number of emotion groups, e.g. six so-called "basic" emotion proposed by Paul Ekman which we believe insufficient to classify textual emotions. Hence we propose a different approach to sense affective information from texts by applying the cognitive theory of emotions known as OCC model [1] which distinguishes several emotion types that can be identified by assessing valenced reactions to events, agents or objects described in the texts. In particular we want to create a formal model that can not only "understand" what emotions people wrap with their textual messages, but also can make automatic empathic response with respect to the emotional state detected in the text (e.g. in a chat system). We first briefly describe relevant works and then we explain our proposal with examples. Finally we conclude with future work plans.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {303–305},
numpages = {3},
keywords = {computational humor, affective UI, emotions, affective computing, OCC model, affective chat},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111519,
author = {Komatsu, Takanori},
title = {Audio Subtle Expressions Affecting User's Perceptions},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111519},
doi = {10.1145/1111449.1111519},
abstract = {Can we assign attitudes to an artifact based on its expressed beep sounds as audio subtle expressions? If so, which kinds of beep sounds are perceived as specific attitudes, such as "disagreement" as a negative attitude, "hesitation" as neutral or "agreement" as positive? To examine this issue, I carried out an experiment to observe and clarify how participants assign an attitude to an artifact according to beeps of different durations and F0 values. The results revealed that 1) sounds with rising tones regardless of duration were perceived by participants as "disagreement," and 2) flat sounds with longer duration were interpreted as "hesitation", and 3) falling tones with shorter duration were taken as "agreement".},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {306–308},
numpages = {3},
keywords = {affective computing, prosody, subtle expressions, beeps},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111520,
author = {Clerckx, Tim and Vandervelpen, Chris and Luyten, Kris and Coninx, Karin},
title = {A Task-Driven User Interface Architecture for Ambient Intelligent Environments},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111520},
doi = {10.1145/1111449.1111520},
abstract = {This paper presents a modular runtime architecture supporting our model-based user interface design approach for designing context-aware, distributable user interfaces for ambient intelligent environments.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {309–311},
numpages = {3},
keywords = {task-based user interface design, ambient intelligence, distributed user interfaces, DynaMo-AID},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111521,
author = {Kumar, Mithilesh and Gupta, Akhilesh and Saha, Sharad},
title = {An Approach to Adaptive User Interfaces Using Interactive Media Systems},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111521},
doi = {10.1145/1111449.1111521},
abstract = {Adaptive interfaces are a promising attempt to overcome contemporary problems due to the increasing complexity of human-computer interaction. They are designed to tailor a system's interactive behavior with consideration of individual needs of human users and altering conditions within an application environment. For building adaptive user interfaces, we developed a system that interacts with users in a variety of terminals. The system has three categories. First we have MPEG-4 Binary Format for Scenes(BIFS) [5,6] for creating interactive media. The second category is the adaptor chain which brings about a user interface depending upon user preferences, terminal capabilities and network constraints. The third category is the iPlayer or Interactive Player that plays the transferred media data and interacts with the user. The player, when implemented finally, operates on Win32, WinCE and Linux and plays MPEG-4 video and MP3 audio.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {312–314},
numpages = {3},
keywords = {human computer interaction, MPEG-4, usability, context awareness, adaptive user interfaces, interactive media},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111522,
author = {Thomas, Kavita and Proske, Pierre and Rickardsson, Mattias},
title = {Intelligent Fridge Poetry Magnets},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111522},
doi = {10.1145/1111449.1111522},
abstract = {This paper presents a community of communicating embodied agents which learn an adjacency-based grammar from user interactions. The agents act as intelligent fridge magnets, each printing a word on their respective displays. The user places agents next to other agents on the fridge, removing and replacing them if the word they display is ungrammatical given the current context, thereby indicating grammatical acceptability. We present these agents both as a test bed for exploring research into embodied communicating agents and as a means of investigating how users respond to expressive devices like fridge poetry magnets which learn from user interaction.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {315–317},
numpages = {3},
keywords = {interaction-based grammar-learning, user interaction, expressive user-interfaces, intelligent agents, embodied communicating agents},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111523,
author = {Tang, Lijun and Kender, John R.},
title = {Designing an Intelligent User Interface for Instructional Video Indexing and Browsing},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111523},
doi = {10.1145/1111449.1111523},
abstract = {Instructional videos are used intensively in universities for remote education and e-learning, and a typical university course consists of videos of more than two thousand minutes in total length. This paper presents a novel graphics user interface for indexing and browsing such extensive but thematically related content. We present how the interface automatically extracts semantic indices from the visual content, and then presents both high- and low-level cues from five different conceptual viewpoints. We detail each of these novel UI units, and show how they are integrated into a user-adjustable main framework, and interconnected and navigated through user mouse events.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {318–320},
numpages = {3},
keywords = {video browsing, video visualization, video indexing, user interface},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111524,
author = {Richards, Debbie and Szilas, Nicolas},
title = {Training a Training System},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111524},
doi = {10.1145/1111449.1111524},
abstract = {We are interested in using game technology to provide an engaging and immersive environment for experiential learning of workplace situations. Narrative intelligence will be used to provide the adventure. For authoring we provide an adaptive interface that allows the direct capture of the workplace situations and the knowledge driving the interaction. We include an initial study comparing the learning outcomes for an animated demonstration with video footage of a similar scenario.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {321–323},
numpages = {3},
keywords = {adaptive interfaces, knowledge based systems, animation, narrative intelligence, training},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111525,
author = {Wang, Xugang and Li, Junfeng and Ao, Xiang and Wang, Gang and Dai, Guozhong},
title = {Multimodal Error Correction for Continuous Handwriting Recognition in Pen-Based User Interfaces},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111525},
doi = {10.1145/1111449.1111525},
abstract = {In this paper, we describe a multimodal error correction mechanism. It allows the user to correct errors in continuous handwriting recognition naturally by simultaneously using pen gesture and speech. A multimodal fusion algorithm is designed to enhance recognition accuracies of handwriting and speech through cross-modal influence. We have performed preliminary evaluation experiments and the results show that this multimodal mechanism can efficiently correct the errors in continuous handwriting recognition.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {324–326},
numpages = {3},
keywords = {multimodal fusion, pen-based user interface, speech recognition, handwriting recognition},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111526,
author = {Bridle, Robert and McCreath, Eric},
title = {Inducing Shortcuts on a Mobile Phone Interface},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111526},
doi = {10.1145/1111449.1111526},
abstract = {Due to size restrictions, mobile phone user interfaces are often difficult to use[8]. In this short paper, we investigated inducing shortcuts to replace the sequence of actions required to complete common tasks on a mobile phone. In particular, we used mobile phone interaction data to evaluate several methods for inducing shortcuts. We considered the balance between maximising interface efficiency and shortcuts that remained stable and hence predictable.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {327–329},
numpages = {3},
keywords = {mobile phone interfaces, adaptive user-interface, user oriented machine learning},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111527,
author = {Imoto, Kazunori and Sasajima, Munehiko and Shimomori, Taishii and Yamanaka, Noriko and Yajima, Makoto and Masai, Yasuyuki},
title = {A Multi Modal Supporting Tool for Multi Lingual Communication by Inducing Partner's Reply},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111527},
doi = {10.1145/1111449.1111527},
abstract = {This paper introduces a new tool for supporting multilingual communication between speakers of different languages. Conventional tools such as electronic dictionaries enable users to communicate basic intentions to others, but are often insufficient to help understand replies. The input of a Japanese sentence in the proposed tool not only produces a translation of the sentences but also displays a window featuring possible answers. The authors have evaluated the function of a prototype system which resulted in a thorough understanding of the merits and comings of the proposed tool.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {330–332},
numpages = {3},
keywords = {retrieving meaning-equivalent sentences, answer induction, translation, speech processing},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111528,
author = {Breton, Gaspard and Pel\'{e}, Danielle and Garcia, Christophe},
title = {Modeling Gaze Behavior for a 3D ECA in a Dialogue Situation},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111528},
doi = {10.1145/1111449.1111528},
abstract = {This paper presents an approach to model the gaze behavior of an Embodied Conversational Agent in a real time multimodal dialogue interaction with users. The ECA's gaze control results from the fusion of a rational dialogue engine based on natural language interaction and a multi-users face tracker.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {333–335},
numpages = {3},
keywords = {face tracking, dialogue, 3D ECA, gaze behavior},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111529,
author = {Wasinger, Rainer and Kr\"{u}ger, Antonio},
title = {Modality Preferences in an Instrumented Environment},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111529},
doi = {10.1145/1111449.1111529},
abstract = {In this paper, we describe the results of a usability study on user preferences for multimodal interaction in an instrumented environment. The study was conducted in a public setting, and provides insight into modality preferences among users, and specific to among men and women. The returned results are also contrasted to the results of a former study based on the same evaluation procedures but conducted under a laboratory setting.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {336–338},
numpages = {3},
keywords = {multimodal interaction, ubiquitous computing, mobile},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111530,
author = {Khiat, Abdelaziz and Toyota, Masataka and Matsumoto, Yoshio and Ogasawara, Tsukasa},
title = {Investigating the Relation between Robot Bodily Expressions and Their Impression on the User},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111530},
doi = {10.1145/1111449.1111530},
abstract = {During an interaction process, people usually adapt their behavior according to the interpretation of their partner's bodily expressions. It is not known how much similar expressions performed by robots affect a human observer. This paper explores this issue. The study shows a correlation between the nature of the bodily expressions, through the result of questionnaires, and the effect on brain activity. It has been demonstrated that unpleasant bodily expressions of the robot elicit unpleasant impressions and vice versa. This was observed through brain activity in a specific area when the expression is pleasant, and in another area when it is unpleasant.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {339–341},
numpages = {3},
keywords = {robot impression, brain activity, bodily expression},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111531,
author = {Xiang, Peifeng and Shi, Yuanchun},
title = {Recovering Semantic Relations from Web Pages Based on Visual Cues},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111531},
doi = {10.1145/1111449.1111531},
abstract = {Recovering semantic relations between different parts of web pages are of great importance for multi-platform web interface development, as they make it possible to re-distribute interaction objects and change the structure of interfaces while preserving the semantics of the UI. Important semantic relations include topic, order, hierarchy, etc. This paper presents a visual cues based approach, which is tag-tree structure independent, to automatically detect such kind of semantic relations in web pages. Comparing with other existing techniques, such as DOM-based methods, this approach mostly depends on interfaces' perceptible visual information that is more reliable. The preliminary evaluation on complex web sites shows promising results. We believe further exploration is worth taken.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {342–344},
numpages = {3},
keywords = {semantic relation, pattern, visual cues, user interface},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111532,
author = {Stumpfel, Jessi and Arvo, James and Novins, Kevin},
title = {Geometric Anticipation: Assisting Users in 2D Layout Tasks},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111532},
doi = {10.1145/1111449.1111532},
abstract = {We describe an experimental interface that anticipates a user's intentions and accommodates predicted changes in advance. Our canonical example is an interactive version of ``magnetic poetry'' in which rectangular blocks containing single words can be juxtaposed to form arbitrary sentences or ``poetry.'' The user can rearrange the blocks at will, forming and dissociating word sequences. A crucial attribute of the blocks in our system is that they anticipate insertions and gracefully rearrange themselves in time to make space for a new word or phrase. The challenges in creating such an interface are three fold: 1) the user's intentions must be inferred from noisy input, 2) arrangements must be altered smoothly and intuitively in response to anticipated changes, and 3) new and changing goals must be handled gracefully at any time, even in mid animation. We describe a general approach for handling the dynamic creation and deletion of organizational goals. Fluid motion is achieved by continually applying and correcting goal-directed forces to the objects. Future applications of this idea include the manipulation of text and graphical elements within documents and the manipulation of symbolic information such as equations.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {345–347},
numpages = {3},
keywords = {computer interface, anticipatory interface, fluid motion, eager recognition},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111533,
author = {Lee, Chia-Hsun Jackie and Bonanni, Leonardo and Espinosa, Jose H. and Lieberman, Henry and Selker, Ted},
title = {Augmenting Kitchen Appliances with a Shared Context Using Knowledge about Daily Events},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111533},
doi = {10.1145/1111449.1111533},
abstract = {Networked appliances might make them aware of each other, but interacting with a complex network can be difficult in itself. KitchenSense is a sensor rich networked kitchen research platform that uses Common Sense reasoning to simplify control interfaces and augment interaction. The system's sensor net attempts to interpret people's intentions to create fail-soft support for safe, efficient and aesthetic activity. By considering embedded sensor data together with daily-event knowledge, a centrally-controlled system can develop a shared context across various appliances. The system is a research platform that is used to evaluate augmented intelligent support of work scenarios in physical spaces.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {348–350},
numpages = {3},
keywords = {commonsense reasoning, shared context, kitchen, intelligent environments, home appliances, daily events},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111534,
author = {Taib, Ronnie and Ruiz, Natalie},
title = {Multimodal Interaction Styles for Hypermedia Adaptation},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111534},
doi = {10.1145/1111449.1111534},
abstract = {We explore the concept of interaction styles used to navigate through hypermedia systems. A demonstrator was built to conduct a user study with the objective of detecting whether any interaction pattern exists in relation to input modality choices. Our lightweight server-side web demonstrator is able to adapt output modalities as a function of input received from the user. The interface and content displayed are built from predefined presentation schemes that attempt to optimize the user's experience and website's functionality. The results suggest that some levels of entrenchment do occur with reference to modality choices, with 45% of participants deviating from their preferred pattern in one or less interaction turns.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {351–353},
numpages = {3},
keywords = {multimodal interaction, user adaptive interfaces, web design},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111535,
author = {Cai, Guoray and Xue, Yinkun},
title = {Activity-Oriented Context-Aware Adaptation Assisting Mobile Geo-Spatial Activities},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111535},
doi = {10.1145/1111449.1111535},
abstract = {Human geospatial activities often involves the use of geographic information in mobile environment where the context of technology use is dynamic, complex, and unstable, creating unique challenges in designing effective mobile mapping applications. Enhancing the context awareness of the computing device can improve the usability of mobile map applications, but the potentially large number of contexts (physical context, computing context, human factors, and time) are not easily managed without a workable organizing structure. This paper proposes an activity-oriented context model that establish late (run-time) binding of contexts to the ongoning avtivity according to how they contribute to the success of the activity. Using this context model, adaptation of mobile map display to the changes of other contexts is based on the knowledge of ongoing task (within an activity) rather anticipated tasks. We discuss advantages of such an approach over traditional template-based model of context models in mobile computing applications.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {354–356},
numpages = {3},
keywords = {collaborative plans, context-awareness, activity model},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111536,
author = {Stumptner, Markus and Thomas, Bruce},
title = {Constraint-Based Livespaces Configuration Management},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111536},
doi = {10.1145/1111449.1111536},
abstract = {In this paper, we describe use of constraint-based methods for configuring ubiquitous workspaces. A declarative representation allows succinct, easily maintainable definitions of the dependencies inherent in setting up a meeting, and permits the use of general constraint reasoners for various standard tasks such as setting up meeting interfaces, switching between setting for different meetings, and saving and restoring settings. Personalisation techniques can be used for intelligently adapting the workspace to individual user needs.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {357–359},
numpages = {3},
keywords = {ubiquitous workspaces, liveSpaces, constraint satisfaction, configuration},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111537,
author = {Leuski, Anton and Pair, Jarrell and Traum, David and McNerney, Peter J. and Georgiou, Panayiotis and Patel, Ronakkumar},
title = {How to Talk to a Hologram},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111537},
doi = {10.1145/1111449.1111537},
abstract = {There is a growing need for creating life-like virtual human simulations that can conduct a natural spoken dialog with a human student on a predefined subject. We present an overview of a spoken-dialog system that supports a person interacting with a full-size hologram-like virtual human character in an exhibition kiosk settings. We also give a brief summary of the natural language classification component of the system and describe the experiments we conducted with the system.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {360–362},
numpages = {3},
keywords = {spoken dialog, text classification},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111538,
author = {Ferguson, Ronald W. and Cutshaw, Neil and Zafar, Huzaifa},
title = {Intelligent Drawing Correction Using Place Vocabulary Constraints},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111538},
doi = {10.1145/1111449.1111538},
abstract = {Diagrams used in many domains often require continual redrawing. Diagram drawing programs often aid redrawing by applying secondary corrections that change visual elements to maintain preexisting relationships. These corrections, though useful, can operate in unintuitive ways and cause disfluencies. We describe an implemented prototype system that improves corrections based on place vocabularies (domain-specific spatial relation sets). Place vocabulary constraints (PVCs) translate high-level place vocabularies into low-level geometric constraints by reversing pre-existing recognition rules. By making corrections congruent with a domain vocabulary, PVCs may provide more intuitive drawing corrections.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {363–365},
numpages = {3},
keywords = {qualitative spatial representation, diagrammatic reasoning},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111539,
author = {Wang, Hua and Chignell, Mark and Ishizuka, Mitsuru},
title = {Are Two Talking Heads Better than One? When Should Use More than One Agent in e-Learning?},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111539},
doi = {10.1145/1111449.1111539},
abstract = {Recent interest in the use of software character agents raises the issue of how many agents should be used in online learning. In this paper we review evidence concerning the relative effectiveness of multi-agent systems and introduce a multiple agent system that we have developed for online instruction. A user test is carried out that compares one and two agent versions of the learning system. The results are interpreted in terms of their implications for selecting when and how more than one agent should be used in online learning. We conclude with some recommendations on when multiple agents may help online learners to interact with the learning environment more easily and efficiently.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {366–368},
numpages = {3},
keywords = {e-learning, educational interface, eye tracking, multiple agents, tracing, character agent},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111540,
author = {Gandhe, Sudeep and Gordon, Andrew S. and Traum, David},
title = {Improving Question-Answering with Linking Dialogues},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111540},
doi = {10.1145/1111449.1111540},
abstract = {Question-answering dialogue systems have found many applications in interactive learning environments. This paper is concerned with one such application for Army leadership training, where trainees input free-text questions that elicit pre-recorded video responses. Since these responses are already crafted before the question is asked, a certain degree of incoherence exists between the question that is asked and the answer that is given. This paper explores the use of short linking dialogues that stand in between the question and its video response to alleviate the problem of incoherence. We describe a set of experiments with human generated linking dialogues that demonstrate their added value. We then describe our implementation of an automated method for utilizing linking dialogues and show that these have better coherence properties than the original system without linking dialogues.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {369–371},
numpages = {3},
keywords = {coherence, training, question-answering dialogue systems},
location = {Sydney, Australia},
series = {IUI '06}
}

@inproceedings{10.1145/1111449.1111541,
author = {Barrington, Luke and Lyons, Michael J. and Diegmann, Dominique and Abe, Shinji},
title = {Ambient Display Using Musical Effects},
year = {2006},
isbn = {1595932879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1111449.1111541},
doi = {10.1145/1111449.1111541},
abstract = {The paper presents a novel approach to the peripheral display of information by applying audio effects to an arbitrary selection of music. We examine a specific instance: the communication of information about human affect, and construct a functioning prototype which captures behavioral activity level from the face and maps it to musical effects. Several audio effects are empirically evaluated as to their suitability for ambient display. We report measurements of the ambience, perceived affect, and pleasure of these effects. The findings support the hypothesis that musical effects are a promising method for ambient informational display.},
booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
pages = {372–374},
numpages = {3},
keywords = {ambient display, musical interface, affective computing},
location = {Sydney, Australia},
series = {IUI '06}
}

