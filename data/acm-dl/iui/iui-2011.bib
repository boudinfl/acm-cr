@inproceedings{10.1145/3253014,
author = {Riecken, Doug},
title = {Session Details: Keynote Address},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253014},
doi = {10.1145/3253014},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943405,
author = {Horvitz, Eric},
title = {Bricks, Arches, and Cathedrals: Reflections on Paths to Deeper Human-Computer Symbioses},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943405},
doi = {10.1145/1943403.1943405},
abstract = {I will share thoughts about achievements to date and opportunities moving forward on harnessing advances in machine intelligence to enable new forms of competent and fluid human-computer collaboration. I will discuss the promise of assembling key building blocks of methods in machine perception, learning, and inference into larger integrative solutions that draw upon a symphony of skills and that operate over extended periods of time. Explorations of such integrative machine intelligence frames research on the coordination of multiple components for sensing and reasoning to create higher-level functionalities and abstractions. I will discuss the promise of these efforts to advance us toward realizing dreams of deeper human-computer symbioses as imagined by such visionaries as Licklider and Engelbart.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {1},
numpages = {1},
keywords = {multimodal interfaces, mixed-initiative interaction, complementary computing, augmented cognition, user modeling, integrative artificial intelligence, conversational systems},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253015,
author = {M\"{u}ller, Christian},
title = {Session Details: Handheld Devices},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253015},
doi = {10.1145/3253015},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943407,
author = {Okoye, Ifeyinwa and Mahmud, Jalal and Lau, Tessa and Cerruti, Julian},
title = {Find This for Me: Mobile Information Retrieval on the Open Web},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943407},
doi = {10.1145/1943403.1943407},
abstract = {With all the information available on the web, there is a growing need to provide mobile access to this information for the large, growing population of mobile internet users. In this paper, we propose a solution to the problem of open web mobile information retrieval, by conducting a dialogue with the user over a simple text-based interface. Using techniques from NLP, web page analysis, and information extraction, our approach automatically navigates web sites on the user's behalf and extracts specific information from those sites to present to the user textually. Empirical evaluation shows that our approach to open web information retrieval is feasible, and a qualitative evaluation validates that such a system meets user needs for mobile information access.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {3–12},
numpages = {10},
keywords = {mobile web, information retrieval, information extraction, NLP},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943408,
author = {Bourke, Steven and McCarthy, Kevin and Smyth, Barry},
title = {The Social Camera: A Case-Study in Contextual Image Recommendation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943408},
doi = {10.1145/1943403.1943408},
abstract = {The digital camera revolution has changed the world of photography and now most people have access to, and even regularly carry, a digital camera. Often these cameras have been designed with simplicity in mind: they harness a variety of sophisticated technologies in order to automatically take care of all manner of complex settings (aperture, shutter speed, flash etc.) for point-and-shoot ease, these assistive features are usually incorporated directly into the cameras interface. However, there is little or no support for the end-user when it comes to helping them to compose or frame a scene. To this end we describe a novel recommendation process which uses a variety of intelligent and assistive interfaces to guide the user in taking relevant compositions given their current location and scene context. This application has been implemented on the Android platform and we describe its core user interaction, recommendation technologies and demonstrate its effectiveness in a number of real-world scenarios. Specifically we report on the results of a live-user trial of the technology in a real-world tourist setting.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {13–22},
numpages = {10},
keywords = {user interaction, social camera, social, camera, photography, composition, recommender system, mobile, interface},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943409,
author = {Song, Wei and Finch, Andrew Michael and Tanaka-Ishii, Kumiko and Sumita, Eiichiro},
title = {PicoTrans: An Icon-Driven User Interface for Machine Translation on Mobile Devices},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943409},
doi = {10.1145/1943403.1943409},
abstract = {In this paper we present a novel user interface that integrates two popular approaches to language translation for travelers allowing multimodal communication between the parties involved. In our approach we integrate the popular picture-book, in which the user simply points to multiple picture icons representing what they want to say, with a statistical machine translation system that can translate arbitrary word sequences. The simple pointing at pictures paradigm is used as the primary method of user input and the users can use the device as if it were a picture book. The application is then able to generate a complete sentence in the user's native language for what they wish to say from the sequence of picture icons chosen by the user. Once the user is satisfied that the sentence provided by the system adequately represents what they wish to convey, the application can automatically translate the sentence into the language of the other party, who can interpret the intended meaning of the first party by combining evidence from both modes of communication: the picture sequence, and the machine translation. The prototype system we have developed inherits many of the positive features of both approaches, while at the same time mitigating their main weaknesses. The user may combine the pictures in considerably more combinations than is possible with a picture book designed with combinations from only within the same page spread of the book in mind, making the application more expressive than a book. The machine translation system can contribute a detailed and precise translation which is supported by the picture-based mode which not only provides a rapid method to communicate basic concepts but also gives a 'second opinion' on the machine transition output that catches machine translation errors and allows the users to retry the sentence, avoiding misunderstandings.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {23–32},
numpages = {10},
keywords = {user interfaces, touch screen},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943410,
author = {Nurmi, Petteri and Salovaara, Antti and Bhattacharya, Sourav and Pulkkinen, Teemu and Kahl, Gerrit},
title = {Influence of Landmark-Based Navigation Instructions on User Attention in Indoor Smart Spaces},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943410},
doi = {10.1145/1943403.1943410},
abstract = {Using landmark-based navigation instructions is widely considered to be the most effective strategy for presenting navigation instructions. Among other things, landmark-based instructions can reduce the user's cognitive load, increase confidence in navigation decisions and reduce the number of navigational errors. Their main disadvantage is that the user typically focuses considerable amount of attention on searching for landmark points, which easily results in poor awareness of the user's surroundings. In indoor spaces, this implies that landmark-based instructions can reduce the attention the user pays on advertisements and commercial displays, thus rendering the assistance commercially inviable. To better understand how landmark-based instructions influence the user's awareness of her surroundings, we conducted a user study with $20$ participants in a large national supermarket that investigated how the attention the user pays on her surroundings varies across two types of landmark-based instructions that vary in terms of their visual demand. The results indicate that an increase in the visual demand of landmark-based instructions does not necessarily improve the participant's recall of their surrounding environment and that this increase can cause a decrease in navigation efficiency. The results also indicate that participants generally pay little attention to their surroundings and are more likely to rationalize than to actually remember much from their surroundings. Implications of the findings on navigation assistants are discussed.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {33–42},
numpages = {10},
keywords = {landmarks, user study, navigation, mobile computing},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253016,
author = {Callaway, Charles},
title = {Session Details: Multimodal Interfaces},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253016},
doi = {10.1145/3253016},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943412,
author = {UzZaman, Naushad and Bigham, Jeffrey P. and Allen, James F.},
title = {Multimodal Summarization of Complex Sentences},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943412},
doi = {10.1145/1943403.1943412},
abstract = {In this paper, we introduce the idea of automatically illustrating complex sentences as multimodal summaries that combine pictures, structure and simplified compressed text. By including text and structure in addition to pictures, multimodal summaries provide additional clues of what happened, who did it, to whom and how, to people who may have difficulty reading or who are looking to skim quickly. We present ROC-MMS, a system for automatically creating multimodal summaries (MMS) of complex sentences by generating pictures, textual summaries and structure. We show that pictures alone are insufficient to help people understand most sentences, especially for readers who are unfamiliar with the domain. An evaluation of ROC-MMS in the Wikipedia domain illustrates both the promise and challenge of automatically creating multimodal summaries.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {43–52},
numpages = {10},
keywords = {picture, AAC, ROC MMS, automatic illustration, illustration, sentence compression, MMS, pictorial representation, summarization, visualization, multimodal summarization, text-to-picture, augmentative and alternative communication},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943413,
author = {Gilroy, Stephen W. and Cavazza, Marc O. and Vervondel, Valentin},
title = {Evaluating Multimodal Affective Fusion Using Physiological Signals},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943413},
doi = {10.1145/1943403.1943413},
abstract = {In this paper we present an evaluation of an affective multimodal fusion approach utilizing dimensional representations of emotion. The evaluation uses physiological signals as a reference measure of users' emotional states. Surface electromyography (EMG) and galvanic skin response (GSR) signals are known to be correlated with specific dimensions of emotion (Pleasure and Arousal) and are compared here to real time continuous values of these dimensions obtained from affective multimodal fusion. The results (both qualitative and quantitative) suggest that the particular multimodal fusion approach described is consistent with physiological indicators of emotion, constituting a first positive evaluation of the approach.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {53–62},
numpages = {10},
keywords = {multimodal interfaces, affective interfaces, physiological evaluation},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943414,
author = {Scoditti, Adriano and Blanch, Renaud and Coutaz, Jo\"{e}lle},
title = {A Novel Taxonomy for Gestural Interaction Techniques Based on Accelerometers},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943414},
doi = {10.1145/1943403.1943414},
abstract = {A large variety of gestural interaction techniques based on accelerometers is now available. In this article, we propose a new taxonomic space as a systematic structure for supporting the comparative analysis of these techniques as well as for designing new ones. An interaction technique is plotted as a point in a space where the vertical axis denotes the semantic coverage of the techniques, and the horizontal axis expresses the physical actions users are engaged in, i.e. the lexicon. In addition, syntactic modifiers are used to express the interpretation process of input tokens into semantics, as well as pragmatic modifiers to make explicit the level of indirection between users' actions and system responses. To demonstrate the coverage of the taxonomy, we have classified 25 interaction techniques based on accelerometers. The analysis of the design space per se reveals directions for future research.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {63–72},
numpages = {10},
keywords = {body, multi-modal interfaces, input and interaction technologies, speech etc.), handheld devices and mobile computing, recognition and interpretation of user input (face},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253017,
author = {Lieberman, Henry},
title = {Session Details: Social Computing and Navigation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253017},
doi = {10.1145/3253017},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943416,
author = {Callaway, Charles and Stock, Oliviero and Dekoven, Elyon and Noy, Kinneret and Citron, Yael and Dobrin, Yael},
title = {Mobile Drama in an Instrumented Museum: Inducing Group Conversation via Coordinated Narratives},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943416},
doi = {10.1145/1943403.1943416},
abstract = {Museum visits can be more enjoyable to small groups if they can be both social and educational experiences. One very rewarding aspect of a visit, especially those involving small groups such as families, is the unmediated group discussion that can ensue during a shared cultural experience. We present a museum mobile system that perceives and analyzes group behavior and uses the result to adaptively deliver coordinated dramatic narrative presentations, resulting in the stimulation of group conversation. In particular, our drama-based presentations contain slight differences in content between the two visitors, leveraging the narrative tension/release cycle to naturally lead visitors to fill in missing pieces by interacting with friends and initiate a conversation. As a first step at evaluation, we present a study in a neutral environment centered around the effects of those differences in stories between pairs of participants, showing that listening to narratives with slight differences between them can significantly increase subsequent conversation.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {73–82},
numpages = {10},
keywords = {multimodal presentations, cultural heritage, drama, experimentation, narrative, human factors},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943417,
author = {MacLean, Diana and Hangal, Sudheendra and Teh, Seng Keat and Lam, Monica S. and Heer, Jeffrey},
title = {Groups without Tears: Mining Social Topologies from Email},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943417},
doi = {10.1145/1943403.1943417},
abstract = {As people accumulate hundreds of "friends" in social media, a flat list of connections becomes unmanageable. Interfaces agnostic to social structure hinder the nuanced sharing of personal data such as photos, status updates, news feeds, and comments. To address this problem, we propose social topologies, a set of potentially overlapping and nested social groups, that represent the structure and content of a person's social network as a first-class object. We contribute an algorithm for creating social topologies by mining communication history and identifying likely groups based on co-occurrence patterns. We use our algorithm to populate a browser interface that supports creation and editing of social groups via direct manipulation. A user study confirms that our approach models subjects' social topologies well, and that our interface enables intuitive browsing and management of a personal social landscape.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {83–92},
numpages = {10},
keywords = {social topology, data sharing, social graph, access control},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943418,
author = {Vig, Jesse and Sen, Shilad and Riedl, John},
title = {Navigating the Tag Genome},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943418},
doi = {10.1145/1943403.1943418},
abstract = {Tags help users understand a rich information space, by showing them specific text annotations for each item in the space and enabling them to search by these annotations. Often, however, users may wish to move from one item to other items that are similar overall, but that differ in key characteristics. For example, a user who loves Pulp Fiction might want to see a similar movie, but might be in a mood for a less "dark" movie. This paper introduces Movie Tuner, a novel interface that supports navigation from one item to nearby items along dimensions represented by tags. Movie Tuner is based on a data structure called the tag genome, which is described in separate work. The tag genome encodes each item's relationship to a common set of tags by applying machine learning algorithms to user-contributed content. The present paper discusses our design of Movie Tuner, including algorithms for navigating to new items and for suggesting tags for navigation. We present the results of a 7-week field trial of 2,531 users of Movie Tuner, and of a survey evaluating users' subjective experience.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {93–102},
numpages = {10},
keywords = {tagging, conversational recommenders, recommender systems},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253018,
author = {Pu, Pearl},
title = {Session Details: Keynote Address},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253018},
doi = {10.1145/3253018},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943420,
author = {Broder, Andrei Z.},
title = {An Introduction to Online Targeted Advertising: Principles, Implementation, Controversies},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943420},
doi = {10.1145/1943403.1943420},
abstract = {Online user interaction is becoming increasingly personalized both via explicit means: customizations, options, add-ons, skins, apps, etc. and via implicit means, that is, deep data mining of user activities that allows automated selection of content and experiences, e.g. individualized top news stories, personalized ranking of search results, personal "radio stations" that capture idiosyncratic tastes from past choices, individually recommended purchases, and so on. On the other hand, the vast majority of providers of content and services (e.g. portals, search engines, social sites) are supported by advertising, which at core, is just a different type of information. Thus, not surprisingly, on-line advertising is becoming increasingly personalized as well, supported by an emerging new scientific sub-discipline, Computational Advertising.The central problem of Computational Advertising is to find the "best match" between a given user in a given context and a suitable advertisement. The context could be a user entering a query in a search engine ("sponsored search"), a user reading a web page ("content match" and "display ads"), a user communicating via instant-messaging or via e-mail, a user interacting with a portable device, and many more. The information about the user can vary from scarily detailed to practically nil. The number of potential advertisements might be in the billions. Thus, depending on the definition of "best match" this problem leads to a variety of massive optimization and search problems, with complicated constraints. The solution to these problems provides the scientific and technical foundations of the online advertising industry, which according to E-Marketer, is estimated to achieve $25.8B dollars in revenue in 2010 in US alone, for the first time exceeding print advertising revenue at "only" 22.8B dollars.The focus of this talk is targeted advertising, a form of personalized advertising whereby advertisers specify the features of their desired audience, either explicitly, by specifying characteristics such as demographics, location, and context, or implicitly by providing examples of their ideal audience. A particular form of targeted advertising is behavioral targeting, where the desired audience is characterized by its past behavior. We will discuss how targeted advertising fits the optimization framework above, present some of the mechanisms by which targeted and behavioral advertising are implemented, and briefly survey the controversies surrounding behavioral advertising as a potential infringement on user privacy. We will conclude with some speculations about the future of personalized advertising and interesting areas of research.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {103},
numpages = {1},
keywords = {targeted advertising, computational advertising, on-line advertising, behavioral targeting},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253019,
author = {Jameson, Anthony},
title = {Session Details: Intelligent Help Agents},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253019},
doi = {10.1145/3253019},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943422,
author = {van Pinxteren, Youri and Geleijnse, Gijs and Kamsteeg, Paul},
title = {Deriving a Recipe Similarity Measure for Recommending Healthful Meals},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943422},
doi = {10.1145/1943403.1943422},
abstract = {A recipe recommender system may stimulate healthful and varied eating, when the presented recipes fit the lifestyle of the user. As consumers face the barrier to change their eating and cooking behavior, we aim for a strategy to provide more healthful variations to routine recipes. In this paper, a similarity measure for recipes is derived by taking a user-centered approach. Such a measure can be used to recommend healthier alternatives to commonly selected meals, which are perceived to be similar. Recipes presented using this strategy may fit the demand for health and variation within the boundaries of a busy lifestyle. Having derived and evaluated a recipe similarity measure, we explore its use through an at-home trial.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {105–114},
numpages = {10},
keywords = {card-sorting, user evaluation, natural language processing, recipe similarity, at-home trail},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943423,
author = {Wong, Weng-Keen and Oberst, Ian and Das, Shubhomoy and Moore, Travis and Stumpf, Simone and McIntosh, Kevin and Burnett, Margaret},
title = {End-User Feature Labeling: A Locally-Weighted Regression Approach},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943423},
doi = {10.1145/1943403.1943423},
abstract = {When intelligent interfaces, such as intelligent desktop assistants, email classifiers, and recommender systems, customize themselves to a particular end user, such customizations can decrease productivity and increase frustration due to inaccurate predictions - especially in early stages, when training data is limited. The end user can improve the learning algorithm by tediously labeling a substantial amount of additional training data, but this takes time and is too ad hoc to target a particular area of inaccuracy. To solve this problem, we propose a new learning algorithm based on locally weighted regression for feature labeling by end users, enabling them to point out which features are important for a class, rather than provide new training instances. In our user study, the first allowing ordinary end users to freely choose features to label directly from text documents, our algorithm was both more effective than others at leveraging end users' feature labels to improve the learning algorithm, and more robust to real users' noisy feature labels. These results strongly suggest that allowing users to freely choose features to label is a promising method for allowing end users to improve learning algorithms effectively.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {115–124},
numpages = {10},
keywords = {feature labeling, machine learning, locally weighted logistic regression, intelligent interfaces},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943424,
author = {Ehrlich, Kate and Kirk, Susanna E. and Patterson, John and Rasmussen, Jamie C. and Ross, Steven I. and Gruen, Daniel M.},
title = {Taking Advice from Intelligent Systems: The Double-Edged Sword of Explanations},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943424},
doi = {10.1145/1943403.1943424},
abstract = {Research on intelligent systems has emphasized the benefits of providing explanations along with recommendations. But can explanations lead users to make incorrect decisions? We explored this question in a controlled experimental study with 18 professional network security analysts doing an incident classification task using a prototype cybersecurity system. The system provided three recommendations on each trial. The recommendations were displayed with explanations (called "justifications") or without. On half the trials, one of the recommendations was correct; in the other half none of the recommendations was correct. Users were more accurate with correct recommendations. Although there was no benefit overall of explanation, we found that a segment of the analysts were more accurate with explanations when a correct choice was available but were less accurate with explanations in the absence of a correct choice. We discuss implications of these results for the design of intelligent systems.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {125–134},
numpages = {10},
keywords = {individual differences, evaluation, adaptive agents, explanations, recommendations, intelligent systems},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943425,
author = {Gervasio, Melinda and Yeh, Eric and Myers, Karen},
title = {Learning to Ask the Right Questions to Help a Learner Learn},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943425},
doi = {10.1145/1943403.1943425},
abstract = {Intelligent systems require substantial bodies of problem-solving knowledge. Machine learning techniques hold much appeal for acquiring such knowledge but typically require extensive amounts of user-supplied training data. Alternatively, informed question asking can supplement machine learning by directly eliciting critical knowledge from a user. Question asking can reduce the amount of training data required, and hence the burden on the user; furthermore, focused question asking holds significant promise for faster and more accurate acquisition of knowledge. In previous work, we developed static strategies for question asking that provide background knowledge for a base learner, enabling the learner to make useful generalizations even with few training examples. Here, we extend that work with a learning approach for automatically acquiring question-asking strategies that better accommodate the interdependent nature of questions. We present experiments validating the approach and showing its usefulness for acquiring efficient, context-dependent question-asking strategies.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {135–144},
numpages = {10},
keywords = {active learning, question asking, metalearning, decision tree induction, preference learning},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@dataset{10.1145/review-1943403.1943425_R46500,
author = {Hodgson, Jonathan P. E.},
title = {Review ID:R46500 for DOI: 10.1145/1943403.1943425},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1943403.1943425_R46500}
}

@inproceedings{10.1145/3253020,
author = {Cavazza, Marc},
title = {Session Details: Input Technologies},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253020},
doi = {10.1145/3253020},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943427,
author = {Micire, Mark and Desai, Munjal and Drury, Jill L. and McCann, Eric and Norton, Adam and Tsui, Katherine M. and Yanco, Holly A.},
title = {Design and Validation of Two-Handed Multi-Touch Tabletop Controllers for Robot Teleoperation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943427},
doi = {10.1145/1943403.1943427},
abstract = {Controlling the movements of mobile robots, including driving the robot through the world and panning the robot's cameras, typically requires many physical joysticks, buttons, and switches. Operators will often employ a technique called "chording" to cope with this situation. Much like a piano player, the operator will simultaneously actuate multiple joysticks and switches with his or her hands to create a combination of complimentary movements. However, these controls are in fixed locations and unable to be reprogrammed easily. Using a Microsoft Surface multi-touch table, we have designed an interface that allows chording and simultaneous multi-handed interaction anywhere that the user wishes to place his or her hands. Taking inspiration from the biomechanics of the human hand, we have created a dynamically resizing, ergonomic, and multi-touch controller (the DREAM Controller). This paper presents the design and testing of this controller with an iRobot ATRV-JR robot.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {145–154},
numpages = {10},
keywords = {finger registration, ergonomic, hand registration, hand detection, multi-touch, joystick, touch screen, tabletop, controller},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943428,
author = {Weibel, Nadir and Signer, Beat and Norrie, Moira C. and Hofstetter, Hermann and Jetter, Hans-Christian and Reiterer, Harald},
title = {PaperSketch: A Paper-Digital Collaborative Remote Sketching Tool},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943428},
doi = {10.1145/1943403.1943428},
abstract = {Pen and paper support the rapid production of sketches. However, the paper interface is not always optimal for collaborative sketching as seen in brainstorming sessions where multiple parties would often like to communicate and participate in the sketching synchronously. Novel interactive paper solutions may provide the answer by bridging the paper-digital divide and allowing users to sketch on paper simultaneously while capturing the actions digitally. We present an analysis of collaborative sketching activities in working environments with remote participation. After highlighting the importance of paper for natural interaction in these settings, we introduce PaperSketch, an interactive paper-digital tool for collaborative remote sketching. We discuss the collaborative development of ideas based on the prototype and outline how important feedback issues have been addressed by utilising spatial constraints and multimodal features.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {155–164},
numpages = {10},
keywords = {Skype, interactive paper, remote collaboration, sketching},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943429,
author = {Setlur, Vidya and Rossoff, Samuel and Gooch, Bruce},
title = {Wish I Hadn't Clicked That: Context Based Icons for Mobile Web Navigation and Directed Search Tasks},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943429},
doi = {10.1145/1943403.1943429},
abstract = {Typical web navigation techniques tend to support undirected web browsing, a depth-first search of information pages. This search strategy often results in the unintentional behavior of 'web surfing', where a user starts in search of information, but is sidetracked by tangential links. A mobile user in particular, would prefer to extract the desired information quickly and with minimal mental effort. In this paper, we introduce 'SemantiLynx' to visually augment hyperlinks on web pages for better supporting the task of directed searches on small-screen ubiquitous platforms. Our algorithm comprises four parts: establishing the context of information related to a hyperlink, retrieving relevant imagery based on this context, applying image simplification, and finally compositing a visual icon for the given hyperlink. We evaluated our system by conducting user studies for directed web search tasks and comparing the results to using textual snippets and webpage thumbnails.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {165–174},
numpages = {10},
keywords = {mobile device, icons, hyperlinks, directed search, web},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253021,
author = {Gervasio, Melinda},
title = {Session Details: User Modeling and Personalization},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253021},
doi = {10.1145/3253021},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943431,
author = {Loboda, Tomasz D. and Brusilovsky, Peter and Brunstein, J\"{o}erg},
title = {Inferring Word Relevance from Eye-Movements of Readers},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943431},
doi = {10.1145/1943403.1943431},
abstract = {Reading is one of the most important skills in today's society. The ubiquity of this activity has naturally affected many information systems; the only goal of some is the presentation of textual information. One concrete task often performed on a computer and involving reading is finding relevant parts of text. In the current study, we investigated if word-level relevance, defined as a binary measure of an individual word being congruent with the reader's current informational needs, could be inferred given only the text and eye movements of readers. We found that the number of fixations, first-pass fixations, and the total viewing time can be used to predict the relevance of sentence-terminal words. In light of what is known about eye movements of readers, knowing which sentence-terminal words are relevant can help in an unobtrusive identification of relevant sentences.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {175–184},
numpages = {10},
keywords = {user study, text relevance, word-level relevance, information seeking, eye movements, implicit indicator, reading, eye tracking},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943432,
author = {Yencken, Lars and Baldwin, Timothy},
title = {Predicting and Compensating for Lexicon Access Errors},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943432},
doi = {10.1145/1943403.1943432},
abstract = {Learning a foreign language is a long, error-prone process, and much of a learner's time is effectively spent studying vocabulary. Many errors occur because words are only partly known, and this makes their mental storage and retrieval problematic. This paper describes how an intelligent interface may take advantage of the access structure of the mental lexicon to help predict the types of mistakes that learners make, and thus compensate for them. We give two examples, firstly a dictionary interface which circumvents the tip-of-the-tongue problem through search-by-similarity, and secondly an adaptive test generator which leverages user errors to generate plausible multiple-choice distractors.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {185–194},
numpages = {10},
keywords = {character similarity, dictionary search, adaptive vocabulary testing},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943433,
author = {Davis, Paul A. and Shipman, Frank M.},
title = {Learning Usability Assessment Models for Web Sites},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943433},
doi = {10.1145/1943403.1943433},
abstract = {Our work explores an approach to learning types of usability concerns considered useful for the management of Web sites and to identifying usability concerns based on these learned models. By having one or more Web site managers rate a subset of pages in a site based on a number of usability criteria, we build a model that determines what automatically measurable characteristics are correlated to issues identified. To test this approach, we collected usability assessments from twelve students pursuing advanced degrees in the area of computer-human interaction. These students were divided into two groups and given different scenarios of use of a Web site. They assessed the usability of Web pages from the site, and their data was divided into a training set, used to find models, and a prediction set, used to evaluate the relative quality of models. Results show that the learned models predicted remaining data for one scenario in more categories of usability than did the single model found under the alternate scenario. Results also show how systems may prioritize usability problems for Web site managers by probability of occurrence rather than by merely listing pages that break specific rules, as provided by some current tools.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {195–204},
numpages = {10},
keywords = {document triage, web engineering, usability models, user interface design, automated assessment of usability},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943434,
author = {Lu, Jie and Pan, Shimei and Lai, Jennifer C. and Wen, Zhen},
title = {Information at Your Fingertips: Contextual IR in Enterprise Email},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943434},
doi = {10.1145/1943403.1943434},
abstract = {We present ICARUS, a contextual information retrieval system, which uses the current email message and a multi-tiered user model to retrieve relevant content and make it available in a sidebar widget embedded in the email client. The system employs a dynamic retrieval strategy to conduct automated contextual search across multiple information sources including the user's hard drive, online documents (wikis, blogs and files) and other email messages. It also presents the user with information about the sender of the current message, which varies in detail and degree based on how often the user interacts with this sender. We conducted a formative evaluation which compared three retrieval methods that used different context information: current message plus a multi-tiered user model; current message plus a single-tiered, aggregate user model; and lastly, cur-rent message only. Results indicate that the multi-tiered user modeling approach yields better retrieval performance than the other two. In addition, the study suggests that dynamically determining which sources to search, what query parameters to use, and how to filter/re-rank results can further improve the effectiveness of contextual IR.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {205–214},
numpages = {10},
keywords = {user modeling, context-sensitive search, contextual information retrieval, email, inbox},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253022,
author = {Andr\'{e}, Elisabeth},
title = {Session Details: Keynote Address},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253022},
doi = {10.1145/3253022},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943436,
author = {Perlin, Ken},
title = {The Future of Human/Computer Interfaces},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943436},
doi = {10.1145/1943403.1943436},
abstract = {What will the interface between people and computers look like in five years? In ten years? In twenty five years? Will we still have screens? Keyboards? Will we all be seeing Princess Leia in a beam of light? Based on current trends and inspired guesswork, we will go together on a tour of the future.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {215},
numpages = {1},
keywords = {user interfaces},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253023,
author = {Nakano, Yukiko},
title = {Session Details: Intelligent Authoring and Information Presentation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253023},
doi = {10.1145/3253023},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943438,
author = {Chi, Pei-Yu and Lieberman, Henry},
title = {Intelligent Assistance for Conversational Storytelling Using Story Patterns},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943438},
doi = {10.1145/1943403.1943438},
abstract = {People who are not professional storytellers usually have difficulty composing travel photos and videos from a mundane slideshow into a coherent and engaging story, even when it is about their own experiences. However, consider putting the same person in a conversation with a friend - suddenly the story comes alive.We present Raconteur 2, a system for conversational storytelling that encourages people to make coherent points, by instantiating large-scale story patterns and suggesting illustrative media. It performs natural language processing in real-time on a text chat between a storyteller and a viewer and recommends appropriate media items from a library. Each item is annotated with one or a few sentences in unrestricted English. A large commonsense knowledge base and a novel commonsense inference technique are used to identify story patterns such as problem and resolution or expectation violation. It uses a concept vector representation that goes beyond keyword matching or word co-occurrence based techniques. A small experiment shows that people find Raconteur's interaction design engaging, and suggestions helpful for real-time storytelling.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {217–226},
numpages = {10},
keywords = {storytelling, story pattern, video, commonsense computing, digital media, chat, conversation, life stories, photograph},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943439,
author = {Gil, Yolanda and Ratnakar, Varun and Frtiz, Christian},
title = {TellMe: Learning Procedures from Tutorial Instruction},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943439},
doi = {10.1145/1943403.1943439},
abstract = {This paper describes an approach to allow end users to define new procedures through tutorial instruction. Our approach allows users to specify procedures in natural language in the same way that they would instruct another person, while the system handles incompleteness and ambiguity inherent in natural human instruction and formulates follow up questions. We describe the key features of our approach, which include exposing prior knowledge, deductive and heuristic reasoning, shared learning state, and selectively asking questions to the user. We also describe how those key features are realized in our implemented TellMe system, and present preliminary user studies where non-programmers were able to easily specify complex multi-step procedures.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {227–236},
numpages = {10},
keywords = {procedure learning, natural instruction, tutorial instruction},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943440,
author = {Fritz, Christian and Gil, Yolanda},
title = {A Formal Framework for Combining Natural Instruction and Demonstration for End-User Programming},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943440},
doi = {10.1145/1943403.1943440},
abstract = {We contribute to the difficult problem of programming via natural language instruction. We introduce a formal framework that allows for the use of program demonstrations to resolve several types of ambiguities and omissions that are common in such instructions. The framework effectively combines some of the benefits of programming by demonstration and programming by natural instruction. The key idea of our approach is to use non-deterministic programs to compactly represent the (possibly infinite) set of candidate programs for given instructions, and to filter from this set by means of simulating the execution of these programs following the steps of a given demonstration. Due to the rigorous semantics of our framework we can prove that this leads to a sound algorithm for identifying the intended program, making assumptions only about the types of ambiguities and omissions occurring in the instruction. We have implemented our approach and demonstrate its ability to resolve ambiguities and omissions by considering a list of classes of such issues and how our approach resolves them in a concrete example domain. Our empirical results show that our approach can effectively and efficiently identify programs that are consistent with both the natural instruction and the given demonstrations.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {237–246},
numpages = {10},
keywords = {programming by demonstration, programming by instruction},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943441,
author = {Kazi, Hameedullah and Haddawy, Peter and Suebnukarn, Siriwan},
title = {METEOR: Medical Tutor Employing Ontology for Robustness},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943441},
doi = {10.1145/1943403.1943441},
abstract = {Problem based learning is becoming widely popular as an effective teaching method in medical education. Paying individual attention to a small group of students in medical PBL can place burden on the workload of medical faculty whose time is very costly. Intelligent tutoring systems offer a cost effective alternative in helping to train the students, but they are typically prone to brittleness and the knowledge acquisition bottleneck. Existing tutoring systems accept a small set of approved solutions for each problem scenario stored into the system. Plausible student solutions that lie outside the scope of the explicitly encoded ones receive little acknowledgment from the system. Tutoring hints are also confined to the knowledge space of the approved solutions, leading to brittleness in the tutoring approach. We report a tutoring system for medical PBL that employs the widely available medical knowledge source UMLS as the domain ontology. We exploit the structure of the ontology to expand the plausible solution space and generate hints based on the problem solving context. Evaluation of student learning outcomes led to highly significant learning gains (Mann-Whitney, p&lt;0.001).},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {247–256},
numpages = {10},
keywords = {tutoring system, user studies, UMLS, robustness, learning gains, medical PBL, ontology},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/3253024,
author = {Kr\"{u}ger, Antonio},
title = {Session Details: Pen-Based Interfaces},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253024},
doi = {10.1145/3253024},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943443,
author = {Weibel, Nadir and Fouse, Adam and Hutchins, Edwin and Hollan, James D.},
title = {Supporting an Integrated Paper-Digital Workflow for Observational Research},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943443},
doi = {10.1145/1943403.1943443},
abstract = {The intertwining of everyday life and computation, along with a new generation of inexpensive digital recording devices and storage facilities, is revolutionizing our ability to collect and analyze human activity data. Such ubiquitous data collection has an exciting potential to augment human cognition and radically improve information-intensive work. In this paper we introduce a system to aid the process of data collection and analysis during observational research by providing non-intrusive automatic capture of paper-based annotations. The system exploits current note-taking practices and incorporates digital pen technology. We describe the development, deployment and use of the system for interactive visualization and annotation of multiple stream of video and other types of time-based data.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {257–266},
numpages = {10},
keywords = {interactive visualization, observational research, video analysis, digital pens},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943444,
author = {Ouyang, Tom Y. and Davis, Randall},
title = {ChemInk: A Natural Real-Time Recognition System for Chemical Drawings},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943444},
doi = {10.1145/1943403.1943444},
abstract = {We describe a new sketch recognition framework for chemical structure drawings that combines multiple levels of visual features using a jointly trained conditional random field. This joint model of appearance at different levels of detail makes our framework less sensitive to noise and drawing variations, improving accuracy and robustness. In addition, we present a novel learning-based approach to corner detection that achieves nearly perfect accuracy in our domain. The result is a recognizer that is better able to handle the wide range of drawing styles found in messy freehand sketches. Our system handles both graphics and text, producing a complete molecular structure as output. It works in real time, providing visual feedback about the recognition progress. On a dataset of chemical drawings our system achieved an accuracy rate of 97.4%, an improvement over the best reported results in literature. A preliminary user study also showed that participants were on average over twice as fast using our sketch-based system compared to ChemDraw, a popular CAD-based tool for authoring chemical diagrams. This was the case even though most of the users had years of experience using ChemDraw and little or no experience using Tablet PCs.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {267–276},
numpages = {10},
keywords = {chemical diagram recognition, graphical models, pen-based interfaces, sketch recognition},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943445,
author = {Costagliola, Gennaro and Fuccella, Vittorio and Di Capua, Michele},
title = {Text Entry with KeyScretch},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943445},
doi = {10.1145/1943403.1943445},
abstract = {KeyScretch is a recently proposed text entry method which makes use of gestures to input frequent word chunks on a menu-augmented soft keyboard. Each gesture is initiated on a key and is driven by the key surrounding menu. In this paper we present the performance of an instance of the method with a 4-items menu, specifically designed for the Italian language. The study shows that the method is easy to learn and significantly outperforms the traditional tapping-based method on the QWERTY layout.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {277–286},
numpages = {10},
keywords = {keyscretch, soft keyboard, text entry, menu},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943447,
author = {Baltrunas, Linas and Ludwig, Bernd and Ricci, Francesco},
title = {Context Relevance Assessment for Recommender Systems},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943447},
doi = {10.1145/1943403.1943447},
abstract = {Research on context aware recommender systems is taking for granted that context matters. But, often attempts to show the influence of context have failed. In this paper we consider the problem of quantitatively assessing context relevance. For this purpose we are assuming that users can imagine a situation described by a contextual feature, and judge if this feature is relevant for their decision making task. We have designed a UI suited for acquiring such information in a travel planning scenario. In fact, this interface is generic and can also be used for other domains (e.g., music). The experimental results show that it is possible to identify the contextual factors that are relevant for the given task and that the relevancy depends on the type of the place of interest to be included in the plan.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {287–290},
numpages = {4},
keywords = {user preferences, recommender systems, context-aware},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943448,
author = {Baur, Dominikus and Hering, Bernhard and Boring, Sebastian and Butz, Andreas},
title = {Who Needs Interaction Anyway: Exploring Mobile Playlist Creation from Manual to Automatic},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943448},
doi = {10.1145/1943403.1943448},
abstract = {Currently available user interfaces for playlist generation allow creating playlists in various ways, within a spectrum from fully automatic to fully manual. However, it is not entirely clear how users interact with such systems in the field and whether different situations actually demand different interfaces. In this paper we describe Rush 2, a music interface for mobile touch-screen devices that incorporates three interaction modes with varying degrees of automation: Adding songs manually, in quick succession using the rush interaction technique or filling the playlist automatically. For all techniques various filters can be set. In a two- week diary study (with in-depth interaction logging) we gained insight into how people interact with music in their everyday lives and how much automation and interactivity are really necessary.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {291–294},
numpages = {4},
keywords = {recommendation, interaction, automation, music, mobile},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943449,
author = {Blythe, Jim and Camp, Jean and Garg, Vaibhav},
title = {Targeted Risk Communication for Computer Security},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943449},
doi = {10.1145/1943403.1943449},
abstract = {Attacks on computer systems are rapidly becoming more numerous and more sophisticated, and current preventive techniques do not seem able to keep pace. Many successful attacks can be attributed to user errors: for example, while focused on other tasks, users may succumb to 'social engineering' attacks such as phishing or trojan horses. Warnings about the danger of these attacks are often vaguely worded and given long before the dangers are realized, and are therefore too easy to ignore. However, we hypothesize that users are more likely to be persuaded by messages that (1) leverage mental models to describe the dangers, (2) describe particular vulnerabilities that the user may be exposed to and (3) are delivered close in time before the danger may actually be realized. We discuss the design and initial implementation of a system to achieve this. It first shows a video about a potential danger, then creates warnings tailored to the user's environment and given at the time they may be most useful, displaying a still frame or snippet from the video to remind the user of the potential danger. The system uses templates of user activities as input to a markov logic network to recognize potentially risky behaviors. This approach can identify likely next steps that can be used to predict immediate danger and customize warnings.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {295–298},
numpages = {4},
keywords = {planning and plan recognition, help intelligent assistants for complex tasks, modeling and prediction of user behavior},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943450,
author = {Bobrow, Daniel G. and Condoravdi, Cleo and Richardson, Kyle and Waldinger, Richard and Das, Amar},
title = {Deducing Answers to English Questions from Structured Data},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943450},
doi = {10.1145/1943403.1943450},
abstract = {We describe ongoing research using natural English text queries as an intelligent interface for inferring answers from structured data in a specific domain. Users can express queries whose answers need to be deduced from data in different databases, without knowing the structures of those databases nor even the existence of the sources used. Users can pose queries incrementally, elaborating on an initial query, and ask follow-up questions based on answers to earlier queries.Inference in an axiomatic theory of the subject domain links the natural form in which the question is posed to the way relevant data is represented in a database, and composes information obtained from several databases into an answer to a complex question.We describe the status of a prototype system, called Quadri, for answering questions about HIV treatment, using the Stanford HIV Drug Resistance Database [8] and European resources. We discuss some of the problems that need to be solved to make this approach work, and some of our solutions.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {299–302},
numpages = {4},
keywords = {natural-language database access, deductive question answering, theorem proving, domain-specific queries, logical form},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943451,
author = {Carter, Scott and Chen, Francine and Muralidharan, Aditi S. and Pickens, Jeremy},
title = {DiG: A Task-Based Approach to Product Search},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943451},
doi = {10.1145/1943403.1943451},
abstract = {While there are many commercial systems to help people browse and compare products, these interfaces are typically product centric. To help users identify products that match their needs more efficiently, we instead focus on building a task centric interface and system. Based on answers to initial questions about the situations in which they expect to use the product, the interface identifies products that match their needs, and exposes high-level product features related to their tasks, as well as low-level information including customer reviews and product specifications. We developed semi-automatic methods to extract the high-level features used by the system from online product data. These methods identify and group product features, mine and summarize opinions about those features, and identify product uses. User studies verified our focus on high-level features for browsing products and low-level features and specifications for comparing products.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {303–306},
numpages = {4},
keywords = {interactive interfaces, products, text mining},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943452,
author = {Chali, Yllias and Hasan, Sadid A. and Imam, Kaisar},
title = {A Reinforcement Learning Framework for Answering Complex Questions},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943452},
doi = {10.1145/1943403.1943452},
abstract = {Scoring sentences in documents given abstract summaries created by humans is important in extractive multi-document summarization. In this paper, we use extractive multi-document summarization techniques to perform complex question answering and formulate it as a reinforcement learning problem. We use a reward function that measures the relatedness of the candidate (machine generated) summary sentences with abstract summaries. In the training stage, the learner iteratively selects original document sentences to be included in the candidate summary, analyzes the reward function and updates the related feature weights accordingly. The final weights found in this phase are used to generate summaries as answers to complex questions given unseen test data. We use a modified linear, gradient-descent version of Watkins' Q(») algorithm with µ-greedy policy to determine the best possible action i.e. selecting the most important sentences. We compare the performance of this system with a Support Vector Machine (SVM) based system. Evaluation results show that the reinforcement method advances the SVM system improving the ROUGE scores by &lt; 28%.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {307–310},
numpages = {4},
keywords = {multi-document summarization, complex question answering, reinforcement learning, reward function, support vector machines},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943453,
author = {Chen, Li and Pu, Pearl},
title = {Users' Eye Gaze Pattern in Organization-Based Recommender Interfaces},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943453},
doi = {10.1145/1943403.1943453},
abstract = {In this paper, we report the hotspot and gaze path of users' eye-movements on three different layouts for recommender interfaces. One is the standard list layout, as appearing in most of current recommender systems. The other two are variations of organization interfaces where recommended items are organized into categories and each category is annotated by a title. Gaze plots infer that the organization interfaces, especially the quadrant layout, are likely to arouse users' attentions to more recommendations. In addition, more users chose products from the organization layouts. Combining the results with our prior works, we suggest a set of design guidelines and practical implications to our future work.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {311–314},
numpages = {4},
keywords = {recommender interfaces, layout design, eye-tracking study},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943454,
author = {Chen, Siyuan and Epps, Julien and Ruiz, Natalie and Chen, Fang},
title = {Eye Activity as a Measure of Human Mental Effort in HCI},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943454},
doi = {10.1145/1943403.1943454},
abstract = {The measurement of a user's mental effort is a problem whose solutions may have important applications to adaptive interfaces and interface evaluation. Previous studies have empirically shown links between eye activity and mental effort; however these have usually investigated only one class of eye activity on tasks atypical of HCI. This paper reports on research into eight eye activity based features, spanning eye blink, pupillary response and eye movement information, for real time mental effort measurement. Results from an experiment conducted using a computer-based training system show that the three classes of eye features are capable of discriminating different cognitive load levels. Correlation analysis between various pairs of features suggests that significant improvements in discriminating different effort levels can be made by combining multiple features. This shows an initial step towards a real-time cognitive load measurement system in human-computer interaction.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {315–318},
numpages = {4},
keywords = {eye movement, cognitive load, adaptive interfaces, mental effort, eye blink, pupillary response},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943455,
author = {Delaye, Adrien and Sekkal, Rafik and Anquetil, Eric},
title = {Continuous Marking Menus for Learning Cursive Pen-Based Gestures},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943455},
doi = {10.1145/1943403.1943455},
abstract = {In this paper, we present a new type of Marking menus. Continuous Marking Menus are specifically dedicated to pen-based interfaces, and designed to define a set of cursive, realistic handwritten gestures. In menu mode, they offer a continuous visual feedback and fluent exploration of menu hierarchy, inviting the user to execute cursive gestures for invoking the desired commands. In marking mode, a specific gesture recognition method is proposed and proved to be very efficient for recognizing cursive gestures.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {319–322},
numpages = {4},
keywords = {marking menus, cursive gestures, pen-based gestures},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943456,
author = {Vrande\v{c}i\'{c}, Denny and Gil, Yolanda and Ratnakar, Varun},
title = {Want World Domination? Win at Risk! Matching to-Do Items with How-Tos from the Web},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943456},
doi = {10.1145/1943403.1943456},
abstract = {To-Do lists are widely used for personal task management. We propose a novel approach to assist users in managing their To-Dos by matching them to How-To knowledge from the Web. We have implemented a system that, given a To-Do item, provides a number of possibly matching How-Tos, broken down into steps that can be used as new To-Do entries. Our implementation is in the form of a web service that can be easily integrated into existing To-Do applications. This can help users by providing them with an approach to tackle the To-Do by listing smaller, more actionable To-Dos. In this paper we present our implementation, an evaluation of the matching component over two sets of To-Do corpora with very different characteristics, and a discussion of the results.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {323–326},
numpages = {4},
keywords = {how-to, to-do, tasks, personal information management, intelligent assistant},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943457,
author = {Endres, Christoph and Schwartz, Tim and M\"{u}ller, Christian A.},
title = {Geremin": 2D Microgestures for Drivers Based on Electric Field Sensing},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943457},
doi = {10.1145/1943403.1943457},
abstract = {We introduce the "Geremin" approach on in-car 2D microgesture recognition, which belongs to the category of electric field sensing techniques detecting the presence of a human hand near a conductive object (not affected by light and dynamic backgrounds, fast response times). The core component is essentially a modified "Theremin", an early electronic musical instrument named after the Russian inventor Professor Leon Theremin. Gesture recognition is done using a Dynamic Time Warp DTW algorithm. With respect to the application domain, we follow the direction of "selective mapping to theme or function" suggested in the literature. For gesture location, we propose the immediate proximity of the steering wheel, which has the advantage of providing gesture-based interaction without requiring the driver to take off hand(s). The major motivating factor for the proposed approach is reducing installation costs. Although, we use a single-antenna setup for this study, our results indicate that the gain in recognition accuracy justifies the use of two or more.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {327–330},
numpages = {4},
keywords = {gesture recognition, automotive},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943458,
author = {Gervasio, Melinda and Haines, Will and Morley, David and Lee, Thomas J. and Overholtzer, C. Adam and Saadati, Shahin and Spaulding, Aaron},
title = {How to Serve Soup: Interleaving Demonstration and Assisted Editing to Support Nonprogrammers},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943458},
doi = {10.1145/1943403.1943458},
abstract = {The Adept Task Learning system is an end-user programming environment that combines programming by demonstration and direct manipulation to support customization by nonprogrammers. Previously, Adept enforced a rigid procedure-authoring workflow consisting of demonstration followed by editing. However, a series of system evaluations with end users revealed a desire for more feedback during learning and more flexibility in authoring. We present a new approach that interleaves incremental learning from demonstration and assisted editing to provide users with a more flexible procedure-authoring experience. The approach relies on maintaining a "soup" of alternative hypotheses during learning, propagating user edits through the soup, and suggesting repairs as needed. We discuss the learning and reasoning techniques that support the new approach and identify the unique interaction design challenges they raise, concluding with an evaluation plan to resolve the design challenges and complete the improved system.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {331–334},
numpages = {4},
keywords = {programming by demonstration, programming by direct manipulation, end-user programming, learning from demonstration},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943459,
author = {Hannon, John and McCarthy, Kevin and Lynch, James and Smyth, Barry},
title = {Personalized and Automatic Social Summarization of Events in Video},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943459},
doi = {10.1145/1943403.1943459},
abstract = {Social services like Twitter are increasingly used to provide a conversational backdrop to real-world events in real-time. Sporting events are a good example of this and this year, millions of users tweeted their comments as they watched the World Cup matches from around the world. In this paper, we look at using these time-stamped opinions as the basis for generating video highlights for these soccer matches. We introduce the PASSEV system and describe and evaluate two basic summarization approaches.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {335–338},
numpages = {4},
keywords = {video summarization, web 2.0, Twitter},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943460,
author = {Holzmann, Clemens and Hochgatterer, Matthias},
title = {Vision-Based Distance and Position Estimation of Nearby Objects for Mobile Spatial Interaction},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943460},
doi = {10.1145/1943403.1943460},
abstract = {New mobile phone technologies are enablers for the emerging field of mobile spatial interaction, which refers to the direct access and manipulation of spatially-related information and services. Typical applications include the visualization of information about historical buildings or the discovery and selection of surrounding devices, by simply pointing to the real-world objects of interest. However, a major drawback is the required augmentation of the objects or knowledge about the environment, in order to be able to distinguish at which object the user is actually aiming at. We address this issue by estimating the distance and position of arbitrary objects within a mobile phone's line of sight, solely based on the information provided by its on-board sensors. This new approach uses stereo vision to estimate the distance to nearby objects, inertial sensors to measure the displacement of the camera between successive images, as well as GPS and a digital compass to get its absolute position and orientation. In this paper, we focus on the vision-based estimation of distances, and present the results of an experiment which demonstrates its accuracy and performance.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {339–342},
numpages = {4},
keywords = {stereo vision, mobile spatial interaction, inertial sensing},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943461,
author = {Hu, Beibei and Hidders, Jan and Cimiano, Philipp},
title = {A Rule Engine for Relevance Assessment in a Contextualized Information Delivery System},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943461},
doi = {10.1145/1943403.1943461},
abstract = {In order to support police officers in their daily activities, we have designed a rule-based system which can deliver contextualized information to police officers, thus supporting decision making. In particular, we present a framework that has been designed on the basis of requirements elicited in a previous study, focusing on the rule language and the engine that essentially defines and allows to configure the behaviour of the system. The rules consist of a body which specifies conditions that need to be fulfilled in a certain context. The head of the rules specifies how the relevance ratings of certain information items for specific users need to be updated given that the conditions in the body are met. On the basis of cumulated ratings, the system generates a user- and context specific ranking of information items. Quantitative evaluations in terms of precision and recall with respect to a gold standard determined in cooperation with police officers show that the system can cater for the requirements of our end users and yields reasonable precision and recall values.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {343–346},
numpages = {4},
keywords = {semantic web, SPARQL, RDF, context-aware information systems, rule-based systems},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943462,
author = {Hu, Rong and Pu, Pearl},
title = {Enhancing Recommendation Diversity with Organization Interfaces},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943462},
doi = {10.1145/1943403.1943462},
abstract = {Research increasingly indicates that accuracy cannot be the sole criteria in creating a satisfying recommender from the users' point of view. Other criteria, such as diversity, are emerging as important characteristics for consideration as well. In this paper, we try to address the problem of augmenting users' perception of recommendation diversity by applying an organization interface design method to the commonly used list interface. An in-depth user study was conducted to compare an organization interface with a standard list interface. Our results show that the organization interface indeed effectively increased users' perceived diversity of recommendations, especially perceived categorical diversity. Furthermore, 65% of users preferred the organization interface, versus 20% for the list interface. 70% of users thought the organization interface is better at helping them perceive recommendation diversity versus only 15% for the list interface.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {347–350},
numpages = {4},
keywords = {diversity, recommender system, user study, interface},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943463,
author = {Huette, Stephanie and Huang, Yazhou and Kallmann, Marcelo and Matlock, Teenie and Matthews, Justin L.},
title = {Gesture Variants and Cognitive Constraints for Interactive Virtual Reality Training Systems},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943463},
doi = {10.1145/1943403.1943463},
abstract = {Two studies investigated the nature of environmental context on various parameters of pointing. The results revealed the need for extreme temporal precision and the need for efficient algorithms to parse out different styles of pointing. Most variability in pointing came from individual differences, and a method to classify the kind of point and derive its temporal parameters is discussed. These results and methods improve the pragmatism of virtual reality, making events appear more realistic by emphasizing temporal precision.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {351–354},
numpages = {4},
keywords = {virtual reality, virtual agents, pointing, gesture},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943464,
author = {Jiang, Hao and Xu, Songhua and Lau, Francis Chi-Moon},
title = {Capturing User Reading Behaviors for Personalized Document Summarization},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943464},
doi = {10.1145/1943403.1943464},
abstract = {We propose a new personalized document summarization method that observes a user's personal reading preferences. These preferences are inferred from the user's reading behaviors, including facial expressions, gaze positions, and reading durations that were captured during the user's past reading activities. We compare the performance of our algorithm with that of a few peer algorithms and software packages. The results of our comparative study show that our algorithm can produce more superior personalized document summaries than all the other methods in that the summaries generated by our algorithm can better satisfy a user's personal preferences.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {355–358},
numpages = {4},
keywords = {facial expressions, reading durations, personal preferences, reading preference, gaze positions, personalized document summarization},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943465,
author = {Kahl, Gerrit and Spassova, L\"{u}bomira and Sch\"{o}ning, Johannes and Gehring, Sven and Kr\"{u}ger, Antonio},
title = {IRL SmartCart - a User-Adaptive Context-Aware Interface for Shopping Assistance},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943465},
doi = {10.1145/1943403.1943465},
abstract = {The electronic market has rapidly grown in the last few years. However, despite this success, consumers still enjoy visiting a "real store with real products". Therefore various common technologies have been installed in supermarkets to support the customer's shopping process and experience. In this paper, we introduce the IRL SmartCart - an instrumented shopping cart that acts as a user interface to support the shopping process. We show how RFID technology enables recognizing products that are put in the cart's basket. We are also able to determine the cart's position in an instrumented shopping environment. User input and visual output are possible by means of a touch screen, which is fitted in the IRL SmartCart's handle to support different tasks involved in the shopping process. We present and discuss different location- and context-based services that run on the cart interface system, e.g. a personalized shopping list sorted corresponding to the products in the user's vicinity or a navigation service to different products that the customer is searching for.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {359–362},
numpages = {4},
keywords = {i/o device, location-based services, hands-free interaction interface, instrumented shopping cart, user interface},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943466,
author = {Komatsuzaki, Mizuho and Tsukada, Koji and Siio, Itiro},
title = {DrawerFinder: Finding Items in Storage Boxes Using Pictures and Visual Markers},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943466},
doi = {10.1145/1943403.1943466},
abstract = {We propose a novel search technique called DrawerFinder that helps users find commodities stored in two types of storage boxes (with drawers or lids) on a shelf. First, we attach visual markers inside these storage boxes. When a user opens a box, a camera attached above the shelf detects the visual marker and the system automatically takes a picture. Next, the picture is automatically uploaded to an online database tagged with the box ID. Users can then browse these pictures using a PC or cellular phone equipped with a common web browser. We believe our system helps users find items in boxes efficiently as they can browse both pictures of boxes and the surrounding environment (e.g., who last opened the storage box) quickly.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {363–366},
numpages = {4},
keywords = {shelf, picture, drawer, visual marker, storage box, web browser},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943467,
author = {Kong, Nicholas and Hanrahan, Ben and Weksteen, Thi\'{e}baud and Convertino, Gregorio and Chi, Ed H.},
title = {VisualWikiCurator: Human and Machine Intelligencefor Organizing Wiki Content},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943467},
doi = {10.1145/1943403.1943467},
abstract = {Corporate wikis are affected by poor adoption rates. The high interaction costs required to organize and maintain information in these wikis are a key factor that limits broader adoption. We present VisualWikiCurator, a wiki extension designed to lower such costs by (a) recommending new content to easily update a wiki page, and (b) extracting structured data from the wiki page while providing new alternative visualizations of the data. The visualizations of extracted semantic data act both as alternative views and as tools to organize the page content. Since no information extraction algorithm is perfect with generic unstructured data, we use a mixed-initiative approach to allow users to refine machine-extracted metadata and easily re-organize the content in wiki pages.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {367–370},
numpages = {4},
keywords = {visualization, corporate wikis, organization, Web 2.0},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943468,
author = {Kratz, Sven and Rohs, Michael},
title = {Protractor3D: A Closed-Form Solution to Rotation-Invariant 3D Gestures},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943468},
doi = {10.1145/1943403.1943468},
abstract = {Protractor 3D is a gesture recognizer that extends the 2D touch screen gesture recognizer Protractor to 3D gestures. It inherits many of Protractor's desirable properties, such as high recognition rate, low computational and low memory requirements, ease of implementation, ease of customization, and low number of required training samples. Protractor 3D is based on a closed-form solution to finding the optimal rotation angle between two gesture traces involving quaternions. It uses a nearest neighbor approach to classify input gestures. It is thus well-suited for application in resource-constrained mobile devices. We present the design of the algorithm and a study that evaluated its performance.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {371–374},
numpages = {4},
keywords = {template matching, gesture-based interaction, rotation invariance, nearest neighbor approach, gesture recognition},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943469,
author = {Kuflik, Tsvi and Lanir, Joel and Dim, Eyal and Wecker, Alan and Corra', Michele and Zancanaro, Massimo and Stock, Oliviero},
title = {Indoor Positioning: Challenges and Solutions for Indoor Cultural Heritage Sites},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943469},
doi = {10.1145/1943403.1943469},
abstract = {Museums are both appealing and challenging as an environment for indoor positioning research. By nature, they are dense and rich in objects and information, and as a result they contain more information than a visitor can absorb in a time-limited visit. Many research projects have explored the potential of novel technologies to support information delivery to museum visitors. Having an accurate visitor position is a key factor in the success of such projects. In spite of numerous technologies experimented with, there is no prevailing indoor positioning technology. Each technology has its benefits as well as its limitations. In addition, museums have their own constrains when it comes to installation of sensors in their space. In the framework of the PIL project, a flexible "light weight" proximity based positioning system was developed and deployed at the Hecht museum and a general framework for indoor positioning is proposed. The inherent limitations of the basic technology are addressed by an abstract reasoning layer and by a dialog with the user.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {375–378},
numpages = {4},
keywords = {human-computer interaction, visitor guides, indoor positioning},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943470,
author = {Kurihara, Kazutaka and Nagano, Naoshi and Watanabe, Yuta and Fujimura, Yuichi and Minaduki, Akinori and Hayashi, Hidehiko and Tutiya, Yohei},
title = {Toward Localizing Audiences' Gaze Using a Multi-Touch Electronic Whiteboard with SPieMenu},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943470},
doi = {10.1145/1943403.1943470},
abstract = {Direct-touch presentation devices such as touch-sensitive electronic whiteboards have two serious problems. First, the presenter's hand movements tend to distract the audience's attention from content. Second, the presenter's manipulation tends to obscure content. In this paper we propose "audience gaze localization" as an interface design paradigm to cope with the problems. It is an attitude to maximize the usability of the application with respect to the presenter, while minimizing the negative effects of the presenter's manipulations from the perspective of the audience. Based on the paradigm, we develop a new electronic whiteboard system that supports multi-touch gestures and employs a special pie menu interface named "sPieMenu." This pie menu is displayed under the presenter's palm and is thus invisible to the audience, while kept visible to the presenter.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {379–382},
numpages = {4},
keywords = {audience gaze localization, pie menu, multi-touch},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943471,
author = {Larsen, Jakob Eg and Stopczynski, Arkadiusz and Larsen, Jan and Vesterskov, Claus and Krogsgaard, Peter and Sondrup, Thomas},
title = {Augmenting the Sound Experience at Music Festivals Using Mobile Phones},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943471},
doi = {10.1145/1943403.1943471},
abstract = {In this paper we describe experiments carried out at the Nibe music festival in Denmark involving the use of mobile phones to augment the participants' sound experience at the concerts. The experiments involved N=19 test participants that used a mobile phone with a headset playing back sound received over FM from the PA audio mixer system. Based on the location of the participant (distance to the stage) a delay was estimated and introduced to the playback on the mobile phone in order to align the sound in the headset with that from the on-stage speakers. We report our findings from our initial "in-the-wild" experiments augmenting the sound experience at two concerts at this music festival.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {383–386},
numpages = {4},
keywords = {augmented audio, music, concert, sound delay, mobile phone},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943472,
author = {McNally, Kevin and O'Mahony, Michael P. and Smyth, Barry and Coyle, Maurice and Briggs, Peter},
title = {Social and Collaborative Web Search: An Evaluation Study},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943472},
doi = {10.1145/1943403.1943472},
abstract = {In this paper we describe the results of a live-user study to demonstrate the benefits of using the social search utility HeyStaks, a novel approach to Web search that combines ideas from personalization and social networking to provide a more collaborative search experience.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {387–390},
numpages = {4},
keywords = {HeyStaks, user evaluation, collaborative web search},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943473,
author = {Sonntag, Daniel},
title = {Towards Learned Feedback for Enhancing Trust in Information Seeking Dialogue for Radiologists},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943473},
doi = {10.1145/1943403.1943473},
abstract = {Dialogue-based Question Answering (QA) in the context of information seeking applications is a highly complex user interaction task. QA systems normally include various natural language processing components (i.e., components for question classification and information extraction) and information retrieval components. This paper presents a new approach to equip a multimodal QA system for radiologists with some form of self-knowledge about the expected dialogue processing behaviour and the results themselves. The learned models are used to provide feedback of the QA process, i.e., what the system is doing and delivers as results. The resulting automatic feedback behaviour should enhance the user's trust in the system. To this end, examples of the learned feedback are provided in the context of the generation of system-initiative dialogue feedback to a radiologist's questions.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {391–394},
numpages = {4},
keywords = {user feedback, trust, meta-communication, explanation, dialogue systems, adaptive agents},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943474,
author = {Zancanaro, Massimo and Oliviero, Stock and Tomasini, Daniel and Pianesi, Fabio},
title = {A Socially Aware Persuasive System for Supporting Conversations at the Museum Caf\'{e}},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943474},
doi = {10.1145/1943403.1943474},
abstract = {In this paper we propose a new type of system explicitly aimed at influencing immediate behavior in an informal, non goal-oriented co-located small group. The state of the group dynamics is automatically assessed in order for the system to continuously plan and deploy minimalist strategies using evocative means to influence behavior, rather than explicit recommendations. A key aspect of our approach is that the main "interaction channel" is left for direct human-to-human interaction, while no large conscious elaboration effort nor actions are meant by the user toward the interface. We present here the concept and a working implementation of a prototype system targeted to a museum scenario. The system has the form of a table in the museum caf\'{e}, and is aimed at inducing a group of friends to talk about the content of their visit to the museum.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {395–398},
numpages = {4},
keywords = {context awareness, small groups, museum, persuasive interfaces},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943475,
author = {Tan, Ning and Pruvost, Ga\"{e}tan and Courgeon, Matthieu and Clavel, C\'{e}line and Bellik, Yacine and Martin, Jean-Claude},
title = {A Location-Aware Virtual Character in a Smart Room: Effects on Performance, Presence and Adaptivity},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943475},
doi = {10.1145/1943403.1943475},
abstract = {Location-aware ambient environments are relevant in designing interactive virtual characters. However, they raise several questions about spatial behaviors to be displayed by virtual characters, and about the perception of virtual characters by users. We designed a location-aware virtual agent that adapts its spatial behavior to users' and objects' locations during a search task in a smart room. We conducted an experimental evaluation comparing this adaptive agent with an agent that does not perceive nor use the location of users and objects. The location-aware adaptive agent elicited higher levels of perceived presence and perceived adaptivity. Furthermore, performance was less influenced by task difficulty when users interacted with the adaptive agent. Such results can be useful for the design of future location-aware virtual agents.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {399–402},
numpages = {4},
keywords = {interactive virtual agent, multimodal user interfaces, spatial behaviors, adaptive agents, ambient interaction, experimental studies},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943476,
author = {Tausky, David and Lank, Edward and Mann, Richard and Labahn, George},
title = {Analyzing Sketch Content Using In-Air Packet Information},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943476},
doi = {10.1145/1943403.1943476},
abstract = {Recognizing hand drawn mathematical matrices on tablet computers has proven to be a particularly challenging task. While individual expression recognition can be simplified by assuming the entire content is a single semantic construct, a single math expression, a matrix is composed of multiple expressions arranged in rows and columns. These expressions must first be segmented into matrix elements, and then each individual matrix element expression must be recognized. In this work, we show how a simple algorithm on in-air (i.e. non-inking) strokes can be used to analyze the drawing order of a matrix. Once the drawing order is recognized, we show how outlier analysis on in-air packets gives rapid, reliable segmentation of matrix elements.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {403–406},
numpages = {4},
keywords = {mathematics, matrices, pen-math, recognition, stylus},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943477,
author = {Reddington, Joseph and Tintarev, Nava},
title = {Automatically Generating Stories from Sensor Data},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943477},
doi = {10.1145/1943403.1943477},
abstract = {Recent research in Augmented and Alternative Communication (AAC) has begun to make use of Natural Language Generation (NLG) techniques. This creates an opportunity for constructing stories from sensor data, akin to existing work in life-logging. This paper examines the potential of using NLG to merge the AAC and life-logging domains. It proposes a four stage hierarchy that categorises levels of complexity of output text. It formulates a key subproblem of clustering sensor data into narrative events and describes three potential approaches for resolving this subproblem.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {407–410},
numpages = {4},
keywords = {event generation, life-logging, story, narrative, NLG, AAC, sensors},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943478,
author = {Tudorache, Tania and Noy, Natalya F. and Falconer, Sean M. and Musen, Mark A.},
title = {A Knowledge Base Driven User Interface for Collaborative Ontology Development},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943478},
doi = {10.1145/1943403.1943478},
abstract = {Scientists and researchers often use ontologies to describe their data, to share and integrate this data from heterogeneous sources. Ontologies are formal computer models that describe the main concepts and their relationships in a particular domain. Ontologies are usually authored by a community of users with different roles and levels of expertise. To support collaboration among distributed teams and to provision for distinct authoring requirements of each of the user roles and of individual users, we designed a configurable Web-based ontology editor, WebProtege. WebProtege extends Protege, a widely popular ontology editor with more than 150,000 registered users. The user interface layout and configuration for WebProtege is model-based and declarative: we represent it in a knowledge base, with an ontology defining its structure, and linking the interface configuration to the users, their roles, and access policies. We will discuss how the knowledge base driven configuration of the user interface supports the reuse and modularization of layout configurations. Such configuration is also highly flexible and extensible, and is easier to manage than many traditional approaches.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {411–414},
numpages = {4},
keywords = {configuration, web-based user interface, roles, model-based user interface, declarative user interface, knowledge base interfaces, reuse},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943479,
author = {Vildjiounaite, Elena and Kantorovitch, Julia and Kyll\"{o}nen, Vesa and Niskanen, Ilkka and Hillukkala, Mika and Virtanen, Kimmo and Vuorinen, Olli and M\"{a}kel\"{a}, Satu-Marja and Ker\"{a}nen, Tommi and Peltola, Johannes and M\"{a}ntyj\"{a}rvi, Jani and Tokmakoff, Andrew},
title = {Designing Socially Acceptable Multimodal Interaction in Cooking Assistants},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943479},
doi = {10.1145/1943403.1943479},
abstract = {Cooking assistant is an application that needs to find a trade-off between providing efficient help to the users (e.g., reminding them to stir a meal if it is about to burn) and avoiding users' annoyance. This trade-off may vary in different contexts, such as cooking alone or in a group, cooking new or known recipe etc. The results of the user study, presented in this paper, show which features of a multimodal interface users perceive as socially acceptable or unacceptable in different situations, and how this perception depends on user's age.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {415–418},
numpages = {4},
keywords = {context, cooking assistant},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943480,
author = {Wilson, Theresa and Hofer, Gregor},
title = {Using Linguistic and Vocal Expressiveness in Social Role Recognition},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943480},
doi = {10.1145/1943403.1943480},
abstract = {In this paper, we investigate two types of expressiveness, linguistic and vocal, and whether they are useful for recognising the social roles of participants in meetings. Our experiments show that combining expressiveness features with speech activity does improve social role recognition over speech activity features alone.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {419–422},
numpages = {4},
keywords = {analysis of user states, group interaction, role recognition},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943481,
author = {Yu, Kun and Epps, Julien and Chen, Fang},
title = {Cognitive Load Evaluation of Handwriting Using Stroke-Level Features},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943481},
doi = {10.1145/1943403.1943481},
abstract = {This paper examines several writing features for the evaluation of cognitive load. Our analysis is focused on writing features within and between written strokes, including writing pressure, writing velocity, stroke length and inter-stroke movements. Based on a study of 20 subjects performing a sentence composition task, the reported findings reveal that writing pressure and writing velocity information are very good indicators of cognitive load. A stroke selection threshold was investigated for constraining the feature extraction to long strokes, which resulted in a small further improvement. Differing from most previous research investigating cognitive load during writing based on task performance criteria, this work proposes a new approach to cognitive load measurement using writing dynamics, with the potential to allow new or improve existing handwriting interfaces.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {423–426},
numpages = {4},
keywords = {handwriting, stroke, cognitive load, inter-stroke},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943482,
author = {Zheng, Feng and Li, Hongsong},
title = {ARCrowd - a Tangible Interface for Interactive Crowd Simulation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943482},
doi = {10.1145/1943403.1943482},
abstract = {Manipulating a large virtual crowd in an interactive virtual reality environment is a challenging task due to the limitations of the traditional user interface. To address this problem, a tangible interface based on augmented reality (AR) technology is introduced. With a novel interaction framework, the users are allowed to manipulate the virtual characters directly, or to control the crowd behaviors with markers and gestures. The marker-gesture pairs are used to adjust the environment factors, the decision-making processes of virtual crowds, and their reactions. The AR interface provides more intuitive means of control for the users, promoting the efficiency of user interface. Several simulation examples are provided to illustrate the various crowd control methods.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {427–430},
numpages = {4},
keywords = {augmented reality, crowd authoring, crowd simulation, user interface},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943484,
author = {Agarwal, Sheetal K. and Jain, Anupam and Kumar, Arun and Manwani, Priyanka and Rajput, Nitendra},
title = {Spoken Web: Creation, Navigation and Searching of VoiceSites},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943484},
doi = {10.1145/1943403.1943484},
abstract = {The Spoken Web is a voice-based equivalent of the World Wide Web (WWW), developed by IBM Research Laboratory, India, primarily designed for rural and semi-urban people to provide information of value to them through their mobile or landline phones.This demonstration aims to present the use of VoiceSites for information creation and access for the rural population. VoiceSites can be accessed by calling a phone number and end-users can listen to the content over phone and navigate through voice or the phone keypad. While one demonstration is of creating a VoiceSite, the other is for browsing a multitude of VoiceSites that would also demonstrate conducting transactions across VoiceSites. We will also present the mechanism to search for content on VoiceSites. These demonstrations will help in presenting the concept of the Spoken Web, which we foresee, can have the same effect in the developing regions community which the WWW has done to the developed world over the last decade.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {431–432},
numpages = {2},
keywords = {organizational and social implications, mobile communication, developing regions, technology adoption},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943485,
author = {Castronovo, Sandro and Endres, Christoph and Del Fabro, Tobias and Schnabel, Nils and M\"{u}ller, Christian A.},
title = {Multimodal Conspicuity-Enhancement for e-Bikes: The Hybrid Reality Model of Environment Transformation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943485},
doi = {10.1145/1943403.1943485},
abstract = {A prototypical conspicuity enhancement (CE) system for vulnerable road users (here e-bikes) is described. We stress that CE is a form of multimodal output. We argue that previous CE approaches have the drawback of affecting uninvolved (road) users. We argue further that augmented reality as an alternative is error prone because objects need to be tracked. Our system implements the hybrid reality modality model, where directed information emanates from the objects themselves and therefore no object recognition/tracking is needed. We describe the components of a functional demonstrator based on standard compliant car-to-car communication components.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {433–434},
numpages = {2},
keywords = {car-to-car communication, multimodal interaction},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943486,
author = {Ehlen, Patrick and Johnston, Michael},
title = {Multimodal Local Search in Speak4it},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943486},
doi = {10.1145/1943403.1943486},
abstract = {Speak4it is a consumer-oriented mobile search application that leverages multimodal input and output to allow users to search for and act on local business information. It supports true multimodal integration where user inputs can be distributed over multiple input modes. In addition to specifying queries by voice e.g. bike repair shops near the golden gate bridge users can combine speech and gesture, for example, gas stations + <route drawn="" on="" display=""> will return the gas stations along the specified route traced on the display. We describe the underlying multimodal architecture and some challenges of supporting multimodal interaction as a deployed mobile service.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {435–436},
numpages = {2},
keywords = {dialog, multimodal user interface, local search},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943487,
author = {Geleijnse, Gijs and Nachtigall, Peggy and van Kaam, Pim and Wijgergangs, Luci\"{e}nne},
title = {A Personalized Recipe Advice System to Promote Healthful Choices},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943487},
doi = {10.1145/1943403.1943487},
abstract = {We present a prototype of a personalized recipe advice system, which facilitates its users to make health-aware meal choices based on past selections. To stimulate the adoption of a healthier lifestyle, a goal setting mechanism is applied in combination with personalized recipe suggestions.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {437–438},
numpages = {2},
keywords = {recipes, goal setting, user centered design},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943488,
author = {Guerini, Marco and Strapparava, Carlo and Stock, Oliviero},
title = {Slanting Existing Text with <i>Valentino</i>},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943488},
doi = {10.1145/1943403.1943488},
abstract = {In this paper we present a tool for valence shifting of natural language texts, named Valentino (VALENced Text INOculator). Valentino can modify existing textual expressions towards more positively or negatively valenced versions. To this end we built specific resources, gathering valenced terms that are semantically or contextually connected to the original one, and implemented strategies that use these resources in the substitution process. Valentino is meant to be a modular component. It is non-domain specific and it requires as its input a coefficient that represents the desired valence for the final expression.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {439–440},
numpages = {2},
keywords = {affective intelligent interfaces, affective natural language processing, text analysis and paraphrasing},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943489,
author = {Hanrahan, Benjamin V. and Weksteen, Thiebaud and Kong, Nicholas and Convertino, Gregorio and Bouchard, Guillaume and Archambeau, Cedric and Chi, Ed H.},
title = {Mail2Wiki: Posting and Curating Wiki Content from Email},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943489},
doi = {10.1145/1943403.1943489},
abstract = {Enterprise wikis commonly see low adoption rates, preventing them from reaching the critical mass that is needed to make them valuable. The high interaction costs for contributing content to these wikis is a key factor impeding wiki adoption. Much of the collaboration among knowledge workers continues to occur in email, which causes useful information to stay siloed in personal inboxes. In this demo we present Mail2Wiki, a system that enables easy contribution and initial curation of content from the personal space of email to the shared repository of a wiki.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {441–442},
numpages = {2},
keywords = {enterprise Wikis, email plugin, sharing, organizing},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943490,
author = {Kim, Heung-Nam and El Saddik, Abdulmotaleb and Lee, Kee-Sung and Lee, Yeon-Ho and Jo, Geun-Sik},
title = {Photo Search in a Personal Photo Diary by Drawing Face Position with People Tagging},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943490},
doi = {10.1145/1943403.1943490},
abstract = {In recent years, people tend to maintain personal photos in digital spaces not only to share their experiences with social friends but also to jog their own memory. Therefore, an effective solution is crucial to the growth of the needs for recording one's daily life. In this study, we have developed a complete system for personal photo diary system, namely MePTroy. With a friendly user interface, users can easily maintain personal episodes and memories with photos. In addition, we also support a flexible method for photo search based on the position of facial appearance that enables users to access episodes quickly. By integrating face detection and recognition technologies, as well as a friendly UI, MePTory offers diverse functionalities to annotate and search photos.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {443–444},
numpages = {2},
keywords = {face photo search, photo diary, people tagging},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943491,
author = {Li, Nan and Wang, Zheshen and Yuriar, Jesus and Li, Baoxin},
title = {TactileFace: A System for Enabling Access to Face Photos by Visually-Impaired People},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943491},
doi = {10.1145/1943403.1943491},
abstract = {Face photos/Portraits play an important role in people's social and emotional life. Unfortunately, this type of media is inaccessible to people with visual impairment. We propose a novel, prototypical system that was designed to demonstrate the feasibility of bridging this accessibility gap through automatic and realtime conversion of face images into their tactile counterparts. Unlike conventional and existing tactile conversion efforts, which are largely done by human specialists, the proposed system serves to provide an intelligent interface between blind computer users and this important type of media, human face images.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {445–446},
numpages = {2},
keywords = {interface, tactile graphics, human face/portrait},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943492,
author = {Miller, Christopher A. and Rye, Jeffrey M. and Wu, Peggy},
title = {Modeling Information Fit: A Tool for Interface Design},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943492},
doi = {10.1145/1943403.1943492},
abstract = {This demonstration illustrates a computational analysis method using information theoretic attributes to quantitatively characterize information need for task performance, as well as information conveyed by a candidate display. Once represented in this way, various computational algorithms can provide a "mismatch" analysis of the "fit" between the two. This approach has been implemented in a prototype user interface analysis tool: MAID (Multi-modal Aid for Interface Design). MAID supports user interface design and redesign in response to procedure revisions for NASA applications. MAID has been demonstrated on examples of designs for the International Space Station, Space Shuttle (both current interfaces and proposed upgrades) and for hypothetical designs for the Crew Exploration Vehicle Orion. At least one of these examples will be presented.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {447–448},
numpages = {2},
keywords = {information theory, formal methods, user interface design, model-based ui, computational analysis, evaluation},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943493,
author = {\"{O}zbal, G\"{o}zde and Strapparava, Carlo},
title = {MEANS: Moving Effective Assonances for Novice Students},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943493},
doi = {10.1145/1943403.1943493},
abstract = {Vocabulary acquisition constitutes a crucial but difficult and time consuming step of learning a foreign language. There exist several teaching methods which aim to facilitate this step by providing learners with various verbal and visual tips. However, building systems based on these methods is generally very costly since it requires so many resources such as time, money and human labor. In this paper, we introduce a fully automatized vocabulary teaching system which uses state-of-the-art natural language processing (NLP) and information retrieval (IR) techniques. For each foreign word the user is willing to learn, the system is capable of automatically producing memorization tips including key- words, sentences, colors, textual animations and images.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {449–450},
numpages = {2},
keywords = {latent semantic analysis, keyword method, vocabulary acquisition, second language learning, text animation, levenshtein distance},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943494,
author = {Paulheim, Heiko and Meyer, Lars},
title = {Ontology-Based Information Visualization in Integrated UIs},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943494},
doi = {10.1145/1943403.1943494},
abstract = {This demo presents the Semantic Data Explorer, which visualizes linked data contained in different integrated applications. It presents a conceptual graphical view of data, which can be combined with user interfaces of legacy applications to facilitate a hybrid view.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {451–452},
numpages = {2},
keywords = {visualization, user experience, linked data, UI integration},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943495,
author = {Reinecke, Katharina and Minder, Patrick and Bernstein, Abraham},
title = {MOCCA - a System That Learns and Recommends Visual Preferences Based on Cultural Similarity},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943495},
doi = {10.1145/1943403.1943495},
abstract = {We demonstrate our culturally adaptive system MOCCA, which is able to automatically adapt its visual appearance to the user's national culture. Rather than only adapting to one nationality, MOCCA takes into account a person's current and previous countries of residences, and uses this information to calculate user-specific preferences. In addition, the system is able to learn new, and refine existing adaptation rules from users' manual modifications of the user interface based on a collaborative filtering mechanism, and from observing the user's interaction with the interface.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {453–454},
numpages = {2},
keywords = {cultural adaptivity, localization, user interface design, cultural similarity},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943496,
author = {Segarra, Franco M. and Leiva, Luis A. and Paredes, Roberto},
title = {A Relevant Image Search Engine with Late Fusion: Mixing the Roles of Textual and Visual Descriptors},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943496},
doi = {10.1145/1943403.1943496},
abstract = {A fundamental problem in image retrieval is how to improve the text-based retrieval systems, which is known as "bridging the semantic gap". The reliance on visual similarity for judging semantic similarity may be problematic due to the semantic gap between low-level content and higher-level concepts. One way to overcome this problem and increase thus retrieval performance is to consider user feedback in an interactive scenario. In our approach, a user starts a query and is then presented with a set of (hopefully) relevant images; selecting from these images those which are more relevant to her. Then the system refines its results after each iteration, using late fusion methods, and allowing the user to dynamically tune the amount of textual and visual information that will be used to retrieve similar images. We describe how does our approach fit in a real-world setting, discussing also an evaluation of results.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {455–456},
numpages = {2},
keywords = {relevant feedback, late fusion, image retrieval},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943497,
author = {Sen, Shilad and Charlton, Henry and Kerwin, Ryan and Lim, Jeremy and Maus, Brandon and Miller, Nathaniel and Naminski, Megan R. and Schneeman, Alex and Tran, Anthony and Nunes, Ernesto and Sparling, E. Isaac},
title = {Macademia: Semantic Visualization of Research Interests},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943497},
doi = {10.1145/1943403.1943497},
abstract = {The Macademia website promotes faculty collaboration and research by visualizing faculty research interests as a dynamic "constellation."Semantic similarity inference algorithms power the site's visualization, allowing users to spatially browse related research interests, and researchers who have those interests.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {457–458},
numpages = {2},
keywords = {semantic similarity, user interfaces, visualization, tagging},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943498,
author = {Sonntag, Daniel and Liwicki, Marcus and Weber, Markus},
title = {Interactive Paper for Radiology Findings},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943498},
doi = {10.1145/1943403.1943498},
abstract = {This paper presents a pen-based interface for clinical radiologists. It is of utmost importance in future radiology practices that the radiology reports be uniform, comprehensive, and easily managed. This means that reports must be "readable" to humans and machines alike. In order to improve reporting practices, we allow the radiologist to write structured reports with a special pen on normal paper. A handwriting recognition and interpretation software takes care of the interpretation of the written report which is transferred into an ontological representation. The resulting report is then stored in a semantic backend system for further use. We will focus on the pen-based interface and new interaction possibilities with gestures in this scenario.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {459–460},
numpages = {2},
keywords = {pen/ink interface, design, medical healthcare},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943500,
author = {Jameson, Anthony},
title = {Tutorial / What Every IUI Researcher Should Know about Human Choice and Decision Making},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943500},
doi = {10.1145/1943403.1943500},
abstract = {There are many reasons why a researcher in the area of intelligent user interfaces (IUI) might decide not to attend this tutorial: 1. I didn't take a tutorial at my last conference. 2. I'm not the kind of person who takes tutorials at conferences. 3. Hardly any of my friends take tutorials. 4. It's not the policy of my organization for researchers to take tutorials. 5. The topic does not seem at first glance to be one that I need to pay attention to. 6. The cost of taking this tutorial is immediate and clear, but the benefits would be spread out over years, and I'm not sure what they would be, or how large. 7. I'm feeling impatient, and I want to move on to the next page.But here's the catch: Every one of the reasons listed above can also cause users to disregard the recommendations of the researcher's novel recommender system, reject the adaptations of their adaptive interface, or generally make choices concerning the use of IUI innovations that seem wrong to the researchers who developed them and maybe to the users, if they took the trouble to reconsider them.In other words: IUI researchers do need to know something about human choice and decision making. Just consulting common knowledge or reading a textbook isn't enough, since the most IUI relevant concepts and results are found in a number of subareas of research on judgment and decision making, learning and habitual behavior, and strategies for influencing choices; and their relevance to IUI issues is hardly ever made explicit.This new tutorial aims to fill this gap: It presents relevant concepts and insights from psychological research with explicit reference to issues that IUI researchers typically encounter. With the help of the take-home supplementary material, participants will be able to understand and predict more realistically (though less confidently) the choices that users make about or with the help of their systems. And they can try in more imaginative ways to influence these choices. They might also think of a fresh research issue for their next project proposal.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {461},
numpages = {1},
keywords = {decision making, intelligent user interfaces},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943501,
author = {Konstan, Joseph A.},
title = {Tutorial / HCI for Recommender Systems: A Tutorial},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943501},
doi = {10.1145/1943403.1943501},
abstract = {This tutorial is an introduction to the concepts and techniques from human-computer interaction, focused on designing usable interfaces. Topics covered include user and task analysis, prototyping, design techniques, interface evaluation, and various processes for designing interfaces. While the overall content mirrors general user interface design courses, a section will focus specifically on challenges in designing intelligent systems (including adaptive systems, recommender systems, agent-based interfaces, etc.), including an exploration of the metaphors and paradigms of interaction with intelligent systems.The tutorial is intended for those who do not have an HCI background (it would be redundant with a typical undergraduate course on the topic), and it is focused on practical techniques that could be applied when designing recommender systems for end users.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {463},
numpages = {1},
keywords = {human computer interaction, user interface design, intelligent systems},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943503,
author = {Hammond, Tracy Anne and Adler, Aaron},
title = {IUI 2011 Workshop: Sketch Recognition},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943503},
doi = {10.1145/1943403.1943503},
abstract = {The 2011 IUI workshop on Sketch Recognition was a daylong event held on February 13th, 2011 in Palo Alto, California. The workshop consisted of an invited talk by Dr. Sharon Oviatt, several short and long talks, a student research poster session, and a series of discussions about pertinent topics in and about the field of sketch recognition.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {465–466},
numpages = {2},
keywords = {CAD, sketching, sketch understanding, design, pen-input computing, sketch recognition, tablet PCs, intelligent user interfaces, document processing},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943504,
author = {Hussein, Tim and Lukosch, Stephan and Ziegler, Juergen and Paulheim, Heiko and Calvary, Gaelle},
title = {2nd International Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS 2011)},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943504},
doi = {10.1145/1943403.1943504},
abstract = {The International Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS 2011) aims to identify emerging trends in interactive system design and execution using semantic models.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {467–468},
numpages = {2},
keywords = {ontologies, semantic models, GUI, user interface, adaptivity},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943505,
author = {Agarwal, Sheetal K. and Paek, Tim and Rajput, Nitendra and Thies, Bill},
title = {2nd International Workshop on Intelligent User Interfaces for Developing Regions: IUI4DR},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943505},
doi = {10.1145/1943403.1943505},
abstract = {Information Technology (IT) has had significant impact on the society and has touched all aspects of our lives. Up and until now computers and expensive devices have fueled this growth. It has resulted in several benefits to the society. The challenge now is to take this success of IT to its next level where IT services can be accessed by the users in developing regions. The focus of the workshop in 2011 is to identify the alternative sources of intelligence and use them to ease the interaction process with information technology. We would like to explore the different modalities, their usage by the community, the intelligence that can be derived by the usage, and finally the design implications on the user interface. We would also like to explore ways in which people in developing regions would react to collaborative technologies and/or use collaborative interfaces that require community support to build knowledge bases (example Wikipedia) or to enable effective navigation of content and access to services.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {469–470},
numpages = {2},
keywords = {illiteracy, developing countries, collaboration},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943506,
author = {De Luca, Ernesto William and Said, Alan and B\"{o}hmer, Matthias and Michahelles, Florian},
title = {Workshop on Context-Awareness in Retrieval and Recommendation},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943506},
doi = {10.1145/1943403.1943506},
abstract = {Context-aware information is widely available in various ways such as interaction patterns, location, devices, annotations, query suggestions and user profiles and is becoming more and more important for enhancing retrieval performance and recommendation results. At the moment, the main issue to cope with is not only recommending or retrieving the most relevant items and content, but defining them ad hoc. Other relevant issues are personalizing and adapting the information and the way it is displayed to the user's current situation (device, location) and interests.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {471–472},
numpages = {2},
keywords = {recommendation, retrieval, context-awareness},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943507,
author = {Endres, Christoph and Meixner, Gerrit and M\"{u}ller, Christian A.},
title = {MIAA 2011: Multimodal Interaction for the Intelligent Environment Car},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943507},
doi = {10.1145/1943403.1943507},
abstract = {Automotive development has been dominated by the constraints of driving. However, natural relations to the more general area of Intelligent User Interfaces exist. Previous research in related fields therefore should be adopted and included. The aim of the 2011 MIAA workshop is to foster discussion between experts in otherwise unrelated fields of research. For example, public interfaces use crossmodal referencing in order to circumvent restrictions by the users current focus on a limited communication channel. Our aim is to raise awareness for this approach, concluding that crossmodal references in the car are helpful to bridge the gap between information inside the car and the environment. Another focus topic of the workshop is eco-friendly driving. Although universally regarded as a necessity, it remains an open question how to encourage drivers to drive ecologically. We discuss for example awards for eco-friendly driving by making it competitive and game-like.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {473–474},
numpages = {2},
keywords = {multimodal interaction, automotive},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943508,
author = {Handschuh, Siegfried and Aroyo, Lora and Thai, VinhTuan},
title = {Visual Interfaces to the Social and Semantic Web (VISSW 2011)},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943508},
doi = {10.1145/1943403.1943508},
abstract = {The large amount of data created, published and consumed by users on the Social and Semantic Web raises significant and exciting research challenges such as data integration as well as effective access to and navigation across heterogeneous data sources on different platforms. Building on the success of the VISSW 2009 and 2010 workshops, the IUI2011 workshop on Visual Interfaces to the Social and Semantic Web aims to bring together researchers and practitioners from different fields to discuss the latest research results and challenges in designing, implementing, and evaluating intelligent interfaces supporting access, navigation and publishing of different types of contents on the Social and Semantic Web. This paper outlines the context of the workshop.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {475–476},
numpages = {2},
keywords = {social web, semantic web, visual interfaces},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943509,
author = {Kahl, Gerrit and Schwartz, Tim and Nurmi, Petteri and Brandherm, Boris and Dim, Eyal and Forsblom, Andreas},
title = {IUI 2011 Workshop on Location Awareness for Mixed and Dual Reality (LAMDa)},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943509},
doi = {10.1145/1943403.1943509},
abstract = {The LAMDa workshop aims at discussing the impact of Dual Reality (DR) and Mixed Reality (MR) on location awareness and other applications in smart environments. Virtual environments - which are an essential part of dual and mixed realities - can be used to create new applications and to enhance already existing applications in the real world. On the other hand, existing sensors in the real world can be used to enhance the virtual world as well. The combination of both worlds can be well illustrated by location-based services, such as location-based advertising.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {477–478},
numpages = {2},
keywords = {mixed reality, positioning, dual reality, location-based services},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943510,
author = {Nakano, Yukiko and Conati, Cristina and Bader, Thomas},
title = {2nd Workshop on Eye Gaze in Intelligent Human Machine Interaction},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943510},
doi = {10.1145/1943403.1943510},
abstract = {This workshop addresses a wide range of issues concerning eye gaze: recognizing user's gaze, generating gaze behaviors in conversational humanoids, analyzing human attentional behaviors during interacting with IUIs, and evaluation of gaze-based IUIs. Through a comprehensive discussion, the workshop aims at bringing together researchers with different backgrounds, and establishing an interdisciplinary research community in "attention aware interactive systems".},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {479–480},
numpages = {2},
keywords = {intelligent human machine interaction, eye gaze},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943511,
author = {Hartmann, Melanie and Schreiber, Daniel and Luyten, Kris and Brdiczka, Oliver and M\"{u}hlh\"{a}user, Max},
title = {Workshop on Interacting with Smart Objects},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943511},
doi = {10.1145/1943403.1943511},
abstract = {The number of smart objects in our everyday life is steadily increasing. In this workshop we discuss how the interaction with these smart objects should be designed from various perspectives.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {481–482},
numpages = {2},
keywords = {ubiquitous computing, tangible interaction, smart objects, interaction design, user studies},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

@inproceedings{10.1145/1943403.1943512,
author = {Aroyo, Lora and Bohnert, Fabian and Kuflik, Tsvi and Oomen, Johan},
title = {Personalized Access to Cultural Heritage (PATCH 2011)},
year = {2011},
isbn = {9781450304191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943403.1943512},
doi = {10.1145/1943403.1943512},
abstract = {This workshop focuses on the specific challenges for personalization in the cultural heritage setting from the point of view of user interaction and visitor experience. It investigates how the user interface - the contact point of visitors and systems - can become more intelligent by means of personalization. Overall, the workshop aims at attracting presentations of novel ideas for addressing these challenges and the current state of the art in this field.},
booktitle = {Proceedings of the 16th International Conference on Intelligent User Interfaces},
pages = {483–484},
numpages = {2},
keywords = {personalization, cultural heritage},
location = {Palo Alto, CA, USA},
series = {IUI '11}
}

