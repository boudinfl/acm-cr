@inproceedings{10.1145/2166966.2166968,
author = {Ziebart, Brian and Dey, Anind and Bagnell, J. Andrew},
title = {Probabilistic Pointing Target Prediction via Inverse Optimal Control},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166968},
doi = {10.1145/2166966.2166968},
abstract = {Numerous interaction techniques have been developed that make "virtual" pointing at targets in graphical user interfaces easier than analogous physical pointing tasks by invoking target-based interface modifications. These pointing facilitation techniques crucially depend on methods for estimating the relevance of potential targets. Unfortunately, many of the simple methods employed to date are inaccurate in common settings with many selectable targets in close proximity. In this paper, we bring recent advances in statistical machine learning to bear on this underlying target relevance estimation problem. By framing past target-driven pointing trajectories as approximate solutions to well-studied control problems, we learn the probabilistic dynamics of pointing trajectories that enable more accurate predictions of intended targets.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {1–10},
numpages = {10},
keywords = {cursor prediction, continuous control, probabilistic inference},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166969,
author = {Baldwin, Tyler and Chai, Joyce},
title = {Towards Online Adaptation and Personalization of Key-Target Resizing for Mobile Devices},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166969},
doi = {10.1145/2166966.2166969},
abstract = {Software (soft) keyboards are becoming increasingly popular on mobile devices. To attempt to improve soft keyboard input accuracy, key-target resizing algorithms that dynamically change the size of each key's target area have been developed. Although methods that employ personalized touch models have been shown to outperform general models, previous work has relied upon laboratory-based offline calibration to collect the data necessary to build these models. Such approaches are unrealistic and interuptive, and it is unlikely that offline calibration can be applied in a realistic usage setting, as hundreds or thousands of touch points are necessary to build the models. To combat this problem, this paper explores the possibility of online adaptation of key-target resizing algorithms. In particular, we propose and examine three online data collection methods that can be used to build and dynamically update personalized key-target resizing models. Our results suggest that a data collection methodology that makes inference based on vocabulary and error correction behavior is able to perform on par with gold standard personalized models, while reducing relative error rate by 10.4% over general models. This approach is simple, computationally inexpensive, and calculable via information that the system already has access to. Additionally, we show that these models can be built quickly, requiring less than one week's worth of text input by an average mobile device user.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {11–20},
numpages = {10},
keywords = {online adaptation, personalization, key-target resizing},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166970,
author = {Ehlen, Patrick and Johnston, Michael},
title = {Multimodal Interaction Patterns in Mobile Local Search},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166970},
doi = {10.1145/2166966.2166970},
abstract = {Speak4it™ is a mobile search application that leverages multimodal input and integration to allow users to search for and act on local business information. We present an initial empirical analysis of user interaction with a multimodal local search application deployed in the field with real users. Specifically, we focus on queries involving multimodal commands, and analyze multimodal interaction behaviors seen in a deployed multimodal system.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {21–24},
numpages = {4},
keywords = {multimodal, location-based, search, gesture, speech},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166971,
author = {Silva, Hugo and Louren\c{c}o, Andr\'{e} and Fred, Ana},
title = {In-Vehicle Driver Recognition Based on Hand ECG Signals},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166971},
doi = {10.1145/2166966.2166971},
abstract = {We present a system for in-vehicle driver recognition based on biometric information extracted from electrocardiographic (ECG) signals collected at the hands. We recur to non-intrusive techniques, that are easy to integrate into components with which the driver naturally interacts with, such as the steering wheel. This system is applicable to the automatic customization of vehicle settings according to the perceived driver, being also prone to expand the security features of the vehicle through the detection of hands-off steering wheel events in a continuous or near-continuous manner. We have performed randomized tests for performance evaluation of the system, in a subject identification scenario, using closed sets of up to 5 subjects, showing promising results for the intended application.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {25–28},
numpages = {4},
keywords = {user identification, customization, vehicles, ecg, biometrics},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166972,
author = {Kristensson, Per Ola and Vertanen, Keith},
title = {Performance Comparisons of Phrase Sets and Presentation Styles for Text Entry Evaluations},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166972},
doi = {10.1145/2166966.2166972},
abstract = {We empirically compare five different publicly-available phrase sets in two large-scale (N = 225 and N = 150) crowdsourced text entry experiments. We also investigate the impact of asking participants to memorize phrases before writing them versus allowing participants to see the phrase during text entry. We find that asking participants to memorize phrases increases entry rates at the cost of slightly increased error rates. This holds for both a familiar and for an unfamiliar text entry method. We find statistically significant differences between some of the phrase sets in terms of both entry and error rates. Based on our data, we arrive at a set of recommendations for choosing suitable phrase sets for text entry evaluations.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {29–32},
numpages = {4},
keywords = {phrase sets, keyboards, crowdsourcing, text entry},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166973,
author = {Demmans Epp, Carrie and Djordjevic, Justin and Wu, Shimu and Moffatt, Karyn and Baecker, Ronald M.},
title = {Towards Providing Just-in-Time Vocabulary Support for Assistive and Augmentative Communication},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166973},
doi = {10.1145/2166966.2166973},
abstract = {Many people cannot communicate effectively with those around them. The causes vary but several tools and strategies can support their communication. These tools, which collectively fall under the banner of Assistive and Augmentative Communication (AAC), are rarely adaptive. Of those that are, few provide context-based or just-in-time vocabulary support to users even though the proliferation of smartphones makes this possible. To meet this need, we developed four algorithms to retrieve relevant vocabulary from Internet-based corpora. We used discourse completion tasks to evaluate each algorithm's ability to identify appropriate vocabulary across a set of specific contexts. The results indicate that our approach identifies appropriate context-specific words that complement general AAC vocabularies: when combined with a typical base vocabulary, the algorithms outperformed the support provided by the base vocabulary alone. They did this by adding small targeted vocabularies.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {33–36},
numpages = {4},
keywords = {adaptivity, vocabulary support, aac},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166974,
author = {Feld, Michael and Momtazi, Saeedeh and Freigang, Farina and Klakow, Dietrich and M\"{u}ller, Christian},
title = {Mobile Texting: Can Post-ASR Correction Solve the Issues? An Experimental Study on Gain vs. Costs},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166974},
doi = {10.1145/2166966.2166974},
abstract = {The next big step in embedded, mobile speech recognition will be to allow completely free input as it is needed for messaging like SMS or email. However, unconstrained dictation remains error-prone, especially when the environment is noisy. In this paper, we compare different methods for improving a given free-text dictation system used to enter textbased messages in embedded mobile scenarios, where distraction, interaction cost, and hardware limitations enforce strict constraints over traditional scenarios. We present a corpus-based evaluation, measuring the trade-off between improvement of the word error rate versus the interaction steps that are required under various parameters. Results show that by post-processing the output of a "black box" speech recognizer (e.g. a web-based speech recognition service), a reduction of word error rate by 55% (10.3% abs.) can be obtained. For further error reduction, however, a richer representation of the original hypotheses (e.g. lattice) is necessary.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {37–40},
numpages = {4},
keywords = {messaging, error correction, speech recognition, automotive},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166976,
author = {Young, James and Ishii, Kentaro and Igarashi, Takeo and Sharlin, Ehud},
title = {Style by Demonstration: Teaching Interactive Movement Style to Robots},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166976},
doi = {10.1145/2166966.2166976},
abstract = {The style in which a robot moves, expressed through its gait or locomotion, can convey effective messages to people. For example, a robot could move aggressively in reaction to a person's actions, or alternatively react using a set of careful, submissive movements. Designing, implementing and programming robotic interfaces that react to users' actions with properly styled movements can be a difficult, daunting, and time consuming technical task. On the other hand, most people can easily perform such stylistic tasks and movements, for example, through acting them out.Following this observation, we propose to enable people to use their existing teaching skills to directly demonstrate to robots, via in-situ acting, a desired style of interaction. In this paper we present an initial style-by-demonstration (SBD) proof-of-concept of our approach, allowing people to teach a robot specific, interactive locomotion styles by providing a demonstration. We present a broomstick-robot interface for directly demonstrating locomotion style to a collocated robot, and a design critique evaluation by experienced programmers that compares our SBD approach to traditional programming methods.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {41–50},
numpages = {10},
keywords = {tangible user interfaces, style by demonstration, qualitative evaluation, programming by demonstration, social human robot interaction, locomotion style},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166977,
author = {Cheema, Salman and LaViola, Joseph},
title = {PhysicsBook: A Sketch-Based Interface for Animating Physics Diagrams},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166977},
doi = {10.1145/2166966.2166977},
abstract = {We present PhysicsBook, a prototype system that enables users to solve physics problems using a sketch-based interface and then animates any diagram used in solving the problem to show that the solution is correct. PhysicsBook recognizes the diagrams in the solution and infers relationships among diagram components through the recognition of mathematics and annotations such as arrows and dotted lines. For animation, PhysicsBook uses a customized physics engine that provides entry points for hand-written mathematics and diagrams. We discuss the design of PhysicsBook, including details of algorithms for sketch recognition, inference of user intent and creation of animations based on the mathematics written by a user. Specifically, we describe how the physics engine uses domain knowledge to perform data transformations in instances where it cannot use a given equation directly. This enables PhysicsBook to deal with domains of problems that are not directly related to classical mechanics. We provide examples of scenarios of how PhysicsBook could be used as part of an intelligent tutoring system and discuss the strengths and weaknesses of our current prototype. Lastly, we present the findings of a preliminary usability study with five participants.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {51–60},
numpages = {10},
keywords = {sketch recognition, sketch-based user interfaces, mathematical sketching, inferring user intent},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166978,
author = {de la Villa, Manuel and Aparicio, Fernando and Ma\~{n}a, Manuel J. and de Buenaga, Manuel},
title = {A Learning Support Tool with Clinical Cases Based on Concept Maps and Medical Entity Recognition},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166978},
doi = {10.1145/2166966.2166978},
abstract = {The search for truthful health information through Internet is an increasingly complex process due to the growing amount of resources. Access to information can be difficult to control even in environments where the goal pursued is well-defined, as in the case of learning activities with medical students. In this paper, we present a computer tool devised to ease the process of understanding medical concepts from information in clinical case histories. To this end, it automatically constructs concept maps and presents reliable information from different ontologies and knowledge bases. The two main components of the system are an Intelligent Information Access interface and a Concept Map Graph that retrieves medical concepts from a text input, and provides rich information and semantically related concepts. The paper includes a user evaluation of the first component and a systematic assessment for the second component. Results show that our proposal can be efficient and useful for students in a medical learning environment.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {61–70},
numpages = {10},
keywords = {ontologies, visual information retrieval, learning-based interaction, software systems in medicine, health informatics, semantic interoperability, concept-based learning},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166979,
author = {Kim, Jihie and Chang, Yu-Han and Cai, Sen and Jain, Siddharth},
title = {PedConnect: An Intelligent Assistant for Teacher Social Networking},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166979},
doi = {10.1145/2166966.2166979},
abstract = {Social networking has gained immense traction in many areas, including teaching and learning. Networking sites for teachers aim to facilitate teacher communication and information sharing, but fall short of their potential. In order to support more effective use of online resources and better communication among teachers, we develop a suite of new user modeling and recommendation capabilities within a middle school teacher networking site. We foster collaboration among novice and experienced teachers when they share similar interests, enabling new mentoring relationships, and promote the use of relevant educational resources. We illustrate our approach with an implemented system called PedConnect that analyzes user activities and presents intelligent suggestions for collaboration and resource use.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {71–74},
numpages = {4},
keywords = {teacher social networking, topic modeling, user profiling},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166981,
author = {Bigdelou, Ali and Schwarz, Loren and Navab, Nassir},
title = {An Adaptive Solution for Intra-Operative Gesture-Based Human-Machine Interaction},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166981},
doi = {10.1145/2166966.2166981},
abstract = {Computerized medical systems play a vital role in the operating room, however, sterility requirements and interventional workflow often make interaction with these devices challenging for surgeons. Typical solutions, such as delegating physical control of keyboard and mouse to assistants, add an undesirable level of indirection. We present a touchless, gesture-based interaction framework for the operating room that lets surgeons define a personalized set of gestures for controlling arbitrary medical computerized systems. Instead of using cameras for capturing gestures, we rely on a few wireless inertial sensors, placed on the arms of the surgeon, eliminating the dependence on illumination and line-of-sight. A discriminative gesture recognition approach based on kernel regression allows us to simultaneously classify performed gestures and to track the relative spatial pose within each gesture, giving surgeons fine-grained control of continuous parameters. An extensible software architecture enables a dynamic association of learned gestures to arbitrary intraoperative computerized systems. Our experiments illustrate the performance of our approach and encourage its practical applicability.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {75–84},
numpages = {10},
keywords = {gesture-based interaction, operating room, inertial sensors},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166982,
author = {Jiang, Yingying and Tian, Feng and Zhang, Xiaolong and Liu, Wei and Dai, Guozhong and Wang, Hongan},
title = {Unistroke Gestures on Multi-Touch Interaction: Supporting Flexible Touches with Key Stroke Extraction},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166982},
doi = {10.1145/2166966.2166982},
abstract = {Gesture inputs on multi-touch tabletops usually involve multiple fingers (more than two) and casual touchdowns or liftoffs of fingers. This flexibility of touch gestures allows more natural user interaction, but also poses new challenges for accurate recognition of multi-touch gestures. To address these challenges, we propose a new approach to recognize flexible multi-touch stroke gestures on tabletops. Based on a user study on multi-touch unistroke gestures, we develop a gesture recognition method by extracting key strokes embedded in flexible multi-touch input. Our evaluation study result shows that this method can greatly improve the recognition accuracy of flexible multi-touch unistroke gestures on tabletops.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {85–88},
numpages = {4},
keywords = {unistroke gesture recognition, flexible gesture inputs, multi-touch interaction},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166983,
author = {Kristensson, Per Ola and Nicholson, Thomas and Quigley, Aaron},
title = {Continuous Recognition of One-Handed and Two-Handed Gestures Using 3D Full-Body Motion Tracking Sensors},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166983},
doi = {10.1145/2166966.2166983},
abstract = {In this paper we present a new bimanual markerless gesture interface for 3D full-body motion tracking sensors, such as the Kinect. Our interface uses a probabilistic algorithm to incrementally predict users' intended one-handed and twohanded gestures while they are still being articulated. It supports scale and translation invariant recognition of arbitrarily defined gesture templates in real-time. The interface supports two ways of gesturing commands in thin air to displays at a distance. First, users can use one-handed and two-handed gestures to directly issue commands. Second, users can use their non-dominant hand to modulate single-hand gestures. Our evaluation shows that the system recognizes one-handed and two-handed gestures with an accuracy of 92.7%--96.2%.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {89–92},
numpages = {4},
keywords = {motion tracking, gesture recognition, wall-sized displays},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166984,
author = {Kurdyukova, Ekaterina and Redlin, Matthias and Andr\'{e}, Elisabeth},
title = {Studying User-Defined IPad Gestures for Interaction in Multi-Display Environment},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166984},
doi = {10.1145/2166966.2166984},
abstract = {The paper investigates the iPad gestures that users naturally perform for data transfer. We examine the transfer between two iPads, iPad and a tabletop, and iPad and a public display. Three gesture modalities are investigated: multi-touch gestures, performed using iPad display, spatial gestures, performed by manipulating iPad in 3D space, and direct contact gestures, involving the physical contact of iPad and other device. We report on user choices of the modalities and gesture types, and derive critical points for the design of iPad gestures.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {93–96},
numpages = {4},
keywords = {multi-display interaction, tablet pc, user-defined gestures},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166985,
author = {Gehring, Sven and L\"{o}chtefeld, Markus and Daiber, Florian and B\"{o}hmer, Matthias and Kr\"{u}ger, Antonio},
title = {Using Intelligent Natural User Interfaces to Support Sales Conversations},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166985},
doi = {10.1145/2166966.2166985},
abstract = {During sales conversations, gestures and mimics are of high importance to communicate information about a product. One prominent example for such sales gestures is the meat and cheese counter, which is one of the remaining spots in supermarkets where sales persons interact with customers. Interactions at such counters in supermarkets normally follow a simple protocol. The customer points at an item of choice. The employee takes out the item and, in most of the cases the product needs to be cut to fit the amount the customer wants to buy. Often it is ambiguous about what specific product the customer and the employees are talking about. Up to now, there are just a few efforts in HCI research to enrich communication at the point of sale. In this paper we report and analyze one scenario in which an intelligent natural user interface can support communication between customer and employee in a sales conversation. Furthermore, we report on our prototype that is able to track pointing gestures by using a depth camera and to display information about items pointed at.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {97–100},
numpages = {4},
keywords = {gestural interaction, pointing, sales conversation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166986,
author = {Miller, Sam and Smith, Andy and Bahram, Sina and St. Amant, Robert},
title = {A Glove for Tapping and Discrete 1D/2D Input},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166986},
doi = {10.1145/2166966.2166986},
abstract = {This paper describes a glove with which users enter input by tapping fingertips with the thumb or by rubbing the thumb over the palmar surfaces of the middle and index fingers. The glove has been informally tested as the controller for two semi-autonomous robots in a a 3D simulation environment. A preliminary evaluation of the glove's performance is presented.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {101–104},
numpages = {4},
keywords = {glove-based interaction, mobile, tactile, proprioception, wearable},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166987,
author = {Satyanarayan, Arvind and Weibel, Nadir and Hollan, James},
title = {Using Overlays to Support Collaborative Interaction with Display Walls},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166987},
doi = {10.1145/2166966.2166987},
abstract = {Large-scale display walls, and the high-resolution visualizations they support, promise to become ubiquitous. Natural interaction with them, especially in collaborative environments, is increasingly important and yet remains an on-going challenge. Part of the problem is a resolution mismatch between low-resolution input devices and high-resolution display walls. In addition, enabling concurrent use by multiple users is difficult - for example, how would this large workspace be managed for multiple users and what novel collaborative interactions could occur? In this paper, we present an overlay interface element superimposed on wall-display applications to help constrain interaction, focus attention on subsections of a display wall, and facilitate a collaborative multi-user workflow.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {105–108},
numpages = {4},
keywords = {multiuser interaction, high-resolution ultra-scale displays, multi-scale interaction},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166989,
author = {Horiuchi, Yosuke and Inoue, Tomoo and Okada, Ken-ichi},
title = {Virtual Stage Linked with a Physical Miniature Stage to Support Multiple Users in Planning Theatrical Productions},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166989},
doi = {10.1145/2166966.2166989},
abstract = {Theater is a collaborative art form that involves production team members with different specialties. Because theater involves various technical elements, such as stage design and lighting, the production team must work in cooperation among various departments to design a theatrical production. When planning a theatrical production, it is difficult to visualize the stage as a whole and to incorporate the ideas of production team members from various departments. In this paper, we propose a system for reproducing the theatrical stage by means of a virtual stage linked to a physical miniature stage. The miniature stage is presented on a tabletop interface, and the virtual stage is created by computer graphics to reflect the actions on the miniature stage in real time. By actually presenting theatrical production ideas in two spaces, users can more easily collaborate and gain a comprehensive view of the stage.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {109–118},
numpages = {10},
keywords = {theater, virtual space, tangible interface, tabletop interface},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166990,
author = {Gilroy, Stephen and Porteous, Julie and Charles, Fred and Cavazza, Marc},
title = {Exploring Passive User Interaction for Adaptive Narratives},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166990},
doi = {10.1145/2166966.2166990},
abstract = {Previous Interactive Storytelling systems have been designed to allow active user intervention in an unfolding story, using established multi-modal interactive techniques to influence narrative development. In this paper we instead explore the use of a form of passive interaction where users' affective responses, measured by physiological proxies, drive a process of narrative adaptation. We introduce a system that implements a passive interaction loop as part of narrative generation, monitoring users' physiological responses to an on-going narrative visualization and using these to adapt the subsequent development of character relationships, narrative focus and pacing. Idiomatic cinematographic techniques applied to the visualization utilize existing theories of establishing characteristic emotional tone and viewer expectations to foster additional user response. Experimental results support the applicability of filmic emotional theories in a non-film visual realization, demonstrating significant appropriate user physiological response to narrative events and "emotional cues". The subsequent narrative adaptation provides a variation of viewing experience with no loss of narrative comprehension.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {119–128},
numpages = {10},
keywords = {passive interaction, interactive storytelling, entertainment computing, physiological},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166992,
author = {Sharmin, Moushumi and Bergman, Lawrence and Lu, Jie and Konuru, Ravi},
title = {On Slide-Based Contextual Cues for Presentation Reuse},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166992},
doi = {10.1145/2166966.2166992},
abstract = {Reuse of existing presentation materials is prevalent among knowledge workers. However, finding the most appropriate material for reuse is challenging. Existing information management and search tools provide inadequate support for reuse due to their dependence on users' ability to effectively categorize, recall, and recognize existing materials. Based on our findings from an online survey and contextual interviews, we designed and implemented a slide-based contextual recommender, ConReP, for supporting reuse of presentation materials. ConReP utilizes a user-selected slide as a search-key, recommends materials based on similarity to the selected slide, and provides a local-context-based visual representation of the recommendations. Users input provides new insight into presentation reuse and reveals that slide-based search is more effective than keyword-based search, local-context-based visual representation helps in better recall and recognition, and shows the promise of this general approach of exploiting individual slides and local-context for better presentation reuse.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {129–138},
numpages = {10},
keywords = {visual representation, contextual recommendation, slide-based search, local context},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166993,
author = {Campbell, Amy and Wienberg, Christopher and Gordon, Andrew},
title = {Collecting Relevance Feedback on Titles and Photographs in Weblog Posts},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166993},
doi = {10.1145/2166966.2166993},
abstract = {We investigate new interfaces that allow users to specify topics of interest in streams of weblog stories by providing relevance feedback to a search algorithm. Noting that weblog stories often contain photographs taken by the blogger during the course of the narrated events, we investigate whether these photographs can serve as a proxy for the whole post when users are making judgments as to the post's relevance. We developed a new story annotation interface for collecting relevance feedback with three variations: users are presented either with the full post as it appears in a weblog, an embedded photograph, or only the title of the post. We describe a user evaluation that compares annotation time, quality, and subjective user experience across each of these three conditions. The results show that relevance judgments based on embedded photographs or titles are far less accurate than when reading the whole weblog post, but the time required to acquire an accurate model of the user's topic interest is greatly reduced.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {139–148},
numpages = {10},
keywords = {photographs, weblogs, user study, user interfaces for machine learning, relevance feedback},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166994,
author = {Hangal, Sudheendra and Nagpal, Abhinay and Lam, Monica},
title = {Effective Browsing and Serendipitous Discovery with an Experience-Infused Browser},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166994},
doi = {10.1145/2166966.2166994},
abstract = {In the digital age, users can have perfect recall of their online experiences. In this paper, we explore how this recall can be leveraged during web browsing.We have built a system called the Experience-Infused Browser that indexes a user's digital history such as email and chat archives. As the user browses the web, it observes the contents of pages viewed, and appropriately highlights named entities on the page that the user has encountered in the past. This browser has two benefits. First, it highlights terms on the page that occur frequently in the user's communications, effectively personalizing the page for the user. Second, the system can remind the user of names that he has encountered in the past but may not remember.We evaluated how users reacted to the browser during organic web browsing. Our users have reported that it was useful on crowded web pages to surface content that they otherwise may have missed, and in recalling serendipitous connections to people that they had forgotten. Most of our users said they would use the browser beyond the experimental study, indicating that they derived clear benefit from it.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {149–158},
numpages = {10},
keywords = {web browsing, personal digital archives, annotation, personalization, email},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166995,
author = {Dong, Ruihai and McCarthy, Kevin and O'Mahony, Michael and Schaal, Markus and Smyth, Barry},
title = {Towards an Intelligent Reviewer's Assistant: Recommending Topics to Help Users to Write Better Product Reviews},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166995},
doi = {10.1145/2166966.2166995},
abstract = {User opinions and reviews are an important part of the modern web and all major e-commerce sites typically provide their users with the ability to provide and access customer reviews across their product catalog. Indeed this has become a vital part of the service provided by sites like Amazon and TripAdvisor, so much so that many of us will routinely check appropriate product reviews before making a purchase decision, regardless of whether we intend to purchase online or not. The importance of reviews has highlighted the need to help users to produce better reviews and in this paper we describe the development and evaluation of a Reviewer's Assistant for this purpose. We describe a browser plugin that is designed to work with major sites like Amazon and to provide users with suggestions as they write their reviews. These suggestions take the form of topics (e.g. product features) that a reviewer may wish to write about and the suggestions automatically adapt as the user writes their review. We describe and evaluate a number of different algorithms to identify useful topics to recommend to the user and go on to describe the results of a preliminary live-user trial.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {159–168},
numpages = {10},
keywords = {intelligent user interfaces, text mining, browser plugin., writer's assistance},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166996,
author = {Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
title = {Are Explanations Always Important? A Study of Deployed, Low-Cost Intelligent Interactive Systems},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166996},
doi = {10.1145/2166966.2166996},
abstract = {Intelligent interactive systems (IIS) have great potential to improve users' experience with technology by tailoring their behaviour and appearance to users' individual needs; however, these systems, with their complex algorithms and dynamic behaviour, can also suffer from a lack of comprehensibility and transparency. We present the results of two studies examining the comprehensibility of, and desire for explanations with deployed, low-cost IIS. The first study, a set of interviews with 21 participants, reveals that i) comprehensibility is not always dependent on explanations, and ii) the perceived cost of viewing explanations tends to outweigh the anticipated benefits. Our second study, a two-week diary study with 14 participants, confirms these findings in the context of daily use, with participants indicating a desire for an explanation in only 7% of diary entries. We discuss the implications of our findings for the design of explanation facilities.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {169–178},
numpages = {10},
keywords = {qualitative evaluations, recommender systems, diary studies, transparency, explanations, comprehensibility},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166998,
author = {Kang, Byungkyu and O'Donovan, John and H\"{o}llerer, Tobias},
title = {Modeling Topic Specific Credibility on Twitter},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166998},
doi = {10.1145/2166966.2166998},
abstract = {This paper presents and evaluates three computational models for recommending credible topic-specific information in Twitter. The first model focuses on credibility at the user level, harnessing various dynamics of information flow in the underlying social graph to compute a rating. The second model applies a content-based strategy to compute a finer-grained credibility score for individual tweets. Lastly, we discuss a third model which combines facets from both models in a hybrid method, using both averaging and filtering hybrid strategies. To evaluate our novel credibility models, we perform an evaluation on 7 topic specific data sets mined from the Twitter streaming API, with specific focus on a data set of 37K users who tweeted about the topic "Libya". Results show that the social model outperfoms hybrid and content-based prediction models in terms of predictive accuracy over a set of manually collected credibility ratings on the "Libya" dataset.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {179–188},
numpages = {10},
keywords = {microblogs, data mining, social networking, credibility, trust},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2166999,
author = {Nichols, Jeffrey and Mahmud, Jalal and Drews, Clemens},
title = {Summarizing Sporting Events Using Twitter},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2166999},
doi = {10.1145/2166966.2166999},
abstract = {The status updates posted to social networks, such as Twitter and Facebook, contain a myriad of information about what people are doing and watching. During events, such as sports games, many updates are sent describing and expressing opinions about the event. In this paper, we describe an algorithm that generates a journalistic summary of an event using only status updates from Twitter as a source. Temporal cues, such as spikes in the volume of status updates, are used to identify the important moments within an event, and a sentence ranking method is used to extract relevant sentences from the corpus of status updates describing each important moment within an event. We evaluate our algorithm compared to human-generated summaries and the previous best summarization algorithm, and find that the results of our method are superior to the previous algorithm and approach the readability and grammaticality of the human-generated summaries.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {189–198},
numpages = {10},
keywords = {journalism, social media, status updates, implicit crowdsourcing},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167000,
author = {Lu, Jie and Wen, Zhen and Pan, Shimei and Lai, Jennifer},
title = {EPIC: A Multi-Tiered Approach to Enterprise Email Prioritization},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167000},
doi = {10.1145/2166966.2167000},
abstract = {We present Enterprise Priority Inbox Classifier (EPIC), an automatic personalized email prioritization system based on a topic-based user model built from the user's email data and relevant enterprise information. The user model encodes the user's topics of interest and email processing behaviors (e.g. read/reply/file) at the granularity of pair-wise interactions between the user and each of his/her email contacts. Given a new message, the user model is used in combination with the message metadata and content to determine the values of a set of contextual features. Contextual features include people-centric features representing information about the user's interaction history and relationship with the email sender, as well as message-centric features focusing on the properties of the message itself. Based on these feature values, EPIC uses a dynamic strategy to combine a global priority classifier with a user-specific classifier for determining the message's priority. An evaluation of EPIC based on 2,064 annotated email messages from 11 users, using 10-fold cross-validation, showed that the system achieves an average accuracy of 81.3%. The user-specific classifier contributed an improvement of 11.5%. Lastly we report on findings regarding the relative value of different contextual features for email prioritization.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {199–202},
numpages = {4},
keywords = {email, enterprise, priority inbox, prioritization, user model},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167001,
author = {Zhou, Michelle and Zhang, Wei and Smith, Barton and Varga, Erika and Farias, Martin and Badenes, Hernan},
title = {Finding Someone in My Social Directory Whom i Do Not Fully Remember or Barely Know},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167001},
doi = {10.1145/2166966.2167001},
abstract = {REACH is an intelligent, people-finding system that helps users to find someone in their social directory, especially those whom they do not fully remember or barely know. It analyzes a user's communication and social networking data to automatically extract all the contacts and derive multiple facets to characterize each contact in relation to the user. It then employs a personalized, faceted search to retrieve and present a ranked list of matched contacts based on their properties. A preliminary evaluation shows the effectiveness of our approach.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {203–206},
numpages = {4},
keywords = {contact, multifaceted people finding, social directory},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167003,
author = {Luong, The Nhan and Etcheverry, Patrick and Marquesuza\`{a}, Christophe and Nodenot, Thierry},
title = {A Visual Programming Language for Designing Interactions Embedded in Web-Based Geographic Applications},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167003},
doi = {10.1145/2166966.2167003},
abstract = {Visual programming languages (VPLs) provide notations for representing both the intermediate and the final results of a knowledge engineering process. Whereas some VPLs particularly focus on control flow and/or data flow of a software, very few VPLs stress on the interactive dimension of application (dialogue flow). This paper focuses on a VPL allowing designers to specify interactions between a user and a system, in the field of Web-based geographic applications. We first present the underlying interaction model that the VPL is based on, and then the detailed characteristics of the VPL. We show how this VPL has been integrated in a graphical design framework allowing designers to immediately assess their specification. Then we illustrate the way to use the framework from the design step to the final code generation step. Last, we detail an experimentation aiming at evaluating the strengths and the weaknesses of our VPL.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {207–216},
numpages = {10},
keywords = {visual design language, geographic application design, interaction design, visual authoring tools},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167004,
author = {Bellucci, Federico and Ghiani, Giuseppe and Patern\`{o}, Fabio and Porta, Claudio},
title = {Automatic Reverse Engineering of Interactive Dynamic Web Applications to Support Adaptation across Platforms},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167004},
doi = {10.1145/2166966.2167004},
abstract = {The effort and time required to develop user interface models has been one of the main limitations to the adoption of model-based approaches, which enable intelligent processing of user interface descriptions. In this paper, we present a tool to perform reverse engineering of interactive dynamic Web applications into a model-based framework able to describe them at various abstraction levels. We indicate how information in HTML, HTML 5, CSS, Ajax and JavaScript is transformed into such logical framework, which facilitates adaptation to other types of interactive devices. We also discuss how this reverse engineering tool has been exploited in an environment for run-time adaptation or migration of interactive Web applications to various devices in ubiquitous use cases.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {217–226},
numpages = {10},
keywords = {web applications, user interface reverse engineering, model-based user interface descriptions},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167005,
author = {Pedemonte, Pablo and Mahmud, Jalal and Lau, Tessa},
title = {Towards Automatic Functional Test Execution},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167005},
doi = {10.1145/2166966.2167005},
abstract = {As applications are developed, functional tests ensure they continue to function as expected. Nowadays, functional testing is mostly done manually, with human testers verifying a system's functionality themselves, following hand-written instructions. While there exist tools supporting functional test automation, in practice they are hard to use, require programming skills, and do not provide good support for test maintenance. In this paper, we take an alternative approach: we semi-automatically convert hand-written instructions into automated tests. Our approach consists of two stages: first, employing machine learning and natural language processing to compute an intermediate representation from test steps; and second, interactively disambiguating that representation to create a fully automated test. These two stages comprise a complete system for converting hand-written functional tests into automated tests. We also present a quantitative study analyzing the effectiveness of our approach. Our results show that 70% of manual test steps can be automatically converted to automated test steps with no user intervention.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {227–236},
numpages = {10},
keywords = {natural language processing, supervised learning, manual test automation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167006,
author = {Graells, Eduardo and Jaimes, Alejandro},
title = {Lin-Spiration: Using a Mixture of Spiral and Linear Visualization Layouts to Explore Time Series},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167006},
doi = {10.1145/2166966.2167006},
abstract = {Time series data is pervasive in many domains and interactive visualization of such data is useful for a wide range of tasks including analysis and prediction. In spite of the importance of visualizing time series data and the fact that time series data is often easily interpretable, traditional approaches are either very simple and limited, or are aimed at domain experts. In this paper, we propose a novel interactive visualization paradigm for exploring and comparing multiple sets of time series data. In particular, we propose a focus+context approach, where a "focus" segment of a time series is zoomed into and visualized using a linear layout at one scale, while the remaining segments of the time series (i.e., the context) are visualized using spiral data layouts. Our paradigm allows the user to dynamically select and compare different sections of each time series independently, facilitating the exploration of time series data in a fun and engaging way.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {237–240},
numpages = {4},
keywords = {focus + context, visual interfaces, visualization, time series},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167008,
author = {Ludwig, Jeremy and Geiselman, Eric},
title = {Intelligent Pairing Assistant for Air Operation Centers},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167008},
doi = {10.1145/2166966.2167008},
abstract = {Within an Air Operations Center (AOC), planners make crucial decisions to create the air plan for any given day. They are expected to complete the plan in part by pairing targeting or collection tasks with the available platforms. Any assistance these planners can acquire to help create the plan in a timely manner would make the entire process more efficient and effective. This paper describes the Intelligent Pairing Assistant (IPA) prototype, which would provide pairing recommendations at specific decision points in the planning process. IPA is designed as a plug-in for software systems already in use within AOCs. The primary contribution described in this paper is the application of existing research in intelligent user interfaces to a novel domain.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {241–244},
numpages = {4},
keywords = {air operations center, intelligent user interface, pairing, reinforcement learning},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167009,
author = {Bahram, Sina and Chakraborty, Arpan and St. Amant, Robert},
title = {CAVIAR: A Vibrotactile Device for Accessible Reaching},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167009},
doi = {10.1145/2166966.2167009},
abstract = {CAVIAR is designed to aid people with vision impairment in locating, identifying, and acquiring objects in their peripersonal space. A mobile phone, worn on the chest, captures video in front of the user; the computer vision component locates the user's hand and objects in the video stream. The auditory component informs the user about the presence of objects. On user confirmation, the reaching component sends signals to vibrotactile actuators on the user's wristband, guiding the hand to a specific object. This paper describes an end-to-end prototype of CAVIAR and its formative evaluation.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {245–248},
numpages = {4},
keywords = {accessibility, haptic, mobile, tactile},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167010,
author = {Liu, Jie and Yu, Chun and Xu, Wenchang and Shi, Yuanchun},
title = {Clustering Web Pages to Facilitate Revisitation on Mobile Devices},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167010},
doi = {10.1145/2166966.2167010},
abstract = {Due to small screens, inaccuracy of input and other limitations of mobile devices, revisitation of Web pages in mobile browsers takes more time than that in desktop browsers. In this paper, we propose a novel approach to facilitate revisitation. We designed AutoWeb, a system that clusters opened Web pages into different topics based on their contents. Users can quickly find a desired opened Web page by narrowing down the searching scope to a group of Web pages that share the same topic. Clustering accuracy is evaluated to be 92.4% and computing resource consumption was proved to be acceptable. A user study was conducted to explore user experience and how much AutoWeb facilitates revisitation. Results showed that AutoWeb could save up a significant time for revisitation and participants rated the system highly.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {249–252},
numpages = {4},
keywords = {clustering, mobile web, revisitation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167011,
author = {Forsblom, Andreas and Nurmi, Petteri and \r{A}man, Pirkka and Liikkanen, Lassi},
title = {Out of the Bubble: Serendipitous Even Recommendations at an Urban Music Festival},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167011},
doi = {10.1145/2166966.2167011},
abstract = {Advances in positioning technologies have resulted in a surge of location-based recommendation systems for mobile devices. A central challenge in these systems is to avoid the so-called filter bubble effect, i.e., that people are not only exposed to information that is in line with their personal ecosystem, but that they can also discover novel and otherwise interesting content. We present results from a field study of a mobile recommendation system that has been aimed to support serendipitous discovery of events at an urban culture festival. Results from the study indicate that suitably designed recommendations together with access to relevant external information sources can lead to serendipitous discovery of new content, such as new artists, bands or individual songs. Our results also indicate that proximity has little effect on the effectiveness of serendipitous recommendations.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {253–256},
numpages = {4},
keywords = {urban computing, serendipity, mobile recommendations},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167012,
author = {Martinez-Gomez, Pascual and Chen, Chen and Hara, Tadayoshi and Kano, Yoshinobu and Aizawa, Akiko},
title = {Image Registration for Text-Gaze Alignment},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167012},
doi = {10.1145/2166966.2167012},
abstract = {Applications using eye-tracking devices need a higher accuracy in recognition when the task reaches a certain complexity. Thus, more sophisticated methods to correct eye-tracking measurement errors are necessary to lower the penetration barrier of eye-trackers in unconstrained tasks. We propose to take advantage of the content or the structure of textual information displayed on the screen to build informed error-correction algorithms that generalize well. The idea is to use feature-based image registration techniques to perform a linear transformation of gaze coordinates to find a good alignment with text printed on the screen. In order to estimate the parameters of the linear transformation, three optimization strategies are proposed to avoid the problem of local minima, namely Monte Carlo, multi-resolution and multi-blur optimization. Experimental results show that a more precise alignment of gaze data with words on the screen can be achieved by using these methods, allowing a more reliable use of eye-trackers in complex and unconstrained tasks.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {257–260},
numpages = {4},
keywords = {image registration, error correction, text-gaze alignment},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167013,
author = {Dias, Ricardo and Fonseca, Manuel J. and Gon\c{c}alves, Daniel},
title = {Music Listening History Explorer: An Alternative Approach for Browsing Music Listening History Habits},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167013},
doi = {10.1145/2166966.2167013},
abstract = {Nowadays, people spend time using services to track their music listening history. Although these services provide statistics and small graphics/charts, they are mainly used to record and to allow direct access to the information, not providing any visualization and exploration functionality. In this paper we describe a new approach for browsing and visualizing music listening histories, which combines a timeline-based visualization, with a set of synchronized-views and an interactive filtering mechanism to provide a flexible and easy to use solution. This was complemented with brushing and highlighting techniques that allow users to observe trends on artists, albums and tracks listening. Experimental evaluation with users revealed that they were able to complete all the proposed tasks with a low error rate, and that they found the solution easy to use. Moreover, users liked our approach for browsing and exploring listening histories, emphasizing its flexibility and effectiveness, and founding the full experience engaging and rewarding.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {261–264},
numpages = {4},
keywords = {listening history, interactive browsing, visualization},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167014,
author = {Kang, Bo and LaViola, Joseph},
title = {LogicPad: A Pen-Based Application for Visualization and Verification of Boolean Algebra},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167014},
doi = {10.1145/2166966.2167014},
abstract = {We present LogicPad, a pen-based application for boolean algebra visualization that lets users manipulate boolean function representations through handwritten symbol and gesture recognition coupled with a drag-and-drop interface. We discuss LogicPad's user interface and the general algorithm used for verifying the equivalence of three different boolean function representations: boolean expressions, truth tables, and logic gate diagrams. We also conducted a short, informal user study evaluating LogicPad's user interface, visualization techniques, and overall performance. Results show that visualizations were generally well-liked and verification results matched user expectations.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {265–268},
numpages = {4},
keywords = {pen-based user interface, logic verification, boolean algebra, sketch understanding},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167015,
author = {Szekely, Pedro and Chang, Yu-Han and Maheswaran, Rajiv and Wang, Yan and Cheng, Huihui and Singh, Karan},
title = {Interactive Uncertainty Analysis},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167015},
doi = {10.1145/2166966.2167015},
abstract = {Humans have difficulty evaluating the effects of uncertainty on schedules. People often mitigate the effects of uncertainty by adding slack based on experience and non-stochastic analyses such as the critical path method (CPM). This is costly as it leads to longer than necessary schedules, and can be ineffective without a clear understanding of where slack is needed. COMPASS is an interactive real-time tool that analyzes schedule uncertainty for a stochastic task network. An important feature is that it concurrently calculates stochastic critical paths and critical tasks. COMPASS visualizes this information on top of a traditional Gantt view, giving users insight into how delays caused by uncertain durations propagate down the schedule. Evaluations with 10 users show that users can use COMPASS to answer a variety of questions about the possible evolutions of a schedule (e.g., what is the likelihood that all activities will complete before a given date?)},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {269–272},
numpages = {4},
keywords = {plan understanding, visualization, schedule visualization, gantt chart, uncertainty analysis, monte carlo simulation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167016,
author = {Dennis, Matt and Masthoff, Judith and Mellish, Chris},
title = {The Quest for Validated Personality Trait Stories},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167016},
doi = {10.1145/2166966.2167016},
abstract = {This paper describes how a set of stories, each conveying a personality trait from the Five Factor Model at a high or low level, were developed using Amazon's Mechanical Turk. These stories will be used to develop interfaces that adapt to personality using a User as Wizard method. The paper shows how difficult it is to construct stories that convey a single personality trait. It also shows how such stories can be constructed for most cases, and how Mechanical Turk can aid to achieve this.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {273–276},
numpages = {4},
keywords = {personality, adaptation, user stories, validation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167017,
author = {Ajmera, Jitendra and Deshmukh, Om D and Jain, Anupam and Nanavati, Amit Anil and Rajput, Nitendra and Srivastava, Saurabh},
title = {Audio Cloud: Creation and Rendering},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167017},
doi = {10.1145/2166966.2167017},
abstract = {Word clouds are extensively used to present a summary of the prominent words in a document on the World Wide Web. Such clouds give the user an idea about the content of the document. In this paper we present a mechanism to create and render an audio cloud for audio content. Such audio clouds are expected to provide a similar summary of the audio documents. They have wide applicability in various domains, especially for low-literate users who currently do not use the Internet but interact with audio-based systems.Detecting words from an audio content is challenging, especially if the audio is in languages for which a speech recognition system does not exist. We present a language-independent mechanism to detect frequently occurring words within an audio document. We then present four ways to render these words that form an audio cloud. The four prototypes for rendering the audio cloud are based on varying the amplitude, the voice quality, echo and the repetition of audio words. An evaluation study conducted across 32 users suggests that literate and low-literate users easily understand the concept of audio cloud.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {277–280},
numpages = {4},
keywords = {audio cloud, low-literate, language independent},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167018,
author = {Zhao, YangLei and Chakraborty, Arpan and Hong, Kyung Wha and Kakaraddi, Shishir and St. Amant, Robert},
title = {Pointing at Responsive Objects Outdoors},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167018},
doi = {10.1145/2166966.2167018},
abstract = {In this paper we analyze pointing techniques for simple remote control of nearby and distant objects in an outdoor environment, using a mobile phone. In an experiment we determine the accuracy of pointing at targets from a few meters to a few hundred meters away, either by focusing the phone's camera on a target or holding the phone at waist level in the direction of the target. We describe a simulated network application in which users can activate and control one or more responsive objects using either interaction technique.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {281–284},
numpages = {4},
keywords = {no keywords},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167019,
author = {Curran, William and Moore, Travis and Kulesza, Todd and Wong, Weng-Keen and Todorovic, Sinisa and Stumpf, Simone and White, Rachel and Burnett, Margaret},
title = {Towards Recognizing "Cool": Can End Users Help Computer Vision Recognize Subjective Attributes of Objects in Images?},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167019},
doi = {10.1145/2166966.2167019},
abstract = {Recent computer vision approaches are aimed at richer image interpretations that extend the standard recognition of objects in images (e.g., cars) to also recognize object attributes (e.g., cylindrical, has-stripes, wet). However, the more idiosyncratic and abstract the notion of an object attribute (e.g., cool car), the more challenging the task of attribute recognition. This paper considers whether end users can help vision algorithms recognize highly idiosyncratic attributes, referred to here as subjective attributes. We empirically investigated how end users recognized three subjective attributes of carscool, cute, and classic. Our results suggest the feasibility of vision algorithms recognizing subjective attributes of objects, but an interactive approach beyond standard supervised learning from labeled training examples is needed.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {285–288},
numpages = {4},
keywords = {human factors., interactive machine learning, classification, computer vision},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167020,
author = {Camara, Fatoumata and Calvary, Ga\"{e}lle and Demumieux, Rachel and Mandran, Nadine},
title = {Where Do Facebook Intelligent Lists Come From?},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167020},
doi = {10.1145/2166966.2167020},
abstract = {On September 19th 2011, Facebook introduced "Intelligent Lists" which are Friends Lists (FL) automatically created and pre-filled based on users' and their contacts' profiles information (education, work, city of living, kin, etc.). In early 2011, we conducted a study on contact management in Facebook in order to understand users' real needs. Outcomes from this study suggest several recommendations, some of which can be found today in the Facebook Intelligent Lists.This paper provides explanations on the recent evolution in Facebook contact management. The user study involved 148 participants. From their Facebook accounts, we retrieved 340 Friends Lists and 347 family ties. In the overall, the study has led to numerous interesting outocomes. In this paper, we focus on those related to Friends Lists and, particularly, on recommendations that have not yet been implemented in Facebook.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {289–292},
numpages = {4},
keywords = {facebook, contact management, sns, recommendations},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167021,
author = {Smith, Benjamin and Garnett, Guy},
title = {Machine Listening: Acoustic Interface with ART},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167021},
doi = {10.1145/2166966.2167021},
abstract = {Recent developments in machine listening present opportunities for innovative new paradigms for computer-human interaction. Voice recognition systems demonstrate a typical approach that conforms to event oriented control models. However, acoustic sound is continuous, and highly dimensional, presenting a rich medium for computer interaction. Unsupervised machine learning models present great potential for real-time machine listening and understanding of audio and sound data. We propose a method for harnessing unsupervised machine learning algorithms, Adaptive Resonance Theory specifically, in order to inform machine listening, build musical context information, and drive real-time interactive performance systems. We present the design and evaluation of this model leveraging the expertise of trained, improvising musicians.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {293–296},
numpages = {4},
keywords = {machine listening, artificial intelligence, music, unsupervised machine learning, adaptive resonance theory},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167022,
author = {Vatavu, Radu-Daniel},
title = {1F: One Accessory Feature Design for Gesture Recognizers},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167022},
doi = {10.1145/2166966.2167022},
abstract = {One Feature (1F) is a simple and intuitive pruning strategy that reduces considerably the amount of computations required by Nearest-Neighbor gesture classifiers while still preserving the high recognition rate. Performance results are reported for 1F by analyzing a large set of candidate features showing recognition rates of 99% with a peak reduction in computations of 70%. 1F is easy to implement, flexible with respect to the choice of the feature, and exploits the intuition of the designer by exposing clear inner workings.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {297–300},
numpages = {4},
keywords = {gesture descriptors, comparing classifiers, pruning, gesture recognition, training set, nearest neighbor, classification, feature selection},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167023,
author = {Doryab, Afsaneh and Togelius, Julian and Bardram, Jakob},
title = {Activity-Aware Recommendation for Collaborative Work in Operating Rooms},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167023},
doi = {10.1145/2166966.2167023},
abstract = {This paper presents a recommender system for teams of medical professionals working collaboratively in hospital operating rooms. The system recommends relevant virtual actions, such as retrieval of information resources and initiation of communication with professionals outside the operating rooms. Recommendations are based on the current state of the ongoing operation as recognised from sensor data using machine learning techniques. The selection and non-selection of virtual actions during operations are interpreted as implicit feedback and used to update the weight matrices that guide recommendations. A pilot user study involving medical professionals indicates that the adaptation mechanism is effective and that the system provides adequate recommendations.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {301–304},
numpages = {4},
keywords = {operating room, collaborative work, recommendation, hospitals, context-aware, information retrieval},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167025,
author = {Matsumura, Kohei and Sakamoto, Daisuke and Inami, Masahiko and Igarashi, Takeo},
title = {Universal Earphones: Earphones with Automatic Side and Shared Use Detection},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167025},
doi = {10.1145/2166966.2167025},
abstract = {We present universal earphones that use both a proximity sensor and a skin conductance sensor and we demonstrate several implicit interaction techniques they achieve by automatically detecting the context of use. The universal earphones have two main features. The first involves detecting the left and right sides of ears, which provides audio to either ear, and the second involves detecting the shared use of earphones and this provides mixed stereo sound to both earphones. These features not merely free users from having to check the left and right sides of earphones, but they enable them to enjoy sharing stereo audio with other people.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {305–306},
numpages = {2},
keywords = {earphones, intelligent interface, implicit interaction},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167026,
author = {Bastos, Pedro and Alvarez Blanco, Xenxo and Orvalho, Ver\'{o}nica},
title = {A Demo of a Facial UI Design Approach for Digital Artists},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167026},
doi = {10.1145/2166966.2167026},
abstract = {In the character animation industry, animators use facial UI's to animate a character's face. A facial UI provides widgets and handles that the animator interacts with to control the character's facial regions. This paper presents a facial UI design approach to control the animation of the six basic facial expressions of the anthropomorphic face. The design is based in square shaped widgets holding circular handles that allow the animator to produce the muscular activity relative to the basic facial expressions. We have implemented a prototype of the facial UI design in the Blender open-source animation software and did a preliminary pilot study with three animators. Two parameters were evaluated: the number of clicks and the time taken to animate the six basic facial expressions. The study reveals there was little variation in the values each animator marked for both parameters, despite the natural difference in their creative performance.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {307–308},
numpages = {2},
keywords = {facial animation, user interfaces, widgets, handles},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167027,
author = {Leiva, Luis and Vidal, Enrique},
title = {Simple, Fast, and Accurate Clustering of Data Sequences},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167027},
doi = {10.1145/2166966.2167027},
abstract = {Many devices generate large amounts of data that follow some sort of sequentiality, e.g., motion sensors, e-pens, or eye trackers, and therefore these data often need to be compressed for classification, storage, and/or retrieval purposes. This paper introduces a simple, accurate, and extremely fast technique inspired by the well-known K-means algorithm to properly cluster sequential data. We illustrate the feasibility of our algorithm on a web-based prototype that works with trajectories derived from mouse and touch input. As can be observed, our proposal outperforms the classical K-means algorithm in terms of accuracy (better, well-formed segmentations) and performance (less computation time).},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {309–310},
numpages = {2},
keywords = {clustering, trajectory segmentation, sequential data},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167028,
author = {Leiva, Luis},
title = {Interaction-Based User Interface Redesign},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167028},
doi = {10.1145/2166966.2167028},
abstract = {This paper demonstrates a general framework to restyle UI widgets, in order to adapt them to the user behavior. Different implementation examples illustrate its feasibility. The value of this methodology comes from the fact that it is suited to any application language or toolkit supporting structured data hierarchies and style sheets; e.g., interfaces created in HTML, XUL, Flex/AIR (ActionScript), or Java. As described in the paper, an explicit end user intervention is not required, and changes are gradually applied so that they are not intrusive for the user.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {311–312},
numpages = {2},
keywords = {adaptive interfaces, implicit interaction, redesign},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167029,
author = {Paulheim, Heiko},
title = {Explain-a-LOD: Using Linked Open Data for Interpreting Statistics},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167029},
doi = {10.1145/2166966.2167029},
abstract = {While statistics are omnipresent, e.g., depicting the corruption in different countries, it is often not trivial to find the explanation for a statistical effect, e.g., why the corruption is higher in some countries than in others. The necessary facts that can explain a statistic are often not contained in the statistics file itself. This demo shows Explain-a-LOD, a tool for generating possible explanations for statistics from Linked Open Data. The tool accepts statistical data as input, and it automatically retrieves data from the Linked Open Data cloud and generates possible explanations.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {313–314},
numpages = {2},
keywords = {data analysis, semantic web, linked open data, statistics},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167030,
author = {N\'{o}brega, Rui and Correia, Nuno},
title = {Smart Interface for Reshaping Photos in 3D},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167030},
doi = {10.1145/2166966.2167030},
abstract = {In this work we present an interactive prototype for an interface that supports the interaction with virtual objects integrated in a real life scenario. The user can reshape or re-design a real space with virtual objects using several pictures of the desired space. The images are analyzed for known features such as surfaces, edges, floor location and room orientation. Using these elements, it is possible to devise an augmented reality system where the user can add virtual objects to the scenario. The smart interface attaches the objects to the scene elements (e.g., floor) automatically. The current demo loads images from user files or takes a snapshot directly from the camera. The high-level features are automatically detected, but can be manually adjusted. A use-case example of an augmented reality application is presented.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {315–316},
numpages = {2},
keywords = {augmented reality, hci, computer vision, image recognition},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167031,
author = {Sonntag, Daniel and Schulz, Christian and Reuschling, Christian and Galarraga, Luis},
title = {RadSpeech's Mobile Dialogue System for Radiologists},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167031},
doi = {10.1145/2166966.2167031},
abstract = {With RadSpeech, we aim to build the next generation of intelligent, scalable, and user-friendly semantic search interfaces for the medical imaging domain, based on semantic technologies. Ontology-based knowledge representation is used not only for the image contents, but also for the complex natural language understanding and dialogue management process. This demo shows a speech-based annotation system for radiology images and focuses on a new and effective way to annotate medical image regions with a specific medical, structured, diagnosis while using speech and pointing gestures on the go.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {317–318},
numpages = {2},
keywords = {speech dialogue, mobility, healthcare},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167032,
author = {Amma, Christoph and Schultz, Tanja},
title = {Airwriting: Demonstrating Mobile Text Input by 3D-Space Handwriting},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167032},
doi = {10.1145/2166966.2167032},
abstract = {We demonstrate our airwriting interface for mobile hands-free text entry. The interface enables a user to input text into a computer by writing in the air like on an imaginary blackboard. Hand motion is measured by an accelerometer and a gyroscope attached to the back of the hand and data is sent wirelessly to the processing computer. The system can continuously recognize arbitrary sentences based on a predefined vocabulary in real-time. The recognizer uses Hidden Markov Models (HMM) together with a statistical language model. We achieve a user-independent word error rate of 11% for a 8K vocabulary based on an experiment with nine users.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {319–320},
numpages = {2},
keywords = {accelerometers, handwriting recognition, human computer interaction, wearable computing, gesture recognition},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167033,
author = {Antonelli, Fabrizio and Biamino, Giulia and Carmagnola, Francesca and Cena, Federica and Chiabrando, Elisa and Console, Luca and Cuciti, Vincenzo and Demichelis, Matteo and Fassio, Franco and Franceschi, Fabrizio and Furnari, Roberto and Gena, Cristina and Geymonat, Marina and Grimaldi, Piercarlo and Grillo, Pierluigi and Guercio, Elena and Likavec, Silvia and Lombardi, Ilaria and Mana, Dario and Marcengo, Alessandro and Mioli, Michele and Mirabelli, Mario and Perrero, Monica and Picardi, Claudia and Protti, Federica and Rapp, Amon and Sandon, Roberta and Simeoni, Rossana and Dupr\'{e}, Daniele Theseider and Torre, Ilaria and Toso, Andrea and Torta, Fabio and Vernero, Fabiana},
title = {Wheeling around with Wanteat: Exploring Mixed Social Networks in the Gastronomy Domain},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167033},
doi = {10.1145/2166966.2167033},
abstract = {Wanteat is a framework and a suite of applications which allow users to interact with and explore mixed social networks of smart objects and people in the gastronomy domain, thus promoting the cultural heritage of a territory. Wanteat interaction model is based on the concept of a "wheel" [1].},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {321–322},
numpages = {2},
keywords = {cultural heritage, gastronomy, smart objects, mobile applications, social web of things, playful interaction},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167034,
author = {Said, Alan and De Luca, Ernesto William and Kille, Benjamin and Jain, Brijnesh and Micus, Immo and Albayrak, Sahin},
title = {KMulE: A Framework for User-Based Comparison of Recommender Algorithms},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167034},
doi = {10.1145/2166966.2167034},
abstract = {Collaborative Filtering Recommender Systems come in a wide variety of variants. In this paper we present a system for visualizing and comparing recommendations provided by different collaborative recommendation algorithms. The system utilizes a set of context-aware, hybrid, and other collaborative filtering solutions in order to generate various recommendations from which its users can pick those corresponding best to their current situation (i.e. context). All user interaction is fed back to the system in order to additionally improve the quality of the recommendations. Additionally, users can explicitly ask the system to treat certain recommenders as more important than others, or disregard them completely if the list of recommended movies is not to their liking.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {323–324},
numpages = {2},
keywords = {context-awareness, movie recommendation, recommender systems, human factors, personalization, user-centric evaluation, analysis, evaluation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167035,
author = {Sanchez-Cortina, Isaias and Serrano, Nicol\'{a}s and Sanchis, Alberto and Juan, Alfons},
title = {A Prototype for Interactive Speech Transcription Balancing Error and Supervision Effort},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167035},
doi = {10.1145/2166966.2167035},
abstract = {A system to transcribe speech data is presented following an interactive paradigm in which both, the system produces automatically speech transcriptions and the user is assisted by the system to amend output errors as efficiently as possible. Partially supervised transcriptions with a tolerance error fixed by the user are used to incrementally adapt the underlying system models. The prototype uses a simple yet effective method to find an optimal balance between recognition error and supervision effort.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {325–326},
numpages = {2},
keywords = {speech recognition, computer-assisted speech transcription, confidence measures, interactive machine learning},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167036,
author = {Bandara, Udana},
title = {Seamless Online/Offline Shopping Experience Design for in-Store Customers},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167036},
doi = {10.1145/2166966.2167036},
abstract = {Over the last few years, the conventional brick and mortar business model has been challenged by the proliferation of smartphone-based shopping apps, which exploit the weaknesses of this conventional model. As an alternative to these apps, we have developed Ubira [1], a patent-pending service platform that allows healthy online/offline competition rather than merely exploiting the weaknesses. This business model provides brick and mortar shops a fair chance to compete with online stores while creating a seamless shopping experience for in-store customers based on an online/offline partnership. The main design challenge in Ubira has been to promote serendipity in shopping rather than bargain hunting, and integrate the legacy inventory systems of brick and mortar businesses into the platform. To overcome these challenges, we have made some critical design choices based on context awareness and seamful design methods.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {327–328},
numpages = {2},
keywords = {retailers, mobile shopping interface, context awareness},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167037,
author = {Verma, Pramod},
title = {IcAuth: Image-Color Based Authentication System},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167037},
doi = {10.1145/2166966.2167037},
abstract = {Authentication interfaces are GUIs that provide the protection for an application or system. In this paper, we present icAuth: a novel image and color based authentication interface for the authentication process. We enhance the existing Image Based Authentication (IBA) with an additional interactive method. In our approach, the user not only chooses image(s) as a key during the registration process, but also clicks on various regions on the image to generate an additional key. This additional key is in the form of a sequence of colors that correspond to the clicked areas. In essence, the user chooses a color sequence along with the selected images. During the next authentication process, the user has to produce the same color sequence on the recognized images. The user is required to remember the same switching sequence among the images, without having to memorize the precise location of the initial clicks during setup.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {329–330},
numpages = {2},
keywords = {iba, usability, security},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167038,
author = {Buschbeck, Sven and Jameson, Anthony and Schneeberger, Tanja and Woll, Robin},
title = {A Web-Based User Interface for Interaction with Hierarchically Structured Events},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167038},
doi = {10.1145/2166966.2167038},
abstract = {Intelligent technologies have been used in various ways to support more effective representation and processing of media and documents in terms of the events that they refer to. This demo presents some innovations that have been introduced in a web-based interface to a repository of media and documents that are organized in terms of hierarchically structured events.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {331–332},
numpages = {2},
keywords = {visualization, interaction, events},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167039,
author = {Gilroy, Stephen and Porteous, Julie and Charles, Fred and Cavazza, Marc},
title = {PINTER: Interactive Storytelling with Physiological Input},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167039},
doi = {10.1145/2166966.2167039},
abstract = {The dominant interaction paradigm in Interactive Storytelling (IS) systems so far has been active interventions by the user by means of a variety of modalities. PINTER is an IS system that uses physiological inputs - surface electromyography (EMG) and galvanic skin response (GSR) [1] - as a form of passive interaction, opening up the possibility of the use of traditional filmic techniques [2, 3] to implement IS without requiring immersion-breaking interactive responses. The goal of this demonstration is to illustrate the ways in which passive interaction combined with filmic visualisation, dialogue and music, and a plan-based narrative generation approach can form a new basis for an adaptive interactive narrative.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {333–334},
numpages = {2},
keywords = {interactive storytelling, physiological input},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167040,
author = {Bigdelou, Ali and Schwarz, Loren and Benz, Tobias and Navab, Nassir},
title = {A Flexible Platform for Developing Context-Aware 3D Gesture-Based Interfaces},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167040},
doi = {10.1145/2166966.2167040},
abstract = {In this paper, we introduce a flexible framework that can facilitate the definition of 3D gesture-based interfaces. Highlighting the need for context awareness in complex domains, such as the operating room, we argue how the proposed architecture can overcome integration challenges. Through a real-life scenario, an intra-operative medical image viewer, we demonstrate how the proposed framework can be used in practice to define user interfaces in collaborative environments, where the behavior and the system response can be adapted based on the current workflow stage and individual user requirements. Finally, we demonstrate how the defined interface can be manipulated using a high-level visual programming interface. The extensibility of the proposed architecture makes it applicable to a wide range of scenarios.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {335–336},
numpages = {2},
keywords = {context awareness, framework, gesture-based interaction},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167041,
author = {Dong, Ruihai and McCarthy, Kevin and O'Mahony, Michael and Schaal, Markus and Smyth, Barry},
title = {First Demonstration of the Intelligent Reviewer's Assistant},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167041},
doi = {10.1145/2166966.2167041},
abstract = {User opinions and reviews are an important part of the modern web and all major e-commerce sites typically provide their users with the ability to provide and access customer reviews across their product catalog. The importance of reviews has driven the need to improve the review quality by providing interactive support for the reviewer and we will demonstrate the first version of an Intelligent Reviewer's Assistant for this purpose. Our browser plugin is designed to work with major sites like Amazon and to provide users with suggestions as they write their reviews. In particular, these suggestions take the form of topics (e.g. product features) that a reviewer may wish to write about and the suggestions automatically adapt as the user writes their review.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {337–338},
numpages = {2},
keywords = {writer's assistance, intelligent user interfaces},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167042,
author = {Johnston, Michael and Ehlen, Patrick},
title = {Collecting Multimodal Data in the Wild},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167042},
doi = {10.1145/2166966.2167042},
abstract = {Multimodal interaction allows users to specify commands using combinations of inputs from multiple different modalities. For example, in a local search application, a user might say "gas stations" while simultaneously tracing a route on a touchscreen display. In this demonstration, we describe the extension of our cloud-based speech recognition architecture to a Multimodal Semantic Interpretation System (MSIS) that supports processing of multimodal inputs streamed over HTTP. We illustrate the capabilities of the framework using Speak4itSM, a deployed mobile local search application supporting combined speech and gesture input. We provide interactive demonstrations of Speak4it on the iPhone and iPad and explain the challenges of supporting true multimodal interaction in a deployed mobile service.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {339–340},
numpages = {2},
keywords = {speech, multimodal, gesture},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167044,
author = {Weninger, Beate},
title = {Deducing Parameters for Personalizing Maps from Map Interaction Patterns},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167044},
doi = {10.1145/2166966.2167044},
abstract = {Interactive maps on the internet have become frequently used means to convey spatial information to the public. However, many maps are not developed to suit a variety of users and thus lead to frustration. To user-center maps we therefore recommend to personalize them to individual users. As many parameters that can be used as a trigger for personalization are not easy to be logged on the internet, we suggest user-map interaction. Interaction can be easily tracked and gives comprehensive information about map use. Since no interpretation of user-map interaction is available it is the aim of this PhD to observe interaction, and to evaluate and interpret it. We hypothesize that there are map interaction patterns, means recurring sequences of consecutive actions which are necessary to complete a task. Our goal is to deduce parameters for personalization from these map interaction patterns.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {341–344},
numpages = {4},
keywords = {interactive maps, interaction, personalization, adaptive maps},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167045,
author = {Wong, Bee Suan},
title = {Evaluating an Organic Interface for Learning Mathematics},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167045},
doi = {10.1145/2166966.2167045},
abstract = {The current formats used for presenting mathematics either on paper or in electronic form have usability limitations that make learning mathematics challenging. The concept of an Organic User Interface, promises a natural interface that blends with the human ecology system and therefore affords smoother transition and improved usability. This research aims to examine how the affordances of an Organic User Interface influence users learning of important mathematical concepts. The relationship between learning time and the usability factors, or affordances of an Organic User Interface will be determined and contrasted with those of Graphical User Interfaces.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {345–348},
numpages = {4},
keywords = {affordance, learning time, usability, organic user interface},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167046,
author = {Liu, Wei},
title = {Generation Y Interactions},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167046},
doi = {10.1145/2166966.2167046},
abstract = {Information technology (IT) support of office work has increased rapidly in functionality, but the interaction styles have evolved more slowly. This project explores interaction design opportunities of IT supported tools in the context of office work. A series of (contextual) interviews was conducted with Generation Y office workers, aiming to identify their interaction qualities. Three interactive prototypes were built to map these interaction qualities and to demonstrate future ways of working. This project resulted in a set of design guidelines, aiming to support Generation Y interactions in future office work. Designers and researchers who focus on understanding (rich interactions in) the work context would benefit from the result of this project.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {349–352},
numpages = {4},
keywords = {interactive prototyping, interaction qualities, generation y office worker, design guidelines},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167047,
author = {Scott-Harden, Simon},
title = {Active Forms for Responsive Environments},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167047},
doi = {10.1145/2166966.2167047},
abstract = {Active Forms are interactive artefacts that are a focal point of attention for the user. Such devices are interactive and can change shape. They are embedded with both sensors and actuators and are a visualisation and embodiment of some application or service. To be more specific, Active Forms are defined as interactive products or devices that can render content thanks to perceptible changes to their physical form and appearance. We see Active Forms as ideal gateway for the interaction with and the control of Responsive Environments (RE) as defined in [1].Tangible interaction is the precursor of Active Forms, it was essentially about coupling digital content and physical elements of an interface in an integrating combination. The content is about the internal state of the products and about some of the application(s) and service(s) they support. The tangible interaction focuses on the interface or systems that are physically embodied in the physical artifact. Tangible User Interfaces (TUI) are reactive devices that require a user input to change shape. Active Forms, on the other hand are interactive devices that change shape and appearance. The changes in the Active Forms are a result of either, user actions or internal actuators, both the physical form, such as shape or size, and the appearance, such as colour or temperature, can change.Within Active Forms, there is a balance to be had between the cognitive load on the user, the selection of modalities, the media bandwidth and the user attention. The aim being to have the Active Forms as the user focus of interaction and attention. We have listed below some of the key features of Active Forms: Active Forms are interactive devices that are both reactive to user actions and proactive in displaying information.Active Forms are a gateway to applications or services within the RE and there is a change to the internal state of the device.The user actions and the device reactions of an Active Form are merged and are spatially co-located.Active Forms act as their embodiment, as physical objects, Active Forms also have aesthetic value per se.§ The changes in the Active Forms are a result of either, user actions or internal actuators, both the physical form, such as shape or size, and the appearance, such as colour or temperature, can change.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {353–358},
numpages = {6},
keywords = {merged modalities, user experience, interactive products, tangible interaction, embedded interaction, smart objects},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167048,
author = {Goldhaber, Tanya},
title = {Using Theories of Intrinsic Motivation to Support ICT Learning for the Ageing Population},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167048},
doi = {10.1145/2166966.2167048},
abstract = {Access to Information and Communication Technology (ICT) has the potential to improve the quality of life for many members of the ageing population. However, some older users lack the intrinsic motivation to learn to use this technology, and poor user interface design is partly to blame. The research presented here investigates how motivation theory can be applied to interface design in order to encourage older users to learn to use ICT. In addition to a brief literature review, an overview of methods, research goals, and current research status are presented.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {359–362},
numpages = {4},
keywords = {information and communication technology (ict), ageing population, inclusive design, intrinsic motivation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167049,
author = {Leite, Lu\'{\i}s},
title = {Virtual Marionette},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167049},
doi = {10.1145/2166966.2167049},
abstract = {Virtual Marionette is a research on digital puppetry, an interdisciplinary approach that brings the art of puppetry into the world of digital animation. Inspired in the traditional marionette technology our intention is to study novel interfaces as an interaction platform for creating artistic contents based on computer animated puppets. The overall goal of this thesis is to research and deploy techniques and methods for the manipulation of articulated puppets in real-time with low-cost interfaces to establish an interaction model for digital puppetry.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {363–366},
numpages = {4},
keywords = {digital puppetry, virtual marionette, real-time animation, performance animation, computer kinematics, human computer interaction, interactive animation},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167050,
author = {Gomer, Richard},
title = {Eliciting Evaluative Comments from Users in Web 2.0 Scenarios},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167050},
doi = {10.1145/2166966.2167050},
abstract = {In recent years, we've seen a huge growth in the level of user-supplied reviews posted online. These reviews range from feedback on eBay or comments on sites such as YouTube, to social bookmarking sites like StumbleUpon that allow users to comment on almost any page on the web.I'm interested in how these comments are incorporated into evaluative judgements by the users that read them, and how we can improve them through better user interfaces in order to maximise their value to other users. The work draws on psychology and neurology, as well as ideas around credibility from information science, to design and test the impact of intelligent interface changes and behaviour on review composition and ascertain how the composition of a review can make it more or less useful.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {367–370},
numpages = {4},
keywords = {comment, nudge, review, feedback, qualitative},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167051,
author = {Tiroshi, Amit},
title = {Graph Based User Modeling},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167051},
doi = {10.1145/2166966.2167051},
abstract = {An overload in service applications and websites induced by ubiquitous connectivity has brought the need for personalization, as a way to cope with it. However, the need for providing every service with a user model calls for interoperable user models, since user details are scattered in many different systems (e.g., online services such as mail/banking/healthcare/ecommerce sites/social networks), each storing the user's details, preferences and history in different representations and data formats. Various approaches for user modeling interoperability were studied from different perspectives (general ontologies, personalized ontologies, mediation), but so far the challenges are yet to be met. This paper proposes a new way for representing user models, an abstracted graph based one, which will support both interoperability and advanced user modeling features.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {371–374},
numpages = {4},
keywords = {personalization, ubiquitous user modeling, graphs},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167052,
author = {Kulesza, Todd},
title = {An Explanation-Centric Approach for Personalizing Intelligent Agents},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167052},
doi = {10.1145/2166966.2167052},
abstract = {Intelligent agents are becoming ubiquitous in the lives of users, but the research community has only recently begun to study how people establish trust in and communicate with such agents. I plan to design an explanation-centric approach to support end users in personalizing their intelligent agents and in assessing their strengths and weaknesses. My goal is to define an approach that helps people understand when they can rely on their intelligent agents' decisions, and allows them to directly debug their agents' reasoning when it does not align with their own.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {375–378},
numpages = {4},
keywords = {mental models, interactive machine learning, trust, end-user programming},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167053,
author = {Gao, Feng},
title = {Design for Reflection on Health Behavior Change},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167053},
doi = {10.1145/2166966.2167053},
abstract = {Although the persuasion-based health behavior change systems have achieved certain success particularly in motivating physical activity, researchers now start criticizing that persuasion-based systems have problems in taking over too much control, paying not enough attention to people's thinking, and failing in acknowledging external constraints and exploring resources. The alternative notion of reflection has been supported by different researchers' views, and in my thesis work I aim to explore this notion in the context of dietary change. The main goal of my thesis work is to explore what people think in the different food- related activities and apply those understandings into system designs to foster and assist people's reflection on everyday dietary change.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {379–382},
numpages = {4},
keywords = {behavior change, dietary change, reflection},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167054,
author = {Smith, Dustin},
title = {Managing Implicit Assumptions in Natural Language Interfaces},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167054},
doi = {10.1145/2166966.2167054},
abstract = {A person's choice of what to communicate and how to communicate it depends on the information he or she believes is shared with the audience. This presents a challenge for natural language interfaces, because it is hard for people to predict what information they share with the interface and how it will use this information to interpret their text. This is especially difficult for pragmatic-level assumptions supplied by the interpreter that go beyond the information in the surface text, because these assumptions are negotiated in dialogue and frequently revised or redacted.We have built a calendaring interface that allows users to communicate English event descriptions. This constrained task gives us a clear criteria for communication success and failure. Failures are opportunities to acquire and revise assumptions: to collect lexical and semantic knowledge from a variety of users. By lowering the interaction barrier so end users can contribute to the linguistic interpretation process, we can collect culture-specific lexical and semantic knowledge directly from the members of the cultural group who possess it. This knowledge is essential for the pragmatic task of deriving what a speaker meant from what they said.The goal of this research is to make the assumptions involved with interpreting natural language explicit to the user. Using a model of language generation and interpretation based on planning and plan recognition, we capture, through user contributions, word definitions and commonsense assumptions - and we represent both as belief-changing actions. Using visualizations and a direct manipulation interface, users can access the interpretation status, inspect which assumptions were made, and suggest or modify existing assumptions. With the aim of providing the functionally equivalent of the negotiation stage in interpersonal dialogue, we evaluate the interface by how it allows users to revise and extend assumptions toward successful interpretation.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {383–388},
numpages = {6},
keywords = {natural language interfaces, knowledge acquisition, event management, end-user programming, commonsense},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167055,
author = {Martinez-Gomez, Pascual},
title = {Quantitative Analysis and Inference on Gaze Data Using Natural Language Processing Techniques},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167055},
doi = {10.1145/2166966.2167055},
abstract = {Eye-tracking devices find applications in human-machine interaction, hypothesis testing in psycholinguistic and usability studies, relevant feature extraction when designing models related to human behavior and to build user-centered information systems. We aim at providing a general and robust framework to do quantitative analysis and inference using data collected by eye-trackers when users read text. To achieve this objective, first the accuracy of eye-trackers has to be increased beyond sensor capabilities by using information from the content or the structure of the text. Then, natural language processing techniques will be used to process text appearing on the screen and the recognized reading word sequence. Within this framework, it will be possible to better understand user's intentions, record knowledge acquisition and predict information needs. The intention is to build a user model and user model of the World from texts that users have read. This opens the door to more personalized systems with on-line adaptation capabilities.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {389–392},
numpages = {4},
keywords = {quantitative approaches, natural language processing, eye-tracking, user-centered systems},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167057,
author = {Schwartz, Tim and Kahl, Gerrit and Pulkkinen, Teemu and Nurmi, Petteri and Dim, Eyal and Applin, Sally},
title = {2nd Workshop on Location Awareness for Mixed and Dual Reality (LAMDa'12)},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167057},
doi = {10.1145/2166966.2167057},
abstract = {The workshop explores the interactions between location awareness and Dual/Mixed Reality in smart environments and the impact on culture and society. The main scope of this workshop is: How can the Dual Reality paradigm be used to improve applications in smart environments and which new possibilities are opened up by these paradigms? This includes positioning methods and location-based services using the DR paradigm, such as navigation services and group interaction services (location-based social signal processing). The workshop is also open to discuss sensor and actuator technologies that may help to realize the synchronization of the virtual and real world.The main scope of this workshop is: How can the Dual Reality paradigm be used to improve location-based and socially-aware services and other applications in smart environments?},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {393–396},
numpages = {4},
keywords = {positioning, dual reality, mixed reality, social anthropology, location-based services},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167058,
author = {Mahmud, Jalal and Nichols, Jeffrey and Zhou, Michelle},
title = {1st International Workshop on User Modeling from Social Media},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167058},
doi = {10.1145/2166966.2167058},
abstract = {Massive amounts of data are being generated on social media sites, such as Twitter and Facebook. People from all walks of life share data about social events, express opinions, discuss their interests, publicize businesses, recommend products, and, explicitly or implicitly, reveal personal information. This workshop will focus on the use of social media data for creating models of individual users from the content that they publish. Deeper understanding of user behavior and associated attributes can benefit a wide range of intelligent applications, such as social recommender systems and expert finders, as well as provide the foundation in support of novel user interfaces (e.g., actively engaging the crowd in mixed-initiative question-answering systems). These applications and interfaces may offer significant benefits to users across a wide variety of domains, such as retail, government, healthcare and education. User modeling from public social media data may also reveal information that users would prefer to keep private. Such concerns are particularly important because individuals do not have complete control over the information they share about themselves. For example, friends of a user may inadvertently divulge private information about that user in their own posts. In this workshop we will also discuss possible mechanisms that users might employ to monitor what information has been revealed about themselves on social media and obfuscate any sensitive information that has been accidentally revealed.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {397–400},
numpages = {4},
keywords = {user modeling, social media},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167059,
author = {Hussein, Tim and Lukosch, Stephan and Paulheim, Heiko and Ziegler, J\"{u}rgen and Calvary, Ga\"{e}lle},
title = {3rd Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS): (SEMAIS)},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167059},
doi = {10.1145/2166966.2167059},
abstract = {The International Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS 2012) aims to identify emerging trends in interactive system design using semantic models.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {401–404},
numpages = {4},
keywords = {usability, model-driven user interfaces, semantic models, adaptive interactive systems, interface design},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167060,
author = {Biswas, Pradipta and Langdon, Pat and Jung, Christoph and Hamisu, Pascal and Duarte, Carlos and Almeida, Luis},
title = {Developing Intelligent User Interfaces for E-Accessibility and e-Inclusion},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167060},
doi = {10.1145/2166966.2167060},
abstract = {This workshop aims to gap the bridge between mainstream research on intelligent systems and accessibility researchers by presenting papers and demonstrations on developing adaptable multimodal systems for elderly and disabled users. The workshop is organized in the context of EU GUIDE project and focus on Web and Digital TV applications. However the research and applications are relevant for different platforms like computers, tablet and ubiquitous devices. The workshop consists of a keynote speech on standardization of developing intelligent and accessible system followed by five paper and demonstration presentations. A set of papers from this workshop will later appear at the International Journal of Digital Television.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {405–408},
numpages = {4},
keywords = {usability evaluation, human-computer interaction, user model, e-inclusion, assistive technology},
location = {Lisbon, Portugal},
series = {IUI '12}
}

@inproceedings{10.1145/2166966.2167061,
author = {De Luca, Ernesto William and B\"{o}hmer, Matthias and Said, Alan and Chi, Ed},
title = {2nd Workshop on Context-Awareness in Retrieval and Recommendation: (CaRR 2012)},
year = {2012},
isbn = {9781450310482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2166966.2167061},
doi = {10.1145/2166966.2167061},
abstract = {Context-aware information is widely available in various ways and is becoming more and more important for enhancing retrieval performance and recommendation results. The current main issue to cope with is not only recommending or retrieving the most relevant items and content, but defining them ad hoc. Other relevant issues include personalizing and adapting the information and the way it is displayed to the user's current situation and interests. Ubiquitous computing further provides new means for capturing user feedback on items and providing information.},
booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
pages = {409–412},
numpages = {4},
keywords = {recommender systems, context-awareness, information retrieval},
location = {Lisbon, Portugal},
series = {IUI '12}
}

