@inproceedings{10.1145/1040830.1040835,
author = {de Ruyter, Boris and Jain, Yogendra and Keyson, David and Rich, Charles},
title = {The Usability Crisis in High-Tech Home Products: An Opportunity for Intelligent User Interfaces?},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040835},
doi = {10.1145/1040830.1040835},
abstract = {Ordinary people already have great difficulty using the advanced features of digitally-operated household devices, such personal video recorders, DVD burners, etc., and "white goods," such as washing machines, microwave ovens, programmable thermostats, etc. And the problem is getting worse as more customization and programming features are continually being added. This is challenging and practical application for intelligent user interface research, and one in which new ideas are badly needed. This panel brings together industrial and academic researchers as well as business people to report on their activities and stimulate others to join.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {4},
numpages = {1},
keywords = {usability, consumer electronics},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040837,
author = {Kray, Christian and Butz, Andreas and Kr\"{u}ger, Antonio and Schmidt, Albrecht and Prendinger, Helmut},
title = {Multi-User and Ubiquitous User Interfaces: (MU3I 2005)},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040837},
doi = {10.1145/1040830.1040837},
abstract = {This second workshop on Multi-User and Ubiquitous User Interfaces aims at further investigating two major issues identified at last year's MU3I: control and consistency. The former relates to how a user gains control of devices in a ubiquitous computing environment, how control is passed, and how it is shared in such a setting. The second one concerns interfaces that span multiple devices or move from one set of devices to another. Both issues will be discussed in this year's workshop (with a focus on consistency.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {6},
numpages = {1},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040838,
author = {Conati, Cristina and Marsella, Stacy and Paiva, Ana},
title = {Affective Interactions: The Computer in the Affective Loop},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040838},
doi = {10.1145/1040830.1040838},
abstract = {There has been an increasing interest in exploring how recognition of a user's affective state can be exploited in creating more effective human-computer interaction. It has been argued that IUIs may be able to improve interaction by including affective elements in their communication with the user (e.g. by showing empathy via adequate phrasing of feedback.) This workshop will address a variety of issues related to the development of what we will call the affective loop: detection/modeling of relevant user's states, selection of appropriate system responses (including responses that are designed to influence the user affective state but are not overtly affective), as well as synthesis of the appropriate affective expressions.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {7},
numpages = {1},
keywords = {affective computing, affective interfaces},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040839,
author = {van Setten, Mark and McNee, Sean M. and Konstan, Joseph A.},
title = {Beyond Personalization: The next Stage of Recommender Systems Research},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040839},
doi = {10.1145/1040830.1040839},
abstract = {This workshop intends to bring recommender systems researchers and practitioners together in order to discuss the current state of recommender systems research, both on existing and emerging research topics, and to determine how research in this area should proceed. We are at a pivotal point in recommender systems research where researchers are both looking inward at what recommender systems are and looking outward at where recommender systems can be applied, and the implications of applying them out 'in the wild.' This creates a unique opportunity to both reassess the current state of research and directions research is taking in the near and long term.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {8},
numpages = {1},
keywords = {ersonalization, recommender systems},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/3249362,
author = {Kim, Jihie},
title = {Session Details: Tutorials},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249362},
doi = {10.1145/3249362},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
numpages = {1},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040843,
author = {Raiha, Kari-Jouko and Hyrskykari, Aulikki and Majaranta, Paivi},
title = {Gaze-Based Human-Computer Interaction},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040843},
doi = {10.1145/1040830.1040843},
abstract = {The tutorial provides examples, experiences and design guidelines for using eye-gaze in human-computer interaction. The goal of the tutorial is to give insight into exploiting the information about gaze direction in human-computer interaction. The participants will learn the basics of eye-tracking, but the focus of the tutorial is on the interaction issues. After the tutorial, the participants understand the pros and cons of using gaze for real-time input. The tutorial consists of lectures and live demonstrations with a state-of-the-art eye-tracking device.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {10},
numpages = {1},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040841,
author = {Johnson, Lewis},
title = {Interaction with Embodied Conversational Agents},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040841},
doi = {10.1145/1040830.1040841},
abstract = {Embodied Conversational Agents (ECAs) are computer-controlled synthetic characters that can engage in dialog with users. This tutorial will present an overview of techniques and methods relating to the design, construction, and evaluation of ECAs that interact appropriately with users. It will introduce the major technologies for controlling ECA behavior. It will then consider the problem of how to design a successful interactive interface that incorporates ECAs. Finally, it will discuss how to evaluate ECA-enhanced interfaces, including evaluation methods and factors that can influence the evaluation.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {10},
numpages = {1},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040842,
author = {Pu, Pearl and Faltings, Boi},
title = {Intelligent Interfaces for Preference-Based Search},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040842},
doi = {10.1145/1040830.1040842},
abstract = {Preference-based search, defined as finding the most preferred item in a large collection, is becoming an increasingly important subject in computer science with many applications: multi-attribute product search, constraint-based plan optimization, configuration design, and recommendation systems. Decision theory formalizes what the most preferred item is and how it can be identified. In recent years, decision theory has pointed out discrepancies between the normative models of how people should reason and empirical studies of how they in fact think and decide. However, many search tools are still based on the normative model, thus ignoring some of the fundamental cognitive aspects of human decision making. Consequently these search tools do not find accurate results for users. This tutorial starts by giving an overview of recent literature in decision theory, and explaining the differences between descriptive, and normative approaches. It then describes some of the principles derived from behavior decision theory and how they can be turned into principles for developing intelligent user interfaces to help users to make better choices while searching. It develops in particular the issues of how to model user preferences with a limited interaction effort, how to support tradeoff, and how to implement practical search tools using the principles.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {10},
numpages = {1},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040845,
author = {Wang, Ning and Johnson, W. Lewis and Rizzo, Paola and Shaw, Erin and Mayer, Richard E.},
title = {Experimental Evaluation of Polite Interaction Tactics for Pedagogical Agents},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040845},
doi = {10.1145/1040830.1040845},
abstract = {Recent research shows that instructors commonly use politeness strategies to achieve affective scaffolding in educational contexts. The importance of affective factors such as self-confidence and interest that contribute to learner motivation is well recognized. In this paper, we describe the results of a Wizard-of-Oz experiment to study the effect of politeness strategies on both cognitive and motivational factors. We compare the results of two different politeness strategies, direct and polite, in assisting seventeen students in a computer-based learning task. We find that politeness can affect students' motivational state and help students learn difficult concepts. The results of the experiment provide a basis for the design of a polite pedagogical agent and its tutorial intervention strategies.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {12–19},
numpages = {8},
keywords = {politeness, pedagogical agents, affective interfaces, proactive, agent-based paradigm, user evaluation},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040845_R40661,
author = {Glenn, Bernice T.},
title = {Review ID:R40661 for DOI: 10.1145/1040830.1040845},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040845_R40661}
}

@inproceedings{10.1145/1040830.1040846,
author = {Costantini, Erica and Pianesi, Fabio and Prete, Michela},
title = {Recognising Emotions in Human and Synthetic Faces: The Role of the Upper and Lower Parts of the Face},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040846},
doi = {10.1145/1040830.1040846},
abstract = {Embodied Conversational Agents that can express emotions are a popular topic. Yet, despite recent attempts, reliable methods are still lacking to assess the quality of facial displays. This paper extends and refines the work in [6], focusing on the role of the upper and the lower portions of the face. We analysed the recognition rates and errors from the responses of 74 subjects to the presentations of dynamic (human and synthetic) faces. The results points to the possibility of: a) addressing the issue of the naturalness of synthetic faces, and b) a greater importance of the upper part.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {20–27},
numpages = {8},
keywords = {emotion recognition, face regions, user study, expressiveness, synthetic faces},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040846_R39031,
author = {Calvi, Licia},
title = {Review ID:R39031 for DOI: 10.1145/1040830.1040846},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040846_R39031}
}

@inproceedings{10.1145/1040830.1040847,
author = {Tanaka, Yuki and Takamura, Hiroya and Okumura, Manabu},
title = {Extraction and Classification of Facemarks},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040847},
doi = {10.1145/1040830.1040847},
abstract = {We propose methods for extracting facemarks (emoticons) in text and classifying them into some emotional categories. In text-based communication, facemarks have gained popularity, since they help us understand what writers imply. However, there are two problems in text-based communication using facemarks; the first is the variety of facemarks and the second is lack of good comprehension in using facemarks. These problems are more serious in the areas where 2-byte characters are used, because the 2-byte characters can generate a quite large number of different facemarks. Therefore, we are going to propose methods for extraction and classification of facemarks. Regarding the extraction of facemarks as a chunking task, we automatically annotate a tag to each character in text. In the classification of the extracted facemarks, we apply the dynamic time alignment kernel (DTAK) and the string subsequence kernel (SSK) for scoring in the k-nearest neighbor (k-NN) method and for expanding usual Support Vector Machines (SVMs) to accept sequential data such as facemarks. We empirically show that our methods work well in classification and extraction of facemarks, with appropriate settings of parameters.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {28–34},
numpages = {7},
keywords = {emoticon, affect analysis, facemark, kernel methods, SVM},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040849,
author = {Pan, Shimei and Shen, Siwei and Zhou, Michelle X. and Houck, Keith},
title = {Two-Way Adaptation for Robust Input Interpretation in Practical Multimodal Conversation Systems},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040849},
doi = {10.1145/1040830.1040849},
abstract = {Multimodal conversation systems allow users to interact with computers effectively using multiple modalities, such as natural language and gesture. However, these systems have not been widely used in practical applications mainly due to their limited input understanding capability. As a result, conversation systems often fail to understand user requests and leave users frustrated. To address this issue, most existing approaches focus on improving a system's interpretation capability. Nonetheless, such improvements may still be limited, since they would never cover the entire range of input expressions. Alternatively, we present a two-way adaptation framework that allows both users and systems to dynamically adapt to each other's capability and needs during the course of interaction. Compared to existing methods, our approach offers two unique contributions. First, it improves the usability and robustness of a conversation system by helping users to dynamically learn the system's capabilities in context. Second, our approach enhances the overall interpretation capability of a conversation system by learning new user expressions on the fly. Our preliminary evaluation shows the promise of this approach.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {35–42},
numpages = {8},
keywords = {robust input interpretation, natural language understanding, context-sensitive help, multimodal input interpretation, adaptive systems, intelligent multimodal interfaces},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040850,
author = {Chai, Joyce Y. and Prasov, Zahar and Blaim, Joseph and Jin, Rong},
title = {Linguistic Theories in Efficient Multimodal Reference Resolution: An Empirical Investigation},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040850},
doi = {10.1145/1040830.1040850},
abstract = {Multimodal conversational interfaces provide a natural means for users to communicate with computer systems through multiple modalities such as speech, gesture, and gaze. To build effective multimodal interfaces, understanding user multimodal inputs is important. Previous linguistic and cognitive studies indicate that user language behavior does not occur randomly, but rather follows certain linguistic and cognitive principles. Therefore, this paper investigates the use of linguistic theories in multimodal interpretation. In particular, we present a greedy algorithm that incorporates Conversation Implicature and Givenness Hierarchy for efficient multimodal reference resolution. Empirical studies indicate that this algorithm significantly reduces the complexity in multimodal reference resolution compared to a previous graph-matching approach. One major advantage of this greedy algorithm is that the prior linguistic and cognitive knowledge can be used to guide the search and significantly prune the search space. Because of its simplicity and generality, this approach has the potential to improve the robustness of interpretation and provide a more practical solution to multimodal input interpretation.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {43–50},
numpages = {8},
keywords = {reference resolution, multimodal input interpretation},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040851,
author = {Kaiser, Edward C.},
title = {Multimodal New Vocabulary Recognition through Speech and Handwriting in a Whiteboard Scheduling Application},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040851},
doi = {10.1145/1040830.1040851},
abstract = {Our goal is to automatically recognize and enroll new vocabulary in a multimodal interface. To accomplish this our technique aims to leverage the mutually disambiguating aspects of co-referenced, co-temporal handwriting and speech. The co-referenced semantics are spatially and temporally determined by our multimodal interface for schedule chart creation. This paper motivates and describes our technique for recognizing out-of-vocabulary (OOV) terms and enrolling them dynamically in the system. We report results for the detection and segmentation of OOV words within a small multimodal test set. On the same test set we also report utterance, word and pronunciation level error rates both over individual input modes and multimodally. We show that combining information from handwriting and speech yields significantly better results than achievable by either mode alone.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {51–58},
numpages = {8},
keywords = {vocabulary learning, multimodal interaction, mutual disambiguation},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040852,
author = {J\"{o}st, Matthias and H\"{a}u\ss{}ler, Jochen and Merdes, Matthias and Malaka, Rainer},
title = {Multimodal Interaction for Pedestrians: An Evaluation Study},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040852},
doi = {10.1145/1040830.1040852},
abstract = {What are the most suitable interaction paradigms for navigational and informative tasks for pedestrians? Is there an influence of social and situational context on multimodal interaction? Our study takes a closer look at a multimodal system on a handheld device that was recently developed as a prototype for mobile navigation assistance. The system allows visitors of a city to navigate, to get information on sights, and to use and manipulate map information. In an outdoor evaluation, we studied the usability of such a system on site. The study yields insight about how multimodality can enhance the usability of hand-held devices with their future services. We show, for example that for our more complicated tasks multimodal interaction is superior to classical unimodal interaction.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {59–66},
numpages = {8},
keywords = {evaluation, SmartKom, multimodal interaction, mobile systems},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040854,
author = {Kushmerick, Nicholas and Lau, Tessa},
title = {Automated Email Activity Management: An Unsupervised Learning Approach},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040854},
doi = {10.1145/1040830.1040854},
abstract = {Many structured activities are managed by email. For instance, a consumer purchasing an item from an e-commerce vendor may receive a message confirming the order, a warning of a delay, and then a shipment notification. Existing email clients do not understand this structure, forcing users to manage their activities by sifting through lists of messages. As a first step to developing email applications that provide high-level support for structured activities, we consider the problem of automatically learning an activity's structure. We formalize activities as finite-state automata, where states correspond to the status of the process, and transitions represent messages sent between participants. We propose several unsupervised machine learning algorithms in this context, and evaluate them on a collection of e-commerce email.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {67–74},
numpages = {8},
keywords = {machine learning, email, text classification, clustering, automaton induction, activity management},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040854_R41263,
author = {Eastman, Caroline Merriam},
title = {Review ID:R41263 for DOI: 10.1145/1040830.1040854},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040854_R41263}
}

@inproceedings{10.1145/1040830.1040855,
author = {Dragunov, Anton N. and Dietterich, Thomas G. and Johnsrude, Kevin and McLaughlin, Matthew and Li, Lida and Herlocker, Jonathan L.},
title = {TaskTracer: A Desktop Environment to Support Multi-Tasking Knowledge Workers},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040855},
doi = {10.1145/1040830.1040855},
abstract = {This paper reports on TaskTracer --- a software system being designed to help highly multitasking knowledge workers rapidly locate, discover, and reuse past processes they used to successfully complete tasks. The system monitors users' interaction with a computer, collects detailed records of users' activities and resources accessed, associates (automatically or with users' assistance) each interaction event with a particular task, enables users to access records of past activities and quickly restore task contexts. We present a novel Publisher-Subscriber architecture for collecting and processing users' activity data, describe several different user interfaces tried with TaskTracer, and discuss the possibility of applying machine learning techniques to recognize/predict users' tasks.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {75–82},
numpages = {8},
keywords = {knowledge management, user interface, machine learning, multitasking, activity monitoring},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040856,
author = {Lee, Danico and Tsatsoulis, Costas},
title = {Intelligent Data Entry Assistant for XML Using Ensemble Learning},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040856},
doi = {10.1145/1040830.1040856},
abstract = {XML has emerged as the primary standard of data representation and data exchange [13]. Although many software tools exist to assist the XML implementation process, data must be manually entered into the XML documents. Current form filling technologies are mostly for simple data entry and do not provide support for the complexity and nested structures of XML grammars. This paper presents SmartXAutofill, an intelligent data entry assistant for predicting and automating inputs for XML documents based on the contents of historical document collections in the same XML domain. SmartXAutofill incorporates an ensemble classifier, which integrates multiple internal classification algorithms into a single architecture. Each internal classifier uses approximate techniques to propose a value for an empty XML field, and, through voting, the ensemble classifier determines which value to accept. As the system operates it learns which internal classification algorithms work better for a specific XML document domain and modifies its weights (confidence) in their predictive ability. As a result, the ensemble classifier adapts itself to the specific XML domain, without the need to develop special learners for the infinite number of domains that XML users have created. We evaluated our system performance using data from eleven different XML domains. The results show that the ensemble classifier adapted itself to different XML document domains, and most of the time (for 9 out of 11 domains) produced predictive accuracies as good as or better than the best individual classifier for a domain.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {83–89},
numpages = {7},
keywords = {machine learning, XML, autofill, ensemble learning},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040857,
author = {Gervasio, Melinda T. and Moffitt, Michael D. and Pollack, Martha E. and Taylor, Joseph M. and Uribe, Tomas E.},
title = {Active Preference Learning for Personalized Calendar Scheduling Assistance},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040857},
doi = {10.1145/1040830.1040857},
abstract = {We present PLIANT, a learning system that supports adaptive assistance in an open calendaring system. PLIANT learns user preferences from the feedback that naturally occurs during interactive scheduling. It contributes a novel application of active learning in a domain where the choice of candidate schedules to present to the user must balance usefulness to the learning module with immediate benefit to the user. Our experimental results provide evidence of PLIANT's ability to learn user preferences under various conditions and reveal the tradeoffs made by the different active learning selection strategies.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {90–97},
numpages = {8},
keywords = {machine learning, active learning, learning preferences, adaptive user interfaces},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040859,
author = {Chen, Chaomei},
title = {The Centrality of Pivotal Points in the Evolution of Scientific Networks},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040859},
doi = {10.1145/1040830.1040859},
abstract = {In this paper, we describe the development of CiteSpace as an integrated environment for identifying and tracking thematic trends in scientific literature. The goal is to simplify the process of finding not only highly cited clusters of scientific articles, but also pivotal points and trails that are likely to characterize fundamental transitions of a knowledge domain as a whole. The trails of an advancing research field are captured through a sequence of snapshots of its intellectual structure over time in the form of Pathfinder networks. These networks are subsequently merged with a localized pruning algorithm. Pivotal points in the merged network are algorithmically identified and visualized using the betweenness centrality metric. An example of finding clinical evidence associated with reducing risks of heart diseases is included to illustrate how CiteSpace could be used. The contribution of the work is its integration of various change detection algorithms and interactive visualization capabilities to simply users' tasks.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {98–105},
numpages = {8},
keywords = {betweenness centrality, intellectual turning points, research fronts, information visualization, knowledge domain visualization},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040860,
author = {Appan, Preetha and Shevade, Bageshree and Sundaram, Hari and Birchfield, David},
title = {Interfaces for Networked Media Exploration and Collaborative Annotation},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040860},
doi = {10.1145/1040830.1040860},
abstract = {In this paper, we present our efforts towards creating interfaces for networked media exploration and collaborative annotation. The problem is important since online social networks are emerging as conduits for exchange of everyday experiences. These networks do not currently provide media-rich communication environments. Our approach has two parts -- collaborative annotation, and a media exploration framework. The collaborative annotation takes place through a web based interface, and provides to each user personalized recommendations, based on media features, and by using a common sense inference toolkit. We develop three media exploration interfaces that allow for two-way interaction amongst the participants -- (a) spatio-temporal evolution, (b) event cones and (c) viewpoint centric interaction. We also analyze the user activity to determine important people and events, for each user. We also develop subtle visual interface cues for activity feedback. Preliminary user studies indicate that the system performs well and is well liked by the users.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {106–113},
numpages = {8},
keywords = {collaborative annotation, networked media, media exploration, personalized media interaction, communication},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040861,
author = {Zhou, Michelle X. and Wen, Zhen and Aggarwal, Vikram},
title = {A Graph-Matching Approach to Dynamic Media Allocation in Intelligent Multimedia Interfaces},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040861},
doi = {10.1145/1040830.1040861},
abstract = {To aid users in exploring large and complex data sets, we are building an intelligent multimedia conversation system. Given a user request, our system dynamically creates a multimedia response that is tailored to the interaction context. In this paper, we focus on the problem of media allocation, a process that assigns one or more media, such as graphics or speech, to best convey the intended response content. Specifically, we develop a graph-matching approach to media allocation, whose goal is to find a set of data-media mappings that maximizes the satisfaction of various allocation constraints (e.g., data-media compatibility and presentation consistency constraints). Compared to existing rule-based or plan-based approaches to media allocation, our work offers three unique contributions. First, we provide an extensible computational framework that optimizes media assignments by dynamically balancing all relevant constraints. Second, we use feature-based metrics to uniformly model various allocation constraints, including those cross-content and cross-media constraints, which often require special treatment in existing approaches. Third, we further improve the quality of a response by automatically detecting and repairing undesired allocation results. We have applied our approach to two different applications and our preliminary study has shown the promise of our work.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {114–121},
numpages = {8},
keywords = {automated generation of multimedia presentations, media allocation, intelligent multimedia interfaces},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040862,
author = {Look, Gary and Kottahachchi, Buddhika and Laddaga, Robert and Shrobe, Howard},
title = {A Location Representation for Generating Descriptive Walking Directions},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040862},
doi = {10.1145/1040830.1040862},
abstract = {An expressive representation for location is an important component in many applications. However, while many location-aware applications can reason about space at the level of coordinates and containment relationships, they have no way to express the semantics that define how a particular space is used. We present Lair, an ontology that addresses this problem by modeling both the geographical relationships between spaces as well as the functional purpose of a given space. We describe how Lair was used to create an application that produces walking directions comparable to those given by a person, and a pilot study that evaluated the quality of these directions. We also describe how Lair can be used to evaluate other intelligent user interfaces.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {122–129},
numpages = {8},
keywords = {navigation directions, location ontologies},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040864,
author = {Chklovski, Timothy and Ratnakar, Varun and Gil, Yolanda},
title = {User Interfaces with Semi-Formal Representations: A Study of Designing Argumentation Structures},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040864},
doi = {10.1145/1040830.1040864},
abstract = {When designing mixed-initiative systems, full formalization of all potentially relevant knowledge may not be cost-effective or practical. This paper motivates the need for semi-formal representations that combine machine-processable structures with free text statements, and discusses the need to design them in a way that makes the free text more amenable to automated structuring and processing. Our work is done in the context of argumentation systems, and has explored a range of tradeoffs in combining informal free-text statements with formal connectors. The paper compares alternative argument representations which combine structured argument connectors with free text. We discuss merits of the systems based on a variety of analysis structures that we have collected from Web users to date.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {130–136},
numpages = {7},
keywords = {meaning decomposition, semi-formal representations, decision-making, natural language understanding, argumentation},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040865,
author = {Nguyen, Anh and Wobcke, Wayne},
title = {An Agent-Based Approach to Dialogue Management in Personal Assistants},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040865},
doi = {10.1145/1040830.1040865},
abstract = {Personal assistants need to allow the user to interact with the system in a flexible and adaptive way such as through spoken language dialogue. In this research we focus on an application in which the user can use a variety of devices to interact with a collection of personal assistants each specializing in a task domain such as email or calendar management, information seeking, etc. We propose an agent-based approach for developing the dialogue manager that acts as the central point maintaining continuous user-system interaction and coordinating the activities of the assistants. In addition, this approach enables development of multi-modal interfaces. We describe our initial implementation which contains an email management agent that the user can interact with through a spoken dialogue and an interface on PDAs. The dialogue manager was implemented by extending a BDI agent architecture.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {137–144},
numpages = {8},
keywords = {dialogue modelling, personal assistant, BDI agent architecture},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040866,
author = {Li, Junfeng and Zhang, Xiwen and Ao, Xiang and Dai, Guozhong},
title = {Sketch Recognition with Continuous Feedback Based on Incremental Intention Extraction},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040866},
doi = {10.1145/1040830.1040866},
abstract = {On-line synchronous sketch recognition has the advantages of convenient input and natural interaction. But among the existing algorithms, some are just able to process simple sketches, and some have so high computational complexity as not to satisfy the real-time demand. In order to solve the problem of efficiency and coverage, a sketch recognition algorithm based on incremental intention extraction is presented. By defining the lag window, the algorithm understands the sketch intention of users on the base of incremental intention extraction. Moreover, the algorithm can update the existing intention sections according to the latest information in order that the recognition results are in line with the sketch intention of users. Experiments show that, the algorithm can recognize kinds of sketches in real time.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {145–150},
numpages = {6},
keywords = {incremental intention extraction, lag window, on-line synchronous recognition, sketch recognition},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040867,
author = {Kristensson, Per-Ola and Zhai, Shumin},
title = {Relaxing Stylus Typing Precision by Geometric Pattern Matching},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040867},
doi = {10.1145/1040830.1040867},
abstract = {Fitts' law models the inherent speed-accuracy trade-off constraint in stylus typing. Users attempting to go beyond the Fitts' law speed ceiling will tend to land the stylus outside the targeted key, resulting in erroneous words and increasing users' frustration. We propose a geometric pattern matching technique to overcome this problem. Our solution can be used either as an enhanced spell checker or as a way to enable users to escape the Fitts' law constraint in stylus typing, potentially resulting in higher text entry speeds than what is currently theoretically modeled. We view the hit points on a stylus keyboard as a high resolution geometric pattern. This pattern can be matched against patterns formed by the letter key center positions of legitimate words in a lexicon. We present the development and evaluation of an "elastic" stylus keyboard capable of correcting words even if the user misses all the intended keys, as long as the user's tapping pattern is close enough to the intended word.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {151–158},
numpages = {8},
keywords = {stylus keyboard, spell checker, typing correction, text input, virtual keyboard, Fitts' law, typing errors},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040869,
author = {Billsus, Daniel and Hilbert, David M. and Maynes-Aminzade, Dan},
title = {Improving Proactive Information Systems},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040869},
doi = {10.1145/1040830.1040869},
abstract = {Proactive contextual information systems help people locate information by automatically suggesting potentially relevant resources based on their current tasks or interests. Such systems are becoming increasingly popular, but designing user interfaces that effectively communicate recommended information is a challenge: the interface must be unobtrusive, yet communicate enough information at the right time to provide value to the user. In this paper we describe our experience with the FXPAL Bar, a proactive information system designed to provide contextual access to corporate and personal resources. In particular, we present three features designed to communicate proactive recommendations more effectively: translucent recommendation windows increase the user's awareness of particularly highly-ranked recommendations, query term highlighting communicates the relationship between a recommended document and the user's current context, and a novel recommendation digest function allows users to return to the most relevant previously recommended resources. We present empirical evidence supporting our design decisions and relate lessons learned for other designers of contextual recommendation systems.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {159–166},
numpages = {8},
keywords = {agents, proactive recommendations, context},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040870,
author = {O'Donovan, John and Smyth, Barry},
title = {Trust in Recommender Systems},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040870},
doi = {10.1145/1040830.1040870},
abstract = {Recommender systems have proven to be an important response to the information overload problem, by providing users with more proactive and personalized information services. And collaborative filtering techniques have proven to be an vital component of many such recommender systems as they facilitate the generation of high-quality recom-mendations by leveraging the preferences of communities of similar users. In this paper we suggest that the traditional emphasis on user similarity may be overstated. We argue that additional factors have an important role to play in guiding recommendation. Specifically we propose that the trustworthiness of users must be an important consideration. We present two computational models of trust and show how they can be readily incorporated into standard collaborative filtering frameworks in a variety of ways. We also show how these trust models can lead to improved predictive accuracy during recommendation.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {167–174},
numpages = {8},
keywords = {profile similarity, reputation, collaborative filtering, trust, recommender systems},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040871,
author = {McCarthy, Kevin and Reilly, James and McGinty, Lorraine and Smyth, Barry},
title = {Experiments in Dynamic Critiquing},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040871},
doi = {10.1145/1040830.1040871},
abstract = {Conversational recommender systems are commonly used to help users to navigate through complex product-spaces by alternatively making product suggestions and soliciting user feedback in order to guide subsequent suggestions. Recently, there has been a surge of interest in developing effective interfaces that support user interaction in domains of limited user expertise. Critiquing has proven to be a popular and successful user feedback mechanism in this regard, but is typically limited to the modification of single features. We review a novel approach to critiquing, dynamic critiquing, that allows users to modify multiple features simultaneously by choosing from a range of so-called compound critiques that are automatically proposed based on their current position within the product-space. In addition, we introduce the results of an important new live-user study that evaluates the practical benefits of dynamic critiquing.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {175–182},
numpages = {8},
keywords = {user-interfacing/feedback, recommender systems, critiquing},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040872,
author = {Corradini, Andrea and Mehta, Manish and Bernsen, Niels-Ole and Charfuelan, Marcela},
title = {Animating an Interactive Conversational Character for an Educational Game System},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040872},
doi = {10.1145/1040830.1040872},
abstract = {Within the framework of the project NICE (Natural Interactive Communication for Edutainment) [2], we have been developing an educational and entertaining computer game that allows children and teenagers to interact with a conversational character impersonating the fairy tale writer H.C. Andersen (HCA). The rationale behind our system is to make kids learn about HCA's life, fairy tales and historical period while playing and having fun. We report on the character's generation and realization of both verbal and 3D graphical non-verbal output behaviors, such as speech, body gestures and facial expressions. This conveys the impression of a human-like agent with relevant domain knowledge, and distinct personality. With the educational goal in the foreground, coherent and synchronized output presentation becomes mandatory, as any inconsistency may undermine the user's learning process rather than reinforcing it.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {183–190},
numpages = {8},
keywords = {edutainment, embodied conversational agent, user interface, multimodal output},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040872_R40666,
author = {Godwin, Stewart Mark},
title = {Review ID:R40666 for DOI: 10.1145/1040830.1040872},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040872_R40666}
}

@inproceedings{10.1145/1040830.1040874,
author = {Blythe, Jim},
title = {Task Learning by Instruction in Tailor},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040874},
doi = {10.1145/1040830.1040874},
abstract = {In order for intelligent systems to be applicable in a wide range of situations, end users must be able to modify their task descriptions. We introduce Tailor, a system that allows users to modify task information through instruction. In this approach, the user enters a short sentence to describe the desired change. The system maps the sentence into valid, plausible modifications and checks for unexpected side-effects they may have, working interactively with the user throughout the process. We conducted preliminary tests in which subjects used Tailor to make modifications to domains drawn from the eHow website, applying modifications posted by readers as 'tips'. In this way the subjects acted as interpreters between Tailor and the human-generated descriptions of modifications. Almost all the subjects were able to make all modifications to the process descriptions with Tailor, indicating that the interpreter role is quite natural for users.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {191–198},
numpages = {8},
keywords = {task learning by instruction, knowledge acquisition, reasoning about actions},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040875,
author = {Sereno, Bertrand and Shum, Simon Buckingham and Motta, Enrico},
title = {ClaimSpotter: An Environment to Support Sensemaking with Knowledge Triples},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040875},
doi = {10.1145/1040830.1040875},
abstract = {Annotating a document with an interpretation of its contents raises a number of challenges that we are hoping to address via the creation of a supporting environment. We present these challenges and motivate an approach based on the notion of suggestions to support document annotation, hoping these suggestions would act as leads to follow for annotators, therefore reducing some of the difficulties inherent to the task. The environment resulting from this approach, ClaimSpotter, is presented. Aspects of its evaluation are also given, using the findings of a study involving a group of participants faced with a document annotation task.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {199–206},
numpages = {8},
keywords = {user studies, interface, annotation, sensemaking},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040876,
author = {Maguitman, Ana and Leake, David and Reichherzer, Thomas},
title = {Suggesting Novel but Related Topics: Towards Context-Based Support for Knowledge Model Extension},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040876},
doi = {10.1145/1040830.1040876},
abstract = {Much intelligent user interfaces research addresses the problem of providing information relevant to a current user topic. However, little work addresses the complementary question of helping the user identify potential topics to explore next. In knowledge acquisition, this question is crucial to deciding how to extend previously-captured knowledge. This paper examines requirements for effective topic suggestion and presents a domain-independent topic-generation algorithm designed to generate candidate topics that are novel but related to the current context. The algorithm iteratively performs a cycle of topic formation, Web search for connected material, and context-based filtering. An experimental study shows that this approach significantly outperforms a baseline at developing new topics similar to those chosen by an expert for a hand-coded knowledge model.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {207–214},
numpages = {8},
keywords = {human-centered knowledge acquisition tools, automatic topic search, context, concept mapping},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040876_R39495,
author = {Mulvenna, Maurice D},
title = {Review ID:R39495 for DOI: 10.1145/1040830.1040876},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040876_R39495}
}

@inproceedings{10.1145/1040830.1040877,
author = {Puerta, Angel and Micheletti, Michael and Mak, Alan},
title = {The UI Pilot: A Model-Based Tool to Guide Early Interface Design},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040877},
doi = {10.1145/1040830.1040877},
abstract = {In this paper, we introduce the User Interface Pilot, a model-based software tool that enables designers and engineers to create the initial specifications for the pages of a website, or for the screens of a desktop or mobile application. The tool guides the design of these specifications, commonly known as wireframes, in a user-centered fashion by framing the context of the design within the concepts of user tasks, user types, and data objects. Unlike previous model-based tools, the User Interface Pilot does not impose a rigid model-driven methodology and functions well within common software engineering development processes. The tool has been used in over twenty real-world user interface design projects.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {215–222},
numpages = {8},
keywords = {model-based user interface development, user interface tools, user interface models, wireframes, XIML, knowledge-based user interface design},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040879,
author = {Graziola, Ilenia and Pianesi, Fabio and Zancanaro, Massimo and Goren-Bar, Dina},
title = {Dimensions of Adaptivity in Mobile Systems: Personality and People's Attitudes},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040879},
doi = {10.1145/1040830.1040879},
abstract = {In this work, we present a study about adaptation on a mobile museum guide aiming at investigating the relationships between personality traits and the attitudes toward some basic dimensions of adaptivity. Each participant was exposed to two simulated systems that realized an adaptive and a non-adaptive version, respectively, on each of the dimensions investigated. The study showed interesting effects of Big Five personality traits on acceptance of the adaptivity dimensions; in particular conscientiousness, creativity and stability. Locus of control seemed to have a limited yet quite selective effect on delegating to the system the choice of follow-ups.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {223–230},
numpages = {8},
keywords = {user evaluation, mobile, HCI, adaptivity, PDA},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040880,
author = {Leong, Lee Hoi and Kobayashi, Shinsuke and Koshizuka, Noboru and Sakamura, Ken},
title = {CASIS: A Context-Aware Speech Interface System},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040880},
doi = {10.1145/1040830.1040880},
abstract = {In this paper, we propose a robust natural language interface called CASIS for controlling devices in an intelligent environment. CASIS is novel in a sense that it integrates physical context acquired from the sensors embedded in the environment with traditionally used context to reduce the system error rate and disambiguate deictic references and elliptical inputs. The n-best result of the speech recognizer is re-ranked by a score calculated using a Bayesian network consisting of information from the input utterance and context. In our prototype system that uses device states, brightness, speaker location, chair occupancy, speech direction and action history as context, the system error rate has been reduced by 41% compared to a baseline system that does not leverage on context information.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {231–238},
numpages = {8},
keywords = {speech user interface, context-aware computing, natural language processing, Bayesian network},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040881,
author = {Mo, Zhenyao and Lewis, J. P. and Neumann, Ulrich},
title = {SmartCanvas: A Gesture-Driven Intelligent Drawing Desk System},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040881},
doi = {10.1145/1040830.1040881},
abstract = {This paper describes SmartCanvas, an intelligent desk system that allows a user to perform freehand drawing on a desk or similar surface with gestures. Our system requires one camera and no touch sensors. The key underlying technique is a vision-based method that distinguishes drawing gestures and transitional gestures in real time, avoiding the need for "artificial" gestures to mark the beginning and end of a drawing stroke. The method achieves an average classification accuracy of 92.17%. Pie-shaped menus and a "rotate-to-and-select" approach eliminate the need for a fixed menu display, resulting in an "invisible" interface.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {239–243},
numpages = {5},
keywords = {intelligent user interface, gesture recognition, support vector machine},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040883,
author = {Partala, Timo and Surakka, Veikko and Vanhala, Toni},
title = {Person-Independent Estimation of Emotional Experiences from Facial Expressions},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040883},
doi = {10.1145/1040830.1040883},
abstract = {The aim of this research was to develop methods for the automatic person-independent estimation of experienced emotions from facial expressions. Ten subjects watched series of emotionally arousing pictures and videos, while the electromyographic (EMG) activity of two facial muscles: zygomaticus major (activated in smiling) and corrugator supercilii (activated in frowning) was registered. Based on the changes in the activity of these two facial muscles, it was possible to distinguish between ratings of positive and negative emotional experiences at a rate of almost 70% for pictures and over 80% for videos. Using these methods, the computer could adapt its behavior according to the user's emotions during human-computer interaction.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {246–248},
numpages = {3},
keywords = {facial expressions, emotions, social agents},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040884,
author = {Baylor, Amy L.},
title = {Preliminary Design Guidelines for Pedagogical Agent Interface Image},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040884},
doi = {10.1145/1040830.1040884},
abstract = {Pedagogical agent image is a key feature for animated interface agents. Experimental research indicates that agent interface images should be carefully designed, considering both the relevant outcomes (learning or motivational) together with student characteristics. This paper summarizes empirically-derived design guidelines for pedagogical agent image.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {249–250},
numpages = {2},
keywords = {image, pedagogical agent, motivation, social interface, agent, human-computer interaction, user studies},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040885,
author = {Inanoglu, Zeynep and Caneel, Ron},
title = {Emotive Alert: HMM-Based Emotion Detection in Voicemail Messages},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040885},
doi = {10.1145/1040830.1040885},
abstract = {Voicemail has become an integral part of our personal and professional communication. The number of messages that accumulate in our voice mailboxes necessitate new ways of prioritizing them. Currently, we are forced to actively listen to all messages in order to find out which ones are important and which ones can be attended to later on. In this paper, we describe Emotive Alert, a system that can detect some of the significant emotions in a new message and notify the account owner along various affective axes, including urgency, formality, valence (happy vs. sad) and arousal (calm vs. excited). We have used a purely acoustic, HMM-based approach for identifying the emotions, which allows application of this system to all messages independent of language.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {251–253},
numpages = {3},
keywords = {machine learning, voicemail processing, affective computing},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040887,
author = {Singh, Randeep and Seth, Bhartendu and Desai, Uday B.},
title = {Vision Based GUI for Interactive Mobile Robots},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040887},
doi = {10.1145/1040830.1040887},
abstract = {Interactive mobile robots are an active area of research. This paper presents a framework for designing a real-time vision based hand-body gesture user interface for such robots. The said framework works in real world lighting conditions, with complex background, and can handle intermittent motion of the camera. The input signal is captured by using a singular monocular color camera. Vision is the only feedback sensor being used. It is assumed that the gesturer is wearing clothes that are slightly different from the background. We have tested this framework on a gesture database consisting of 11 hand-body gestures and have recorded recognition accuracy up to 90%.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {254–256},
numpages = {3},
keywords = {interactive robots, gesture user interaction (GUI)},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040888,
author = {Rosenstein, Michael T. and Fagg, Andrew H. and Ou, Shichao and Grupen, Roderic A.},
title = {User Intentions Funneled through a Human-Robot Interface},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040888},
doi = {10.1145/1040830.1040888},
abstract = {We describe a method for predicting user intentions as part of a human-robot interface. In particular, we show that funnels, i.e., geometric objects that partition an input space, provide a convenient means for discriminating individual objects and for clustering sets of objects for hierarchical tasks. One advantage of the proposed implementation is that a simple parametric model can be used to specify the shape of a funnel, and a straightforward heuristic for setting initial parameter values appears promising. We discuss the possibility of adapting the user interface with machine learning techniques, and we illustrate the approach with a humanoid robot performing a variation of a standard peg-insertion task.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {257–259},
numpages = {3},
keywords = {telerobotics, predictive display, human-robot interaction},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040890,
author = {Al-Mubaid, Hisham and Chen, Ping},
title = {Context-Based Similar Words Detection and Its Application in Specialized Search Engines},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040890},
doi = {10.1145/1040830.1040890},
abstract = {This paper presents a new context-based method for automatic detection and extraction of similar and related words from texts. Finding similar words is a very important task for many NLP applications including anaphora resolution, document retrieval, text segmentation, and text summarization. Here we use word similarity to improve search quality for search engines in (general and) specific domains. Our method is based on rules for extracting the words in the neighborhood of a target word, then connecting this with the surroundings of other occurrences of the same word in the (training) text corpus. This is an on-going work, and is still under extensive testing. The preliminary results, however, are promising and encouraging more work in this direction.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {260–262},
numpages = {3},
keywords = {information retrieval, word-similarity detection},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040891,
author = {Tuchinda, Rattapoom and Knoblock, Craig A.},
title = {Interactively Building Agents for Consumer-Side Data Mining},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040891},
doi = {10.1145/1040830.1040891},
abstract = {Integrating and mining data from different web sources can make end-users well-informed when they make decisions. One of many limitations that bars end-users from taking advantages of such process is the complexity in each of the steps required to gather, integrate, monitor, and mine data from different websites. We present the idea of combining the data integration, monitoring, and mining as one single process in the form of an intelligent assistant that guides end-users to specify their mining tasks by just answering questions. This easy-to-use approach, which trades off complexity in terms of available operations with the ease of use, has the ability to provide interesting insight into the data that would requires days of human effort to gather, combine, and mine manually from the web.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {263–265},
numpages = {3},
keywords = {user interface, information agent, information integration},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040892,
author = {Yoo, Jungsoon and Li, Cen and Pettey, Chrisila},
title = {Adaptive Teaching Strategy for Online Learning},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040892},
doi = {10.1145/1040830.1040892},
abstract = {Finding the optimal teaching strategy for an individual student is difficult even for an experienced teacher. Identifying and incorporating multiple optimal teaching strategies for different students in a class is even harder. This paper presents an Adaptive tutor for online Learning, AtoL, for Computer Science laboratories that identifies and applies the appropriate teaching strategies for students on an individual basis. The optimal strategy for a student is identified in two steps. First, a basic strategy for a student is identified using rules learned from a supervised learning system. Then the basic strategy is refined to better fit the student using models learned using an unsupervised learning system that takes into account the temporal nature of the problem solving process. The learning algorithms as well as the initial experimental results are presented.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {266–268},
numpages = {3},
keywords = {adaptive user interface, personalization, intelligent tutoring system, user modeling},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040892_R39146,
author = {Hirschfelder, John J.},
title = {Review ID:R39146 for DOI: 10.1145/1040830.1040892},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040892_R39146}
}

@inproceedings{10.1145/1040830.1040893,
author = {Ramachandran, Ashwin and Young, R. Michael},
title = {Providing Intelligent Help across Applications in Dynamic User and Environment Contexts},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040893},
doi = {10.1145/1040830.1040893},
abstract = {The problem of providing help for complex application interfaces has been a source of interest for a number of researcher efforts. As the computational power of computers increases, typical applications not only increase in functionality but also in the degree of interaction with the computational environment in which they reside. This paper describes an ongoing project to design an Intelligent Help System (IHS) that provides context-sensitivity not only through its modeling of application states but also its modeling of the interaction between applications and between an application and the environment in which it resides.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {269–271},
numpages = {3},
keywords = {planning, intelligent help systems, intelligent interactive environments},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040895,
author = {Chi, Ed H. and Hong, Lichan and Gumbrecht, Michelle and Card, Stuart K.},
title = {ScentHighlights: Highlighting Conceptually-Related Sentences during Reading},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040895},
doi = {10.1145/1040830.1040895},
abstract = {Researchers have noticed that readers are increasingly skimming instead of reading in depth. Skimming also occur in re-reading activities, where the goal is to recall specific topical facts. Bookmarks and highlighters were invented precisely to achieve this goal. For skimming activities, readers need effective ways to direct their attention toward the most relevant passages within text. We describe how we have enhanced skimming activity by conceptually highlighting sentences within electronic text that relate to search keywords. We perform the conceptual highlighting by computing what conceptual keywords are related to each other via word co-occurrence and spreading activation. Spreading activation is a cognitive model developed in psychology to simulate how memory chunks and conceptual items are retrieved in our brain. We describe the method used, and illustrate the idea with realistic scenarios using our system.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {272–274},
numpages = {3},
keywords = {eBooks, information scent, contextualization, dynamic summarization, personalized information access, automatic text highlighting},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040896,
author = {Callaway, Charles and Kuflik, Tsvi and Not, Elena and Novello, Alessandra and Stock, Oliviero and Zancanaro, Massimo},
title = {Personal Reporting of a Museum Visit as an Entrypoint to Future Cultural Experience},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040896},
doi = {10.1145/1040830.1040896},
abstract = {Museum visitors can continue interacting with museum exhibits even after they have left the museum. We can help them do this by creating a report that includes a basic, personalized narration of their visit, the items and relationships they found most interesting, pointers to additional related online information, and suggestions for future visits to the current and other museums. In this work we describe the automatic generation of personalized natural language reports to help create one episode in an ongoing coherent sequence of cultural activities.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {275–277},
numpages = {3},
keywords = {personalized information presentation, continous interaction, natural language generation},
location = {San Diego, California, USA},
series = {IUI '05}
}

@dataset{10.1145/review-1040830.1040896_R38975,
author = {James, Edward Baker},
title = {Review ID:R38975 for DOI: 10.1145/1040830.1040896},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1040830.1040896_R38975}
}

@inproceedings{10.1145/1040830.1040898,
author = {Lieberman, Henry and Faaborg, Alexander and Daher, Waseem and Espinosa, Jos\'{e}},
title = {How to Wreck a Nice Beach You Sing Calm Incense},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040898},
doi = {10.1145/1040830.1040898},
abstract = {A principal problem in speech recognition is distinguishing between words and phrases that sound similar but have different meanings. Speech recognition programs produce a list of weighted candidate hypotheses for a given audio segment, and choose the "best" candidate. If the choice is incorrect, the user must invoke a correction interface that displays a list of the hypotheses and choose the desired one. The correction interface is time-consuming, and accounts for much of the frustration of today's dictation systems. Conventional dictation systems prioritize hypotheses based on language models derived from statistical techniques such as n-grams and Hidden Markov Models.We propose a supplementary method for ordering hypotheses based on Commonsense Knowledge. We filter acoustical and word-frequency hypotheses by testing their plausibility with a semantic network derived from 700,000 statements about everyday life. This often filters out possibilities that "don't make sense" from the user's viewpoint, and leads to improved recognition. Reducing the hypothesis space in this way also makes possible streamlined correction interfaces that improve the overall throughput of dictation systems.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {278–280},
numpages = {3},
keywords = {predictive interfaces, open mind common sense, speech recognition},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040899,
author = {Sezgin, Tevfik Metin and Davis, Randall},
title = {HMM-Based Efficient Sketch Recognition},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040899},
doi = {10.1145/1040830.1040899},
abstract = {Current sketch recognition systems treat sketches as images or a collection of strokes, rather than viewing sketching as an interactive and incremental process. We show how viewing sketching as an interactive process allows us to recognize sketches using Hidden Markov Models. We report results of a user study indicating that in certain domains people draw objects using consistent stroke orderings. We show how this consistency, when present, can be used to perform sketch recognition efficiently. This novel approach enables us to have polynomial time algorithms for sketch recognition and segmentation, unlike conventional methods with exponential complexity.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {281–283},
numpages = {3},
keywords = {sketch recognition, intelligent user interfaces, interpretation of user input, enabling input technologies},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040900,
author = {Olwal, Alex and Feiner, Steven},
title = {Interaction Techniques Using Prosodic Features of Speech and Audio Localization},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040900},
doi = {10.1145/1040830.1040900},
abstract = {We describe several approaches for using prosodic features of speech and audio localization to control interactive applications. This information can be applied to parameter control, as well as to speech disambiguation. We discuss how characteristics of spoken sentences can be exploited in the user interface; for example, by considering the speed with which a sentence is spoken and the presence of extraneous utterances. We also show how coarse audio localization can be used for low-fidelity gesture tracking, by inferring the speaker's head position.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {284–286},
numpages = {3},
keywords = {interaction, gesture, voice I/O, speech},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040901,
author = {Yeh, Tom and Darrell, Trevor},
title = {Doubleshot: An Interactive User-Aided Segmentation Tool},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040901},
doi = {10.1145/1040830.1040901},
abstract = {In this paper, we describe an intelligent user interface designed for camera phones to allow mobile users to specify the object of interest in the scene simply by taking two pictures: one with the object and one without the object. By comparing these two images, the system can reliably extract the visual appearance of the object, which can be useful to a wide-range of applications such as content-based image retrieval and object recognition.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {287–289},
numpages = {3},
keywords = {object recognition, computer vision, mobile application},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040902,
author = {Ziegler, J\"{u}rgen and El Jerroudi, Zoulfa and B\"{o}hm, Karsten},
title = {Generating Semantic Contexts from Spoken Conversation in Meetings},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040902},
doi = {10.1145/1040830.1040902},
abstract = {SemanticTalk is a tool for supporting face-to-face meetings and discussions by automatically generating a semantic context from spoken conversations. We use speech recognition and topic extraction from a large terminological database to create a network of discussion topics in real-time. This network includes concepts explicitly addressed in the discussion as well as semantically associated terms, and is visualized to increase conversational awareness and creativity in the group.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {290–292},
numpages = {3},
keywords = {intelligent assistance, real-time speech-recognition, semantic context, conversational awareness},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040903,
author = {Heeman, Peter A. and Yang, Fan and Kun, Andrew L. and Shyrokov, Alexander},
title = {Conventions in Human-Human Multi-Threaded Dialogues: A Preliminary Study},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040903},
doi = {10.1145/1040830.1040903},
abstract = {In this paper, we explore the conventions that people use in managing multiple dialogue threads. In particular, we focus on where in a thread people interrupt when switching to another thread. We find that some subjects are able to vary where they switch depending on how urgent the interrupting task is. When time-allowed, they switched at the end of a discourse segment, which we hypothesize is less disruptive to the interrupted task when it is later resumed.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {293–295},
numpages = {3},
keywords = {dialogue, multi-tasking, speech interface},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040904,
author = {Hazan, Amaury},
title = {Towards Automatic Transcription of Expressive Oral Percussive Performances},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040904},
doi = {10.1145/1040830.1040904},
abstract = {We describe a tool for transcribing voice generated percussive rhythms. The system consists of: (a) a segmentation component which separates the monophonic input stream into percussive events (b) a descriptors generation component that computes a set of acoustic features from each of the extracted segments, (c) a machine learning component which assigns to each of the segmented sounds of the input stream a symbolic class. We describe each of these components and compare different machine learning strategies that can be used to obtain a symbolic representation of the oral percussive performance.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {296–298},
numpages = {3},
keywords = {knowledge-based approaches, speech processing, performance transcription},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040905,
author = {Albertini, Adriano and Brunelli, Roberto and Stock, Oliviero and Zancanaro, Massimo},
title = {Communicating User's Focus of Attention by Image Processing as Input for a Mobile Museum Guide},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040905},
doi = {10.1145/1040830.1040905},
abstract = {The paper presents a first prototype of a handheld museum guide delivering contextualized information based on the recognition of drawing details selected by the user through the guide camera. The resulting interaction modality has been analyzed and compared to previous approaches. Finally, alternative, more scalable, solutions are presented that preserve the most interesting features of the system described.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {299–301},
numpages = {3},
keywords = {appearance-based recognition, machine learning, human-machine interaction},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040907,
author = {Williams, Ryan and Barry, Barbara and Singh, Push},
title = {ComicKit: Acquiring Story Scripts Using Common Sense Feedback},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040907},
doi = {10.1145/1040830.1040907},
abstract = {At the Media Lab we are developing a resource called StoryNet, a very-large database of story scripts that can be used for commonsense reasoning by computers. This paper introduces ComicKit, an interface for acquiring StoryNet scripts from casual internet users. The core element of the interface is its ability to dynamically make common-sense suggestions that guide user story construction. We describe the encouraging results of a preliminary user study, and discuss future directions for ComicKit.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {302–304},
numpages = {3},
keywords = {common sense, knowledge acquisition, story representation, case-based reasoning},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040908,
author = {Liu, Hugo and Lieberman, Henry},
title = {Metafor: Visualizing Stories as Code},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040908},
doi = {10.1145/1040830.1040908},
abstract = {Every program tells a story. Programming, then, is the art of constructing a story about the objects in the program and what they do in various situations. So-called programming languages, while easy for the computer to accurately convert into code, are, unfortunately, difficult for people to write and understand.We explore the idea of using descriptions in a natural language as a representation for programs. While we cannot yet convert arbitrary English to fully specified code, we can use a reasonably expressive subset of English as a visualization tool. Simple descriptions of program objects and their behavior generate scaffolding (underspecified) code fragments, that can be used as feedback for the designer. Roughly speaking, noun phrases can be interpreted as program objects; verbs can be functions, adjectives can be properties. A surprising amount of what we call programmatic semantics can be inferred from linguistic structure. We present a program editor, Metafor, that dynamically converts a user's stories into program code, and in a user study, participants found it useful as a brainstorming tool.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {305–307},
numpages = {3},
keywords = {storytelling, case tools, natural language programming},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040909,
author = {Birnbaum, Larry and Hopp, Wallace and Iravani, Seyed and Livingston, Kevin and Shou, Biying and Tirpak, Thomas},
title = {Task Aware Information Access for Diagnosis of Manufacturing Problems},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040909},
doi = {10.1145/1040830.1040909},
abstract = {Pinpoint is a promising first step towards using a rich model of task context in proactive and dynamic IR systems. Pinpoint allows a user to navigate decision tree representations of problem spaces, built by domain experts, while dynamically entering annotations specific to their problem. The system then automatically generates queries to information repositories based on both the user's annotations and location in the problem space, producing results that are both task focused and problem specific. Initial feedback from users and domain experts has been positive.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {308–310},
numpages = {3},
keywords = {user task and context modeling, dynamic information retrieval},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040910,
author = {Chklovski, Timothy},
title = {Designing Interfaces for Guided Collection of Knowledge about Everyday Objects from Volunteers},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040910},
doi = {10.1145/1040830.1040910},
abstract = {A new generation of intelligent applications can be enabled by broad-coverage knowledge repositories about everyday objects. We distill lessons in design of intelligent user interfaces which collect such broad-coverage knowledge from untrained volunteers. We motivate the knowledge-driven template-based approach adopted in Learner2, a second generation proactive acquisition interface for eliciting such knowledge. We present volume, accuracy, and recall of knowledge collected by fielding the system for 5 months. Learner2 has so far acquired 99,018 general statements, emphasizing knowledge about parts of and typical uses of objects.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {311–313},
numpages = {3},
keywords = {collecting broad-coverage knowledge repositories, generalization in knowledge acquisition, interfaces for knowledge elicitation},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040911,
author = {Bauer, Mathias and Baldes, Stephan},
title = {An Ontology-Based Interface for Machine Learning},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040911},
doi = {10.1145/1040830.1040911},
abstract = {Machine learning (ML) is a complex process that can hardly be carried out by non-expert users. Especially when using adaptive systems that interpret and exploit observations of the user to modify their behavior according to the user's perceived preferences, even na\"{\i}ve users may be confronted with learning systems. This paper presents an approach to make non-expert users understand and influence an ML system such as to improve trust and acceptance of the overall system behavior.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {314–316},
numpages = {3},
keywords = {machine learning, transparency, user modeling},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040913,
author = {Bonanni, Leonardo and Lee, Chia-Hsun and Selker, Ted},
title = {A Framework for Designing Intelligent Task-Oriented Augmented Reality User Interfaces},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040913},
doi = {10.1145/1040830.1040913},
abstract = {A task-oriented space can benefit from an augmented reality interface that layers the existing tools and surfaces with useful information to make cooking more easy, safe and efficient. To serve experienced users as well as novices, augmented reality interfaces need to adapt modalities to the user's expertise and allow for multiple ways to perform tasks. We present a framework for designing an intelligent user interface that informs and choreographs multiple tasks in a single space according to a model of tasks and users. A residential kitchen has been outfitted with systems to gather data from tools and surfaces and project multi-modal interfaces back onto the tools and surfaces themselves. Based on user evaluations of this augmented reality kitchen, we propose a system to tailor information modalities based on the spatial and temporal qualities of the task, and the expertise, location and progress of the user. The intelligent augmented reality user interface choreographs multiple tasks in the same space at the same time.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {317–319},
numpages = {3},
keywords = {ubiquitous computing, industrial design, smart environments, augmented reality, kitchen},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040914,
author = {Butz, Andreas and Jung, Ralf},
title = {Seamless User Notification in Ambient Soundscapes},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040914},
doi = {10.1145/1040830.1040914},
abstract = {We describe a method for notifying users through auditory cues embedded in an ambient soundscape in the environment. It uses pieces of music which are composed in such a way, that particular instruments or motifs can be added or omitted without losing the aesthetic quality of the overall composition. This allows for very subtle modifications in the soundscape which are only noticed by those users who have chosen this particular instrument or motif as "their" notification instrument before. As a side effect, the soundscape itself can be used to subtly influence the mood of users. The method has been implemented in a prototype, which we briefly discuss. The prototype is implemented using a spatial audio framework and can hence notify users from particular directions.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {320–322},
numpages = {3},
keywords = {auditory cues, soundscapes, ambient audio, peripheral awareness},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040915,
author = {Cumby, Chad and Fano, Andrew and Ghani, Rayid and Krema, Marko},
title = {Building Intelligent Shopping Assistants Using Individual Consumer Models},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040915},
doi = {10.1145/1040830.1040915},
abstract = {This paper describes an Intelligent Shopping Assistant designed for a shopping cart mounted tablet PC that enables individual interactions with customers. We use machine learning algorithms to predict a shopping list for the customer's current trip and present this list on the device. As they navigate through the store, personalized promotions are presented using consumer models derived from loyalty card data for each inidvidual. In order for shopping assistant devices to be effective, we believe that they have to be powered by algorithms that are tuned for individual customers and can make accurate predictions about an individual's actions. We formally frame the shopping list prediction as a classification problem, describe the algorithms and methodology behind our system, and show that shopping list prediction can be done with high levels of accuracy, precision, and recall. Beyond the prediction of shopping lists we briefly introduce other aspects of the shopping assistant project, such as the use of consumer models to select appropriate promotional tactics, and the development of promotion planning simulation tools to enable retailers to plan personalized promotions delivered through such a shopping assistant.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {323–325},
numpages = {3},
keywords = {classification, retail applications, machine learning},
location = {San Diego, California, USA},
series = {IUI '05}
}

@inproceedings{10.1145/1040830.1040916,
author = {Kray, Christian and Kortuem, Gerd and Kr\"{u}ger, Antonio},
title = {Adaptive Navigation Support with Public Displays},
year = {2005},
isbn = {1581138946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1040830.1040916},
doi = {10.1145/1040830.1040916},
abstract = {In this paper, we describe a public navigation system which uses adaptive displays as directional signs. The displays are mounted to walls where they provide passersbys with directional information. Each sign is an autonomous, wirelessly networked digital displays connected to a central server. The signs are position-aware and able to adapt their display content in accordance with their current position. Advantages of such a navigation system include improved flexibility, dynamic adaptation and ease of setup and maintenance.},
booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces},
pages = {326–328},
numpages = {3},
keywords = {pervasive navigation, public displays},
location = {San Diego, California, USA},
series = {IUI '05}
}

