@inproceedings{10.1145/2732158.2732183,
author = {Krishna, Amrith and Bhowmick, Plaban and Ghosh, Krishnendu and Sahu, Archana and Roy, Subhayan},
title = {Automatic Generation and Insertion of Assessment Items in Online Video Courses},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732183},
doi = {10.1145/2732158.2732183},
abstract = {In this paper, we propose a prototype system for automatic generation and insertion of assessment items in online video courses. The proposed system analyzes text transcript of a requested video lecture to suggest self-assessment items in runtime through automatic discourse segmentation and question generation. To deal with the problem of question generation from noisy transcription, the system relies on semantically similar Wikipedia text segments. We base our study on a popular video lecture portal - National Programme on Technology Enhanced Learning (NPTEL). However, it can be adapted to other portals as well.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {1–4},
numpages = {4},
keywords = {latent semantic analysis, moocs, question generation, online video courses, rhetorical structure theory (rst)},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732178,
author = {Birnbaum, Larry and Boon, Miriam and Bradley, Scott and Wilson, Jennifer},
title = {The News Context Project},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732178},
doi = {10.1145/2732158.2732178},
abstract = {We describe intelligent information technologies designed to automatically provide both journalists and ordinary newsreaders with a broad range of the contextual information they need in order to better understand news stories, presented in an immediate and compelling fashion. These systems automatically identify, select, and present appropriate contextual information based on the story a user is currently viewing. Our experiences in building a number of specific systems of this kind have led to the creation of a general architecture and platform for developing such applications. These systems interact with news consumers directly through mechanisms such as browser extensions.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {5–8},
numpages = {4},
keywords = {contextual search, computational journalism, intelligent information systems},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732193,
author = {Cassani, Raymundo and Banville, Hubert and Falk, Tiago H.},
title = {MuLES: An Open Source EEG Acquisition and Streaming Server for Quick and Simple Prototyping and Recording},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732193},
doi = {10.1145/2732158.2732193},
abstract = {The past few years have seen the availability of consumer electroencephalography (EEG) devices increase significantly. These devices, usually with a compact form factor and affordable price, now allow researchers and enthusiasts to use EEG in various new contexts and environments. However, the many consumer headsets often require extensive programming experience to interface with their respective drivers; moreover, standardization of the access and recording of EEG data across the devices still remains to be done. Consequently, a tool is needed to facilitate the recording and streaming of EEG data from consumer headsets that can easily be interfaced with different programming languages and software, and that allows interchangeability between devices. This paper describes the open source MuSAE Lab EEG Server (MuLES), an EEG acquisition and streaming server that aims at creating a standard interface for portable EEG headsets, in order to accelerate the development of brain-computer interfaces (BCIs) and of general EEG use in novel contexts. In addition to the EEG server interface which currently supports five different consumer devices and session playback, clients are developed for use on different platforms and in various programming languages, making prototyping and recording a quick and simple task. To validate the functionality and usability of the EEG server, a use case highlighting its main features is presented. The developed tool simplifies the acquisition and recording of EEG data from portable consumer devices by providing a single efficient interface, with applications in areas such as basic and behavioural research, prototyping, neurogaming, live performance and arts.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {9–12},
numpages = {4},
keywords = {portable eeg, neurofeedback, electroencephalography (eeg), brain-computer interface (bci), neurogaming},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732180,
author = {de la Cruz, Gabriel V. and Peng, Bei and Lasecki, Walter S. and Taylor, Matthew E.},
title = {Towards Integrating Real-Time Crowd Advice with Reinforcement Learning},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732180},
doi = {10.1145/2732158.2732180},
abstract = {Reinforcement learning is a powerful machine learning paradigm that allows agents to autonomously learn to maximize a scalar reward. However, it often suffers from poor initial performance and long learning times. This paper discusses how collecting on-line human feedback, both in real time and post hoc, can potentially improve the performance of such learning systems. We use the game Pac-Man to simulate a navigation setting and show that workers are able to accurately identify both when a sub-optimal action is executed, and what action should have been performed instead. Demonstrating that the crowd is capable of generating this input, and discussing the types of errors that occur, serves as a critical first step in designing systems that use this real-time feedback to improve systems' learning performance on-the-fly.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {17–20},
numpages = {4},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732172,
author = {Hamlet, Connor and Korn, Daniel and Prasad, Nikhil and Siedlecki, Volodymyr and Encarnacion, Eliezer and Bartel, Jacob and Dewan, Prasun},
title = {User-Interfaces for Incremental Recipient and Response Time Predictions in Asynchronous Messaging},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732172},
doi = {10.1145/2732158.2732172},
abstract = {We have created a new set of existing and novel predictive user-interfaces for exchanging messages in asynchronous collaborative systems such as email and internet communities. These interfaces support predictions of tags, hierarchical recipients, and message response times. The predictions are made incrementally, as messages are composed, and are offered to both senders and receivers of messages. The user interfaces are implemented by a test-bed that also supports experiments to evaluate them. It can automate the actions of the collaborators with whom a subject exchanges messages, replay user actions, and gather and display effort and correctness metrics related to these predictions. The collaborator actions and predictions are specified using a declarative mechanism. A video demonstration of this work is available at http://youtu.be/NJt9Rfqb1ko.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {21–24},
numpages = {4},
keywords = {recommender systems},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732177,
author = {Long, Duri and Dillon, Nicholas and Wang, Kun and Carter, Jason and Dewan, Prasun},
title = {Interactive Control and Visualization of Difficulty Inferences from User-Interface Commands},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732177},
doi = {10.1145/2732158.2732177},
abstract = {Recently, there has been research on inferring user emotions. Like other inference research, it requires an iterative process in which what-if scenarios are played with different features and algorithms. Traditional, general-purpose data mining tools such as Weka have played an important part in promoting this process. We have augmented this toolset with an additional interactive test-bed designed for prediction and communication of programmer difficulties from user-interface commands. It provides end-user interfaces for communicating, correcting, and reacting to the predictions. In addition, it offers researchers user-interfaces for interacting with the prediction process as it is executed rather than, as in traditional mining tools, after it has generated data for a set of experimental subjects. These user-interfaces can be used to determine key elements of the prediction process, why certain wrong or right predictions have been made, and change parameters of the process. A video demonstration this work is available at http://youtu.be/09LpDIPG5h8.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {25–28},
numpages = {4},
keywords = {recommender systems},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732189,
author = {Gao, Yuan and Ilves, Kalle and G\l{}owacka, Dorota},
title = {OfficeHours: A System for Student Supervisor Matching through Reinforcement Learning},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732189},
doi = {10.1145/2732158.2732189},
abstract = {We describe OfficeHours, a recommender system that assists students in finding potential supervisors for their dissertation projects. OfficeHours is an interactive recommender system that combines reinforcement learning techniques with a novel interface that assists the student in formulating their query and allows active engagement in directing their search. Students can directly manipulate document features (keywords) extracted from scientific articles written by faculty members to indicate their interests and reinforcement learning is used to model the student's interests by allowing the system to trade off between exploration and exploitation. The goal of system is to give the student the opportunity to more effectively search for possible project supervisors in a situation where the student may have difficulties formulating their query or when very little information may be available on faculty members' websites about their research interests.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {29–32},
numpages = {4},
keywords = {exploratory search, student support systems},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732186,
author = {Kim, Heesun and Huh, Bo Kyung and Im, Seung Hyen and Joung, Hae Youn and Kwon, Gyu Hyun and Park, Ji-Hyung},
title = {From "Overview" to "Detail": An Exploration of Contextual Transparency for Public Transparent Interfaces},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732186},
doi = {10.1145/2732158.2732186},
abstract = {This study explores the contextual transparency of information presented on public transparent user interfaces through the maintenance of adequate legibility. To address this issue, we investigate the relationship between the information and transparency in a shop context. In this paper, we present an experiment which examines the effects of transparency, changing user's proximity, and information types on legibility with a public transparent information system. We report significant effects on performance and legibility, and the results indicate the different contextual transparency related to the user's proximity, depending on whether the user focuses on the information or the environment. In addition, under the 50% transparency (25% and 50% levels) fit into the closer proximity while the 50% transparency offers more harmonious view in a distant context. The implications of these results to the usability of public transparent user interfaces and design recommendations are also discussed.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {33–36},
numpages = {4},
keywords = {legibility, contextual transparency, public transparent interfaces, transparent displays},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732179,
author = {Masuko, Soh and Muta, Masafumi and Shinzato, Keiji and Mujibiya, Adiyan},
title = {WallSHOP: Multiuser Interaction with Public Digital Signage Using Mobile Devices for Personalized Shopping},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732179},
doi = {10.1145/2732158.2732179},
abstract = {We propose WallSHOP, a novel interactive shopping experience that extends content sharing between publicly available digital signage and mobile devices. Multiple users can freely access and browse the content of public digital signage through a public network. Furthermore, users can interact with this content using a personalized cursor that can be controlled with a touch-screen mobile device. WallSHOP also supports pulling content from the digital signage to a user's device, allowing users to browse through available products and privately perform checkouts by utilizing the advantages of both public and private displays. WallSHOP focuses on feasibility and scalability; therefore, it is implemented using only web-based components and does not require the installation of additional software.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {37–40},
numpages = {4},
keywords = {contents sharing, web-based application, public display, personal devices, e-commerce, digital signage},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732185,
author = {Maus, Adam N. and Atwood, Amy K.},
title = {Surveying Older Adults About a Recommender System for a Digital Library},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732185},
doi = {10.1145/2732158.2732185},
abstract = {We present results from a survey of adults, 63 and older, about the potential implementation of a recommender system within a digital library of health-related content. We studied how these older adults perceive the idea of a recommender system and different aspects of its design. We presented four different types of recommender systems in the survey and our results indicate that this group would prefer a system based on explicit feedback in the form of ratings that measure the helpfulness of content. Reinforcing previous research, we learned this group is interested in a system that explains why it recommended content and they do not want to spend much time creating a profile of interests to warm the system. We discuss where we would use this recommender system, how we designed the survey for our audience, and plans for future studies on this subject.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {41–44},
numpages = {4},
keywords = {user study, older adults, digital library recommender systems, recommender interfaces},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732181,
author = {Michel, Felix and Gil, Yolanda and Ratnakar, Varun and Hauder, Matheus},
title = {A Task-Centered Interface for On-Line Collaboration in Science},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732181},
doi = {10.1145/2732158.2732181},
abstract = {Although collaborative activities are paramount in science, little attention has been devoted to supporting on-line scientific collaborations. Our work focuses on scientific collaborations that revolve around complex science questions that require significant coordination to synthesize multi-disciplinary findings, enticing contributors to remain engaged for extended periods of time, and continuous growth to accommodate new contributors as needed as the work evolves over time. This paper presents the interface of the Organic Data Science Wiki to address these challenges. Our solution is based on the Semantic MediaWiki and extends it with new features for scientific collaboration. We present preliminary results from the usage of the interface in a pilot research project.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {45–48},
numpages = {4},
keywords = {collaboration interfaces, scientific collaboration, organic data science, semantic mediawiki},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732190,
author = {Mutlu, Belgin and Veas, Eduardo and Trattner, Christoph and Sabol, Vedran},
title = {VizRec: A Two-Stage Recommender System for Personalized Visualizations},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732190},
doi = {10.1145/2732158.2732190},
abstract = {Identifying and using the information from distributed and heterogeneous information sources is a challenging task in many application fields. Even with services that offer well-defined structured content, such as digital libraries, it becomes increasingly difficult for a user to find the desired information. To cope with an overloaded information space, we propose a novel approach - VizRec - combining recommender systems (RS) and visualizations. VizRec suggests personalized visual representations for recommended data. One important aspect of our contribution and a prerequisite for VizRec are user preferences that build a personalization model. We present a crowd based evaluation and show how such a model of preferences can be elicited.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {49–52},
numpages = {4},
keywords = {collaborative filtering, recommender systems, crowd-based experiment, visualization recommendation},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732194,
author = {Nelligan, Trevor and Polsley, Seth and Ray, Jaideep and Helms, Michael and Linsey, Julie and Hammond, Tracy},
title = {Mechanix: A Sketch-Based Educational Interface},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732194},
doi = {10.1145/2732158.2732194},
abstract = {At the university level, high enrollment numbers in classes can be overwhelming for professors and teaching assistants to manage. Grading assignments and tests for hundreds of students is time consuming and has led towards a push for software-based learning in large university classes. Unfortunately, traditional quantitative question-and-answer mechanisms are often not sufficient for STEM courses, where there is a focus on problem-solving techniques over finding the "right" answers. Working through problems by hand can be important in memory retention, so in order for software learning systems to be effective in STEM courses, they should be able to intelligently understand students' sketches. Mechanix is a sketch-based system that allows students to step through problems designed by their instructors with personalized feedback and optimized interface controls. Optimizations like color-coding, menu bar simplification, and tool consolidation are recent improvements in Mechanix that further the aim to engage and motivate students in learning.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {53–56},
numpages = {4},
keywords = {user-centered design, graphical user interfaces (gui), computer-assisted instruction (cai), interaction styles, guides},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732175,
author = {Orlosky, Jason and Weber, Markus and Gu, Yecheng and Sonntag, Daniel and Sosnovsky, Sergey},
title = {An Interactive Pedestrian Environment Simulator for Cognitive Monitoring and Evaluation},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732175},
doi = {10.1145/2732158.2732175},
abstract = {Recent advances in virtual and augmented reality have led to the development of a number of simulations for different applications. In particular, simulations for monitoring, evaluation, training, and education have started to emerge for the consumer market due to the availability and affordability of immersive display technology. In this work, we introduce a virtual reality environment that provides an immersive traffic simulation designed to observe behavior and monitor relevant skills and abilities of pedestrians who may be at risk, such as elderly persons with cognitive impairments. The system provides basic reactive functionality, such as display of navigation instructions and notifications of dangerous obstacles during navigation tasks. Methods for interaction using hand and arm gestures are also implemented to allow users explore the environment in a more natural manner.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {57–60},
numpages = {4},
keywords = {evaluation, cognitive monitoring, simulation, interaction, virtual reality},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732192,
author = {Pienta, Robert and Tamersoy, Acar and Tong, Hanghang and Endert, Alex and Chau, Duen Horng (Polo)},
title = {Interactive Querying over Large Network Data: Scalability, Visualization, and Interaction Design},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732192},
doi = {10.1145/2732158.2732192},
abstract = {Given the explosive growth of modern graph data, new methods are needed that allow for the querying of complex graph structures without the need of a complicated querying languages; in short, interactive graph querying is desirable. We describe our work towards achieving our overall research goal of designing and developing an interactive querying system for large network data. We focus on three critical aspects: scalable data mining algorithms, graph visualization, and interaction design. We have already completed an approximate subgraph matching system called MAGE in our previous work that fulfills the algorithmic foundation allowing us to query a graph with hundreds of millions of edges. Our preliminary work on visual graph querying, Graphite, was the first step in the process to making an interactive graph querying system. We are in the process of designing the graph visualization and robust interaction needed to make truly interactive graph querying a reality.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {61–64},
numpages = {4},
keywords = {graph querying and mining, visualization, interaction design},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732174,
author = {Prange, Alexander and Sandrala, Indra Praveen and Weber, Markus and Sonntag, Daniel},
title = {Robot Companions and Smartpens for Improved Social Communication of Dementia Patients},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732174},
doi = {10.1145/2732158.2732174},
abstract = {In this demo paper we describe how a digital pen and a humanoid robot companion can improve the social communication of a dementia patient. We propose the use of NAO, a humanoid robot, as a companion to the dementia patient in order to continuously monitor his or her activities and provide cognitive assistance in daily life situations. For example, patients can communicate with NAO through natural language by the speech dialogue functionality we integrated. Most importantly, to improve communication, i.e., sending digital messages (texting, emails), we propose the usage of a smartpen, where the patients write messages on normal paper with an invisible dot pattern to initiate hand-writing and sketch recognition in real-time. The smartpen application is embedded into the human-robot speech dialogue.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {65–68},
numpages = {4},
keywords = {realtime interaction, healthcare, reality orientation dialogue, design, pen/ink interface, speech dialogue},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732195,
author = {Raybourn, Elaine M. and Fabian, Nathan and Davis, Warren and Parks, Raymond C. and McClain, Jonathan and Trumbo, Derek and Regan, Damon and Durlach, Paula},
title = {Data Privacy and Security Considerations for Personal Assistants for Learning (PAL)},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732195},
doi = {10.1145/2732158.2732195},
abstract = {A hypothetical scenario is utilized to explore privacy and security considerations for intelligent systems, such as a Personal Assistant for Learning (PAL). Two categories of potential concerns are addressed: factors facilitated by user models, and factors facilitated by systems. Among the strategies presented for risk mitigation is a call for ongoing, iterative dialog among privacy, security, and personalization researchers during all stages of development, testing, and deployment.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {69–72},
numpages = {4},
keywords = {security, personalized learning, privacy},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732184,
author = {Sakai, Daiki and Yamamoto, Michiya and Nagamatsu, Takashi},
title = {Framework for Realizing a Free-Target Eye-Tracking System},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732184},
doi = {10.1145/2732158.2732184},
abstract = {Various eye-trackers have recently become commercially available, but studies on more high-spec eye-tracking system have been conducted. Especially, studies have shown that conventional eye-trackers are rather inflexible in layout. The cameras employed in these eye-trackers, as well as the light sources and user's position are fixed, and only a predefined plane can be the target of the eye-tracking. In this study, we propose a new framework that we call a Free-Target Eye-tracking System, which consists of eye-tracking hardware and a hardware layout solver. We developed a prototype of a hardware layout solver and demonstrated its effectiveness.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {73–76},
numpages = {4},
keywords = {free target, eye-tracking, gaze cone},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732182,
author = {Spiliopoulou, Evangelia and Rugaber, Spencer and Goel, Ashok and Chen, Lianghao and Wiltgen, Bryan and Jagannathan, Arvind Krishnaa},
title = {Intelligent Search for Biologically Inspired Design},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732182},
doi = {10.1145/2732158.2732182},
abstract = {In Biologically Inspired Design (BID), engineers use biology as a source of ideas for solving engineering problems. However, locating relevant literature is difficult due to vocabulary differences and lack of domain knowledge. IBID is an intelligent search mechanism that uses a functional taxonomy to direct search and a formal modeling notation for annotating relevant search targets.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {77–80},
numpages = {4},
keywords = {natural language processing, biologically inspired design, intelligent search},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732187,
author = {Toshniwal, Shubham and Sharma, Parikshit and Srivastava, Saurabh and Sehgal, Richa},
title = {USHER: An Intelligent Tour Companion},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732187},
doi = {10.1145/2732158.2732187},
abstract = {Audio Guides have been the prevalent mode of information delivery in public spaces such as Museums and Art Galleries. These devices are programmed to render static information to their users about the collections and artworks present and require human input to operate. The inability to automatically deliver contextual messages and the lack of interactivity are major hurdles to ensuring a rich and seamless user experience. Ubiquitous smartphones can be leveraged to create pervasive audio guides that provide rich and personalized user experience. In this paper, we present the design and implementation of "Usher", an intelligent tour companion. Usher provides three distinct advantages over traditional audio guides. First, Usher uses smartphone sensors to infer user context such as his physical location, locomotive state and orientation to deliver relevant information to the user. Second, Usher also provides interface to a cognitive Question Answer(QA) service for the inquisitive users and answers contextual queries. Finally, Usher notifies users if any of their social media friends are present in the vicinity. The ability to seamlessly track user context to provide rich semantic information and the cognitive capability to answer contextual queries means that Usher can enhance the user experience in a museum by multitudes.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {81–84},
numpages = {4},
keywords = {natural language and speech processing, social media, museum tour companion, context based services},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732171,
author = {Tomiyasu, Fumiharu and Mase, Kenji},
title = {Human-Machine Cooperative Viewing System for Wide-Angle Multi-View Videos},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732171},
doi = {10.1145/2732158.2732171},
abstract = {Wide-angle multi-view video, which provides viewers with a realistic experience, has received increasing attention in recent years. Users want to watch such videos interactively, switching viewpoints freely, but without the burdens of consecutive viewpoint selection or complex operation. Viewing systems should therefore satisfy these conflicting needs simultaneously. In this paper, we take the novel approach of confronting multi-view videos as a cooperative work. We also introduce a human-machine cooperative viewing system for wide-angle multi-view videos exploiting target-centered viewing. Our system consists of a manual viewpoint selection function and an automatic viewpoint selection function based on our concept.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {85–88},
numpages = {4},
keywords = {wide-angle multi-view video, video viewing interface, target-centered viewing, cooperative work},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732176,
author = {Vega, Katia and Cunha, Marcio and Fuks, Hugo},
title = {Hairware: Conductive Hair Extensions as a Capacitive Touch Input Device},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732176},
doi = {10.1145/2732158.2732176},
abstract = {Our aim is to use our own bodies as an interactive platform. We are trying to move away from traditional wearable devices worn on clothes and accessories where gestures are noticeable and remind cyborg looking. We follow Beauty Technology paradigm that uses the body's surface as an interactive platform by integrating technology into beauty products applied directly to one's skin, fingernails and hair. Thus, we propose Hairware, a Beauty Technology Prototype that connects chemically metalized hair extensions to a microcontroller turning it into an input device for triggering different objects. Hairware acts as a capacitive touch sensor that detects touch variations on hair and uses machine learning algorithms in order to recognize user's intention. In this way, we add a new functionality to hair extensions, becoming a seamless device that recognizes auto-contact behaviors that no observers would identify. This work presents the design of Hairware's hardware and software implementation. In this demo, we show Hairware acting as a controller for smartphones and computers.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {89–92},
numpages = {4},
keywords = {gesture recognition, hairware, conductive hair, beauty technology, wearable computing},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732173,
author = {Fan, Xiangmin and Liu, Youming and Cao, Nan and Hong, Jason and Wang, Jingtao},
title = {MindMiner: Quantifying Entity Similarity via Interactive Distance Metric Learning},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732173},
doi = {10.1145/2732158.2732173},
abstract = {We present MindMiner, a mixed-initiative interface for capturing subjective similarity measurements via a combination of new interaction techniques and machine learning algorithms. MindMiner collects qualitative, hard to express similarity measurements from users via active polling with uncertainty and example based visual constraint creation. MindMiner also formulates human prior knowledge into a set of inequalities and learns a quantitative similarity distance metric via convex optimization. In a 12-participant peer-review understanding task, we found MindMiner was easy to learn and use, and could capture users' implicit knowledge about writing performance and cluster target entities into groups that match subjects' mental models.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {93–96},
numpages = {4},
keywords = {machine learning, mixed-initiative interface, visualization, clustering, convex optimization},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732188,
author = {Wolf, KatieAnna E. and Gliner, Genna and Fiebrink, Rebecca},
title = {A Model for Data-Driven Sonification Using Soundscapes},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732188},
doi = {10.1145/2732158.2732188},
abstract = {A sonification is a rendering of audio in response to data, and is used in instances where visual representations of data are impossible, difficult, or unwanted. Designing sonifications often requires knowledge in multiple areas as well as an understanding of how the end users will use the system. This makes it an ideal candidate for end-user development where the user plays a role in the creation of the design. We present a model for sonification that utilizes user-specified examples and data to generate cross-domain mappings from data to sound. As a novel contribution we utilize soundscapes (acoustic scenes) for these user-selected examples to define a structure for the sonification. We demonstrate a proof of concept of our model using sound examples and discuss how we plan to build on this work in the future.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {97–100},
numpages = {4},
keywords = {cross-domain mappings, soundscapes, end-user development, mutltimedia uis, hci},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732159,
author = {Rao, Huaming},
title = {Towards a Crowd-Based Picture Schematization System},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732159},
doi = {10.1145/2732158.2732159},
abstract = {Picture schematization has shown to be a very important step for a wide range of applications and remains challenging as an active research area. Many automation methods have been proposed to solve this problem but yet far from expectation. Since crowdsourcing has been successfully applied to fill the gap that AI can not reach yet, we are interested to explore how crowdsourcing can be utilized into this area. This paper briefly summarizes our recent efforts towards building a feasible crowd-based system to schematise pictures in a reliable and cost-effective way.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {101–104},
numpages = {4},
keywords = {remote collaboration, picture schematization, crowdsourcing, spatial},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732160,
author = {Hoque, Enamul},
title = {Visual Text Analytics for Asynchronous Online Conversations},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732160},
doi = {10.1145/2732158.2732160},
abstract = {In the last decade, there has been an exponential growth of online conversations thanks to the rise of social media. Analyzing and gaining insights from such conversations can be quite challenging for a user, especially when the discussions become very long. During my doctoral research, I aim to investigate how to integrate Information Visualization with Natural Language Processing techniques to better support the user's task of exploring and analyzing conversations. For this purpose, I consider the following approaches: apply design study methodology in InfoVis to uncover data and task abstractions; apply NLP methods for extracting the identified data to support those tasks; and incorporate human feedback in the text analysis process when the extracted data is noisy and/or may not match the user's mental model, and current tasks. Through a set of design studies, I aim to evaluate the effectiveness of our approaches.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {105–108},
numpages = {4},
keywords = {interactive topic modeling, asynchronous conversation, computer mediated communication, text visualization},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732161,
author = {Pollmann, Kathrin},
title = {Real-Time Emotion Detection for Neuro-Adaptive Systems},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732161},
doi = {10.1145/2732158.2732161},
abstract = {Our research explores possibilities to apply neurophysiological methods for real-time emotion detection during human-technology interaction. The present paper outlines our scientific approach, research plan and methodology.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {109–112},
numpages = {4},
keywords = {neurophysiological methods, fnirs, emotions, eeg, adaptive systems, brain-computer interface, affective computing},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732162,
author = {Trivedi, Gaurav},
title = {Clinical Text Analysis Using Interactive Natural Language Processing},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732162},
doi = {10.1145/2732158.2732162},
abstract = {Natural Language Processing (NLP) systems are typically developed by informaticists skilled in machine learning techniques that are unfamiliar to end-users. Although NLP has been widely used in extracting information from clinical text, current systems generally do not provide any provisions for incorporating feedback and revising models based on input from domain experts. The goal of this research is to close this gap by building highly-usable tools suitable for the analysis of free text reports.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {113–116},
numpages = {4},
keywords = {interactive machine learning, visualization, electronic medical records},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732163,
author = {Irwin, Germaine},
title = {Perceptive Home Energy Interfaces: Navigating the Dynamic Household Structure},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732163},
doi = {10.1145/2732158.2732163},
abstract = {Much discussion has taken place regarding environmental sustainability, fossil fuels and other efforts to reverse the trend of global climate change. Unfortunately, individuals often choose the path of least resistance when making home energy decisions. Thus, it is imperative to consider all of the underlying causes that influence home energy consumption in an effort to build a more perceptive interface that addresses the variety of household occupant needs.This research seeks to explore the dynamic nature of household occupancy, individual comfort and situational variants that impact home energy consumption in an effort to discover critical design factors for building novel interfaces for home energy systems.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {117–120},
numpages = {4},
keywords = {guides, consumption, design, context, instructions, energy, design kit, hci},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732164,
author = {Costa, David},
title = {On-Body Interaction for Optimized Accessibility},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732164},
doi = {10.1145/2732158.2732164},
abstract = {This thesis addresses the suitability of body interaction techniques, when used by persons with different levels of visual impairment, to improve the accessibility of mobile devices. The research will focus on: understanding how on-body interaction can surpass the current accessibility levels of mobile devices, characterizing the different complexities of skin mapping for different levels of visual impairment, perceiving for what types of input tasks it is best suited, and studying how it can complement other input modalities. Results will include an on-body interaction model, and several prototypes and studies characterizing body interaction.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {121–124},
numpages = {4},
keywords = {accessibility, visual impairments, mobile devices, body interaction model},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732165,
author = {Wolf, KatieAnna E.},
title = {Assisting End Users in the Design of Sonification Systems},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732165},
doi = {10.1145/2732158.2732165},
abstract = {In my dissertation I plan to explore the design of digital systems and how we can support users in the design process. Specifically, I focus on the design of sonifications, which are the representation of data using sound. Creating the algorithm that maps data to sound is not an easy task as there are many things to consider: an individual's aesthetic preferences, multiple dimensions of sound, complexities of the data to be represented, and previously developed theories for how to convey information using sound. This makes it an ideal domain for end-user development and data-driven design creation.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {125–128},
numpages = {4},
keywords = {end-user development, mutlimedia uis, sonification, hci, soundscapes, cross-domain mappings},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732166,
author = {Guo, Xuan},
title = {Multimodal Interactive Machine Learning for User Understanding},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732166},
doi = {10.1145/2732158.2732166},
abstract = {Designing intelligent computer interfaces requires human intelligence, which can be captured through multimodal sensors during human-computer interactions. These data modalities may involve users' language, vision, and body signals, which shed light on different aspects of human cognition and behaviors. I propose to integrate multimodal data to more effectively understand users during interactions. Since users' manipulation of big data (e.g., texts, images, videos) through interfaces can be computationally intensive, an interactive machine learning framework will be constructed in an unsupervised manner.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {129–132},
numpages = {4},
keywords = {interactive machine learning, multimodal data fusion, unsupervised knowledge discovery},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732167,
author = {Zheng, Yong},
title = {A Revisit to The Identification of Contexts in Recommender Systems},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732167},
doi = {10.1145/2732158.2732167},
abstract = {In contrast to traditional recommender systems (RS), context-aware recommender systems (CARS) emerged to adapt to users' preferences in various contextual situations. During those years, different context-aware recommendation algorithms have been developed and they are able to demonstrate the effectiveness of CARS. However, this field has yet to agree on the definition of context, where researchers may incorporate diversified variables (e.g., user profiles or item features), which further creates confusions between content-based RS and context-based RS, and positions the problem of context identification in CARS. In this paper, we revisit the definition of contexts in recommender systems, and propose a context identification framework to clarify the preliminary selection of contextual variables, which may further assist interpretation of contextual effects in RS.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {133–136},
numpages = {4},
keywords = {context-aware recommendation, contextual, context},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732168,
author = {Cunha, Marcio},
title = {AmbLEDs: Context-Aware I/O for AAL Systems},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732168},
doi = {10.1145/2732158.2732168},
abstract = {Ambient Assisted Living (AAL) applications aim to allow elderly, sick and disabled people to stay safely at home while collaboratively assisted by their family, friends and medical staff. In principle, AAL amalgamated with Internet of Things (IoT) introduces a new healthcare connectivity paradigm that interconnects mobile apps and sensors allowing constant monitoring of the patient. By hiding technology into light fixtures, in this thesis proposal we present AmbLEDs, a ambient light sensing system, as an alternative to spreading sensors that are perceived as invasive, such as cameras, microphones, microcontrollers, tags or wearables, in order to create a crowdware ubiquitous context-aware interface for recognizing, informing and alerting home environmental changes and human activities to support continuous proactive care.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {137–140},
numpages = {4},
keywords = {collective intelligence, smart light, internet of things, collaborative systems, ambient assisted living, crowdware},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732169,
author = {Dey, Sanorita},
title = {Know Your Surroundings with an Interactive Map},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732169},
doi = {10.1145/2732158.2732169},
abstract = {The advancement of mobile technology inspired research communities to achieve centimeter level accuracy in indoor positioning systems [2]. But to get the best out of it, we need assisting navigation applications that will not only help us to reach the destination quickly but will also make us familiar with the surroundings. To address this concern, we propose a two stage approach which can help pedestrians navigate in an indoor location and simultaneously enhance their spatial awareness. In the first stage, we will conduct a behavioral user study to identify the prominent behavioral patterns during different navigational challenges. Once the behavioral state model is prepared, we need to analyze the sensor data in multiple dimensions and build a dynamic sensor state model. This model will enable us to map the behavioral state model to the sensor states and draw a direct one to one relation between the two.},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {141–144},
numpages = {4},
keywords = {navigation applications, sensors, behavioral state model, spatial knowledge},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

@inproceedings{10.1145/2732158.2732170,
author = {Jung, Hee-Tae},
title = {Extended Virtual Presence of Therapists through Home Service Robots},
year = {2015},
isbn = {9781450333085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2732158.2732170},
doi = {10.1145/2732158.2732170},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
pages = {145–148},
numpages = {4},
keywords = {latent dirichlet allocation, robot-mediated therapy, programming by demonstration, customized therapy, learning from demonstration},
location = {Atlanta, Georgia, USA},
series = {IUI Companion '15}
}

