@inproceedings{10.1145/2451176.2451178,
author = {Dostal, Jakub},
title = {Designing Context-Aware Display Ecosystems},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451178},
doi = {10.1145/2451176.2451178},
abstract = {Display ecosystems encapsulate a number of independent and/or interconnected displays and their users. We are seeing the emergence of more complex display ecosystems, whether it is due to the number of collaborators, the number of devices or displays, the complexity of the user interface or increased information flow or a combination of all of all these factors. I hypothesise that interactions within display ecologies would benefit from awareness of the computational, physiological and environmental context. This paper presents a brief overview of related work as well as the research goals, relevant methodology and current research status.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {1–4},
numpages = {4},
keywords = {subtle interaction, distance-aware, context-aware, multi-user, multi-display},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451179,
author = {Eivazi, Shahram},
title = {Measuring Situation Awareness of Micro-Neurosurgeons},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451179},
doi = {10.1145/2451176.2451179},
abstract = {Micro-neurosurgery is performed with high power microscope. The microscope provides a precise perception of operative neurosurgical anatomy. The surgery is conducted using miniaturized instruments through a small hole in the skull and spin channel. Although there are predefined routine procedures in the micro-neurosurgery, still surgeons have to maintain a high level of situation awareness (SA) to operate safely. In this paper I discuss about my PhD research that focuses on relationship between eye movement pattern and level of SA.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {5–8},
numpages = {4},
keywords = {micro-neurosurgeons, situation awareness, eye tracking},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451180,
author = {Galatas, Georgios and Makedon, Fillia},
title = {Multi-Modal Context-Awareness for Ambient Intelligence Environments},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451180},
doi = {10.1145/2451176.2451180},
abstract = {Context-awareness constitutes a fundamental attribute of a smart environment. Our research aims at advancing the context-awareness capabilities of ambient intelligence environments by combining multi-modal information from both stationary and moving sensors. The collected data enables us to perform person identification and 3-D localization and recognize activities. In addition, we explore closed-loop feedback by integrating autonomous robots interacting with the users.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {9–12},
numpages = {4},
keywords = {autonomous interactive robots, speech processing, 3-d interaction, localization, smart environments, context-awareness, multi-modal input},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451181,
author = {Gardner, Andrew and Duncan, Christian A. and Selmic, Rastko and Kanno, Jinko},
title = {Real-Time Classification of Dynamic Hand Gestures from Marker-Based Position Data},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451181},
doi = {10.1145/2451176.2451181},
abstract = {In this paper we describe plans for a dynamic hand gesture recognition system based on motion capture cameras with unlabeled markers. The intended classifier is an extension of previous work on static hand gesture recognition in the same environment. The static gestures are to form the basis of a vocabulary that will allow precise descriptions of various expressive hand gestures when combined with inferred motion and temporal data. Hidden Markov Models and dynamic time warping are expected to be useful tools in achieving this goal.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {13–16},
numpages = {4},
keywords = {dynamic time warping, hidden markov models, gesture recognition, motion capture},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451182,
author = {Huang, Yi-Ching and Wang, Chun-I and Hsu, Jane},
title = {Leveraging the Crowd for Creating Wireframe-Based Exploration of Mobile Design Pattern Gallery},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451182},
doi = {10.1145/2451176.2451182},
abstract = {The use of mobile device is becoming more popular than before. There are many designers entering the area of mobile app design and development. However, due to the limitation of the screen size and context of use, it becomes extremely difficult for non-experienced designers or developers to make a good mobile application design. This paper introduces a wireframe-based matching technique to help people seek relevant mobile UI design examples for inspirations. We leveraged the wisdom of the crowd for creating coherent mappings between wireframes and design examples. Furthermore, we constructed a mobile UI design gallery for designers to explore inspiring examples in the wireframing stage.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {17–20},
numpages = {4},
keywords = {design, crowdsourcing, mobile design, wireframe, examples},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451183,
author = {Mancilla-Caceres, Juan F. and Amir, Eyal and Espelage, Dorothy},
title = {Adaptive Game for Reducing Aggressive Behavior},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451183},
doi = {10.1145/2451176.2451183},
abstract = {Peer influence in social networks has long been recognized as one of the key factors in many of the social health issues that affect young people. In order to study peer networks, scientists have relied on the use of self-report surveys that impose limitations on the types of issues than can be studied. On the other hand, the ever increasing use of computers for communication has given rise to new ways of studying group dynamics and, even more importantly, it has enabled a new way to affect those dynamics as they are detected. Our work is focused on designing and analyzing computer social games that can be used as data collection tools for social interactions, and that can also react and change accordingly in order to promote prosocial, rather than aggressive, behavior.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {21–24},
numpages = {4},
keywords = {bullying detection, games with a purpose, computational social science},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451184,
author = {Mezhoudi, Nesrine},
title = {User Interface Adaptation Based on User Feedback and Machine Learning},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451184},
doi = {10.1145/2451176.2451184},
abstract = {With the growing need for intelligent software, exploring the potential of Machine Learning (ML) algorithms for User Interface (UI) adaptation becomes an ultimate requirement. The work reported in this paper aims at enhancing the UI interaction by using a Rule Management Engine (RME) in order to handle a training phase for personalization. This phase is intended to teach to the system novel adaptation strategies based on the end-user feedback concerning his interaction (history, preferences...). The goal is also to ensure an adaptation learning by capitalizing on the user feedbacks via a promoting/demoting technique, and then to employ it later in different levels of the UI development.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {25–28},
numpages = {4},
keywords = {user interfaces, adaptation based on machine learning algorithms},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451185,
author = {Papangelis, Alexandros and Karkaletsis, Vangelis and Huang, Heng},
title = {Towards Adaptive Dialogue Systems for Assistive Living Environments},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451185},
doi = {10.1145/2451176.2451185},
abstract = {Adaptive Dialogue Systems can be seen as smart interfaces that typically use natural language (spoken or written) as a means of communication. They are being used in many applications, such as customer service, in-car interfaces, even in rehabilitation, and therefore it is essential that these systems are robust, scalable and quickly adaptable in order to cope with changing user or system needs or environmental conditions. Making Dialogue Systems adaptive means overcoming several challenges, such as scalability or lack of training data. Achieving adaptation online has thus been an even greater challenge. We propose to build such a system, that will operate in an Assistive Living Environment and provide its services as a coach to patients that need to perform rehabilitative exercises. We are currently in the process of developing it, using Robot Operating System on a robotic platform.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {29–32},
numpages = {4},
keywords = {reinforcement learning, personalization, adaptive dialogue systems, dialogue management},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451186,
author = {Seyed, Teddy and Burns, Chris and Costa Sousa, Mario and Maurer, Frank},
title = {From Small Screens to Big Displays: Understanding Interaction in Multi-Display Environments},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451186},
doi = {10.1145/2451176.2451186},
abstract = {Devices such as tablets, mobile phones, tabletops and wall displays all incorporate different sizes of screens, and are now commonplace in a variety of situations and environments. Environments that incorporate these devices, multi-display environments (MDEs) are highly interactive and innovative, but the interaction in these environments is not well understood. The research presented here investigates and explores interaction and users in MDEs. This exploration tries to understand the conceptual models of MDEs for users and then examine and validate interaction approaches that can be done to make them more usable. In addition to a brief literature review, the methodology, research goals and current research status are presented.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {33–36},
numpages = {4},
keywords = {mobile-devices, multi-display interaction, cross-device interaction, multi-display environments, multi-surface environments, touch, tabletop},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451187,
author = {Vrzakova, Hana},
title = {Computational Approaches to Visual Attention for Interaction Inference},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451187},
doi = {10.1145/2451176.2451187},
abstract = {Many aspects of interaction are hard to directly observe and measure. My research focuses on particular aspects of UX such as cognitive workload, problem solving or engagement, and establishes computational links between them and visual attention. Using machine learning and pattern recognition techniques, I aim to achieve automatic inferences for HCI and employ them as enhancements in gaze-aware interfaces.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {37–40},
numpages = {4},
keywords = {interaction inference, machine learning, eye-tracking},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451189,
author = {Pappu, Aasish and Rudnicky, Alexander},
title = {Deploying Speech Interfaces to the Masses},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451189},
doi = {10.1145/2451176.2451189},
abstract = {Speech systems are typically deployed either over phones, e.g. IVR agents, or on embodied agents, e.g. domestic robots. Most of these systems are limited to a particular platform i.e., only accessible by phone or in situated interactions. This limits scalability and potential domain of operation. Our goal is to make speech interfaces more widely available, and we are proposing a new approach for deploying such interfaces on the internet along with traditional platforms. In this work, we describe a lightweight speech interface architecture built on top of Freeswitch, an open source softswitch platform. A softswitch enables us to provide users with access over several types of channels (phone, VOIP, etc.) as well as support multiple users at the same time. We demonstrate two dialog applications developed using this approach: 1) Virtual Chauffeur: a voice based virtual driving experience and 2) Talkie: a speech-based chat bot.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {41–42},
numpages = {2},
keywords = {phone apps, speech interfaces, web apps, voip apps},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451190,
author = {Denoue, Laurent and Carter, Scott and Cooper, Matthew and Adcock, John},
title = {Real-Time Direct Manipulation of Screen-Based Videos},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451190},
doi = {10.1145/2451176.2451190},
abstract = {We describe direct video manipulation interactions applied to screen-based tutorials. In addition to using the video timeline, users of our system can quickly navigate into the video by mouse-wheel, double click over a rectangular region to zoom in and out, or drag a box over the video canvas to select text and scrub the video until the end of a text line even if not shown in the current frame. We describe the video processing techniques developed to implement these direct video manipulation techniques, and show how they are implemented to run in most modern web browsers using HTML5's CANVAS and Javascript.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {43–44},
numpages = {2},
keywords = {web browser, real-time, direct manipulation, video processing, html5, intelligent user interface},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451191,
author = {Gou, Liang and Mahmud, Jalal and Haber, Eben and Zhou, Michelle},
title = {PersonalityViz: A Visualization Tool to Analyze People's Personality with Social Media},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451191},
doi = {10.1145/2451176.2451191},
abstract = {This paper presents an interactive visualization tool, PersonalityViz, to help people understand their personality traits derived from social media. The system uses the Linguistic Inquiry and Word Count (LIWC) text analysis tool and LIWC/Big Five personality correlations to compute a person's Big Five personality from one's tweets. It provides an interactive visual interface that allows a user to explore her personality traits over time, and examine the visual evidence to understand how the personality traits are derived from the relevant tweets.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {45–46},
numpages = {2},
keywords = {personality, social media, big five, personality changes, visualization},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451192,
author = {Shirokura, Takumi and Munekata, Nagisa and Ono, Tetsuo},
title = {E3-Player: Emotional Excitement Enhancing Video Player Using Skin Conductance Response},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451192},
doi = {10.1145/2451176.2451192},
abstract = {We developed E3-player, a novel video player with three operation modes which enhances video experiences by using a user's physiological inputs. This system's purpose is to enhance the emotional excitement of the users by reinforcing their response to the videos they are watching. Users who use the E3-player need only to attach a physiological sensor to their own hand and wearing noise-cancelling headphones. Through our experiments, we ensure that the E3-player can indeed enhance video experience and provide new video experiences for viewers.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {47–48},
numpages = {2},
keywords = {physiological input, skin conductance response, video player, entertainment computing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451193,
author = {Leidinger, Tobias and Spassova, L\"{u}bomira and Arens, Andreas and R\"{o}sch, Norbert},
title = {MoFIS: A Mobile User Interface for Semi-Automatic Extraction of Food Product Ingredient Lists},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451193},
doi = {10.1145/2451176.2451193},
abstract = {The availability of food ingredient information in digital form is a major factor in modern information systems related to diet management and health issues. Although ingredient information is printed on food product labels, corresponding digital data is rarely available for the public. In this demo, we present the Mobile Food Information Scanner (MoFIS), a mobile user interface designed to enable users to semi-automatically extract ingredient lists from food product packaging.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {49–50},
numpages = {2},
keywords = {information extraction, mobile user interface},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451194,
author = {Adams, Rachel and Kuntz, Alex and Marks, Morgan and Martin, William and Musicant, David},
title = {Keeping Wiki Content Current via News Sources},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451194},
doi = {10.1145/2451176.2451194},
abstract = {Online resources known as wikis are commonly used for collection and distribution of information. We present a software implementation that assists wiki contributors with the task of keeping a wiki current. Our demonstration, built using English Wikipedia, enables wiki contributors to subscribe to sources of news, based on which it makes intelligent recommendations for pages within Wikipedia where the new content should be added. This tool is also potentially useful for helping new Wikipedia editors find material to contribute.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {51–52},
numpages = {2},
keywords = {recommendations, workflow, wiki, news feeds},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451195,
author = {Lee, Ahyun and Suh, Jeong Dae and Lee, Joo-Haeng},
title = {Interactive Design of Planar Curves Based on Spatial Augmented Reality},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451195},
doi = {10.1145/2451176.2451195},
abstract = {In this paper, we introduce an interactive application for planar curve design in a real world based on spatial augmented reality (SAR). The key component is a projector-camera unit that recognizes physical control objects (i.e., key points of an intended curve) using a camera and displays a design result (i.e., a B-spline curve) directly on the real world surface using a projector. Usually, geometric design is performed with the aid of CAD software and traditional user interfaces of a computer system. The main contribution of this paper is application of spatial augmented reality techniques in the domain of computer-aided geometric design (CAGD) for more tangible and intuitive interaction in a real world. We describe the feature of the prototype system and demonstrate the working application with examples.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {53–54},
numpages = {2},
keywords = {spatial augmented reality (sar), cagd, projector-camera system, tangible interaction, calibration},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451196,
author = {\"{O}zbal, G\"{u}zde and Strapparava, Carlo},
title = {Namelette: A Tasteful Supporter for Creative Naming},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451196},
doi = {10.1145/2451176.2451196},
abstract = {In this paper, we introduce a system that supports the naming process by exploiting natural language processing and linguistic creativity techniques in a completely unsupervised fashion. The system generates two types of neologisms based on the category of the service to be named and the properties to be underlined. While the first type consists of homophonic puns and metaphors, the second consists of neologisms that are produced by adding Latin suffixes to English words or homophonic puns. During this process, both semantic appropriateness and sound pleasantness of the generated names are taken into account.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {55–56},
numpages = {2},
keywords = {branding, computational creativity, natural language processing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451197,
author = {Ahmed, Zeeshan and Steiner, Ingmar and Sz\'{e}kely, \'{E}va and Carson-Berndsen, Julie},
title = {A System for Facial Expression-Based Affective Speech Translation},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451197},
doi = {10.1145/2451176.2451197},
abstract = {In the emerging field of speech-to-speech translation, emphasis is currently placed on the linguistic content, while the significance of paralinguistic information conveyed by facial expression or tone of voice is typically neglected. We present a prototype system for multimodal speech-to-speech translation that is able to automatically recognize and translate spoken utterances from one language into another, with the output rendered by a speech synthesis system. The novelty of our system lies in the technique of generating the synthetic speech output in one of several expressive styles that is automatically determined using a camera to analyze the user's facial expression during speech.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {57–58},
numpages = {2},
keywords = {video analysis, multi-modal interfaces, emotion and affective user interface, speech i/o},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451198,
author = {Nov\'{a}\v{c}ek, V\'{\i}t and Burns, Gully},
title = {SKIMMR: Machine-Aided Skim-Reading},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451198},
doi = {10.1145/2451176.2451198},
abstract = {Unlike full reading, 'skim-reading' involves the process of looking quickly over information in an attempt to cover more material whilst still being able to retain a superficial view of the underlying content. Within this work, we specifically emulate this natural human activity by providing a dynamic graph-based view of entities automatically extracted from text using superficial text parsing / processing techniques. We provide a preliminary web-based tool (called 'SKIMMR') that generates a network of inter-related concepts from a set of documents. In SKIMMR, a user may browse the network to investigate the lexically-driven information space extracted from the documents. When a particular area of that space looks interesting to a user, the tool can then display the documents that are most relevant to the displayed concepts. We present this as a simple, viable methodology for browsing a document collection (such as a collection scientific research articles) in an attempt to limit the information overload of examining that document collection. This paper presents a motivation and overview of the approach, outlines technical details of the preliminary SKIMMR implementation, describes the tool from the user's perspective and summarises the related work.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {59–60},
numpages = {2},
keywords = {text mining, distributional semantics, knowledge extraction, information visualisation},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451199,
author = {G\l{}owacka, Dorota and Ruotsalo, Tuukka and Konyushkova, Ksenia and Athukorala, Kumaripaba and Kaski, Samuel and Jacucci, Giulio},
title = {SciNet: A System for Browsing Scientific Literature through Keyword Manipulation},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451199},
doi = {10.1145/2451176.2451199},
abstract = {Techniques for both exploratory and known item search tend to direct only to more specific subtopics or individual documents, as opposed to allowing directing the exploration of the information space. We present SciNet, an interactive information retrieval system that combines Reinforcement Learning techniques along with a novel user interface design to allow active engagement of users in directing the search. Users can directly manipulate document features (keywords) to indicate their interests and Reinforcement Learning is used to model the user by allowing the system to trade off between exploration and exploitation. This gives users the opportunity to more effectively direct their search.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {61–62},
numpages = {2},
keywords = {recommender/filtering systems, information retrieval, datamining and machine learning, adaptive interfaces},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451200,
author = {Ehlen, Patrick and Johnston, Michael},
title = {A Multimodal Dialogue Interface for Mobile Local Search},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451200},
doi = {10.1145/2451176.2451200},
abstract = {Speak4itSM uses a multimodal interface to perform mobile search for local businesses. Users combine simultaneous speech and touch to input queries or commands, for example, by saying, "gas stations", while tracing a route on a touchscreen. This demonstration will exhibit an extension of our multimodal semantic processing architecture from a one-shot query system to a multimodal dialogue system that tracks dialogue state over multiple turns and resolves prior context using unification-based context resolution. We illustrate the capabilities and limitations of this approach to multimodal interpretation, describing the challenges of supporting true multimodal interaction in a deployed mobile service, while offering an interactive demonstration on tablets and smartphones.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {63–64},
numpages = {2},
keywords = {search, multimodal interfaces, dialog},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451201,
author = {Knox, W. Bradley and Stone, Peter and Breazeal, Cynthia},
title = {Teaching Agents with Human Feedback: A Demonstration of the TAMER Framework},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451201},
doi = {10.1145/2451176.2451201},
abstract = {Incorporating human interaction into agent learning yields two crucial benefits. First, human knowledge can greatly improve the speed and final result of learning compared to pure trial-and-error approaches like reinforcement learning. And second, human users are empowered to designate "correct" behavior. In this abstract, we present research on a system for learning from human interaction - the TAMER framework - then point to extensions to TAMER, and finally describe a demonstration of these systems.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {65–66},
numpages = {2},
keywords = {modeling and prediction of user behavior, interactive machine learning, human-agent interaction, end-user programming, reinforcement learning},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451202,
author = {Khayyamian, Mahdy and Kim, Jihie},
title = {An Intelligent Web-Based Interface for Programming Content Detection in Q&amp;a Forums},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451202},
doi = {10.1145/2451176.2451202},
abstract = {In this demonstration, we introduce a novel web-based intelligent interface which automatically detects and highlights programming content (programming code and messages) in Q&amp;A programming forums. We expect our interface helps enhancing visual presentation of such forum content and enhance effective participation.We solve this problem using several alternative approaches: a dictionary-based baseline method, a non-sequential Na\"{\i}ve Bayes classification algorithm, and Conditional Random Fields (CRF) which is a sequential labeling framework. The best results are produced by CRF method with an F1-Score of 86.9%.We also experimentally validate how robust our classifier is by testing the constructed CRF model built on a C++ forum against a Python and a Java dataset. The results indicate the classifier works quite well across different domains.To demonstrate detection results, a web-based graphical user interface is developed that accepts a user input programming forum message and processes it using trained CRF model and then displays the programming content snippets in a different font to the user.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {67–68},
numpages = {2},
keywords = {q&amp;a forums, text classification, conditional random fields, web-based intelligent interface},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451204,
author = {Mahmud, Jalal},
title = {Improving Rich Internet Application Development Using Patterns},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451204},
doi = {10.1145/2451176.2451204},
abstract = {With changes of customer requirements, web development, especially developing Rich Internet Applications (RIA) with complex widgets and data-driven behavior can be a time-consuming task. In our previous work [3], we have presented a test-driven web development approach using ClearScript test cases as requirements to automatically generate widgets, and thus reduce the barrier of web development and testing. We extend on this work, and develop a machine learning based algorithm to identify RIA patterns [1] from requirements specified as test cases, and automatically instantiate them using simple rules. We also present performance of our algorithm and a user study which demonstrates the viability of our approach.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {69–70},
numpages = {2},
keywords = {data driven, ria, pattern detection},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451205,
author = {Hagiya, Toshiyuki and Kato, Tsuneo},
title = {Adaptable Probabilistic Flick Keyboard Based on HMMs},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451205},
doi = {10.1145/2451176.2451205},
abstract = {To provide an accurate and user-adaptable software keyboard for touchscreens, we propose a probabilistic flick keyboard based on HMMs. This keyboard can reduce the input error by taking the time series of the actual touch position into consideration and by user adaptation. We evaluated performance of the HMM-based flick keyboard and MLLR adaptation. Experimental results showed that a user-dependent model reduced the error rate by 28.2%. In a practical setting, MLLR user adaptation with only 10 words reduced the error rate by 16.5% and increased typing speed by 10.5%.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {71–72},
numpages = {2},
keywords = {input technologies, handheld devices, personalization},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451206,
author = {Hwang, Sungjae and Wohn, Kwangyun},
title = {VibroTactor: Low-Cost Placement-Aware Technique Using Vibration Echoes on Mobile Devices},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451206},
doi = {10.1145/2451176.2451206},
abstract = {In this paper, we present a low-cost placement-aware technique, called VibroTactor, which allows mobile devices to determine where they are placed (e.g., in a pocket, on a phone holder, on the bed, or on the desk). This is achieved by filtering and analyzing the acoustic signal generated when the mobile device vibrates. The advantage of this technique is that it is inexpensive and easy to deploy because it uses a microphone, which already embedded in standard mobile devices. To verify this idea, we implemented a prototype and conducted a preliminary test. The results show that this system achieves an average success rate of 91% in 12 different real-world placement sets.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {73–74},
numpages = {2},
keywords = {pattern recognition, pseudo sensor, context-aware, vibration echoes, placement detection, sensor repurposing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451207,
author = {Hwang, Sungjae and Ahn, Myungwook and Wohn, Kwangyun},
title = {Magnetic Marionette: Magnetically Driven Elastic Controller on Mobile Device},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451207},
doi = {10.1145/2451176.2451207},
abstract = {In this paper, we present the Magnetic Marionette, a magnetically driven elastic controller that enables tangible interaction on mobile devices. This technique can determine eight different gestures in excess of 99% accuracy by sensing and tracking the magnets embedded on the controller. The advantage of this technique is that it is lightweight, battery-free, and inexpensive because it uses a magnetometer, which is already embedded in smart phones today. This simple and noble technique allows users to achieve richer tactile feedback, expand their interaction area, and enhance expressiveness without the need for hardware modification.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {75–76},
numpages = {2},
keywords = {pseudo sensor, magnetometer, tui, pattern recognition, tangible controller, mobile device, sensor repurposing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451208,
author = {Karasudani, Akira and Iwata, Satoshi and Matsumoto, Tatsuro and Aritake, Hirokazu},
title = {Extracting Document Relationships by Analyzing User's Activity History},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451208},
doi = {10.1145/2451176.2451208},
abstract = {In order to reduce people's workload of looking for valuable information from a large amount of available information, recommendation systems, task management systems, and so on are attracting considerable attention. Such systems are expected to allow easy access to information under the current work context. In the development of these systems, how to handle a user's current work context to know what information he wants to use is a key point. We have developed a novel method to extract relationships among documents as the work context by analyzing the user's activity history according to several viewpoints of a human being who memorizes and seeks information. We report the details of the proposed method, the evaluation result, and an application example.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {77–78},
numpages = {2},
keywords = {activity history, relationships between documents},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451209,
author = {Picard, S\'{e}bastien and Yu, Shanshan and Nakashima, Satoshi},
title = {Eye Corner Detector Robust to Shape and Illumination Changes},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451209},
doi = {10.1145/2451176.2451209},
abstract = {We introduce a robust and accurate eye corner detector. The purpose of this technology is to improve the robustness of natural user interfaces' inputs, such as eye movements, in real-life environments for various users. Our technology relies on the pupil centers and particularly the inter-pupil direction, to define simple features capturing the structural characteristics of the eye corners independently of the shape and appearance of their neighborhoods. Our method proved to be robust to different lighting environments, eye shapes and different patterns of reflection on glasses. We report an error below 2% of the inter-pupil distance for 98% of the images, and maintain processing time below 3ms for computation on both eyes.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {79–80},
numpages = {2},
keywords = {detector, eye corners, robustness},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451210,
author = {Shen, Jianqiang and Brdiczka, Oliver and Liu, Juan and Suzuki, Masafumi},
title = {WhoAmi: Profiling Attendees before Meetings},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451210},
doi = {10.1145/2451176.2451210},
abstract = {Mobile phones have been widely used to access, retrieve and organize information. In this paper, we present the meshin system, an intelligent personal assistant that organizes messages, notifications and appointments for mobile phone users. To help users prepare for meetings, meshin automatically creates a profile for each meeting attendee. The meshin system searches the Internet with the attendee's name and the domain of the email address, then retrieves and aggregates information for this attendee. To get a better understanding of the attendee, it further estimates the personality profile based on the emails he/she wrote. Our experimental results show that our system can predict personality with reasonable accuracies (95%).},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {81–82},
numpages = {2},
keywords = {email, personal assistant, personality, text processing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451211,
author = {Mace, David and Gao, Wei and Coskun, Ayse},
title = {Accelerometer-Based Hand Gesture Recognition Using Feature Weighted Na\"{\i}ve Bayesian Classifiers and Dynamic Time Warping},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451211},
doi = {10.1145/2451176.2451211},
abstract = {Accelerometer-based gesture recognition is a major area of interest in human-computer interaction. In this paper, we compare two approaches: na\"{\i}ve Bayesian classification with feature separability weighting [1] and dynamic time warping [2]. Algorithms based on these two approaches are introduced and the results are compared. We evaluate both algorithms with four gesture types and five samples from five different people. The gesture identification accuracy for Bayesian classification and dynamic time warping are 97% and 95%, respectively.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {83–84},
numpages = {2},
keywords = {feature separability weighting, accelerometer, dynamic time warping, gesture recognition;, bayesian classifier},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451212,
author = {Kuwabara, Chihiro and Yamamoto, Keiko and Kuramoto, Itaru and Tsujino, Yoshihiro and Minakuchi, Mitsuru},
title = {Ghost-Hunting: A Cursor-Based Pointing Technique with Picture Guide Indication of the Shortest Path},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451212},
doi = {10.1145/2451176.2451212},
abstract = {Ghost-Hunting (GH) is a new technique that improves pointing performance in a graphical user interface (GUI) by expanding targets to facilitate easier access. In GH, the effect of decreasing the movement distance of a cursor by expanding the size of onscreen targets is utilized to improve the GUI. GH shows the guides of the end point of the shortest movement path, called ghosts, inside expanded target areas. Users can optimize their cursor movements by only moving their cursor towards the ghosts in GH, unlike other techniques that use the invisible outline of an expanded target such as with Bubble Cursor. We conduct an experimental evaluation to clarify the effectiveness of GH in menu-item selection tasks. The result shows that GH's selection time was significantly faster than that of the ordinal cursor or Bubble Cursor. In particular, GH is faster than Bubble Cursor in environments with a high density of targets.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {85–86},
numpages = {2},
keywords = {target acquisition, bubble cursor, area cursor, ghost-hunting, voronoi diagram, pointing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451213,
author = {Alexenko, Tatiana and Biondo, Megan and Banisakher, Deya and Skubic, Marjorie},
title = {Android-Based Speech Processing for Eldercare Robotics},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451213},
doi = {10.1145/2451176.2451213},
abstract = {A growing elderly population has created a need for innovative eldercare technologies. The use of a home robot to assist with daily tasks is one such example. In this paper we describe an interface for human-robot interaction, which uses built-in speech recognition in Android phones to control a mobile robot. We discuss benefits of using a smartphone for speech-based robot control and present speech recognition accuracy results for younger and older adults obtained with an Android smartphone.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {87–88},
numpages = {2},
keywords = {older adults, user study, human-robot interaction, speech recognition, eldercare, smartphones, android, robotics},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451214,
author = {O'Banion, Shawn and Birnbaum, Larry and Bradley, Scott},
title = {Finding the Local Angle in National News},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451214},
doi = {10.1145/2451176.2451214},
abstract = {Journalists often localize news stories that are not explicitly about the community they serve by investigating and describing how those stories affect that community. This is, in essence, a form of personalization based not on a reader's personal interests, but rather on their ties to a geographic location. In this paper we present The Local Angle, an approach for automating the process of finding national and international news stories that are locally relevant. The Local Angle associates the people, companies, and organizations mentioned in news stories with geographic locations using semantic analysis tools and online knowledge bases. We describe the design and implementation of our prototype system that helps content curators and consumers discover articles that are of local interest even if they do not originate locally.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {89–90},
numpages = {2},
keywords = {local news, recommendation system, personalization},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451215,
author = {Kim, Kyung Soo and Choi, Yong Suk},
title = {Computerized Adaptive Testing and Learning Using Bayesian Network},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451215},
doi = {10.1145/2451176.2451215},
abstract = {In this paper, we propose a novel CAT (Computerized Adaptive Testing) system based on Bayesian network. Our novel system makes good use of topology and probabilistic inference algorithm of Bayesian network to efficiently estimate proficiency of learner and also give an adaptive learning guide when needed. From several experiments, we identified that our system could considerably improve proficiency-estimation performance when compared with conventional CAT methods.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {91–92},
numpages = {2},
keywords = {computerized adaptive testing, adaptive learning guide, bayesian network},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451216,
author = {Kahl, Gerrit},
title = {A Visual Monitoring and Management Tool for Smart Environments},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451216},
doi = {10.1145/2451176.2451216},
abstract = {Smart spaces are equipped with a large number of sensors and actuators. Data measured by the sensors is sent to respective services, which can react on them and control actuators correspondingly. In order to improve the services and make them smarter, they can communicate with each other and exchange data. The more interferences between the services exist, the more complex is the monitoring and extension of such smart spaces. In this paper, we propose a monitoring tool for these environments, which consists of a real and a virtual component. The real component is the physical smart space itself and the virtual one consists of a three-dimensional model of the space. Sensor information is transmitted from the real to the virtual component and represented there, via an appropriate visualization. Additionally, the tool offers a communication channel from the virtual component to the real counterpart to control the physical actuators.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {93–94},
numpages = {2},
keywords = {dual reality, monitoring tool, smart spaces},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451217,
author = {Shin, Sangjin and Ko, Jihoon and Shin, Dong-Hoon and Jung, Jooik and Lee, Kyong-Ho},
title = {Semantic Search for Smart Mobile Devices},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451217},
doi = {10.1145/2451176.2451217},
abstract = {To enhance the incorrectness of keyword based search, we propose an efficient semantic search method based on a lightweight mobile ontology designed for smart mobile devices. In addition, we implement a prototype of semantic search engine working on Android smartphones and our prototype engine provides better user experience compared with keyword based search.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {95–96},
numpages = {2},
keywords = {semantic search, smart phone, mobile ontology},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451218,
author = {Schulz, Christian and Sonntag, Daniel and Weber, Markus and Toyama, Takumi},
title = {Multimodal Interaction Strategies in a Multi-Device Environment around Natural Speech},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451218},
doi = {10.1145/2451176.2451218},
abstract = {In this paper we present an intelligent user interface which combines a speech-based interface with several other input modalities. The integration of multiple devices into a working environment should provide greater flexibility to the daily routine of medical experts for example. To this end, we will introduce a medical cyber-physical system that demonstrates the use of a bidirectional connection between a speech-based interface and a head-mounted see-through display. We will show examples of how we can exploit multiple input modalities and thus increase the usability of a speech-based interaction system.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {97–98},
numpages = {2},
keywords = {natural language processing, medical healthcare, interaction design, multimodal interaction, pervasive computing},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451219,
author = {Bourke, Steven and O'Mahony, Michael and Rafter, Rachael and Smyth, Barry},
title = {Ranking in Information Streams},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451219},
doi = {10.1145/2451176.2451219},
abstract = {Information streams allow social network users to receive and interact with the latest messages from friends and followers. But as our social graphs grow and mature it becomes increasingly difficult to deal with the information overload that these realtime streams introduce. Some social networks, like Facebook, use proprietary interestingness metrics to rank messages in an effort to improve stream relevance and drive engagement. In this paper we evaluate learning to rank approaches to rank content based on a variety of features taken from live-user data.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {99–100},
numpages = {2},
keywords = {social recommendation, facebook, social streams, information stream;, learning to rank},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451220,
author = {Tamura, Ayano and Okada, Shogo and Nitta, Katsumi and Harada, Tetsuya and Sato, Makoto},
title = {HAPPIcom: Haptic Pad for Impressive Text Communication},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451220},
doi = {10.1145/2451176.2451220},
abstract = {We propose a system called Haptic Pad for Impressive Text Communication for creating text messages with haptic stimuli using the SPIDAR-tablet haptic interface. This system helps users indicate emotion in text messages and actions of characters in storytelling by attaching physical feedback to words in text. We evaluated the effectiveness of the system experimentally in two scenarios: storytelling and text messaging. We found that effective use of haptic stimuli depends on each situation and participant.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {101–102},
numpages = {2},
keywords = {touch panel, e-mail application, haptics, text messaging, affect, haptic interface, communication},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451221,
author = {Wu, Shuguang and Xiao, Jun and Reily, Ken},
title = {PhotoAct: Act on Photo Taking},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451221},
doi = {10.1145/2451176.2451221},
abstract = {In many commercial environments understanding the user's intention can lead to more engaging and intelligent user interactions. We looked at theme park photo kiosks where many people use their camera phones to capture their ride photos on preview displays. We believe that by identifying people with photo-taking intention and engaging them through intelligent UI can help reduce the instances of people opting for low quality but free screen capture. We built a prototype system called PhotoAct, using depth camera to recognize human postures and in real time infer people's photo-taking intentions. In this paper, we describe the system components, the detection algorithm, and present preliminary lab study results.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {103–104},
numpages = {2},
keywords = {camera detection, photoware, posture analysis},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451222,
author = {Perakakis, Manolis and Potamianos, Alexandros},
title = {An Affective Evaluation Tool Using Brain Signals},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451222},
doi = {10.1145/2451176.2451222},
abstract = {We propose a new interface evaluation tool that incorporates affective metrics which are provided from the ElectroEncephaloGraphy (EEG) signals of the Emotiv EPOC neuro-headset device. The evaluation tool captures and analyzes information in real time from a multitude of sources such as EEG, affective metrics such as frustration, engagement and excitement and facial expression. The proposed tool has been used to gain detailed affective information of users interacting with a mobile multimodal (touch and speech) iPhone application, for which we investigated the effect of speech recognition errors and modality usage patterns.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {105–106},
numpages = {2},
keywords = {evaluation tool, iphone, usability research, affective evaluation, brain signals, eeg},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451223,
author = {Kahl, Gerrit and Paradowski, Denise},
title = {A Privacy-Aware Shopping Scenario},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451223},
doi = {10.1145/2451176.2451223},
abstract = {Providing private data is a highly controversial and widely debated topic. Not only the information about individuals but also about companies should be kept private. In order to satisfy the needs of both individuals and companies, corresponding privacy protection mechanisms have to be implemented. For example, systems which assist customers during their shopping process in a physical retail store require customer related information, such as the shopping list, allergy or bank account information as well as data from the retailer, like the product range and prices. In this paper, we introduce a concept for decoupling both information sources implemented in a shopping scenario, which amongst others allows Mobile Payment without the transmission of private data. The implemented prototype has been presented at a large fair to potential users in order to receive valuable feedback.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {107–108},
numpages = {2},
keywords = {nfc, mobile payment, smart shopping cart},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451224,
author = {Gil, Yolanda and Knight, Angela and Zhang, Kevin and Zhang, Larry and Sethi, Ricky},
title = {An Initial Analysis of Semantic Wikis},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451224},
doi = {10.1145/2451176.2451224},
abstract = {Semantic wikis augment wikis with semantic properties that can be used to aggregate and query data through reasoning. Semantic wikis are used by many communities, for widely varying purposes such as organizing genomic knowledge, coding software, and tracking environmental data. Although wikis have been analyzed extensively, there has been no published analysis of the use of semantic wikis. We carried out an initial analysis of twenty semantic wikis selected for their diverse characteristics and content. Based on the number of property edits per contributor, we identified several patterns to characterize community behaviors that are common to groups of wikis.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {109–110},
numpages = {2},
keywords = {social knowledge collection, semantic wikis, rdf, semantic web},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451225,
author = {Islam, Gazi and Li, Baoxin and Kahol, Kanav},
title = {An Affordable Real-Time Assessment System for Surgical Skill Training},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451225},
doi = {10.1145/2451176.2451225},
abstract = {This research proposes a novel computer-vision-based approach for skill assessment by observing a surgeon's hand and surgical tool movements in minimally invasive surgical training, which can be extended to the evaluation in real surgeries. Videos capturing the surgical field are analyzed using a system composed of a series of computer vision algorithms. The system automatically detects major skill measuring features from surgical task videos and provides real-time performance feedback on objective and quantitative measurement of surgical skills.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {111–112},
numpages = {2},
keywords = {skill assessment, surgical training, computer vision, feature detection},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451227,
author = {Schnelle-Walka, Dirk and Huber, Jochen and Lissermann, Roman and Brdiczka, Oliver and Luyten, Kris and M\"{u}hlh\"{a}user, Max},
title = {SmartObjects: Second Workshop on Interacting with Smart Objects},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451227},
doi = {10.1145/2451176.2451227},
abstract = {Smart objects are everyday objects that have computing capabilities and give rise to new ways of interaction with our environment. The increasing number of smart objects in our life shapes how we interact beyond the desktop. In this workshop we explore various aspects of the design, development and deployment of smart objects including how one can interact with smart objects.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {113–114},
numpages = {2},
keywords = {context-aware computing, user studies, usability testing and evaluation, input and interaction technologies, user interface design, home, multi-modal interfaces, user experience design / experience design, interaction design},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451228,
author = {Schwartz, Tim and Kahl, Gerrit and Applin, Sally A. and Dim, Eyal},
title = {IUI 2013 3rd Workshop on Location Awareness for Mixed and Dual Reality: (LAMDa'13)},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451228},
doi = {10.1145/2451176.2451228},
abstract = {This workshop explores the interactions between location awareness and Dual/Mixed/PolySocial Reality in smart (instrumented) environments and their impact on culture and society. The main scope of this workshop is to explore how a Dual/Mixed/PolySocial Reality paradigm can be used to improve applications in smart environments and, by extension, which new possibilities can be opened up by these paradigms.These may include positioning methods and location-based services using the DR paradigm, such as navigation services and group interaction services (location-based social signal processing) as well as agent based intermediaries to offset errant voluminous multiplexed communication messaging. The workshop is also open to discuss sensor and actuator technologies that are being developed to foster the growth of interaction possibilities in smart environments.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {115–118},
numpages = {4},
keywords = {polysocial reality, mixed reality, social signal processing, location-based services, dual reality, social anthropology, positioning},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451229,
author = {Agarwal, Sheetal and Rajput, Nitendra and Kodagoda, Neesha and Wong, B.L. William and Oviatt, Sharon},
title = {3rd International Workshop on Intelligent User Interfaces for Developing Regions: IUI4DR},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451229},
doi = {10.1145/2451176.2451229},
abstract = {Information Technology (IT) has had significant impact on the society and has touched all aspects of our lives. Up and until now computers and expensive devices have fueled this growth. It has resulted in several benefits to the society. The challenge now is to take this success to its next level where IT services can be accessed by users in developing regions.The first IUI4DR workshop was held at IUI 2008. This workshop focused on low cost interfaces, interfaces for illiterate people and on exploring different input mechanisms. The second workshop held at IUI 2011 focused on multimodal applications and collaborative interfaces in particular to aid effective navigation of content and access to services.So far we have concentrated on mobile devices as the primary method for people to access content and services. In particular we focused on low-end feature phones that are widely used. However the smart phone market is booming even in developing countries with touch phones available for as little as 50 USD. We want to explore how devices such as smart TVs, smart phones, and old desktop machines, radios, etc. can be used to provide novel interaction methods and interfaces for the low literate populations. We would also like to continue our focus on interaction modalities other than speech such as gestures, haptic inputs and touch interfaces. },
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {119–120},
numpages = {2},
keywords = {developing regions, interaction design, multimodal interfaces, intelligent assistants},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

@inproceedings{10.1145/2451176.2451230,
author = {Amershi, Saleema and Cakmak, Maya and Knox, W. Bradley and Kulesza, Todd and Lau, Tessa},
title = {IUI Workshop on Interactive Machine Learning},
year = {2013},
isbn = {9781450319669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451176.2451230},
doi = {10.1145/2451176.2451230},
abstract = {Many applications of Machine Learning (ML) involve interactions with humans. Humans may provide input to a learning algorithm (in the form of labels, demonstrations, corrections, rankings or evaluations) while observing its outputs (in the form of feedback, predictions or executions). Although humans are an integral part of the learning process, traditional ML systems used in these applications are agnostic to the fact that inputs/outputs are from/for humans.However, a growing community of researchers at the intersection of ML and human-computer interaction are making interaction with humans a central part of developing ML systems. These efforts include applying interaction design principles to ML systems, using human-subject testing to evaluate ML systems and inspire new methods, and changing the input and output channels of ML systems to better leverage human capabilities. With this Interactive Machine Learning (IML) workshop at IUI 2013 we aim to bring this community together to share ideas, get up-to-date on recent advances, progress towards a common framework and terminology for the field, and discuss the open questions and challenges of IML.},
booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
pages = {121–124},
numpages = {4},
keywords = {feature labeling, programming by demonstration, interactive clustering, reinforcement learning with human feedback or guidance, transparency and feedback in machine learning, end-user programming, empirical studies and computational models of human teaching, active learning, democratizing machine learning, human-in-the-loop intelligent systems},
location = {Santa Monica, California, USA},
series = {IUI '13 Companion}
}

