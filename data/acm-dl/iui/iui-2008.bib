@inproceedings{10.1145/1378773.1378775,
author = {Paulson, Brandon and Hammond, Tracy},
title = {PaleoSketch: Accurate Primitive Sketch Recognition and Beautification},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378775},
doi = {10.1145/1378773.1378775},
abstract = {Sketching is a natural form of human communication and has become an increasingly popular tool for interacting with user interfaces. In order to facilitate the integration of sketching into traditional user interfaces, we must first develop accurate ways of recognizing users' intentions while providing feedback to catch recognition problems early in the sketching process. One approach to sketch recognition has been to recognize low-level primitives and then hierarchically construct higher-level shapes based on geometric constraints defined by the user, however, current low-level recognizers only handle a few number of primitive shapes. We propose a new low-level recognition and beautification system that can recognize eight primitive shapes, as well as combinations of these primitives, with recognition rates at 98.56%. Our system also automatically generates beautified versions of these shapes to provide feedback early in the sketching process. In addition to looking at geometric perception, much of our recognition success can be attributed to two new features, along with a new ranking algorithm, which have proven to be significant in distinguishing polylines from curved segments.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {1–10},
numpages = {10},
keywords = {pen-based interfaces, sketch recognition, shape beautification, low-level processing},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378776,
author = {Hurst, Amy and Hudson, Scott E. and Mankoff, Jennifer and Trewin, Shari},
title = {Automatically Detecting Pointing Performance},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378776},
doi = {10.1145/1378773.1378776},
abstract = {Since not all persons interact with computer systems in the same way, computer systems should not interact with all individuals in the same way. This paper presents a significant step in automatically detecting characteristics of persons with a wide range of abilities based on observing their user input events. Three datasets are used to build learned statistical models on pointing data collected in a laboratory setting from individuals with varying ability to use computer pointing devices. The first dataset is used to distinguish between pointing behaviors from individuals with pointing problems vs. individuals without with 92.7% accuracy. The second is used to distinguish between pointing data from Young Adults and Adults vs. Older Adults vs. individuals with Parkinson's Disease with 91.6% accuracy. The final data set is used to predict the need for a specific adaptation based on a user's performance with 94.4% accuracy. These results suggest that it may be feasible to use such models to automatically identify computer users who would benefit from accessibility tools, and to even make specific tool recommendations.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {11–19},
numpages = {9},
keywords = {activity recognition, interaction techniques, accessibility, learned statistical models, motor impairments},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378777,
author = {Prasov, Zahar and Chai, Joyce Y.},
title = {What's in a Gaze? The Role of Eye-Gaze in Reference Resolution in Multimodal Conversational Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378777},
doi = {10.1145/1378773.1378777},
abstract = {Multimodal conversational interfaces allow users to carry a dialog with a graphical display using speech to accomplish a particular task. Motivated by previous psycholinguistic findings, we examine how eye-gaze contributes to reference resolution in such a setting. Specifically, we present an integrated probabilistic framework that combines speech and eye-gaze for reference resolution. We further examine the relationship between eye-gaze and increased domain modeling with corresponding linguistic processing. Our empirical results show that the incorporation of eye-gaze significantly improves reference resolution performance. This improvement is most dramatic when a simple domain model is used. Our results also show that minimal domain modeling combined with eye-gaze significantly outperforms complex domain modeling without eye-gaze, which indicates that eye-gaze can be used to potentially compensate a lack of domain modeling for reference resolution.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {20–29},
numpages = {10},
keywords = {eye-gaze, multimodal conversational interfaces, reference resolution},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378778,
author = {Kim, Jonghwa and Mastnik, Stephan and Andr\'{e}, Elisabeth},
title = {EMG-Based Hand Gesture Recognition for Realtime Biosignal Interfacing},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378778},
doi = {10.1145/1378773.1378778},
abstract = {In this paper the development of an electromyogram (EMG) based interface for hand gesture recognition is presented. To recognize control signs in the gestures, we used a single channel EMG sensor positioned on the inside of the forearm. In addition to common statistical features such as variance, mean value, and standard deviation, we also calculated features from the time and frequency domain including Fourier variance, region length, zerocrosses, occurrences, etc. For realizing real-time classification assuring acceptable recognition accuracy, we combined two simple linear classifiers (k-NN and Bayes) in decision level fusion. Overall, a recognition accuracy of 94% was achieved by using the combined classifier with a selected feature set. The performance of the interfacing system was evaluated through 40 test sessions with 30 subjects using an RC Car. Instead of using a remote control unit, the car was controlled by four different gestures performed with one hand. In addition, we conducted a study to investigate the controllability and ease of use of the interface and the employed gestures.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {30–39},
numpages = {10},
keywords = {biosignal analysis, electromyogram, human-computer interaction, gesture recognition, neural interfacing},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378780,
author = {Jin, Jing and Sanchez, Romeo and Maheswaran, Rajiv T. and Szekely, Pedro},
title = {VizScript: On the Creation of Efficient Visualizations for Understanding Complex Multi-Agent Systems},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378780},
doi = {10.1145/1378773.1378780},
abstract = {One of the most difficult tasks in software development is understanding the behavior of the final product. Making sure that a system behaves as users expect is a challenging endeavor. Understanding the behavior of a multi-agent system is even more challenging given the additional complexities of multi-agent problems. In this paper, we address the problem of users creating visualizations to debug and understand complex multi-agent systems. We introduce VizScript, a generic framework that expedites the process of creating such visualizations. VizScript combines a generic application instrumentation, a knowledge-base, and simple scene definitions primitives with a reasoning system, to produce an easy to use visualization platform. Using VizScript, we were able to recreate the visualizations for a complex multiagent system with an order-of-magnitude less effort than was required in a Java implementation},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {40–49},
numpages = {10},
keywords = {rule-based systems, scripting languages, multi-agent systems, software visualization},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378781,
author = {Stumpf, Simone and Sullivan, Erin and Fitzhenry, Erin and Oberst, Ian and Wong, Weng-Keen and Burnett, Margaret},
title = {Integrating Rich User Feedback into Intelligent User Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378781},
doi = {10.1145/1378773.1378781},
abstract = {The potential for machine learning systems to improve via a mutually beneficial exchange of information with users has yet to be explored in much detail. Previously, we found that users were willing to provide a generous amount of rich feedback to machine learning systems, and that the types of some of this rich feedback seem promising for assimilation by machine learning algorithms. Following up on those findings, we ran an experiment to assess the viability of incorporating real-time keyword-based feedback in initial training phases when data is limited. We found that rich feedback improved accuracy but an initial unstable period often caused large fluctuations in classifier behavior. Participants were able to give feedback by relying heavily on system communication in order to respond to changes. The results show that in order to benefit from the user's knowledge, machine learning systems must be able to absorb keyword-based rich feedback in a graceful manner and provide clear explanations of their predictions.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {50–59},
numpages = {10},
keywords = {machine learning, user feedback},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378782,
author = {Zhang, Wei and Matsumoto, Takashi and Liu, Juan and Chu, Maurice and Begole, Bo},
title = {An Intelligent Fitting Room Using Multi-Camera Perception},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378782},
doi = {10.1145/1378773.1378782},
abstract = {In this paper, we describe the architecture of the vision system for the Responsive Mirror, a novel system for retail fitting rooms that enables online social fashion comparisons in physical stores based on multi-camera perception. This vision system provides implicitly controlled real-time interaction for "self" and "social" clothing comparisons by automatically tracking user's motion as she tries on clothes. We describe the key components of the motion-tracking and clothes-recognition systems and evaluate their effectiveness against images collected during a previous user study and a dataset of images representing content from a social fashion network.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {60–69},
numpages = {10},
keywords = {computer vision, multi-camera, fashion, clothes recognition, tracking, learning, ubiquitous computing},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378784,
author = {Wen, Zhen and Zhou, Michelle. X.},
title = {An Optimization-Based Approach to Dynamic Data Transformation for Smart Visualization},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378784},
doi = {10.1145/1378773.1378784},
abstract = {We are building a smart visual dialog system that aids users in investigating large and complex data sets. Given a user's data request, we automate the generation of a visual response that is tailored to the user's context. In this paper, we focus on the problem of data transformation, which is the process of preparing the raw data (e.g., cleaning and scaling) for effective visualization. Specifically, we develop an optimization-based approach to data transformation. Compared to existing approaches, which normally focus on specific transformation techniques, our work addresses how to dynamically determine proper data transformations for a wide variety of visualization situations. As a result, our work offers two unique contributions. First, we provide a general computational framework that can dynamically derive a set of data transformations to help optimize the quality of the target visualization. Second, we provide an extensible, feature-based model to uniformly represent various data transformation operations and visualization quality metrics. Our evaluation shows that our work significantly improves visualization quality and helps users to better perform their tasks.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {70–79},
numpages = {10},
keywords = {smart graphics, automated visualization design, data transformation, information visualization},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378785,
author = {Hallett, Catalina},
title = {Multi-Modal Presentation of Medical Histories},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378785},
doi = {10.1145/1378773.1378785},
abstract = {This paper describes a visualisation architecture that integrates graphical devices and natural language in a cooperative system for navigating through complex images of medical histories. We show how the addition of automatically generated natural language can be used to improve the usability of a graphical user interface and conversely how the graphical user interface can be used to specify the content of user customizable medical reports.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {80–89},
numpages = {10},
keywords = {visualisation, natural language generation, navigation tool, electronic patient records},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378786,
author = {Nelson, Mark J. and Mateas, Michael},
title = {An Interactive Game-Design Assistant},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378786},
doi = {10.1145/1378773.1378786},
abstract = {Game-design novices increasingly hope to use game-like expression as a way to express content such as opinions and educational material. Existing game-design toolkits such as Game Maker ease the programming burden, bringing the design of small games within the technical reach of low-budget, non-expert groups. The design process itself remains a roadblock, however: It is not at all obvious how to present topics such as political viewpoints or bike safety in a way that makes use of the unique qualities of the interactive game medium. There are no tools to assist in that aspect of the game design process, and as a result virtually all expressive games come from a small number of game studios founded by experts in designing such games. We propose a game-design assistant that acts in a mixed-initiative fashion, helping the author understand the content of her design-in-progress, providing suggestions or automating the process where possible, and even offering the possibility for parts of the game to be dynamically generated at runtime in response to player interaction. We describe a prototype system that interactively helps authors define spaces of games in terms of common-sense constraints on their real-world references, provides support for them to understand and iteratively refine such spaces, and realizes specific games from the spaces as playable mobile-phone games in response to user input.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {90–98},
numpages = {9},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378787,
author = {Schrier, Evan and Dontcheva, Mira and Jacobs, Charles and Wade, Geraldine and Salesin, David},
title = {Adaptive Layout for Dynamically Aggregated Documents},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378787},
doi = {10.1145/1378773.1378787},
abstract = {We present a system for designing and displaying grid-based document designs that adapt to many different viewing conditions and content selections. Our system can display traditional, static documents, or it can assemble dynamic documents "on the fly" from many disparate sources via the Internet. Our adaptive layouts for aggregated documents are inspired by traditional newspaper design. Furthermore, our system allows documents to be interactive so that readers can customize documents as they read them. Our system builds on previous work on adaptive documents, using constraint-based templates to specify content-independent page designs. The new templates we describe are much more flexible in their ability to adapt to different types of content and viewing situations. This flexibility comes from allowing the individual components, or "elements," of the templates to be mixed and matched, according to the content being displayed. We demonstrate our system with two example applications: an interactive news reader for the New York Times, and an Internet news aggregator based on MSN Newsbot.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {99–108},
numpages = {10},
keywords = {CSS, XSL, XML, adaptive layout, grid-based layout, PDF, constraints},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378788,
author = {Perer, Adam and Shneiderman, Ben},
title = {Systematic yet Flexible Discovery: Guiding Domain Experts through Exploratory Data Analysis},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378788},
doi = {10.1145/1378773.1378788},
abstract = {During exploratory data analysis, visualizations are often useful for making sense of complex data sets. However, as data sets increase in size and complexity, static information visualizations decrease in comprehensibility. Interactive techniques can yield valuable discoveries, but current data analysis tools typically support only opportunistic exploration that may be inefficient and incomplete.We present a refined architecture that uses systematic yet flexible (SYF) design goals to guide domain expert users through complex exploration of data over days, weeks and months. The SYF system aims to support exploratory data analysis with some of the simplicity of an e-commerce check-out while providing added flexibility to pursue insights. The SYF system provides an overview of the analysis process, suggests unexplored states, allows users to annotate useful states, supports collaboration, and enables reuse of successful strategies. The affordances of the SYF system are demonstrated by integrating it into a social network analysis tool employed by social scientists and intelligence analysts. The SYF system is a tool-independent component and can be incorporated into other data analysis tools.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {109–118},
numpages = {10},
keywords = {systematic yet flexible, wizards, exploratory data analysis, guides, information visualization, social networks},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378789,
author = {Deller, Matthias and Agne, Stefan and Ebert, Achim and Dengel, Andreas and Hagen, Hans and Klein, Bertin and Bender, Michael and Bernardin, Tony and Hamann, Bernd},
title = {Managing a Document-Based Information Space},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378789},
doi = {10.1145/1378773.1378789},
abstract = {We present a novel user interface in the form of a complementary virtual environment for managing personal document archives, i.e., for document filing and retrieval. Our implementation of a spatial medium for document interaction, exploratory search and active navigation plays to the strengths of human visual information processing and further stimulates it.Our system provides a high degree of immersion so that the user readily forgets the artificiality of our environment. Three well-integrated features support this immersion: first, we enable users to interact more naturally through gestures and postures (the system can be taught custom ones); second, we exploit 3D display technology; and third, we allow users to manage arrangements (manually edited structures, as well as computer-generated semantic structures). Our ongoing evaluation indicates that even non-expert users can efficiently work with the information in a document collection and that the process can actually be enjoyable.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {119–128},
numpages = {10},
keywords = {human-centered design, multimodal interaction, immersion, interactive search, 3d user interface},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378790,
author = {Sch\"{o}ning, Johannes and Hecht, Brent and Raubal, Martin and Kr\"{u}ger, Antonio and Marsh, Meredith and Rohs, Michael},
title = {Improving Interaction with Virtual Globes through Spatial Thinking: Helping Users Ask "Why?"},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378790},
doi = {10.1145/1378773.1378790},
abstract = {Virtual globes have progressed from little-known technology to broadly popular software in a mere few years. We investigated this phenomenon through a survey and discovered that, while virtual globes are en vogue, their use is restricted to a small set of tasks so simple that they do not involve any spatial thinking. Spatial thinking requires that users ask "what is where" and "why"; the most common virtual globe tasks only include the "what". Based on the results of this survey, we have developed a multi-touch virtual globe derived from an adapted virtual globe paradigm designed to widen the potential uses of the technology by helping its users to inquire about both the "what is where" and "why" of spatial distribution. We do not seek to provide users with full GIS (geographic information system) functionality, but rather we aim to facilitate the asking and answering of simple "why" questions about general topics that appeal to a wide virtual globe user base.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {129–138},
numpages = {10},
keywords = {spatial thinking, multi-touch interaction, semantic relatedness, artificial intelligence, wall-size interfaces, Wikipedia, virtual globes},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378792,
author = {Tuchinda, Rattapoom and Szekely, Pedro and Knoblock, Craig A.},
title = {Building Mashups by Example},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378792},
doi = {10.1145/1378773.1378792},
abstract = {Creating a Mashup, a web application that integrates data from multiple web sources to provide a unique service, involves solving multiple problems, such as extracting data from multiple web sources, cleaning it, and combining it together. Existing work relies on a widget paradigm where users address those problems during a Mashup building process by selecting, customizing, and connecting widgets together. While these systems claim that their users do not have to write a single line of code, merely abstracting programming methods into widgets has several disadvantages. First, as the number of widgets increases to support more operations, locating the right widget for the task can be confusing and time consuming. Second, customizing and connecting these widgets usually requires users to understand programming concepts. In this paper, we present a Mashup building approach that (a) combines most problem areas in Mashup building into a unified interactive framework that requires no widgets, and (b) allows users with no programming background to easily create Mashups by example.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {139–148},
numpages = {10},
keywords = {Mashups, information integration, programming by demonstration},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378793,
author = {Nichols, Jeffrey and Lau, Tessa},
title = {Mobilization by Demonstration: Using Traces to Re-Author Existing Web Sites},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378793},
doi = {10.1145/1378773.1378793},
abstract = {Today's web pages provide many useful features, but unfortunately nearly all are designed first and foremost for the desktop form factor. At the same time, the number of mobile devices with different form factors and unique input and output facilities is growing substantially. The Highlight re-authoring environment addresses these problems by allowing users to start with existing sites they already use and create mobile versions that are customized to their tasks and mobile devices. This "re-authoring" is performed through a combination of demonstrating desired interactions with an existing web site and directly specifying content to be included on mobile pages. The system has been tested successfully with a variety of existing sites. A study showed that novice users were able to use the system to create useful mobile applications for sites of their own choosing.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {149–158},
numpages = {10},
keywords = {CoScripter, programming by demonstration, highlight, end-user programming, re-authoring, mobile web, Koala},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378794,
author = {Chen, Jiun-Hung and Weld, Daniel S.},
title = {Recovering from Errors during Programming by Demonstration},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378794},
doi = {10.1145/1378773.1378794},
abstract = {Many end-users wish to customize their applications, automating common tasks and routines. Unfortunately, this automation is difficult today --- users must choose between brittle macros and complex scripting languages. Programming by demonstration (PBD) offers a middle ground, allowing users to demonstrate a procedure multiple times and generalizing the requisite behavior with machine learning. Unfortunately, many PBD systems are almost as brittle as macro recorders, offering few ways for a user to control the learning process or correct the demonstrations used as training examples. This paper presents CHINLE, a system which automatically constructs PBD systems for applications based on their interface specification. The resulting PBD systems have novel interaction and visualization methods, which allow the user to easily monitor and guide the learning process, facilitating error recovery during training. CHINLE-constructed PBD systems learn procedures with conditionals and perform partial learning if the procedure is too complex to learn completely.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {159–168},
numpages = {10},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378796,
author = {Bigham, Jeffrey P. and Cavender, Anna C. and Kaminsky, Ryan S. and Prince, Craig M. and Robison, Tyler S.},
title = {Transcendence: Enabling a Personal View of the Deep Web},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378796},
doi = {10.1145/1378773.1378796},
abstract = {A wealth of structured, publicly-available information exists in the deep web but is only accessible by querying web forms. As a result, users are restricted by the interfaces provided and lack a convenient mechanism to express novel and independent extractions and queries on the underlying data. Transcendence enables personalized access to the deep web by enabling users to partially reconstruct web databases in order to perform new types of queries. From just a few examples, Transcendence helps users produce a large number of values for form input fields by using unsupervised information extraction and collaborative filtering of user suggestions. Structural and semantic analysis of returned pages finds individual results and identifies relevant fields. Users may revise automated decisions, balancing the power of automation with the errors it can introduce. In a user evaluation, both programmers and non-programmers found Transcendence to be a powerful way to explore deep web resources and wanted to use it in the future.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {169–178},
numpages = {10},
keywords = {web forms, information extraction, deep web},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378797,
author = {Gon\c{c}alves, Daniel and Jorge, Joaquim A.},
title = {In Search of Personal Information: Narrative-Based Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378797},
doi = {10.1145/1378773.1378797},
abstract = {Most computer users find organizing large amounts of personal information problematic. Often, hierarchies are the sole means to do it. However, users can remember a broader range of autobiographic contextual data about their personal items. Unfortunately, it can seldom be used to manage and retrieve them. Even when this is possible, it is often done by asking users to fill in values for arbitrary properties in dialog boxes or wizards.We propose that narrative-based interfaces can be a natural and effective way to help users recall relevant autobiographic data about their personal items and convey it to the computer. Using Quill, a narrative-based personal document retrieval interface, as a case-study, we show how such an interface can be designed. We demonstrate the approach's validity based on a set of user studies, discussing how the problems raised by the evaluation of such an interface were overcome.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {179–188},
numpages = {10},
keywords = {narrative-based interfaces, personal information management, document retrieval},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378798,
author = {Gyllstrom, Karl and Soules, Craig},
title = {Seeing is Retrieving: Building Information Context from What the User Sees},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378798},
doi = {10.1145/1378773.1378798},
abstract = {As the user's document and application workspace grows more diverse, supporting personal information management becomes increasingly important. This trend toward diversity renders it difficult to implement systems which are tailored to specific applications, file types, or other information sources.We developed SeeTrieve, a personal document retrieval and classification system which abstracts applications by considering only the text they present to the user through the user interface. Associating the visible text which surrounds a document in time, SeeTrieve is able to identify important information about the task within which a document is used. This context enables novel, useful ways for users to retrieve their personal documents. When compared to content based systems, this context based retrieval achieved substantial improvements in document recall.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {189–198},
numpages = {10},
keywords = {user modeling, contextual search},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378800,
author = {Dredze, Mark and Wallach, Hanna M. and Puller, Danny and Pereira, Fernando},
title = {Generating Summary Keywords for Emails Using Topics},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378800},
doi = {10.1145/1378773.1378800},
abstract = {Email summary keywords, used to concisely represent the gist of an email, can help users manage and prioritize large numbers of messages. We develop an unsupervised learning framework for selecting summary keywords from emails using latent representations of the underlying topics in a user's mailbox. This approach selects words that describe each message in the context of existing topics rather than simply selecting keywords based on a single message in isolation. We present and compare four methods for selecting summary keywords based on two well-known models for inferring latent topics: latent semantic analysis and latent Dirichlet allocation. The quality of the summary keywords is assessed by generating summaries for emails from twelve users in the Enron corpus. The summary keywords are then used in place of entire messages in two proxy tasks: automated foldering and recipient prediction. We also evaluate the extent to which summary keywords enhance the information already available in a typical email user interface by repeating the same tasks using email subject lines.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {199–206},
numpages = {8},
keywords = {topic modeling, keyword generation, foldering, recipient prediction, email},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378801,
author = {Shen, Jianqiang and Geyer, Werner and Muller, Michael and Dugan, Casey and Brownholtz, Beth and Millen, David R},
title = {Automatically Finding and Recommending Resources to Support Knowledge Workers' Activities},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378801},
doi = {10.1145/1378773.1378801},
abstract = {Knowledge workers perform many different activities daily. Each activity defines a distinct work context with different information needs. In this paper we leverage users' activity representations, stored in an activity management system, to automatically recommend resources to support knowledge workers in their current activity. We developed a collaborative activity predictor to both predict the current work activity and measure a resource's relevance to a specific activity. Relevant resources are then displayed in a contextual side bar on the desktop. We describe the system, our new activity-centric search algorithm, and experimental results based on the data from 50 real users.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {207–216},
numpages = {10},
keywords = {task, productivity, recommendation, attention, activity-centric collaboration, intelligent interface, search},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378802,
author = {Felfernig, Alexander and Teppan, Erich and Friedrich, Gerhard and Isak, Klaus},
title = {Intelligent Debugging and Repair of Utility Constraint Sets in Knowledge-Based Recommender Applications},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378802},
doi = {10.1145/1378773.1378802},
abstract = {Recommenders support effective product retrieval processes for online users. These systems propose repair actions in situations where no solution can be found and derive recommendations including a set of explanations as to why a certain product has been selected. In this context utility constraints (scoring rules) have to be defined which specify the way utilities of products, explanations, and repair alternatives are determined. Such constraints can be faulty which means that they calculate rankings in a way not expected by marketing and sales experts. The maintenance and repair of such constraints is an extremely error-prone task. In this paper we present an intelligent environment which supports the automated adaptation of faulty utility constraints taking into account existing marketing and sales requirements. In this context we discuss experiences from commercial projects.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {217–226},
numpages = {10},
keywords = {knowledge acquisition, knowledge-based recommenders, multi-attribute utility theory (MAUT)},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378804,
author = {Glass, Alyssa and McGuinness, Deborah L. and Wolverton, Michael},
title = {Toward Establishing Trust in Adaptive Agents},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378804},
doi = {10.1145/1378773.1378804},
abstract = {As adaptive agents become more complex and take increasing autonomy in their user's lives, it becomes more important for users to trust and understand these agents. Little work has been done, however, to study what factors influence the level of trust users are willing to place in these agents. Without trust in the actions and results produced by these agents, their use and adoption as trusted assistants and partners will be severely limited. We present the results of a study among test users of CALO, one such complex adaptive agent system, to investigate themes surrounding trust and understandability. We identify and discuss eight major themes that significantly impact user trust in complex systems. We further provide guidelines for the design of trustable adaptive agents. Based on our analysis of these results, we conclude that the availability of explanation capabilities in these agents can address the majority of trust concerns identified by users.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {227–236},
numpages = {10},
keywords = {automated assistants, evaluation, complex agents, explanation, trust, user study, adaptive agents},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378805,
author = {Qu, Shaolin and Chai, Joyce Y.},
title = {Beyond Attention: The Role of Deictic Gesture in Intention Recognition in Multimodal Conversational Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378805},
doi = {10.1145/1378773.1378805},
abstract = {In a multimodal conversational interface supporting speech and deictic gesture, deictic gestures on the graphical display have been traditionally used to identify user attention, for example, through reference resolution. Since the context of the identified attention can potentially constrain the associated intention, our hypothesis is that deictic gestures can go beyond attention and apply to intention recognition. Driven by this assumption, this paper systematically investigates the role of deictic gestures in intention recognition. We experiment with different model-based methods and instancebased methods to incorporate gestural information for intention recognition. We examine the effects of utilizing gestural information in two different processing stages: speech recognition stage and language understanding stage. Our empirical results have shown that utilizing gestural information improves intention recognition. The performance is further improved when gestures are incorporated in both speech recognition and language understanding stages compared to either stage alone.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {237–246},
numpages = {10},
keywords = {multimodal interface, gesture, speech, language understanding},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378806,
author = {Biswas, Pradipta and Robinson, Peter},
title = {Automatic Evaluation of Assistive Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378806},
doi = {10.1145/1378773.1378806},
abstract = {Computers offer valuable assistance to people with physical disabilities. However designing human-computer interfaces for these users is complicated. The range of abilities is more diverse than for able-bodied users, which makes analytical modelling harder. Practical user trials are also difficult and time consuming. We are developing a simulator to help with the evaluation of assistive interfaces. It can predict the likely interaction patterns when undertaking a task using a variety of input devices, and estimate the time to complete the task in the presence of different disabilities and for different levels of skill. In this paper we describe the different components of the simulator in detail and present a prototype of its implementation.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {247–256},
numpages = {10},
keywords = {simulator, usability evaluation, human computer interaction, assistive technology},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378807,
author = {Shirogane, Junko and Fukazawa, Yoshiaki},
title = {Correspondence Validation Method for GUI Operations and Scenarios by Operation History Analysis},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378807},
doi = {10.1145/1378773.1378807},
abstract = {Interactions between users and software are usually described as scenarios so that it is easy to reflect users' viewpoints in software development. In many cases, scenarios are written in a natural language so that users can communicate with software developers smoothly. However, it is difficult to validate correspondences between the flows of operations written in scenarios and those in software. We assume that the flows of software can be expressed by the flows of Graphical User Interface (GUI) operations. In this paper, we propose a method for validating the correspondences between the flows of operations in scenarios and those of actual GUIs. This validation can be performed by analyzing the historic data of GUI operations heuristically. The label names on widgets are extracted from the histories, terms corresponding to label names on widgets are extracted from scenarios, and then the orders of appearance of label names and f terms are validated.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {257–266},
numpages = {10},
keywords = {history analysis, correspondence validation, GUI, scenario},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378809,
author = {Basu, Sumit and Gupta, Surabhi and Mahajan, Milind and Nguyen, Patrick and Platt, John C.},
title = {Scalable Summaries of Spoken Conversations},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378809},
doi = {10.1145/1378773.1378809},
abstract = {In this work, we present a novel means of browsing recorded audio conversations. The method we develop produces scalable summaries of the recognized speech, in which we can increase the amount of text continuously with the desired level of detail to best fill the available space. We present an interface in which a user can view an entire conversation in one screen, but can also quickly zoom in to see the full transcript; the corresponding audio can be easily played as well. The scaling is achieved via a combination of topic segmentation and informative phrase selection, where the threshold for informativeness decreases with increasing level of detail. Finally, we evaluate our method and interface against a baseline interface with a user study.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {267–275},
numpages = {9},
keywords = {speech browsing, zoomable user interfaces, conversation summarization, speech summarization, conversation browsing},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378810,
author = {Ehlen, Patrick and Purver, Matthew and Niekrasz, John and Lee, Kari and Peters, Stanley},
title = {Meeting Adjourned: Off-Line Learning Interfaces for Automatic Meeting Understanding},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378810},
doi = {10.1145/1378773.1378810},
abstract = {Upcoming technologies will automatically identify and extract certain types of general information from meetings, such as topics and the tasks people agree to do. We explore interfaces for presenting this information to users after a meeting is completed, using two post-meeting interfaces that display information from topics and action items respectively. These interfaces also provide an excellent forum for obtaining user feedback about the performance of classification algorithms, allowing the system to learn and improve with time. We describe how we manage the delicate balance of obtaining necessary feedback without overburdening users. We also evaluate the effectiveness of feedback from one interface on improvement of future action item detection.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {276–284},
numpages = {9},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378811,
author = {Wu, Stephen and Schwartz, Lane and Schuler, William},
title = {Exploiting Referential Context in Spoken Language Interfaces for Data-Poor Domains},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378811},
doi = {10.1145/1378773.1378811},
abstract = {This paper describes an implementation of a shell-like programming interface that utilizes referential context (that is, information about the current state of an interfaced application) in order to achieve accurate recognition -- even in user-defined domains with no available domain-specific training corpora. The interface incorporates a knowledge of context into its model of syntax, yielding a referential semantic language model. Interestingly, the referential semantic language model exploits context dynamically, unlike other recent systems, by using incremental processing and the limited stack memory of an HMM-like time series model.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {285–292},
numpages = {8},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378813,
author = {Adams, Brett and Greenhill, Stewart and Venkatesh, Svetha},
title = {Temporal Semantic Compression for Video Browsing},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378813},
doi = {10.1145/1378773.1378813},
abstract = {We present a video browsing approach, termed Temporal Semantic Compression (TSC), that uses automated measures of interest to support today's foraging behaviours. Conventional browsers 'compress' a video stream using simple 2x or 8x fast-forward. TSC browsers dynamically filter video based on a single user gesture to leave out more or less of the boring bits. We demonstrate a browser with an example interest measure, derived from an automated estimate of movie tempo, to forage in terms of narrative structures such as crises, climaxes, and action sequence book-ends. Media understanding algorithms facilitate browsing, and interactivity enables the human-in-the-loop to cope when those algorithms fail to cross the semantic gap.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {293–296},
numpages = {4},
keywords = {video browsing, media aesthetics, compression},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378814,
author = {Bharath, A. and Madhvanath, Sriganesh},
title = {FreePad: A Novel Handwriting-Based Text Input for Pen and Touch Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378814},
doi = {10.1145/1378773.1378814},
abstract = {The last decade has seen tremendous growth in mobile devices such as Pocket PCs, mobile phones, Tablet PCs and notebooks. Most of these devices enable interaction through a stylus or touch interface, powered by handwriting recognition (HWR) capability. In this paper, we propose a novel input method that addresses some of the issues that arise due to the constraints posed by these devices in accepting handwriting input. For instance, many of the devices have a small writing area making "continuous" input difficult if not impossible, and the process of handwriting input demands significant user attention. The proposed solution is inspired by touch-typing, and appreciably reduces user's effort in the interaction, and it is especially suited for very small writing areas. The approach has been demonstrated using a prototype system that recognizes handwritten English words, and its accuracy has been evaluated using a standard dataset of handwritten words. A preliminary user study has also been carried out to understand user acceptance of the proposed technique.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {297–300},
numpages = {4},
keywords = {text input, pen and touch interfaces, handwriting recognition},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378815,
author = {Blythe, Jim and Russ, Thomas},
title = {Case-Based Reasoning for Procedure Learning by Instruction},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378815},
doi = {10.1145/1378773.1378815},
abstract = {To control intelligent tools that perform a variety of complex procedures, users need to be able to both modify existing procedure descriptions and communicate new procedures. In one approach, the user describes fragments of a procedure with text, and the tool searches the space of potential procedures for a match. This approach sometimes provides too little guidance for users, yet providing templates for guidance can require an expensive knowledge engineering effort in each new domain. We investigate the use of case-based reasoning to help guide the user, treating previously-defined procedures in the domain as cases. We describe domainindependent methods to find similar procedures while the user creates or modifies a procedure, to suggest potential steps to copy and to manage mapping the variables from the existing procedure into the procedure being edited. In some cases, the mapping tool suggests auxiliary steps to copy along with the desired steps, following an approach similar to derivational analogy. We evaluate the potential of this approach with an implemented tool, CB-Tailor, in a travel domain containing a number of procedures that may be added by the user. Our experiences suggest that the tool can provide useful guidance in a realistic set of situations.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {301–304},
numpages = {4},
keywords = {learning by instruction, knowledge acquisition, procedure learning},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378816,
author = {Bogdan, Cristian and Kaindl, Hermann and Falb, J\"{u}rgen and Popp, Roman},
title = {Modeling of Interaction Design by End Users through Discourse Modeling},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378816},
doi = {10.1145/1378773.1378816},
abstract = {End users of software typically have to let someone else develop it and its user interface, or to learn to design and to program it themselves. Especially user interfaces developed by someone else may not fit well the given task. Designing and programming is hard and takes a lot of effort in general, and even more so for people not especially trained or experienced.Therefore, we propose end-user development of user interfaces through a new approach and interface for discourse modeling. End users may themselves model an interaction design as a discourse (in the sense of a dialogue between human and computer). From such an interaction design, eventually a user interface is to be generated automatically by a tool. As a consequence, end-user development becomes end-user modeling instead of programming.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {305–308},
numpages = {4},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378817,
author = {Church, Karen and Smyth, Barry},
title = {Who, What, Where &amp; When: A New Approach to Mobile Search},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378817},
doi = {10.1145/1378773.1378817},
abstract = {Mobile devices and the mobile Internet represent an extremely challenging search environment. Limited screenspace, restricted text-input and interactivity, and impatient users all conspire to exacerbate the shortcomings of modern Web search. Recently researchers have proposed that typically vague search queries be augmented by context information, as a way to help search engines to retrieve more relevant information. In this paper we propose a novel interface to support multi-dimensional, context-sensitive mobile search, combining context features such as location, time, and community preferences to offer a unique search experience that is well-adapted to the needs of mobile users.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {309–312},
numpages = {4},
keywords = {time, preferences, communities, context, mobile search, location, mobile web, personalisation, search interfaces},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378818,
author = {Dasgupta, Tirthankar and Basu, Anupam},
title = {Prototype Machine Translation System from Text-to-Indian Sign Language},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378818},
doi = {10.1145/1378773.1378818},
abstract = {This paper presents a prototype Text-To-Indian Sign Language (ISL) translation system. The system will help dissemination of information to the deaf people in India. This paper also presents the SL-dictionary tool, which can be used to create bilingual ISL dictionary and can store ISL phonological information.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {313–316},
numpages = {4},
keywords = {HamNoSys, Indian sign language, sign language dictionary, NLP, machine translation},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378819,
author = {P, Deepak and Bhamidipaty, Anuradha and Challa, Swati},
title = {Intelligent User Assistance for Cost Effective Usage of Mobile Phone},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378819},
doi = {10.1145/1378773.1378819},
abstract = {Cost is the governing factor which defines the penetration and adoption of mobile phones in lower strata (lower income group) of the society particularly in developing countries like India. In this paper we describe an enhancement to the mobile phone design which interacts with the user to facilitate cost-conscious usage of the mobile phone. In particular, we propose an intelligent component in the mobile phone which tracks mobile usage pattern and informs the user of deviations in usage and suggests means of using the device cost effectively.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {317–320},
numpages = {4},
keywords = {pattern analysis, cost-effective usage, mobile phone interfaces},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378820,
author = {Dredze, Mark and Brooks, Tova and Carroll, Josh and Magarick, Joshua and Blitzer, John and Pereira, Fernando},
title = {Intelligent Email: Reply and Attachment Prediction},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378820},
doi = {10.1145/1378773.1378820},
abstract = {We present two prediction problems under the rubric of Intelligent Email that are designed to support enhanced email interfaces that relieve the stress of email overload. Reply prediction alerts users when an email requires a response and facilitates email response management. Attachment prediction alerts users when they are about to send an email missing an attachment or triggers a document recommendation system, which can catch missing attachment emails before they are sent. Both problems use the same underlying email classification system and task specific features. Each task is evaluated for both single-user and cross-user settings.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {321–324},
numpages = {4},
keywords = {attachment prediction, email overload, reply prediction},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378821,
author = {Gennari, Rosella and Mich, Ornella},
title = {Designing and Assessing an Intelligent E-Tool for Deaf Children},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378821},
doi = {10.1145/1378773.1378821},
abstract = {LODE is a logic-based web tool for Italian deaf children who have problems in the comprehension of narratives in a verbal language; namely, it aims at stimulating global reasoning on written e-stories. Presently, LODE deals with global temporal reasoning; temporal reasoning problems are encoded as constraint satisfaction problems that can be solved by a constraint reasoner. The focus of this paper is the intelligent user interface of LODE; after characterizing the intended end users of LODE, this paper focuses on critical issues faced in the design and assessment of the interface of our e-tool. A preliminary assessment and an evaluation plan of LODE conclude our paper.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {325–328},
numpages = {4},
keywords = {AI techniques in interfaces, intelligent visualization, interfaces that teach and provide feedback},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378822,
author = {Gil, Yolanda and Ratnakar, Varun},
title = {Towards Intelligent Assistance for To-Do Lists},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378822},
doi = {10.1145/1378773.1378822},
abstract = {Assisting users with to-do lists presents new challenges for intelligent user interfaces. This paper presents a detailed analysis of to-do list entries jotted by users of a system that automates tasks for users that we would like to extend to assist users with their to-do entries. We also present four distinct stages of interpretation of to-do entries that can be accomplished and evaluated separately. A system that has good performance in any of these four stages can provide intelligent assistance that is useful to users.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {329–332},
numpages = {4},
keywords = {automated assistance, to-do lists, user interfaces, knowledge acquisition, knowledge collection from web volunteers, natural language interpretation, office assistants},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378823,
author = {Good, Judith and Romero, Pablo and du Boulay, Benedict and Reid, Henry and Howland, Katherine and Robertson, Judy},
title = {An Embodied Interface for Teaching Computational Thinking},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378823},
doi = {10.1145/1378773.1378823},
abstract = {We describe an innovative educational system designed to, firstly, motivate young people to engage with computational concepts and secondly, provide them with tools to do so in an embodied manner. The interface is designed as a "magic mirror" in which users can, through augmented reality technology, take on the role of a character and control the character's movements via their own movements. They are able to record movements, and using a Wii Remote as a mouse and pointing device, organise these movements into sequences. We are now working on ways in which the recorded movements can be manipulated in ways that foster computational thinking.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {333–336},
numpages = {4},
keywords = {augmented reality, computational thinking, Embodied interfaces},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378824,
author = {Jagdish, Deepak and Sawhney, Rahul and Gupta, Mohit and Nangia, Shreyas},
title = {Sonic Grid: An Auditory Interface for the Visually Impaired to Navigate GUI-Based Environments},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378824},
doi = {10.1145/1378773.1378824},
abstract = {This paper explores the prototype design of an auditory interface enhancement called the Sonic Grid that helps visually impaired users navigate GUI-based environments. The Sonic Grid provides an auditory representation of GUI elements embedded in a two-dimensional interface, giving a 'global' spatial context for use of auditory icons, ear-cons and speech feedback. This paper introduces the Sonic Grid, discusses insights gained through participatory design with members of the visually impaired community, and suggests various applications of the technique, including its use to ease the learning curve for using computers by the visually impaired.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {337–340},
numpages = {4},
keywords = {accessibility, auditory interface, touch based devices},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378825,
author = {Jiang, Yingying and Wang, Xugang and Tian, Feng and Ao, Xiang and Dai, Guozhong and Wang, Hongan},
title = {Multimodal Chinese Text Entry with Speech and Keypad on Mobile Devices},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378825},
doi = {10.1145/1378773.1378825},
abstract = {Chinese text entry is challenging on mobile devices which rely on keypad input. Entering one character may require many key presses. This paper proposes a multimodal text entry technique for Chinese. In this method, Chinese user can enter Chinese text by simultaneously using the simplified phonemic input method named Jianpin with keypad and speech utterance. The key of the technique is a multimodal fusion algorithm, which synchronizes speech and keypad input and fuses redundant information from two modalities to get the best candidate. A preliminary evaluation shows that users appreciate this technique and it could reduce key presses and enhance the input efficiency.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {341–344},
numpages = {4},
keywords = {speech, mobile devices, keypad, multimodal, Chinese text entry},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378826,
author = {Kanai, Hideaki and Tsuruma, Goushi and Nakada, Toyohisa and Kunifuji, Susumu},
title = {Notification of Dangerous Situation for Elderly People Using Visual Cues},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378826},
doi = {10.1145/1378773.1378826},
abstract = {There are various dangers that could lead to accidents in daily life at home. It is difficult for elderly people to realize these dangers beforehand. In this study, we focus on a method for enhancing the risk perception of elderly people. We have developed a system that enhances the awareness of dangerous situations. It performs the following functions: (1) it recognizes the behavior and situation of the elderly person, (2) it estimates the risk, and (3) when the risk is estimated to be high, it notifies the person of the risk by means of visual and audio cues. In this paper, we outline our system and report a user test that evaluates the notification function, particularly the use of visual cues in our experimental living environment. The result is that the visual cues are suitable for elderly rather than healthy people in the environment of a dark room. As a future work, we will investigate the effects of visual and audio cues as notifications of danger for elderly people.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {345–348},
numpages = {4},
keywords = {dangerous situation awareness, visual cues, elderly person},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378827,
author = {Kane, Shaun K. and Wobbrock, Jacob O. and Harniss, Mark and Johnson, Kurt L.},
title = {TrueKeys: Identifying and Correcting Typing Errors for People with Motor Impairments},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378827},
doi = {10.1145/1378773.1378827},
abstract = {People with motor impairments often have difficulty typing using desktop keyboards. We developed TrueKeys, a system that combines models of word frequency, keyboard layout, and typing error patterns to automatically identify and correct typing mistakes. In this paper, we describe the TrueKeys algorithm, compare its performance to existing correction algorithms, and report on a study of TrueKeys with 9 motor-impaired and 9 non-impaired participants. Running in non-interactive mode, TrueKeys performed more corrections than popular commercial and open source spell checkers. Used interactively, both motor-impaired and non-impaired users performed typing tasks significantly more accurately with TrueKeys than without. However, typing speed was reduced while TrueKeys was enabled.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {349–352},
numpages = {4},
keywords = {computer access, spell checking, minimum string distance, motor impairments, error correction, typing errors},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378828,
author = {Kristensson, Per Ola and Zhai, Shumin},
title = {Improving Word-Recognizers Using an Interactive Lexicon with Active and Passive Words},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378828},
doi = {10.1145/1378773.1378828},
abstract = {The words a user is likely to write comprise the user's active vocabulary. This vocabulary is considerably smaller than the passive vocabulary of words a user reads. We explore an interactive adaptive lexicon method that separates a large lexicon into active and passive sets, and gradually expands and adapts the active set to reflect the user's active vocabulary. The adaptation is achieved through lightweight interaction as a by product of actual use. The effectiveness of the technique is demonstrated through a computational experiment and a user study.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {353–356},
numpages = {4},
keywords = {adaptive user interfaces, lexicon, handwriting recognition, recognition},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378829,
author = {Laufer, L\'{a}szl\'{o} and N\'{e}meth, Botty\'{a}n},
title = {Predicting User Action from Skin Conductance},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378829},
doi = {10.1145/1378773.1378829},
abstract = {There are many studies focusing on enhancing physiological data in user interfaces. On one hand biofeedback games are using skin conductance and heart rate data to reflect the emotional state of the user, on the other hand BCI research tries to conclude user intentions from EEG signals.In our research we are collecting usual biofeedback data but process it with complex algorithms similarly to the BCI methodologies. This way we are able to conclude more complex user states than relaxation or anxiety.In our experiments we asked users to play with a simple arcade game, while we were recording physiological data. We were training artificial neural networks to learn the time of user action from the physiological signals. The networks were capable of detecting and also predicting user action 2 seconds before it was carried out.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {357–360},
numpages = {4},
keywords = {artificial neural networks, biofeedback, skin conductance},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378830,
author = {Liu, Jiahui and Gruen, Daniel M.},
title = {Between Ontology and Folksonomy: A Study of Collaborative and Implicit Ontology Evolution},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378830},
doi = {10.1145/1378773.1378830},
abstract = {We present our first user study of CRAFT, a semantic prototype for collaborative investigation and analysis, which allows users to extend the system's ontology to capture new concepts as they conduct their work. We devised a paradigm in which multiple series of ontologies evolve in different trajectories from the same initial point. We analyze the ontology evolution quantitatively with several metrics, and user behavior qualitatively through interviews and observation. Based on our study, we propose a set of design suggestions for semantic applications with collaborative and implicit ontology development.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {361–364},
numpages = {4},
keywords = {ontology, folksonomy, collaboration, user study},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378831,
author = {Mahmud, Jalal and Borodin, Yevgen and Ramakrishnan, I. V.},
title = {Assistive Browser for Conducting Web Transactions},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378831},
doi = {10.1145/1378773.1378831},
abstract = {People with visual impairments use screen readers to browse the Web. Sequential processing of web pages by screen readers causes information overload, making web browsing time-consuming and strenuous. These problems are further exacerbated in web transactions (e.g.: online shopping), which involve multiple steps spanning several web pages. In this paper we present a lightweight approach for doing Web transactions using non-visual modalities. We describe how analysis of context surrounding the link coupled with a shallow knowledge-base with patterns and keywords can help identify various concepts (e.g.: "add to cart", "item description", etc.) that are important in web transactions. Our preliminary results show promise that presenting such concepts to the users can reduce information overload and improve their overall browsing experience.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {365–368},
numpages = {4},
keywords = {shallow knowledge-base, partitioning, web transaction, segments, context},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378832,
author = {Molina, Martin and Flores, Victor},
title = {A Presentation Model for Multimedia Summaries of Behavior},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378832},
doi = {10.1145/1378773.1378832},
abstract = {Presentation models are used by intelligent user interfaces to automatically construct adapted presentations according to particular communication goals. This paper describes the characteristics of a presentation model that was designed to automatically produce multimedia presentations about the summarized behavior of dynamic systems. The presentation model is part of the MSB application (Multimedia Summarizer of Behavior). MSB was developed for the problem of management of dynamic systems where different types of users (operators, decision-makers, other institutions, etc.) need to be informed about the evolution of the system, especially during critical situations. The paper describes the details of the presentation model based on a hierarchical planner together with graphical resources. The paper also describes an application in the field of hydrology for which the model was developed.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {369–372},
numpages = {4},
keywords = {multimedia user interface, behavior summarization, presentation model},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378833,
author = {Mollenbach, Emilie and Stefansson, Thorarinn and Hansen, John Paulin},
title = {All Eyes on the Monitor: Gaze Based Interaction in Zoomable, Multi-Scaled Information-Spaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378833},
doi = {10.1145/1378773.1378833},
abstract = {The experiment described in this paper, shows a test environment constructed with two information spaces; one large with 2000 nodes ordered in semi-structured groups in which participants performed search and browse tasks; the other was smaller and designed for precision zooming, where subjects performed target selection simulation tasks. For both tasks, modes of gaze- and mouse-controlled navigation were compared.The results of the browse and search tasks showed that the performances of the most efficient mouse and gaze implementations were indistinguishable. However, in the target selection simulation tasks the most efficient gazecontrol proved to be about 16% faster than the most efficient mouse-control.The results indicate that gaze-controlled pan/zoom navigation is a viable alternative to mouse control in inspection and target exploration of large, multi-scale environments. However, supplementing mouse control with gaze navigation also holds interesting potential for interface and interaction design.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {373–376},
numpages = {4},
keywords = {gaze-based interaction, interface design, pan and zoom navigation, large multi-scaled information-spaces},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378834,
author = {Mori, Junichiro and Basselin, Nathalie and Kr\"{o}ner, Alexander and Jameson, Anthony},
title = {Find Me If You Can: Designing Interfaces for People Search},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378834},
doi = {10.1145/1378773.1378834},
abstract = {Selecting relevant people is crucial for collaborative systems exploiting other users' experiences. With the new developments of the Web and ubiquitous technologies, various user data may support people selection. Given the wide range of user data sources, the question is now how to select appropriate users meeting the information seeker's goal. We propose recommendations for the design of people search interfaces, providing an overview of the user data and tools of relevance and two examples of how such recommendations can be met in one single interface, ensuring the selection of appropriate and reachable people. We also show applications of people search interfaces in different scenarios.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {377–380},
numpages = {4},
keywords = {interface design, people search, people selection},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378835,
author = {Nguyen, Quang Nhat and Ricci, Francesco},
title = {Long-Term and Session-Specific User Preferences in a Mobile Recommender System},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378835},
doi = {10.1145/1378773.1378835},
abstract = {User preferences acquisition plays a very important role for recommender systems. In a previous paper, we proposed a critique-based mobile recommendation methodology exploiting both long-term and session-specific user preferences. In this paper, we evaluate the impact on the recommendation accuracy of the two kinds of user preferences. We have ran off-line experiments exploiting the log data recorded in a previous live-user evaluation, and we show here that exploiting both long-term and session-specific preferences results in a better recommendation accuracy than using a single user model component. Moreover, we show that when the simulated user behavior deviates from that dictated by the acquired user model the session-specific preferences are more useful than the long-term ones in predicting user decisions.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {381–384},
numpages = {4},
keywords = {user model, mobile recommender systems, critiquing},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378836,
author = {Oliver, Nuria and Czerwinski, Mary and Smith, Greg and Roomp, Kristof},
title = {RelAltTab: Assisting Users in Switching Windows},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378836},
doi = {10.1145/1378773.1378836},
abstract = {We present RelAltTab, an enhanced ALT+TAB prototype that assists users in switching windows. Our approach uses semantic and temporal information to create a list of related windows to the window that the user is currently engaged in. The main assumption is that the user is more likely to switch to a related window than to any other window in the system. We propose two different user interfaces that present the related window list to the user. We describe in detail the techniques and user interfaces of the RelAltTab system, and present the results of one user study comparing our approach to the standard Windows ALT+TAB program.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {385–388},
numpages = {4},
keywords = {intelligent window switching applications, window similarity modeling, related windows, ALT+TAB},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378837,
author = {Pedersen, Elin R\o{}nby and McDonald, David W.},
title = {Relating Documents via User Activity: The Missing Link},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378837},
doi = {10.1145/1378773.1378837},
abstract = {In this paper we describe a system for creating and exposing relationships between documents: a user's interaction with digital objects (like documents) is interpreted as links - to be discovered and maintained by the system. Such relationships are created automatically, requiring no priming by the user. Using a very simple set of heuristics, we demonstrate the uniquely useful relationships that can be established between documents that have been touched by the user. Furthermore, this mechanism for relationship building is media agnostic, thus discovering relationships that would not be found by conventional content based approaches. We describe a proof-of-concept implementation of this basic idea and discuss a couple of natural expansions of the scope of user activity monitoring.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {389–392},
numpages = {4},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378838,
author = {Porta, Daniel and Conrad, Jan},
title = {UBIGIouS: A Ubiquitous, Mixed-Reality Geographic Information System},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378838},
doi = {10.1145/1378773.1378838},
abstract = {Moving in virtual environments has become very common. On the one hand there are e.g. non-interactive route guidance systems which are not adequate for pedestrians. On the other hand interactive applications like Second Life fascinate a broad community.This work presents the information system UBIGIouS that combines reality with virtuality in an interactive mixed reality scenario. It is intended to link Virtual Reality Geographic Information Systems with purely virtual interactive applications. For ubiquitous access, users can participate from their homes by standard, stationary PCs or on site using mobile devices like smartphones. By means of visual building recognition capabilities UBIGIouS offers location-based services with or without positioning via the Global Positioning System GPS.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {393–396},
numpages = {4},
keywords = {mixed-reality, geographic information system, building recognition, ubiquitous computing, location-based service},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378839,
author = {Rashid, Daniel R. and Smith, Noah A.},
title = {Relative Keyboard Input System},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378839},
doi = {10.1145/1378773.1378839},
abstract = {This paper describes a "relative keyboard," where keystrokes are treated as inputs in a continuous space relative to each other, instead of a discrete, unambiguous sequence. A user with the ability to touch-type may type anywhere on the sensing surface without the need for a visual keyboard. An implementation of such a system is explored and evaluated on simulated data and real user data.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {397–400},
numpages = {4},
keywords = {relative keyboard, soft keyboard, predictive keyboard},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378840,
author = {Thompson, Will and Gergle, Darren},
title = {Modeling Situated Conversational Agents as Partially Observable Markov Decision Processes},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378840},
doi = {10.1145/1378773.1378840},
abstract = {A Situated Conversational Agent (SCA) is an agent that engages in dialog about the context within which it is embedded. An SCA is distinguished from non-situated conversational agents by an intimate connection of the agent's dialog to its embedding context, and by intricate dependencies between its linguistic and physical actions. Constructing an SCA that can interact naturally with users while engaged in collaborative physical tasks requires the agent to interleave decision making under uncertainty, action execution, and observation while maximizing expected utility over a sequence of interactions. These requirements can be fulfilled by modeling an SCA as a partially observable Markov decision process (POMDP). We show how POMDPs can be used to formalize and implement psycholinguistic proposals on how situated dialog participants collaborate in order to make and ground dialog contributions.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {401–404},
numpages = {4},
keywords = {decision-theoretic planning, situated conversational agents},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378841,
author = {Yeh, Tom and Darrell, Trevor},
title = {Multimodal Question Answering for Mobile Devices},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378841},
doi = {10.1145/1378773.1378841},
abstract = {This paper introduces multimodal question answering, a new interface for community-based question answering services. By offering users an extra modality---photos---in addition to the text modality to formulate queries, multimodal question answering overcomes the limitations of text-only input methods when the users ask questions regarding visually distinctive objects. Such interface is especially useful when users become curious about an interesting object in the environment and want to know about it---simply by taking a photo and asking a question in a situated (from a mobile device) and intuitive (without describing the object in words) manner. We propose a system architecture for multimodal question answering, describe an algorithm for searching the database, and report on the findings of two prototype studies.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {405–408},
numpages = {4},
keywords = {mobile application, question answering, information retrieval, pattern matching},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378842,
author = {Zhang, Li and Gillies, Marco and Barnden, John},
title = {EMMA: An Automated Intelligent Actor in e-Drama},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378842},
doi = {10.1145/1378773.1378842},
abstract = {We report work on adding an improvisational AI actor and 3D emotional animation to an existing edrama program, a system for dramatic improvisation in simple virtual scenarios. The improvisational AI actor has an affect-detection component, aimed at detecting affective aspects of human-controlled characters' textual input. It also makes an appropriate response to stimulate the improvisation based on this affective understanding. A distinctive feature of our work is a focus on the metaphorical ways in which affect is conveyed. Moreover, we have also introduced how the detected affective states activate the animation engine to produce emotional gestures for human-controlled characters. Finally, we report user testing conducted for the AI actor. Our work contributes to the conference themes on affective user interfaces, natural language processing and emotionally believable gesture generation.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {409–412},
numpages = {4},
keywords = {an improvisational AI actor and emotional behavior, metaphorical language, affect detection},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378843,
author = {Zhao, Shiwan and Du, Nan and Nauerz, Andreas and Zhang, Xiatian and Yuan, Quan and Fu, Rongyao},
title = {Improved Recommendation Based on Collaborative Tagging Behaviors},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378843},
doi = {10.1145/1378773.1378843},
abstract = {Considering the natural tendency of people to follow direct or indirect cues of other people's activities, collaborative filtering-based recommender systems often predict the utility of an item for a particular user according to previous ratings by other similar users. Consequently, effective searching for the most related neighbors is critical for the success of the recommendations. In recent years, collaborative tagging systems with social bookmarking as their key component from the suite of Web 2.0 technologies allow users to freely bookmark and assign semantic descriptions to various shared resources on the web. While the list of favorite web pages indicates the interests or taste of each user, the assigned tags can further provide useful hints about what a user thinks of the pages.In this paper, we propose a new collaborative filtering approach TBCF (Tag-based Collaborative Filtering) based on the semantic distance among tags assigned by different users to improve the effectiveness of neighbor selection. That is, two users could be considered similar not only if they rated the items similarly, but also if they have similar cognitions over these items. We tested TBCF on real-life datasets, and the experimental results show that our approach has significant improvement against the traditional cosine-based recommendation method while leveraging user input not explicitly targeting the recommendation system.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {413–416},
numpages = {4},
keywords = {tag, collaborative filtering, recommendation, web 2.0},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378845,
author = {Bostr\"{o}m, Fredrik and Flor\'{e}en, Patrik and Liu, Tianyan and Nurmi, Petteri and Oikarinen, Tiina-Kaisa and Vetek, Akos and Boda, P\'{e}ter},
title = {Capricorn: An Intelligent Interface for Mobile Widgets},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378845},
doi = {10.1145/1378773.1378845},
abstract = {Widgets are embeddable objects that provide easy and ubiquitous access to dynamic information sources, for example weather, news or TV program information. Widgets are typically rather static - they provide the information regardless of whether the information is relevant to the user's current information needs. In this paper we introduce Capricorn, which is an intelligent interface for mobile widgets. The interface uses various adaptive web techniques for facilitating navigation. For example, we use collaborative filtering to recommend suitable widgets and we dim infrequently used widgets. The demonstration presents the Capricorn interface focusing on the adaptive parts of the interface. The user interface is web-based, and as such platform independent. However, our target environment is mobile phones, and thus the interface has been optimized for mobile phones.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {417–418},
numpages = {2},
keywords = {adaptive user interfaces, information aggregation, context awareness},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378846,
author = {Chittaro, Luca and Ranon, Roberto},
title = {An Adaptive 3D Virtual Environment for Learning the X3D Language},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378846},
doi = {10.1145/1378773.1378846},
abstract = {This demo will illustrate the adaptive interface of an application (whose architecture and implementation have been presented in detail in [2]) for learning 3D Graphics programming (in the X3D ISO standard). The application situates users in a 3D Virtual Environment where they can learn by selecting and inspecting actual examples.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {419–420},
numpages = {2},
keywords = {adaptive interfaces, X3D, personalization, web-based learning},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378847,
author = {Gundelsweiler, Fredrik and Konstanzer, Robert and Reiterer, Harald},
title = {An Innovative User Interface Concept for Large Hierarchical Data Spaces by Example of the EPDM Domain},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378847},
doi = {10.1145/1378773.1378847},
abstract = {In this paper we will describe a new approach to navigation and interaction with the visualization of a data space of an electronic product data management (EPDM) system. The main problems are the amount of data and therefore the location of an item of interest, show specific relations and narrow or expand the information space. We combine a scalable visualization of the hierarchical data space with search and filter techniques like dynamic queries and direct manipulation to solve the stated problems. We assume that the proposed concept for EPDM can be adapted to data spaces like social networks or company structures.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {421–422},
numpages = {2},
keywords = {scalable visualization, semantic pixel display, hierarchies},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378848,
author = {K\"{o}nig, Werner A. and B\"{o}ttger, Joachim and V\"{o}lzow, Nikolaus and Reiterer, Harald},
title = {Laserpointer-Interaction between Art and Science},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378848},
doi = {10.1145/1378773.1378848},
abstract = {We employ Laserpointer-Interaction as an intuitive, direct and flexible interaction concept particularly for large, highresolution displays which enforce physical navigation. We therefore demonstrate general applicability and suitability by applying Laserpointer-Interaction to a wide range of domains -- from scientific applications and formal experiments to artistic installations for the broad public.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {423–424},
numpages = {2},
keywords = {laserpointer-interaction, tapping test, large high-resolution display, artistic installation, pointing device},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378849,
author = {Mistry, Pranav and Maes, Pattie},
title = {Intelligent Sticky Notes That Can Be Searched, Located and Can Send Reminders and Messages},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378849},
doi = {10.1145/1378773.1378849},
abstract = {We present 'Quickies: Intelligent Sticky Notes', an attempt to bring one of the most useful inventions of the 20th century into the digital age: the ubiquitous sticky notes. Sticky notes help us manage our-to-do lists, tag our objects and documents and capture short reminders or information that we may need in the near future. 'Quickies' enrich the experience of using sticky notes by allowing them to be tracked and managed more effectively. Quickies are stickies that have intelligence and the ability to remind us about the task we ought to perform or to provide us at the right time with the information we captured in the past. The project explores how the use of Artificial Intelligence, RFID, and ink recognition technologies can make it possible to create intelligent sticky notes that can be searched, located, can send reminders and messages, and more broadly, can help us to seamlessly connect our physical and digital experiences.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {425–426},
numpages = {2},
keywords = {connecting the physical and information world, handwriting recognition, RFID, post-it notes},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378850,
author = {Sanchez, Romeo and Jin, Jing and Maheswaran, Rajiv T. and Szekely, Pedro},
title = {Interfaces for Team Coordination},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378850},
doi = {10.1145/1378773.1378850},
abstract = {Coordinators are intelligent software agents that help humans to collaborate and coordinate execution of multiple activities in dynamic, distributed and uncertain domains. One of the main challenges is the generation of effective user interfaces for team coordination. Intelligent interfaces that avoid information overload, and facilitate user interactions to repair mission plans are needed, and they are the focus of this work.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {427–428},
numpages = {2},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378851,
author = {Scerri, Simon},
title = {Semanta: Your Personal Email Semantic Assistant},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378851},
doi = {10.1145/1378773.1378851},
abstract = {The complete lack of structure and semantics in email content is one reason why data channeled between the sender and the recipient is hard to be correctly interpreted and acted upon. This causes information overload, tedious personal information management, and jeopardizes the disconnected workflow that is characteristic of email. Through Semanta, we will show how by extending the current email model to support light-weight semantics pertaining to the purposes of email messages, we can substantially reduce the occurrence of these problems.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {429–430},
numpages = {2},
keywords = {speech acts, personal information management, semantic email, semantic web},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378852,
author = {Sugimoto, Futoshi and Yoneyama, Masahide},
title = {Lips Animation Based on Japanese Phoneme Context for an Automatic Reading System with Emotion},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378852},
doi = {10.1145/1378773.1378852},
abstract = {We developed a lips animation system that is simple and suits the characteristics of Japanese. It adopts phoneme context that is usually used in speech synthesis. It only needs a small database that contains tracing data of movement of lips for each phoneme context. Through an experiment using subjects in which the subjects read a word from lips animation, we got result as correct as from real lips.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {431–432},
numpages = {2},
keywords = {lips animation, text-to-speech, phoneme context},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378853,
author = {Valenti, Roberto and Jaimes, Alejandro and Sebe, Nicu},
title = {Facial Expression Recognition as a Creative Interface},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378853},
doi = {10.1145/1378773.1378853},
abstract = {We present an audiovisual creativity tool that automatically recognizes facial expressions in real time, producing sounds in combination with images. The facial expression recognition component detects and tracks a face and outputs a feature vector of motions of specific locations in the face. The feature vector is used as input to a Bayesian network which classifies facial expressions into several categories (e.g., angry, disgusted, happy, etc.). The classification results are used along with the feature vector to generate a combination of sounds and images that change in real time depending on the person's facial expressions. We explain the basic components of our tool and several possible applications in the arts (performance, installation) and medical domains.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {433–434},
numpages = {2},
keywords = {gesture-based interaction, multimodal, facial therapy interface, affective, interface, sonification},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378855,
author = {Rehm, Matthias and Andr\'{e}, Elisabeth and Nakano, Yukiko and Nishida, Toyoaki},
title = {Enculturating Conversational Interfaces by Socio-Cultural Aspects of Communication},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378855},
doi = {10.1145/1378773.1378855},
abstract = {The workshop is centered around three main research challenges: 1.) Computationally viable models of cultural aspects of conversations: Cultural norms and values penetrate all our communications and interactions by giving us heuristics how to behave and how to interpret the verbal and nonverbal behavior of others. To make such a notion like culture available for computation, we need a very specific theory of culture that takes its effects on communication and interaction into account.2.) Reliable empirical data on cultural/cross-cultural interaction: To realize technical systems that take cultural influences on behavior into account, precise data analysis on how this influence manifests itself is necessary. In the literature, this information is often given in very general forms without to the precise data on which the observations are based.3.) Enculturating conversational interfaces: Having identified cultural influences on verbal/nonverbal communicative behaviors, it remains to be shown how this can be applied to the development of human-computer interfaces, for instance in an interface reflecting cultural norms and values of communication.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {435},
numpages = {1},
keywords = {cultural computing, HCI, embodied conversational agents},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378856,
author = {Mukasa, Kizito Ssamula and Holzinger, Andreas and Karshmer, Arthur I.},
title = {Workshop on Intelligent User Interfaces for Ambient Assisted Living},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378856},
doi = {10.1145/1378773.1378856},
abstract = {The vision of ambient assisted living (AAL) is to provide technologies for supporting these people in their daily lives, allowing them to stay longer within their own home aiming at living independent and self-determined. We believe that intelligent user interfaces (IUI) can play an important role here. Consequently, this workshop addresses the questions related to the role, application, advantages (and also disadvantages) of IUI in the context of AAL. It aims at discussing on challenges, solutions and approaches related to these issues especially for elderly and impaired users.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {436},
numpages = {1},
keywords = {intelligent user interfaces, ambient assisted living, usability},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378857,
author = {Agarwal, Sheetal K and Rajput, Nitendra and Canny, John and Chavan, Apala Lahiri},
title = {IUI4DR: Intelligent User Interfaces for Developing Regions},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378857},
doi = {10.1145/1378773.1378857},
abstract = {Information Technology has had significant impact on the society and has touched all aspects of our lives. So far, computers and expensive devices have fueled this growth. The challenge now is to take this success of IT to its next level where IT services can be accessed by masses. "Masses" here mean the people who (a) are not yet IT literate and/or (b) do not have the purchase power to use the current IT delivery mechanisms (PC centric model) and/or (c) do not find current IT solutions and services relevant to their life or business. Interestingly, a huge portion of the world's population falls in this category. To enable the IT access to such masses, this workshop focuses on easy-to-use and affordable, yet powerful, user interfaces that can be used by this population.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {437},
numpages = {1},
keywords = {cost-effective interfaces, illiteracy, developing countries},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378858,
author = {Kuflik, Tsvi and Berkovsky, Shlomo and Heckmann, Dominik and Kr\"{u}ger, Antonio},
title = {UbiqUM 2008: Theories and Applications of Ubiquitous User Modeling},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378858},
doi = {10.1145/1378773.1378858},
abstract = {In today's information world, small personal computerized devices, such as PDAs, smart phones and other smart appliances, become widely available and essential tools in many situations. This ongoing penetration of computers into everyday life leads to so-called ubiquitous environments, where computational power and networking capabilities are available (and used) everywhere. The strive of providing personal services to users made user modeling capability an essential part of any ubiquitous application. Ubiquitous user modeling describes ongoing modeling and exploitation of user behavior with a variety of systems that share their user models. Currently, issues relating to ubiquitous user modeling are gaining more and more attention from research groups representing the user modeling, the human-computer interaction, and the ubiquitous computing research communities. The goal of this workshop is to bring together academic and industrial researchers from these communities to discuss the most innovative approaches to ubiquitous user modeling, to enhance the exchange of ideas and concepts, to determine the veins the research should proceed, and to go one step further towards personalization in ubiquitous computing.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {438},
numpages = {1},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378859,
author = {Bergman, Lawrence and Kim, Jihie and Mobasher, Bamshad and Rueger, Stefan and Siersdorfer, Stefan and Sizov, Sergej and Stolze, Markus},
title = {International Workshop on Recommendation and Collaboration (ReColl 2008)},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378859},
doi = {10.1145/1378773.1378859},
abstract = {The International Workshop on Recommendation and Collaboration (ReColl 2008) aims to identify emerging trends in recommendation technology and collaborative environments in the context of intelligent user interfaces. We explore these two topics separately and the synergies between them.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {439},
numpages = {1},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378860,
author = {Gordon, Andrew S. and Havasi, Catherine and Lux, Mathias and Strohmaier, Markus},
title = {Common Sense Knowledge and Goal-Oriented Interfaces},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378860},
doi = {10.1145/1378773.1378860},
abstract = {We present an overview of the workshop on Common Sense Knowledge and Goal-Oriented Interfaces held at the 2008 Intelligent User Interfaces conference. Six papers were accepted from diverse research groups, each offering innovative new research on interfaces that incorporate common sense knowledge and that are oriented around the goals of their users.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {440},
numpages = {1},
keywords = {common sense knowledge, goal-oriented interfaces},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378862,
author = {Berger, Theodore W.},
title = {Implantable Biomimetic Electronics as Neural Prostheses for Lost Memory Function},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378862},
doi = {10.1145/1378773.1378862},
abstract = {The talk presents results of a multi-disciplinary project that is developing a microchip-based neural prosthesis for the hippocampus, a region of the brain responsible for the formation of long-term memories. Damage to the hippocampus is frequently associated with epilepsy, stroke, and dementia (Alzheimer's disease), and is considered to underlie the memory deficits related to these neurological conditions.The essential goals of Dr. Bergers multi-laboratory effort include:1. experimental study of neuron and neural network function - how does the hippocampus encode information?2. formulation of biologically realistic models of neural system dynamics - can that encoding process be described mathematically to realize a predictive model of how the hippocampus responds to any event?3. microchip implementation of neural system models - can the mathematical model be realized as a set of electronic circuits to achieve parallel processing, rapid computational speed, and miniaturization?4. creation of hybrid neuron-silicon interfaces - can structural and functional connections between electronic devices and neural tissue be achieved for long-term, bi-directional communication with the brain?By integrating solutions to these component problems, we are realizing a microchip-based model of hippocampal nonlinear dynamics that can perform the same function as part of the hippocampus. Through bi-directional communication with other neural tissue that normally provides the inputs and outputs to/from a damaged hippocampal area, the biomimetic model could serve as a neural prosthesis. A proof-of-concept is presented in which the CA3 region of the hippocampal slice is surgically removed, and is replaced by a microchip model of CA3 nonlinear dynamics the "hybrid" hippocampal circuit displays normal physiological properties. Major strides also have been made in creating "hybrid electro-biological" systems in the behaving animal, and these are described as well.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {441},
numpages = {1},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

@inproceedings{10.1145/1378773.1378863,
author = {Motta, Enrico},
title = {Exploiting Large Scale Web Semantics to Build End User Applications},
year = {2008},
isbn = {9781595939876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378773.1378863},
doi = {10.1145/1378773.1378863},
abstract = {A large scale semantic web, already characterized by thousands of ontologies and millions of RDF documents, is now a reality and this rapidly growing resource is opening the way to a new generation of intelligent applications. In this talk I will show some work we have been doing on building end-user applications which exploit this unprecedented resource. In particular, I will show how large scale semantics can be used to try and enhance typical web-centric activities, such as web browsing, searching for information, and rating and reviewing consumer items.While most of this work is still at a rather early stage, it already provides evidence that the Semantic Web can be concretely used to bring new functionalities to the users. These positive results also show that it is possible to build intelligent and robust applications, while at the same time doing away with the traditional assumptions in knowledgebased systems, that the available domain knowledge has to be consistent, well-designed and high quality.},
booktitle = {Proceedings of the 13th International Conference on Intelligent User Interfaces},
pages = {442},
numpages = {1},
location = {Gran Canaria, Spain},
series = {IUI '08}
}

