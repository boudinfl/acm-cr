@inproceedings{10.1145/1842993.1842995,
author = {Keim, Daniel A. and Bak, Peter and Bertini, Enrico and Oelke, Daniela and Spretke, David and Ziegler, Hartmut},
title = {Advanced Visual Analytics Interfaces},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1842995},
doi = {10.1145/1842993.1842995},
abstract = {Advanced visual interfaces, like the ones found in information visualization, intend to offer a view on abstract data spaces to enable users to make sense of them. By mapping data to visual representations and providing interactive tools to explore and navigate, it is possible to get an understanding of the data and possibly discover new knowledge. With the advent of modern data collection and analysis technologies, the direct visualization of data starts to show its limitations due to limited scalability in terms of volumes and to the complexity of required analytical reasoning. Many analytical problems we encounter today require approaches that go beyond pure analytics or pure visualization. Visual analytics provides an answer to this problems by advocating a tight integration between automatic computation and interactive visualization, proposing a more holistic approach. In this paper, we argue for Advanced Visual Analytics Interfaces (AVAIs), visual interfaces in which neither the analytics nor the visualization needs to be advanced in itself but where the synergy between automation and visualization is in fact advanced. We offer a detailed argumentation around the needs and challenges of AVAIs and provide several examples of this type of interfaces.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {3–10},
numpages = {8},
keywords = {data mining, information visualization, knowledge discovery, visual analytics},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1842996,
author = {Lynch, Patrick J.},
title = {Aesthetics and Trust: Visual Decisions about Web Pages},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1842996},
doi = {10.1145/1842993.1842996},
abstract = {Eyetracking studies seem to suggest that users do not look at large expressive graphics on web pages [1,2], as seen in the relatively few gaze fixations such graphics attract from users in task-driven eyetracking studies. However, many studies show that users react in very fast important ways to the overall design of web pages, and that such reactions have a profound effect on user's judgments of the usability, aesthetic merit, and trustworthiness of web page designs [3,4].},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {11–15},
numpages = {5},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1842997,
author = {Wigdor, Daniel},
title = {Architecting Next-Generation User Interfaces},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1842997},
doi = {10.1145/1842993.1842997},
abstract = {Emerging technologies provide platforms for new devices, applications, and user interfaces. These technologies have shown potential in early research, but their true utility and measures of success lie in their ability to reflect and enhance the capabilities of the people who use them.My research seeks to address this problem by thoroughly examining and understanding humans, hardware, and software to create tools that enable users in new ways and meet real needs. In this talk, I will discuss both sides of the coin: the potential, and the limitations of emerging input technologies that require fundamentally different user interface designs to realize their full utility. With particular focus on the area of multi-touch and surface computing, I will describe how leveraging and mirroring human motor, cognitive, and social abilities and needs can produce interfaces that are both learnable and enabling of high-bandwidth communication between the user and the computer. Further, such leverage and reflection also ensures that the resulting tools solve real problems and enable their users in ways that a traditional mouse-based user interface do not.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {16–22},
numpages = {7},
keywords = {Keywords are your own designated keywords},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1842999,
author = {Luboschik, Martin and Radloff, Axel and Schumann, Heidrun},
title = {A New Weaving Technique for Handling Overlapping Regions},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1842999},
doi = {10.1145/1842993.1842999},
abstract = {The use of transparencies is a common strategy in visual representations to guarantee the visibility of different overlapping graphical objects, especially, if no visibility-deciding order is given (e.g., importance, depth). Alpha-blending, however, could generate new colors that are not specified by the given color scale and overlapping shapes may become difficult to be separated visually and the selection of specific elements would be difficult. In this paper, we present a new approach for representing overlapping regions: Instead of blending different colors, our weaving technique separates the original colors and shapes are easier to differentiate. Due to a deterministic weaving order, all overlapping objects are visible. We apply our approach to scatter plot visualizations to enhance the communication of overlapping clusters.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {25–32},
numpages = {8},
keywords = {information visualization, weaving, overlapping, interaction, transparency},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843000,
author = {Forlines, Clifton and Wittenburg, Kent},
title = {Wakame: Sense Making of Multi-Dimensional Spatial-Temporal Data},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843000},
doi = {10.1145/1842993.1843000},
abstract = {As our ability to measure the world around us improves, we are quickly generating massive quantities of high-dimensional, spatial-temporal data. In this paper, we concern ourselves with datasets in which the spatial characteristics are relatively static but many dimensions prevail and data is sampled over different time periods. Example applications include building energy management and HVAC unit diagnostics. We present methods employed in our Wakame visualization system to support such tasks as discovering anomalies and comparing performance across multiple time series. Novel methods include animated transitions that relate data in spatially located 3D views with conventional 2D graphs. Additionally, several components of our prototype employ analytics to guide the user to "interesting" portions of the dataset.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {33–40},
numpages = {8},
keywords = {visual analytics, infovis, multi-dimensional data, spatial-temporal data, radar graph},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843001,
author = {Wang, Xiaoyu and Janssen, Bill and Bier, Eric},
title = {Finding Business Information by Visualizing Enterprise Document Activity},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843001},
doi = {10.1145/1842993.1843001},
abstract = {In an enterprise environment, business information, such as project proposals and product discussions, is dynamic and often embedded in documents and document activities (e.g, emails, Web pages and office documents). Because this information is essential to business processes, corporate employees need an effective means to retrieve it. Some commercial products, including Google Desktop, provide keyword searches for finding some of this information. However, this approach is not always effective as successful keyword searches can be difficult to construct, and even the best queries may fail to find some important materials. In this paper, we present Taste (Temporal Activities and Story TElling), an interactive visual analytics system that enhances the enterprise employee's capabilities in searching and sharing diverse and dynamic business information. Taste was designed, after interviews with corporate employees, to follow their information retrieval cues and help them manage, review and share the business information embedded in their document activities. Results of our lab and field studies validate that Taste provides employees the confidence and necessary features to more efficiently and effectively retrieve business information from their documents and activities.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {41–48},
numpages = {8},
keywords = {collaboration, temporal information visualization, document management, personal information management},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843002,
author = {Tatu, Andrada and Bak, Peter and Bertini, Enrico and Keim, Daniel and Schneidewind, Joern},
title = {Visual Quality Metrics and Human Perception: An Initial Study on 2D Projections of Large Multidimensional Data},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843002},
doi = {10.1145/1842993.1843002},
abstract = {Visual quality metrics have been recently devised to automatically extract interesting visual projections out of a large number of available candidates in the exploration of high-dimensional databases. The metrics permit for instance to search within a large set of scatter plots (e.g., in a scatter plot matrix) and select the views that contain the best separation among clusters. The rationale behind these techniques is that automatic selection of "best" views is not only useful but also necessary when the number of potential projections exceeds the limit of human interpretation. While useful as a concept in general, such metrics received so far limited validation in terms of human perception. In this paper we present a perceptual study investigating the relationship between human interpretation of clusters in 2D scatter plots and the measures automatically extracted out of them. Specifically we compare a series of selected metrics and analyze how they predict human detection of clusters. A thorough discussion of results follows with reflections on their impact and directions for future research.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {49–56},
numpages = {8},
keywords = {visual quality metrics, user study},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843004,
author = {Riche, Nathalie Henry and Lee, Bongshin and Chevalier, Fanny},
title = {IChase: Supporting Exploration and Awareness of Editing Activities on Wikipedia},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843004},
doi = {10.1145/1842993.1843004},
abstract = {To increase its credibility and preserve the trust of its readers. Wikipedia needs to ensure a good quality of its articles. To that end, it is critical for Wikipedia administrators to be aware of contributors' editing activity to monitor vandalism, encourage reliable contributors to work on specific articles, or find mentors for new contributors. In this paper, we present iChase, a novel interactive visualization tool to provide administrators with better awareness of editing activities on Wikipedia. Unlike the currently used visualizations that provide only page-centric information. iChase visualizes the trend of activities for two entity types; articles and contributors. iChase is based on two heatmaps (one for each entity type) synchronized to one timeline. It allows users to interactively explore the history of changes by drilling down into specific articles and contributors, or time points to access the details of the changes. We also present a case study to illustrate how iChase can be used to monitor editing activities of Wikipedia authors, as well as a usability study. We conclude by discussing the strengths and weaknesses of iChase.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {59–66},
numpages = {8},
keywords = {Wikipedia visualization, timeline visualization, interaction},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843005,
author = {D\'{\i}az, Paloma and Aedo, Ignacio and Rosson, Mary Beth and Carroll, John M.},
title = {A Visual Tool for Using Design Patterns as Pattern Languages},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843005},
doi = {10.1145/1842993.1843005},
abstract = {Design patterns document successful solutions to recurrent problems in a specific software development domain. However, finding the patterns you need can be difficult, often requiring the designer to comprehend a long narrative description to understand the benefits, implications and trade-offs of each pattern and of its relationships with others. In this paper we propose a visual notation supported by a software tool that may help to identify patterns that could satisfy a designer's goals, as well as conveying the positive and negative relations among patterns, including dependencies and collisions among patterns selected for a specific problem. This work extends the concept of Softgoal Interdependency Graphs (SIG) enhancing them with a number of visual clues and interaction capabilities to help designers realize the contributions and trade-offs of their design ideas and the complexity of the solution space they are building up.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {67–74},
numpages = {8},
keywords = {visual languages, goal-based design, design patterns},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843006,
author = {Ardito, C. and Costabile, M. F. and Lanzilotti, R.},
title = {Gameplay on a Multitouch Screen to Foster Learning about Historical Sites},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843006},
doi = {10.1145/1842993.1843006},
abstract = {The use of gameplay has been shown to be an excellent educational tool, especially if such games are supported by innovative and engaging technologies. This paper presents two new games implemented on a large multitouch screen, designed to support young students learning about historical sites like archaeological parks during school visits. Students are encouraged to collaborate to solve the proposed challenges, but they can also play against each other, since direct competition is known to be another way to stimulate and reinforce learning. We believe that such games can make visits to historical sites more effective and exciting.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {75–78},
numpages = {4},
keywords = {multitouch, mobile system, learning game},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843008,
author = {McCrae, James and Glueck, Michael and Grossman, Tovi and Khan, Azam and Singh, Karan},
title = {Exploring the Design Space of Multiscale 3D Orientation},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843008},
doi = {10.1145/1842993.1843008},
abstract = {Recently, research in 3D computer graphics and interaction has started to move beyond the narrow domain of single object authoring and inspection, and has begun to consider complex multiscale objects and environments. This generalization of problem scope calls for more general solutions, which are more akin to information visualization techniques than traditional computer graphics approaches.We consider the general problem of the user's understanding of their position and orientation within a multiscale 3D scene and propose a classification of the design space. To ground this theoretical discussion, we present initial explorations into grouping techniques, visualizations, and interactions to facilitate multiscale 3D orientation.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {81–88},
numpages = {8},
keywords = {design space, visualization, 3D orientation, multiscale},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843009,
author = {Kritikos, Kyriakos and Patern\`{o}, Fabio},
title = {Task-Driven Service Discovery and Selection},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843009},
doi = {10.1145/1842993.1843009},
abstract = {Services are becoming more and more widely used. When designing interactive applications based on services one important issue is how to identify those services most relevant for the application functionalities. The proposed approach takes as input a task model, which includes the user's view of the interactive system, and an ontology capturing the application domain, and automatically discovers a set of ordered service descriptions for each system task of the model. The discovered descriptions can be used in order to invoke a particular service operation that fulfils a task's required functionality. In this way, the whole application functionality can be realized by a set of service operations without writing a single line of code. As a result, the application development time is significantly reduced and it is possible to complete the development of interactive front-ends by integrating our solution in existing model-based HCI approaches.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {89–92},
numpages = {4},
keywords = {service discovery, semantics, interactive service-based application design, service front-ends},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843010,
author = {Celentano, Augusto and Orsini, Renzo and Pittarello, Fabio},
title = {Towards an Environment for Designing and Evaluating Multimedia Art Guides},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843010},
doi = {10.1145/1842993.1843010},
abstract = {We discuss the design and implementation environment of a family of multimedia guides for art exhibitions on Apple iPod touch devices. The project aims at developing a unique framework adaptable to different content types and presentation styles, while retaining a common interface model with consistent gestures and a fast development process based on standard environments and toolkits. Evaluation is based on automatic collection of information about the user behavior by logging user actions.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {93–96},
numpages = {4},
keywords = {information access, rich multimedia content, Webkit},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843011,
author = {Hyakutake, Akito and Ozaki, Koichiro and Kitani, Kris Makoto and Koike, Hideki},
title = {3-D Interaction with a Large Wall Display Using Transparent Markers},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843011},
doi = {10.1145/1842993.1843011},
abstract = {In this paper we proposed a new interface for interacting with large displays via small video devices such as a cell phone. We estimate the location of the camera relative to the display using a matrix of transparent markers embedded on display. As a result, our interface allows the user to interact with digital contents without being distracted by opaque visual markers. Our interface enables intuitive interactions such as pointing, rotating, dragging and dropping. Moreover, our use of a small hand-held camera device allows for interaction with large scale displays without the need for direct contact with the display surface. Thus our system is well suited for interactions when there is some distance between the user and the display. Our proposed system has applications to large scale advertisement displays and can enable interactions between individuals and large scale digital content.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {97–100},
numpages = {4},
keywords = {LCD, transparent markers, vision-based HCI, marker, augmented reality, polarization, interaction, wall display},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843013,
author = {Convertino, Gregorio and Kairam, Sanjay and Hong, Lichan and Suh, Bongwon and Chi, Ed H.},
title = {Designing a Cross-Channel Information Management Tool for Workers in Enterprise Task Forces},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843013},
doi = {10.1145/1842993.1843013},
abstract = {This paper presents a research project on the design of a cross-channel information management tool for knowledge workers: we focus on IT services professionals in a large enterprise who work in multiple ad hoc task forces. Through three rounds of investigation, we characterized their work practices and needs, specified their requirements for a cross-channel information management tool, and designed and evaluated a prototype to address these needs. We found that these workers shared the problem of managing information across multiple channels, requiring better support for aggregating, filtering, and organizing this information. We report the requirements elicited and the prototypes built during the design process.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {103–110},
numpages = {8},
keywords = {CSCW, cross-channel, cross-media, enterprise, information management, task force, design},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843014,
author = {Bardram, Jakob E. and Fuglsang, Christina and Pedersen, Simon C.},
title = {CompUTE: A Runtime Infrastructure for Device Composition},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843014},
doi = {10.1145/1842993.1843014},
abstract = {In this paper, we present the idea of a composite device, which is one device made up of a composition of several separate devices working together in concert. We present the CompUTE architecture as a runtime infrastructure for device composition. This architecture is implemented in the CompUTE .net platform, which enables device composition between Windows XP devices based on an 'extended desktop' metaphor. We discuss how the CompUTE .net platform enables users to merge multiple computers into one composite device with an enlarged desktop area and several keyboards and mice. Each user is equipped with a unique cursor, which works across all connected devices and she can drag and drop any application window and files between the connected devices. User can also work collaboratively on the composite device. We reports from a usability study involving 24 participants who found the CompUTE .net platform very useful, easy to use, and easy to learn.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {111–118},
numpages = {8},
keywords = {composite device, co-located cooperation, distributed clipboard, control re-direction, application view re-direction},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843015,
author = {Martens, Jean-Bernard and Parthesius, Frans and Atasoy, Berke},
title = {Design TeamMate: A Platform to Support Design Activities of Small Teams},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843015},
doi = {10.1145/1842993.1843015},
abstract = {Traditional desktop computers are known to offer insufficient functionality to designers. They are often complemented by pen-based tablet devices in order to better support key activities such as sketching and modeling. However, even such extended systems are restricted, as they insufficiently support other key activities of individual designers and design teams, such as collecting and sorting inspirational material, viewing and manipulating 3D models, brainstorming, discussing or presenting. Advanced visual interfaces, such as augmented surfaces, have been proposed as being potentially complimentary in this respect, as they can support multi-user interaction, bimanual interaction (even in 3D), and a better integration between physical and digital media. In this paper, we present Design TeamMate, a system in which individual workstations of designers are fluently integrated with an augmented tabletop and wall display. We discuss how this platform can support a wide range of individual and group design activities.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {119–126},
numpages = {8},
keywords = {face-to-face collaboration, design environment, tabletop, augmented surfaces},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843016,
author = {Tsujita, Hitomi and Tsukada, Koji and Kambara, Keisuke and Siio, Itiro},
title = {Complete Fashion Coordinator: A Support System for Capturing and Selecting Daily Clothes with Social Networks},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843016},
doi = {10.1145/1842993.1843016},
abstract = {For some people, selecting the clothes you wear is sometimes tedious, difficult and requires you to remember what you have previously worn. While there are many fashion SNS (Social Networking Services) sites and related research devoted to addressing certain aspects of this issue, there is no system that combines both the automated cataloguing of one's own clothes with near real-time recommendation by their social network. In this paper, we propose a novel system which allows users to easily organize and optimize their daily clothing selection based on historical data. By combining historical information about what the user has worn with several options such as the user's planned activities and the weather, it can help the user in coordinating what to wear. In order to simplify and automate the capture, storage and cataloging of image of the users clothing, we propose a system which allows for the automatic and standardized capturing of a person's clothes by simply hanging an item on a hook built into a cabinet. Furthermore, by utilizing the internet and common SNS sites, it allows friends, family living apart and/or romantic couples to seamlessly share the catalogued photos of their clothes, initiate conversation and help select what is appropriate to wear.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {127–132},
numpages = {6},
keywords = {fashion coordination, recommendation, social network, communication},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843017,
author = {Ginige, Athula and Paolino, Luca and Sebillo, Monica and Shrodkar, Richa and Vitiello, Giuliana},
title = {User Requirements for a Web Based Spreadsheet-Mediated Collaboration},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843017},
doi = {10.1145/1842993.1843017},
abstract = {This paper reports the initial results of a research project to investigate how to develop a web based spreadsheet mediated business collaboration system that could notably enhance the business processes presently carried out by Small to Medium sized Enterprises. Using a scenario-based design approach, a set of user's requirements were extracted from an appropriate field study. These requirements were then analysed in the context of well-known usability principles, and a set of design implications were derived based on a selected set of HCI design patterns related to cooperative interaction design. Starting from that knowledge, suitable interactive collaboration scenarios have been drawn, from which a list of user interface requirements for a web based spreadsheet mediated collaboration system has been formulated.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {133–136},
numpages = {4},
keywords = {artifact mediated collaboration, usability principles, HCI design patterns, scenario-based design},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843019,
author = {Bader, Thomas and Heck, Astrid and Beyerer, J\"{u}rgen},
title = {Lift-and-Drop: Crossing Boundaries in a Multi-Display Environment by Airlift},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843019},
doi = {10.1145/1842993.1843019},
abstract = {Many of the interactive environments surrounding us today consist of multiple mobile and/or stationary visual displays. However, interaction with such multi-display environments is still dominated by the personal computer paradigm - one user interacts with one single display at a time.In this paper first we present a new video-based input device called Airlift, which captures hands and fingertips independent from any display and therefore allows for consistent interaction across display boundaries. Second, we propose a system architecture for interaction spanning multiple displays. Third, we start to explore this new design space by proposing and evaluating a new interaction technique Lift-and-Drop for copying data from one display to another.According to the results of our study for the task considered the new technique is superior to other techniques based on traditional direct input devices which are limited to the surface of single displays like pen or touch.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {139–146},
numpages = {8},
keywords = {gesture-based interaction, multi-display multi-user environments},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843020,
author = {Tsandilas, Theophanis and Mackay, Wendy E.},
title = {Knotty Gestures: Subtle Traces to Support Interactive Use of Paper},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843020},
doi = {10.1145/1842993.1843020},
abstract = {We introduce the knotty gesture, a simple yet powerful technique for interacting with paper. Knots are tiny circles that can be added to any gesture. Users can leave subtle marks that permit both immediate interaction in the flow of writing and create rich opportunities for future interaction. We identify diverse applications of knotty gestures and explore alternative techniques for interacting with their traces. We conducted two experiments to evaluate the design and recognition heuristics and demonstrated that people can successfully execute knotty gestures, even without feedback. Knotty gestures provide users with a subtle, in-the-flow-of-writing technique for tagging information and subsequently interacting with the paper.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {147–154},
numpages = {8},
keywords = {pen gestures, interactive paper, tangible interfaces},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843021,
author = {Samp, Krystian and Decker, Stefan},
title = {Supporting Menu Design with Radial Layouts},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843021},
doi = {10.1145/1842993.1843021},
abstract = {One of the ways of decreasing selection times in displayed menus is through the use of radial layouts which shorten distances to the items and increase the item sizes. Previous work on radial menus does not demonstrate that radial layouts are beneficial for menu hierarchies. The paper focuses on this topic.We compare two main characteristics of radial and linear layouts: a) the time it takes to find an item (i.e. visual search time), b) the time it takes to navigate to an item (i.e. pointing time). We use objective and subjective measures, two menu sizes, three menu levels, one linear and three radial layout variations.We also present requirements and the Compact Radial Layout (CRL) design which supports menu hierarchies. We assess its performance for novice and expert users.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {155–162},
numpages = {8},
keywords = {menus, radial layout},
location = {Roma, Italy},
series = {AVI '10}
}

@dataset{10.1145/review-1842993.1843021_R47307,
author = {Brooks, Andrew},
title = {Review ID:R47307 for DOI: 10.1145/1842993.1843021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1842993.1843021_R47307}
}

@inproceedings{10.1145/1842993.1843022,
author = {Qin, Yongqiang and Shi, Yuanchun and Jiang, Hao and Yu, Chun},
title = {Structured Laser Pointer: Enabling Wrist-Rolling Movements as a New Interactive Dimension},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843022},
doi = {10.1145/1842993.1843022},
abstract = {In this paper, we re-visit the issue of multi-point laser pointer interaction from a wrist-rolling perspective. Firstly, we proposed SLP---Structured Laser Pointer, and detects a laser pointer's rotation along its emitting axis. SLP adds the wrist-rolling gestures as a new interactive dimension to the conventional laser pointer interaction approach. We asked a group of users to perform certain tasks using SLP, and derived from test results a set of criteria to distinguish between incidental and intentional SLP rolling, and then the experimental results also approved the high accuracy and acceptable speed as well as throughput of such rolling interaction.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {163–166},
numpages = {4},
keywords = {wrist-rolling movements, structured laser pointer, performance exploration},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843023,
author = {van Schooten, Boris W. and van Dijk, Elisabeth M. A. G. and Zudilova-Seinstra, Elena and Suinesiaputra, Avan and Reiber, Johan H. C.},
title = {The Effect of Stereoscopy and Motion Cues on 3D Interpretation Task Performance},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843023},
doi = {10.1145/1842993.1843023},
abstract = {We study the effectiveness of stereoscopy and smooth motion as 3D cues for medical interpretation of vascular structures as obtained by 3D medical imaging techniques. We designed a user study where the user has to follow a path in a mazelike solid shaded 3D structure. The user controls rotation of the model. We measure user performance in terms of time taken and error rate. The experiment was executed with 32 (medical and non-medical) users. The results show that motion cue is more important than stereoscopy, and that stereoscopy has no added value when motion is already present, which is not consistent with previous experiments.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {167–170},
numpages = {4},
keywords = {motion cue, angiography, graphics, stereoscopy, medical visualization},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843025,
author = {Francone, J\'{e}r\'{e}mie and Bailly, Gilles and Lecolinet, Eric and Mandran, Nadine and Nigay, Laurence},
title = {Wavelet Menus on Handheld Devices: Stacking Metaphor for Novice Mode and Eyes-Free Selection for Expert Mode},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843025},
doi = {10.1145/1842993.1843025},
abstract = {This paper presents the design and evaluation of the Wavelet menu and its implementation on the iPhone. The Wavelet menu consists of a concentric hierarchical Marking menu using simple gestures. The novice mode, i.e. when the menu is displayed, is well adapted to the limited screen space of handheld devices because the representation of the menu hierarchy is inverted, the deeper submenu being always displayed at the center of the screen. The visual design is based on a stacking metaphor to reinforce the perception of the hierarchy and to help users to quickly understand how the technique works. The menu also supports submenu previsualization, a key property to navigate efficiently in a hierarchy of commands. The quantitative evaluation shows that the Wavelet menu provides an intuitive way for supporting efficient gesture-based navigation. The expert mode, i.e. gesture without waiting for the menu to pop-up, is another key property of the Wavelet menu: By providing stroke shortcuts, the Wavelet favors the selection of frequent commands in expert mode and makes eyes-free selection possible. A user experiment shows that participants are able to select commands, eyes-free, while walking.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {173–180},
numpages = {8},
keywords = {handheld devices, menu techniques, wave menus},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843026,
author = {Pini, Stefano and Han, Sangmok and Wallace, David R.},
title = {Text Entry for Mobile Devices Using Ad-Hoc Abbreviation},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843026},
doi = {10.1145/1842993.1843026},
abstract = {This paper presents a new method for improving the number of keystrokes and time required for text entry on mobile devices using ad-hoc abbreviations. The approach is easy-to-use because: users are not required to learn any pre-defined abbreviation rules; abbreviated input phrases are automatically detected and expanded; and it is possible to recover words that may be omitted from phrases either by accident or intention. The paper develops algorithms to detect abbreviated phrases using a Support Vector Machine trained on abbreviation examples and to expand abbreviations into complete phrases using a Hidden Markov Model learned from a text corpus. The abbreviation detector was evaluated on 3,000 word-abbreviation pairs and achieved 90% accuracy. The abbreviation expander was evaluated on 100,000 phrases and achieved 95% accuracy. A user study with 10 participants was performed to measure time and keystroke savings of the new approach compared to the existing iPhone® text entry system. Keystroke savings were consistent amongst users, with an average decrease of 32%. Time for input varied considerably depending on familiarity with the approach, increasing for novice users. However, experienced users achieved an average time saving of 26%. Observations suggest that novice users were spending time thinking about how they wanted to abbreviate words.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {181–188},
numpages = {8},
keywords = {abbreviation, mobile devices, Hidden Markov model, text input, auto-completion, support vector machine},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843027,
author = {Sareika, Markus and Schmalstieg, Dieter},
title = {Bimanual Handheld Mixed Reality Interfaces for Urban Planning},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843027},
doi = {10.1145/1842993.1843027},
abstract = {Tabletop models are common in architectural and urban planning tasks. We report here on an investigation for view navigation in and manipulation of tracked tabletop models using a handheld Mixed Reality interface targeted at a user group with varying professional background and skill level. Users were asked to complete three basic task types: searching, inserting and creating content in a mixed reality scene, each requiring the user to navigate in the scene while interacting. This study was designed to naturally progress on classic problems like travel, selection and manipulation in an applied scenario concerned with urban planning. The novel bimanual interface configurations utilize a handheld touch screen display for Mixed Reality, with the camera/viewpoint attached or handheld separately. Usability aspects and user satisfaction are scrutinized by a user study, aimed at optimizing usability and supporting the user's intentions in a natural way. We present the results from the user study showing significant differences in task completion times as well as user preferences and practical issues concerning both interface and view navigation design.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {189–196},
numpages = {8},
keywords = {mixed reality, Urban planning, 3D interaction, augmented reality, architecture, design, bimanual interaction},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843029,
author = {Forsell, Camilla and Johansson, Jimmy},
title = {An Heuristic Set for Evaluation in Information Visualization},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843029},
doi = {10.1145/1842993.1843029},
abstract = {Evaluation is a key research challenge within the international Information Visualization (InfoVis) community, and Heuristic Evaluation is one recognized method. Various sets of heuristics have been proposed but there remains no consensus as to which heuristics are most useful for addressing aspects specific to the complex interactive visual displays used in modern InfoVis systems. This paper presents a first effort to empirically determine a new set of such general heuristics tailored for Heuristic Evaluation of common and important usability problems in InfoVis techniques. Participants in the study rated how well a total of 63 heuristics from 6 earlier published heuristic sets could explain a collection of 74 usability problems derived from earlier InfoVis evaluations. The results were used to synthesize 10 heuristics that, as a set, provided the highest explanatory coverage. The paper also stresses the challenges for future research to validate and further improve upon this set.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {199–206},
numpages = {8},
keywords = {heuristic evaluation, information visualization, heuristics},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843030,
author = {Wessel, Ginette and Ziemkiewicz, Caroline and Chang, Remco and Sauda, Eric},
title = {GPS and Road Map Navigation: The Case for a Spatial Framework for Semantic Information},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843030},
doi = {10.1145/1842993.1843030},
abstract = {Urban environments require cognitive abilities focused on both spatial overview and detailed understanding of uses and places. These abilities are distinct but overlap and reinforce each other. Our work quantitatively and qualitatively measures the effects on a user's overall understanding of the environment after navigating with either a GPS or a road map in a previously unknown neighborhood. Experimental recall of spatial and semantic information indicates that using a road map enables subjects to demonstrate a significantly better spatial understanding, identify semantic elements more often using common terms, place semantic elements in spatial locations with greater accuracy and recall semantic elements in tighter clusters than when using a GPS. We conclude that a spatial understanding is a necessary framework for organizing semantic information that is useful for inferred tasks.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {207–214},
numpages = {8},
keywords = {spatial information, semantic information, navigation},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843031,
author = {Ziemkiewicz, Caroline and Kosara, Robert},
title = {Implied Dynamics in Information Visualization},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843031},
doi = {10.1145/1842993.1843031},
abstract = {Information visualization is a powerful method for understanding and working with data. However, we still have an incomplete understanding of how people use visualization to think about information. We propose that people use visualization to support comprehension and reasoning by viewing abstract visual representations as physical scenes with a set of implied dynamics between objects. Inferences based on these implied dynamics are metaphorically extended to form inferences about the represented information. This view predicts that even seemingly meaningless properties of a visualization, including such minor design elements as borders, background areas, and the connectedness of parts, may affect how people perceive semantic aspects of data by suggesting different potential dynamics between data points. We present a study that supports this claim and discuss the design implications of this theory of information visualization.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {215–222},
numpages = {8},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843033,
author = {Gomi, Ai and Itoh, Takayuki},
title = {MIAOW: A 3D Image Browser Applying a Location- and Time-Based Hierarchical Data Visualization Technique},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843033},
doi = {10.1145/1842993.1843033},
abstract = {Browsing techniques for large image collections become increasingly important for locating and retrieving images. We had a questionnaire result saying that many photograph collectors think that time and location are useful information to organize, browse, and retrieve images. This paper proposes MIAOW (Memorized Image Album Organized by When/Where); a 3D image browser which represents hierarchically categorized photographs based on their shooting locations and times. MIAOW utilizes a 3D space with an orthogonal coordinate system to place a set of photographs; it assigns two axes to the shooting locations of the photographs, and the other axis to their shooting time. Supposing that all images have shooting locations (longitudes and latitudes) and times, MIAOW hierarchically categorizes the set of images in preprocessing step. MIAOW then places all clusters of the images onto the XY-plane of the 3D space as nested rectangular regions, while it attempts to avoid overlapping, minimize the occupied area, and reflect the locations. It also places the same set of clusters onto the XZ- and YZ-planes. avoids any overlaps, minimizes the occupied area, and reflects the time and result of the placement on XY-plane. MIAOW provides an orientation and zooming user interface, so that users can use to easily navigate between location and time spaces and zoom into interested clusters of photographs. This paper demonstrates our user experiments showing that the users required less time to search for specific photographs by using MIAOW rather than using an existing browser.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {225–232},
numpages = {8},
keywords = {information visualization, hierarchical data, image browser},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843034,
author = {Hurter, Christophe and Serrurier, Mathieu and Alonso, Roland and Tabart, Gilles and Vinot, Jean-Luc},
title = {An Automatic Generation of Schematic Maps to Display Flight Routes for Air Traffic Controllers: Structure and Color Optimization},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843034},
doi = {10.1145/1842993.1843034},
abstract = {Aircraft must follow strict Air Traffic Control (ATC) rules. One of these rules is that aircraft have to fly over pre-defined Flight Routes (FR). Current ATC visualizations do not display FRs because they are numerous and run into each other, and thus spoil the visualization. The schematic views for metro maps are used to maximize the transmission of relevant information (lines, metro stops) of network visualization. In this paper, we will focus on two different issues. First, we show how we transposed mathematical constraints used to produce metro maps into the specific field of ATC. The view produced is a context compatible, 2D picture of a schematic maps view for Air Traffic Control. Second, we propose to investigate the generation and placement of colors to be assigned to lines of the network. The first step is to find as many colors as lines of the network. These colors must be perceptually as distinct as possible, and available in the vocabulary of colors. The second step is to solve the NP-complete problem of the optimal assignment of these colors so that close lines have the most perceptively distant color. Finally, we assess the map produced through experimentation to validate its quality.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {233–240},
numpages = {8},
keywords = {schematic maps, colors assignment, air traffic controller, visualization},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843035,
author = {Kim, Nam Wook and Card, Stuart K. and Heer, Jeffrey},
title = {Tracing Genealogical Data with TimeNets},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843035},
doi = {10.1145/1842993.1843035},
abstract = {We present TimeNets, a new visualization technique for genealogical data. Most genealogical diagrams prioritize the display of generational relations. To enable analysis of families over time, TimeNets prioritize temporal relationships in addition to family structure. Individuals are represented using timelines that converge and diverge to indicate marriage and divorce; directional edges connect parents and children. This representation both facilitates perception of temporal trends and provides a substrate for communicating non-hierarchical patterns such as divorce, remarriage, and plural marriage. We also apply degree-of-interest techniques to enable scalable, interactive exploration. We present our design decisions, layout algorithm, and a study finding that TimeNets accelerate analysis tasks involving temporal data.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {241–248},
numpages = {8},
keywords = {timelines, genealogy, visualization, TimeNets},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843036,
author = {Buono, Paolo and Simeone, Adalberto L.},
title = {Video Abstraction and Detection of Anomalies by Tracking Movements},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843036},
doi = {10.1145/1842993.1843036},
abstract = {The increasing adoption of video surveillance makes it possible to watch over sensitive areas and identify people responsible for damage, theft and violence. However, when such events are not detected immediately, the subsequent video analysis can be a long and tedious task. The aim of this paper is to present a technique that allows a human investigator to focus only on those parts of a video showing the event as it unfolds, and so helping to save on the time needed to identify and understand how it happened. The presented technique creates a single interactive image of the whole video that shows everything that happened m the scene. The human investigator can then select an area of interest and those parts of the video related to that specific area will start to play.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {249–252},
numpages = {4},
keywords = {video abstraction, visual analytics, video analysis},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843037,
author = {Wittenburg, Kent},
title = {Setting the Bar for Set-Valued Attributes},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843037},
doi = {10.1145/1842993.1843037},
abstract = {In this paper, we present an interactive visualization method for set-valued attributes that maintains the advantages of item-oriented views and interactions found in parallel multivariate visualizations such as bargrams (equal-height histograms). The challenge is to accommodate renderings of an item when it appears multiple times in set-valued attribute views while at the same time preserving value- and item-based selection, brushing, and filtering. Such techniques can help users derive particular types of insights into data based on distributions and correlations of attribute values.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {253–256},
numpages = {4},
keywords = {multivariate visualization, information visualization, set-valued attributes},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843039,
author = {Tu, Ying},
title = {Multi-Con: Exploring Graphs by Fast Switching among Multiple Contexts},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843039},
doi = {10.1145/1842993.1843039},
abstract = {Focus+Context is a popular and effective technique for graph exploration. While previous works concentrate on studying how to display focal nodes with a single context, we argue that it is often difficult to select an optimal context for a complex graph exploration task in practice. In this paper, we propose Multi-Con, a technique to allow users viewing multiple contexts to explore graphs more effectively and efficiently. Our idea is to let users define multiple contexts to reveal different aspects of the graph and enable users to switch between these contexts quickly and interactively in a single view during exploration. Multi-Con provides two key features to ensure the effectiveness and efficiency when using multiple contexts for graph exploration. First, it can achieve good legibility when displaying foci with each context in limited viewing space. In addition, it allows users to switch between contexts smoothly and quickly. We have conducted a case study with social network data extracted from paper authorship relations on three major conferences in computer architecture and systems areas. The results have shown that Multi-Con can help users quickly learn the relationship between foci and the rest of the network in multiple aspects.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {259–266},
numpages = {8},
keywords = {information visualization, graph layout adjustment, graph exploration, focus+context},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843040,
author = {Fukuchi, Kentaro and Sato, Toshiki and Mamiya, Haruko and Koike, Hideki},
title = {Pac-Pac: Pinching Gesture Recognition for Tabletop Entertainment System},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843040},
doi = {10.1145/1842993.1843040},
abstract = {We present our new interaction technique for tabletop system and video game application using it. This technique is for recognizing a pinching gesture performed with the thumb and forefinger and tapping gestures with them by a ceiling camera above the table. The positions and orientations of multiple gestures are recognized at 200Hz, and the users around the table are tracked by their arm positions. This technique is useful for large-sized tabletop system for multiple users because it does not require any additional equipments to them nor registration process before using the system. Some pilot studies demonstrated the robustness and accuracy of the proposed technique with displaying appropriate guide on the display. We also developed a video game application called "Pac-pac". A player can shoot a bullet along the orientation of his hand by tapping, from any side of the table. We exhibited Pac-pac several time and well-received.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {267–273},
numpages = {7},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843041,
author = {De Carolis, Berardina and Mazzotta, Irene and Novielli, Nicole and Pizzutilo, Sebastiano},
title = {Social Robots and ECAs for Accessing Smart Environments Services},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843041},
doi = {10.1145/1842993.1843041},
abstract = {As far as interaction is concerned Ambient Intelligence (AmI) research emphasizes the need of natural and friendly interfaces for accessing services provided by the environment. In this paper we present the result of an experimental study aiming at understanding whether Embodied Conversational Agents (ECAs) and Social Robots may improve the naturalness and effectiveness of interaction by playing different roles when acting as interface between users and smart environment services. Results obtained so far show that ECAs seem to have a better evaluation than robots for information related tasks. On the other side, Social Robots are preferred for welcoming people and for guiding them in the smart environment, due to their possibility to move and to the perceived sense of presence. Moreover, the robot seems to elicit a more positive evaluation in terms of user experience.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {275–278},
numpages = {4},
keywords = {animated interfaces, interface evaluation},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843043,
author = {Tobita, Hiroaki},
title = {Comic Engine: Interactive System for Creating and Browsing Comic Books with Attention Cuing},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843043},
doi = {10.1145/1842993.1843043},
abstract = {Comic Engine is an interactive comic creation system that uses a unique Attention Cuing technique. Our system focuses on both comic creation and comic browsing. To enhance both functions, we use a unique Attention Cuing technique, which is a kind of comic grammar, and is used to control the reader's viewpoint by professional comic creators. This technique is common for comic creators; therefore, we integrated it with comic creation to create more practical comic books. Both functions based on Attention Cuing are simple. However, users can depict a wide variety of comic content using simple interactions of the graphical user interface. We describe a prototype of the Comic Engine system, focusing on the design features and efficiencies.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {281–288},
numpages = {8},
keywords = {attention cuing, interactive system, communication, browsing, visualization technique, creation, animation, comic},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843044,
author = {Meskens, Jan and Luyten, Kris and Coninx, Karin},
title = {Jelly: A Multi-Device Design Environment for Managing Consistency across Devices},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843044},
doi = {10.1145/1842993.1843044},
abstract = {When creating applications that should be available on multiple computing platforms, designers have to cope with different design tools and user interface toolkits. Incompatibilities between these design tools and toolkits make it hard to keep multi-device user interfaces consistent. This paper presents Jelly, a flexible design environment that can target a broad set of computing devices and toolkits. Jelly enables designers to copy parts of a user interface from one device to another and to maintain the different user interfaces in concert using linked editing. Our approach lowers the burden of designing multi-device user interfaces by eliminating the need to switch between different design tools and by providing tool support for keeping the user interfaces consistent across different platforms and toolkits.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {289–296},
numpages = {8},
keywords = {GUI builder, design tools, multi-platform GUI design},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843045,
author = {Ishihara, Makio and Ishihara, Yukio},
title = {A Reflex in Eye-Hand Coordination for Calibrating Coordinates of a Tabletop Display},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843045},
doi = {10.1145/1842993.1843045},
abstract = {This manuscript introduces a technique for pointing on large tabletop displays for collaborative work. In an environment of large tabletop displays, some contents might be out of the users' reach and the coordinates of the screen might not be aligned with the users' positions. A reflex in eye-hand coordination is a natural response to inconsistency between kinetic information of a mouse and visual feedback of the mouse cursor. The reflex yields information on which side the user sees the screen from, so that the coordinates of the screen are aligned with the user's position. Once the coordinates of the screen are aligned, the user can manipulate the mouse cursor in a usual manner.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {297–300},
numpages = {4},
keywords = {tabletop display, reflex, screen calibration, eye-hand coordination},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843047,
author = {Jugel, Uwe},
title = {Visual, in-Place Data Flow Modeling},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843047},
doi = {10.1145/1842993.1843047},
abstract = {The graphical UI-builder is a type of tool that has been implemented for many programming frameworks and programming languages, and it utilizes many useful and intuitive concepts facilitating easy UI-modeling and thus faster development of applications. In this paper we identify a problem of the separated design-view/data-view concept that is used in many GUI-builders, and we propose a solution to these problems. We present an approach that leverages visual, in-place, data flow modeling, making data flow modeling within UI-builders more efficient than in classic UI-builders and also, more efficient than in state-of-the-art presentation-oriented end-user modeling approaches.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {303–306},
numpages = {4},
keywords = {graphical modeling, end-user development, visual programming, data visualization},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843048,
author = {Fogli, Daniela and Provenza, Loredana Parasiliti and Bernareggi, Cristian},
title = {A Design Pattern Language for Accessible Web Sites},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843048},
doi = {10.1145/1842993.1843048},
abstract = {Dynamic web sites and rich internet applications have recently got widespread. An important challenge is guaranteeing their accessibility to all potential users regardless of physical and cognitive disabilities as well as hardware and software limitations. To this aim, WCAG 2.0 guidelines have been released as the newest W3C recommendation for accessible web content, and WAI-ARIA are reference specifications for accessible rich internet applications. However, both design resources contain a huge amount of information, and, like all standards and guidelines, do not provide designers with a clear design method. This paper proposes a design pattern language for accessibility to help web designers create accessible rich internet applications compliant with the most recent standards. The language has been implemented as an accessible rich internet application itself, allowing designers with disabilities to participate in web design. The results of a preliminary evaluation are finally discussed.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {307–310},
numpages = {4},
keywords = {accessibility, rich internet application, design pattern},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843049,
author = {Pittarello, Fabio},
title = {An Architecture and a Visual Interface for Tagging the 3D Web},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843049},
doi = {10.1145/1842993.1843049},
abstract = {Content classification performed by end users is spreading through the web. Most of the work done so far is related to the hypermedia web. In spite of that, there is a growing mass of 3D content that is not associated to high-level information. This situation prevents any advanced use of the data available, such as searching, extraction or automatic manipulation of such content. In the last few years there have been a number of approaches for adding metadata to 3D content, but most of them use a top-down, designer driven, classification. This work proposes a different approach based on a bottom-up, user driven, classification. A web based architecture for tagging and browsing 3D objects and worlds is presented and applied to a case study related to the cultural heritage domain.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {311–315},
numpages = {5},
keywords = {virtual reality, X3D, folksonomy, tag representation, social tagging},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843050,
author = {Bedn\'{a}rek, David and Dokulil, Ji\v{r}\'{\i} and Yaghob, Jakub and Zavoral, Filip},
title = {MetroNG: Multimodal Interactive Scheduling Interface},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843050},
doi = {10.1145/1842993.1843050},
abstract = {Scheduling of lectures at a large university or a college is a complex and specialized task with many rules but no ideal solution and no formal model and quality measure for the result. This prevents the use of any automated scheduling system, requiring each lecture to be scheduled by humans. This paper describes the MetroNG application -- a visual interactive tool for multiparametric multidimensional scheduling, which we created to address the complex issues of scheduling at universities.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {317–320},
numpages = {4},
keywords = {data visualization, interactive scheduling},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843051,
author = {Schwartze, Veit and Blumendorf, Marco and Albayrak, Sahin},
title = {Adjustable Context Adaptations for User Interfaces at Runtime},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843051},
doi = {10.1145/1842993.1843051},
abstract = {The definition of different variants of a user interface at design time does not seem to be flexible enough to address future needs. Context sensitivity, user preferences and unforeseen situations require new means for automatic adaptation at runtime and mechanisms for user interventions within these adaptations. In our work we aim at the utilization of models at runtime to create user interfaces that are aware of their state and the meaning behind. An important part of this approach is a layout model that constrains and eventually defines the presentation of the user interface. The model contains statements about the orientation and size of the user interface elements that generate a constraint system at runtime to calculate the layout of the interface. Based on this model we provide mechanisms for the automatic calculation of user interface layouts as well as (meta) user interface that allows the user to intervene and adjust the layout to personal preferences.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {321–324},
numpages = {4},
keywords = {constraint generation, smart environments, end-user development, human-computer interaction, context-of-use, adaptation, layouting},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843052,
author = {Monigatti, Paul and Apperley, Mark and Rogers, Bill},
title = {Power and Energy Visualization for the Micro-Management of Household Electricity Consumption},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843052},
doi = {10.1145/1842993.1843052},
abstract = {The paper describes a pilot system for the detailed management of domestic electricity consumption aimed at minimizing demand peaks and consumer cost. Management decisions are made both interactively by consumers themselves, and where practical, automatically by computer. These decisions are based on realtime pricing and availability information, as well as current and historic usage data. The benefits of the energy strategies implied by such a system are elaborated, showing the potential for significant peak demand reduction and slowing of the need for growth in generation capacity. An overview is provided of the component technologies and interaction methods we have designed, but the paper focuses on the communication of real-time information to the consumer through a combination of specific and ambient visualizations. There is a need for both overview information (eg how much power is being used right now; how much energy have we used so far today; what does it cost?) and information at the point-of-use (is it OK to turn this dryer on now, or should I wait until later?). To assist the design of these visualizations, a survey is underway aimed at establishing people's understanding of power and energy concepts.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {325–328},
numpages = {4},
keywords = {domestic technology, information visualization, ambient visualization, domestic energy consumption, demand-side load management},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843054,
author = {Mazzola, Luca and Mazza, Riccardo},
title = {An Infrastructure for Creating Graphical Indicators of the Learner Profile by Mashing up Different Sources},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843054},
doi = {10.1145/1842993.1843054},
abstract = {The procedures to collect information about users are well known in computer science till long time. They range from getting explicit information from users, required in order to enable some functionalities, to the gathering of user behaviors, collected as log files generated by software applications. In the field of Technology Enhanced Learning the creation of a user profile is necessary in order to fulfill some didactical tasks, such as measuring the degree of participation to a course, or the performance on quizzes and assignments. The task of collecting students' data is normally performed by Learning Management Systems, which also provide with a way to explore this data. Our approach extends the information that models user profiles in Learning Management Systems with data coming from other online resources, such as social network websites. In this paper, we describe our idea of opening the learners' profile, eventually for integrating it with external on-line resources. The ultimate goal of our work is to create graphical indicators for the profile of the learners that take into account internal and external user data, in order to have a more complete and comprehensive view of user behaviors in Learning Management Systems.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {329–332},
numpages = {4},
keywords = {MashUp, open learner models, life long learning},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843055,
author = {Collomb, Maxime and Hasco\"{e}t, Mountaz},
title = {Synchronous Cooperation and Visualization for Social Bookmarking Systems},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843055},
doi = {10.1145/1842993.1843055},
abstract = {In this paper, our aim is to facilitate synchronous and co-present interaction with social bookmarking systems for groups of related users meeting to discuss and share their collections of tags and bookmarks. Our work results in a system called Orchis that proposes a graphical user interface based on cooperative visualization and interaction as an alternative graphical user interface for social bookmarking systems. Orchis presents three major characteristics: (1) graphical overviews of collections of annotated bookmarks and tags, (2) advanced drag-and-drop interaction styles adaptable to distributed display environments and (3) support for distributed architectures possibly running different windowing systems. Our hypothesis is that by using Orchis, related users will be able to better compare and share tags and bookmarks. They will also be able to build cooperatively valuable shared collections. We expect that, in turn, this will participate in improving the overall quality of both folksonomies and social bookmarking collections.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {333–336},
numpages = {4},
keywords = {group and organization interfaces, distributed display environments, synchronous cooperative systems, adaptable systems, social bookmarking, heterogeneity, new interaction techniques and devices},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843056,
author = {G\"{o}bel, Sebastian and Geiger, Christian and Heinze, Christin and Marinos, Dionysios},
title = {Creating a Virtual Archery Experience},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843056},
doi = {10.1145/1842993.1843056},
abstract = {In this paper we describe the design of a virtual reality simulator for traditional intuitive archery. Traditional archers aim without a target figure. Good shooting results require an excellent body-eye coordination that allows the user to perform identical movements when drawing the bow. Our simulator provides a virtual archery experience and supports the user to learn and to practice the motion sequence of traditional archery in a virtual environment. We use a low-cost tracking system to capture the user's motion in order to correct his movement. To provide a realistic haptic feedback a real bow is used as interaction device. Our system should provide a believable user experience and support the user to learn how to shoot in the traditional way. Following a user-centered iterative design approach we developed a number of prototypes and evaluated them for refinement in sequent iteration cycles.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {337–340},
numpages = {4},
keywords = {3D interaction, user experience, user centred design, VR archery, interactive sport simulation},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843057,
author = {Christiernin, Linn Gustavsson and Martin, Anneli},
title = {A Multi-Layered Aesthetical Web-Portal Interface for Governmental Integration Issues},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843057},
doi = {10.1145/1842993.1843057},
abstract = {The County Administrative Board, a governmental authority in The West Region of Sweden, has in collaboration with the local Counties asked us for advice in presenting information in an official and simple way on the web for the foreign person or refugee, just arrived in Sweden. Administrator officers and social workers are taking part in their introduction. In this paper, we describe our investigation and study in how to present a web design for a "newcomer" in Sweden through a multi-Layered design concept, a kind of design which will interact with each person"s needs. In this multipurpose concept and portal, it has been important to consider aesthetical values, layout and graphic design. It has also been important to design a layout that provides different users with different contents.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {341–344},
numpages = {4},
keywords = {multi-layered design and aesthetical values, web-interface},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843058,
author = {Stellmach, Sophie and Nacke, Lennart and Dachselt, Raimund},
title = {3D Attentional Maps: Aggregated Gaze Visualizations in Three-Dimensional Virtual Environments},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843058},
doi = {10.1145/1842993.1843058},
abstract = {Gaze visualizations hold the potential to facilitate usability studies of interactive systems. However, visual gaze analysis in three-dimensional virtual environments still lacks methods and techniques for aggregating attentional representations. We propose three novel gaze visualizations for the application in such environments: projected, object-based, and surface-based attentional maps. These techniques provide an overview of how visual attention is distributed across a scene, among different models, and across a model's surface. Two user studies conducted among eye tracking and visualization experts approve the high value of these techniques for the fast evaluation of eye tracking studies in virtual environments.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {345–348},
numpages = {4},
keywords = {virtual environments, attentional map, gaze visualizations, eye tracking, three-dimensional scene, eye movements},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843059,
author = {Thai, Vinh Tuan and Handschuh, Siegfried},
title = {Enhanced Navigation and Focus on TileBars with Barycenter Heuristic-Based Reordering},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843059},
doi = {10.1145/1842993.1843059},
abstract = {The classic TileBars paradigm has been used to show distribution information of query terms in full-text documents. However, when used to show the distribution of a large number of entities of interest to users within a document, it hinders users' quick comprehension due to the inherent visual complexity problem. In this paper, we present a novel approach to improve the visual presentation of TileBars, in which barycenter heuristic for bigraph crossing minimization is used to reorder TileBars' elements. The reordered TileBars enables users to quickly and easily identify which entities appear in the beginning, end, or throughout a document. A user study has shown that the reordered TileBars can provide users with better focus and navigation while exploring text documents.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {349–352},
numpages = {4},
keywords = {text exploration, barycenter heuristic, reordering, TileBars},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843060,
author = {Teraoka, Teruhiko},
title = {Doughnut Crumbs: Visual Navigation for Data Hierarchies},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843060},
doi = {10.1145/1842993.1843060},
abstract = {Efficient hierarchy navigation is essential in information systems. Various techniques have been developed in research on user interfaces and information visualization. However, a universally accepted technique has not been developed yet for navigating large hierarchies. Doughnut crumbs is a new technique for visual navigation of hierarchies. It displays a hierarchy as a series of nested layers, each one represented by an oval or a rectangle. A hidden layer is used to visualize a large hierarchy on a screen where the display size is limited. In the Doughnut crumbs interface, a hierarchy is visualized as layers nested concentrically or eccentrically.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {353–356},
numpages = {4},
keywords = {hierarchy, visualization, navigation},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843062,
author = {Belatar, Mohammed and Coldefy, Fran\c{c}ois},
title = {Gestures as a "Creation" Mechanism for Tabletop Interfaces},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843062},
doi = {10.1145/1842993.1843062},
abstract = {Gestures are usually used as a means of communication between a user and an interactive system. In this paper, we extend command gestures to "creation" gestures. The user can perform a simple analogical gesture to add graphical components (windows, widgets, controls, ...) to the interface. The benefit of this technique is that the desired object is created at the exact location and dimensions the user wants to avoid disturbing any collaborating users on a tabletop interactive surface. We describe three variations of creation gestures and compare them in terms of performance and user satisfaction in a controlled laboratory experiment.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {357–360},
numpages = {4},
keywords = {UI orientation, menu technique, CSCW, co-located collaboration, interaction technique, tabletop display},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843063,
author = {Shannon, Ross and Quigley, Aaron and Nixon, Paddy},
title = {Deep Diffs: Visually Exploring the History of a Document},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843063},
doi = {10.1145/1842993.1843063},
abstract = {Software tools are used to compare multiple versions of a textual document to help a reader understand the evolution of that document over time. These tools generally support the comparison of only two versions of a document, requiring multiple comparisons to be made to derive a full history of the document across multiple versions. We present Deep Diffs, a novel visualisation technique that exposes the multiple layers of history of a document at once, directly in the text, highlighting areas that have changed over multiple successive versions, and drawing attention to passages that are new, potentially unpolished or contentious. These composite views facilitate the writing and editing process by assisting memory and encouraging the analysis of collaboratively-authored documents. We describe how this technique effectively supports common text editing tasks and heightens participants' understanding of the process in collaborative editing scenarios like wiki editing and paper writing.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {361–364},
numpages = {4},
keywords = {text visualization, history, collaborative writing, Wikipedia, undo, diffing, versions, temporal visualization, editing, wiki},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843064,
author = {Kollukuduru, Sravanthi and Karlapalem, Kamalakar},
title = {"Wheels of Web" Visual User Interface},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843064},
doi = {10.1145/1842993.1843064},
abstract = {The primary goal of the work in this paper is to present a novel visual user interface design that can be used by even novice users without much effort. The design of the user interface needs to ensure that the users require short learning curve. A compact WHEEL structure was chosen as it not only requires less screen space, but also, enables users to view and explore the data of large datasets (having many relationships) with minimal clicks and scrolling. The paper describes the design choices, design process, the final design and the results from the user tests which were conducted to evaluate the usability and utility of the interface.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {365–368},
numpages = {4},
keywords = {wheel structure, novice users, world wide web, usability test, interface/interaction design, HCI, hypermedia},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843065,
author = {Yu, Yaohua and Liu, Zhengjie},
title = {Improving the Performance and Usability for Visual Menu Interface on Mobile Computers},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843065},
doi = {10.1145/1842993.1843065},
abstract = {The paper presents an approach to improve the menu interface of mobile computers by supporting the user with audio information. The experiment that compared the standard menu with the sonically-enhanced menu on mobile computers was conducted. The results confirm the improvement of the sonically-enhanced menu in term of the performance and usability.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {369–372},
numpages = {4},
keywords = {PDA, mobile computer, sonically-enhanced menu, non-speech sound},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843066,
author = {Oliveira, Rodrigo Silva and Cunha, Tiago Oliveira and de Souza, Fillipe Dias Moreira and de Oliveira, J\'{u}lia Epischina Engr\'{a}cia and de Albuquerque Ara\'{u}jo, Arnaldo},
title = {EVEREVIS: Event Recognizer in Video Scenes},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843066},
doi = {10.1145/1842993.1843066},
abstract = {This paper proposes a content-based video analysis system called EVEREVIS (Event Recognizer in Video Scenes), implemented as a Web-based system. In this prototype, news broadcast videos are segmented into indoor and outdoor scenes in order to facilitate navigation. Video summarization is performed and then the visual information content is characterized using HueSIFT. Support vector machine classifier is used for scenes classification and results show the plausibility of the system.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {373–376},
numpages = {4},
keywords = {video scene segmentation, web applications, SVM, HueSIFT, digital video analysis, visual information},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843067,
author = {Shannon, Ross and Quigley, Aaron and Nixon, Paddy},
title = {Showtime: Increasing Viewer Understanding of Dynamic Network Visualisations},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843067},
doi = {10.1145/1842993.1843067},
abstract = {Visualisations of dynamic networks are animated over time, reflecting changes in the underlying data structure. As viewers of these visualisations, it is up to us to accurately perceive and keep up with the constantly shifting view, mentally noting as visual elements are added, removed, changed and rearranged, sometimes at great pace. In a complex data set with a lot happening, this can put a strain on the observer's perceptions, with changes in layout and visual population disrupting their internalised mental model of the visualisation, making it difficult to understand what the changes represent. We present Showtime, a novel visualisation technique which dilates the flow of time so that observers have proportionally more time to understand each change based on the density of activity in the visualisation. This is paired with a novel timeline element which tracks the flow of time visually.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {377–380},
numpages = {4},
keywords = {temporal manipulation, information visualization, graphs, dynamic graph drawing, time-series},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843068,
author = {Abate, A. F. and Nappi, M. and Ricciardi, S. and Tortora, G. and Levialdi, S. and De Marsico, M.},
title = {Virtual-ICSI: A Visual-Haptic Interface for Virtual Training in Intra Cytoplasmic Sperm Injection},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843068},
doi = {10.1145/1842993.1843068},
abstract = {Virtual simulators have been used in the last twenty years for applications ranging from flight simulation to computer-based training, just to name a few. More recently a new level of simulation has been introduced thanks to haptic interfaces able to reproduce kinesthetic and/or tactile feedback, typically experimented during interaction with real-world objects. In this paper visual simulation and haptic interfaces are integrated in a novel training system for Intra Cytoplasmic Sperm Injection (ICSI), an in-vitro fertilization technique which is now a standard for the treatment of human infertility. We describe a virtual micromanipulation simulator made by two hand-based Cyberforce haptic devices (a synthetic replica of the actual manipulation gear) and a visual-haptic engine simulating the shape and the dynamic behavior of the main components in the artificial fertilization process: the human egg, the selected sperm and the micro needles required to inject the latter into the egg's cytoplasm. Our first tests, conducted so far, are encouraging.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {381–384},
numpages = {4},
keywords = {3D object manipulation, visual-haptic interface, ICSI},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843070,
author = {Tamaki, Emi and Miyak, Takashi and Rekimoto, Jun},
title = {BrainyHand: A Wearable Computing Device without HMD and It's Interaction Techniques},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843070},
doi = {10.1145/1842993.1843070},
abstract = {Existing wearable devices like an eyeglass-type head-mounted display(HMD) are very bulky and cannot be worn everyday. On the other hand, the earphone is popular wearable device, bacause it is small. However, the earphone cannot be used as an interaction device because of the lack of input and visual feedback components. In this paper, we propose BrainyHand - an enhanced earphone device for use in interaction systems. BrainyHand consists of a color camera and a laser projector. The camera recognizes the user's hand gestures for the input. For the visual feedback, the images projected on the user's hand or other nearby objects or surfaces using the projector. Since laser microprojector is becoming small, we expect this device configuration would eventwally a become as small as today earphones. We introduce several interaction methods based on hand gesture recognitions and object detections.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {387–388},
numpages = {2},
keywords = {hand gesture, interaction device, wearable, projector, input device},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843071,
author = {Avola, Danilo and Bottoni, Paolo and Levialdi, Stefano and Panizzi, Emanuele},
title = {Interacting Annotations in <i>MADCOW 2.0</i>},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843071},
doi = {10.1145/1842993.1843071},
abstract = {MADCOW 2.0 is a system for annotation of Web content, supporting the production and exploration of personal and public annotations on text, images and videos in a Web page. Its design starts from the main requirement that the annotation activity does not have to disrupt the normal browsing of Web pages by a user. MADCOW 2.0 allows interaction with the annotated portions of the page to provide access to the annotation content. Conversely, the representation of the existing notes supports different forms of exploration of the Web page, and can become the starting point for further navigation over the Web. A uniform style of interaction has been adopted for creating and accessing annotations on text, images and videos, and some novel solutions have been introduced to cope with overlaps between the annotated portions. The annotation user experience is facilitated by enabling forms of in-place annotation and manipulation of both the annotated portion and the annotation content.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {389–390},
numpages = {2},
keywords = {multimedia annotation, web annotation, HCI},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843072,
author = {Bellucci, Andrea and Malizia, Alessio and Diaz, Paloma and Aedo, Ignacio},
title = {Don't Touch Me: Multi-User Annotations on a Map in Large Display Environments},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843072},
doi = {10.1145/1842993.1843072},
abstract = {Touchless interaction techniques do not require physical contact while interacting with a system so to allow natural interaction with digital information, made tangible in the physical world through pervasive screen displays. In this project we explore the use of Nintendo Wii Remote controller as a touchless interface for interacting with map based applications in large displays environments. A prototype (Don't Touch Me) was developed that allows users to collaborative place multimodal annotations on a map: pictorials, auditives and haptics.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {391–392},
numpages = {2},
keywords = {CSCW, human-display interaction, georeferenced information, touchless interaction},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843073,
author = {Di Giacomo, Emilio and Didimo, Walter and Liotta, Giuseppe and Palladino, Pietro},
title = {Visual Analysis of Financial Crimes: [System Paper]},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843073},
doi = {10.1145/1842993.1843073},
abstract = {This paper shortly describes a system, called VisForFraud, that uses Information Visualization techniques for the discovery of financial crimes.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {393–394},
numpages = {2},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843074,
author = {Barbieri, Giuseppe and Celentano, Augusto and Finocchi, Valeria and Maurizio, Marek and Orsini, Renzo and Pittarello, Fabio},
title = {Experience with Interactive Multimedia Art Guides},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843074},
doi = {10.1145/1842993.1843074},
abstract = {We present the results of an experience in design and evaluation of multimedia guides for art exhibitions based on Apple iPod-class devices, gesture based interaction and rich multimedia content. Design is based on decoupling between content, interface and interaction design, adaptation to different user skills, and reusability; the evaluation is based on logging users' actions, time spent in the visit and content access. We report about the lesson learned in building and testing on the field two different guides during a period of six months.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {395–396},
numpages = {2},
keywords = {cultural heritage, rich multimedia content, user profile},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843075,
author = {Tobita, Hiroaki},
title = {EnforManga: Interactive Comic Creation with Deformation},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843075},
doi = {10.1145/1842993.1843075},
abstract = {The EnforManga is an interactive system for creating comic books based on the simple manipulation of images. To create a comic book that is similar to an actual comic book, the system provides two types of deformations: background and character, which translate images more comically. As a result, the deformed comic book is more like an actual comic book than comics created using conventional systems. Moreover, the manipulations in our system are based on drag and drop, so even beginners and even children can easily create a comic book.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {397–398},
numpages = {2},
keywords = {manga, interactive system, image deformation, zooming and interaction technique, user interface, comic book creation},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843076,
author = {Aloise, F. and Schettini, F. and Aric\`{o}, P. and Bianchi, L. and Riccio, A. and Mecella, M. and Babiloni, F. and Mattia, D. and Cincotti, F.},
title = {Advanced Brain Computer Interface for Communication and Control},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843076},
doi = {10.1145/1842993.1843076},
abstract = {The brain computer interface (BCI) technology allows a direct connection between brain and computer without any muscular activity required, and thus it offers a unique opportunity to enhance and/or to restore communication and actions into external word in people with severe motor disability.Here, we present the framework of the current research progresses regarding noninvasive EEG-based BCI applications specifically devoted to interact with the environment and other software. The P300 potentials recorded from the scalp represent a suitable BCI signal control for applications like environmental control. Here we present a set of findings that confirm the feasibility of a real domotic environmental control operated via P300-based BCI and a novelty interface approach to evoke the P300 signal.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {399–400},
numpages = {2},
keywords = {technologies for independent life, brain-computer interfaces, severe motor impairment, ambient intelligence},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843078,
author = {Costabile, Maria Francesca and De Ruyter, Boris and Mehandjiev, Nikolay and Mussio, Piero},
title = {End-User Development of Software Services and Applications},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843078},
doi = {10.1145/1842993.1843078},
abstract = {End-User Development (EUD) has traditionally been focusing on non-programmers tailoring or even creating software artifacts, often in organizational context. Some examples of successful EUD concepts include spreadsheet and word processing macros and the specification of e-mail filters by means of rules. Recent developments, such as Web 2.0 and Semantic Web, which enable end users to be contributors rather than just consumers of information on the WWW, have renewed interest in EUD research and applications. This trend is now moving from content and personalization to functionality in the direction of user-generated web services. Various on-going projects are already considering this new trend, but primarily from a technology perspective. The workshop aims at establishing a new forum for discussion and fruitful cross-fertilization of ideas among all the communities that can contribute to and benefit from allowing end users to generate web services: human-computer interaction, software engineering, artificial intelligence, computer-supported cooperative work and innovation management.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {403–407},
numpages = {5},
keywords = {end-user development, service-oriented architectures, design pattern, component-based systems, meta-design, ambient intelligence, household appliance, end-user composition, service composition approaches, process modeling, annotations, web services},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843079,
author = {Barricelli, Barbara R. and Mussio, Piero and Valtolina, Stefano and Padula, Marco and Scala, Paolo L. and Piccinno, Antonio},
title = {Visual Workflow Composition through Semantic Orchestration of Web Services},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843079},
doi = {10.1145/1842993.1843079},
abstract = {There is an increasing request by organizations to allow people outside the IT department to create, shape and adapt the software artifacts they use as they do with real ones in their work practice. Moreover, organizations have recently become aware that they are part of a complex network of connections with partners, customers, and suppliers. This new consciousness has led them to the need for new ways to share their knowledge outside the organization borders. This paper capitalizes on the experience gained in the collaboration with a certification institution to propose a novel network of software environments, i.e., the Task Management System (TMS) network, and a web-service based architecture to support end users to exploit their knowledge and expertise in their daily work activities. In particular, the network allows the end users of an organization to design, execute, and check the execution of a workflow. The goal is not to automate the skills of the end users, but to assist them in their activity, permitting them to use the knowledge and expertise they possess. A prototype for the proposed architecture is currently under development, starting from the software environment dedicated to the design of workflows.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {405},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843080,
author = {Calefato, Caterina and Frumento, Enrico and Milani, Monica and Montanari, Roberto},
title = {Seeing the Self in the Washing Machine: The Deep Affordance of 2.0 Philosophy in the Household Appliance Domain},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843080},
doi = {10.1145/1842993.1843080},
abstract = {The acceleration of rhythm of everyday life requires efficiency and flexibility in daily routines. The real expectations and needs of people concerning intelligent home devices should be carefully researched. The project Moon 2.0 by Indesit Company presents alternative ways of producing household appliance services developing a 2.0 Human Machine Interface and programs setting unit for washing machines, totally manageable by smart phones or I-Phones. Users cannot explicitly control washing machines when they would like to use a feature combination that has not application in a current washing program. The application of the Web 2.0 philosophy to the washing machine let the user the possibility to directly control all the existing features of the washing programs and to decide time by time how many programs their machine should have, with regards to the transparency and interactivity concepts of the ambient intelligence. Moon 2.0 should not be confused with an hand held personal home assistant capable of controlling a wide range of electronic home devices. The smart phone behaves the intelligence of the washing machine and offers the user endless customisation possibilities.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {405},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843081,
author = {Coutaz, Jo\"{e}lle and Fontaine, Emeric and Mandran, Nadine and Demeure, Alexandre},
title = {About Composing Our Own Smart Home},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843081},
doi = {10.1145/1842993.1843081},
abstract = {This paper reports on an empirical study performed to validate a theoretical model about the composition of smart artifacts by end-users. We have solicited 17 families and used a combination of interviews and a playful cultural probe. Results show that families are willing to couple smart objects to improve their lives, and that the theoretical questions raised by our model are sound. New services are more easily envisioned when coupling involves a "communicating" object or a "programmable" object. Being a communicating object has more impact than being programmable. Services envisioned by families included: Service substitution (e.g., replacing the user interface of the alarm clock with that of the time setting available on mobile phones); Service improvement (e.g., extending appliances such as the washing machine, by coupling them with the interaction resources of the TV set); Service chaining as ready for use "packages" to improve well-being for routine activities; along with Service "starters" as a means to control packages. Other findings are related to the playful cultural probe. Based on pictures of objects taken by the family members, our probe served as an ice-breaker; family members "revealed their house" naturally and the use of images of intimate objects increased interest and imagination.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {405–406},
numpages = {2},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843082,
author = {Fogli, Daniela and Provenza, Loredana Parasiliti and Colosio, Sergio},
title = {Metadesigning E-Government Services: A Case Study in a Local Agency},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843082},
doi = {10.1145/1842993.1843082},
abstract = {This paper describes the ongoing collaboration between the Department of Information Engineering of the University of Brescia and a local government agency. The goal is to create the socio-technical conditions for transferring the ability to develop web-based government-to-citizen services from software professionals to administrative personnel. To this end, proper end-user development techniques should be defined by capturing and exploiting employees' best practices and expertise. With reference to a typical government service, the paper reports summary results from a study of administrative personnel work practices and explores employees' motivations to become end-user software developers. It then outlines the design pattern language we have been defining for the considered domain to represent, from the employees' point of view, the problems encountered while creating government services together with their possible solutions. This is the starting point for identifying a further language that addresses the problem of end-user development of e-government services from an interaction-design point of view. These pattern languages can be regarded as metadesign tools for end-user development whose final aim is to support, and even improve, existing best practices in service creation, thus increasing employees' motivation and engagement in end-user development activities.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {406},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843083,
author = {Heil, Andreas and Smith, Matthew J. and Br\"{a}ndle, Alexander},
title = {Future Development Environments for Computational Scientists},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843083},
doi = {10.1145/1842993.1843083},
abstract = {Computational Scientists are both creators and end-users of scientific models. Different aspects to their work target different audiences and generally require different development approaches. The research of computational scientists typically involves the development of new computational models and methods often exposed as services. Complex multi-component models, usually bringing together previously developed and new services into a larger dynamical model, are now frequently developed. The communication of scientific models and their predictions is now a major area of science, with policy makers increasingly turning to scientists for predictions of complex dynamical systems. Scientific model development is also often done collaboratively, with different scientific teams working on components of the larger model, becoming analogous to professional software development. It is therefore not surprising that the majority of scientists consider developing scientific software as important for their own research. Despite the need for software to help conduct and communicate scientific research, computational scientists are generally "end-user programmers" with entirely different goals to Software Engineers when creating and composing software. Here we report outcomes of an experimental collaboration between Software Engineers and Computational Scientists to create a new development environment to encompass diverse end user groups.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {406},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843084,
author = {Locatelli, Marco P. and Simone, Carla},
title = {A Community Based Metaphor Supporting EUD within Communities},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843084},
doi = {10.1145/1842993.1843084},
abstract = {The paper proposes an approach to EUD focusing on communities: on the one hand, users are considered as a community of cooperating actors; on the other hand, applications and devices are considered as a (artificial) community that, by interacting with those actors, cooperate to support their collaboration. This idea facilitates an integration based on modularization and abstraction, by applying to the technology principles that are derived from human collaboration: in so doing, it others a uniform approach that allows users with different technical capabilities to operate at different levels of abstraction by applying the same conceptual tools. The community metaphor inspires a model that helps the users community integrating devices and applications according to its needs. In turn, the model defines a layered structure of primitives: from the basic ones up to the domain and application dependent ones, passing through the domain and application independent primitives. The approach is illustrated by an example in the education domain: the interaction flows in an augmented classroom can be defined and adapted by communities where teachers, tutors and students organize their collaboration.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {406},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843085,
author = {Lombardi, Jean-Philippe and Vogel, J\"{u}rgen},
title = {Wizard-Based Process Modeling for Business Users},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843085},
doi = {10.1145/1842993.1843085},
abstract = {Modeling the business processes of an organization for the purpose of documentation, optimization, or execution is a vital application in many domains. However, a general issue with existing process modeling (PM) tools is a lack of modeling methodologies for non-IT savvy business users (BUs). Instead, PM is usually performed by specially trained experts that then need to acquire the specific process knowledge from the BUs for modeling, resulting in costly and error-prone PM. Instead, we propose to allow BUs to perform modeling tasks directly by an appropriate user-friendly PM approach. We present our research on End User Development (EUD) for PM aimed at improving the ability of BUs to effectively modify process models according to their individual needs. Our EUD technique is based on a step-by-step instruction design (or wizard) pattern, which has been judged suitable for the considered users. The approach specifically considers how the knowledge of IT experts can be integrated in the development of a tool for supporting PM as these experts know how PM activities are performed and what information is required to support BUs in performing those activities. We have developed a wizard prototype for PM and present first evaluation results.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {406},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843086,
author = {Patern\'{o}, Fabio and Santoro, Carmen and Spano, Lucio Davide},
title = {User Task-Based Development of Multi-Device Service-Oriented Applications},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843086},
doi = {10.1145/1842993.1843086},
abstract = {In this paper, we present a method and the associated tool support able to exploit Web services in model-based user interface development, starting with the results of a task analysis phase, and using the content of Web service annotations. The resulting environment is a powerful support for developing multi-device interactive applications based on Web Services, since it is able to generate usable service front ends specified in a variety of implementation languages. This is achieved through connecting pre-existing Web services with the task model of the interactive application that has to be built. Then, the task model is used as a starting point for the generation of corresponding user interfaces descriptions at different abstraction levels, through a number of transformations that aim to preserve the usability of the corresponding models or implementations. The environment also allows designers to specify and customize such transformations among various levels of detail of the user interface description.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {407},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843087,
author = {Wajid, Usman and Namoune, Abdallah and Mehandjiev, Nikolay},
title = {A Comparison of Three Service Composition Approaches for End Users},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843087},
doi = {10.1145/1842993.1843087},
abstract = {This paper compares user preferences for three alternative approaches to service composition, namely: control flow, data flow, and assisted composition approach. The end user perspective is gathered by organizing three focus groups that include discussions and subjective questionnaires, involving 35 non-technical participants. The comparison of alternative composition approaches yielded results confirming that users favour system-driven or assisted composition which deals with technological complexities such as service compatibility problems while allowing user control and involvement. The results also define the requirements for user-friendly design of a service composition tool, which is being developed in the EC-funded project SOA4 All.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {407},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843088,
author = {Dix, Alan and Quigley, Aaron and Subramanian, Sriram and Terrenghi, Lucia},
title = {Workshop on Coupled Display Visual Interfaces},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843088},
doi = {10.1145/1842993.1843088},
abstract = {Interactive displays are increasingly distributed in a broad spectrum of everyday life environments: They have very diverse form factors and portability characteristics, support a variety of interaction techniques, and can be used by a variable number of people. The coupling of multiple displays can thus create interactive "ecosystems" which mingle in the social context, and generate novel settings of communication, performance and ownership. The objective of this workshop is to focus on the range of research challenges and opportunities afforded by applications that rely on visual interfaces that can spread across multiple displays. Such displays are physically decoupled (i.e. connected to multiple computers) yet are visually coupled due to the interfaces and interactions they support. This can range from visual interfaces spread across multiple small private input displays (e.g. information exchange or game play) to small private displays coupled with larger public displays (e.g. public photo sharing).},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {408–410},
numpages = {3},
keywords = {interactive surfaces, mobile user interfaces, HCI, tablet, gestures, ubiquitous computing, multi-display and CSCW, multi-touch},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843089,
author = {Waldner, Manuela and Schmalstieg, Dieter},
title = {Experiences with Mouse Control in Multi-Display Environments},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843089},
doi = {10.1145/1842993.1843089},
abstract = {It is now increasingly common to extend private workstations with large public displays into a shared multi-display environment (MDE). Mouse-based interaction across multiple displays provides a convenient way to quickly shift between private work on the personal monitor and tightly coupled collaboration on shared display spaces (Figure 1). However, mouse pointer navigation can be negatively influenced by display factors in the environment and thereby limit fluid interaction across displays. We report findings from an experiment comparing four mouse pointer navigation techniques in a heterogeneous MDE.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {411},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843090,
author = {Jenabi, Mahsa and Reiterer, Harald},
title = {Primitive Interaction Tasks for Multi-Display Environments (PrIME): A Hands-on Approach},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843090},
doi = {10.1145/1842993.1843090},
abstract = {Cross-display interaction is a challenge for HCI researchers, because a naive adaptation of mechanisms in single-display workspaces might be inappropriate for teamwork in multi-user multi-display environments. In this paper, we identify a set of primitive cross-display interaction tasks, which, so far, have not been addressed in the literature. Additionally, we present our ideas to design a prototype that incorporates the identified primitive tasks, using an iPhone as a mobile input device with an integrated display.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {412},
numpages = {1},
keywords = {multi-display environment, cross-display interaction, input device},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843091,
author = {Finke, Matthias and Kaviani, Nima and Wang, Ivy and Tsao, Vincent and Fels, Sidney and Lea, Rodger},
title = {Investigating Distributed User Interfaces across Interactive Large Displays and Mobile Devices},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843091},
doi = {10.1145/1842993.1843091},
abstract = {The use of a dual mobile and large screen approach offers a number of intriguing possibilities including a potential solution to the problem of managing conflicts that arise when a large screen is shared in a public setting. Here, we report on a series of experiments carried out to determine quantitative or qualitative effects of user performance when interaction is split across large public and smaller private screens. Our position is that using mobile devices as an auxiliary device for interaction can boost user experience when interacting with large displays.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {413},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843092,
author = {Ghiani, Giuseppe and Patern\`{o}, Fabio and Santoro, Carmen},
title = {Partial Web Interface Migration},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843092},
doi = {10.1145/1842993.1843092},
abstract = {We discuss our solution for partial Web migration from large screens to mobile devices. It is based on multiple UI abstraction levels and some transformations that allow the migration of selected UI components to another device.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {414},
numpages = {1},
keywords = {partial migration, ubiquitous environments},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843093,
author = {Bucci, Manuela and Calefato, Caterina and Colombetti, Sergio and Milani, Monica and Montanari, Roberto},
title = {Fridge Fridge on the Wall: What Can I Cook for Us All? An HMI Study for an Intelligent Fridge},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843093},
doi = {10.1145/1842993.1843093},
abstract = {New technologies have changed our life, making everyday tasks easier and faster. This new style of living requires a new kind of distribution of cognitive processes, resources and information. Trends in appliance design propose more sophisticated control and networking capabilities. Current white goods may be equipped with complex softwares and GUIs, that may be inputted, by mobile phones. The idea of inputting and interacting with our kitchen households by any personal nomadic device, leaving a public message on an available display surface, i.e. as the fridge surface, will create an interactive ecosystem supported by the coupling of multiple display. The ZmartFRI project aims at developing a seamless technology with an interactive fridge surface, assuring simplicity and intuitiveness of interaction. In this way home appliance that were in the past considered plain and utilitarian, become entertainment devices or, as in the case of ZmartFRI, become a family information hub. The house inhabitants may send and receive messages and information from the fridge, that play the role of family totem.The fridge surface equipped with a display and an effective GUI provides more than additional memory device supporting human activities and providing opportunities to reorganize what is known. Thanks to a coupled display system between the fridge and the user mobile device, the fridge is able to alert products expiration date, to suggest recipes, to fill in and send by sms or email the shopping list, to send and post messages for the house residents. Using RFID technology, an intelligent fridge should be able to sense the context and to communicate the user context variations (i.e. approaching expiring dates or close empty cartons) or context implications (i.e. a good recipe to use a product close to expire). Besides these functions, we implemented in ZmartFRI also the ability to automatically fill in a grocery shopping list, that may be communicated to the user via sms or email when s/he is shopping. Moreover it improves its traditional function of showcase for anyone's message with magnets or post-it by sending and posting messages electronically and visualising them on its own display.Context-aware systems and ubiquitous computing promise more than just infrastructure, suggesting indeed new paradigms of interaction inspired by widespread access to information and computational capabilities. To attain this aim, the driving design principles for our intelligent fridge were the simplicity of the application and intuitiveness of the interaction. To understand in details which functions the user may desire about an intelligent fridge, short ethnographic research has been conducted to gather typical users' ideas, expectations, and concerns. The findings of the ethnographic study allowed us at designing ZmartFRI for specific needs, but starting from a particular point of view: home is already smart, smart not in terms of technology, but in terms of how people conduct their lives at home. During the participatory design session the interaction between the display of the personal device (private display) and the fridge display (public display), has been defined. The user identified several actions that the intelligent fridge should perform: i) checking the goods in the fridge, ii) creating a shopping list, iii) sending to a personal device the shopping list if requested iv) being guided on how to prepare a recipe, v) writing and delivering messages, vi) creating, rearranging and deleting notes, vii) mailing a note to one of the family members whose portrait is decorated with a cover iconThe ZmartFRI project follows a main design principle: this is the "just use it" requirement. The fridge prototype is still virtual, but it represents a promising start, which we plan to pursue further, implementing a mock up that will be used for usability tests with users. With the adequate improvements we intend to test its use in a real context, by installing it in the residence of our subjects, and testing its uptake as part of their daily life over some prolonged period, according to the ethnographic approach we undertook. A future challenge will be the design of a wider display that will open new interaction concept and modalities between the family totem (the fridge) and the personal portable devices.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {415},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843094,
author = {Villanueva, Pedro G. and Gallud, Jos\'{e} A. and Tesoriero, Ricardo},
title = {WallShare: A Multi-Pointer System for Portable Devices},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843094},
doi = {10.1145/1842993.1843094},
abstract = {WallShare introduces a new system to improve the collaboration possibilities among the participants in face-to-face meetings and working groups. It defines an novel interaction device and platform to develop collaborative applications. The system provides a shared zone displayed by a projector over a wall. Through their cursors and mobile devices users are capable of post notes and messages, and sharing files, such as documents, images, etc. This article also exposes a preliminary usability evaluation of WallShare showing the effectiveness, productivity and satisfaction of users.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {416},
numpages = {1},
keywords = {UI distribution, mobile devices, HCI, interaction resources},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843095,
author = {Rashid, Umer and Terrenghi, Lucia and Quigley, Aaron},
title = {Labeling Large Displays for Interaction with Mobile Devices: Recognition of Symbols for Pairing Techniques},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843095},
doi = {10.1145/1842993.1843095},
abstract = {Large interactive displays are an effective means to exchange contents with mobile devices for co-located collaboration in offices and schools. It is very important that the users are able to easily comprehend and learn the interaction techniques to pair their mobile devices with large displays. In this paper, we report on the results of an exploratory case study investigating the comprehension and understandability of the display labels for four pairing techniques i.e. pointing, touching, drawing and typing.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {417},
numpages = {1},
keywords = {communication design, multi-display systems, intuitive interfaces},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843096,
author = {Chorianopoulos, Konstantinos and Fern\'{a}ndez, Francisco Javier Bur\'{o}n and Salcines, Enrique Garc\'{\i}a and de Castro Lozano, Carlos},
title = {Delegating the Visual Interface between a Tablet and a TV},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843096},
doi = {10.1145/1842993.1843096},
abstract = {The introduction and wide adoption of small and powerful mobile computers, such as smart phones and tablets, has raised the opportunity of employing them into multi-device scenarios and blending the distinction between input and output devices. In particular, the partnership between a personal device and a shared one provides two possible output screens. Then, one significant research issue is to balance the visual interface between two devices with advanced output abilities. Do the devices compete or cooperate for the attention and the benefit of the user? Most notably, how multi-device interaction is appreciated in multi-user scenarios? Previous research has raised and considered the above research issues and questions for dual screen set-ups in the work environment. In our research, we are exploring multi-device user interface configurations in the context of a leisure environment and for entertainment applications. Our objective is to provide interaction possibilities that are more than the sum of the parts.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {418},
numpages = {1},
keywords = {evaluation, TV, interaction, tablet, design},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843097,
author = {D\"{o}ring, Tanja and Shirazi, Alireza Sahami and Schmidt, Albrecht},
title = {Exploring Gesture-Based Interaction Techniques in Multi-Display Environments with Mobile Phones and a Multi-Touch Table},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843097},
doi = {10.1145/1842993.1843097},
abstract = {In this paper, we explore the potential of combining shared and interactive displays (e.g. a multi-touch table) with personal devices (e.g. mobile phones) as an important class of heterogeneous multi-display environments. Within six case studies applications and interactions were invented and implemented that utilize the potential of such heterogeneous multi-display environments. We were in particular interested how to design systems that include interaction across different displays and how to manage public and private information in a group setting. One case study, a digital card game, highlights these design challenges. We explore different natural ways of interaction, including touching the table as well as motion gestures with mobile phones. With this application we provide a use case to discuss gestures combining mobile phones with tabletop surfaces, as well as to explore a private-public display setting. First results showed that combining tables and mobile phones provide a suitable and understandable way for interaction in these settings.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {419},
numpages = {1},
keywords = {multi-display environment, mobile phone, gestures, multi-touch table, card games, interactive surface},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843098,
author = {Gude, Rasmus},
title = {Digital Hospitality: Expressing Hospitality towards Guests in Smart Homes Using Private and Domestic Displays},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843098},
doi = {10.1145/1842993.1843098},
abstract = {For more than a decade the use of ubiquitous computing technologies in the domestic space -- the so-called smart homes - has been a subject for research. While research has focused on smart homes and its inhabitants in various incarnations, little or no research has been questioning how these smart homes engender hospitality towards guests and how inhabitants in a smart home can express hospitality using ubiquitous technologies. This paper defines the novel notion of "digital hospitality" and proposes an early state system design based on coupled displays. The system called EWIA is designed to facilitate and strengthen the relationship between guest and host by utilizing both private smart phone displays and domestic displays.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {420},
numpages = {1},
keywords = {digital hospitality, mobile user interfaces, group interfaces, ubiquitous computing technologies},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843099,
author = {Zudilova-Seinstra, Elena and Martens, Jean-Bernard and Adriaansen, Tony},
title = {Interactive Data Exploration and Knowledge Discovery},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843099},
doi = {10.1145/1842993.1843099},
abstract = {People have always relied on visual tools such as maps, charts and diagrams to better understand problems and solve them in less time. Continuous improvements in computer processing power and graphics capabilities have made it possible to incorporate a wide range of advanced visualization techniques in most computing application domains, including business, medicine, engineering and science.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {421–422},
numpages = {2},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843100,
author = {Foster, Christopher and Burd, Liz and Hatch, Andrew},
title = {Exploring Concepts Collaboratively: Considering How Wii Interact},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843100},
doi = {10.1145/1842993.1843100},
abstract = {This abstract describes ongoing research on human to human interaction between early career Computer Scientists as they explore a complex collaborative concept mapping task performed by a collocated group using a large wall-screen projected display. We have investigated the effects of input configuration and mode of input on human to human computer interaction through the use of gesture based controllers. Application of Bales' Interaction Process Analysis (IPA) [1] supports identity trade offs in choosing from a plethora of available input devices and displays when investigating interaction and knowledge discovery.Increasingly, Higher Educational departments are encouraged to plan and deploy technologies that facilitate interaction as a fundamental principle of moving into the Interaction Age, specifically 'new tools are needed to support informal learning activities, in particular processes associated with conceptual development' [2]. This need for new tools resulted in the creation of WiiDraw; software through which single or multiple users could interact with and manipulate conceptual mapping diagrams using gestural interaction concurrently. Gaming interfaces like the Nintendo Wii provide options for creating gesture-based input beyond the move-click capability of a mouse, offering new modes to groups who interact with and create conceptual knowledge with large screens.Other example systems have used mouse input [3] and laser pointers [4] as a means through which to explore large-screen based systems, yet none of these have emerged as a clear choice for a range of applications, and there may not be a single best fit option. However, we now present a study of eleven groups who completed a conceptual mapping task on a shared wall-display to determine how the configuration and mode of input influenced the amount of interaction. The experiment consisted of a single between-groups factor of input configuration of two levels (one controller and two controllers) and a single within-groups factor of interaction style, consisting of two levels (controller with no gestures enabled and controller with gestures enabled). IPA was applied to the data that was obtained from video recordings made of each experiment. ANOVA indicated a main effect of number of controllers, F(1,18)=6.38, p=0.02, with a higher number of interactions when dyads had one controller (M=432, SD=93) than two controllers (M=310, SD=140). A main effect of gestures was evident, F(1,18)=5.08, p=0.04 with more interactions occurring with gestures (M=420, SD=119), than without (M=310, SD=129) (see Figure 1). The interaction effect was not statistically significant.Results indicate that one controller afforded higher levels of human to human interaction, with gestures also increasing the number of interactions seen. Further analysis describes the differences in type of interaction and its impact upon knowledge discovery. However it appears Wii interact more when gesturing with concepts.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {423},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843101,
author = {Tsuji, Shunichiro and Kono, Yasuyuki},
title = {Generation of Roadside Panoramic Images without Obstacles},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843101},
doi = {10.1145/1842993.1843101},
abstract = {This paper presents the method for generating panoramic image(s) from plural in-vehicle camera images. Our real-world map system employing the proposed method has the following features: 1) it puts the generated panoramic images of the real-world to an existing web map, e.g., GoogleMaps, 2) partial regions in the images are classified according to the depth from the camera by tracking each partial region employing the SIFT feature, so that 3) it can obtain panoramic background images that exclude obstacles, e.g., parked vehicles. Our updatable real-world map system can offer up-to-date information to map-based systems, e.g., car navigation system or web interface any time.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {424},
numpages = {1},
keywords = {panoramic image generation, obstacle exclusion, design feature, real-world map, SIFT feature},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843102,
author = {Sedig, Kamran},
title = {Human-Information Interaction in Epistemic Activities},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843102},
doi = {10.1145/1842993.1843102},
abstract = {We use, work, and think with information to be able to make decisions, solve problems, plan, analyze, forecast, and learn. These information-based activities can be classified as epistemic activities (EAs), as they all involve or are related to knowing. Often, we use computational tools in the form of Visual Cognitive Tools (VCTs) to help us carry out these EAs. VCTs maintain and display information in a digital, visual form to mediate our EAs. They sit at the interface between the mind and an information space and participate in the 'interplay' between the two. This paper presents a framework for a systematic exploration of the anatomical structure of the space between the mind and a given information space---that is, the space in which the interplay between the mind and information takes place. The motivation behind the creation of this framework is to facilitate the analysis and design of VCTs that can effectively support our EAs.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {425},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843103,
author = {Lia, Hai-Ning and Sedig, Kamran},
title = {Role of Externalization and Composite Interactions in the Exploration of Complex Visualization Spaces: A Usability Study},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843103},
doi = {10.1145/1842993.1843103},
abstract = {Complex visualization spaces are not easy to explore. This is especially true of exploring 4D mathematical structures due to occlusion and visual clutter. In this paper, we present preliminary results involving a usability study of two strategies for designing interaction strategies, namely, externalization and composite interactions, to aid in the exploration of 4D mathematical structures. Study results show the potential benefits of these two strategies for exploring complex mathematical structures, in particular, and other complex visualization spaces, in general.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {426},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843104,
author = {Scheuner, Barbara},
title = {Evaluating the Utilization of Clustering Methods Connected with Multivariate Visualizations},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843104},
doi = {10.1145/1842993.1843104},
abstract = {Visualization software in all fields becomes increasingly interactive with more and more elements to support users. Elements that help an observer to interpret given data sets by computing certain properties of the data to enrich their visualization we call "visual scouts".Many visualization programs implement visual scouts, but few is known about how users apply them in a real setting. In order to learn more about how users work with interactive visualization software we provide them with clustering methods (k-mean and hierarchical clustering), as one possibility to manipulate the data. Subsequently we evaluate how natural science students use these clustering methods as provided by an interactive comparative visualization software for high dimensional data (VisuLab®). The students are introduced to four different visualization methods (figure 1) and given the possibility to apply four clustering methods to help them when interpreting two sample datasets (table 1 first two rows). This is part of a guided instruction after which they independently interpret two new but related real data sets (table 1 last two rows). In total they work for about six hours.During our evaluation we were able to record the clustering activities of ~250 students, by directly logging the user's activities within the software. Based on this data we computed how many times the data was clustered and with which visualization methods the results were visualized. In total we registered over 57'000 clustering activities of which 30% where recorded during the instruction period and the remaining 70% during the time they worked independently.Based on the data gained we investigate relationships between clustering methods, the type of data analyzed and the visualization method chosen. This is shown in figure 2, where the number of clustering in regard to the visualization method is presented in a boxplot.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {427},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843105,
author = {Foley, Simon},
title = {Virtual Environment for the Navigation of Ideas and Concepts in Education (V.E.N.I.C.E)},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843105},
doi = {10.1145/1842993.1843105},
abstract = {This paper reports on current research into the development of an interactive visualisation tool for postgraduate research students. The aim of the research is to construct a virtual environment that allows students to navigate ideas, which they can then relate to conceptual structures. V. E.N.I.C.E offers users a virtual learning environment, which is at once a concept map, a file manager, and a memory palace. Modelled loosely on the infrastructure of the medieval city of Venice the application encourages users to build metaphorical relationships between conceptual islands of ideas, that are separated by canals, but linked by bridges, which in turn lead to further islands. On each island the user constructs a memory palace, which acts as a repository for data associated with a single idea. The palace is located within a confluence of discursive pathways that allow the student to position, affirm, challenge and expand upon a line of related argument.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {428},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843106,
author = {Cunningham, Andrew and Xu, Kai and Thomas, Bruce},
title = {Seeing More than the Graph: Evaluation of Multivariate Graph Visualization Methods},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843106},
doi = {10.1145/1842993.1843106},
abstract = {Many real-world networks are multivariate, i.e., they have attributes associated with nodes and/or edges. Examples include social networks whose nodes represent people and edges represent relationships. There is usually information about each person (such as name, age, and gender) and the relationship (such type, duration, and strength). Besides common graph analysis tasks (such as identifying the most influential or structurally important nodes), there are more complex analyses for multivariate networks. One of these is the multivariate graph clustering, i.e., identifying clusters formed by nodes that have similar attributes and are close to each other in terms of graph distance. For instance, in social network analysis, it is interesting to sociologists whether or not people with similar characteristics (node attributes) are also connected to each other. Currently there are very few visualization methods available for such analysis.Graph and multivariate visualization have been well studied separately in the literature. Herman et al. summarized the recent work on graph visualization [3], and Wong and Bergeron covered the development in multivariate visualization [4]. However, there is relatively less work available on multivariate network visualization. Two types of approaches are commonly used. The first one is the mapping approach, which maps attributes to visual elements of a node or edge. A simple example is to map one attribute to node size and another to node color [2]. A more advanced mapping approach uses glyphs to represent node or edge attributes. One such example is to use the length and width of a rectangle node glyph to represent two node attributes [1]. The second one is the 2.5D approach: it uses the third dimension to present the multivariate information, while the graph is shown on a 2D plane. Examples include the recently proposed "GraphScape" [5], which adopts a landscape metaphor: each attribute is represented by a two-and-a-half- dimensional surface, whose height indicates its value.Each approach has its strength and weakness. The mapping approach is effective of showing numerical value using visual element such as size, but it can be difficult to compare the value of attributes represented by different elements such as size and color. The problem is alleviated by a carefully designed glyph, but visual complexity increases quickly as the number of attributes that a glyph needs to represent grows. The 2.5D approach is good at showing the distribution of attribute values over the network, but the attribute surface could introduce occlusion and affect the visibility of underlying network.In this paper, we present a study evaluating the effectiveness of these two approaches for different analysis tasks. We compare the performance of mapping and 2.5D approach in a controlled lab environment. We included both simple tasks (such as identifying nodes with the largest attribute value) and complex tasks (such as multivariate graph clustering). The performance is measured both in terms of accuracy and completion time. The results indicate that statistically mapping approach performs better for the simple tasks, while the 2.5D approach is favored in the complex task. The outcomes from this study provide some guidelines for the design of effective multivariate graph visualization for different analysis tasks.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {429},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

@inproceedings{10.1145/1842993.1843107,
author = {Fraga, Eric S.},
title = {An Interactive Exploration Environment for Complex Process Design},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843107},
doi = {10.1145/1842993.1843107},
abstract = {Process design requires the solution of complex models. These models are typically nonlinear and non-convex. The design optimisation problem is also often combinatorial in nature. An example is the design of thermally integrated process plants for energy minimisation where excess heat from one part of a process plant may be used to meet heating demands in other parts of the same plant (cf. e.g. [2]). Due to the complexity of the models and the combinatorial nature of the search, design is often undertaken as a series of steps with increasing detail from step to step [1]. Information gained in any step can be useful in subsequent steps. This information may come from data generated during design. Therefore, data analysis and visualisation are key elements in effective design.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {430},
numpages = {1},
location = {Roma, Italy},
series = {AVI '10}
}

