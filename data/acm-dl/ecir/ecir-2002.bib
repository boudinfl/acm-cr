@inproceedings{10.5555/645319.756414,
author = {S\o{}dring, Thomas and Smeaton, Alan F.},
title = {Evaluating a Melody Extraction Engine},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper introduces the CEOLAIRE Music Information Retrieval System; a system which stores, indexes and provides content-based retrieval on a collection of over 7,000 music files. What makes CEOLAIRE different from most other music information retrieval systems is that it indexes actual raw compressed or uncompressed audio rather than just indexing MIDI, which is effectively instructions for generating musical notes. The paper includes an overview of the CEOLAIRE system and includes an evaluation of the effectiveness of its melody extraction engine, the crucial part of CEOLAIRE which recognises the notes and melody being played. Our results show that for the type of melody matching used in CEOLAIRE'S retrieval engine, the performance of our melody recognition is quite acceptable.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {1–21},
numpages = {21}
}

@inproceedings{10.5555/645319.649740,
author = {Duffing, G\'{e}rald and Sma\"{\i}l, Malika},
title = {Organising and Searching Partially Indexed Image Databases},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper addresses the issue of efficient retrieval from image corpora in which only a little proportion is textually indexed. We propose a hybrid approach integrating textual search with content-based retrieval. We show how a preliminary double clustering of image corpus exploited by an adequate retrieval process constitutes an answer to the pursued objective. The retrieval process takes advantage of user-system interaction via relevance feedback mechanism whose results are integrated in a virtual image. Experimental results on the PICAP prototype are reported ed and discussed to demonstrate the effectiveness of this work.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {22–40},
numpages = {19}
}

@inproceedings{10.5555/645319.649745,
author = {Heesch, Daniel and R\"{u}ger, Stefan M.},
title = {Combining Features for Content-Based Sketch Retrieval - A Comparative Evaluation of Retrieval Performance},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We study three transformation-invariant shape descriptors and evaluate their relative strengths in the context of content-based retrieval of graphical sketches. We show that the use of a combination of different shape representations may lead to a significant improvement of retrieval performance and identify an optimal combination that proves robust across different data sets and queries.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {41–52},
numpages = {12}
}

@inproceedings{10.5555/645319.756421,
author = {Tsikrika, Theodora and Lalmas, Mounia},
title = {Combining Web Document Representations in a Bayesian Inference Network Model Using Link and Content-Based Evidence},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper introduces an expressive formal Information Retrieval model developed for the Web. It is based on the Bayesian inference network model and views IR as an evidential reasoning process. It supports the explicit combination of multiple Web document representations under a single framework. Information extracted from the content of Web documents and derived from the analysis of the Web link structure is used as source of evidence in support of the ranking algorithm. This content and link-based evidential information is utilised in the generation of the multiple Web document representations used in the combination.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {53–72},
numpages = {20}
}

@inproceedings{10.5555/645319.649278,
author = {Kim, Sung Jin and Lee, Sang Ho},
title = {An Improved Computation of the PageRank Algorithm},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The Google search site (http://www.google.com) exploits the link structure of the Web to measure the relative importance of Web pages. The ranking method implemented in Google is called PageRank [3]. The sum of all PageRank values should be one. However, we notice that the sum becomes less than one in some cases. We present an improved PageRank algorithm that computes the PageRank values of the Web pages correctly. Our algorithm works out well in any situations, and the sum of all PageRank values is always maintained to be one. We also present implementation issues of the improved algorithm. Experimental evaluation is carried out and the results are also discussed.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {73–85},
numpages = {13}
}

@inproceedings{10.5555/645319.649749,
author = {Lepouras, George and Vassilakis, Costas and Weir, George R. S.},
title = {Serving Enhanced Hypermedia Information},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {An apparent limitation of existing Web pages is their inability to accommodate differences in the interests and needs of individual users. The present paper describes an approach that dynamically customises the content of public Web-based information via an interceding 'enhancement server'. The design and operation of this system is described with examples drawn from two current versions. Indications from early trials support the view that this approach affords considerable scope for accommodating the needs and interests of individual Web users.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {86–92},
numpages = {7}
}

@inproceedings{10.5555/645319.757469,
author = {White, Ryen and Ruthven, Ian and Jose, Joemon M.},
title = {The Use of Implicit Evidence for Relevance Feedback in Web Retrieval},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we report on the application of two contrasting types of relevance feedback for web retrieval. We compare two systems; one using explicit relevance feedback (where searchers explicitly have to mark documents relevant) and one using implicit relevance feedback (where the system endeavours to estimate relevance by mining the searcher's interaction). The feedback is used to update the display according to the user's interaction. Our research focuses on the degree to which implicit evidence of document relevance can be substituted for explicit evidence. We examine the two variations in terms of both user opinion and search effectiveness.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {93–109},
numpages = {17}
}

@inproceedings{10.5555/645319.649752,
author = {Vakkari, Pertti},
title = {Subject Knowledge, Source of Terms, and Term Selection in Query Expansion: An Analytical Study},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The role of subject and search knowledge in query expansion (QE) is an unmapped terrain in research on information retrieval. It is likely that both have an impact on the process and outcome of QE. In this paper our aim is an analytical study of the connections between subject and search knowledge and term selection in QE based both on thesaurus and relevance feedback. We will also argue analytically how thesaurus, term suggestion in interactive QE and term extraction in automatic QE support users with differing levels of subject knowledge in their pursuit of search concepts and terms. It is suggested that in QE the initial query concepts representing the information need should not be treated as separate entities, but as conceptually interrelated. These interrelations contribute to the meaning of the conceptual construct, which the query represents, and this should be reflected in the terms identified for QE.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {110–123},
numpages = {14}
}

@inproceedings{10.5555/645319.649742,
author = {Benammar, Anis and Hubert, Gilles and Mothe, Josiane},
title = {Automatic Profile Reformulation Using a Local Document Analysis},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {User profiles are more and more used in information retrieval system in order to assist users in finding relevant information. Profiles are continuously updated to evolve at the same time the user information need does. In this paper we present a reformulation strategy used to automatically update the profile content. In a first stage, a local document set is computed from the search results. In a second stage, the local set is analyzed to select the terms to add to the profile expression. Experiments have been performed on an extract from the OHSUMED database to evaluate the effectiveness of the adaptation process.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {124–134},
numpages = {11}
}

@inproceedings{10.5555/645319.649743,
author = {Boughanem, M. and Tamine, Lynda},
title = {A Study on Using Genetic Niching for Query Optimisation in Document Retrieval},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents a new genetic approach for query optimisation in document retrieval. The main contribution of the paper is to show the effectiveness of the genetic niching technique to reach multiple relevant regions of the document space. Moreover, suitable merging procedures have been proposed in order to improve the retrieval evaluation. Experimental results obtained using a TREC sub-collection indicate that the proposed approach is promising for applications.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {135–149},
numpages = {15},
keywords = {information retrieval, niching, genetic algorithm, multiple query evaluation}
}

@inproceedings{10.5555/645319.649276,
author = {Rajapakse, R. K. and Denham, M.},
title = {Concept Based Adaptive IR Model Using FCA-BAM Combination for Concept Representation and Encoding},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The model described here is based on the theory of Formal Concept Analysis (FCA). Each document is represented in a Concept Lattice: a structured organisation of concepts according to a subsumption relation and is encoded in a Bidirectional Associative Memory (BAM): a two-layer heterogeneous neural network architecture. The document retrieval process is viewed as a continuous conversation between queries and documents, during which documents are allowed to learn a consistent set of significant concepts to help its retrieval. A reinforcement learning strategy based on relevance feedback information makes the similarity of relevant documents stronger and nonrelevant documents weaker for each query.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {150–168},
numpages = {19}
}

@inproceedings{10.5555/645319.649741,
author = {Campos, Luis M. de and Fern\'{a}ndez-Luna, Juan M. and Huete, Juan F.},
title = {A Layered Bayesian Network Model for Document Retrieval},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose a probabilistic document retrieval model based on Bayesian networks. The network is used to compute the posterior probabilities of relevance of the documents in the collection given a query. These computations can be carried out efficiently, because of the specific network topology and conditional probability tables being considered, which allow the use of a fast and exact probabilities propagation algorithm. In the initial model, only direct relationships between the terms in the glossary and the documents that contain them are considered, giving rise to a Bayesian network with two layers. Next, we consider an extended model that also includes direct relationships between documents, using a network topology with three layers. We also report the results of a set of experiments with the two models, using several standard document collections.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {169–182},
numpages = {14}
}

@inproceedings{10.5555/645319.649744,
author = {Amati, Gianni and Rijsbergen, C. J. van},
title = {Term Frequency Normalization via Pareto Distributions},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We exploit the Feller-Pareto characterization of the classical Pareto distribution to derive a law relating the probability of a given term frequency in a document and its the length. A similar law was derived by Mandelbrot. We exploit the paretian distribution to obtain a term frequency normalization to substitute for the actual term frequency in the probabilistic models of Information Retrieval recently introduced in TREC-10. Preliminary results show that the unique parameter of the framework can be eliminated in favour of the the term frequency normalization derived by the Paretian law.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {183–192},
numpages = {10}
}

@inproceedings{10.5555/645319.649738,
author = {Lavrenko, Victor},
title = {Optimal Mixture Models in IR},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We explore the use of Optimal Mixture Models to represent topics. We analyze two broad classes of mixture models: set-based and weighted. We provide an original proof that estimation of set-based models is NP-hard, and therefore not feasible. We argue that weighted models are superior to set-based models, and the solution can be estimated by a simple gradient descent technique. We demonstrate that Optimal Mixture Models can be successfully applied to the task of document retrieval. Our experiments show that weighted mixtures outperform a simple language modeling baseline. We also observe that weighted mixtures are more robust than other approaches of estimating topical models.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {193–212},
numpages = {20}
}

@inproceedings{10.5555/645319.649750,
author = {Kongovi, Madhusudhan and Guzman, Juan Carlos and Dasigi, Venu},
title = {Text Categorization: An Experiment Using Phrases},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Typical text classifiers learn from example and training documents that have been manually categorized. In this research, our experiment dealt with the classification of news wire articles using category profiles. We built these profiles by selecting feature words and phrases from the training documents. For our experiments we decided on using the text corpus Reuters-21578. We used precision and recall to measure the effectiveness of our classifier. Though our experiments with words yielded good results, we found instances where the phrase-based approach produced more effectiveness. This could be due to the fact that when a word along with its adjoining word - a phrase - is considered towards building a category profile, it could be a good discriminator. This tight packaging of word pairs could bring in some semantic value. The packing of word pairs also filters out words occurring frequently in isolation that do not bear much weight towards characterizing that category.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {213–228},
numpages = {16}
}

@inproceedings{10.5555/645319.649275,
author = {Gaussier, \'{E}ric and Goutte, Cyril and Popat, Kris and Chen, Francine},
title = {A Hierarchical Model for Clustering and Categorising Documents},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose a new hierarchical generative model for textual data, where words may be generated by topic specific distributions at any level in the hierarchy. This model is naturally well-suited to clustering documents in preset or automatically generated hierarchies, as well as categorising new documents in an existing hierarchy. Training algorithms are derived for both cases, and illustrated on real data by clustering news stories and categorising newsgroup messages. Finally, the generative model may be used to derive a Fisher kernel expressing similarity between documents.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {229–247},
numpages = {19}
}

@inproceedings{10.5555/645319.649739,
author = {Peters, C. and Koster, Cornelis H. A.},
title = {Uncertainty-Based Noise Reduction and Term Selection in Text Categorization},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper introduces a new criterium for term selection, which is based on the notion of Uncertainty. Term selection according to this criterium is performed by the elimination of noisy terms on a class-by-class basis, rather than by selecting the most significant ones. Uncertainty-based term selection (UC) is compared to a number of other criteria like Information Gain (IG), simplified 2 (SX), Term Frequency (TF) and Document Frequency (DF) in a Text Categorization setting. Experiments on data sets with different properties (Reuters- 21578, patent abstracts and patent applications) and with two different algorithms (Winnow and Rocchio) show that UC-based term selection is not the most aggressive term selection criterium, but that its effect is quite stable across data sets and algorithms. This makes it a good candidate for a general "install-and-forget" term selection mechanism. We also describe and evaluate a hybrid Term Selection technique, first applying UC to eliminate noisy terms and then using another criterium to select the best terms.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {248–267},
numpages = {20}
}

@inproceedings{10.5555/645319.649748,
author = {Vegas, Jes\'{u}s and Fuente, Pablo de la and Crestani, Fabio},
title = {A Graphical User Interface for Structured Document Retrieval},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Structured document retrieval requires different user graphical interfaces from standard Information Retrieval. An Information Retrieval system dealing with structured documents has to enable a user to query, browse retrieved documents, provide query refinement and relevance feedback based not only on full documents, but also on specific document structural parts. In this paper, we present a new graphical user interface for structured document retrieval that provides the user with an intuitive and powerful set of tools for structured document searching, retrieved list navigation, and search refinement. We also present the results of a preliminary evaluation of the interface which highlights strengths and weaknesses of the current implementation and suggests directions of future work.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {268–283},
numpages = {16}
}

@inproceedings{10.5555/645319.649746,
author = {R\"{o}lleke, Thomas and Lalmas, Mounia and Kazai, Gabriella and Ruthven, Ian and Quicker, Stefan},
title = {The Accessibility Dimension for Structured Document Retrieval},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Structured document retrieval aims at retrieving the document components that best satisfy a query, instead of merely retrieving pre-defined document units. This paper reports on an investigation of a tf-idf-acc approach, where tf and idf are the classical term frequency and inverse document frequency, and acc, a new parameter called accessibility, that captures the structure of documents. The tf-idf-acc approach is defined using a probabilistic relational algebra. To investigate the retrieval quality and estimate the acc values, we developed a method that automatically constructs diverse test collections of structured documents from a standard test collection, with which experiments were carried out. The analysis of the experiments provides estimates of the acc values.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {284–302},
numpages = {19}
}

@inproceedings{10.5555/645319.649747,
author = {McEwan, Craig J. A. and Ounis, Iadh and Ruthven, Ian},
title = {Building Bilingual Dictionaries from Parallel Web Documents},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we describe a system for automatically constructing a bilingual dictionary for cross-language information retrieval applications. We describe how we automatically target candidate parallel documents, filter the candidate documents and process them to create parallel sentences. The parallel sentences are then automatically translated using an adaptation of the EMIM technique and a dictionary of translation terms is created. We evaluate our dictionary using human experts. The evaluation showed that the system performs well. In addition the results obtained from automatically-created corpora are comparable to those obtained from manually created corpora of parallel documents. Compared to other available techniques, our approach has the advantage of being simple, uniform, and easy-to-implement while providing encouraging results.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {303–323},
numpages = {21}
}

@inproceedings{10.5555/645319.649751,
author = {Oard, Douglas W. and Ertunc, Funda},
title = {Translation-Based Indexing for Cross-Language Retrieval},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Structured queries have proven to be an effective technique for cross-language information retrieval when evidence about translation probability is not available. Query execution time is adversely impacted, however, because the full postings list for each translation is used in the computation. This paper describes an alternative approach, translation-based indexing, that improves query-time efficiency by integrating the translation and indexing processes. Experiment results demonstrate that similar effectiveness can be achieved at a cost in indexing time that is roughly linear in the average number of known translations for each term.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {324–333},
numpages = {10}
}

@inproceedings{10.5555/645319.757468,
author = {Sormunen, Eero},
title = {A Retrospective Evaluation Method for Exact-Match and Best-Match Queries Applying an Interactive Query Performance Analyser},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A retrospective method for the performance comparison of Boolean and best-match queries is introduced. The method is based on the interactive optimisation of queries by a group of test searchers using a query performance analyser. The case experiment focused on comparing the maximum effectiveness of Boolean exact-match queries, and structured and unstructured best-match queries. The experiment verified the problems in maintaining precision of Boolean queries at high recall levels. Interesting similarities were also observed between structured and unstructured best-match queries giving new light on the results of earlier studies. The case experiment showed that the proposed evaluation method yields more elaborated results in comparisons than earlier query-centred methods.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {334–352},
numpages = {19}
}

@inproceedings{10.5555/645319.649277,
author = {Finn, Aidan and Kushmerick, Nicholas and Smyth, Barry},
title = {Genre Classification and Domain Transfer for Information Filtering},
year = {2002},
isbn = {3540433430},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The World Wide Web is a vast repository of information, but the sheer volume makes it difficult to identify useful documents. We identify document genre is an important factor in retrieving useful documents and focus on the novel document genre dimension of subjectivity. We investigate three approaches to automatically classifying documents by genre: traditional bag of words techniques, part-of-speech statistics, and hand-crafted shallow linguistic features. We are particularly interested in domain transfer: how well the learned classifiers generalize from the training corpus to a new document corpus. Our experiments demonstrate that the part-of-speech approach is better than traditional bag of words techniques, particularly in the domain transfer conditions.},
booktitle = {Proceedings of the 24th BCS-IRSG European Colloquium on IR Research: Advances in Information Retrieval},
pages = {353–362},
numpages = {10}
}

