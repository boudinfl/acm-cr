@inproceedings{10.5555/2964060.2964062,
author = {Gao, Ning and Webber, William and Oard, Douglas W.},
title = {Reducing Reliance on Relevance Judgments for System Comparison by Using Expectation-Maximization},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Relevance judgments are often the most expensive part of information retrieval evaluation, and techniques for comparing retrieval systems using fewer relevance judgments have received significant attention in recent years. This paper proposes a novel system comparison method using an expectation-maximization algorithm. In the expectation step, real-valued pseudo-judgments are estimated from a set of system results. In the maximization step, new system weights are learned from a combination of a limited number of actual human judgments and system pseudo-judgments for the other documents. The method can work without any human judgments, and is able to improve its accuracy by incrementally adding human judgments. Experiments using TREC Ad Hoc collections demonstrate strong correlations with system rankings using pooled human judgments, and comparison with existing baselines indicates that the new method achieves the same comparison reliability with fewer human judgments.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {1–12},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964063,
author = {Wilkie, Colin and Azzopardi, Leif},
title = {Best and Fairest: An Empirical Analysis of Retrieval System Bias},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we explore the bias of term weighting schemes used by retrieval models. Here, we consider bias as the extent to which a retrieval model unduly favours certain documents over others because of characteristics within and about the document. We set out to find the least biased retrieval model/weighting. This is largely motivated by the recent proposal of a new suite of retrieval models based on the Divergence From Independence DFI framework. The claim is that such models provide the fairest term weighting because they do not make assumptions about the term distribution unlike most other retrieval models. In this paper, we empirically examine whether fairness is linked to performance and answer the question; is fairer better?},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {13–25},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964064,
author = {Din\c{c}er, B. Taner and Ounis, Iadh and Macdonald, Craig},
title = {Tackling Biased Baselines in the Risk-Sensitive Evaluation of Retrieval Systems},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The aim of optimising information retrieval IR systems using a risk-sensitive evaluation methodology is to minimise the  risk  of performing any particular topic less effectively than a given baseline system. Baseline systems in this context determine the reference effectiveness for topics, relative to which the effectiveness of a given IR system in minimising the risk will be measured. However, the comparative risk-sensitive evaluation of a set of diverse IR systems --- as attempted by the TREC 2013 Web track --- is challenging, as the different systems under evaluation may be based upon a variety of different base retrieval models, such as learning to rank or language models. Hence, a question arises about how to properly measure the risk exhibited by each system. In this paper, we argue that no model of information retrieval alone is representative enough in this respect to be a true reference for the models available in the current state-of-the-art, and demonstrate, using the TREC\"{\i} undefined2012 Web track data, that as the baseline system changes, the resulting risk-based ranking of the systems changes significantly. Instead of using a particular system's effectiveness as the reference effectiveness for topics, we propose several remedies including the use of mean within-topic system effectiveness as a baseline, which is shown to enable unbiased measurements of the risk-sensitive effectiveness of IR systems.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {26–38},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_4,
author = {Zhang, Chenyi and Zhao, Xueyi and Wang, Ke and Sun, Jianling},
title = {Content + Attributes: A Latent Factor Model for Recommending Scientific Papers in Heterogeneous Academic Networks},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_4},
doi = {10.1007/978-3-319-06028-6_4},
abstract = {This paper focuses on the precise recommendation of scientific papers in academic networks where users' social structure, items' content and attributes exist and have to be profoundly exploited. Different from conventional collaborative filtering cases with only a user-item utility matrix, we study the standard latent factor model and extend it to a heterogeneous one, which models the interaction of different kinds of information. This latent model is called "Content + Attributes", which incorporates latent topics and descriptive attributes using probabilistic matrix factorization and topic modeling to figure out the final recommendation results in heterogeneous scenarios. Moreover, we further propose a solution to handle the cold start problem of new users by adopting social structures. We conduct extensive experiments on the DBLP dataset and the experimental results show that our proposed model outperforms the baseline methods.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {39–50},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_5,
author = {Lommatzsch, Andreas},
title = {Real-Time News Recommendation Using Context-Aware Ensembles},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_5},
doi = {10.1007/978-3-319-06028-6_5},
abstract = {With the rapidly growing amount of items and news articles on the internet, recommender systems are one of the key technologies to cope with the information overload and to assist users in finding information matching the their individual preferences. News and domain-specific information portals are important knowledge sources on the Web frequently accessed by millions of users. In contrast to product recommender systems, news recommender systems must address additional challenges, e.g. short news article lifecycles, heterogonous user interests, strict time constraints, and context-dependent article relevance. Since news articles have only a short time to live, recommender models have to be continuously adapted, ensuring that the recommendations are always up-to-date, hampering the pre-computations of suggestions. In this paper we present our framework for providing real-time news recommendations. We discuss the implemented algorithms optimized for the news domain and present an approach for estimating the recommender performance. Based on our analysis we implement an agent-based recommender system, aggregation several different recommender strategies. We learn a context-aware delegation strategy, allowing us to select the best recommender algorithm for each request. The evaluation shows that the implemented framework outperforms traditional recommender approaches and allows us to adapt to the specific properties of the considered news portals and recommendation requests.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {51–62},
numpages = {12},
keywords = {real-time recommendations, context-aware ensemble, online evaluation},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_6,
author = {Rikitianskii, Andrei and Harvey, Morgan and Crestani, Fabio},
title = {A Personalised Recommendation System for Context-Aware Suggestions},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_6},
doi = {10.1007/978-3-319-06028-6_6},
abstract = {The recently introduced TREC Contextual Suggestion track proposes the problem of suggesting contextually relevant places to a user visiting a new city based on his/her preferences and the location of the new city. In this paper we introduce a more sophisticated approach to this problem which very carefully constructs user profiles in order to provide more accurate and relevant recommendations. Based on the track evaluations we demonstrate that our system not only significantly outperforms a baseline method but also performs very well in comparison to other runs submitted to the track, managing to achieve the best results in nearly half of all test contexts.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {63–74},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_7,
author = {Schuth, Anne and Sietsma, Floor and Whiteson, Shimon and Rijke, Maarten},
title = {Optimizing Base Rankers Using Clicks},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_7},
doi = {10.1007/978-3-319-06028-6_7},
abstract = {We study the problem of optimizing an individual base ranker using clicks. Surprisingly, while there has been considerable attention for using clicks to optimize linear combinations of base rankers, the problem of optimizing an individual base ranker using clicks has been ignored. The problem is different from the problem of optimizing linear combinations of base rankers as the scoring function of a base ranker may be highly non-linear. For the sake of concreteness, we focus on the optimization of a specific base ranker, viz. BM25. We start by showing that significant improvements in performance can be obtained when optimizing the parameters of BM25 for individual datasets. We also show that it is possible to optimize these parameters from clicks, i.e., without the use of manually annotated data, reaching or even beating manually tuned parameters.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {75–87},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_8,
author = {Arguello, Jaime},
title = {Predicting Search Task Difficulty},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_8},
doi = {10.1007/978-3-319-06028-6_8},
abstract = {Search task difficulty refers to a user's assessment about the amount of effort required to complete a search task. Our goal in this work is to learn predictive models of search task difficulty. We evaluate features derived from the user's interaction with the search engine as well as features derived from the user's level of interest in the task and level of prior knowledge in the task domain. In addition to user-interaction features used in prior work, we evaluate features generated from scroll and mouse-movement events on the SERP. In some situations, we may prefer a system that can predict search task difficulty early in the search session. To this end, we evaluate features in terms of whole-session evidence and first-round evidence, which excludes all interactions starting with the second query. Our results found that the most predictive features were different for whole-session vs.\"{\i} undefinedfirst-round prediction, that mouseover features were effective for first-round prediction, and that level of interest and prior knowledge features did not improve performance.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {88–99},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964158,
author = {Ostroumova, Liudmila and Bogatyy, Ivan and Chelnokov, Arseniy and Tikhonov, Alexey and Gusev, Gleb},
title = {Crawling Policies Based on Web Page Popularity Prediction},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we focus on crawling strategies for newly discovered URLs. Since it is impossible to crawl all the new pages right after they appear, the most important or popular pages should be crawled with a higher priority. One natural measure of page importance is the number of user visits. However, the popularity of newly discovered URLs cannot be known in advance, and therefore should be predicted relying on URLs' features. In this paper, we evaluate several methods for predicting new page popularity against previously investigated crawler performance measurements, and propose a novel measurement setup aiming to evaluate crawler performance more realistically. In particular, we compare short-term and long-term popularity of new ephemeral URLs by estimating the rate of popularity decay. Our experiments show that the information about popularity decay can be effectively used for optimizing ordering policies of crawlers, but further research is required to predict it accurately enough.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {100–111},
numpages = {12},
keywords = {new web pages, crawling policies, popularity prediction},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964160,
author = {Traub, Myriam C. and Ossenbruggen, Jacco and He, Jiyin and Hardman, Lynda},
title = {Measuring the Effectiveness of Gamesourcing Expert Oil Painting Annotations},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Tasks that require users to have expert knowledge are difficult to crowdsource. They are mostly too complex to be carried out by non-experts and the available experts in the crowd are difficult to target. Adapting an expert task into a non-expert user task, thereby enabling the ordinary "crowd" to accomplish it, can be a useful approach. We studied whether a simplified version of an expert annotation task can be carried out by non-expert users. Users conducted a game-style annotation task of oil paintings. The obtained annotations were compared with those from experts. Our results show a significant agreement between the annotations done by experts and non-experts, that users improve over time and that the aggregation of users' annotations per painting increases their precision.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {112–123},
numpages = {12},
keywords = {wisdom of the crowd, expert tasks, crowdsourcing, annotations},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964161,
author = {Yates, Andrew and Goharian, Nazli and Frieder, Ophir},
title = {Relevance-Ranked Domain-Specific Synonym Discovery},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Interest in domain-specific search is growing rapidly, creating a need for domain-specific synonym discovery. The best-performing methods for this task rely on query logs and are thus difficult to use in many circumstances. We propose a method for domain-specific synonym discovery that requires only a domain-specific corpus. Our method substantially outperforms previously proposed methods in realistic evaluations. Due to the difficulty of identifying pairs of synonyms from among a large number of terms, methods have traditionally been evaluated by their ability to choose a target term's synonym from a small set of candidate terms. We generalize this evaluation by evaluating methods' performance when required to choose a target term's synonym from progressively larger sets of candidate terms. We approach synonym discovery as a ranking problem and evaluate the methods' ability to rank a target term's candidate synonyms. Our results illustrate that while our proposed method substantially outperforms existing methods, synonym discovery is still a difficult task to automate and is best coupled with a human moderator.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {124–135},
numpages = {12},
keywords = {domain-specific search, Synonym discovery, thesaurus construction},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964162,
author = {Chhabra, Shruti and Bedathur, Srikanta},
title = {Towards Generating Text Summaries for Entity Chains},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Given a large knowledge graph, discovering meaningful relationships between a given pair of entities has gained a lot of attention in the recent times. Most existing algorithms focus their attention on identifying one or more structures ---such as relationship chains or subgraphs--- between the entities. The burden of interpreting these results, after combining with contextual information and description of relationships, lies with the user. In this paper, we present a framework that eases this burden by generating a textual summary which incorporates the context and description of individual dyadic relationships, and combines them to generate a ranked list of summaries. We develop a model that captures key properties of a well-written text, such as coherence and information content. We focus our attention on a special class of relationship structures, two-length entity chains, and show that the generated ranked list of summaries have 79% precision at rank-1. Our results demonstrate that the generated summaries are quite useful to users.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {136–147},
numpages = {12},
keywords = {text summarization, entity chain, entity-relationship graphs, relationship queries},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964164,
author = {Li, Le and Smucker, Mark D.},
title = {Tolerance of Effectiveness Measures to Relevance Judging Errors},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Crowdsourcing relevance judgments for test collection construction is attractive because the practice has the possibility of being more affordable than hiring high quality assessors. A problem faced by all crowdsourced judgments --- even judgments formed from the consensus of multiple workers --- is that there will be differences in the judgments compared to the judgments produced by high quality assessors. For two TREC test collections, we simulated errors in sets of judgments and then measured the effect of these errors on effectiveness measures. We found that some measures appear to be more tolerant of errors than others. We also found that to achieve high rank correlation in the ranking of retrieval systems requires conservative judgments for average precision AP and nDCG, while precision at rank 10 requires neutral judging behavior. Conservative judging avoids mistakenly judging non-relevant documents as relevant at the cost of judging some relevant documents as non-relevant. In addition, we found that while conservative judging behavior maximizes rank correlation for AP and nDCG, to minimize the error in the measures' values requires more liberal behavior. Depending on the nature of a set of crowdsourced judgments, the judgments may be more suitable with some effectiveness measures than others, and the use of some effectiveness measures will require higher levels of judgment quality than others.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {148–159},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964165,
author = {Lv, Yuanhua and Fuxman, Ariel and Chandra, Ashok K.},
title = {Evaluation of IR Applications with Constrained Real Estate},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Traditional IR applications assume that there is always enough space "real estate" available to display as many results as the system returns. Consequently, traditional evaluation metrics were typically designed to take a length cutoff k of the result list as a parameter. For example, one computes DCG@k, Prec@k, etc., based on the top-k results in the ranking list. However, there are important modern ranking applications where the result real estate is constrained to a small fixed space, such as the search verticals aggregated in the Web search results and the recommendation systems. For such applications, the following tradeoff arises: given a fixed amount of real estate, shall we show a small number of results with rich captions and details, or a larger number of results with less informative captions? In other words, there is a tradeoff between the length of the result list i.e., quantity and the informativeness of the results i.e., quality. This tradeoff has important implications for evaluation metrics, since it leads the length cutoff k hard to be determined a priori. In order to tackle this problem, we propose two desirable formal constraints to capture the heuristics of regulating the quantity-quality tradeoff, inspired by the axiomatic approach to IR. We then present a general method to normalize the well-known Discounted Cumulative Gain DCG metric for balancing the quantity-quality tradeoff, yielding a new metric, that we call Length-adjusted Discounted Cumulative Gain LDCG. LDCG is shown to be able to automatically balance the length and the informativeness of a ranking list without requiring an explicit parameter k, while still preserving the good properties of DCG.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {160–171},
numpages = {12},
keywords = {Constrained Real Estate, Evaluation, Aggregated Search, LDCG, Quantity-Quality Tradeoff, LNDCG},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964166,
author = {Kazai, Gabriella and Sung, Homer},
title = {Dissimilarity Based Query Selection for Efficient Preference Based IR Evaluation},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The evaluation of Information Retrieval IR systems has recently been exploring the use of preference judgments over two lists of search results, presented side-by-side to judges. Such preference judgments have been shown to capture a richer set of relevance criteria than traditional methods of collecting relevance labels per single document. However, preference judgments over lists are expensive to obtain and are less reusable as any change to either side necessitates a new judgment. In this paper, we propose a way to measure the dissimilarity between two sides in side-by-side evaluation experiments and show how this measure can be used to prioritize queries to be judged in an offline setting. Our proposed measure, referred to as Weighted Ranking Difference WRD, takes into account both the ranking differences and the similarity of the documents across the two sides, where a document may, for example, be a URL or a query suggestion. We empirically evaluate our measure on a large-scale, real-world dataset of crowdsourced preference judgments over ranked lists of auto-completion suggestions. We show that the WRD score is indicative of the probability of tie preference judgments and can, on average, save 25% of the judging resources.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {172–183},
numpages = {12},
keywords = {judging cost reduction, preference judgments, query prioritization, weighted ranked difference measure, Side-by-side evaluation},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964168,
author = {Lefortier, Damien and Serdyukov, Pavel and Romanenko, Fedor and Rijke, Maarten},
title = {Blending Vertical and Web Results},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Modern search engines aggregate results from specialized verticals into the Web search results. We study a setting where vertical and Web results are blended into a single result list, a setting that has not been studied before. We focus on video intent and present a detailed observational study of Yandex's two video content sources i.e., the specialized vertical and a subset of the general web index thus providing insights into their complementary character. By investigating how to blend results from these sources, we contrast traditional federated search and fusion-based approaches with newly proposed approaches that significantly outperform the baseline methods.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {184–196},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964169,
author = {Makeev, Stanislav and Plakhov, Andrey and Serdyukov, Pavel},
title = {Personalizing Aggregated Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Aggregated search nowadays has become a widespread technique of generating Search Engine Result Page SERP. The main task of aggregated search is incorporating results from a number of specialized search collections often referenced as verticals into a ranked list of Web-search results. To proceed with the blending algorithm one can use a variety of different sources of information starting from some textual features up to query-log data. In this paper we study the usefulness of personalized features for improving the quality of aggregated search ranking. The study is carried out by training a number of machine-learned blending algorithms, which differ by the sets of used features. Thus we not only measure the value of personalized approach in the aggregated search context, but also find out which classes of personalized features outperform the others.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {197–209},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964170,
author = {Luo, Chen and Guan, Renchu and Wang, Zhe and Lin, Chenghua},
title = {HetPathMine: A Novel Transductive Classification Algorithm on Heterogeneous Information Networks},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Transductive classification TC using a small labeled data to help classifying all the unlabeled data in information networks. It is an important data mining task on information networks. Various classification methods have been proposed for this task. However, most of these methods are proposed for homogeneous networks but not for heterogeneous ones, which include multi-typed objects and relations and may contain more useful semantic information. In this paper, we firstly use the concept of meta path to represent the different relation paths in heterogeneous networks and propose a novel meta path selection model. Then we extend the transductive classification problem to heterogeneous information networks and propose a novel algorithm, named HetPathMine. The experimental results show that: 1 HetPathMine can get higher accuracy than the existing transductive classification methods and 2 the weight obtained by HetPathMine for each meta path is consistent with human intuition or real-world situations.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {210–221},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964172,
author = {Nguyen, Tu Ngoc and Kanhabua, Nattiya},
title = {Leveraging Dynamic Query Subtopics for Time-Aware Search Result Diversification},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Search result diversification is a common technique for tackling the problem of ambiguous and multi-faceted queries by maximizing query aspects or subtopics in a result list. In some special cases, subtopics associated to such queries can be temporally ambiguous, for instance, the query US Open is more likely to be targeting the tennis open in September, and the golf tournament in June. More precisely, users' search intent can be identified by the popularity of a subtopic with respect to the time where the query is issued. In this paper, we study search result diversification for time-sensitive queries, where the temporal dynamics of query subtopics are explicitly determined and modeled into result diversification. Unlike aforementioned work that, in general, considered only static subtopics, we leverage dynamic subtopics by analyzing two data sources i.e., query logs and a document collection. By using these data sources, it provides the insights from different perspectives of how query subtopics change over time. Moreover, we propose novel time-aware diversification methods that leverage the identified dynamic subtopics. A key idea is to re-rank search results based on the freshness and popularity of subtopics. To this end, our experimental results show that the proposed methods can significantly improve the diversity and relevance effectiveness for time-sensitive queries in comparison with state-of-the-art methods.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {222–234},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964173,
author = {Yang, Bishan and Parikh, Nish and Singh, Gyanit and Sundaresan, Neel},
title = {A Study of Query Term Deletion Using Large-Scale E-Commerce Search Logs},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Query term deletion is one of the commonly used strategies for query rewriting. In this paper, we study the problem of query term deletion using large-scale e-commerce search logs. Specifically, we focus on queries that do not lead to user clicks and aim to predict a reduced and better query that can lead to clicks by term deletion. Accurate prediction of term deletion can potentially help users recover from poor search results and improve shopping experience. To achieve this, we use various term-dependent and query-dependent measures as features and build a classifier to predict which term is the most likely to be deleted from a given query. Our approach is data-driven. We investigate the large-scale query history and the document collection, verify the usefulness of previously proposed features, and also propose to incorporate the query category information into the term deletion predictors. We observe that training within-category classifiers can result in much better performance than training a unified classifier. We validate our approach using a large collection of query sessions logs from a leading e-commerce site and demonstrate that our approach provides promising performance in query term deletion prediction.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {235–246},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964174,
author = {Thuma, Edwin and Rogers, Simon and Ounis, Iadh},
title = {Detecting Missing Content Queries in an SMS-Based HIV/AIDS FAQ Retrieval System},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Automated Frequently Asked Question FAQ answering systems use pre-stored sets of question-answer pairs as an information source to answer natural language questions posed by the users. The main problem with this kind of information source is that there is no guarantee\"{\i} undefinedthat there will be a relevant question-answer pair for all user queries. In this paper, we propose to deploy a binary classifier in an existing SMS-Based HIV/AIDS FAQ retrieval system to detect user queries that do not have the relevant question-answer pair in the FAQ document collection. Before deploying such a classifier, we first evaluate different feature sets for training in order to determine the sets of features that can build a model that yields the best classification accuracy. We carry out our evaluation using seven different feature sets generated from a query log before and after retrieval by the FAQ retrieval system. Our results suggest that, combining different feature sets markedly improves the classification accuracy.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {247–259},
numpages = {13},
keywords = {Missing Content Queries, Text Classification, Frequently Asked Question},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964176,
author = {Lee, Chia-Jung and Croft, W. Bruce},
title = {Cross-Language Pseudo-Relevance Feedback Techniques for Informal Text},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Previous work has shown that pseudo relevance feedback PRF can be effective for cross-lingual information retrieval CLIR. This research was primarily based on corpora such as news articles that are written using relatively formal language. In this paper, we revisit the problem of CLIR with a focus on the problems that arise with informal text, such as blogs and forums. To address the problem of the two major sources of "noisy" text, namely translation and the informal nature of the documents, we propose to select between inter- and intra-language PRF, based on the properties of the language of the query and corpora being searched. Experimental results show that this approach can significantly outperform state-of-the-art results reported for monolingual and cross-lingual environments. Further analysis indicates that inter-language PRF is particularly helpful for queries with poor translation quality. Intra-language PRF is more useful for high-quality translated queries as it reduces the impact of any potential translation errors in documents.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {260–272},
numpages = {13},
keywords = {pseudo-relevance feedback, Informal text, discussion forum, cross-language information retrieval},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964177,
author = {Marcheggiani, Diego and T\"{a}ckstr\"{o}m, Oscar and Esuli, Andrea and Sebastiani, Fabrizio},
title = {Hierarchical Multi-Label Conditional Random Fields for Aspect-Oriented Opinion Mining},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A common feature of many online review sites is the use of an overall rating that summarizes the opinions expressed in a review. Unfortunately, these document-level ratings do not provide any information about the opinions contained in the review that concern a specific aspect e.g., cleanliness of the product being reviewed e.g., a hotel. In this paper we study the finer-grained problem of aspect-oriented opinion mining at the sentence level, which consists of predicting, for all sentences in the review, whether the sentence expresses a positive, neutral, or negative opinion or no opinion at all about a specific aspect of the product. For this task we propose a set of increasingly powerful models based on conditional random fields CRFs, including a hierarchical multi-label CRFs scheme that jointly models the overall opinion expressed in the review and the set of aspect-specific opinions expressed in each of its sentences. We evaluate the proposed models against a dataset of hotel reviews which we here make publicly available in which the set of aspects and the opinions expressed concerning them are manually annotated at the sentence level. We find that both hierarchical and multi-label factors lead to improved predictions of aspect-oriented opinions.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {273–285},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964178,
author = {Graus, David and Tsagkias, Manos and Buitinck, Lars and Rijke, Maarten},
title = {Generating Pseudo-Ground Truth for Predicting New Concepts in Social Streams},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The manual curation of knowledge bases is a bottleneck in fast paced domains where new concepts constantly emerge. Identification of nascent concepts is important for improving early entity linking, content interpretation, and recommendation of new content in real-time applications. We present an unsupervised method for generating pseudo-ground truth for training a named entity recognizer to specifically identify entities that will become concepts in a knowledge base in the setting of social streams. We show that our method is able to deal with missing labels, justifying the use of pseudo-ground truth generation in this task. Finally, we show how our method significantly outperforms a lexical-matching baseline, by leveraging strategies for sampling pseudo-ground truth based on entity confidence scores and textual quality of input documents.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {286–298},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964180,
author = {Alsum, Ahmed and Nelson, Michael L.},
title = {Thumbnail Summarization Techniques for Web Archives},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Thumbnails of archived web pages as they appear in common browsers such as Firefox or Chrome can be useful to convey the nature of a web page and how it has changed over time. However, creating thumbnails for all archived web pages is not feasible for large collections, both in terms of time to create the thumbnails and space to store them. Furthermore, at least for the purposes of initial exploration and collection understanding, people will likely only need a few dozen thumbnails and not thousands. In this paper, we develop different algorithms to optimize the thumbnail creation procedure for web archives based on information retrieval techniques. We study different features based on HTML text that correlate with changes in rendered thumbnails so we can know in advance which archived pages to use for thumbnails. We find that SimHash correlates with changes in the thumbnails  \"{\i} undefined =0.59,  p &lt;0.005. We propose different algorithms for thumbnail creation suitable for different applications, reducing the number of thumbnails to be generated to 9% --- 27% of the total size.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {299–310},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964181,
author = {Caragea, Cornelia and Wu, Jian and Ciobanu, Alina and Williams, Kyle and Fern\'{a}ndez-Ram\'{\i}rez, Juan and Chen, Hung-Hsuan and Wu, Zhaohui and Giles, Lee},
title = {CiteSeerx: A Scholarly Big Dataset},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The CiteSeer <emphasis fontcategory="NonProportional">x</emphasis>  digital library stores and indexes research articles in Computer Science and related fields. Although its main purpose is to make it easier for researchers to search for scientific information, CiteSeer <emphasis fontcategory="NonProportional">x</emphasis>  has been proven as a powerful resource in many data mining, machine learning and information retrieval applications that use rich metadata, e.g., titles, abstracts, authors, venues, references lists, etc. The metadata extraction in CiteSeer <emphasis fontcategory="NonProportional">x</emphasis>  is done using automated techniques. Although fairly accurate, these techniques still result in noisy metadata. Since the performance of models trained on these data highly depends on the quality of the data, we propose an approach to CiteSeer <emphasis fontcategory="NonProportional">x</emphasis>  metadata cleaning that incorporates information from an external data source. The result is a subset of CiteSeer <emphasis fontcategory="NonProportional">x</emphasis> , which is substantially cleaner than the entire set. Our goal is to make the new dataset available to the research community to facilitate future work in Information Retrieval.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {311–322},
numpages = {12},
keywords = {Scholarly Big Data, Record Linkage, CiteSeerx},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964182,
author = {Koolen, Marijn},
title = {"User Reviews in the Search Index? That'll Never Work!"},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Online book search services allow users to tag and review books but do not include such data in the search index, which only contains titles, author names and professional subject descriptors. Such professional metadata is a limited description of the book, whereas tags and reviews can describe the content in more detail and cover many other aspects such as quality, writing style and engagement. In this paper we investigate the impact of including such user-generated content in the search index of a large collection of book records from Amazon and LibraryThing. We find that professional metadata is often too limited to provide good recall and precision and that both user reviews and tags can substantially improve performance. We perform a detailed analysis of different types of metadata and their impact on a number of topic categories and find that user-generated content is effective for a range of information needs. These findings are of direct relevance to large online book sellers and social cataloguing sites.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {323–334},
numpages = {12},
keywords = {User-Generated Content, Book Search, Metadata, Social Media},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964066,
author = {Houlsby, Neil and Ciaramita, Massimiliano},
title = {A Scalable Gibbs Sampler for Probabilistic Entity Linking},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Entity linking involves labeling phrases in text with their referent entities, such as Wikipedia or Freebase entries. This task is challenging due to the large number of possible entities, in the millions, and heavy-tailed mention ambiguity. We formulate the problem in terms of probabilistic inference within a topic model, where each topic is associated with a Wikipedia article. To deal with the large number of topics we propose a novel efficient Gibbs sampling scheme which can also incorporate side information, such as the Wikipedia graph. This conceptually simple probabilistic approach achieves state-of-the-art performance in entity-linking on the Aida-CoNLL dataset.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {335–346},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964067,
author = {Filice, Simone and Castellucci, Giuseppe and Croce, Danilo and Basili, Roberto},
title = {Effective Kernelized Online Learning in Language Processing Tasks},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Kernel-based methods for NLP tasks have been shown to enable robust and effective learning, although their inherent complexity is manifest also in Online Learning OL scenarios, where time and memory usage grows along with the arrival of new examples. A state-of-the-art budgeted OL algorithm is here extended to efficiently integrate complex kernels by constraining the overall complexity. Principles of Fairness and Weight Adjustment are applied to mitigate imbalance in data and improve the model stability. Results in Sentiment Analysis in Twitter and Question Classification show that performances very close to the state-of-the-art achieved by batch algorithms can be obtained.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {347–358},
numpages = {12},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964068,
author = {Catena, Matteo and Macdonald, Craig and Ounis, Iadh},
title = {On Inverted Index Compression for Search Engine Efficiency},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Efficient access to the inverted index data structure is a key aspect for a search engine to achieve fast response times to users' queries. While the performance of an information retrieval IR system can be enhanced through the compression of its posting lists, there is little recent work in the literature that thoroughly compares and analyses the performance of modern integer compression schemes across different types of posting information document ids, frequencies, positions. In this paper, we experiment with different modern integer compression algorithms, integrating these into a modern IR system. Through comprehensive experiments conducted on two large, widely used document corpora and large query sets, our results show the benefit of compression for different types of posting information to the space- and time-efficiency of the search engine. Overall, we find that the simple Frame of Reference compression scheme results in the best query response times for all types of posting information. Moreover, we observe that the frequency and position posting information in Web corpora that have large volumes of anchor text are more challenging to compress, yet compression is beneficial in reducing average query response times.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {359–371},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964070,
author = {Goswami, Parantapa and Moura, Simon and Gaussier, Eric and Amini, Massih-Reza and Maes, Francis},
title = {Exploring the Space of IR Functions},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we propose an approach to discover functions for IR ranking from a space of simple closed-form mathematical functions. In general, all IR ranking models are based on two basic variables, namely, term frequency and document frequency. Here a grammar for generating all possible functions is defined which consists of the two above said variables and basic mathematical operations - addition, subtraction, multiplication, division, logarithm, exponential and square root. The large set of functions generated by this grammar is filtered by checking mathematical feasibility and satisfiability to heuristic constraints on IR scoring functions proposed by the community. Obtained candidate functions are tested on various standard IR collections and several simple but highly efficient scoring functions are identified. We show that these newly discovered functions are outperforming other state-of-the-art IR scoring models through extensive experimentation on several IR collections. We also compare the performance of functions satisfying IR constraints to those which do not, and show that the former set of functions clearly outperforms the latter one.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {372–384},
numpages = {13},
keywords = {Function Generation, Automatic Discovery, IR Theory},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964071,
author = {Brucato, Matteo and Montesi, Danilo},
title = {Metric Spaces for Temporal Information Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Documents and queries are rich in temporal features, both at the meta-level and at the content-level. We exploit this information to define temporal scope similarities between documents and queries in metric spaces. Our experiments show that the proposed metrics can be very effective for modeling the relevance for different search tasks, and provide insights into an inherent asymmetry in temporal query semantics. Moreover, we propose a simple ranking model that combines the temporal scope similarity with traditional keyword similarities. We experimentally show that it is not worse than traditional keyword-based rankings for non-temporal queries, and that it improves the overall effectiveness for time-based queries.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {385–397},
numpages = {13},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964072,
author = {Bai, Lu and Guo, Jiafeng and Lan, Yanyan and Cheng, Xueqi},
title = {Local Linear Matrix Factorization for Document Modeling},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Mining low dimensional semantic representations of document is a key problem in many document analysis and information retrieval tasks. Previous studies show better representation mining results by incorporating geometric relationships among documents. However, existing methods model the geometric relationships between a document and its neighbors as independent pairwise relationship; while the pairwise relationship relies on some heuristic similarity/dissimilarity measures and predefined threshold. To address these problems, we propose a Local Linear Matrix Factorization LLMF, for low dimensional representation learning. Specifically, LLMF exploits the geometric relationships between a document and its neighbors based on local linear combination assumption, which encodes richer geometric information among the documents. Moreover, the linear combination relationships can be learned from the data without any heuristic parameter definition. We present an iterative model fitting algorithm based on quasi-Newton method for the optimization of LLMF. In the experiments, we compare LLMF with the state-of-the-art semantic mining methods on two text data sets. The experimental results show that LLMF can produce better document representations and higher accuracy in document classification task.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {398–411},
numpages = {14},
keywords = {document modeling, local linear combination, matrix factorization},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964074,
author = {Ghamdi, Manal Al and Gotoh, Yoshihiko},
title = {Video Clip Retrieval by Graph Matching},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents a new approach to video clip retrieval using the Earth Mover's Distance EMD. The approach builds on the many-to-many match methodology between two graph-based representations. The problem of measuring similarity between two clips is formulated as a graph matching task in two stages. First, a bipartite graph with spatio-temporal neighbourhood is constructed to explore the relation between data points and estimate the relevance between a pair of video clips. Secondly, using the EMD, the problem of matching a clip pair is converted to computing the minimum cost of transportation within the spatio-temporal graph. Experimental results on the UCF YouTube Action dataset show that the presented work attained a significant improvement in retrieval capability over conventional techniques.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {412–417},
numpages = {6},
keywords = {Earth Mover's Distance, graph matching, video retrieval},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964075,
author = {Bansal, Romil and Panem, Sandeep and Gupta, Manish and Varma, Vasudeva},
title = {EDIUM: Improving Entity Disambiguation via User Modeling},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Entity Disambiguation is the task of associating entity name mentions in text to the correct referent entities in the knowledge base, with the goal of understanding and extracting useful information from the document. Entity disambiguation is a critical component of systems designed to harness information shared by users on microblogging sites like Twitter. However, noise and lack of context in tweets makes disambiguation a difficult task. In this paper, we describe an Entity Disambiguation system, EDIUM, which uses User interest Models to disambiguate the entities in the user's tweets. Our system jointly models the user's interest scores and the context disambiguation scores, thus compensating the sparse context in the tweets for a given user. We evaluated the system's entity linking capabilities on tweets from multiple users and showed that improvement can be achieved by combining the user models and the context based models.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {418–423},
numpages = {6},
keywords = {Entity Disambiguation, Knowledge Graph, User Modeling},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964076,
author = {Barr\'{o}n-Cede\~{n}o, Alberto and Paramita, Monica Lestari and Clough, Paul and Rosso, Paolo},
title = {A Comparison of Approaches for Measuring Cross-Lingual Similarity of Wikipedia Articles},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Wikipedia has been used as a source of comparable texts for a range of tasks, such as Statistical Machine Translation and Cross-Language Information Retrieval. Articles written in different languages on the same topic are often connected through inter-language-links. However, the extent to which these articles are similar is highly variable and this may impact on the use of Wikipedia as a comparable resource. In this paper we compare various language-independent methods for measuring cross-lingual similarity: character n-grams, cognateness, word count ratio, and an approach based on outlinks. These approaches are compared against a baseline utilising MT resources. Measures are also compared to human judgements of similarity using a manually created resource containing 700 pairs of Wikipedia articles in 7 language pairs. Results indicate that a combination of language-independent models char-n-grams, outlinks and word-count ratio is highly effective for identifying cross-lingual similarity and performs comparably to language-dependent models translation and monolingual analysis.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {424–429},
numpages = {6},
keywords = {Wikipedia, Cross-Lingual Similarity},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964077,
author = {Bellog\'{\i}n, Alejandro and Samar, Thaer and Vries, Arjen P. and Said, Alan},
title = {Challenges on Combining Open Web and Dataset Evaluation Results: The Case of the Contextual Suggestion Track},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The TREC 2013 Contextual Suggestion Track allowed participants to submit personalised rankings using documents either from the OpenWeb or from an archived, static Web collection, the ClueWeb12 dataset. We argue that this setting poses problems in how the performance of the participants should be compared. We analyse biases found in the process, both objective and subjective, and discuss these issues in the general framework of evaluating personalised Information Retrieval using dynamic against static datasets.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {430–436},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964078,
author = {Bouchoucha, Arbi and Liu, Xiaohua and Nie, Jian-Yun},
title = {Integrating Multiple Resources for Diversified Query Expansion},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Diversified query expansion aims to cover different possible intents of a short and ambiguous query. Most standard approaches use a single source of information, e.g., the initial retrieval list or some external resource like ConceptNet. The coverage is thus limited by that of the resource. To alleviate this issue, we propose the use of multiple resources. More specifically, our framework first automatically generates a list of diversified queries for each resource, and then combines the retrieved documents for all the expanded queries following the Maximal Marginal Relevance principal. We evaluate our framework on several TREC data sets, and demonstrate that our framework outperforms the state-of-the-art approaches, suggesting the effectiveness of incorporating different resources for diversified query expansion.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {437–442},
numpages = {6},
keywords = {Resource Integration, Diversified Query Expansion},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964079,
author = {Chen, Chen and Dongxing, Wu and Chunyan, Hou and Xiaojie, Yuan},
title = {Facet-Based User Modeling in Social Media for Personalized Ranking},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Micro-blogging service has grown to a popular social media and provides a number of real-time messages for users. Although these messages allow users to access information on-the-fly, users often complain the problems of information overload and information shortage. Thus, a variety of methods of information filtering and recommendation are proposed, which are associated with user modeling. In this study, we propose an effective method of user modeling, facet-based user modeling, to capture user's interests in social media. We evaluate our models in the context of personalized ranking of microblogs. Experiments on real-world data show that facet-based user modeling can provide significantly better ranking than traditional ranking methods. We also shed some light on how different facets impact user's interest.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {443–448},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_40,
author = {Corney, David and Martin, Carlos and G\"{o}ker, Ayse},
title = {Spot the Ball: Detecting Sports Events on Twitter},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_40},
doi = {10.1007/978-3-319-06028-6_40},
abstract = {Messages from social media are increasingly being mined to extract useful information and to detect trends. These can relate to matters as serious as earthquakes and wars or as trivial as haircuts and cats. Football remains one of the world's most popular sports, and events within big matches are heavily discussed on Twitter. It therefore provides an excellent case study for event detection.Here we analyse tweets about the FA Cup final, the climax of the English football season, for 2012 and 2013. We evaluate an automated topic detection system using a ground truth derived from mainstream media. We also show that messages can be associated with different teams' fans, and that they discuss the same events from very different perspectives.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {449–454},
numpages = {6},
keywords = {football, Twitter, topic detection},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964081,
author = {Djafari Naini, Kaweh and Altingovde, Ismail Sengor},
title = {Exploiting Result Diversification Methods for Feature Selection in Learning to Rank},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we adopt various greedy result diversification strategies to the problem of feature selection for learning to rank. Our experimental evaluations using several standard datasets reveal that such diversification methods are quite effective in identifying the feature subsets in comparison to the baselines from the literature.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {455–461},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964082,
author = {Gall\'{e}, Matthias and Renders, Jean-Michel},
title = {Boilerplate Detection and Recoding},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Many information access applications have to tackle natural language texts that contain a large proportion of repeated and mostly invariable patterns --- called boilerplates ---, such as automatic templates, headers, signatures and table formats. These domain-specific standard formulations are usually much longer than traditional collocations or standard noun phrases and typically cover one or more sentences. Such motifs clearly have a non-compositional meaning and an ideal document representation should reflect this phenomenon.We propose here a method that detects automatically and in an unsupervised way such motifs; and enriches the document representation by including specific features for these motifs. We experimentally show that this document recoding strategy leads to improved classification on different collections.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {462–467},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964083,
author = {Huang, Jia and Ding, Hao and Hu, Xiaohua and Liu, Yong},
title = {A Two-Level Approach for Subtitle Alignment},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we propose a two-level Needleman-Wunsch algorithm to align two subtitle files. We consider each subtitle file as a sequence of sentences, and each sentence as a sequence of characters. Our algorithm aligns the OCR and Web subtitles from both sentence level and character level. Experiments on ten datasets from two TV shows indicate that our algorithm outperforms the state-of-the-art approaches with an average precision and recall of 0.96 and 0.95.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {468–473},
numpages = {6},
keywords = {sequence alignment, dynamic programming, subtitle alignment},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964084,
author = {Kaptein, Rianne and Boertjes, Erik and Langley, David},
title = {Analyzing Discussions on Twitter: Case Study on HPV Vaccinations},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this work we analyze the discussions on Twitter around the Human papillomavirus HPV vaccinations. We collect a dataset consisting of tweets related to the HPV vaccinations by searching for relevant keywords, by retrieving the conversations on Twitter, and by retrieving tweets from our user group mentioning semi-relevant keywords. We find that by tracking the conversations on Twitter relevant tweets can be found with reasonable precision. Although sentiments and opinions change regularly in a discussion, we find few cases of topic drift.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {474–480},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_45,
author = {Kumar, Varun and Bhat, Savita and Pedanekar, Niranjan},
title = {Automatically Retrieving Explanatory Analogies from Webpages},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_45},
doi = {10.1007/978-3-319-06028-6_45},
abstract = {Explanatory analogies make learning complex concepts easier by elaborately mapping a target concept onto a more familiar source concept. Solutions exist for automatically retrieving shorter metaphors from natural language text, but not for explanatory analogies. In this paper, we propose an approach to find webpages containing explanatory analogies for a given target concept. For this, we propose the use of a 'region of interest' ROI based on the observation that linguistic markers and source concept often co-occur with various forms of the word 'analogy'. We also suggest an approach to identify the source concepts contained in a retrieved analogy webpage. We demonstrate these approaches on a dataset created using Google custom search to find candidate web pages that may contain analogies.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {481–486},
numpages = {6},
keywords = {Information Retrieval, Machine Learning, Webpages, Analogy},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_46,
author = {Li, Wen and Eickhoff, Carsten and Vries, Arjen P.},
title = {Geo-Spatial Domain Expertise in Microblogs},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_46},
doi = {10.1007/978-3-319-06028-6_46},
abstract = {In this paper, we present a framework for describing a user's geo-spatial domain expertise in microblog settings. We investigate a novel way of casting the expertise problem by using points of interest POI as a possible categorization of expertise. To this end, we study a large-scale sample of geo-tagged tweets and model users' location tracks in order to gain insights into their daily activities and competencies. Based on a qualitative user study among active Twitter users, we present an initial exploration of domain expertise indicators on microblogging portals and design a classification scheme that is able to reliably identify domain experts.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {487–492},
numpages = {6},
keywords = {Domain expertise, Geo-tagging, Twitter},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_47,
author = {Liang, Shangsong and Ren, Zhaochun and Rijke, Maarten},
title = {The Impact of Semantic Document Expansion on Cluster-Based Fusion for Microblog Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_47},
doi = {10.1007/978-3-319-06028-6_47},
abstract = {Searching microblog posts, with their limited length and creative language usage, is challenging. We frame the microblog search problem as a data fusion problem. We examine the effectiveness of a recent cluster-based fusion method on the task of retrieving microblog posts. We find that in the optimal setting the contribution of the clustering information is very limited, which we hypothesize to be due to the limited length of microblog posts. To increase the contribution of the clustering information in cluster-based fusion, we integrate semantic document expansion as a preprocessing step. We enrich the content of microblog posts appearing in the lists to be fused by Wikipedia articles, based on which clusters are created. We verify the effectiveness of our combined document expansion plus fusion method by making comparisons with microblog search algorithms and other fusion methods.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {493–499},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_48,
author = {Mcdonald, Graham and Macdonald, Craig and Ounis, Iadh and Gollins, Timothy},
title = {Towards a Classifier for Digital Sensitivity Review},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_48},
doi = {10.1007/978-3-319-06028-6_48},
abstract = {The sensitivity review of government records is essential before they can be released to the official government archives, to prevent sensitive information such as personal information, or that which is prejudicial to international relations from being released. As records are typically reviewed and released after a period of decades, sensitivity review practices are still based on paper records. The transition to digital records brings new challenges, e.g. increased volume of digital records, making current practices impractical to use. In this paper, we describe our current work towards developing a sensitivity review classifier that can identify and prioritise potentially sensitive digital records for review. Using a test collection built from government records with real sensitivities identified by government assessors, we show that considering the entities present in each record can markedly improve upon a text classification baseline.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {500–506},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964089,
author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li\^{e}n and Popineau, Fabrice},
title = {Unsupervised Approach for Identifying Users' Political Orientations},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Opinions, in news media platforms, provide a world wide access to what people think about daily life topics. Thus, exploiting such a source of information to identify the trends can be very useful in many scenarios, such as political parties who are interested in monitoring their impact. In this paper, we present an unsupervised technique to classify users based on their political orientations. Our approach is based on two main concepts: 1 the selection of the aspects and the sentiments users have expressed in their opinions, and 2 the creation of knowledge base from Wikipedia to automatically classify users according to their political orientations. We have tested our approach on two datasets crawled from CNN and Aljazeera. The results show that our approach achieves high quality results.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {507–512},
numpages = {6},
keywords = {Sentiment analysis, Political Opinion Mining, Political leaning},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964090,
author = {Mohd Shariff, Shafiza and Zhang, Xiuzhen and Sanderson, Mark},
title = {User Perception of Information Credibility of News on Twitter},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we examine user perception of credibility for news-related tweets. We conduct a user study on a crowd-sourcing platform to judge the credibility of such tweets. By analysing user judgments and comments, we find that eight features, including some that can not be automatically identified from tweets, are perceived by users as important for judging information credibility. Moreover, distinct features like link in tweet, display name and user belief consistently lead users to judge tweets as credible. We also find that users can not consistently judge or even misjudge the credibility for some tweets on politics news.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {513–518},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964091,
author = {Moniz, Andy and Jong, Franciska},
title = {Sentiment Analysis and the Impact of Employee Satisfaction on Firm Earnings},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Prior text mining studies of corporate reputational sentiment based on newswires, blogs and Twitter feeds have mostly captured reputation from the perspective of two groups of stakeholders --- the media and consumers. In this study we examine the sentiment of a potentially overlooked stakeholder group, namely, the firm's employees. First, we\"{\i} undefinedpresent a novel dataset that uses online employee reviews to capture employee satisfaction. We employ LDA to identify salient aspects in employees' reviews, and manually infer one latent topic that appears to be associated with the firm's outlook. Second, we create a composite document by aggregating employee reviews for each firm and measure\"{\i} undefinedemployee sentiment as the polarity of the composite document using the  General Inquirer  dictionary to count positive and negative terms. Finally, we define employee satisfaction as a weighted combination of the firm outlook topic cluster and employee sentiment. The results of our joint aspect-polarity model suggest that\"{\i} undefinedit may be beneficial for investors to incorporate a measure of employee satisfaction into their method for forecasting firm earnings.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {519–527},
numpages = {9},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964092,
author = {Panem, Sandeep and Bansal, Romil and Gupta, Manish and Varma, Vasudeva},
title = {Entity Tracking in Real-Time Using Sub-Topic Detection on Twitter},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The velocity, volume and variety with which Twitter generates text is increasing exponentially. It is critical to determine latent sub-topics from such tweet data at any given point of time for providing better topic-wise search results relevant to users' informational needs. The two main challenges in mining sub-topics from tweets in real-time are 1 understanding the semantic and the conceptual representation of the tweets, and 2 the ability to determine when a new sub-topic or cluster appears in the tweet stream. We address these challenges by proposing two unsupervised clustering approaches. In the first approach, we generate a semantic space representation for each tweet by keyword expansion and keyphrase identification. In the second approach, we transform each tweet into a conceptual space that represents the latent concepts of the tweet. We empirically show that the proposed methods outperform the state-of-the-art methods.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {528–533},
numpages = {6},
keywords = {Entity Tracking, Sub-Topic Detection, Clustering, Text Mining},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964093,
author = {Pereira, Pedro and Macedo, Joaquim and Craveiro, Olga and Madeira, Henrique},
title = {Time-Aware Focused Web Crawling},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {There is a plethora of information inside the Web. Even the top commercial search engines can not download and index all the available information. So, in the recent years, there are several research works on the design and implementation of focused topic crawlers and also on geographic scope crawlers.Despite other areas of information retrieval, research on Web crawling is not using the temporal information extracted from Web pages in the used crawling criteria. Therefore, our research challenge is the use of temporal data extracted from Web pages as the main crawling criteria to satisfy a given temporal focus. The importance of the time dimension is quite amplified when combined with topic or geography, but now we want to study it isolated. The used approach is based on temporal segmentation of Web pages text. It only follows links within segments tagged with dates in the scope of restriction. A precision around 75% was achieved in preliminary experimental results.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {534–539},
numpages = {6},
keywords = {Web Crawling, Temporal Information Extraction, Temporal Information Retrieval, Temporal Text Segmentation},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964094,
author = {Rybak, Jan and Balog, Krisztian and N\O{}rv\r{a}g, Kjetil},
title = {Temporal Expertise Profiling},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We introduce the temporal expertise profiling task: identifying the skills and knowledge of an individual and tracking how they change over time. To be able to capture and distinguish meaningful changes, we propose the concept of a hierarchical expertise profile, where topical areas are organized in a taxonomy. Snapshots of hierarchical profiles are then taken at regular time intervals. Further, we develop methods for detecting and characterizing changes in a person's profile, such as, switching the main field of research or narrowing/broadening the topics of research. Initial results demonstrate the potential of our approach.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {540–546},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964095,
author = {Sterckx, Lucas and Demeester, Thomas and Deleu, Johannes and Mertens, Laurent and Develder, Chris},
title = {Assessing Quality of Unsupervised Topics in Song Lyrics},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {How useful are topic models based on song lyrics for applications in music information retrieval? Unsupervised topic models on text corpora are often difficult to interpret. Based on a large collection of lyrics, we investigate how well automatically generated topics are related to manual topic annotations. We propose to use the kurtosis metric to align unsupervised topics with a reference model of supervised topics. This metric is well-suited for topic assessments, as it turns out to be more strongly correlated with manual topic quality scores than existing measures for semantic coherence. We also show how it can be used for a detailed graphical topic quality assessment.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {547–552},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964096,
author = {Vechtomova, Olga and Suleman, Kaheer and Thomas, Jack},
title = {An Information Retrieval-Based Approach to Determining Contextual Opinion Polarity of Words},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The paper presents a novel method for determining contextual polarity of ambiguous opinion words. The task of categorizing polarity of opinion words is cast as an information retrieval problem. The advantage of the approach is that it does not rely on hand-crafted rules and opinion lexicons. Evaluation on a set of polarity-ambiguous adjectives as well as a set of both ambiguous and unambiguous adjectives shows improvements compared to a context-independent method.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {553–559},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964097,
author = {Verberne, Suzan and Sappelli, Maya and Kraaij, Wessel},
title = {Query Term Suggestion in Academic Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we evaluate query term suggestion in the context of academic professional search. Our overall goal is to support scientists in their information seeking tasks. We set up an interactive search system in which terms are extracted from clicked documents and suggested to the user before every query specification step. We evaluated our method with the iSearch collection of academic information seeking behaviour and crowdsourced term relevance judgements. We found that query term suggestion can significantly improve recall in academic search.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {560–566},
numpages = {7},
keywords = {query term suggestion, Professional search, user interaction},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964098,
author = {Wang, Yulu and Lin, Jimmy},
title = {The Impact of Future Term Statistics in Real-Time Tweet Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In the real-time tweet search task operationalized in the TREC Microblog evaluations, a topic consists of a query Q and a time t, modeling the task where the user wishes to see the most recent but relevant tweets that address the information need. To simulate the real-time aspect of the task in an evaluation setting, many systems search over the entire collection and then discard results that occur after the query time. This approach, while computationally efficient, "cheats" in that it takes advantage of term statistics from documents not available at query time i.e., future information. We show, however, that such results are nearly identical to a "gold standard" method that builds a separate index for each topic containing only those documents that occur before the query time. The implications of this finding on evaluation, system design, and user task models are discussed.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {567–572},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964100,
author = {Alarfaj, Fawaz and Kruschwitz, Udo and Fox, Chris},
title = {Exploring Adaptive Window Sizes for Entity Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {With the continuous attention of modern search engines to retrieve entities and not just documents for any given query, we introduce a new method for enhancing the entity-ranking task. An entity-ranking task is concerned with retrieving a ranked list of entities as a response to a specific query. Some successful models used the idea of association discovery in a window of text, rather than in the whole document. However, these studies considered only fixed window sizes. This work proposes a way of generating an adaptive window size for each document by utilising some of the document features. These features include document length, average sentence length, number of entities in the document, and the readability index. Experimental results show a positive effect once taking these document features into consideration when determining window size.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {573–578},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964101,
author = {Aly, Robin},
title = {Score Normalization Using Logistic Regression with Expected Parameters},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {State-of-the-art score normalization methods use generative models that rely on sometimes unrealistic assumptions. We propose a novel parameter estimation method for score normalization based on logistic regression, using the expected parameters from past queries. Experiments on the Gov2 and CluewebA collection indicate that our method is consistently more precise in predicting the number of relevant documents in the top-n ranks compared to a state-of-the-art generative approach and another parameter estimate for logistic regression.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {579–584},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964102,
author = {Bast, Hannah and Haussmann, Elmar},
title = {More Informative Open Information Extraction via Simple Inference},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Recent Open Information Extraction OpenIE systems utilize grammatical structure to extract facts with very high recall and good precision. In this paper, we point out that a significant fraction of the extracted facts is, however, not informative. For example, for the sentence The ICRW is a non-profit organization headquartered in Washington, the extracted fact a non-profit organization is headquartered in Washington is not informative. This is a problem for semantic search applications utilizing these triples, which is hard to fix once the triple extraction is completed. We therefore propose to integrate a set of simple inference rules into the extraction process. Our evaluation shows that, even with these simple rules, the percentage of informative triples can be improved considerably and the already high recall can be improved even further. Both improvements directly increase the quality of search on these triples.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {585–590},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964103,
author = {Bauer, Sandro and Clark, Stephen and Rimell, Laura and Graepel, Thore},
title = {Learning a Theory of Marriage and Other Relations from a Web Corpus},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes a method for learning which relations are highly associated with a given seed relation such as marriage or working for a company. Relation instances taken from a large knowledge base are used as seeds for obtaining candidate sentences expressing the associated relations. Relations of interest are identified by parsing the sentences and extracting dependency graph fragments, which are then ranked to determine which of them are most closely associated with the seed relation. We call the sets of associated relations relation theories. The quality of the induced theories is evaluated using human judgements.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {591–597},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964104,
author = {Breuss, Mathias and Tsagkias, Manos},
title = {Learning from User Interactions for Recommending Content in Social Media},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We study the problem of recommending hyperlinks to users in social media in the form of status updates. We start with a candidate set of links posted by a user's social circle e.g., friends, followers and rank these links using a combination of i\"{\i} undefineda user interaction model, and ii\"{\i} undefinedthe similarity of a user profile and a candidate link. Experiments on two datasets demonstrate that our method is robust and, on average, outperforms, a strong chronological baseline.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {598–604},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964105,
author = {Ceroni, Andrea and Fisichella, Marco},
title = {Towards an Entity---Based Automatic Event Validation},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Event Detection algorithms infer the occurrence of real---world events from natural language text and always require a ground truth for their validation. However, the lack of an annotated and comprehensive ground truth makes the evaluation onerous for humans, who have to manually search for events inside it. In this paper, we envision to automatize the evaluation process by defining the novel problem of Entity---based Automatic Event Validation. We propose a first approach which validates events by estimating the temporal relationships among their representative entities within documents in the Web. Our approach reached a Kappa Statistic of 0.68 when compared with the evaluation of real---world events done by humans. This and other preliminary results motivate further research effort on this novel problem.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {605–611},
numpages = {7},
keywords = {Event Detection, Automatic Event Validation},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964106,
author = {Craveiro, Olga and Macedo, Joaquim and Madeira, Henrique},
title = {Query Expansion with Temporal Segmented Texts},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The use of temporal data extracted from text, to improve the effectiveness of Information Retrieval systems, has recently been the focus of important research work. Our research hypothesis is that the usage of the temporal relationship between words improves the Information Retrieval results. For this purpose, the texts are temporally segmented to establish a relationship between words and dates found in texts. This approach was applied in Query Expansion systems, using a collection with Portuguese newspaper texts. The results showed that the use of the temporality of words can enhance retrieval effectiveness. In particular for time-sensitive queries, we achieved 9.5% improvement in Precision@10. To our knowledge, this is the first work using temporal text segmentation to improve retrieval results.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {612–617},
numpages = {6},
keywords = {Temporal Text Segmentation, Temporal Information Retrieval, Query Expansion},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964107,
author = {Frommholz, Ingo and Abbasi, Muhammad Kamran},
title = {On Clustering and Polyrepresentation},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Polyrepresentation is one of the most prominent principles in a cognitive approach to interactive information seeking and retrieval. When it comes to interactive retrieval, clustering is another method for accessing information. While polyrepresentation has been explored and validated in a scenario where a system returns a ranking of documents, so far there are no insights if and how polyrepresentation and clustering can be combined. In this paper we discuss how both are related and present an approach to integrate polyrepresentation into clustering. We further report some initial evaluation results.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {618–623},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964108,
author = {Hofmann, Katja and Schuth, Anne and Bellog\'{\i}n, Alejandro and Rijke, Maarten},
title = {Effects of Position Bias on Click-Based Recommender Evaluation},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Measuring the quality of recommendations produced by a recommender system RS is challenging. Labels used for evaluation are typically obtained from users of a RS, by asking for explicit feedback, or inferring labels from implicit feedback. Both approaches can introduce significant biases in the evaluation process. We investigate biases that may affect labels inferred from implicit feedback. Implicit feedback is easy to collect but can be prone to biases, such as position bias. We examine this bias using click models, and show how bias following these models would affect the outcomes of RS evaluation. We find that evaluation based on implicit and explicit feedback can agree well, but only when the evaluation metrics are designed to take user behavior and preferences into account, stressing the importance of understanding user behavior in deployed RSs.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {624–630},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964109,
author = {Hu, Qinmin and Huang, Xiangji},
title = {Bringing Information Retrieval into Crowdsourcing: A Case Study},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose a novel and economic framework for bringing information retrieval into crowdsourcing. Both crowdsourcing and information retrieval achieve mutual benefits, which result in 1 workers' quality control by using the query-oriented training; 2 cost savings in money and time; and 3 better qualified feedback information. In our case study, the costs of crowdsourcing for 18,260 jobs are as low as $47.25 and as short as 5 hours in total. Furthermore, the experimental results show that information retrieval techniques greatly reduce the workloads of crowdsourcing, which is only 5% of the original work. At the other hand, crowdsourcing improves the accuracy of the information retrieval system through providing qualified feedback information.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {631–637},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964110,
author = {Kim, Seongchan and Jung, Wonchul and Han, Keejun and Lee, Jae-Gil and Yi, Mun Y.},
title = {Quality-Based Automatic Classification for Presentation Slides},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Computerized presentation slides have become essential for effective business meetings, classroom discussions, and even general events and occasions. With the exploding number of online resources and materials, locating the slides of high quality is a daunting challenge. In this study, we present a new, comprehensive framework of information quality developed specifically for computerized presentation slides on the basis of a user study involving 60 university students from two universities and extensive coding analysis, and explore the possibility of automatically detecting the information quality of slides. Using the classifications made by human annotators as the golden standard, we compare and evaluate the performance of alternative information quality features and dimensions. The experimental results support the validity of the proposed approach in automatically assessing and classifying the information quality of slides.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {638–643},
numpages = {6},
keywords = {Classification, Information Quality IQ, Presentation Slides},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964111,
author = {Kram\'{a}r, Tom\'{a}\v{s} and Bielikov\'{a}, M\'{a}ria},
title = {Context of Seasonality in Web Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we discuss human behavior in interaction with information available on the Web via search. We consider seasonality as a novel source of context for Web search and discuss the possible impact it could have on search results quality. Seasonality is used in recommender systems as an attribute of the recommended item that might influence its perceived usefulness for particular user. We extend this idea to Web search, introduce a seasonality search context, describe the challenges it brings to Web search and discuss its applicability. We present our analysis of AOL log that shows that the level of seasonal behavior varies.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {644–649},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964112,
author = {Liakos, Panagiotis and Papakonstantinopoulou, Katia and Sioutis, Michael},
title = {On the Effect of Locality in Compressing Social Networks},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We improve the state-of-the-art method for graph compression by exploiting the locality of reference observed in social network graphs. We take advantage of certain dense parts of those graphs, which enable us to further reduce the overall space requirements. The analysis and experimental evaluation of our method confirms our observations, as our results present improvements over a wide range of social network graphs.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {650–655},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964113,
author = {Loni, Babak and Shi, Yue and Larson, Martha and Hanjalic, Alan},
title = {Cross-Domain Collaborative Filtering with Factorization Machines},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Factorization machines offer an advantage over other existing collaborative filtering approaches to recommendation. They make it possible to work with any auxiliary information that can be encoded as a real-valued feature vector as a supplement to the information in the user-item matrix. We build on the assumption that different patterns characterize the way that users interact with i.e., rate or download items of a certain type e.g., movies or books. We view interactions with a specific type of item as constituting a particular domain and allow interaction information from an auxiliary domain to inform recommendation in a target domain. Our proposed approach is tested on a data set from Amazon and compared with a state-of-the-art approach that has been proposed for Cross-Domain Collaborative Filtering. Experimental results demonstrate that our approach, which has a lower computational complexity, is able to achieve performance improvements.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {656–661},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964114,
author = {Moe, Richard Elling},
title = {Improvements to Suffix Tree Clustering},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We investigate document clustering through adaptation of Zamir and Etzioni's method for Suffix Tree Clustering. We modified it with substantial improvements in effectiveness and efficiency compared to the original algorithm.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {662–667},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964115,
author = {Qi, Yanjun and Das, Sujatha G. and Collobert, Ronan and Weston, Jason},
title = {Deep Learning for Character-Based Information Extraction},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we introduce a deep neural network architecture to perform information extraction on character-based sequences, e.g. named-entity recognition on Chinese text or secondary-structure detection on protein sequences. With a task-independent architecture, the deep network relies only on simple character-based features, which obviates the need for task-specific feature engineering. The proposed discriminative framework includes three important strategies, 1 a deep learning module mapping characters to vector representations is included to capture the semantic relationship between characters; 2 abundant online sequences unlabeled are utilized to improve the vector representation through semi-supervised learning; and 3 the constraints of spatial dependency among output labels are modeled explicitly in the deep architecture. The experiments on four benchmark datasets have demonstrated that, the proposed architecture consistently leads to the state-of-the-art performance.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {668–674},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964116,
author = {Qian, Mingjie},
title = {Text-Image Topic Discovery for Web News Data},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We formally propose a new application problem: unsupervised text-image topic discovery. The application problem is important because almost all news articles have one picture associated. Unlike traditional topic modeling which considers text alone, the new task aims to discover heterogeneous topics from web news of multiple data types. The heterogeneous topic discovery is challenging because different media data types have different characteristics and structures, and a systematic solution that can integrate information propagation and mutual enhancement between data of different types in a principle way is not easy to obtain, especially when no supervision information is available. We propose to tackle the problem by a regularized nonnegative constrained l 2,1-norm minimization framework. We also present a new iterative algorithm to solve the optimization problem. To objectively evaluate the proposed method, we collect two real world text-image web news datasets. Experimental results show the effectiveness of the new approach.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {675–680},
numpages = {6},
keywords = {Text-image topic discovery},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964117,
author = {Schaller, Richard and Harvey, Morgan and Elsweiler, David},
title = {Detecting Event Visits in Urban Areas via Smartphone GPS Data},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In geographic search tasks, where the location of the user is an important part of the task context, knowing whether or not a user has visited a location associated with a returned result could be a useful indicator of system performance. In this paper we derive and evaluate a model to estimate, based on user interaction logs, GPS information and event meta-data, the events that were visited by users of a mobile search system for an annual cultural evening where multiple events were organised across the city of Munich. Using a training / testing set derived from 111 users, our model is able to achieve high levels of accuracy, which will, in future work, allow us to explore how different ways of using the system lead to different outcomes for users.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {681–686},
numpages = {6},
keywords = {detection of visited locations, GPS, location-based services},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964118,
author = {Schnitzer, Dominik and Flexer, Arthur and Toma\v{s}ev, Nenad},
title = {A Case for Hubness Removal in High---Dimensional Multimedia Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This work investigates the negative effects of hubness on multimedia retrieval systems. Because of a problem of measuring distances in high-dimensional spaces, hub objects are close to an exceptionally large part of the data while anti-hubs are far away from all other data points. In the case of similarity based retrieval, hub objects are retrieved over and over again while anti-hubs are nonexistent in the retrieval lists. We investigate textual, image and music data and show how re-scaling methods can avoid the problem and decisively improve the overall retrieval quality. The observations of this work suggest to make hubness analysis an integral part when building a retrieval system.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {687–692},
numpages = {6},
keywords = {hubness, multimedia retrieval, high dimensionality},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964119,
author = {Tsikrika, Theodora and Diou, Christos},
title = {Multi-Evidence User Group Discovery in Professional Image Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This work evaluates the combination of multiple evidence for discovering groups of users with similar interests. User groups are created by analysing the search logs recorded for a sample of 149 users of a professional image search engine in conjunction with the textual and visual features of the clicked images, and evaluated by exploiting their topical classification. The results indicate that the discovered user groups are meaningful and that combining textual and visual features improves the homogeneity of the user groups compared to each individual feature.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {693–699},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964120,
author = {Kasteren, Tim L. and Ulrich, Birte and Srinivasan, Vignesh and Niessen, Maria E.},
title = {Analyzing Tweets to Aid Situational Awareness},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Social media networks can be used to gather near real-time information about safety and security events. In this paper we analyze Twitter data that was captured around fifteen real world safety and security events and use a number of analytical tools to help understand the effectiveness of certain features for event detection and to study how this data can be used to aid situational awareness.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {700–705},
numpages = {6},
keywords = {Social Media Analytics, Situational Awareness},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964121,
author = {Voskarides, Nikos and Odijk, Daan and Tsagkias, Manos and Weerkamp, Wouter and Rijke, Maarten},
title = {Query-Dependent Contextualization of Streaming Data},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose a method for linking entities in a stream of short textual documents that takes into account context both inside a document and inside the history of documents seen so far. Our method uses a generic optimization framework for combining several entity ranking functions, and we introduce a global control function to control optimization. Our results demonstrate the effectiveness of combining entity ranking functions that take into account context, which is further boosted by 6% when we use an informed global control function.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {706–712},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964122,
author = {Wang, Yue and Wu, Hao and Fang, Hui},
title = {An Exploration of Tie-Breaking for Microblog Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Microblog retrieval enables users to access relevant information from the huge number of tweets posted on social media. Since tweets are different from traditional documents, existing IR models might not be the optimal choice for this problem. Tie-breaking has been recently proposed as a new way of combining multiple retrieval signals. In this paper, we focus on studying the potential of this approach in microblog retrieval and propose new methods to further improve the performance. Experiment results show that these tie-breaking based methods can achieve comparable performance with the top runs in the TREC Microblog track.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {713–719},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964123,
author = {Wilkie, Colin and Azzopardi, Leif},
title = {Efficiently Estimating Retrievability Bias},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Retrievability is the measure of how easily a document can be retrieved using a particular retrieval system. The extent to which a retrieval system favours certain documents over others as expressed by their retrievability scores determines the level of bias the system imposes on a collection. Recently it has been shown that it is possible to tune a retrieval system by minimising the retrievability bias. However, to perform such a retrievability analysis often requires posing millions upon millions of queries. In this paper, we examine how many queries are needed to obtain a reliable and useful approximation of the retrievability bias imposed by the system, and an estimate of the individual retrievability of documents in the collection. We find that a reliable estimate of retrievability bias can be obtained, in some cases, with 90% less queries than are typically used while estimating document retrievability can be done with up to 60% less queries.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {720–726},
numpages = {7},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964124,
author = {Younus, Arjumand and O'Riordan, Colm and Pasi, Gabriella},
title = {A Language Modeling Approach to Personalized Search Based on Users' Microblog Behavior},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Personalized Web search offers a promising solution to the task of user-tailored information-seeking, and particularly in cases where the same query may represent diverse information needs. A significant component of any Web search personalization model is the means with which to model a user's interests and preferences to build what is termed as a user profile. This work explores the use of the Twitter microblog network as a source of user profile construction for Web search personalization. We propose a statistical language modeling approach taking into account various features of a user's Twitter network. The richness of the Web search personalization model leads to significant performance improvements in retrieval accuracy. Furthermore, the model is extended to include a similarity measure which further improves search engine performance.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {727–732},
numpages = {6},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964126,
author = {Kabary, Ihab Al and Schuldt, Heiko},
title = {Using Hand Gestures for Specifying Motion Queries in Sketch-Based Video Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In team sports, the analysis of a teams tactical behavior is becoming increasingly important. While this is still mostly based on the manual selection of video sequences from games, coaches and analysts increasingly demand more automated solutions to search for relevant sequences of videos, and to support this search by means of easy-to-use interfaces. In this paper, we present a novel intuitive interface for specifying sketched-based motion queries in sport videos using hand gestures. We have built the interface on top of SportSense, a system for interactive sports video retrieval. SportSense exploits spatiotemporal information incorporating various events within sport games, which is used as metadata to the actual sports videos. The interface has been designed to enable users to fully control the system and facilitate acquiring of the query object needed to perform both spatial and spatiotemporal motion queries using intuitive hand gestures.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {733–736},
numpages = {4},
keywords = {query-by-sketch, gesture recognition, user interface, video retrieval, motion queries},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964127,
author = {Azzopardi, Leif and English, Rosanne and Wilkie, Colin and Maxwell, David},
title = {Page Retrievability Calculator},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Knowing how easily pages within a website can be retrieved using the site's search functionality provides crucial information to the site designer. If the system is not retrieving particular pages then the system or information may need to be changed to ensure that visitors to the site have the best chance of finding the relevant information. In this demo paper, we present a Page Retrievability Calculator, which estimates the retrievability of a page for a given search engine. To estimate the retrievability, instead of posing all possible queries, we focus on issuing only those likely to retrieve the page and use them to obtain an accurate approximation. We can also rank the queries associated with the page to show the site designer what queries are most likely to retrieve the pages and at what rank. With this application we can now explore how it might be possible to improve the site or content to improve the retrievability.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {737–741},
numpages = {5},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964128,
author = {Carrillo-De-Albornoz, Jorge and Amig\'{o}, Enrique and Spina, Damiano and Gonzalo, Julio},
title = {ORMA: A Semi-Automatic Tool for Online Reputation Monitoring in Twitter},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We present a semi-automatic tool that assists experts in their daily work of monitoring the reputation of entities--companies, organizations or public figures--in Twitter. The tool automatically annotates tweets for relevance Is the tweet about the entity?, reputational polarity Does the tweet convey positive or negative implications for the reputation of the entity?, groups tweets in topics and display topics in decreasing order of relevance from a reputational perspective. The interface helps the user to understand the content being analyzed and also to produce a manually annotated version of the data starting from the output of the automatic annotation processes. A demo is available at: <externalref> <refsource> <emphasis fontcategory="NonProportional">http://nlp.uned.es/orma/</emphasis> </refsource> <reftarget address="http://nlp.uned.es/orma/" targettype="URL"></reftarget> </externalref> },
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {742–745},
numpages = {4},
keywords = {Online Reputation Monitoring, Social Media, Twitter},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964129,
author = {Gossen, Tatiana and Nitsche, Marcus and N\"{u}rnberger, Andreas},
title = {My First Search User Interface},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes an adaptable search user interface whose main focus group are young users. In order to address continuous and --- compared to middle-age users --- relatively fast changes in cognitive, fine motor skills and other abilities of young users, we developed a first prototype of an evolving search user interface ESUI. This ESUI is able to handle changes in design requirements. It is adaptable towards individual user characteristics allowing a flexible modification of the SUI in terms of UI element properties like font size, but also UI element types and their properties. In this work, the goal of SUI adaptation is emotional support for children because positive attitudes towards the system keep them motivated.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {746–749},
numpages = {4},
keywords = {context support, information retrieval, search user interface, human-computer interaction, adaptation},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964130,
author = {Kaptein, Rianne and Koot, Gijs and Veld, Mirjam A. and Broek, Egon L.},
title = {Needle Custom Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Web search engines are optimized for early precision, which makes it difficult to perform recall-oriented tasks using these search engines. In this article, we present our tool Needle Custom Search. This tool exploits semantic annotations of Web search results and, thereby, increase the efficiency of recall-oriented search tasks. Semantic annotations, such as temporal annotations, named entities, and part-of-speech tags are used to rerank and cluster search result sets.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {750–753},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964131,
author = {Kelly, Liadh and Dungs, Sebastian and Kriewel, Sascha and Hanbury, Allan and Goeuriot, Lorraine and Jones, Gareth J. and Langs, Georg and M\"{u}ller, Henning},
title = {Khresmoi Professional: Multilingual, Multimodal Professional Medical Search},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this demonstration we present the Khresmoi medical search and access system. The system uses a component based architecture housed in the cloud to support target users medical information needs. This includes web systems, computer applications and mobile applications to support the multilingual and multimodal information needs of three test target groups: the general public, general practitioners GPs and radiologists. This demonstration presents the systems for GPs and radiologists providing multilingual text and image based including 2D and 3D radiology images search functionality.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {754–758},
numpages = {5},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964132,
author = {Meder, Michael and Plumbaum, Till and Hopfgartner, Frank},
title = {DAIKnow: A Gamified Enterprise Bookmarking System},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {One of the core ideas of gamification in an enterprise setting is to engage employees, i.e., to motivate them to fulfil boring, but necessary tasks. In this demo paper, we present a gamified enterprise bookmarking system which incorporates points, badges and a leaderboard. Preliminary studies indicate that these gamification methods result in an increased user engagement.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {759–762},
numpages = {4},
keywords = {social bookmarking system, enterprise gamification},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964133,
author = {Stange, Dominic and N\"{u}rnberger, Andreas},
title = {Search Maps: Enhancing Traceability and Overview in Collaborative Information Seeking},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose a search user interface that is especially designed to make individual contributions to a collaborative search task visible and traceable. The main goal is to support awareness, understanding, and sensemaking within a group working together on the same task. The support is achieved by visualizing the information seeking activities of the user group with an interactive two-dimensional Search Map. The users share the same Search Map and can actively collaborate and evolve their search topic together. The Search Map serves as a common ground and enables each user to gain a more comprehensive understanding of the domain in question by taking advantage of the shared view of the community.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {763–766},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964135,
author = {Angelini, Marco and Ferro, Nicola and Santucci, Giuseppe and Silvello, Gianmaria},
title = {A Visual Interactive Environment for Making Sense of Experimental Data},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We present the Visual Information Retrieval Tool for Upfront Evaluation VIRTUE which is an interactive and visual system supporting two relevant phases of the experimental evaluation process: performance analysis and failure analysis.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {767–770},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964136,
author = {Brilhante, Igo and Macedo, Jose Antonio and Nardini, Franco Maria and Perego, Raffaele and Renso, Chiara},
title = {TripBuilder: A Tool for Recommending Sightseeing Tours},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose TripBuilder, an user-friendly and interactive system for planning a time-budgeted sightseeing tour of a city on the basis of the points of interest and the patterns of movements of tourists mined from user-contributed data. The knowledge needed to build the recommendation model is entirely extracted in an unsupervised way from two popular collaborative platforms: Wikipedia and Flickr. TripBuilder interacts with the user by means of a friendly Web interface that allows her to easily specify personal interests and time budget. The sightseeing tour proposed can be then explored and modified. We present the main components composing the system.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {771–774},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964137,
author = {Campos, Ricardo and Dias, Ga\"{e}l and Jorge, Al\'{\i}pio M\'{a}rio and Nunes, C\'{e}lia},
title = {GTE-Cluster: A Temporal Search Interface for Implicit Temporal Queries},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we present GTE-Cluster an online temporal search interface which consistently allows searching for topics in a temporal perspective by clustering relevant temporal Web search results. GTE-Cluster is designed to improve user experience by augmenting document relevance with temporal relevance. The rationale is that offering the user a comprehensive temporal perspective of a topic is intuitively more informative than retrieving a result that only contains topical information. Our system does not pose any constraint in terms of language or domain, thus users can issue queries in any language ranging from business, cultural, political to musical perspective, to cite just a few. The ability to exploit this information in a temporal manner can be, from a user perspective, potentially useful for several tasks, including user query understanding or temporal clustering.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {775–779},
numpages = {5},
keywords = {Temporal Information Retrieval, Temporal Clustering, Implicit Temporal Queries},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964138,
author = {Granados Buey, Mar\'{\i}a and Luis Garrido, \'{A}ngel and Escudero, Sandra and Trillo, Raquel and Ilarri, Sergio and Mena, Eduardo},
title = {SQX-Lib: Developing a Semantic Query Expansion System in a Media Group},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Recently, there has been an exponential growth in the amount of digital data stored in repositories. Therefore, the efficient and effective retrieval of information from them has become a key issue. Organizations use traditional architectures and methodologies based on classical relational databases, but these approaches do not consider the semantics of the data or they perform complex ETL processes from relational repositories to triple repositories. Most companies do not carry out this type of migration due to lack of time, money or knowledge.In this paper we present a system that performs a semantic query expansion to improve information retrieval from traditional relational databases repositories. We have also linked it to an actual system and we have carried out a set of tests in a real Media Group organization. Results are very promising and show the interest of the proposal.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {780–783},
numpages = {4},
keywords = {information retrieval, semantic search, query expansion},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964139,
author = {Liu, Xitong and Yang, Peilin and Fang, Hui},
title = {EntEXPO: An Interactive Search System for Entity-Bearing Queries},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The paper presents EntEXPO, a search system that aims to improve the search experience for entity-bearing queries. In particular, the system exploits the entities and their relations in the context of query to identify a list of related entities and leverage them in an entity-centric query expansion method to generate more effective search results. Moreover, EntEXPO\"{\i} undefineddisplays the related entities along with the search results to allow search users explore entity relationship to further refine the query through an interactive interface.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {784–788},
numpages = {5},
keywords = {interactive search, entity centric},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_97,
author = {M\"{u}hleisen, Hannes and Samar, Thaer and Lin, Jimmy and Vries, Arjen P.},
title = {Column Stores as an IR Prototyping Tool},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_97},
doi = {10.1007/978-3-319-06028-6_97},
abstract = {We make the suggestion that instead of implementing custom index structures and query evaluation algorithms, IR researchers should simply store document representations in a column-oriented relational database and write ranking models using SQL. For rapid prototyping, this is particularly advantageous since researchers can explore new ranking functions and features by simply issuing SQL queries, without needing to write imperative code. We demonstrate the feasibility of this approach by an implementation of conjunctive BM25 using MonetDB on a part of the ClueWeb12 collection.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {789–792},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_98,
author = {Narducci, Fedelucio and Palmonari, Matteo and Semeraro, Giovanni},
title = {CroSeR: Cross-Language Semantic Retrieval of Open Government Data},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_98},
doi = {10.1007/978-3-319-06028-6_98},
abstract = {CroSer Cross-language Semantic Retrieval is an ir system able to discover links between e-gov services described in different languages. CroSeR supports public administrators to link their own source catalogs of e-gov services described in any language to a target catalog whose services are described in English and are available in the Linked Open Data lod cloud. Our system is based on a cross-language semantic matching method that i translates service labels in English using a machine translation tool, ii extracts a Wikipedia-based semantic representation from the translated service labels using Explicit Semantic Analysis esa, iii evaluates the similarity between two services using their Wikipedia-based representations. The user selects a service in a source catalog and exploits the ranked list of matches suggested by CroSeR to establish a relation of type narrower, equivalent, or broader match with other services in the English catalog. The method is independent from the language adopted in the source catalog and it does not assume the availability of information about the services other than very short text descriptions used as service labels. CroSeR is a web application accessible via <externalref> <refsource> <emphasis fontcategory="NonProportional">http://siti-rack.siti.disco.unimib.it:8080/croser/</emphasis> </refsource> <reftarget address="http://siti-rack.siti.disco.unimib.it:8080/croser/" targettype="URL"></reftarget> </externalref>.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {793–797},
numpages = {5},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_99,
author = {Mayr, Philipp and Scharnhorst, Andrea and Larsen, Birger and Schaer, Philipp and Mutschke, Peter},
title = {Bibliometric-Enhanced Information Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_99},
doi = {10.1007/978-3-319-06028-6_99},
abstract = {Bibliometric techniques are not yet widely used to enhance retrieval processes in digital libraries, although they offer value-added effects for users. In this workshop we will explore how statistical modelling of scholarship, such as Bradfordizing or network analysis of coauthorship network, can improve retrieval services for specific communities, as well as for large, cross-domain collections. This workshop aims to raise awareness of the missing link between information retrieval IR and bibliometrics / scientometrics and to create a common ground for the incorporation of bibliometric-enhanced services into retrieval at the digital library interface.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {798–801},
numpages = {4},
keywords = {Informetrics, Digital Libraries, Scientometrics, Information Retrieval, Bibliometrics},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.5555/2964060.2964144,
author = {Said, Alan and Luca, Ernesto William and Quercia, Daniele and B\"{o}hmer, Matthias},
title = {4th Workshop on Context-Awareness in Retrieval and Recommendation},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Context-aware information is widely available in various ways and is becoming more and more important for enhancing retrieval performance and recommendation results. The current main issue to cope with is not only recommending or retrieving the most relevant items and content, but defining them ad hoc. Other relevant issues include personalizing and adapting the information and the way it is displayed to the user's current situation and interests. Ubiquitous computing further provides new means for capturing user feedback on items and providing information.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {802–805},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_101,
author = {Hopfgartner, Frank and Kazai, Gabriella and Kruschwitz, Udo and Meder, Michael},
title = {Workshop on Gamification for Information Retrieval GamifIR'14},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_101},
doi = {10.1007/978-3-319-06028-6_101},
abstract = {Gamification is the application of game mechanics, such as leader boards, badges or achievement points, in non-gaming environments with the aim to increase user engagement, data quality or cost effectiveness. A core aspect of gamification solutions is to infuse intrinsic motivations to participate by leveraging people's natural desires for achievement and competition. While gamification, on the one hand, is emerging as the next big thing in industry, e.g., an effective way to generate business, on the other hand, it is also becoming a major research area. However, its adoption in Information Retrieval IR is still in its infancy, despite the wide ranging IR tasks that may benefit from gamification techniques. These include the manual annotation of documents for IR evaluation, the participation in user studies to study interactive IR challenges, or the shift from single-user search to social search, just to mention a few.This context provided the motivation to organise the GamifIR'14 workshop at ECIR.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {806–809},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_102,
author = {Albakour, M-Dyaa and Macdonald, Craig and Ounis, Iadh and Clarke, Charles L. and Bicer, Veli},
title = {Information Access in Smart Cities I-ASC},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_102},
doi = {10.1007/978-3-319-06028-6_102},
abstract = {Modern cities are becoming smart where a digital knowledge infrastructure is deployed by local authorities e.g. City councils and municipalities to better serve the information needs of their citizens, and to ensure sustainability and efficient use of power and resources. This knowledge infrastructure consists of a wide range of systems from low-level physical sensors to advanced sensing devices through social sensors. This proposed workshop will be a venue for research on digesting the city's data streams and knowledge databases in order to serve the information needs of citizens and support decision making for local authorities. Possible use cases include helping tourists to find interesting places to go or activities to do while visiting a city, or assisting journalists in reporting local incidents. Indeed, this workshop will foster the development of new information access and retrieval models that can harness effectively and efficiently the large number of heterogeneous big data streams in a city to provide a new generation of information services.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {810–814},
numpages = {5},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_103,
author = {Russell-Rose, Tony},
title = {Designing Search Usability},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_103},
doi = {10.1007/978-3-319-06028-6_103},
abstract = {Search is not just a box and ten blue links. Search is a journey: an exploration where what we encounter along the way changes what we seek. But in order to guide people along this journey, we must understand both the art and science of user experience design.The aim of this tutorial is to deliver a learning experience grounded in good scholarship, integrating the latest research findings with insights derived from the practical experience of designing and optimizing an extensive range of commercial search applications. It focuses on the development of transferable, practical skills that can be learnt and practiced within a half-day session.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {815–818},
numpages = {4},
keywords = {information discovery, user experience design, user behaviour, usability, enterprise search, information seeking, Site search},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_104,
author = {Sebastiani, Fabrizio},
title = {Text Quantification},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_104},
doi = {10.1007/978-3-319-06028-6_104},
abstract = {In recent years it has been pointed out that, in a number of applications involving classification, the final goal is not determining which class or classes individual unlabelled data items belong to, but determining the prevalence or "relative frequency" of each class in the unlabelled data. The latter task has come to be known as quantification [1, 3, 5-10, 15, 18, 19].},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {819–822},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

@inproceedings{10.1007/978-3-319-06028-6_105,
author = {Kurland, Oren},
title = {The Cluster Hypothesis in Information Retrieval},
year = {2014},
isbn = {9783319060279},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-06028-6_105},
doi = {10.1007/978-3-319-06028-6_105},
abstract = {The cluster hypothesis states that "closely associated documents tend to be relevant to the same requests" [45]. This is one of the most fundamental and influential hypotheses in the field of information retrieval and has given rise to a huge body of work. In this tutorial we will present the research topics that have emerged based on the cluster hypothesis. Specific focus will be placed on cluster-based document retrieval, the use of topic models for ad hoc IR, and the use of graph-based methods that utilize inter-document similarities. Furthermore, we will provide an in-depth survey of the suite of retrieval methods that rely, either explicitly or implicitly, on the cluster hypothesis and which are used for a variety of different tasks; e.g., query expansion, query-performance prediction, fusion and federated search, and search results diversification.},
booktitle = {Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Volume 8416},
pages = {823–826},
numpages = {4},
location = {Amsterdam, The Netherlands},
series = {ECIR 2014}
}

