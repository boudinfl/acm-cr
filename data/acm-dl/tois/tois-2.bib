@article{10.1145/503104.503107,
author = {Bharat, Krishna and Mihaila, George A.},
title = {When Experts Agree: Using Non-Affiliated Experts to Rank Popular Topics},
year = {2002},
issue_date = {January 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/503104.503107},
doi = {10.1145/503104.503107},
abstract = {In response to a query, a search engine returns a ranked list of documents. If the query is about a popular topic (i.e., it matches many documents), then the returned list is usually too long to view fully. Studies show that users usually look at only the top 10 to 20 results. However, we can exploit the fact that the best targets for popular topics are usually linked to by enthusiasts in the same domain. In this paper, we propose a novel ranking scheme for popular topics that places the most authoritative pages on the query topic at the top of the ranking. Our algorithm operates on a special index of "expert documents." These are a subset of the pages on the WWW identified as directories of links to non-affiliated sources on specific topics. Results are ranked based on the match between the query and relevant descriptive text for hyperlinks on expert pages pointing to a given result page. We present a prototype search engine that implements our ranking scheme and discuss its performance. With a relatively small (2.5 million page) expert index, our algorithm was able to perform comparably on popular queries with the best of the mainstream search engines.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {47–58},
numpages = {12},
keywords = {WWW search, authorities, topic experts, link analysis, connectivity, ranking, host affiliation}
}

@article{10.1145/503104.503106,
author = {Aridor, Yariv and Carmel, David and Maarek, Yoelle S. and Soffer, Aya and Lempel, Ronny},
title = {Knowledge Encapsulation for Focused Search from Pervasive Devices},
year = {2002},
issue_date = {January 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/503104.503106},
doi = {10.1145/503104.503106},
abstract = {Mobile knowledge seekers often need access to information on the Web during a meeting or on the road, while away from their desktop. A common practice today is to use pervasive devices such as Personal Digital Assistants or mobile phones. However, these devices have inherent constraints (e.g., slow communication, form factor) which often make information discovery tasks impractical.In this paper, we present a new focused-search approach specifically oriented for the mode of work and the constraints dictated by pervasive devices. It combines focused search within specific topics with encapsulation of topic-specific information in a persistent repository. One key characteristic of these persistent repositories is that their footprint is small enough to fit on local devices, and yet they are rich enough to support many information discovery tasks in disconnected mode. More specifically, we suggest a representation for topic-specific information based on "knowledge-agent bases" that comprise all the information necessary to access information about a topic (under the form of key concepts and key Web pages) and assist in the full search process from query formulation assistance to result scanning on the device itself. The key contribution of our work is the coupling of focused search with encapsulated knowledge representation making information discovery from pervasive devices practical as well as efficient. We describe our model in detail and demonstrate its aspects through sample scenarios.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {25–46},
numpages = {22},
keywords = {Focused searches, knowledge agents, pervasive devices, disconnected search}
}

@article{10.1145/503104.503105,
title = {PicASHOW: Pictorial Authority Search by Hyperlinks on the Web},
year = {2002},
issue_date = {January 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/503104.503105},
doi = {10.1145/503104.503105},
abstract = {We describe PicASHOW, a fully automated WWW image retrieval system that is based on several link-structure analyzing algorithms. Our basic premise is that a page p displays (or links to) an image when the author of p considers the image to be of value to the viewers of the page. We thus extend some well known link-based WWW page retrieval schemes to the context of image retrieval.PicASHOW's analysis of the link structure enables it to retrieve relevant images even when those are stored in files with meaningless names. The same analysis also allows it to identify image containers and image hubs. We define these as Web pages that are rich in relevant images, or from which many images are readily accessible.PicASHOW requires no image analysis whatsoever and no creation of taxonomies for preclassification of the Web's images. It can be implemented by standard WWW search engines with reasonable overhead, in terms of both computations and storage, and with no change to user query formats. It can thus be used to easily add image retrieving capabilities to standard search engines.Our results demonstrate that PicASHOW, while relying almost exclusively on link analysis, compares well with dedicated WWW image retrieval systems. We conclude that link analysis, a proven effective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its definition to include the retrieval of image hubs and containers.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–24},
numpages = {24},
keywords = {Image retrieval, image hubs, link structure analysis, hubs and authorities}
}

@article{10.1145/502795.502798,
author = {Yoshioka, Takeshi and Herman, George and Yates, JoAnne and Orlikowski, Wanda},
title = {Genre Taxonomy: A Knowledge Repository of Communicative Actions},
year = {2001},
issue_date = {October 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/502795.502798},
doi = {10.1145/502795.502798},
abstract = {We propose a genre taxonomy as a knowledge repository of communicative structures or "typified actions" enacted by organizational members. The genre taxonomy is intended to help people make sense of diverse types of communicative actions and provide ideas for improving work processes that coordinate the communication of information. It engages several features to achieve this objective. First, the genre taxonomy represents the elements of both genres and genre systems as embedded in a social context reflecting the communicative questions why, what, who, when, where, and how (5W1H). In other words, the genre taxonomy represents the purpose, content, participants, timing, location, and form of communicative action. Second, the genre taxonomy distinguishes between widely recognized genres such as a report and specific genres such as a particular company's technical report, because the difference sheds light on the context of genre use. Third, the genre taxonomy represents use and evolution of a genre over time to help people understand how a genre is used and changed by a community over time. Fourth, the genre taxonomy represents aspects of information coordination via genres, thus providing ideas for improving work processes using genres. We have constructed a prototype of such a genre taxonomy using the Process Handbook, a process knowledge repository developed at MIT. We have included both widely recognized genres such as the memo and specific genres such as those used in the Process Handbook itself. We suggest that this genre taxonomy may be useful in the innovation of new document templates or methods for communication because it helps to clarify different possible uses of similar genres and explicates how genres play a coordination role among people and between people and their tasks.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {431–456},
numpages = {26},
keywords = {taxonomy, information search and retrieval, grammar, genre systems, Genre}
}

@article{10.1145/502795.502797,
author = {Comai, Sara and Damiani, Ernesto and Fraternali, Piero},
title = {Computing Graphical Queries over XML Data},
year = {2001},
issue_date = {October 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/502795.502797},
doi = {10.1145/502795.502797},
abstract = {The rapid evolution of XML from a mere data exchange format to a universal syntax for encoding domain-specific information raises the need for new query languages specifically conceived to address the characteristics of XML. Such languages should be able not only to extract information from XML documents, but also to apply powerful transformation and restructuring operators, based on a well-defined semantics. Moreover, XML queries should be natural to write and understand, as nontechnical persons also are expected to access the large XML information bases supporting their businesses. This article describes XML-GL, a graphical query language for XML data. XML-GL's uniqueness is in the definition of a graph-based syntax to express a wide variety of XML queries, ranging from simple selections to expressive data transformations involving grouping, aggregation, and arithmetic calculations. XML-GL has an operational semantics based on the notion of graph matching, which serves as a guideline both for the implementation of native processors, and for the adoption of XML-GL as a front-end to any of the XML query languages that are presently under discussion as the standard paradigm for querying XML data.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {371–430},
numpages = {60},
keywords = {semantics, graphical query languages, Document restructuring}
}

@article{10.1145/502795.502796,
author = {Wong, Kam-Fai and Song, Dawei and Bruza, Peter and Cheng, Chun-Hung},
title = {Application of Aboutness to Functional Benchmarking in Information Retrieval},
year = {2001},
issue_date = {October 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/502795.502796},
doi = {10.1145/502795.502796},
abstract = {Experimental approaches are widely employed to benchmark the performance of an information retrieval (IR) system. Measurements in terms of recall and precision are computed as performance indicators. Although they are good at assessing the retrieval effectiveness of an IR system, they fail to explore deeper aspects such as its underlying functionality and explain why the system shows such performance. Recently, inductive (i.e., theoretical) evaluation of IR systems has been proposed to circumvent the controversies of the experimental methods. Several studies have adopted the inductive approach, but they mostly focus on theoretical modeling of IR properties by using some metalogic. In this article, we propose to use inductive evaluation for functional benchmarking of IR models as a complement of the traditional experiment-based performance benchmarking. We define a functional benchmark suite in two stages: the evaluation criteria based on the notion of "aboutness," and the formal evaluation methodology using the criteria. The proposed benchmark has been successfully applied to evaluate various well-known classical and logic-based IR models. The functional benchmarking results allow us to compare and analyze the functionality of the different IR models.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {337–370},
numpages = {34},
keywords = {inductive evaluation, logic-based information retrieval, Aboutness, functional benchmarking}
}

@article{10.1145/502115.502120,
author = {Meng, Weiyi and Wu, Zonghuan and Yu, Clement and Li, Zhuogang},
title = {A Highly Scalable and Effective Method for Metasearch},
year = {2001},
issue_date = {July 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/502115.502120},
doi = {10.1145/502115.502120},
abstract = {A metasearch engine is a system that supports unified access to multiple local search engines. Database selection is one of the main challenges in building a large-scale metasearch engine. The problem is to efficiently and accurately determine a small number of potentially useful local search engines to invoke for each user query. In order to enable accurate selection, metadata that reflect the contents of each search engine need to be collected and used. This article proposes a highly scalable and accurate database selection method. This method has several novel features. First, the metadata for representing the contents of all search engines are organized into a single integrated representative. Such a representative yields both computational efficiency and storage efficiency. Second, the new selection method is based on a theory for ranking search engines optimally. Experimental results indicate that this new method is very effective. An operational prototype system has been built based on the proposed approach.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {310–335},
numpages = {26},
keywords = {metasearch engine, resource discovery, Database selection, distributed text retrieval}
}

@article{10.1145/502115.502119,
author = {Aggarwal, Charu C. and Al-Garawi, Fatima and Yu, Philip S.},
title = {On the Design of a Learning Crawler for Topical Resource Discovery},
year = {2001},
issue_date = {July 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/502115.502119},
doi = {10.1145/502115.502119},
abstract = {In recent years, the World Wide Web has shown enormous growth in size. Vast repositories of information are available on practically every possible topic. In such cases, it is valuable to perform topical resource discovery effectively. Consequently, several new ideas have been proposed in recent years; among them a key technique is focused crawling which is able to crawl particular topical portions of the World Wide Web quickly, without having to explore all web pages. In this paper, we propose the novel concept of intelligent crawling which actually learns characteristics of the linkage structure of the World Wide Web while performing the crawling. Specifically, the intelligent crawler uses the inlinking web page content, candidate URL structure, or other behaviors of the inlinking web pages or siblings in order to estimate the probability that a candidate is useful for a given crawl. This is a much more general framework than the focused crawling technique which is based on a pre-defined understanding of the topical structure of the web. The techniques discussed in this paper are applicable for crawling web pages which satisfy arbitrary user-defined predicates such as topical queries, keyword queries, or any combinations of the above. Unlike focused crawling, it is not necessary to provide representative topical examples, since the crawler can learn its way into the appropriate topic. We refer to this technique as intelligent crawling because of its adaptive nature in adjusting to the web page linkage structure. We discuss how to intelligently select features which are most useful for a given crawl. The learning crawler is capable of reusing the knowledge gained in a given crawl in order to provide more efficient crawling for closely related predicates.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {286–309},
numpages = {24},
keywords = {Crawling, World Wide Web}
}

@article{10.1145/502115.502118,
title = {WebQuilt: A Proxy-Based Approach to Remote Web Usability Testing},
year = {2001},
issue_date = {July 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/502115.502118},
doi = {10.1145/502115.502118},
abstract = {WebQuilt is a web logging and visualization system that helps web design teams run usability tests (both local and remote) and analyze the collected data. Logging is done through a proxy, overcoming many of the problems with server-side and client-side logging. Captured usage traces can be aggregated and visualized in a zooming interface that shows the web pages people viewed. The visualization also shows the most common paths taken through the web site for a given task, as well as the optimal path for that task, as designated by the designer. This paper discusses the architecture of WebQuilt and describes how it can be extended for new kinds of analyses and visualizations.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {263–285},
numpages = {23},
keywords = {web proxy, Usability evalution, log file analysis, WebQuilt, web visualization}
}

@article{10.1145/502115.502117,
author = {Kwok, Cody and Etzioni, Oren and Weld, Daniel S.},
title = {Scaling Question Answering to the Web},
year = {2001},
issue_date = {July 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/502115.502117},
doi = {10.1145/502115.502117},
abstract = {The wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as “who was the first American in space?” or “what is the second tallest mountain in the world?” Yet today's most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, first studied in the information retrieval literature, to the web and experimentally evaluate their performance.First we introduce Mulder, which we believe to be the first general-purpose, fully-automated question-answering system available on the web. Second, we describe Mulder's architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare Mulder's performance to that of Google and AskJeeves on questions drawn from the TREC-8 question answering track. We find that Mulder's recall is more than a factor of three higher than that of AskJeeves. In addition, we find that Google requires 6.6 times as much user effort to achieve the same level of recall as Mulder.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {242–262},
numpages = {21},
keywords = {search engines, answer extraction, query formulation, answer selection, natural language processing}
}

@article{10.1145/502115.502116,
author = {Melink, Sergey and Raghavan, Sriram and Yang, Beverly and Garcia-Molina, Hector},
title = {Building a Distributed Full-Text Index for the Web},
year = {2001},
issue_date = {July 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/502115.502116},
doi = {10.1145/502115.502116},
abstract = {We identify crucial design issues in building a distributed inverted index for a large collection of Web pages. We introduce a novel pipelining technique for structuring the core index-building system that substantially reduces the index construction time. We also propose a storage scheme for creating and managing inverted files using an embedded database system. We suggest and compare different strategies for collecting global statistics from distributed inverted indexes. Finally, we present performance results from experiments on a testbed distributed Web indexing system that we have implemented.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {217–241},
numpages = {25},
keywords = {Embedded databases, Distributed indexing, Text retrieval, Inverted files, Pipelining}
}

@article{10.1145/382979.383042,
author = {Meuss, Holger and Schulz, Klaus U.},
title = {Complete Answer Aggregates for Treelike Databases: A Novel Approach to Combine Querying and Navigation},
year = {2001},
issue_date = {April 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/382979.383042},
doi = {10.1145/382979.383042},
abstract = {The use of markup languages like SGML, HTML or XML for encoding the strucutre of documents or linguistic data has lead to many databases where entries are adequately described as trees. In this context querying formalisms are interesting that offer the possiblity to refer both to textual content and logical structure. We consider models where the strucutre specified in a query is not only used as a filter, but also for selecting and presenting different parts of the data. If answers are formalized as mapping from query nodes to the database, a simple enumeration of all mappings in the answer set will often suffer from the effect that many answers have common subparts. From a theoretical point of view this may lead to an exponential time complexity of the computation and presentation of all answers. Concentration on the language of so called tree queries—a variant and extension of Kilpel\"{a}inen's Tree Matching formalism—we introduce the notion of a “complete answer aggregate” for a given query. This new data strucutre offers a compact view of the set of all answer and supports active exploration of the ansewer space. Since complete answer aggregates use a powerful structure-sharing mechanism their maximal size is of order 𝒪(d•h•q) where d and q respectively denote the size of the database and the query, and h is the maximal depth of a path of the database. An algorithm is given that computes a complete answer aggregate for a given treee query in time 𝒪(d•log(d)•h•). For the sublanguage of so-called rigid tree queries, as well as for so-called “nonrecursive” databases, an improved bound of 𝒪(d•log(d)•q) is obtained. The algorithm is based on a specific index structure that supports practical efficiency.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {161–215},
numpages = {55},
keywords = {information retrieval, query languages, tree matching, structured documents, SGML, logic, answer presentation, tree databases, semistructured data, XML}
}

@article{10.1145/382979.383041,
author = {Lempel, R. and Moran, S.},
title = {SALSA: The Stochastic Approach for Link-Structure Analysis},
year = {2001},
issue_date = {April 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/382979.383041},
doi = {10.1145/382979.383041},
abstract = {Today, when searching for information on the WWW, one usually performs a query through a term-based search engine. These engines return, as the query's result, a list of Web pages whose contents matches the query. For broad-topic queries, such searches often result in a huge set of retrieved documents, many of which are irrelevant to the user. However, much information is contained in the link-structure of the WWW. Information such as which pages are linked to others can be used to augment search algorithms. In this context, Jon Kleinberg introduced the notion of two distinct types of Web pages: hubs and authorities. Kleinberg argued that hubs and authorities exhibit a mutually reinforcing relationship: a good hub will point to many  authorities, and a good authority will be pointed at by many hubs. In light of this, he dervised an algoirthm aimed at finding authoritative pages. We present SALSA, a new stochastic approach for link-structure analysis, which examines random walks on graphs derived from the link-structure. We show that both SALSA and Kleinberg's Mutual Reinforcement approach employ the same metaalgorithm.  We then prove that SALSA is quivalent to a weighted in degree analysis of the link-sturcutre of WWW subgraphs, making it computationally more efficient than the Mutual reinforcement approach. We compare that results of applying SALSA to the results derived through Kleinberg's approach. These comparisions reveal a topological Phenomenon called the TKC effectwhich, in certain cases,  prevents the Mutual reinforcement approach from identifying meaningful authorities.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {131–160},
numpages = {30},
keywords = {hubs and authorities, Link-structure analysis, TKC effect, random walks, SALSA}
}

@article{10.1145/382979.383040,
author = {Callan, Jamie and Connell, Margaret},
title = {Query-Based Sampling of Text Databases},
year = {2001},
issue_date = {April 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/382979.383040},
doi = {10.1145/382979.383040},
abstract = {The proliferation of searchable text databases on corporate networks and the Internet causes a database selection problem for many people. Algorithms such as gGLOSS and CORI can automatically select which text databases to search for a given information need, but only if given a set of resource descriptions that accurately represent the contents of each database. The existing techniques for a acquiring resource descriptions have significant limitations when used in wide-area networks controlled by many parties. This paper presents query-based sampling, a new technicque for acquiring accurate resource descriptions. Query-based sampling does not require the cooperation of resource providers, nor does it require that resource providers use a particular search engine or  representation technique. An extensive set of experimental results demonstrates that accurate resource descriptions are crated, that computation and communication costs are reasonable, and that the resource descriptions do in fact enable accurate automatic dtabase selection.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {97–130},
numpages = {34},
keywords = {server selection, resource selection, query-based sampling, distributed information retrieval, resource ranking}
}

@article{10.1145/366836.366874,
author = {Papadias, Dimitris and Mamoulis, Nikos and Delis, Vasilis},
title = {Approximate Spatio-Temporal Retrieval},
year = {2001},
issue_date = {Jan. 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/366836.366874},
doi = {10.1145/366836.366874},
abstract = {This paper proposes a framework for the handling of spatio-temporal queries with inexact matches, using the concept of relation similarity. We initially describe a binary string encoding for 1D relations that permits the automatic derivation of similarity measures. We then extend this model to various granularity levels and many dimensions, and show that reasoning on spatio-temporal structure is significantly facilitated in the new framework. Finally, we provide algorithms and optimization methods for four types of queries: (i) object retrieval based on some spatio-temporal relations with respect to a reference object, (ii) spatial joins, i.e., retrieval of object pairs that satisfy some input relation, (iii) structural queries, which retrieve configurations matching a particular spatio-temporal structure, and (iv) special cases of motion queries. Considering the current large availability of multidimensional data and the increasing need for flexible query-answering mechanisms, our techniques can be used as the core of spatio-temporal query processors.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {53–96},
numpages = {44}
}

@article{10.1145/366836.366869,
author = {de Oliveira, Maria Cristina Ferreira and Turine, Marcelo Augusto Santos and Masiero, Paulo Cesar},
title = {A Statechart-Based Model for Hypermedia Applications},
year = {2001},
issue_date = {Jan. 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/366836.366869},
doi = {10.1145/366836.366869},
abstract = {This paper presents a formal definition for HMBS (Hypermedia Model Based on Statecharts). HMBS uses the structure and execution semantics of statecharts to specify both the structural organization and the browsing semantics of hypermedia applications. Statecharts are an extension of finite-state machines and the model is thus a generalization of hypergraph-based hypertext models. Some of the most important features of HMBS are its ability to model hierarchy and synchronization of information; provision of mechanisms for specifying access structures, navigational contexts, access control, multiple tailored versions,and hierarchical views. Analysis of the underlying statechart machine allows verification of page reachability, valid paths, and other properties, thus providing mechanisms to support authors in the development of structured applications.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {28–52},
numpages = {25},
keywords = {statecharts, navigational model, hypermedia specification, browsing semantics, HMBS}
}

@article{10.1145/366836.366860,
author = {Carpineto, Claudio and de Mori, Renato and Romano, Giovanni and Bigi, Brigitte},
title = {An Information-Theoretic Approach to Automatic Query Expansion},
year = {2001},
issue_date = {Jan. 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/366836.366860},
doi = {10.1145/366836.366860},
abstract = {Techniques for automatic query expansion from top retrieved documents have shown promise for improving retrieval effectiveness on large collections; however, they often rely on an empirical ground, and there is a shortage of cross-system comparisons. Using ideas from Information Theory, we present a computationally simple and theoretically justified method for assigning scores to candidate expansion terms. Such scores are used to select and weight expansion terms within Rocchio's framework for query reweigthing. We compare ranking with information-theoretic query expansion versus ranking with other query expansion techniques, showing that the former achieves better retrieval effectiveness on several performance measures. We also discuss the effect on retrieval effectiveness of the main parameters involved in automatic query expansion, such as data sparseness, query difficulty, number of selected documents, and number of selected terms, pointing out interesting relationships.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–27},
numpages = {27},
keywords = {pseudorelevance feedback, automatic query expansion, information retrieval, information theory}
}

@article{10.1145/358108.358114,
author = {Lu, Hongjun and Feng, Ling and Han, Jiawei},
title = {Beyond Intratransaction Association Analysis: Mining Multidimensional Intertransaction Association Rules},
year = {2000},
issue_date = {Oct. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/358108.358114},
doi = {10.1145/358108.358114},
abstract = {In this paper, we extend the scope of mining association rules from traditional single-dimensional intratransaction associations, to multidimensional intertransaction associations. Intratransaction associations are the associations among items with the same transaction, where the notion of the transaction could be the items bought by the same customer, the events happened on the same day, and so on. However, an intertransaction association describes the association relationships among different transactions, such as “if(company) A's stock goes up on day 1, B's stock will go down on day 2, but go up on day 4.” In this case, whether we treat company or day as the unit of transaction, the associated items belong to different transactions. Moreover, such an intertransaction association can be extended to associate multiple contextual properties in the same rule, so that multidimensional intertransaction associations can be defined and discovered. A two-dimensional intertransaction association rule example is “After McDonald and Burger King open branches, KFC will open a branch two months later and one mile away,” which involves two dimensions: time and space. Mining intertransaction associations poses more challenges on efficient processing than mining intratransaction associations. Interestingly, intratransaction association can be treated as a special case of intertransaction association from both a conceptual and algorithmic point of view. In this study, we introduce the notion of multidimensional intertransaction association rules, study their measurements—support and confidence—and develop algorithms for mining intertransaction associations by extension of Apriori. We overview our experience using the algorithms on both real-life and synthetic data sets. Further extensions of multidimensional intertransaction association rules and potential applications are also discussed.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {423–454},
numpages = {32},
keywords = {multidimensional context, data mining, association rules, intra/intertransaction}
}

@article{10.1145/358108.358111,
author = {Katzenstein, Gary and Lerch, F. Javier},
title = {Beneath the Surface of Organizational Processes: A Social Representation Framework for Business Process Redesign},
year = {2000},
issue_date = {Oct. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/358108.358111},
doi = {10.1145/358108.358111},
abstract = {This paper raises the question, “What is an effective representation framework for organizational process design?” By combining our knowledge of existing process models with data from a field study, the paper develops criteria for an effective process representation. Using these criteria and the case study, the paper integrates the process redesign and information system literatures to develop a representation framework that captures a process' social context. The paper argues that this social context framework, which represents people's motivations, social relationships, and social constraints, gives redesigners a richer sense of the process and allows process redesigners to simultaneously change social and logistic systems. The paper demonstrates the framework and some of its benefits and limitations.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {383–422},
numpages = {40},
keywords = {process representation, organizational change, business process redesign}
}

@article{10.1145/358108.358110,
author = {Fraternali, Piero and Paolini, Paolo},
title = {Model-Driven Development of Web Applications: The AutoWeb System},
year = {2000},
issue_date = {Oct. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/358108.358110},
doi = {10.1145/358108.358110},
abstract = {This paper describes a methodology for the development of WWW applications and a tool environment specifically tailored for the methodology. The methodology and the development environment are based upon models and techniques already used in the hypermedia, information systems, and software engineering fields, adapted and blended in an original mix. The foundation of the proposal is the conceptual design of WWW applications, using HDM-lite, a notation for the specification of structure, navigation, and presentation semantics. The conceptual schema is then translated into a “traditional” database schema, which describes both the organization of the content and the desired navigation and presentation features. The WWW pages can therefore be dynamically generated from the  database content, following the navigation requests of the user. A CASE environment, called Autoweb System, offers a set of software tools, which assist the design and the execution of a WWW application, in all its different aspects, Real-life experiences of the use of the methodology and of the AutoWeb System in both the industrial and academic context are reported.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {323–382},
numpages = {60},
keywords = {intranet, HTML, application, modeling, WWW, development}
}

@article{10.1145/352595.352598,
author = {Cohen, William W.},
title = {Data Integration Using Similarity Joins and a Word-Based Information Representation Language},
year = {2000},
issue_date = {July 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/352595.352598},
doi = {10.1145/352595.352598},
abstract = {The integration of distributed, heterogeneous databases, such as those available on the World Wide Web, poses many problems. Herer we consider the problem of integrating data from sources that lack common object identifiers. A solution to this problem is proposed for databases that contain informal, natural-language “names” for objects; most Web-based databases satisfy this requirement, since they usually present their information to the end-user through a veneer of text. We describe WHIRL, a “soft” database management system which supports “similarity joins,” based on certain robust, general-purpose similarity metrics for text. This enables fragments of text (e.g., informal names of objects) to be used as keys. WHIRL includes   textual objects as a built-in type, similarity reasoning as a built-in predicate, and answers every query with a list of answer substitutions that are ranked according to an overall score. Experiments show that WHIRL is much faster than naive inference methods, even for short queries, and efficient on typical queries to real-world databases with tens of thousands of tuples. Inferences made by WHIRL are also surprisingly accurate, equaling the accuracy of hand-coded normalization routines on one benchmark problem, and outerperforming exact matching with a plausible global domain on a second.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {288–321},
numpages = {34}
}

@article{10.1145/352595.352597,
author = {Greiff, Warren R. and Ponte, Jay M.},
title = {The Maximum Entropy Approach and Probabilistic IR Models},
year = {2000},
issue_date = {July 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/352595.352597},
doi = {10.1145/352595.352597},
abstract = {This paper takes a fresh look at modeling approaches to information retrieval that have been the basis of much of the probabilistically motivated IR research over the last 20 years. We shall adopt a subjectivist Bayesian view of probabilities and argue that classical work on probabilistic retrieval is best understood from this perspective. The main focus of the paper will be the ranking formulas corresponding to the Binary Independence Model (BIM), presented originally by Roberston and Sparck Jones [1977] and the Combination Match Model (CMM), developed shortly thereafter by Croft and Harper [1979]. We will show how these same ranking formulas can result from a probabilistic methodology commonly known as Maximum Entropy (MAXENT).},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {246–287},
numpages = {42},
keywords = {idf weighting, linked dependence, binary independence model, probability ranking principle, combination match}
}

@article{10.1145/352595.352596,
author = {Anderson, Kenneth M. and Taylor, Richard N. and Whitehead, E. James},
title = {Chimera: Hypermedia for Heterogeneous Software Development Enviroments},
year = {2000},
issue_date = {July 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/352595.352596},
doi = {10.1145/352595.352596},
abstract = {Emerging software development environments are characterized by heterogeneity: they are composed of diverse object stores, user interfaces, and tools. This paper presents an approach for providing hypermedia services in this heterogeneous setting. Central notions of the approach include the following: anchors are established with respect to interactive views of objects, rather than the objects themselves; composable, n-ary links can be established between anchors on different views of objects which may be stored in distinct object bases; viewers may be implemented in different programming languages; and, hypermedia services are provided to multiple, concurrently active, viewers. The paper describes the approach, supporting architecture, and lessons  learned. Related work in the areas of supporing heterogeneity and hypermedia data modeling is discussed. The system has been employed in a variety of contexts including research, development, and education.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {211–245},
numpages = {35},
keywords = {link servers, software development environments, hypermedia system architectures, open hypermedia systems, heterogeneous hypermedia}
}

@article{10.1145/348751.348762,
author = {El-Kwae, Essam A. and Kabuka, Mansur R.},
title = {Efficient Content-Based Indexing of Large Image Databases},
year = {2000},
issue_date = {April 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/348751.348762},
doi = {10.1145/348751.348762},
abstract = {Large image databases have emerged in various applications in recent years. A prime requisite of these databases is the means by which their contents can be indexed and retrieved. A multilevel signature file called the Two Signature Multi-level Signature File (2SMLSF) is introduced as an efficient access structure for large image databases. The 2SMLSF encodes image information into binary signatures and creates a tree structures can be efficiently searched to satisfy a user's query. Two types of signatures are generated. Type I signatures are used at all tree levels except the leaf level and are based only on the domain objects included in the image. Type II signatures, on the other hand, are stored at the leaf level and are based on the included domain objects and their spatial relationships. The   2SMLSF was compared analytically to existing signature file techniques. The 2SMLSF significantly reduces the storage requirements; the index structure can answer more queries; and the 2SMLSF performance significantly improves over current techniques. Both storage reduction and performance improvement increase with the number of objects per image and the number of images in the database. For an example large image database, a storage reduction of 78% may be archieved  while the performance improvement may reach 98%.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {171–210},
numpages = {40},
keywords = {multimedia databases, content analysis and indexing, document managing, image databases, index generation}
}

@article{10.1145/348751.348758,
author = {Dourish, Paul and Edwards, W. Keith and LaMarca, Anthony and Lamping, John and Petersen, Karin and Salisbury, Michael and Terry, Douglas B. and Thornton, James},
title = {Extending Document Management Systems with User-Specific Active Properties},
year = {2000},
issue_date = {April 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/348751.348758},
doi = {10.1145/348751.348758},
abstract = {Document properties are a compelling infrastructure on which to develop document management applications. A property-based approach avoids many of the problems of traditional heierarchical storage mechanisms, reflects document organizations meaningful to user tasks, provides a means to integrate the perspectives of multiple individuals and groups, and does this all within a uniform interaction framework. Document properties can reflect not only categorizations of documents and document use, but also expressions of desired system activity, such as sharing criteria, replication management, and versioning. Augmenting property-based document management systems with active properties that carry executable code enables the provision of document-based services on a property infrastructure.   The combination of document properties as a uniform mechanism for document management, and active properties as a way of delivering document services, represents a new paradigm for document management infrastructures. The Placeless Documents system is an experimental prototype developed to explore this new paradigm. It is based on the seamless integration of user-specific, active properties. We present the fundamental design approach, explore the challenges and opportunities it presents, and show our architectures deals with them.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {140–170},
numpages = {31},
keywords = {document services, document management systems, component software, active properties, user experience}
}

@article{10.1145/348751.348754,
author = {Silva de Moura, Edleno and Navarro, Gonzalo and Ziviani, Nivio and Baeza-Yates, Ricardo},
title = {Fast and Flexible Word Searching on Compressed Text},
year = {2000},
issue_date = {April 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/348751.348754},
doi = {10.1145/348751.348754},
abstract = {We present a fast compression technique for natural language texts. The novelties are that (1) decompression of arbitrary portions of the text can be done very efficiently, (2) exact search for words and phrases can be done on the compressed text directly, using any known sequential pattern-matching algorithm, and (3) word-based approximate and extended search can also be done efficiently without any decoding. The compression scheme uses a semistatic word-based model and a Huffman code where the coding alphabet is byte-oriented rather than bit-oriented. We compress typical English texts to about 30% of their original size, against 40% and 35% for Compress and Gzip, respectively. Compression time is close to that of Compress and   approximately half of the time of Gzip, and decompression time is lower than that of Gzip and one third of that of Compress. We present three algorithms to search the compressed text. They allow a large number of variations over the basic word and phrase search capability, such as sets of characters, arbitrary regular expressions, and approximate matching. Separators and stopwords can be discarded at search time without significantly increasing the cost. When searching for simple words, the experiments show that running our algorithms on a compressed text is twice as fast as running the best existing software on the uncompressed version of the same text. When searching complex or approximate patterns, our algorithms are up to 8 times   faster than the search on uncompressed text. We also discuss the impact of our technique in inverted files pointing to logical blocks and argue for the possibility of keeping the text compressed all the time, decompressing only for displaying purposes.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {113–139},
numpages = {27},
keywords = {natural language text compression, compressed pattern matching, word-based Huffman coding, word searching}
}

@article{10.1145/333135.333138,
author = {Xu, Jinxi and Croft, W. Bruce},
title = {Improving the Effectiveness of Information Retrieval with Local Context Analysis},
year = {2000},
issue_date = {Jan. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/333135.333138},
doi = {10.1145/333135.333138},
abstract = {Techniques for automatic query expansion have been extensively studied in information research as a means of addressing the word mismatch between queries and documents. These techniques can be categorized as either global or local. While global techniques rely on analysis of a whole collection to discover word relationships, local techniques emphasize analysis of the top-ranked documents retrieved for a query. While local techniques have shown to be more effective that global techniques in general, existing local techniques are not robust and can seriously hurt retrieved when few of the retrieval documents are relevant. We propose a new technique, called local context analysis, which selects expansion terms based on cooccurrence with the query terms within the  top-ranked documents. Experiments on a number of collections, both English and non-English, show that local context analysis offers more effective and consistent retrieval results. },
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {79–112},
numpages = {34},
keywords = {local context analysis, feedback, cooccurrence, global techniques, information retrieval, document analysis, local techniques}
}

@article{10.1145/333135.333137,
author = {Clarke, Charles L. A. and Cormack, Gordon V.},
title = {Shortest-Substring Retrieval and Ranking},
year = {2000},
issue_date = {Jan. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/333135.333137},
doi = {10.1145/333135.333137},
abstract = {We present a model for arbitrary passage retrieval using Boolean queries. The model is applied to the task of ranking documents, or other structural elements, in the order of their expected relevance. Features such as phrase matching, truncation, and stemming integrate naturally into the model. Properties of Boolean algebra are obeyed, and the exact-match semantics of Boolean retrieval are preserved. Simple inverted-list file structures provide an efficient implementation. Retrieval effectiveness is comparable to that of standard ranking techniques. Since global statistics are not used, the method is of particular value in distributed environments. Since ranking is based on arbitrary passages, the structural elements to be ranked may be specified at query time and do not need to be  restricted to predefined elements.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {44–78},
numpages = {35},
keywords = {Boolean retrieval model, relevance ranking, passage retrieval}
}

@article{10.1145/333135.333136,
author = {Cahoon, Brendon and McKinley, Kathryn S. and Lu, Zhihong},
title = {Evaluating the Performance of Distributed Architectures for Information Retrieval Using a Variety of Workloads},
year = {2000},
issue_date = {Jan. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/333135.333136},
doi = {10.1145/333135.333136},
abstract = {The information explosion across the Internet and elswhere offers access to an increasing number of document collections. In order for users to effectively access these collections, information retrieval (IR) systems must provide coordinated, concurrent, and distributed access. In this article, we explore how to achieve scalable performance in a distributed system for collection sizes ranging from 1GB to 128GB. We implement a fully functional distributed IR system based on a multithreaded version of the Inquery simulation model. We measure performance as a function of system parameters such as client command rate, number of document collections, ter ms per query, query term frequency, number of answers returned, and command mixture. Our results show that it is important to model both  query and document commands because the heterogeneity of commands significantly impacts performance. Based on our results, we recommend simple changes to the prototype and  evaluate the changes using the simulator. Because of the significant resource demands of information retrieval, it is not difficult to generate workloads that overwhelm system resources regardless of the architecture. However under some realistic workloads, we demonstrate system organizations for which response time gracefully degrades as the workload increases and performance scales with the number of processors. This scalable architecture includes a surprisingly small number of brokers through which a large number of clients and servers communicate.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–43},
numpages = {43},
keywords = {distributed information retrieval architectures}
}

@article{10.1145/326440.326447,
author = {Sanderson, Mark and Van Rijsbergen, C. J.},
title = {The Impact on Retrieval Effectiveness of Skewed Frequency Distributions},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/326440.326447},
doi = {10.1145/326440.326447},
abstract = {We present an analysis of word senses that provides a fresh insight 
into the impact of word ambiguity on retrieval effectiveness with potential broader implications for other processes of information retrieval. Using a methodology of forming artifically ambiguous words, known as pseudowords, and through reference to other researchers' work, the analysis illustrates that the distribution of the frequency of occurrance of the senses of a word plays a strong role in ambiguity's impact of effectiveness. Further investigation shows that this analysis may also be applicable to other processes of retrieval, such as Cross Language Information Retrieval, query expansion, retrieval of OCR'ed texts, and stemming. The analysis appears to provide a means of explaining, at least in part, reasons  for the processes' impact (or lack of it) on effectiveness.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {440–465},
numpages = {26},
keywords = {pseudowords, word sense ambiguity, word sense disambiguation}
}

@article{10.1145/326440.326445,
author = {Kaszkiel, Marcin and Zobel, Justin and Sacks-Davis, Ron},
title = {Efficient Passage Ranking for Document Databases},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/326440.326445},
doi = {10.1145/326440.326445},
abstract = {Queries to text collections are resolved by ranking the documents in the collection and returning the highest-scoring documents to the user. An alternative retrieval method is to rank passages, that is, short fragments of documents, a strategy that can improve effectiveness and identify relevant material in documents that are too large for users to consider as a whole. However, ranking of passages can considerably increase retrieval costs. In this article we explore alternative query evaluation techniques, and develop new tecnhiques for evaluating queries on passages. We show experimentally that, appropriately implemented, effective passage retrieval is practical in limited memory on a desktop machine. Compared to passage ranking with adaptations of current document ranking algorithms,  our new “DO-TOS” passage-ranking algorithm requires only a fraction of the resources, at the cost of a small loss of effectiveness.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {406–439},
numpages = {34},
keywords = {inverted files, text databases, passage retrieval, query evaluation, text retrieval}
}

@article{10.1145/326440.326444,
author = {Greiff, Warren R. and Croft, W. Bruce and Turtle, Howard},
title = {PIC Matrices: A Computationally Tractable Class of Probabilistic Query Operators},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/326440.326444},
doi = {10.1145/326440.326444},
abstract = {The inference network model of information retrieval allows a 
probabilistic interpretation of query operators. In particular, Boolean query operators are conveniently modeled as link matrices of the Bayesian Network. Prior work has shown, however, that these operators do not perform as well as the pnorm operators used for modeling query operators in the context of the vector space model. This motivates the search for alternative probabilistic formulations for these operators. The design of such alternatives must contend with the issue of computational tractability, since the evaluation of an arbitrary operator requires exponential time. We define a flexible class of link matrices that are natural candidates for the implementation of query operators and an   O(n2) algorithm (n = the number of parent nodes) for the computation of probabilities involving link matrices of this class. We present experimental results indicating that Boolean operators implemented in terms of link matrices from this class perform as well as pnorm operators in the context of the INQUERY inference network.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {367–405},
numpages = {39},
keywords = {inference networks, query operators, probabilistic information retrieval, computational complexity, pnorm, Boolean queries, Bayesian networks, piecewise linear functions, link matrices}
}

@article{10.1145/326440.326442,
author = {Chen, Hao and Hu, Jianying and Sproat, Richard W.},
title = {Integrating Geometrical and Linguistic Analysis for Email Signature Block Parsing},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/326440.326442},
doi = {10.1145/326440.326442},
abstract = {The signature block is a common structured component found in email messages. Accurate identification and analysis of signature blocks is important in many multimedia messaging and information retrieval applications such as email text-to-speech rendering, automatic construction of personal address databases, and interactive message retrieval. It is also a very challenging task, because signature blocks often appear in complex two-dimensional layouts which are guided only by loose conventions. Traditional text analysis methods designed to deal with sequential text cannot handle two-dimensional structures, while the highly unconstrained nature of signature blocks makes the application of two-dimensional grammars very difficult. In this article, we describe an algorithm for signature  block analysis which combines two-dimensional structural segmentation with one-dimensional grammatical constraints. The information obtained from both layout and linguistic analysis is integrated in the form of weighted finite-state transducers. The algorithm is currently implemented as a component in a preprocessing system for email text-to-speech rendering.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {343–366},
numpages = {24},
keywords = {finite-state transducer, text-to-speech rendering, linguistic analysis, geometrical analysis, email signature block}
}

@article{10.1145/314516.314522,
author = {Plaisant, Catherine and Shneiderman, Ben and Doan, Khoa and Bruns, Tom},
title = {Interface and Data Architecture for Query Preview in Networked Information Systems},
year = {1999},
issue_date = {July 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/314516.314522},
doi = {10.1145/314516.314522},
abstract = {There are numerous problems associated with formulating queries on 
networked information systems. These include increased data volume and complexity, accompanied by slow network access. This article proposes a new approach to a network query user interfaces that consists of two phases: query preview and query refinement. This new approach is based on the concepts of dynamic queries and query previews, which guides users in rapidly and dynamically eliminating undesired records, reducing the data volume to a manageable size, and refining queries locally before submission over a network. Examples of two applications are given: a Restaurant Finder and a prototype for NASA's Earth Observing Systems Data Information Systems (EOSDIS). Data architecture is discussed, and user feedback is  presented.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {320–341},
numpages = {22},
keywords = {graphical user interface, science data, EOSDIS, dynamic query, query refinement, query preview, direct manipulation}
}

@article{10.1145/314516.314521,
author = {Lim, Ee-Peng and Lu, Ying},
title = {Harp: A Distributed Query System for Legacy Public Libraries and Structured Databases},
year = {1999},
issue_date = {July 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/314516.314521},
doi = {10.1145/314516.314521},
abstract = {The main purpose of a digital library is to facilitate users easy 
access to enormous amount of globally networked information. Typically, this information includes preexisting public library catalog data, digitized document collections, and other databases. In this article, we describe the distributed query system of a digital library prototype system known as HARP. In the HARP project, we have designed and implemented a distributed query processor and its query front-end to support integrated queries to preexisting public library catalogs and structured databases. This article describes our experiences in the design of an extended Sequel (SQL) query language known as HarpSQL. It also presents the design and implementation of the distributed query system. Our experience in  distributed query processor and user interface design and development will be highlighted. We believe that our prototyping effort will provide useful lessons to the development of a complete digital library infrastructure.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {294–319},
numpages = {26},
keywords = {digital libraries, Internet databases, interoperable databases}
}

@article{10.1145/314516.314520,
author = {Goh, Cheng Hian and Bressan, St\'{e}phane and Madnick, Stuart and Siegel, Michael},
title = {Context Interchange: New Features and Formalisms for the Intelligent Integration of Information},
year = {1999},
issue_date = {July 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/314516.314520},
doi = {10.1145/314516.314520},
abstract = {The Context Interchange strategy presents a novel 
perspective for mediated data access in which semantic conflicts among heterogeneous systems are not identified a priori, but are detected and reconciled by a context mediator through comparison of contexts axioms corresponding to the systems engaged in data exchange. In this article, we show that queries formulated on shared views, export schema, and shared “ontologies” can be mediated in the same way using the Context Interchange framework. The proposed framework provides a logic-based object-oriented formalsim for representing and reasoning about data semantics in disparate systems, and has been validated in a prototype implementation providing  mediated data access to both traditional and web-based information sources.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {270–293},
numpages = {24},
keywords = {abductive reasoning, semantic heterogeneity, information integration, semantic interoperability, mediators}
}

@article{10.1145/314516.314519,
author = {Gauch, Susan and Wang, Jianying and Rachakonda, Satya Mahesh},
title = {A Corpus Analysis Approach for Automatic Query Expansion and Its Extension to Multiple Databases},
year = {1999},
issue_date = {July 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/314516.314519},
doi = {10.1145/314516.314519},
abstract = {Searching online text collections can be both rewarding and 
frustrating. While valuable information can be found, typically many irrelevant documents are also retrieved, while many relevant ones are missed. Terminology mismatches between the user's query and document contents are a main cause of retrieval failures. Expanding a user's query with related words can improve search performances, but finding and using related words is an open problem. This research uses corpus analysis techniques to automatically discover similar words directly from the contents of the databases which are not tagged with part-of-speech labels. Using these similarities, user queries are automatically expanded, resulting in conceptual retrieval rather than requiring exact word matches between queries and  documents. We are able to achieve a 7.6% improvement for TREC 5 queries and up to a 28.5% improvement on the narrow-domain Cystic Fibrosis collection. This work has been extended to multidatabase collections where each subdatabase has a collection-specific similarity matrix associated with it. If the best matrix is selected, substantial search improvements are possible. Various techniques to select the appropriate matrix for a particular query are analyzed, and a 4.8% improvement in the results is validated.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {250–269},
numpages = {20},
keywords = {query expansion}
}

@article{10.1145/314516.314517,
author = {Fuhr, Norbert},
title = {A Decision-Theoretic Approach to Database Selection in Networked IR},
year = {1999},
issue_date = {July 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/314516.314517},
doi = {10.1145/314516.314517},
abstract = {In networked IR, a client submits a query to a broker, which is in 
contact with a large number of databases. In order to yield a maximum number of documents at minimum cost, the broker has to make estimates about the retrieval cost of each database, and then decide for each database whether or not to use it for the current query, and if, how many documents to retrieve from it. For this purpose, we develop a general decision-theoretic model and discuss different cost structures. Besides cost for retrieving relevant versus nonrelevant documents, we consider the following parameters for each database: expected retrieval quality, expected number of relevant documents in the database and cost factors for query processing and document delivery. For computing the overall optimum, a  divide-and-conquer algorithm is given. If there are several brokers knowing different databases, a preselection of brokers can only be performed heuristically, but the computation of the optimum can be done similarily to the single-broker case. In addition, we derive a formula which estimates the number of relevant documents in a database based on dictionary information.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {229–249},
numpages = {21},
keywords = {probability ranking principle, probabilistic retrieval, networked retrieval, resource discovery}
}

@article{10.1145/306686.306690,
author = {Shipman, Frank M. and McCall, Raymond J.},
title = {Incremental Formalization with the Hyper-Object Substrate},
year = {1999},
issue_date = {April 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/306686.306690},
doi = {10.1145/306686.306690},
abstract = {Computers require formally represented information to perform computations that support users; yet users who have needed such support have often proved to be unable or unwilling to formalize it. To address this problem, this article introduces an approach called incremental formalization, in which, first, users express information informally and then the system aids them in formalizing it. Incremental formalization requires a system architecture the (1) integrates formal and informal representations and (2) supports progressive formalization of information. The system should have both tools to capture naturally available informal information and techniques to suggest possible formalizations of this information. The hyper-object substrate (HOS) was developed to satisfy these  requirements. HOS has been applied to a number of problem domains, including network design, archeological site analysis, and neuroscience education. Users have been successful in adding informal information and then later formalizing it incrementally with the aid of the system. Our experience with HOS has reaffirmed the need for information spaces to evolve during use and has identified additional considerations in the design and instantiation of systems enabling and supporting incremental formalization},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {199–227},
numpages = {29}
}

@article{10.1145/306686.306689,
author = {El-Kwae, Essam A. and Kabuka, Mansur R.},
title = {A Robust Framework for Content-Based Retrieval by Spatial Similarity in Image Databases},
year = {1999},
issue_date = {April 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/306686.306689},
doi = {10.1145/306686.306689},
abstract = {A framework for retrieving images by spatial similarity (FRISS) in ima ge databases is presented. In this framework, a robust retrieval by spatial similarity (RSS) algorithm is defined as one that incorporates both directional and topological spatial constraints, retrieves similar images, and recognized images even after they undergo translation, scaling, rotation (both perfect and multiple), or any arbitrary combination of transformatioins. The FRISS framework is discussed and used as a base for comparing various existing RSS algorithms. Analysis shows that none of them satisfies all the FRISS specifications. An algorithm, SIMdtc, is then presented. SIMdtc introduces the concept of a rotation correction angle(RCA) to align objects in one image spatially closer to  matching objects in another image for more accurate similarity assessment. Similarity between two images is a function of the number of common objects between them and the closeness of directional and topological spatial relationships between object pairs in both images. The SIMdtc retrieval is invariant under translation, scaling, and perfect rotation, and the algorithm is able to rank multiple rotation variants. The algorithm was tested using synthetic images and the TESSA image database. Analysis shows the robustness of the SIMdtc algorithm over current algorithms.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {174–198},
numpages = {25},
keywords = {spatial similarity, image databases, content-based retrieval, similarity retrieval, query formulation, multimedia databases, retrieval models}
}

@article{10.1145/306686.306688,
author = {Cohen, William W. and Singer, Yoram},
title = {Context-Sensitive Learning Methods for Text Categorization},
year = {1999},
issue_date = {April 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/306686.306688},
doi = {10.1145/306686.306688},
abstract = {Two recently implemented machine-learning algorithms, RIPPERand sleeping-experts for phrases, are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the “context” of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences,  both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {141–173},
numpages = {33},
keywords = {context-sensitive models, rule learning, on-line learning, text categorization, mistake-driven algorithms}
}

@article{10.1145/306686.306687,
author = {Bertino, Elisa and Jajodia, Sushil and Samarati, Pierangela},
title = {A Flexible Authorization Mechanism for Relational Data Management Systems},
year = {1999},
issue_date = {April 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/306686.306687},
doi = {10.1145/306686.306687},
abstract = {In this article, we present an authorization model that can be used to express a number of discretionary access control policies for relational data management systems. The model permits both positive and negative authorizations and supports exceptions at the same time. The model is flexible in that the users can specify, for each authorization they grant, whether the authorization can allow for exceptions or whether it must be strongly obeyed. It provides authorization management for groups with exceptions at any level of the group hierarchy, and temporary suspension of authorizations. The model supports ownership together with decentralized administration of authorizations. Administrative privileges can also be restricted so that owners retain control over their tables.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {101–140},
numpages = {40},
keywords = {data management system, access control policy, access control mechanism, group management support, authorization, relational database}
}

@article{10.1145/297117.297126,
author = {Tan, Bernard C. Y. and Wei, Kwok-kee and Watson, Richard T.},
title = {The Equalizing Impact of a Group Support System on Status Differentials},
year = {1999},
issue_date = {Jan. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/297117.297126},
doi = {10.1145/297117.297126},
abstract = {This study investigates the impact of the electronic communication capability of a group support system (GSS) on status differentials in small groups. A laboratory experiment was used to answer the research questions. Three support levels were studied: manual, face-to-face GSS, and dispersed GSS. Two task types were examined: intellective and preference. Five dependent variables reflecting different aspects of status differentials were measured: status influence, sustained influence, residual disagreement, perceived influence, and decision confidence. The results show that manual groups had higher status influence, sustained influence, and decision confidence, but lower residual disagreement than face-to-face GSS and dispersed GSS groups. Preference task groups also produced higher  status influence and sustained influence, but lower residual disagreement compared to intellective task groups. In addition, manual groups working on the preference task reported higher perceived influence than face-to-face GSS and dispersed GSS groups working on the same task. These findings suggest that when groups are engaged in activities for which status differentials are undesirable, a GSS can be used in both face-to-face and dispersed settings to dampen status differentials. Moreover, when a task amplifies status differentials, the use of a GSS tends to produce corresponding stronger dampening effects.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {77–100},
numpages = {24},
keywords = {status differentials, group support systems, electronic communication, task type}
}

@article{10.1145/297117.297123,
author = {Hawking, David and Thistlewaite, Paul},
title = {Methods for Information Server Selection},
year = {1999},
issue_date = {Jan. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/297117.297123},
doi = {10.1145/297117.297123},
abstract = {The problem of using a broker to select a subset of available information servers in order to achieve a good trade-off between document retrieval effectiveness and cost is addressed. Server selection methods which are capable of operating in the absence of global information, and where servers have no knowledge of brokers, are investigated. A novel method using Lightweight Probe queries (LWP method) is compared with several methods based on data from past query processing, while Random and Optimal server rankings serve as controls. Methods are evaluated, using TREC data and relevance judgments, by computing ratios, both empirical and ideal, of recall and early precision for the subset versus the complete set of available servers. Estimates are also made of the best-possible  performance of each of the methods. LWP and Topic Similarity methods achieved best results, each being capable of retrieving about 60% of the relevant documents for only one-third of the cost of querying all servers. Subject to the applicable cost model, the LWP method is likely to be preferred because it is suited to dynamic environments. The good results obtained with a simple automatic LWP implementation were replicated using different data and a larger set of query topics.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {40–76},
numpages = {37},
keywords = {network servers, text retrieval, server selection, information servers, Lightweight Probe queries, server ranking}
}

@article{10.1145/297117.297120,
author = {Chang, Chen-Chuan K. and Garcia-Molina, H\'{e}ctor and Paepcke, Andreas},
title = {Predicate Rewriting for Translating Boolean Queries in a Heterogeneous Information System},
year = {1999},
issue_date = {Jan. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/297117.297120},
doi = {10.1145/297117.297120},
abstract = {Searching over heterogeneous information sources is difficult in part because of the nonuniform query languages. Our approach is to allow users to compose Boolean queries in one rich front-end language. For each user query and target source, we transform the user query into a subsuming query that can be supported by the source but that may return extra documents. The results are then processed by a filter query to yield the correct final results. In this article we introduce the architecture and associated mechanism for query translation. In particular, we discuss techniques for rewriting predicates in Boolean queries into native subsuming forms, which is a basis of translating complex queries. In addition, we present experimental results for evaluating the cost of postfiltering. We  also discuss the drawbacks of this approach and cases when it may not be effective. We have implemented prototype versions of these mechanisms and demonstrated them on heterogeneous Boolean systems.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–39},
numpages = {39},
keywords = {predicate rewriting, query subsumption, content-based retrieval, filtering, Boolean queries, query translation}
}

@article{10.1145/291128.291133,
author = {Croft, W. Bruce},
title = {Author Index},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/291128.291133},
doi = {10.1145/291128.291133},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {413–414},
numpages = {2}
}

@article{10.1145/291128.291132,
author = {Wang, Weigang and Rada, Roy},
title = {Structured Hypertext with Domain Semantics},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/291128.291132},
doi = {10.1145/291128.291132},
abstract = {One important facet of current hypertext research involves using knowledge-based techniques to develop and maintain document structures. A semantic net is one such technique. However, most semantic-net-based hypertext systems leave the linking consistency of the net to individual users. Users without guidance may accidentally introduce structural and relational inconsistencies in the semantic nets. The relational inconsistency hinders the creation of domain information models. The structural inconsistency leads to unstable documents, especially when a document is composed by computation with traversal algorithms. This work tackles to above problems by integrating logical structure and domain semantics into a semantic net. A semantic-net-based structured-hypertext model has been  formalized. The model preserves structural and relational consistency after changes to the semantic net. The hypertext system (RICH) based on this model has been implemented and tested. The RICH system can define and enforce a set of rules to maintain to integrity of the semantic net and provide particular support for creating multihierarchies with the reuse of existing contents and structures. Users have found such flexible but enforceable semantics to be helpful.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {372–412},
numpages = {41},
keywords = {hypertext structures, hypertext models, graph theory}
}

@article{10.1145/291128.291131,
author = {Kolda, Tamara G. and O'Leary, Dianne P.},
title = {A Semidiscrete Matrix Decomposition for Latent Semantic Indexing Information Retrieval},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/291128.291131},
doi = {10.1145/291128.291131},
abstract = {The vast amount of textual information available today is useless unless it can be effectively and efficiently searched. The goal in information retrieval is to find documents that are relevant to a given user query. We can represent and document collection by a matrix whose (i, j) entry is nonzero only if the ith term appears in the jth document; thus each document corresponds to a columm vector. The query is also represented as a column vector whose ith term is nonzero only if the ith term appears in the query. We score each document for relevancy by taking its inner product with the query. The highest-scoring documents are considered the most relevant. Unfortunately, this method does not necessarily retrieve all relevant documents because it is based on literal term matching.  Latent semantic indexing (LSI) replaces the document matrix with an approximation generated by the truncated singular-value decomposition (SVD). This method has been shown to overcome many difficulties associated with literal term matching. In this article we propose replacing the SVD with the semidiscrete decomposition (SDD). We will describe the SDD approximation, show how to compute it, and compare the SDD-based LSI method to the SVD-based LSI methods. We will show that SDD-based LSI does as well as SVD-based LSI in terms of document retrieval while requiring only one-twentieth the storage and one-half the time to compute each query. We will also show how to update the SDD approximation when documents are added or deleted from the document collection.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {322–346},
numpages = {25},
keywords = {latent semantic indexing, semidiscrete decomposition, singular-value decomposition, data mining, text retrieval}
}

@article{10.1145/291128.291130,
author = {Ram, Sudha and Ramesh, V.},
title = {Collaborative Conceptual Schema Design: A Process Model and Prototype System},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/291128.291130},
doi = {10.1145/291128.291130},
abstract = {Recent years have seen an increased interest in providing support for collaborative activities among groups of users participating in various information systems design tasks such as, requirements determination and process modeling. However, little attention has been paid to the collaborative conceptual database design process.  In this article, we develop a model of the collaborative conceptual schema development process and describe the design and implementation of a graphical multiuser conceptual schema design tool that is based on the model.  The system we describe allows a group of users to work collaboratively on the creation of database schemas in synchronous (same-time) mode (either in a face-to-face or distributed setting). Extensive modeling support is provided to assist  users in creating semantically correct conceptual schemas. The system also provides users with several graphical facilities such as, a large drawing workspace with the ability to scroll or “jump” to any portion of this workspace, zooming capabilities, and the ability to move object(s) to any portion of the workspace. The unique component of the system, however, is its built-in support for collaborative schema design.  The system supports a relaxed WYSIWIS environment, i.e., each user can control the graphical layout of the same set of schema objects.  The system ensures that changes/additions made by any user are consistent.  Any conflicts that may compromise to the integrity of the shared schema are flagged and resolved by the system.  The results from a  preliminary experiment suggest that the use of our system in a collaborative mode improved information sharing among users, minimized conflicts, and led to a more comprehensive schema definition.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {347–371},
numpages = {25},
keywords = {database design, groupware, graphical CASE tools, collaboration, semantic modeling, conceptual modeling}
}

@article{10.1145/291128.291129,
author = {Egenhofer, Max J. and Shariff, A. Rashid B. M.},
title = {Metric Details for Natural-Language Spatial Relations},
year = {1998},
issue_date = {Oct. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/291128.291129},
doi = {10.1145/291128.291129},
abstract = {Spatial relations often are desired answers that a geographic information system (GIS) should generate in response to a user's query.  Current GIS's provide only rudimentary support for processing and interpreting natural-language-like spatial relations, because their models and representations are primarily quantitative, while natural-language spatial relations are usually dominated by qualitative properties. Studies of the use of spatial relations in natural language showed that topology accounts for a significant portion of the geometric properties. This article develops a formal model that captures metric details for the description of natural-language spatial relations.  The metric details are expressed as refinements of the categories identified by the   9-intersection, a model for topological spatial relations, and provide a more precise measure than does topology alone as to whether a geometric configuration matches with a spatial term or not. Similarly, these measures help in identifying the spatial term that describes a particular configuration. Two groups of metric details are derived: splitting ratios as the normalized values of lengths and areas of intersections; and closeness measures as the normalized distances between disjoint object parts. The resulting model of topological and metric properties was calibrated for 64 spatial terms in English, providing values for the best fit as well as value ranges for the significant parameters of each term.  Three examples demonstrate how the framework and   its calibrated values are used to determine the best spatial term for a relationship between two geometric objects.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {295–321},
numpages = {27},
keywords = {spatial relations, geographic information systems, topological relations, GIS, Metric refinements}
}

@article{10.1145/290159.290162,
author = {Moffat, Alistair and Neal, Radford M. and Witten, Ian H.},
title = {Arithmetic Coding Revisited},
year = {1998},
issue_date = {July 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/290159.290162},
doi = {10.1145/290159.290162},
abstract = {Over the last decade, arithmetic coding has emerged as an important compression tool. It is now the method of choice for adaptive coding on myltisymbol alphabets because of its speed, low storage requirements, and effectiveness of compression. This article describes a new implementation of arithmetic coding that incorporates several improvements over a widely used earlier version by Witten, Neal, and Cleary, which has become a de facto standard. These improvements include fewer multiplicative operations, greatly extended range of alphabet sizes and symbol probabilities, and the use of low-precision arithmetic, permitting implementation by fast shift/add operations. We also describe a modular structure that separates the coding, modeling, and probability estimation  components of a compression system. To motivate the improved coder, we consider the needs of a word-based text compression program. We report a range of experimental results using this and other models. Complete source code is available.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {256–294},
numpages = {39},
keywords = {text compression, arithmetic coding, word-based model, approximate coding}
}

@article{10.1145/290159.290161,
author = {Crestani, F. and van Rijsbergen, C. J.},
title = {A Study of Probability Kinematics in Information Retrieval},
year = {1998},
issue_date = {July 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/290159.290161},
doi = {10.1145/290159.290161},
abstract = {We analyze the kinematics of probabilistic term weights at retrieval time for different Information Retrieval models. We present four models based on different notions of probabilistic retrieval. Two of these models are based on classical probability theory and can be considered as prototypes of models long in use in Information Retrieval, like the Vector Space Model and the Probabilistic Model. The two other models are based on a logical technique of evaluating the probability of a conditional called imaging; one is a generalization of the other. We analyze the transfer of probabilities occurring in the term space at retrieval time for these four models, compare their retrieval performance using classical test collections, and discuss the results. We believe that our results provide  useful suggestions on how to improve existing probabilistic models of Information Retrieval by taking into consideration term-term similarity.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {225–255},
numpages = {31},
keywords = {probabilistic retrieval, logical imaging, probabilistic modeling}
}

@article{10.1145/290159.290160,
author = {Ackerman, Mark S.},
title = {Augmenting Organizational Memory: A Field Study of Answer Garden},
year = {1998},
issue_date = {July 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/290159.290160},
doi = {10.1145/290159.290160},
abstract = {A growing concern for organizations and groups has been to augment their knowledge and expertise. One such augmentation is to provide an organizational memory, some record of the organization's knowledge. However, relatively little is known about how computer systems might enhance organizational, group, or community memory. This article presents Answer Garden, a system for growing organizational memory. The article describes the system and its underlying implementation. It then presents findings from a field study of Answer Garden. The article discusses the usage data and qualitative evaluations from the field study, and then draws a set of lessons for next-generation organizational memory systems.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {203–224},
numpages = {22},
keywords = {group memory, organizational memory, CSCW, collective memory, computer-supported cooperative work, community memory, field studies}
}

@article{10.1145/279339.279342,
author = {Belussi, Alberto and Faloutsos, Christos},
title = {Self-Spacial Join Selectivity Estimation Using Fractal Concepts},
year = {1998},
issue_date = {April 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/279339.279342},
doi = {10.1145/279339.279342},
abstract = {The problem of selectivity estimation for queries of nontraditional databases is still an open issue. In this article, we examine the problem of selectivity estimation for some types of spatial queries in databases containing real data. We have shown earlier [Faloutsos and Kamel 1994] that real point sets typically have a nonuniform distribution, violating consistently the uniformity and independence assumptions. Moreover, we demonstrated that the theory of fractals can help to describe real point sets. In this article we show how the concept of fractal dimension, i.e., (noninteger) dimension, can lead to the solution for the selectivity estimation problem in spatial databases. Among the infinite family of fractal dimensions, we consider here the  Hausdorff fractal dimension D0 and the “Correlation” fractal dimension D2. Specifically, we show that (a) the average number of neighbors for a given point set follows a power law, with D2 as exponent, and (b) the average number of nonempty range queries follows a power law with E − D0 as exponent (E is the dimension of the embedding space). We present the formulas to estimate the selectivity for “biased” range queries, for self-spatial joins, and for the average number of nonempty range queries. The result of some experiments on real and synthetic point sets are shown. Our formulas achieve very low  relative errors, typically about 10%, versus 40%–100% of the formulas that are based on the uniformity and independence assumptions.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {161–201},
numpages = {41},
keywords = {spatial join, range query, selectivity estimation, fractal dimension}
}

@article{10.1145/279339.279341,
author = {Hicks, David L. and Leggett, John J. and N\"{u}rnberg, Peter J. and Schnase, John L.},
title = {A Hypermedia Version Control Framework},
year = {1998},
issue_date = {April 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/279339.279341},
doi = {10.1145/279339.279341},
abstract = {The areas of application of hypermedia technology, combined with the capabilities that hypermedia provides for manipulating structure, create an environment in which version control is very important. A hypermedia version control framework has been designed to specifically address the version control problem in open hypermedia environments. One of the primary distinctions of the framework is the partitioning of hypermedia version control functionality into intrinsic and application-specific categories. The version control has been used as a model for the design of version control services for a hyperbase management system that provides complete version support for both data and structural entities. In addition to serving as a version control  model for open hypermedia environments, the framework offers a clarifying and unifying context in which to examine the issues of version control in hypermedia.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {127–160},
numpages = {34},
keywords = {hypermedia, hyperbase management system}
}

@article{10.1145/279339.279340,
author = {Wilber, W. John},
title = {The Knowledge in Multiple Human Relevance Judgments},
year = {1998},
issue_date = {April 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/279339.279340},
doi = {10.1145/279339.279340},
abstract = {We show first that the pooling of multiple human judgments of relevance provides predictor of relevance that is superior to that obtained from a single human's relevance judgemts. A learning algorithm applied to a set of relevance judgments obtained from a single human would be expected to perform on new material at a level somewhat below that human. However, we examine two learning methods which when trained on the superior source of pooled human relevance judgments are able to perform at the level of a single human on new material. All performance comparisons are based on an independent human judge. Both algorithms function by producing term weights—one by a log odds calculation and the other by producing a least-squares fit to human relevance ratings. Some characteristics of  the algorithms are examined.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {101–126},
numpages = {26},
keywords = {vector model, minimal-length least-square fit, human relevance judgments, document retrieval test set construction, log odds of relevance, inverse document frequency weights, word weights}
}

@article{10.1145/267954.267958,
author = {Romm, Celia T. and Pliskin, Nava},
title = {Electronic Mail as a Coalition-Building Information Technology},
year = {1998},
issue_date = {Jan. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/267954.267958},
doi = {10.1145/267954.267958},
abstract = {One of the most intriguing lines of research within the literature on diffusion of information technologies (IT) is the study of the power and politics of this process. The major objective of this article is to build on the work of Kling and Markus on power and IT, by extending their perspective to email. To demonstrate how email can be used for political purposes within an organizational context, a case study is presented. The case study describes a series of events which took place in a university. In the case, email was used by a group of employees to stage a rebellion against the university president. The discussion demonstrates that email features make it amenable to a range of political uses. The article is concluded with a discussion of the implications from this case to email research and practice.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {82–100},
numpages = {19},
keywords = {abuse, politics, MIS, email, coalition building}
}

@article{10.1145/267954.267957,
author = {Xu, Jinxi and Croft, W. Bruce},
title = {Corpus-Based Stemming Using Cooccurrence of Word Variants},
year = {1998},
issue_date = {Jan. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/267954.267957},
doi = {10.1145/267954.267957},
abstract = {Stemming is used in many information retrieval (IR) systems to reduce variant word forms to common roots. It is one of the simplest applications of natural-language processing to IR and is one of the most effective in terms of user acceptance and consistency, though small retrieval improvements. Current stemming techniques do not, however, reflect the language use in specific corpora, and this can lead to occasional serious retrieval failures. We propose a technique for using corpus-based word variant cooccurrence statistics to modify or create a stemmer. The experimental results generated using English newspaper and legal text and Spanish text demonstrate the viability of this technique and its advantages relative to conventional approaches that only employ morphological rules.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {61–81},
numpages = {21},
keywords = {class refinement, n-gram, information retrieval, corpus analysis, cooccurence, stemming}
}

@article{10.1145/267954.267956,
author = {Vujovic, N. and Brzakovic, D.},
title = {Evaluation of an Algorithm for Finding a Match of a Distorted Texture Pattern in a Large Image Database},
year = {1998},
issue_date = {Jan. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/267954.267956},
doi = {10.1145/267954.267956},
abstract = {Evaluation of an algorithm for finding a match for a random texture pattern in a large image database is presented. The algorithm was designed assuming that the random pattern may be subject to misregistration relative to its representation in the database and assuming that it may have missing parts. The potential applications involve authentication of legal documents, bank notes, or credit cards, where thin fibers are embedded randomly into the document medium during medium fabrication. The algorithm achieves image matching by a three-step hierarchical procedure, which starts by matching parts of fiber patterns while solving the misregistration problem and ends up by matching complete fiber patterns. Performance of the algorithm is studied both theoretically and experimentally. Theoretical analysis includes the study of the probability that two documents have the same pattern, and the probability of the algorithm establishing a wrong match, as well as the algorithm's performance in terms of processing  time. Experiments involving over 250,000 trials using databases of synthetic documents, containing up to 100,000 documents, were used to confirm theoretical predictions. In addition, experiments involving a database containing real images were conducted in order to confirm that the algorithm has potential in real applications.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {31–60},
numpages = {30},
keywords = {random pattern, image database, presentation of information, image matching, misregistration}
}

@article{10.1145/267954.267955,
author = {Stotts, P. David and Furuta, Richard and Cabarrus, Cyrano Ruiz},
title = {Hyperdocuments as Automata: Verification of Trace-Based Browsing Properties by Model Checking},
year = {1998},
issue_date = {Jan. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/267954.267955},
doi = {10.1145/267954.267955},
abstract = {We present a view of hyperdocuments in which each document encodes its own browsing semantics in its links. This requires a mental shift in how a hyperdocument is thought of abstractly. Instead of treating the links of a document as defining a static directed graph, they are thought of as defining an abstract program, termed the links-automaton of the document. A branching temporal logic notation, termed HTL*, is introduced for specifying properties a document should exhibit during browsing. An automated program verification technique called model checking is used to verify that browsing specifications in a subset of HTL* are met by the behavior defined in the links-automation. We illustrate the generality of these techniques by applying them first to several Trellis documents and then to a Hyperties document.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–30},
numpages = {30},
keywords = {Petri nets, browsing semantics, model checking, temporal logic, hypermedia, hypertext}
}

@article{10.1145/263479.263482,
author = {Navarro, Gonzalo and Baeza-Yates, Ricardo},
title = {Proximal Nodes: A Model to Query Document Databases by Content and Structure},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/263479.263482},
doi = {10.1145/263479.263482},
abstract = {A model to query document databases by both their content and structure is presented. The goal is to obtain a query language that is expressive in practice while being efficiently implementable, features not present at the same time in previous work. The key ideas of the model are a set-oriented query language based on operations on nearby structure elements of one or more hierarchies, together with content and structural indexing and bottom-up evaluation. The model is evaluated in regard to expressiveness and efficiency, showing that it provides a good trade-off between both goals. Finally, it is shown how to include in the model other media different from text.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {400–435},
numpages = {36},
keywords = {structured text, hierarchical documents, text algebras, expressivity and efficiency of query languages}
}

@article{10.1145/263479.263481,
author = {Mostafa, J. and Mukhopadhyay, S. and Palakal, M. and Lam, W.},
title = {A Multilevel Approach to Intelligent Information Filtering: Model, System, and Evaluation},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/263479.263481},
doi = {10.1145/263479.263481},
abstract = {In information-filtering environments, uncertainties associated with changing interests of the user and the dynamic document stream must be handled efficiently. In this article, a filtering model is proposed that decomposes the overall task into subsystem functionalities and highlights the need for multiple adaptation techniques to cope with uncertainties. A filtering system, SIFTER, has been implemented based on the model, using established techniques in information retrieval and artificial intelligence. These techniques include document representation by a vector-space model, document classification by unsupervised learning, and user modeling by reinforcement learning. The system can filter information based on content and a user's specific interests. The user's interests are automatically learned with only limited user intervention in the form of optional relevance feedback for documents. We also describe experimental studies conducted with SIFTER to filter computer and information science documents collected from the Internet and commercial database services. The experimental results demonstrate that the system performs very well in filtering documents in a realistic problem setting.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {368–399},
numpages = {32},
keywords = {information filtering, user modeling, automated document representation}
}

@article{10.1145/263479.263480,
author = {Kimbrough, Steven O. and Moore, Scott A.},
title = {On Automated Message Processing in Electronic Commerce and Work Support Systems: Speech Act Theory and Expressive Felicity},
year = {1997},
issue_date = {Oct. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/263479.263480},
doi = {10.1145/263479.263480},
abstract = {Electronic messaging, whether in an office environment or for electronic commerce, is normally carried out in natural language, even when supported by information systems. For a variety of reasons, it would be useful if electronic messaging systems could have semantic access to, that is, access to the meanings and contents of, the messages they process. Given that natural language understanding is not a practicable alternative, there remain three approaches to delivering systems with semantic access: electronic data interchange (EDI), tagged messages, and the development of a formal language for business communication (FLBC). We favor the latter approach. In this article we compare and contrast these three approaches, present a theoretical basis for an FLBC (using speech act theory), and describe a prototype implementation.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {321–367},
numpages = {47},
keywords = {formal language for business communication, electronic commerce, speech act theory}
}

@article{10.1145/256163.256168,
author = {Cohen, Jonathan D.},
title = {Recursive Hashing Functions for <i>n</i>-Grams},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/256163.256168},
doi = {10.1145/256163.256168},
abstract = {Many indexing, retrieval, and comparison methods are based on counting or cataloguing n-grams in streams of symbols. The fastest method of implementing such operations is through the use of hash tables. Rapid hashing of consecutive n-grams is best done using a recursive hash function, in which the hash value of the current n-gram is drived from the hash value of its predecessor. This article generalizes recursive hash functions found in the literature and proposes new methods offering superior performance. Experimental results demonstrate substantial speed improvement over conventional approaches, while retaining near-ideal hash value distribution.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {291–320},
numpages = {30},
keywords = {hashing, recursive hashing, n-grams, hashing functions}
}

@article{10.1145/256163.256166,
author = {Bookstein, A. and Klein, S. T. and Raita, T.},
title = {Modeling Word Occurrences for the Compression of Concordances},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/256163.256166},
doi = {10.1145/256163.256166},
abstract = {An earlier paper developed a procedure for compressing concordances, assuming that all alements occurred independently. The models introduced in that paper are extended here to take the possiblity of clustering into account. The concordance is conceptualized as a set of bitmaps, in which the bit locations reporesent documents, and the one-bits represent the occurrence of given terms. Hidden Markov Models (HMM's) are used to describe the clustering of the one-bits. However, for computational reasons, the HMM is approximated by traditional Markov models. A set of criteria is developed to constrain the allowable set of n-state models, and a full inventory is given for n ≤ 4. Graph-theoretic reduction and complementation  operations are defined among the various models and are used to provide a structure relating the models studied. Finally, the new methods were tested on the concordances of the English Bible and of two of the world's largest full-text retrieval systems: the Tre´sor de la Langue Franc¸aise and the Responsa Project.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {254–290},
numpages = {37},
keywords = {concordance storage, concordance organization, graph structure, classification of graph nodes}
}

@article{10.1145/256163.256165,
author = {Tomasic, Anthony and Gravano, Luis and Lue, Calvin and Schwarz, Peter and Haas, Laura},
title = {Data Structures for Efficient Broker Implementation},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/256163.256165},
doi = {10.1145/256163.256165},
abstract = {With the profusion of text databases on the Internet, it is becoming increasingly hard to find the most useful databases for a given query. To attack this problem, several existing and proposed systems employ brokers to direct user queries, using a local database of summary information about the available databases. This summary information must effectively distinguish relevant databases and must be compact while allowing efficient access. We offer evidence that one broker, GlOSS, can be effective at locating databases of interest even in a system of hundreds of databased and can examine the performance of accessing the
GlOSS summeries for two promising storage methods: the grid file and partitioned hashing. We show that both methods can be tuned to provide good performance for a  particular workload (within a broad range of workloads), and we discuss the tradeoffs between the two data structures. As a side effect of our work, we show that grid files are more broadly applicable than previously thought; inparticular, we show that by varying the policies used to construct the grid file we can provide good performance for a wide range of workloads even when storing highly skewed data.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {223–253},
numpages = {31},
keywords = {grid files, broker performance, partitioned hashing, distributed information, GlOSS, broker architecture}
}

@article{10.1145/256163.256164,
author = {Dreilinger, Daniel and Howe, Adele E.},
title = {Experiences with Selecting Search Engines Using Metasearch},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/256163.256164},
doi = {10.1145/256163.256164},
abstract = {Search engines are among the most useful and high-profile resources on the Internet. The problem of finding information on the Internet has been replaced with the problem of knowing where search engines are, what they are designed to retrieve, and how to use them. This article describes and evaluates SavvySearch, a metasearch engine designed to intelligently select and interface with multiple remote search engines. The primary metasearch issue examined is the importance of carefully selecting and ranking remote search engines for user queries. We studied the efficacy of SavvySearch's incrementally acquired metaindex approach to selecting search engines by analyzing the effect of time and experience on performance. We also compared the metaindex approach to the 
 simpler categorical approach and showed how much experience is required to surpass the simple scheme.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {195–222},
numpages = {28},
keywords = {machine learning, WWW, search engine, information retrieval}
}

@article{10.1145/248625.248652,
author = {Gladney, H. M.},
title = {Access Control for Large Collections},
year = {1997},
issue_date = {April 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/248625.248652},
doi = {10.1145/248625.248652},
abstract = {Efforts to place vast information resources at the fingertips of each individual in large user populations must be balanced by commensurate attention to information protection. For distributed systems with less-structured tasks, more-diversified information, and a heterogeneous user set, the computing system must administer enterprise-chosen access control policies. One kind of resource is a digital library that emulates massive collections of paper and other physical media for clerical, engineering, and cultural applications. This article considers the security requirements for such libraries and proposes an access control method that mimics organizational practice by combining a subject tree with ad hoc role granting that controls privileges for many operations independently, that  treats (all but one) privileged roles (e.g., auditor, security officer) like every other individual authorization, and that binds access control information to objects indirectly for scaling, flexibility, and reflexive protection. We sketch a realization and show that it will perform well, generalizes many deployed proposed access control policies, and permits individual data centers to implement other models economically and without disruption.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {154–194},
numpages = {41},
keywords = {digital library, information security, electronic library, document, access control}
}

@article{10.1145/248625.248650,
author = {Dunlop, Mark D.},
title = {The Effect of Accessing Nonmatching Documents on Relevance Feedback},
year = {1997},
issue_date = {April 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/248625.248650},
doi = {10.1145/248625.248650},
abstract = {Traditional information retrieval (IR) systems only allow users access to documents that match their current query, and therefore, users can only give relevance feedback on matching documents (or those with a matching strength greater than a set threshold. This article shows that, in systems that allow access to nonmatching documents (e.g., hybrid hypertext and information retrieval systems), the strength of the effect of giving relevance feedback varies between matching and nonmatching documents. For positive feedback the results shown here are encouraging, as they can be justified by an intuitive view of the process. However, for negative feedback the results show behavior that cannot easily be justified and that varies greatly depending on the model of feedback used.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {137–153},
numpages = {17},
keywords = {negative feedback, relevance feedback, hypertext, probabilistic model, vector space model, free-text information retrieval}
}

@article{10.1145/248625.248639,
author = {Manber, Udi},
title = {A Text Compression Scheme That Allows Fast Searching Directly in the Compressed File},
year = {1997},
issue_date = {April 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/248625.248639},
doi = {10.1145/248625.248639},
abstract = {A new text compression scheme is presented in this article. The main purpose of this scheme is to speed up string matching by searching the compressed file directly. The scheme requires no modification of the string-matching algorithm, which is used as a black box; any string-matching procedure can be used. Instead, the pattern is modified; only the outcome of the matching of the modified pattern against the compressed file is decompressed. Since the compressed file is smaller than the original file, the search is faster both in terms of I/O time and precessing time than a search in the original file. For typical text files, we achieve about 30% reduction of space and slightly less of search time. A 30% space saving is not competitive with good text compression schemes, and thus should not be used where space is the predominant concern. The intended applications  of this scheme are files that are searched often, such as catalogs, bibliographic files, and address books. Such files are typically not compressed, but with this scheme they can remain compressed indefinitely, saving space while allowing faster search at the same time. A particular application to an information retrieval system that we developed is also discussed.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {124–136},
numpages = {13},
keywords = {data compression search}
}

@article{10.1145/248625.248627,
author = {Entlich, Richard and Olsen, Jan and Garson, Lorrin and Lesk, Michael and Normore, Lorraine and Weibel, Stuart},
title = {Making a Digital Library: The Contents of the CORE Project},
year = {1997},
issue_date = {April 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/248625.248627},
doi = {10.1145/248625.248627},
abstract = {The CORE (Chemical Online Retrieval Experiment) project is a library of primary journal articles in chemistry. Any library has an inside and an outside; in this article we describe the inside of the library and the methods for building the system and accumulating the database. A later article will describe the outside (user experiences). Among electronic-library projects, the CORE project is unusual in that it has both ASCII derived from typesetting and image data for all its pages, and among experimental electronic-library projects, it is unusually large. We describe here (a) the processes of scanning and analyzing about 400,000 pages of primary journal material, (b) the conversion of a similar amount of textual database material, (c) the linking of these two data sources, and (d)  the indexing of the text material.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {103–123},
numpages = {21},
keywords = {image segmentation}
}

@article{10.1145/239041.239048,
author = {Rus, Daniela and Subramanian, Devika},
title = {Customizing Information Capture and Access},
year = {1997},
issue_date = {Jan. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/239041.239048},
doi = {10.1145/239041.239048},
abstract = {This article presents a customizable architecture for software agents that capture and access information in large, heterogeneous, distributed electronic repositories. The key idea is to exploit underlying structure at various levels of granularity to build high-level indices with task-specific interpretations. Information agents construct such indices and are configured as a network of reusable modules called structure detectors and segmenters. We illustrate our architecture with the design and implementation of smart information filters in two contexts: retrieving stock market data from Internet newsgroups and retrieving technical reports from Internet FTP sites.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {67–101},
numpages = {35},
keywords = {software agents, table recognition, information gathering}
}

@article{10.1145/239041.239045,
author = {Fuhr, Norbert and R\"{o}lleke, Thomas},
title = {A Probabilistic Relational Algebra for the Integration of Information Retrieval and Database Systems},
year = {1997},
issue_date = {Jan. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/239041.239045},
doi = {10.1145/239041.239045},
abstract = {We present a probabilistic relational algebra (PRA) which is a generalization of standard relational algebra. In PRA, tuples are assigned probabilistic weights giving the probability that a tuple belongs to a relation. Based on intensional semantics, the tuple weights of the result of a PRA expression always conform to the underlying probabilistic model. We also show for which expressions extensional semantics yields the same results. Furthermore, we discuss complexity issues and indicate possibilities for optimization. With regard to databases, the approach allows for representing imprecise attribute values, whereas for information retrieval, probabilistic document indexing and probabilistic search term weighting can be modeled. We introduce the concept of vague predicates which  yield probabilistic weights instead of Boolean values, thus allowing for queries with vague selection conditions. With these features, PRA implements uncertainty and vagueness in combination with the relational model.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {32–66},
numpages = {35},
keywords = {logical retrieval model, relational data model, uncortain data, vague predicates, probabilistic retrieval, hypertext retrieval, imprecise data}
}

@article{10.1145/239041.239043,
author = {Wiil, Uffe K. and Leggett, John J.},
title = {Hyperform: A Hypermedia System Development Environment},
year = {1997},
issue_date = {Jan. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/239041.239043},
doi = {10.1145/239041.239043},
abstract = {Development of hypermedia systems is a complex matter. The current trend toward open, extensible, and distributed multiuser hypermedia systems adds additional complexity to the development process. As a means of reducing this complexity, there has been an increasing interest in hyperbase management systems that allow hypermedia system developers to abstract from the intricacies and complexity of the hyperbase layer and fully attend to application and user interface issues. Design, development, and deployment experiences of a dynamic, open, and distributed multiuser hypermedia system development environment called Hyperform is presented. Hyperform is based on the concepts of extensibility, tailorability, and rapid prototyping of hypermedia system services. Open, extensible hyperbase management systems permit hypermedia system developers to tailor hypermedia functionality for specific applications and to serve as a platform for research. The Hyperform development environment is comprised of multiple instances of four component types: (1) a hyperbase management system server, (2) a tool integrator, (3) editors, and (4) participating tools. Hyperform has been deployed in Unix environments, and experiments have shown that Hyperform greatly reduces the effort required to provide customized hyperbase management system support for distributed multiuser hypermedia systems.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–31},
numpages = {31},
keywords = {advanced hypermedia system architecture, object-oriented extension language, extensible hyperbase management system}
}

@article{10.1145/237496.237500,
author = {Author Index},
title = {Author Index},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/237496.237500},
doi = {10.1145/237496.237500},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {471–472},
numpages = {2}
}

@article{10.1145/237496.237499,
author = {Cheung, Waiman and Hsu, Cheng},
title = {The Model-Assisted Global Query System for Multiple Databases in Distributed Enterprises},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/237496.237499},
doi = {10.1145/237496.237499},
abstract = {Today's enterprises typically employ multiple information systems, which are independently developed, locally administered, and different in logical or physical designs. Therefore, a fundamental challenge in enterprise information management is the sharing of information for enterprise users across organizational boundaries; this requires a global query system capable of providing on-line intelligent assistance to users. Conventional technologies, such as schema-based query languages and hard-coded schema integration, are not sufficient to solve this problem. This article develops a new approach, a “model-assisted global query system,” that utilizes an on-line repository of enterprise metadata—the Metadatabase—to facilitate global query formulation and processing with  certain desirable properties such as adaptiveness and open-systems architecture. A definitional model characterizing the various classes and roles of the required metadata as knowledge for the system is presented. The significance of possessing this knowledge (via a Metadatabase) toward improving the global query capabilities available previously is analyzed. On this basis, a direct method using model traversal and a query language using global model constructs are developed along with other new methods required for this approach. It is then tested through a prototype system in a computer-integrated manufacturing (CIM) setting.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {421–470},
numpages = {50}
}

@article{10.1145/237496.237498,
author = {Oberweis, Andreas and Sander, Peter},
title = {Information System Behavior Specification by High Level Petri Nets},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/237496.237498},
doi = {10.1145/237496.237498},
abstract = {The specification of an information system should include a description of structural system aspects as well as a description of the system behavior. In this article, we show how this can be achieved by high-level Petri nets—namely, the so-called NR/T-nets (Nested-Relation/Transition Nets). In NR/T-nets, the structural part is modeled by nested relations, and the behavioral part is modeled by a novel Petri net formalism. Each place of a net represents a nested relation scheme, and the marking of each place is given as a nested relation of the respective type. Insert and delete operations in a nested relational database (NF2-database) are expressed by transitions in a net. These operations may operate not only on whole tuples of a given relation, but also on “subtuples”  of existing tuples. The arcs of a net are inscribed with so-called Filter Tables, which allow (together with an optional logical expression as transition inscription) conditions to be formulated on the specified (sub-) tuples. The occurrence rule for NR/T-net transitions is defined by the operations union, intersection, and “negative” in lattices of nested relations. The structure of an NR/T-net, together with the occurrence rule, defines classes of possible information system procedures, i.e., sequences of (possibly concurrent) operations in an information system.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {380–420},
numpages = {41}
}

@article{10.1145/237496.237497,
author = {Moffat, Alistair and Zobel, Justin},
title = {Self-Indexing Inverted Files for Fast Text Retrieval},
year = {1996},
issue_date = {Oct. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/237496.237497},
doi = {10.1145/237496.237497},
abstract = {Query-processing costs on large text databases are dominated by the need to retrieve and scan the inverted list of each query term. Retrieval time for inverted lists can be greatly reduced by the use of compression, but this adds to the CPU time required. Here we show that the CPU component of query response time for conjunctive Boolean queries and for informal ranked queries can be similarly reduced, at little cost in terms of storage, by the inclusion of an internal index in each compressed inverted list. This method has been applied in a retrieval system for a collection of nearly two million short documents. Our experimental results show that the self-indexing strategy adds less than 20% to the size of the compressed inverted file, which itself occupies less than 10% of the  indexed text, yet can reduce processing time for Boolean queries of 5-10 terms to under one fifth of the previous cost. Similarly, ranked queries of 40-50 terms can be evaluated in as little as 25% of the previous time, with little or no loss of retrieval effectiveness.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {349–379},
numpages = {31}
}

@article{10.1145/230538.230561,
author = {Friedman, Batya and Nissenbaum, Helen},
title = {Bias in Computer Systems},
year = {1996},
issue_date = {July 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/230538.230561},
doi = {10.1145/230538.230561},
abstract = {From an analysis of actual cases, three categories of bias in computer systems have been developed: preexisting, technical, and emergent. Preexisting bias has its roots in social institutions, practices, and attitudes. Technical bias arises from technical constraints of considerations. Emergent bias arises in a context of use. Although others have pointed to bias inparticular computer systems and have noted the general problem, we know of no comparable work that examines this phenomenon comprehensively and which offers a framework for understanding and remedying it. We conclude by suggesting that freedom from bias should by counted amoung the select set of criteria—including reliability, accuracy, and efficiency—according to which the quality of systems in use in society should be judged.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {330–347},
numpages = {18},
keywords = {system design, computers and society, ethics, social impact, values, computer ethics, standards, social computing, universal design, bias, design methods, human values}
}

@article{10.1145/230538.230560,
author = {Gulla, Jon Atle},
title = {A General Explanation Component for Conceptual Modeling in CASE Environments},
year = {1996},
issue_date = {July 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/230538.230560},
doi = {10.1145/230538.230560},
abstract = {In information systems engineering, conceptual models are constructed to assess existing information systems and work out requirements for new ones. As these models serve as a means for communication between customers and developers, it is paramount that both parties understand the models, as well as that the models form a proper basis for the subsequent design and implementation of the systems. New CASE environments are now experimenting with formal modeling languages and various techniques for validating conceptual models, though it seems difficult to come up with a technique that handles the linguistic barriers between the parties involved in a satisfactory manner. In this article, we discuss the theoretical basis of an explanation component implemented for the PPP CASE environment. This component integrates other validation techniques and provides a very flexible natural-language interface to complex model information. It describes properties of the modeling language and the conceptual models in terms familiar to users, and the explanations can be combined with graphical model views. When models are executed, it can justify requested inputs and explain computed outputs by relating trace information to properties of the models.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {297–329},
numpages = {33},
keywords = {paraphrasing, explanation generation, conceptual modeling, linguistics, requirements engineering, help systems}
}

@article{10.1145/230538.230540,
author = {Gottlob, Georg and Schrefl, Michael and R\"{o}ck, Brigitte},
title = {Extending Object-Oriented Systems with Roles},
year = {1996},
issue_date = {July 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/230538.230540},
doi = {10.1145/230538.230540},
abstract = {In many class-based object-oriented systems the association between as instance and a class is exclusive and permanent. Therefore these systems have serious difficulties in representing objects taking on different roles over time. Such objects must be reclassified any time they evolve (e.g., if a person becomes a student and later an employee). Class hierarchies must be planned carefully and may grow exponentially if entities may take on serveral independent roles. The problem is even more servere for object-oriented databases than for common object-oriented programming. Databases store objects over longer periods, during which the represented entities evolve. This article shows how class-based object-oriented systems can be extended to handle evolving objects well. Class hierarchies are complemented by role hierarchies, whose nodes represent role types an object classified in the root may take on. At any point in time, an entity is represented by an instance of the root and an instance of every role type whose role it currently plays. In a natural way, the approach extends traditional object-oriented concepts, such as classification, object identity, specialization, inheritance, and polymorphism in a natural way. The practicability of the approach is demonstrated by an implementation in Smalltalk. Smalltalk was chosen because it is widely known, which is not true for any particular class-based object-oriented database programming language. Roles can be provided in Smalltalk by adding a few classes. There is no need to modify the semantics of Smalltalk itself. Role hierarchies are mapped transparently onto ordinary classes. The presented implementation can easily be ported to object-oriented database programming languages based on Smalltalk, such as Gemstone's OPAL hierarchies are complemented by role hierarchies, whose nodes represent role types an object classified in the root may take on. At any point in time, an entity is represented by an instance of the root and an instance of every role type whose role in currently plays.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {268–296},
numpages = {29}
}

@article{10.1145/230538.230539,
author = {Guglielmo, Eugene J. and Rowe, Neil C.},
title = {Natural-Language Retrieval of Images Based on Descriptive Captions},
year = {1996},
issue_date = {July 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/230538.230539},
doi = {10.1145/230538.230539},
abstract = {We describe a prototype intelligent information retrieval system that uses natural-language understanding to efficiently locate captioned data. Multimedia data generally require captions to explain their features and significance. Such descriptive captions often rely on long nominal compounds (strings of consecutive nouns) which create problems of disambiguating word sence. In our system, captions and user queries are parsed and interpreted to produce a logical form using a detailed theory of the meaning of nominal compounds. A fine-grain match can then compare the logical form of the query to the logical forms for each caption. To improve system efficiency, we first perform a coarse-grain match with index files, using nouns and verbs extracted from the query. Our experiments with randomly selected queries and captions from an existing image library show an increase of 30% in precision and 50% in recall over the keyphrase approach currently used. Our processing times have a median of seven seconds as compared to eight minutes for the existing system, and our system is much easier to use.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {237–267},
numpages = {31},
keywords = {type hierarchy, captions, multimedia database}
}

@article{10.1145/226163.226167,
author = {Grant, Rebecca A. and Higgins, Chris A.},
title = {Computerized Performance Monitors as Multidimensional Systems: Derivation and Application},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/226163.226167},
doi = {10.1145/226163.226167},
abstract = {An increasing number of companies are introducing computer technology into more aspects of work. Effective use of information systems to support office and service work can improve staff productivity, broaden a company's market, or dramatically change its business. It can also increase the extent to which work is computer mediated and thus within the reach of software known as Computerized Performance Monitoring and Control Systems (CPMCSs). Virtually all research has studied CPMCSs as unidimensional systems. Employees are described as “monitored” or “unmonitored” or as subject to “high,” “moderate,” or “low” levels of monitoring. Research that does not clearly distinguish among possible monitor design cannot explain how  designs may differ in effect. Nor can it suggest how to design better monitors. A multidimensional view of CPMCSs describes monitor designs in terms of object of measurements, tasks measured, recipient of data, reporting period, and message content. This view is derived from literature in control systems, organizational behavior, and management information systems. The multidimensional view can then be incorporated into causal models to explain contradictory results of earlier CPMCS research.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {212–235},
numpages = {24},
keywords = {computerized performance evaluation, work monitoring system design, computerized work monitoring}
}

@article{10.1145/226163.226166,
author = {Jungclaus, Ralf and Saake, Gunter and Hartmann, Thorsten and Sernadas, Cristina},
title = {TROLL: A Language for Object-Oriented Specification of Information Systems},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/226163.226166},
doi = {10.1145/226163.226166},
abstract = {TROLL is a language particularly suited for the early stages of information system development, when the universe of discourse must be described. In TROLL the descriptions of the static and dynamic aspects of entities are integrated into object descriptions. Sublanguages for data terms, for first-order and temporal assertions, and for processes, are used to describe respectively the static properties, the behavior, and the evolution over time of objects. TROLL organizes system design through object-orientation and the support of abstractions such as classification, specialization, roles, and aggregation. Language features for state interactions and dependencies among components support the composition of the system from smaller modules, as does the facility of defining interfaces on top of object descriptions.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {175–211},
numpages = {37}
}

@article{10.1145/226163.226165,
author = {Rowe, Neil C.},
title = {Using Local Optimality Criteria for Efficient Information Retrieval with Redundant Information Filters},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/226163.226165},
doi = {10.1145/226163.226165},
abstract = {We consider information retrieval when the data—for instance, multimedia—is computationally expensive to fetch. Our approach uses “information filters” to considerably narrow the universe of possibilities before retrieval. We are especially interested in redundant information filters that save time over more general but more costly filters. Efficient retrieval requires that decisions must be made about the necessity, order, and concurrent processing of proposed filters (an “execution plan”). We develop simple polynomial-time local criteria for optimal execution plans and show that most forms of concurrency are suboptimal with information filters. Although the general problem of finding an optimal execution plan is likely to be exponential in the number of filters, we show experimentally that our local optimality criteria, used in a polynomial-time algorithm, nearly always find the global optimum with 15 filters or less, a sufficient number of filters for most applications. Our methods require no special hardware and avoid the high processor idleness that is characteristic of massive-parallelism solutions to this problem. We apply our ideas to an important application, information retrieval of captioned data using natural-language understanding, a problem for which the natural-language processing can be the bottleneck if not implemented well.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {138–174},
numpages = {37},
keywords = {conjunction, Boolean algebra, queries, filters, natural language, optimization}
}

@article{10.1145/226163.226164,
author = {Lee, Dik Kun and Ren, Liming},
title = {Document Ranking on Weight-Partitioned Signature Files},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/226163.226164},
doi = {10.1145/226163.226164},
abstract = {A signature file organization, called the weight-partitioned signature file, for supporting document ranking is proposed. It employs multiple signature files, each of which corresponds to one term frequency, to represent terms with different term frequencies. Words with the same term frequency in a document are grouped together and hashed into the signature file corresponding to that term frequency. This eliminates the need to record the term frequency explicitly for each word. We investigate the effect of false drops on retrieval effectiveness if they are not eliminated in the search process. We have shown that false drops introduce insignificant degradation on precision and recall when the false-drop probability is below a certain threshold. This is an important result since  false-drop elimination could become the bottleneck in systems using fast signature file search techniques. We perform an analytical study on the performance of the weight-partitioned signature file under different search strategies and configurations. An optimal formula is obtained to determine for a fixed total storage overhead the storage to be allocated to each partition in order to minimize the effect of false drops on document ranks. Experiments were performed using a document collection to support the analytical results.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {109–137},
numpages = {29},
keywords = {document retrieval, superimposed coding, signature file, access method, text retrieval, information retrieval}
}

@article{10.1145/214174.214183,
author = {Berghel, Hal and Roach, David},
title = {An Extension of Ukkonen's Enhanced Dynamic Programming ASM Algorithm},
year = {1996},
issue_date = {Jan. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/214174.214183},
doi = {10.1145/214174.214183},
abstract = {We describe an improvement on Ukkonen's Enhanced Dynamic Programming (EHD) approximate string-matching algorithm for unit-penalty four-edit comparisons. The new algorithm has an asymptotic complexity similar to that of Ukkonen's but is significantly faster due to a decrease in the number of array cell calculations. A 42% speedup was achieved in an application involving name comparisons. Even greater improvements are possible when comparing longer and more dissimilar strings. Although the speed of the algorithm under consideration is comparable to other fast ASM algorithms, it has greater effectiveness in text-processing applications because it supports all four basic Damerau-type editing operations.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {94–106},
numpages = {13},
keywords = {enhanced dynamic programming, approximate string matching, similarity relations, dynamic programming}
}

@article{10.1145/214174.214180,
author = {Taghva, Kazem and Borsack, Julie and Condit, Allen},
title = {Evaluation of Model-Based Retrieval Effectiveness with OCR Text},
year = {1996},
issue_date = {Jan. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/214174.214180},
doi = {10.1145/214174.214180},
abstract = {We give a comprehensive report on our experiments with retrieval from OCR-generated text using systems based on standard models of retrieval. More specifically, we show that average precision and recall is not affected by OCR errors across systems for several collections. The collections used in these experiments include both actual OCR-generated text and standard information retrieval collections corrupted through the simulation of OCR errors. Both the actual and simulation experiments include full-text and abstract-length documents. We also demonstrate that the ranking and feedback methods associated with these models are generally not robust enough to deal with OCR errors. It is further shown that the OCR errors and garbage strings generated from the mistranslation of graphic  objects increase the size of the index by a wide margin. We not only point out problems that can arise from applying OCR text within an information retrieval environment, we also suggest solutions to overcome some of these problems.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {64–93},
numpages = {30},
keywords = {error correction, optical character recognition, feedback, ranking algorithms}
}

@article{10.1145/214174.214178,
author = {Robey, Daniel and Newman, Michael},
title = {Sequential Patterns in Information Systems Development: An Application of a Social Process Model},
year = {1996},
issue_date = {Jan. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/214174.214178},
doi = {10.1145/214174.214178},
abstract = {We trace the process of developing and implementing a materials management system in one company over a 15-year period. Using a process research model developed by Newman and Robey, we identify 44 events in the process and define them as either encounters or episodes. Encounters are concentrated events, such as meetings and announcements, that separate episodes, which are events of longer duration. By examining the sequence of events over the 15 years of the case, we identify a pattern of repeated failure, followed by success. Our discussion centers on the value of detecting and displaying such patterns and the need for theoretical interpretation of recurring sequences of events. Five alternative theoretical perspectives, originally proposed by Kling, are used to interpret the sequential patterns identified by the model. We conclude that the form of the process model allows researchers who operate from different perspectives to enrich their understanding of the process of system development.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {30–63},
numpages = {34},
keywords = {social processes, system implementation}
}

@article{10.1145/214174.214175,
author = {Lucarella, Dario and Zanzi, Antonella},
title = {A Visual Retrieval Environment for Hypermedia Information Systems},
year = {1996},
issue_date = {Jan. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/214174.214175},
doi = {10.1145/214174.214175},
abstract = {We present a graph-based object model that may be used as a uniform framework for direct manipulation of multimedia information. After an introduction motivating the need for abstraction and structuring mechanisms in hypermedia systems, we introduce the data model and the notion of perspective, a form of data abstraction that acts as a user interface to the system, providing control over the visibility of the objects and their properties. A perspective is defined to include an intension and an extension. The intension is defined in terms of a pattern, a subgraph of the schema graph, and the extension is the set of pattern-matching instances. Perspectives, as well as database schema and instances, are graph structures that can be manipulated in various ways. The resulting uniform approach is well suited to a visual interface. A visual interface for complex information systems provides high semantic power, thus exploiting the semantic expressibility of the underlying data model, while maintaining ease of interaction with the system. In this way, we reach the goal of decreasing cognitive load on the user, with the additional advantage of always maintaining the same interaction style. We present a visual retrieval environment that effectively combines filtering, browsing, and navigation to provide an integrated view of the retrieval problem. Design and implementation issues are outlined for MORE (Multimedia Object Retrieval Environment), a prototype system relying on the proposed model. The focus is on the main user interface functionalities, and actual interaction sessions are presented including schema creation, information loading, and information retrieval.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {3–29},
numpages = {27},
keywords = {visual interface, information filtering, direct object manipulation, graph-oriented models, complex objects, hypermedia applications, browsing}
}

@article{10.1145/211430.215258,
author = {Stevens, Scott and Little, Thomas},
title = {Introduction to the Special Issue on Video Information Retrieval},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/211430.215258},
doi = {10.1145/211430.215258},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {371–372},
numpages = {2}
}

@article{10.1145/211430.211440,
author = {Keller, Ralf and Effelsberg, Wolfgang and Lamparter, Bernd},
title = {XMovie: Architecture and Implementation of a Distributed Movie System},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/211430.211440},
doi = {10.1145/211430.211440},
abstract = {We describe a system for storing, transmitting, and presenting digital movies in a computer network. The hardware used in the system is standard hardware, as found in typical workstations today; no special hardware is required, but if available it can be used to provide better performance. The XMovie system has several innovative features. First, it contains a new algorithm for the gradual adaptation of the color lookup table during the presentation of the movie to ensure optimal color quality on low-end workstations. Second, it is a multistandard system supporting the compression techniques MPEG, Motion JPEG, and a newly developed extension to the well-known Color Cell Compression method. Third, it contains AdFEC, a new adaptable forward error correction method for our movie  transmission protocol.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {471–499},
numpages = {29},
keywords = {distributed multimedia system, software motion picture, transmission protocol, digital video}
}

@article{10.1145/211430.211439,
author = {Bulterman, Dick C. A.},
title = {Embedded Video in Hypermedia Documents: Supporting Integration and Adaptive Control},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/211430.211439},
doi = {10.1145/211430.211439},
abstract = {As the availability of digital video becomes commonplace, a shift in application focus will occur from merely accessing video as an independent data stream to embedding video with other multimedia data types into coordinated hypermedia presentations. The migration to embedded video will present new demands on application and support environments: processing of any one piece of video data will depend on how that data relates to other data streams active within the same presentation. This article describes presentation, synchronization, and interaction control issues for manipulating embedded video. First we describe the requirements for embedded video, contrasted against other forms of video use. Next we consider mechanisms for describing and implementing the behavior of embedded-video segments relative to other data items in a document; these relationships form the basis of implementing cooperative control among the events in a presentation. Finally we consider extending the possibilities for tailoring embedded video to the characteristics of the local runtime environment; this forms the basis for adaptive, application-level quality-of-service control of a presentation. In all cases, we describe a mechanism to externalize the behavior of hypermedia presentations containing resource-intensive data requirements so that effective control can be implemented by low-level system facilities based on application-specific requirements. We present our results in terms of the CMIFed authoring/presentation system.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {440–470},
numpages = {31},
keywords = {hypermedia documents, adaptive control, video presentation, embedded video, multimedia, synchronization}
}

@article{10.1145/211430.211433,
author = {Dimitrova, Nevenka and Golshani, Forouzan},
title = {Motion Recovery for Video Content Classification},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/211430.211433},
doi = {10.1145/211430.211433},
abstract = {Like other types of digital information, video sequences must be classified based on the semantics of their contents. A more-precise and completer extraction of semantic information will result in a more-effective classification. The most-discernible difference between still images and moving pictures stems from movements and variations. Thus, to go from the realm of still-image repositories to video databases, we must be able to deal with motion. Particularly, we need the ability to classify objects appearing in a video sequence based on their characteristics and features such as shape or color, as well as their movements. By describing the movements that we derive from the process of motion analysis, we introduce a dual hierarchy consisting of spatial and  temporal parts for video sequence representation. This gives us the flexibility to examine arbitrary sequences of frames at various levels of abstraction and to retrieve the associated temporal information (say, object trajectories) in addition to the spatial representation. Our algorithm for motion detection uses the motion compensation component of the MPEG video-encoding scheme and then computes trajectories for objects of interest. The specification of a language for retrieval of video based on the spatial as well as motion characteristics is presented.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {408–439},
numpages = {32},
keywords = {content-based retrieval of video, motion recovery, video databases, video retrieval, MPEG compressed video analysis}
}

@article{10.1145/211430.211431,
author = {Chua, Tat-Seng and Ruan, Li-Qun},
title = {A Video Retrieval and Sequencing System},
year = {1995},
issue_date = {Oct. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/211430.211431},
doi = {10.1145/211430.211431},
abstract = {Video is an effective medium for capturing the events in the real world around us, and a vast amount of video materials exists, covering a wide range of applications. However, widespread use of video in computer applications is often impeded by the lack of effective tools to manage video information systematically. This article discusses the design and implementation of a frame-based video retrieval and sequencing system (VRSS). The system is designed to support the entire process of video information management: segmenting, indexing, retrieving, and sequencing of video data. A semiautomatic tool is developed to divide video sequences into meaningful shots. Each video shot is logged using text descriptions, audio dialogue, and cinematic attributes. A two-layered, concept-based model is used as the basis for accurately retrieving relevant video shots based on users' free-text queries. A cinematic, rule-based, virtual editing tool is also developed to sequence the video shots retrieved for presentation within a specified time constraint. The system has been tested on a video documentary on the NUS (National University of Singapore) engineering faculty. The results of video retrieval experiments are encouraging.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {373–407},
numpages = {35},
keywords = {cinematic rules, frame-based modeling, multimedia, video retrieval, virtual editing}
}

@article{10.1145/203052.203074,
author = {Kong, Q. and Chen, G.},
title = {On Deductive Databases with Incomplete Information},
year = {1995},
issue_date = {July 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/203052.203074},
doi = {10.1145/203052.203074},
abstract = {In order to extend the ability to handle incomplete information in a definite deductive database, a Horn clause-based system representing incomplete information as incomplete constants is proposed. By using the notion of incomplete constants the deductive database system handles incomplete information in the form of sets of possible values, thereby giving more information than null values. The resulting system extends Horn logic to express a restricted form of indefiniteness. Although a deductive database with this kind of incomplete information is, in fact, a subset of an indefinite deductive database system, it represents indefiniteness in terms of value incompleteness, and therefore it can make use of the existing Horn logic computation rules. The inference rules for such a system are presented, its model theory discussed, and a model theory of indefiniteness proposed. The theory is consistent with minimal model theory and extends its expressive power.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {354–370},
numpages = {17},
keywords = {query evaluation, Horn clause, deductive databases, Prolog, incomplete information}
}

@article{10.1145/203052.203067,
author = {Kwok, K. L.},
title = {A Network Approach to Probabilistic Information Retrieval},
year = {1995},
issue_date = {July 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/203052.203067},
doi = {10.1145/203052.203067},
abstract = {In this article we show how probabilistic information retrieval based on document components may be implemented as a feedforward (feedbackward) artificial neural network. The network supports adaptation of connection weights as well as the growing of new edges between queries and terms based on user relevance feedback data for training, and it reflects query modification and expansion in information retrieval. A learning rule is applied that can also be viewed as supporting sequential learning using a harmonic sequence learning rate. Experimental results with four standard small collections and a large Wall Street Journal collection (173,219 documents) show that performance of feedback improves substantially over no feedback, and further gains are obtained when queries are expanded  with terms from the feedback documents. The effect is much more pronounced in small collections than in the large collection. Query expansion may be considered as a tool for both precision and recall enhancement. In particular, small query expansion levels of about 30 terms can achieve most of the gains at the low-recall high-precision region, while larger expansion levels continue to provide gains at the high-recall low-precision region of a precision recall curve.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {324–353},
numpages = {30},
keywords = {learning, probabilistic retrieval, training, probabilistic indexing, indexing and retrieval, document-focused and query-focused relevance feedback, query expansion, artificial neural networks, item self-learning}
}

@article{10.1145/203052.203065,
author = {Koike, Hideki},
title = {Fractal Views: A Fractal-Based Method for Controlling Information Display},
year = {1995},
issue_date = {July 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/203052.203065},
doi = {10.1145/203052.203065},
abstract = {Computer users often must view large amounts of information through video displays which are physically limited in size. Although some methods, which automatically display/erase information units based on their degrees of importance, have been proposed, they lack an ability to keep the total amount of displayed information nearly constant. We propose a new method for information display based on fractal theory. By regarding the information structures used in computers as complex objects, we can abstract these objects as well as control their amount. Using our method, (1) the total amount of information is kept nearly constant even when users change their focuses of attention and (2) this amount can be set flexibly. Through mathematical analysis, we show our method's ability to control the amount. An application to program display is also shown. When this method is applied to the display of structured programs, it provides fisheye-like views which integrate local details around the focal point and major landmarks further away.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {305–323},
numpages = {19},
keywords = {information visualization, program display, fractals, abstracting methods, UI theory}
}

@article{10.1145/203052.203061,
author = {Tuzhilin, Alexander},
title = {Templar: A Knowledge-Based Language for Software Specifications Using Temporal Logic},
year = {1995},
issue_date = {July 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/203052.203061},
doi = {10.1145/203052.203061},
abstract = {A software specification language Templar is defined in this article. The development of the language was guided by the following objectives: requirements specifications written in Templar should have a clear syntax and formal semantics, should be easy for a systems analyst to develop and for an end-user to understand, and it should be easy to map them into a broad range of design specifications. Templar is based on temporal logic and on the Activity-Event-Condition-Activity model of a rule which is an extension of the Event-Condition-Activity model in active databases. The language supports a rich set of modeling primitives, including rules, procedures, temporal logic operators, events, activities, hierarchical decomposition of activities, parallelism, and decisions combined together into a cohesive system.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {269–304},
numpages = {36},
keywords = {events, temporal logic, rule-based systems, time, activities, specification languages}
}

@article{10.1145/203052.203056,
author = {Celentano, Augusto and Fugini, Maria Grazia and Pozzi, Silvano},
title = {Knowledge-Based Document Retrieval in Office Environments: The Kabiria System},
year = {1995},
issue_date = {July 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/203052.203056},
doi = {10.1145/203052.203056},
abstract = {In the office environment, the retrieval of documents is performed using the concepts contained in the documents, information about the procedural context where the documents are used, and information about the regulations and laws that discipline the life of documents within a given application domain. To fulfill the requirements of such a sophisticated retrieval, we propose a document retrieval model and system based on the representation of knowledge describing the semantic contents of documents, the way in which the documents are managed by procedures and by people in the office, and the application domain where the office operates. The article describes the knowledge representation issues needed for the document retrieval system and presents a document retrieval model that  captures these issues. The effectiveness of the approach is illustrated by describing a system, named Kabiria, built on top of such model. The article describes the querying and browsing environments, and the architecture of the system.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {237–268},
numpages = {32},
keywords = {knowledge base, class, object orientation, instance, link, browser, user interface, hypertext}
}

@article{10.1145/201040.201049,
author = {Strong, Diane M. and Miller, Steven M.},
title = {Exceptions and Exception Handling in Computerized Information Processes},
year = {1995},
issue_date = {April 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/201040.201049},
doi = {10.1145/201040.201049},
abstract = {Exceptions, situations that cannot be correctly processed by computer systems, occur frequently in computer-based information processes. Five perspectives on exceptions provide insights into why exceptions occur and how they might be eliminated or more efficiently handled. We investigate these perspectives using an in-depth study of an operating information process that has frequent exceptions. Our results support the use of a total quality management (TQM) approach of eliminating exceptions for some exceptions, in particular, those caused by computer systems that are poor matches to organizational processes. However, some exceptions are explained better by a political system perspective of conflicting goals between subunits. For these exceptions and several other types, designing an integrated human-computer process will provide better performance than will eliminating exceptions and moving toward an entirely automated process.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {206–233},
numpages = {28},
keywords = {process design, exceptions, Total Quality Management, exception handling}
}

@article{10.1145/201040.201047,
author = {Malone, Thomas W. and Lai, Kum-Yew and Fry, Christopher},
title = {Experiments with Oval: A Radically Tailorable Tool for Cooperative Work},
year = {1995},
issue_date = {April 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/201040.201047},
doi = {10.1145/201040.201047},
abstract = {This article describes a series of tests of the generality of a “radically tailorable” tool for cooperative work. Users of this system can create applications by combining and modifying four kinds of building blocks: objects, views, agents, and links. We found that user-level tailoring of these primitives can provide most of the functionality found in well-known cooperative work systems such as gIBIS, Coordinator, Lotus Notes, and Information Lens. These primitives, therefore, appear to provide an elementary “tailoring language” out of which a wide variety of integrated information management and collaboration applications can be constructed by end users.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {177–205},
numpages = {29},
keywords = {groupware, radical tailorability, computer-supported cooperative work, end-user programming}
}

@article{10.1145/201040.201044,
author = {Rangan, P. Venkat and Ramanathan, Srinivas and Sampathkumar, Srihari},
title = {Feedback Techniques for Continuity and Synchronization in Multimedia Information Retrieval},
year = {1995},
issue_date = {April 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/201040.201044},
doi = {10.1145/201040.201044},
abstract = {Future advances in storage and networking technologies will make it feasible to build multimedia on-demand information servers capable of providing services similar to those of a neighborhood videotape rental store over metropolitan area networks. Such multimedia information servers must not only support retrieval of continuous media units (such as video frames and audio samples), but also preserve synchrony among playback of the different media components constituting a multimedia object. We develop techniques for supporting continuous and synchronous retrieval from multimedia servers. We present feedback techniques by which, during retrieval of multimedia objects from a multimedia server to mediaphones, the multimedia server uses lightweight messages called feedback units transmitted periodically back to it (by mediaphones) to detect impending discontinuities as well as asynchronies at mediaphones. The multimedia server then preventively readjusts media transmission so as to avoid either anomaly, and steers the mediaphones back to synchrony. Given the available buffer sizes at mediaphones and the maximum tolerable asynchrony, we present methods to determine the minimum rate at which feedback units must be transmitted so as to maintain both continuity and synchronization. These feedback techniques remain robust even in the presence of playback rate mismatches and network delay jitter, and their initial simulation for video-audio playback yields a feedback rate of one per 1,000 media units to keep the asynchrony within 250ms, showing that the overhead due to feedback transmission is very small. The constant rate feedback techniques developed in this article form the basis of a prototype on-demand information server being developed at the UCSD Multimedia Laboratory.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {145–176},
numpages = {32},
keywords = {intermedia synchronization, multimedia, synchronization, intramedia continuity, multimedia on-demand information services}
}

@article{10.1145/201040.201041,
author = {Gudivada, Venkat N. and Raghavan, Vijay V.},
title = {Design and Evaluation of Algorithms for Image Retrieval by Spatial Similarity},
year = {1995},
issue_date = {April 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/201040.201041},
doi = {10.1145/201040.201041},
abstract = {Similarity-based retrieval of images is an important task in many image database applications. A major class of users' requests requires retrieving those images in the database that are spatially similar to the query image. We propose an algorithm for computing the spatial similarity between two symbolic images. A symbolic image is a logical representation of the original image where the image objects are uniquely labeled with symbolic names. Spatial relationships in a symbolic image are represented as edges in a weighted graph referred to as spatial-orientation graph. Spatial similarity is then quantified in terms of the number of, as well as the extent to which, the edges of the spatial-orientation graph of the database image conform to the corresponding edges of the spatial-orientation graph of the query image.The proposed algorithm is robust in the sense that it can deal with translation, scale, and rotational variances in images. The algorithm has quadratic time complexity in terms of the total number of objects in both the database and query images. We also introduce the idea of quantifying a system's retrieval quality by having an expert specify the expected rank ordering with respect to each query for a set of test queries. This enables us to assess the quality of algorithms comprehensively for retrieval in image databases. The characteristics of the proposed algorithm are compared with those of the previously available algorithms using a testbed of images. The comparison demonstrated that our algorithm is not only more efficient but also provides a rank ordering of images that consistently matches with the expert's expected rank ordering.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {115–144},
numpages = {30},
keywords = {image databases, image retrieval systems, image retrieval, spatial similarity, rotational invariance}
}

@article{10.1145/195705.195735,
author = {Cooper, William S.},
title = {Some Inconsistencies and Misidentified Modeling Assumptions in Probabilistic Information Retrieval},
year = {1995},
issue_date = {Jan. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/195705.195735},
doi = {10.1145/195705.195735},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {100–111},
numpages = {12},
keywords = {independence, document retrieval, modeling, assumptions, logic, consistency, bibliographic searching}
}

@article{10.1145/195705.195717,
author = {Salminen, Airi and Tague-Sutcliffe, Jean and McClellan, Charles},
title = {From Text to Hypertext by Indexing},
year = {1995},
issue_date = {Jan. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/195705.195717},
doi = {10.1145/195705.195717},
abstract = {A model is presented for converting a collection of documents to hypertext by means of indexing. The documents are assumed to be semistructured, i.e., their text is a hierarchy of parts, and some of the parts consist of natural language. The model is intended as a framework for specifying hypertextual reading capabilities for specific application areas and for developing new automated tools for the conversion of semistructured text to hypertext. In the model, two well-known paradigms—formal grammars and document indexing—are combined.The structure of the source text is defined by a schema that is a constrained context-free grammar. The hierarchic structure of the source may thus be modeled by a parse tree for the grammar. The effect of indexing is described by  grammar transformations. The new grammar, called an indexing schema, is associated with a new parse tree where some text parts are index elements. The indexing schema may hide some parts of the original documents or the structure of some parts. For information retrieval, parts of the indexed text are considered to be nodes of a hypergraph. In the hypergraph-based information access, the navigation capabilities of the hypertext systems are combined with the querying capabilities of information retrieval systems.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {69–99},
numpages = {31},
keywords = {text entities, hypertext, test types, grammars, structured text, constrained grammars, transient hypergraphs, properties}
}

@article{10.1145/195705.195713,
author = {Wong, S. K. M. and Yao, Y. Y.},
title = {On Modeling Information Retrieval with Probabilistic Inference},
year = {1995},
issue_date = {Jan. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/195705.195713},
doi = {10.1145/195705.195713},
abstract = {This article examines and extends the logical models of information retrieval in the context of probability theory. The fundamental notions of term weights and relevance are given probabilistic interpretations. A unified framework is developed for modeling the retrieval process with probabilistic inference. This new approach provides a common conceptual and mathematical basis for many retrieval models, such as the Boolean, fuzzy set, vector space, and conventional probabilistic models. Within this framework, the underlying assumptions employed by each model are identified, and the inherent relationships between these models are analyzed. Although this article is mainly a theoretical analysis of probabilistic inference for information retrieval, practical methods for estimating the required probabilities are provided by simple examples.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {38–68},
numpages = {31}
}

@article{10.1145/195705.195708,
author = {Isakowitz, Tom\'{a}s and Schocken, Shimon and Lucas, Henry C.},
title = {Toward a Logical/Physical Theory of Spreadsheet Modeling},
year = {1995},
issue_date = {Jan. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/195705.195708},
doi = {10.1145/195705.195708},
abstract = {In spite of the increasing sophistication and power of commercial spreadsheet packages, we still lack a formal theory or a methodology to support the construction and maintenance of spreadsheet models. Using a dual logical/physical perspective, we identify four principal components that characterize any spread sheet model: schema, data, editorial, and binding. We present a factoring algorithm for identifying and extracting these components from conventional spreadsheets with minimal user intervention, and a synthesis algorithm that assists users in the construction of executable spreadsheets from reusable model components. This approach opens new possibilities for applying object-oriented and model management  techniques to support the construction, sharing, and reuse of spreadsheet models in organizations. Importantly, our approach to model management and the Windows-based prototype that we have developed are designed to coexist with, rather than replace, traditional spreadsheet programs. In other words, the users are not required to learn a new modeling language; instead, their logical models and data sets are extracted from their spreadsheets transparently, as a side-effect of using standard spreadsheet programs.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–37},
numpages = {37},
keywords = {model management}
}

@article{10.1145/185462.185484,
author = {Wong, Stephen T. C.},
title = {Preference-Based Decision Making for Cooperative Knowledge-Based Systems},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/185462.185484},
doi = {10.1145/185462.185484},
abstract = {Recent advances in cooperative knowledge-based systems (CKBS) offer significant promise for intelligent interaction between multiple AI systems for solving larger, more complex problems. In this paper, we propose a logical, qualitative problem-solving scheme for CKBS that uses social choice theory as a formal basis for making joint decisions and promoting conflict resolution. This scheme consists of three steps: (1) the selection of decision criteria and competing alternatives, (2) the formation of preference profiles and collective choices, and (3) the negotiation among agents as conflicts arise in group decision making. In this paper, we focus on the computational mechanisms developed to support steps (2) and (3) of the scheme. In addition, the practicality of the scheme is illustrated with examples taken from a working prototype dealing with collaborative structural design of buildings.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {407–435},
numpages = {29},
keywords = {social choice theory, decision making, cooperative problem solving, cooperative knowledge-based systems}
}

@article{10.1145/185462.185483,
author = {Chimera, Richard and Shneiderman, Ben},
title = {An Exploratory Evaluation of Three Interfaces for Browsing Large Hierarchical Tables of Contents},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/185462.185483},
doi = {10.1145/185462.185483},
abstract = {Three different interfaces were used to browse a large (1296 items) table of contents. A fully expanded stable interface, expand/contract interface, and multipane interface were studied in a between-groups experiment with 41 novice participants. Nine timed fact retrieval tasks were performed; each task is analyzed and discussed separately. We found that both the expand/contract and multipane interfaces produced significantly faster times than the stable interface for many tasks using this large hierarchy; other advantages of the expand/contract and multipane interfaces over the stable interface are discussed. The animation characteristics of the expand/contract interface appear to play a major role. Refinements to the multipane and expand/contract interfaces are suggested. A predictive model for measuring navigation effort of each interface is presented.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {383–406},
numpages = {24},
keywords = {table of contents, hierarchies, browsing, user interfaces}
}

@article{10.1145/185462.185477,
author = {Chang, Man Kit and Woo, Carson C.},
title = {A Speech-Act-Based Negotiation Protocol: Design, Implementation, and Test Use},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/185462.185477},
doi = {10.1145/185462.185477},
abstract = {Existing negotiation protocols used in Distributed Artificial Intelligence (DAI) systems rarely take into account the results from negotiation research. We propose a negotiation protocol, SANP (Speech-Act-based Negotiation Protocol), which is based on Ballmer and Brennenstuhl's speech act classification and on negotiation analysis literature. The protocol is implemented as a domain-independent system using Strudel, which is an electronic mail toolkit. A small study tested the potential use of the protocol. Although a number of limitations were found in the study, the protocol appears to have potential in domains without these limitations, and it can serve as a building block to design more general negotiation protocols.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {360–382},
numpages = {23},
keywords = {speech act theory, negotiation, organizational computing systems}
}

@article{10.1145/185462.185472,
author = {Merz, Ulla and King, Roger},
title = {DIRECT: A Query Facility for Multiple Databases},
year = {1994},
issue_date = {Oct. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/185462.185472},
doi = {10.1145/185462.185472},
abstract = {The subject of this research project is the architecture and design of a multidatabase query facility. These databases contain structured data, typical for business applications. Problems addressed are: presenting a uniform interface for retrieving data from multiple databases, providing autonomy for the component databases, and defining an architecture for semantic services.DIRECT is a query facility for heterogeneous databases. The databases and their definitions can differ in their data models, names, types, and encoded values. Instead of creating a global schema, descriptions of different databases are allowed to coexist. A multidatabase query language provides a uniform interface for retrieving data from different databases. DIRECT has been exercised with operational  databases that are part of an automated business system.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {339–359},
numpages = {21},
keywords = {query languages, heterogeneous databases, data models}
}

@article{10.1145/183422.183428,
author = {Riloff, Ellen and Lehnert, Wendy},
title = {Information Extraction as a Basis for High-Precision Text Classification},
year = {1994},
issue_date = {July 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/183422.183428},
doi = {10.1145/183422.183428},
abstract = {We describe an approach to text classification that represents a compromise between traditional word-based techniques and in-depth natural language processing. Our approach uses a natural language processing task called “information extraction” as a basis for high-precision text classification. We present three algorithms that use varying amounts of extracted information to classify texts. The relevancy signatures algorithm uses linguistic phrases; the augmented relevancy signatures algorithm uses phrases and local context; and the case-based text classification algorithm uses larger pieces of context. Relevant phrases and contexts are acquired automatically using a training corpus. We evaluate the algorithms on the basis  of two test sets from the MUC-4 corpus. All three algorithms achieved high precision on both test sets, with the augmented relevancy signatures algorithm and the case-based algorithm reaching 100% precision with over 60% recall on one set. Additionally, we compare the algorithms on a larger collection of 1700 texts and describe an automated method for empirically deriving appropriate threshold values. The results suggest that information extraction techniques can support high-precision text classification and, in general, that using more extracted information improves performance. As a practical matter, we also explain how the text classification system can be easily ported across  domains.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {296–333},
numpages = {38},
keywords = {information extraction, text classification}
}

@article{10.1145/183422.183425,
author = {Liddy, Elizabeth D. and Paik, Woojin and Yu, Edmund S.},
title = {Text Categorization for Multiple Users Based on Semantic Features from a Machine-Readable Dictionary},
year = {1994},
issue_date = {July 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/183422.183425},
doi = {10.1145/183422.183425},
abstract = {The text categorization module described here provides a front-end filtering function for the larger DR-LINK text retrieval system [Liddy and Myaeing 1993]. The model evaluates a large incoming stream of documents to determine which documents are sufficiently similar to a profile at the broad subject level to warrant more refined representation and matching. To accomplish this task, each substantive word in a text is first categorized using a feature set based on the semantic Subject Field Codes (SFCs) assigned to individual word senses in a machine-readable dictionary. When tested on 50 user profiles and 550 megabytes of documents, results indicate that the feature set that is the basis of the text categorization module and the algorithm that establishes the boundary of categories  of potentially relevant documents accomplish their tasks with a high level of performance.This means that the category of potentially relevant documents for most profiles would contain at least 80% of all documents later determined to be relevant to the profile. The number of documents in this set would be uniquely determined by the system's category-boundary predictor, and this set is likely to contain less than 5% of the incoming stream of documents.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {278–295},
numpages = {18},
keywords = {subject field coding, semantic vectors}
}

@article{10.1145/183422.183424,
author = {Yang, Yiming and Chute, Christopher G.},
title = {An Example-Based Mapping Method for Text Categorization and Retrieval},
year = {1994},
issue_date = {July 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/183422.183424},
doi = {10.1145/183422.183424},
abstract = {A unified model for text categorization and text retrieval is introduced. We use a training set of manually categorized documents to learn word-category associations, and use these associations to predict the categories of arbitrary documents. Similarly, we use a training set of queries and their related documents to obtain empirical associations between query words and indexing terms of documents, and use these associations to predict the related documents of arbitrary queries. A Linear Least Squares Fit (LLSF) technique is employed to estimate the likelihood of these associations. Document collections from the MEDLINE database and Mayo patient records are used for studies on the effectiveness of our approach, and on how much the effectiveness depends on the choices of training  data, indexing language, word-weighting scheme, and morphological canonicalization. Alternative methods are also tested on these data collections for comparison. It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language. Such a semantic mapping lead to a significant improvement in categorization and retrieval, compared to alternative approaches.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {252–277},
numpages = {26},
keywords = {document categorization, statistical learning of human decisions, query categorization}
}

@article{10.1145/183422.183423,
author = {Apt\'{e}, Chidanand and Damerau, Fred and Weiss, Sholom M.},
title = {Automated Learning of Decision Rules for Text Categorization},
year = {1994},
issue_date = {July 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/183422.183423},
doi = {10.1145/183422.183423},
abstract = {We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to “read” documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {233–251},
numpages = {19}
}

@article{10.1145/196734.196746,
author = {Ruhleder, Karen},
title = {Rich and Lean Representations of Information for Knowledge Work: The Role of Computing Packages in the Work of Classical Scholars},
year = {1994},
issue_date = {April 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/196734.196746},
doi = {10.1145/196734.196746},
abstract = {Applying information systems to complex intellectual tasks requires the representation and codification of ambiguous and fragmentary forms of data. This application effects changes not only in representation of this data, but in the relationships between users and tools, techniques, or systems for data interpretation. It also affects the complex infrastructures that support this process. This article uses a package metaphor to examine the impact on one domain of knowledge work, classical scholarship, of the “computerization” of a key data source, the textual edition. The construction of one on-line textual databank, the Thesaurus Linguae Graecae (TLG), has altered the traditional relationships between text “owners” and “users” has changed the role of the text as a conduit for social and historical information, and has disrupted traditional patterns of transmitting domain expertise. A rich information resource has become lean in its electronic form.The TLG has standardized the corpus of Greek literature and eased access to a broad range of works, including rare and out-of-print materials. At the same time, its construction has decoupled often-contested textual sources from their accompanying critical notes and supplemental materials. The use of the TLG has also shifted notions of objectivity, accuracy, and requisite expertise within the community. The transmission of domain knowledge must now be coupled with the transmission of technical knowledge, a process for which no infrastructure is currently in place. These experiences parallel those of other knowledge workers. “Mechanistic” paradigms of information and knowledge cannot accommodate important components of computing packages, including the transmission of expertise and infrastructures for tool development and evaluation. Recent developments in information storage and dissemination, including gophers and ftp sites may indicate that despite technical advances that could be used to support rich representations (such as hypermedia and multimedia), leaner forms of data may prevail.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {208–230},
numpages = {23},
keywords = {locus of expertise, computing packages, decontextualization of information, computerization of knowledge work, information representations}
}

@article{10.1145/196734.196745,
author = {Orlikowski, Wanda J. and Gash, Debra C.},
title = {Technological Frames: Making Sense of Information Technology in Organizations},
year = {1994},
issue_date = {April 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/196734.196745},
doi = {10.1145/196734.196745},
abstract = {In this article, we build on and extend research into the cognitions and values of users and designers by proposing a systematic approach for examining the underlying assumptions, expectations, and knowledge that people have about technology. Such interpretations of technology (which we call technological frames) are central to understanding technological development, use, and change in organizations. We suggest that where the technological frames of key groups in organizations—such as managers, technologists, and users— are significantly different, difficulties and conflict around the development, use, and change of technology may result. We use the findings of an empirical study to illustrate how the nature, value, and use of a groupware technology were interpreted by  various organizational stakeholders, resulting in outcomes that deviated from those expected. We argue that technological frames offer an interesting and useful analytic perspective for explaining an anticipating actions and meanings that are not easily obtained with other theoretical lenses.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {174–207},
numpages = {34},
keywords = {technological implementation, social cognitions, technological frames, managing expectations, technology use}
}

@article{10.1145/196734.196744,
author = {Walsham, G. and Waema, T.},
title = {Information Systems Strategy and Implementation: A Case Study of a Building Society},
year = {1994},
issue_date = {April 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/196734.196744},
doi = {10.1145/196734.196744},
abstract = {The formation and implementation of strategy with respect to computer-based information systems (IS) are important issues in many contemporary organizations, including those in the financial services sector. This paper describes and analyzes an in-depth case study of the strategy formation and implementation process in one such organization, a medium-sized UK building society, and relates the process to its organizational and broader contexts; the organization is examined over a period of several years and under the contrasting leadership of two different chief executives. The case study is used to develop some general implications on IS strategy and implementation, which can be taken as themes for debate in any new situation. The paper provides an example of a more detailed  perspective on processes in IS strategy and implementation than typically available in the literature. In addition, a new framework for further research in this area is developed, which directs the researcher toward exploring the dynamic interplay of strategic content, multilevel contexts, and cultural and political perspectives on the process of change.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {150–173},
numpages = {24},
keywords = {culture, strategy, politics, change process, multilevel context, implementation}
}

@article{10.1145/196734.196738,
author = {Markus, M. L.},
title = {Finding a Happy Medium: Explaining the Negative Effects of Electronic Communication on Social Life at Work},
year = {1994},
issue_date = {April 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/196734.196738},
doi = {10.1145/196734.196738},
abstract = {The sometimes observed negative social effects of electronic communication technology are often attributed to the characteristics of the technology itself. Electronic mail, for instance, filters out personal and social cues and provides new capabilities not found in traditional media, and it has been argued that these factors have consequences such as “flaming” and depersonalization. Alternative theoretical perspectives on the impacts of information technology suggest that our ability to explain these outcomes might be enhanced by attending to users' intentional choices about how to use technology and to unpredictable technology usage patterns that emerge when users interact with the technology and each other. These alternative perspectives are examined in the context of  an exploratory case study of a complex organization in which electronic mail was heavily used.Users were found to select email deliberately when they wished to avoid unwanted social interactions. At the same time, they actively took steps to avoid negative outcomes, such as depersonalization of their relationships with subordinates. However, despite their well-intentioned efforts, some negative social effects did occur that cannot entirely be attributed to the technological characteristics of electronic communication. Instead, they appear to be ironic side effects of users' thoughtful efforts to use email effectively. These results suggest the value of according a prominent role in explanations of technology impacts to users' intended and unintended technology uses. The  results also imply that negative social effects from using electronic communication technology may not prove easy to eradicate, despite technological developments such as multimedia integration, and despite efforts to train users in the best email “etiquette.”},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {119–149},
numpages = {31},
keywords = {politics, depersonalization, electronic mail, connectedness, social distance, etiquette}
}

@article{10.1145/174608.174612,
author = {Fuhr, Norbert and Pfeifer, Ulrich},
title = {Probabilistic Information Retrieval as a Combination of Abstraction, Inductive Learning, and Probabilistic Assumptions},
year = {1994},
issue_date = {Jan. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/174608.174612},
doi = {10.1145/174608.174612},
abstract = {We show that former approaches in probabilistic information retrieval are based on one or two of the three concepts abstraction, inductive learning, and probabilistic assumptions, and we propose a new approach which combines all three concepts. This approach is illustrated for the case of indexing with a controlled vocabulary. For this purpose, we describe a new probabilistic model first, which is then combined with logistic regression, thus yielding a generalization of the original model. Experimental results for the pure theoretical model as well as for heuristic variants are given. Furthermore, linear and logistic regression are compared.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {92–115},
numpages = {24},
keywords = {probabilistic indexing, probabilistic retrieval, controlled vocabulary, logistic regression}
}

@article{10.1145/174608.174611,
author = {Sch\"{a}uble, Peter and W\"{u}thrich, Beat},
title = {On the Expressive Power of Query Languages},
year = {1994},
issue_date = {Jan. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/174608.174611},
doi = {10.1145/174608.174611},
abstract = {Two main topics are addressed. First, an algebraic approach is presented to define a general notion of expressive power. Heterogeneous algebras represent information systems and morphisms represent the correspondences between the instances of databases, the correspondences between answers, and the correspondences between queries. An important feature of this new notion of expressive power is that query languages of different types can be compared with respect to their expressive power. In the case of relational query languages, the new notion of expressive power is shown to be equivalent to the notion used by Chandra and Harel. In the case of nonrelational query languages, the versatility of the new notion of expressive power is demonstrated by comparing the fixpoint query languages  with an object-oriented query language called FQL. The expressive power of the Functional Query Language FQL is the second main topic of this paper. The specifications of FQL functions can be recursive or even mutually recursive, FQL has a fixpoint semantics based on a complete lattice consisting of bag functions. The query language FQL is shown to be more expressive than the fixpoint query languages. This result implies that FQL is also more expressive than Datalog with stratified negation. Examples of recursive FQL functions are given that determine the ancestors of persons and the bill of materials.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {69–91},
numpages = {23},
keywords = {functional query languages, fixpoint query languages, expressive power of query languages, datalog, relational query languages}
}

@article{10.1145/174608.174610,
author = {Poulovassilis, Alexandra and Levene, Mark},
title = {A Nested-Graph Model for the Representation and Manipulation of Complex Objects},
year = {1994},
issue_date = {Jan. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/174608.174610},
doi = {10.1145/174608.174610},
abstract = {Three recent trends in database research are object-oriented and deductive databases and graph-based user interfaces. We draw these trends together in a data model we call the Hypernode Model. The single data structure of this model is the hypernode, a graph whose nodes can themselves be graphs. Hypernodes are typed, and types, too, are nested graphs. We give the theoretical foundations of hypernodes and types, and we show that type checking is tractable. We show also how conventional type-forming operators can be simulated by our graph types, including cyclic types. The Hypernode Model comes equipped with a rule-based query language called Hyperlog, which is complete with respect to computation and update. We define the operational semantics of Hyperlog and show  that the evaluation can be performed efficiently. We discuss also the use of Hyperlog for supporting database browsing, an essential feature of Hypertext databases. We compare our work with other graph-based data models—unlike previous graph-based models, the Hypernode Model provides inherent support for data abstraction via its nesting of graphs. Finally, we briefly discuss the implementation of a DBMS based on the Hypernode Model.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {35–68},
numpages = {34},
keywords = {nested graph, types, rule-based query and update language, complex object, object store}
}

@article{10.1145/174608.174609,
author = {Marchionini, Gary and Crane, Gregory},
title = {Evaluating Hypermedia and Learning: Methods and Results from the Perseus Project},
year = {1994},
issue_date = {Jan. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/174608.174609},
doi = {10.1145/174608.174609},
abstract = {The Perseus Project has developed a hypermedia corpus of materials related to the ancient Greek world. The materials include a variety of texts and images, and tools for using these materials and navigating the sytem. Results from a three-year evaluation of Perseus use in a variety of college settings are described. The evaluation assessed both this particular system and the application of the technological genre to information management and to learning. The evaluation used a variety of methods to address questions about learning and teaching with hypermedia and to guide the development of early versions of the system. Results illustrate that such environments offer potential for accelerating learning and for supporting new types of learning and teaching; that students and instructors must develop new strategies for learning and teaching with such technology; and that institutions must develop infrastructural support for such technology. The results also illustrate the importance of well-designed interfaces and different types of assignments on user performance.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {5–34},
numpages = {30},
keywords = {hypermedia, teaching, human-computer interaction, learning}
}

@article{10.1145/159764.159763,
author = {Olson, Judith S. and Olson, Gary M. and Storr\o{}sten, Marianne and Carter, Mark},
title = {Groupwork Close up: A Comparison of the Group Design Process with and without a Simple Group Editor},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/159764.159763},
doi = {10.1145/159764.159763},
abstract = {A simple collaborative tool, a shared text editor called ShrEdit, changed the way groups of designers performed their work, and changed it for the better. First, the designs produced by the 19 groups of three designers were of higher quality than those of the 19 groups who worked with conventional whiteboard, paper and pencil. The groups with the new tool reported liking their work process a little less, probably because they had to adapt their work style to a new tool. We expected, from the brainstorming literature and recent work on Group Support Systems, that the reason the designs were of better quality was that the supported groups generated more ideas. To our surprise, the groups working with ShrEdit generated fewer design ideas, but apparently   better ones. It appears that the tool helped the supported groups keep more focused on the core issued in the emerging design, to waste less time on less important topics, and to capture what was said as they went. This suggests that small workgroups can capitalize on the free access they have to a shared workspace, without requiring a facilitator or a work process embedded in the software.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {321–348},
numpages = {28},
keywords = {concurrent editing, small group behavior, groupware, group support system, face-to-face work, collaboration}
}

@article{10.1145/159764.159762,
author = {Ishii, Hiroshi and Kobayashi, Minoru and Grudin, Jonathan},
title = {Integration of Interpersonal Space and Shared Workspace: ClearBoard Design and Experiments},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/159764.159762},
doi = {10.1145/159764.159762},
abstract = {We describe the evolution of the novel shared drawing medium ClearBoard which was designed to seamlessly integrate an interpersonal space and a shared workspace. ClearBoard permits coworkers in two locations to draw with color markers or with electronic pens and software tools while maintaining direct eye contact and the ability to employ natural gestures. The ClearBoard design is based on the key metaphor of “talking through and drawing on a transparent glass window.” We describe the evolution from ClearBoard-1 (which enables shared video drawing) to ClearBoard-2 (which incorporates TeamPaint, a multiuser paint editor). Initial observations and findings gained through the experimental use of the prototype, including the feature of “gaze awareness,” are  discussed. Further experiments are conducted with ClearBoard-0 (a simple mockup), ClearBoard-1, and an actual desktop as a control. In the settings we examined, the ClearBoard environment led to more eye contact and potential awareness of collaborator's gaze direction over the traditional desktop environment.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {349–375},
numpages = {27},
keywords = {video conference, eye contact, groupware, gaze direction, shared drawing, seamless design, gaze awareness}
}

@article{10.1145/159764.159761,
author = {Hindus, Debby and Schmandt, Chris and Horner, Chris},
title = {Capturing, Structuring, and Representing Ubiquitous Audio},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/159764.159761},
doi = {10.1145/159764.159761},
abstract = {Although talking is an integral part of collaboration, there has been little computer support for acquiring and accessing the contents of conversations. Our approach has focused on ubiquitous audio, or the unobtrusive capture of speech interactions in everyday work environments. Speech recognition technology cannot yet transcribe fluent conversational speech, so the words themselves are not available for organizing the captured interactions. Instead, the structure of an interaction is derived from acoustical information inherent in the stored speech and augmented by user interaction during or after capture. This article describes applications for capturing and structuring audio from office discussions and telephone calls, and mechanisms for later retrieval of these   stored interactions. An important aspect of retrieval is choosing an appropriate visual representation, and this article describes the evolution of a family of representations across a range of applications. Finally, this work is placed within the broader context of desktop audio, mobile audio applications, and social implications.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {376–400},
numpages = {25},
keywords = {collaborative work, ubiquitous computing, multimedia workstation software, stored speech, audio interactions, semi-structured data, software telephony}
}

@article{10.1145/159764.159760,
author = {Resnick, Paul},
title = {Phone-Based CSCW: Tools and Trials},
year = {1993},
issue_date = {Oct. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/159764.159760},
doi = {10.1145/159764.159760},
abstract = {Telephones are the most ubiquitous, best-networked, and simplest computer terminals available today. They have been used for voice mail but largely overlooked as a platform for asynchronous cooperative-work applications such as event calendars, issue discussions, and question-and-answer gathering. HyperVoice is a software toolkit for constructing such applications. Its building blocks are high-level presentation formats for collections of structured voice messages. The presentation formats can themselves be presented and manipulated, enabling significant customization of applications by phone. Results of two field trials suggest social-context factors that will influence the success or failure of phone-based cooperative work applications in particular settings.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {401–424},
numpages = {24},
keywords = {telephone bulletin board, application generator, semi-structured messages, interactive voice response, phone-based interface, cooperative work, voice mail, groupware}
}

@article{10.1145/159161.173948,
author = {Shaw, Chris and Green, Mark and Liang, Jiandong and Sun, Yunqi},
title = {Decoupled Simulation in Virtual Reality with the MR Toolkit},
year = {1993},
issue_date = {July 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/159161.173948},
doi = {10.1145/159161.173948},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {287–317},
numpages = {31},
keywords = {interaactive 3D graphics, user interface software}
}

@article{10.1145/159161.159160,
author = {Fitzmaurice, George W. and Zhai, Shumin and Chignell, Mark H.},
title = {Virtual Reality for Palmtop Computers},
year = {1993},
issue_date = {July 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/159161.159160},
doi = {10.1145/159161.159160},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {197–218},
numpages = {22},
keywords = {3D control and display, palmtop computers, virtual reality}
}

@article{10.1145/159161.159159,
author = {Sturman, David J. and Zeltzer, David},
title = {A Design Method for “Whole-Hand” Human-Computer Interaction},
year = {1993},
issue_date = {July 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/159161.159159},
doi = {10.1145/159161.159159},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {219–238},
numpages = {20},
keywords = {input devices, interaction techniques, interface design, user interface, virtual environments}
}

@article{10.1145/159161.155370,
author = {Koike, Hideki},
title = {The Role of Another Spatial Dimension in Software Visualization},
year = {1993},
issue_date = {July 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/159161.155370},
doi = {10.1145/159161.155370},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {266–286},
numpages = {21},
keywords = {information visualization, parallel manipulator, electric power control system}
}

@article{10.1145/159161.155359,
author = {Arthur, Kevin W. and Booth, Kellogg S. and Ware, Colin},
title = {Evaluating 3D Task Performance for Fish Tank Virtual Worlds},
year = {1993},
issue_date = {July 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/159161.155359},
doi = {10.1145/159161.155359},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {239–265},
numpages = {27},
keywords = {virtual worlds, stereopsis, head-coupled display, virtual reality}
}

@article{10.1145/130226.148055,
author = {Bansler, Jorgen P. and B\o{}dker, Keld},
title = {A Reappraisal of Structured Analysis: Design in an Organizational Context},
year = {1993},
issue_date = {April 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/130226.148055},
doi = {10.1145/130226.148055},
abstract = {We review Structured Analysis as presented by Yourdon and DeMarco. First, we examine the implicit assumptions embodied in the method about the nature of organizations, work processes, and design. Following this we present the results of an exploratory study, conducted to find out how the method is applied in practice. This study reveals that while some of the tools of Structured Analysis—notably the data flow diagrams—are used and combined with other tools, the designers do not follow the analysis and design procedures prescribed by the method. Our findings suggest that there is a gap between the way systems development is portrayed in the normative technical literature and the way in which it is carried out.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {165–193},
numpages = {29},
keywords = {design process, structured analysis, qualitative empirical studies}
}

@article{10.1145/130226.145014,
author = {Ciaccia, Paulo and Zezula, Pavel},
title = {Estimating Accesses in Partitioned Signature File Organizations},
year = {1993},
issue_date = {April 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/130226.145014},
doi = {10.1145/130226.145014},
abstract = {We show that performance of some basic methods for the partitioning of signature files, namely Quick Filter and Fixed Prefix, can be easily evaluated by means of a closed formula. The approximation is based on well-known results from probability theory, and, as shown by simulations, introduces no appreciable errors when compared with the exact, cumbersome formulas used so far. Furthermore, we prove that the exact formulas for the two methods coincide. Although this does not imply that the two methods behave in the same way, it sheds light on the way they could be compared.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {133–142},
numpages = {10},
keywords = {access method, performance evaluation, superimposed coding, information retrieval}
}

@article{10.1145/130226.134481,
author = {King, Roger and Novak, Michael},
title = {Designing Database Interfaces with DBface},
year = {1993},
issue_date = {April 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/130226.134481},
doi = {10.1145/130226.134481},
abstract = {DBface is a toolkit for designing interfaces to object-oriented databases. It provides users with a set of tools for building custom interfaces with minimal programming. This is accomplished by combining techniques from User Interface Management Systems (UIMS) with a built-in knowledge about the specific kinds of techniques used by object-oriented databases. DBface allows users to create graphical constructs and interactive techniques by taking advantage of an object-oriented database environment and tools. Not only can database tools be used for creating an interface, but information about the interface being built is stored within a database schema and is syntactically consistent with all other schema information. Thus, an interface can deal with data and schema information, including information about another interface. This allows for easy reusability of graphical constructs such as data representations.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {105–132},
numpages = {28},
keywords = {object-oriented databases, graphical interfaces, user interface management systems}
}

@article{10.1145/130226.134466,
author = {Can, Fazli},
title = {Incremental Clustering for Dynamic Information Processing},
year = {1993},
issue_date = {April 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/130226.134466},
doi = {10.1145/130226.134466},
abstract = {Clustering of very large document databases is useful for both searching and browsing. The periodic updating of clusters is required due to the dynamic nature of databases. An algorithm for incremental clustering is introduced. The complexity and cost analysis of the algorithm together with an investigation of its expected behavior are presented. Through empirical testing it is shown that the algorithm achieves cost effectiveness and generates statistically valid clusters that are compatible with those of reclustering. The experimental evidence shows that the algorithm creates an effective and efficient retrieval environment.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {143–164},
numpages = {22},
keywords = {information retrieval, best-match cluster search, dynamic information retrieval environment, cover coefficient, information retrieval effectiveness, information retrieval efficiency, cluster validity}
}

@article{10.1145/151480.151521,
author = {Schnase, John L. and Leggett, John J. and Hicks, David L. and Szabo, Ron L.},
title = {Semantic Data Modeling of Hypermedia Associations},
year = {1993},
issue_date = {Jan. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/151480.151521},
doi = {10.1145/151480.151521},
abstract = {Many important issues in the design and implementation of hypermedia system functionality focus on the way interobject connections are represented, manipulated, and stored. A prototypic system called HB1 is being designed to meet the storage needs of next-generation hypermedia system architectures. HB1 is referred to as a hyperbase management system (HBMS) because it supports, not only the storage and manipulation of information, but the storage and manipulation of the connectivity data that link information together to form hypermedia. Among HB1's distinctions is its use of a semantic network database system to manage physical storage. Here, basic semantic modeling concepts as they apply to hypermedia systems are reviewed, and experiences using a semantic database system in HB1 are discussed.Semantic data models attempt to provide more powerful mechanisms for structuring objects than are provided by traditional approaches. In HB1, it was necessary to abstract interobject connectivity, behaviors, and information for hypermedia. Building on top of a semantic database system facilitated such a separation and made the structural aspects of hypermedia conveniently accessible to manipulation. This becomes particularly important in the implementation of structure-related operations such as structural queries. Our experience suggests that an integrated semantic object-oriented database paradigm appears to be superior to purely relational, semantic, or object-oriented methodologies for representing the structurally complex interrelationships that arise in hypermedia.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {27–50},
numpages = {24}
}

@article{10.1145/151480.151509,
author = {Szczur, Martha R. and Sheppard, Sylvia B.},
title = {TAE Plus: Transportable Applications Environment Plus: A User Interface Development Environment},
year = {1993},
issue_date = {Jan. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/151480.151509},
doi = {10.1145/151480.151509},
abstract = {The Transportable Applications Environment Plus (TAE Plus) is a NASA-developed user interface development environment (UIDE) for the rapid prototyping, evaluation, implementation, and management of user interfaces. TAE Plus provides an intuitive What You See Is What You Get (WYSIWYG) WorkBench for designing an application's user interface. The WorkBench supports the creation and sequencing of displays, including real-time, data-driven display objects. Users can define context-sensitive help for a target application. They can rehearse the user interface and also generate code automatically. In addition TAE Plus contains application services for the runtime manipulation and management of the user interface. Based on Motif and the MIT X Window System, TAE Plus runs on a variety  of Unix- or VMS-based workstations. TAE Plus is an evolving system. User-defined requirements and new technology guide the development of each new version. Advances in virtual operating systems, human factors, computer graphics, command language design, standardization, and software portability are monitored and incorporated as they become available.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {76–101},
numpages = {26},
keywords = {prototyping, graphical user interfaces, user interface development tools}
}

@article{10.1145/151480.151490,
author = {Rama, D. V. and Srinivasan, Padmini},
title = {An Investigation of Content Representation Using Text Grammars},
year = {1993},
issue_date = {Jan. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/151480.151490},
doi = {10.1145/151480.151490},
abstract = {We extend prior work on a model for natural language text representation and retrieval using a linguistic device called text grammar. We demonstrate the value of this approach in accessing relevant items from a collection of empirical abstracts in a medical domain. The advantage, when compared to traditional keyword retrieval, is that this approach is a significant move towards knowledge representation and retrieval. Text representation in this model includes keywords and their conceptual roles in the text. In particular, it involves extracting TOPIC predicates representing the research issue addressed and DESIGN predicates representing important methodological features of the empirical study. Preliminary experimentation shows that keywords exhibit a variety of text-grammar roles in a text database. Second, as intuitively expected, retrieval using TOPIC predicates identifies a smaller subset of texts than Boolean retrieval does. These empirical results along with the theoretical work indicate that the representation and retrieval strategies proposed have a significant potential. Finally, EMPIRICIST, a prototype system is described. In it the text representation predicates are implemented as a network while retrieval is through constrained-spreading activation strategies.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {51–75},
numpages = {25},
keywords = {text representation for medical abstracts, text representation for retrieval, text grammar}
}

@article{10.1145/151480.151483,
author = {Garzotto, Franca and Paolini, Paolo and Schwabe, Daniel},
title = {HDM—a Model-Based Approach to Hypertext Application Design},
year = {1993},
issue_date = {Jan. 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/151480.151483},
doi = {10.1145/151480.151483},
abstract = {Hypertext development should benefit from a systematic, structured development, especially in the case of large and complex applications. A structured approach to hypertext development suggests the notion of authoring-in-the-large. Authoring-in-the-large allows the description of overall classes of information elements and navigational structures of complex applications without much concern with implementation details, and in a system-independent manner. The paper presents HDM (Hypertext Design Model), a first step towards defining a general purpose model for authoring-in-the-large. Some of the most innovative features of HDM are: the notion of perspective; the identification of different categories of links (structural links, application links, and perspective links) with different representational roles; the distinction between hyperbase and access structures; and the possibility of easily integrating the structure of a hypertext application with its browsing semantics. HDM can be used in different manners: as a modeling device or as an implementation device. As a modeling device, it supports producing high level specifications of existing or to-be-developed applications. As an implementation device, it is the basis for designing tools that directly support application development. One of the central advantages of HDM in the design and practical construction of hypertext applications is that the definition of a significant number of links can be derived automatically from a conceptual-design level description. Examples of usage of HDM are also included.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–26},
numpages = {26},
keywords = {hypertext design models, derived links, hypertext structures, hypertext applications, HDM}
}

@article{10.1145/146486.146558,
author = {Kataoka, Yutaka and Morisaki, Masato and Kuribayashi, Hiroshi and Ohara, Hiroyoshi},
title = {A Model for Input and Output of Multilingual Text in a Windowing Environment},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/146486.146558},
doi = {10.1145/146486.146558},
abstract = {The layered multilingual input/output(I/O) sytems we designed, based on typological studies of major-language writing conventions, unifies common features of such conventions to enable international and local utilization. The internationalization layer input module converts keystroke sequences to phonograms and ideograms. The corresponding output module displays position-independent and dependent characters. The localization layer positions language-specific functions outside the structure, integrating them as tables used by finite automaton interpreters and servers to add new languages and code sets without recompilation.The I/O system generates and displays stateful and stateless code sets, enabling interactive language switching. Going beyond POSIX locale model bounds,  the system generates ISO 2022, ISO/DIS 10646 (1990), and Compound Text, defined for the interchange encoding format in X11 protocols, for basic polyglot text communication and processing. Able to generate multilingual code sets, the I/O system clearly demonstrates that code sets should be selected by applications which have purposes beyond selecting one element from a localization set. Functionality and functions related to text manipulation in an operating sytem (OS) must also be determined by such applications.A subset of this I/O system was implemented in the X window system as a basic use of X11R5 I/O by supplying basic code set generation and string manipulation to eliminate OS interference. To ensure polyglot string manipulation, the I/O system must clearly be  implemented separately from an OS and its limitations.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {438–451},
numpages = {14},
keywords = {linguistics, input method, X window systems, input/output, localization, multilingual, multiwindow, output method, internationalization}
}

@article{10.1145/146486.146557,
author = {Matsuoka, Satoshi and Takahashi, Shin and Kamada, Tomihisa and Yonezawa, Akinori},
title = {A General Framework for Bidirectional Translation between Abstract and Pictorial Data},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/146486.146557},
doi = {10.1145/146486.146557},
abstract = {The merits of direct manipulation are now widely recognized. However, direct manipulation interfaces incur high cost in their creation. To cope with this problem, we present a model of bidirectional translation between pictures and abstract application data, and a prototype system, TRIP2, based on this model. Using this model, general mapping from abstract data to pictures and from pictures to abstract data is realized merely by giving declarative mapping rules, allowing fast and easy creation of direct manipulation interfaces. We apply the prototype system to the generation of the interfaces for kinship diagrams, Graph Editors, E-R diagrams, and an Othello game.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {408–437},
numpages = {30},
keywords = {user interface management systems, direct manipulation, user interface, bidirectional translation, visualization}
}

@article{10.1145/146486.146547,
author = {Bier, Eric A.},
title = {EmbeddedButtons: Supporting Buttons in Documents},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/146486.146547},
doi = {10.1145/146486.146547},
abstract = {EmbeddedButtons is a library of routines and a runtime kernel that support the integration of buttons into document media, including text and graphics. Existing document editors can be modified to participate in this open architecture with the addition of a few simple routines. Unlike many button systems that insert special button objects into document media, this system supports turning existing document objects into buttons. As a consequence, buttons inherit all of the attributes of normal document objects, and the appearance of buttons can be edited using operations already familiar to users. Facilities are provided for linking buttons to application windows so that documents can serve as application control panels. Hence, user interface designers can lay out  control panels using familiar document editors rather than special-purpose tools. Three classes of buttons have been implemented, including buttons that pop up a menu and buttons that store and display the value of a variable. New button classes, editors, and applications can be added at run time. Two editors, one for text and one for graphics, currently participate in the architecture.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {381–407},
numpages = {27},
keywords = {user interface layout, buttons, active documents}
}

@article{10.1145/146486.146495,
author = {Dewan, Prasun and Choudhary, Rajiv},
title = {A High-Level and Flexible Framework for Implementing Multiuser User Interfaces},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/146486.146495},
doi = {10.1145/146486.146495},
abstract = {We have developed a high-level and flexible framework for supporting the construction of multiuser interfaces. The framework is based on a generalized editing interaction model, which allows users to view programs as active data that can be concurrently edited by multiple users. It consists of several novel components including a refinement of both the Seeheim UIMS architecture and the distributed graphics architecture that explicitly addresses multiuser interaction; the abstractions of shared active variables and interaction variables, which allow users and applications to exchange information; a set of default collaboration rules designed to keep the collaboration-awareness low in multiuser programs; and a small but powerful set of primitives for overriding these rules. The  framework allows users to be dynamically added and removed from a multiuser sesssion, different users to use different user interfaces to interact with an application, the modules interacting with a particular user to execute on the local workstation, and programmers to incrementally trade automation for flexibility. We have implemented the framework as part of a system called Suite. This paper motivates, describes, and illustrates the framework using the concrete example of Suite, discusses how it can be implemented in other kinds of systems, compares it with related work, discusses its shortcomings, and suggests directions for future work.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {345–380},
numpages = {36},
keywords = {user interface management systems, groupware, computer-supported cooperative work, editing}
}

@article{10.1145/146486.146489,
author = {Pausch, Randy and Conway, Matthew and Deline, Robert},
title = {Lessons Learned from SUIT, the Simple User Interface Toolkit},
year = {1992},
issue_date = {Oct. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/146486.146489},
doi = {10.1145/146486.146489},
abstract = {In recent years, the computer science community has realized the advantages of GUIs (Graphical User Interfaces). Because high-quality GUIs are difficult to build, support tools such as UIMSs, UI Toolkits, and Interface Builders have been developed. Although these tools are powerful, they typically make two assumptions: first, that the programmer has some familiarity with the GUI model, and second, that he is willing to invest several weeks becoming proficient with the tool. These tools typically operate only on specific platforms, such as DOS, the Macintosh, or UNIX/X-windows.The existing tools are beyond the reach of most undergraduate computer science majors, or professional programmers who wish to quickly build GUIs without investing the time to become specialists in  GUI design. For this class of users, we developed SUIT, the Simple User Iinterface Toolkit. SUIT is an attempt to distill the fundamental components of an interface builder and GUI toolkit, and to explain those concepts with the tool itself, all in a short period of time. We have measured that college juniors with no previous GUI programming experience can use SUIT productively after less than three hours. SUIT is a C subroutine library which provides an external control UIMS, an interactive layout editor, and a set of standard “widgets,” such as sliders, buttons, and check boxes. SUIT-based applications run transparently across the Macintosh, DOS, and UNIX/X platforms. SUIT has been exported  to hundreds of external sites on the internet. This paper describes SUIT's architecture, the design decisions we made during its development, and the lessons we learned from extensive observations of over 120 users.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {320–344},
numpages = {25},
keywords = {GUI, pedagogy, user interface toolkit, learnability, graphical user interface, software tools, export, rapid prototyping, UIMS, portability}
}

@article{10.1145/146760.146791,
author = {Rada, Roy},
title = {Converting a Textbook to Hypertext},
year = {1992},
issue_date = {July 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/146760.146791},
doi = {10.1145/146760.146791},
abstract = {Traditional documents may be transformed into hypertext by first reflecting the document's logical markup in the hypertext (producing first-order hypertext) and then by adding links not evident in the document markup (producing second-order hypertext). In our transformation of a textbook to hypertext, the textbook is placed in an intermediate form based on a semantic net and is then placed into the four hypertext systems: Emacs-Info, Guide, HyperTies, and Super-Book. The first-order Guide and SuperBook hypertexts reflect a depth-first traversal of the semantic net, and the Emacs-Info and HyperTies hypertexts reflect a breadth-first traversal. The semantic net is augmented manually, and then new traversal programs automatically generate alternate outlines. An index based on work patterns in the textbook is also automatically generated for the second-order hypertext. Our suite of programs has been applied to a published textbook, and the resulting hypertexts are publicly available.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {294–315},
numpages = {22},
keywords = {electronic publishing, hypermedia models, document markup, human-computer interaction}
}

@article{10.1145/146760.146779,
author = {Ionnidis, Yannis E. and Saulys, Tomas and Whitsitt, Andrew J.},
title = {Conceptual Learning in Database Design},
year = {1992},
issue_date = {July 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/146760.146779},
doi = {10.1145/146760.146779},
abstract = {This paper examines the idea of incorporating machine learning algorithms into a database system for monitoring its stream of incoming queries and generating hierarchies with the most important concepts expressed in those queries. The goal is for these hierarchies to provide
valuable input to the database administrator for dynamically modifying the physical and external schemas of a database for improved system performance and user productivity. The criteria for choosing the appropriate learning algorithms are analyzed, and based on them, two such algorithms, UNIMEM and COBWEB, are selected as the most suitable ones for the task. Standard UNIMEM and COBWEB implementations have been modified to support queries as input. Based on the results of experiments with these modified implementations, the whole approach appears to be quite promising, expecially if the concept hierarchy from which the learning algorithms start their processing is initialized with some of the most obvious concepts captured in the database.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {265–293},
numpages = {29},
keywords = {/UNIMEM, learning from examples, COBWEB, adaptive database systems}
}

@article{10.1145/146760.146770,
author = {Palaniappan, Murugappan and Yankelovich, Nicole and Fitzmaurice, George and Loomis, Anne and Haan, Bernard and Coombs, James and Meyrowitz, Norman},
title = {The Envoy Framework: An Open Architecture for Agents},
year = {1992},
issue_date = {July 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/146760.146770},
doi = {10.1145/146760.146770},
abstract = {The Envoy Framework addresses a need for computer-based assistants or agents that operate in conjunction with users' existing applications, helping them perform tedious, repetitive, or time-consuming tasks more easily and efficiently. Envoys carry out missions for users by invoking envoy-aware applications called operatives and inform users of mission results via envoy-aware applications called informers. The distributed, open architecture developed for Envoys is derived from an analysis of the best characteristics of existing agent systems. This architecture has been designed as a model for how agent technology can be seamlessly integrated into the electronic desktop. It defines a set of application programmer's interfaces so that developers may convert their software to envoy-aware applications. A subset of the architecture described in this paper has been implemented in an Envoy Framework prototype.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {233–264},
numpages = {32},
keywords = {user agent, application programmer interface}
}

@article{10.1145/146760.146764,
author = {Blake, G. Elizabeth and Bray, Tim and Tompa, Frank Wm.},
title = {Shortening the <i>OED</i>: Experience with a Grammar-Defined Database},
year = {1992},
issue_date = {July 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/146760.146764},
doi = {10.1145/146760.146764},
abstract = {Textual databases with highly variable structure can be usefully described by a grammar-defined model. One example of such a text is the Oxford English Dictionary. This paper describes a first attempt to apply technology based on this model to a real problem. A language called GOEDEL, which is a partial implementation of a set of grammar-defined database operators, was used to extract and alter a subset of the OED in order to assist the editors in their production of The Shorter Oxford English Dictionary. The implementation of the pstring data structure to describe a piece of text and the functions that operate on this pstring are illustrated with some detailed examples. The project was judged a success and the resulting program used in production by the Oxford University Press.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {213–232},
numpages = {20},
keywords = {grammar defined model, parsed string, text database}
}

@article{10.1145/146802.146834,
author = {Carroll, John M. and Rosson, Mary Beth},
title = {Getting around the Task-Artifact Cycle: How to Make Claims and Design by Scenario},
year = {1992},
issue_date = {April 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/146802.146834},
doi = {10.1145/146802.146834},
abstract = {We are developing an “action science” approach to human-computer interaction (HCI), seeking to better integrate activities directed at understanding with those directed at design. The approach leverages development practices of current HCI with methods and concepts to support a shift toward using broad and explicit design rationale to reify where we are in a design process, why we are there, and to guide reasoning about where we might go from there. We represent a designed artifact as the set of user scenarios supported by that artifact and more finely by causal schemas detailing the underlying psychological rationale. These schemas, called claims, unpack wherefores and whys of the scenarios. In this paper, we stand back from several empirical projects to clarify our commitments and practices.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {181–212},
numpages = {32},
keywords = {planning, user interfaces, design rationale}
}

@article{10.1145/146802.146826,
author = {Botafogo, Rodrigo A. and Rivlin, Ehud and Shneiderman, Ben},
title = {Structural Analysis of Hypertexts: Identifying Hierarchies and Useful Metrics},
year = {1992},
issue_date = {April 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/146802.146826},
doi = {10.1145/146802.146826},
abstract = {Hypertext users often suffer from the “lost in hyperspace” problem: disorientation from too many jumps while traversing a complex network. One solution to this problem is improved authoring to create more comprehensible structures. This paper proposes several authoring tools, based on hypertext structure analysis.In many hypertext systems authors are encouraged to create hierarchical structures, but when writing, the hierarchy is lost because of the inclusion of cross-reference links. The first part of this paper looks at ways of recovering lost hierarchies and finding new ones, offering authors different views of the same hypertext. The second part helps authors by identifying properties of the hypertext document. Multiple metrics are developed including compactness and stratum. Compactness indicates the intrinsic connectedness of the hypertext, and stratum reveals to what degree the hypertext is organized so that some nodes must be read before others.Several existing hypertexts are used to illustrate the benefits of each technique. The collection of techniques provides a multifaceted view of the hypertext, which should allow authors to reduce undesired structural complexity and create documents that readers can traverse more easily.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {142–180},
numpages = {39},
keywords = {hierarchies, structural analysis, graph theory, metrics, hypertext}
}

@article{10.1145/146802.146810,
author = {Krovetz, Robert and Croft, W. Bruce},
title = {Lexical Ambiguity and Information Retrieval},
year = {1992},
issue_date = {April 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/146802.146810},
doi = {10.1145/146802.146810},
abstract = {Lexical ambiguity is a pervasive problem in natural language processing. However, little quantitative information is available about the extent of the problem or about the impact that it has on information retrieval systems. We report on an analysis of lexical ambiguity in information retrieval test collections and on experiments to determine the utility of word meanings for separating relevant from nonrelevant documents. The experiments show that there is considerable ambiguity even in a specialized database. Word senses provide a significant separation between relevant and nonrelevant documents, but several factors contribute to determining whether disambiguation will make an improvement in performance. For example, resolving lexical ambiguity was found to have little impact on retrieval effectiveness for documents that have many words in common with the query. Other uses of word sense disambiguation in an information retrieval context are discussed.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {115–141},
numpages = {27},
keywords = {word senses, document retrieval, semantically based search, disambiguation}
}

@article{10.1145/128756.128761,
author = {Wiecha, Charles},
title = {ITS and User Interface Consistency: A Response to Grudin},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/128756.128761},
doi = {10.1145/128756.128761},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {112–114},
numpages = {3}
}

@article{10.1145/128756.128760,
author = {Grudin, Jonathan},
title = {Consistency, Standards, and Formal Approaches to Interface Development and Evaluation: A Note on Wiecha, Bennett, Boies, Gould, and Greene},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/128756.128760},
doi = {10.1145/128756.128760},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {103–111},
numpages = {9}
}

@article{10.1145/128756.128759,
author = {Want, Roy and Hopper, Andy and Falc\~{a}o, Veronica and Gibbons, Jonathan},
title = {The Active Badge Location System},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/128756.128759},
doi = {10.1145/128756.128759},
abstract = {A novel system for the location of people in an office environment is described. Members of staff wear badges that transmit signals providing information about their location to a centralized location service, through a network of sensors. The paper also examines alternative location techniques, system design issues and applications, particularly relating to telephone call routing. Location systems raise concerns about the privacy of an individual and these issues are also addressed.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {91–102},
numpages = {12},
keywords = {active badges, tagging systems, location systems, privacy issues, PBX}
}

@article{10.1145/128756.128758,
author = {Gemmell, Jim and Christodoulakis, Stavros},
title = {Principles of Delay-Sensitive Multimedia Data Storage Retrieval},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/128756.128758},
doi = {10.1145/128756.128758},
abstract = {This paper establishes some fundamental principles for the retrieval and storage of delay-sensitive multimedia data. Delay-sensitive data include digital audio, animations, and video. Retrieval of these data types from secondary storage has to satisfy certain time constraints in order to be acceptable to the user. The presentation is based on digital audio in order to provide intuition to the reader, although the results are applicable to all delay-sensitive data. A theoretical framework is developed for the real-time requirements of digital audio playback. We show how to describe these requirements in terms of the consumption rate of the audio data and the nature of the data-retrieval rate from secondary storage. Making use of this framework, bounds are derived for buffer space requirements for certain common retrieval scenarios. Storage placement strategies for multichannel synchronized data are then categorized and examined. The results presented in this paper are basic to any playback of delay-sensitive data and should assist the multimedia system designer in estimating hardware requirements and in evaluating possible design choices.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {51–90},
numpages = {40},
keywords = {real-time, delay-sensitive, continuous media}
}

@article{10.1145/128756.128757,
author = {Jarke, M. and Mylopoulos, J. and Schmidt, J. W. and Vassiliou, Y.},
title = {DAIDA: An Environment for Evolving Information Systems},
year = {1992},
issue_date = {Jan. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/128756.128757},
doi = {10.1145/128756.128757},
abstract = {We present a framework for the development of information systems based on the premise that the knowledge that influences the development process needs to somehow be captured, represented, and managed if the development process is to be rationalized. Experiences with a prototype environment developed in ESPRIT project DAIDA demonstrate the approach. The project has implemented an environment based on state-of-the-art languages for requirements modeling, design and implementation of information systems. In addition, the environment offers tools for aiding the mapping process from requirements to design and then to implementation, also for representing decisions reached during the development process. The development process itself is represented explicitly within the system, thus making the DAIDA development framework easier to comprehend, use, and modify.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–50},
numpages = {50},
keywords = {knowledge engineering, software information system, mapping assistant, software process model, multi-level specification, repository}
}

@article{10.1145/119311.119315,
author = {Kacmar, Charles J. and Leggett, John J.},
title = {PROXHY: A Process-Oriented Extensible Hypertext Architecture},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/119311.119315},
doi = {10.1145/119311.119315},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {399–419},
numpages = {21}
}

@article{10.1145/119311.119314,
author = {Hart, Paul and Estrin, Deborah},
title = {Inter-Organization Networks, Computer Integration, and Shifts in Interdependence: The Case of the Semiconductor Industry},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/119311.119314},
doi = {10.1145/119311.119314},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {370–398},
numpages = {29}
}

@article{10.1145/119311.119313,
author = {Zezula, P. and Rabitti, F. and Tiberio, P.},
title = {Dynamic Partitioning of Signature Files},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/119311.119313},
doi = {10.1145/119311.119313},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {336–367},
numpages = {32}
}

@article{10.1145/119311.119312,
author = {Siochi, Antonio C. and Ehrich, Roger W.},
title = {Computer Analysis of User Interfaces Based on Repetition in Transcripts of User Sessions},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/119311.119312},
doi = {10.1145/119311.119312},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {309–335},
numpages = {27}
}

@article{10.1145/125187.125200,
author = {Fox, Edward A. and Chen, Qi Fan and Daoud, Amjad M. and Heath, Lenwood S.},
title = {Order-Preserving Minimal Perfect Hash Functions and Information Retrieval},
year = {1991},
issue_date = {July 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/125187.125200},
doi = {10.1145/125187.125200},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {281–308},
numpages = {28},
keywords = {Dictionary structure, inverted file structures, perfect hashing, minimal perfect hashing, indexing, random graph}
}

@article{10.1145/125187.125193,
author = {Gauch, Susan and Smith, John B.},
title = {Search Improvement via Automatic Query Reformulation},
year = {1991},
issue_date = {July 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/125187.125193},
doi = {10.1145/125187.125193},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {249–280},
numpages = {32},
keywords = {Expert Systems, textbases, query reformulation, online search assistance, full-text information retrieval}
}

@article{10.1145/125187.125189,
author = {Fuhr, Norbert and Buckley, Chris},
title = {A Probabilistic Learning Approach for Document Indexing},
year = {1991},
issue_date = {July 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/125187.125189},
doi = {10.1145/125187.125189},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {223–248},
numpages = {26},
keywords = {relevance descriptions, linear retrieval functions, linear indexing functions, probabilistic retrieval, probabilistic indexing, complex document representation}
}

@article{10.1145/125187.125188,
author = {Turtle, Howard and Croft, W. Bruce},
title = {Evaluation of an Inference Network-Based Retrieval Model},
year = {1991},
issue_date = {July 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/125187.125188},
doi = {10.1145/125187.125188},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {187–222},
numpages = {36},
keywords = {document retrieval, network retrieval models, inference networks}
}

@article{10.1145/123078.128729,
author = {Tang, John C. and Minneman, Scott L.},
title = {Videodraw: A Video Interface for Collaborative Drawing},
year = {1991},
issue_date = {April 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/123078.128729},
doi = {10.1145/123078.128729},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {170–184},
numpages = {15},
keywords = {gestural interfaces, shared drawing, user interface, video technology, work practice analysis, colloborative systems}
}

@article{10.1145/123078.128728,
author = {Jacob, Robert J. K.},
title = {The Use of Eye Movements in Human-Computer Interaction Techniques: What You Look at is What You Get},
year = {1991},
issue_date = {April 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/123078.128728},
doi = {10.1145/123078.128728},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {152–169},
numpages = {18},
keywords = {human-computer interaction, input, eye movements, UIMS, eye tracking, state transition diagram}
}

@article{10.1145/123078.128727,
author = {Fischer, Gerhard and Lemke, Andreas C. and Mastaglio, Thomas and Morch, Andres I.},
title = {The Role of Critiquing in Cooperative Problem Solving},
year = {1991},
issue_date = {April 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/123078.128727},
doi = {10.1145/123078.128727},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {123–151},
numpages = {29},
keywords = {high-functionality computer systems, intelligent support systems, design environments, critics, cooperative problem-solving systems, critiquing}
}

@article{10.1145/123078.128726,
author = {Card, Stuart K. and Mackinlay, Jock D. and Robertson, George G.},
title = {A Morphological Analysis of the Design Space of Input Devices},
year = {1991},
issue_date = {April 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/123078.128726},
doi = {10.1145/123078.128726},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {99–122},
numpages = {24},
keywords = {design rationale, design space, input devices, morphological analysis, design knowledge sytematization, semantics}
}

@article{10.1145/103731.103735,
author = {Aiken, Milam W. and Liu Sheng, Olivia R. and Vogel, Douglas R.},
title = {Integrating Expert Systems with Group Decision Support Systems},
year = {1991},
issue_date = {Jan. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/103731.103735},
doi = {10.1145/103731.103735},
abstract = {Expert systems are powerful tools that serve as adjuncts to decision making and have found wide applicability in a wide variety of areas. Integrating expert systems with group decision support systems has the potential to enhance the quality and effeciency of group communication, negotiation, and collaborative work. This paper examines possible synergies between the two technologies and provides a survey of current partially-integrated systems. Finally, a prototype design of a highly-integrated system is described with directions for further research.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {75–95},
numpages = {21},
keywords = {expert systems, group decision support systems, artificial intelligence, knowledge-based systems}
}

@article{10.1145/103731.103734,
author = {Mak, Victor Wing-Kit and Lee, Kuo Chu and Frieder, Ophir},
title = {Exploiting Parallelism in Pattern Matching: An Information Retrieval Application},
year = {1991},
issue_date = {Jan. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/103731.103734},
doi = {10.1145/103731.103734},
abstract = {We propose a document-searching architecture based on high-speed hardware pattern matching to increase the throughput of an information retrieval system. We also propose a new parallel VLSI pattern-matching algorithm called the Data Parallel Pattern Matching (DPPM) algorithm, which serially broadcasts and compares the pattern to a block of data in parallel. The DPPM algorithm utilizes the high degree of integration of VLSI technology to attain very high-speed processing through parallelism. Performance of the DPPM has been evaluated both analytically and by simulation. Based on the simulation statistics and timing analysis on the hardware design, a search rate of multiple gigabytes per second is achievable using 2-μm CMOS technology. The potential performance of the proposed  document-searching architecture is also analyzed using the simulation statistics of the DPPM algorithm.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {52–74},
numpages = {23},
keywords = {pattern matcher, DPPM}
}

@article{10.1145/103731.103733,
author = {Kim, Won and Ballou, Nat and Garza, Jorge F. and Woelk, Darrell},
title = {A Distributed Object-Oriented Database System Supporting Shared and Private Databases},
year = {1991},
issue_date = {Jan. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/103731.103733},
doi = {10.1145/103731.103733},
abstract = {ORION-2 is a commercially available, federated, object-oriented database management system designed and implemented at MCC. One major architectural innovation in ORION-2 is the coexistence of a shared databese and a number of private databases. The shared database is accessible to all authorized users of the system, while each private database is accessible to only the user who owns it. A distributed database system with a shared database and private databases for individual users is a natural architecture for data-intensive application environments on a network of workstations, notably computer-aided design and engineering systems. This paper discusses the benefits and limitations of such a system and explores the impact of such an architecture on the semantics and implementation of some of the key functions of a database system, notably queries, database schema, and versions. Although the issues are discussed in the context of an object-oriented data model, the results (at least significant portions thereof) are applicable to database systems supporting other data models.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {31–51},
numpages = {21},
keywords = {federated databases, client-server architecture, object-oriented databases}
}

@article{10.1145/103731.103732,
author = {Ford, Daniel Alexander and Christodoulakis, Stavros},
title = {Optimal Placement of High-Probability Randomly Retrieved Blocks on CLV Optical Discs},
year = {1991},
issue_date = {Jan. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/103731.103732},
doi = {10.1145/103731.103732},
abstract = {Optimal data placement on a CLV (Constant Linear Velocity) format optical discs has an objective the minimization of the expected access cost of data retrievals from the disc when the probabilities of access of data items may be different. The problem of optimal data placement for optical discs is both important and more difficult than the corresponding problem on magnetic discs. A good data placement on optical discs is more important because data sets on optical discs such as WORM and CD ROM cannot be modified or moved once they are placed on disc. Currently, even rewritable optical discs are best suited for applications that are archival in nature. The problem of optimal data placement on CLV format optical discs is more difficult, mainly because the useful storage space is not  uniformly distributed across the disc surface (along the radius). This leads to a complicated positional performance trade-off not present for magnetic disks.We present a model that encompasses all the important aspects of the placement problem on CLV format optical discs. The model takes into account the nonuniform distribution of useful storage, the dependency of the rotational delay on disc position, a  parameterized seek cost function for optical discs, and the varying access probabilities of data items. We show that the optimal placement of high-probability blocks satisfies a unimodality property. Based on this observation, we solve the optimal placement problem. We then study the impact of the relative weights of the problem parameters and show that the optimal data  placement may be very different from the optimal data placement on magnetic disks. We also validate our model and analysis and give an algorithm for computing the placement of disc sectors.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–30},
numpages = {30},
keywords = {performance, management}
}

@article{10.1145/102675.102678,
author = {Straube, David D. and \"{O}zsu, M. Tamer},
title = {Queries and Query Processing in Object-Oriented Database Systems},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/102675.102678},
doi = {10.1145/102675.102678},
abstract = {Object-oriented database mangement systems (OODBMS) combine the data abstraction and computational models of object-oriented programming languages with the query and performance capabilities of database management systems. A concise, formal data model for OODBMS has not been universally accepted, preventing detailed investigation of various system issues such as query processing. We define a data model that captures the essence of classification-based object-oriented systems and formalize concepts such as object identity, inheritence, and methods. The main topic of the paper is the presentation of a query processing methodology complete with an object calculus to object algebra translation are discussed in detail. The paper concludes with a discussion of equivalence-preserving     transformation rules for object algebra expressions.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {387–430},
numpages = {44},
keywords = {object-oriented databases, query transformation rules, object algebra, object calculus}
}

@article{10.1145/102675.102677,
author = {Kwok, K. L.},
title = {Experiments with a Component Theory of Probabilistic Information Retrieval Based on Single Terms as Document Components},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/102675.102677},
doi = {10.1145/102675.102677},
abstract = {A component theory of information retrieval using single content terms as component for queries and documents was reviewed and experimented with. The theory has the advantages of being able to (1) bootstrap itself, that is, define initial term weights naturally based on the fact that items are self relevent; (2) make use of within-item term frequencies; (3) account for query-focused and document-focused indexing and retrieval strategies cooperatively; and (4) allow for component-specific feedback if such information is available. Retrieval results with four collections support the effectiveness of all the first three aspects, except for predictive retrieval. At the initial indexing stage, the retrieval theory performed much more consistantly across collections than croft's model and   provided results comparable to Salton's tf*idf approach. An inverse collection term frequency (ICTF) formula was also tested that performed much better than the inverse document frequency (IDF). With full feedback retrospective retrieval, the component theory performed substantially better than Croft's, because of the highly specific nature of document-focused feedback. Repetitive retireval results with partial relevance feedback mirrored those for the retrospective. However, for the important case of predictive retrieval using residual ranking, results were not unequivocal.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {363–386},
numpages = {24},
keywords = {document-focused and query-focused relevance feedback, probabilistic retrieval, inverse collection term frequency weighting, probabilistic indexing, ranking and weighting of composite objects, indexing and retrieval, inverse document frequency weighting}
}

@article{10.1145/102675.102676,
author = {Mylopoulos, John and Borgida, Alex and Jarke, Matthias and Koubarakis, Manolis},
title = {Telos: Representing Knowledge about Information Systems},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/102675.102676},
doi = {10.1145/102675.102676},
abstract = {We describe Telos, a language intended to support the development of information systems. The design principles for the language are based on the premise that information system development is knowledge intensive and that the primary responsibility of any language intended for the task is to be able to formally represent the relevent knowledge. Accordingly, the proposed language is founded on concepts from knowledge representations. Indeed, the language is appropriate for representing knowledge about a variety of worlds related to a particular information system, such as the subject world (application domain), the usage world (user models, environments), the system world (software requirements, design), and the development world (teams, metodologies).We introduce the   features of the language through examples, focusing on those provided for desribing metaconcepts that can then be used to describe knowledge relevant to a particular information system. Telos' fetures include an object-centered framework which supports aggregation, generalization, and classification; a novel treatment of attributes; an explicit representation of time; and facilities for specifying integrity constraints and deductive rules. We review actual applications of the language through further examples, and we sketch a formalization of the language.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {325–362},
numpages = {38},
keywords = {proposition, deductive rules, instance, belief time, history time, integrity constraints, class, knowledge base, temporal knowledge, metaclass}
}

@article{10.1145/98188.98204,
author = {Myers, Brad A.},
title = {A New Model for Handling Input},
year = {1990},
issue_date = {July 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/98188.98204},
doi = {10.1145/98188.98204},
abstract = {Although there has been important progress in models and packages for the output of graphics to computer screens, there has been little change in the way that input from the mouse, keyboard, and other input devices is handled. New graphics standards are still using a fifteen-year-old model even though it is widely accepted as inadequate, and most modern window managers simply return a stream of low-level, device-dependent input events. This paper presents a new model that handles input devices for highly interactive, direct manipulation, graphical user interfaces, which could be used in future toolkits, window managers, and graphics standards. This model encapsulates interactive behaviors into a few “Interactor” object types. Application  programs can then create instances of these Interactor objects which hide the details of the underlying window manager events. In addition, Interactors allow a clean separation between the input handling, the graphics, and the application programs. This model has been extensively used as part of the Garnet system and has proven to be convenient, efficient, and easy to learn.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {289–320},
numpages = {32}
}

@article{10.1145/98188.98201,
author = {Hudson, Scott E. and Mohamed, Shamim P.},
title = {Interactive Specification of Flexible User Interface Displays},
year = {1990},
issue_date = {July 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/98188.98201},
doi = {10.1145/98188.98201},
abstract = {One of the problems with conventional UIMSs is that very often there is no graphical way to specify interfaces. This paper describes OPUS, the user interface editor of the Penguims UIMS. This system allows the presentation component of graphical user interfaces to be specified interactively in a graphical notation without explicit programming. The Penguims UIMS supports an underlying model of computation based loosely on spreadsheets. In particular, it supports incremental computations based on a system of equations (one-way constraints) over a set of named values (spreadsheet cells). These equations are used to provide immediate feedback at all levels of the interface. They are used to incrementally determine the position and dynamic appearance of    the individual interactor objects that make up the interface. They are also used to connect the presentation directly to underlying application data thereby supporting semantic feedback. The OPUS user interface editor employs a special graphical notation for specifying the presentation component of a user interface. This notation allows the power of the underlying computational model to be expressed simply and quickly. The resulting presentations are very flexible in nature. They can automatically respond to changes in the size and position of display objects and can directly support derivation of their appearance from application data objects.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {269–288},
numpages = {20}
}

@article{10.1145/98188.98197,
author = {Vlissides, John M. and Linton, Mark A.},
title = {Unidraw: A Framework for Building Domain-Specific Graphical Editors},
year = {1990},
issue_date = {July 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/98188.98197},
doi = {10.1145/98188.98197},
abstract = {Unidraw is a framework for creating graphical editors in domains such as technical and artistic drawing, music composition, and circuit design. The Unidraw architecture simplifies the construction of these editors by proving programming abstractions that are common across domains. Unidraw defines four basic abstractions: components define operations on components, and external representations define the mapping between components and the file format generated by the editor. Unidraw also supports multiple views, graphical connectivity, and dataflow between components. This paper describes the Unidraw design, implementation issues, and three experimental domain specific editors we have developed with Unidraw: a drawing editor, a user interface builder,  and a schematic capture system. Our results indicate a substantial reduction in implementation time and effort compared with existing tools.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {237–268},
numpages = {32}
}

@article{10.1145/98188.98194,
author = {Wiecha, Charles and Bennett, William and Boies, Stephen and Gould, John and Greene, Sharon},
title = {ITS: A Tool for Rapidly Developing Interactive Applications},
year = {1990},
issue_date = {July 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/98188.98194},
doi = {10.1145/98188.98194},
abstract = {The ITS architecture separates applications into four layers. The action layer implements back-end application functions. The dialog layer defines the content of the user interface, independent of its style. Content specifies the objects included in each frame of the interface, the flow of control among frames, and what actions are associated with each object. The style rule layer defines the presentation and behavior of a family of interaction techniques. Finally, the style program layer implements primitive toolkit objects that are composed by the rule layer into complete interaction techniques. This paper describes the architecture in detail, compares it with previous User Interface Management systems and toolkits, and describes how ITS is being used to implement the visitor  information system for EXPO '92.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {204–236},
numpages = {33}
}

@article{10.1145/98188.98191,
author = {Hartson, H. Rex and Siochi, Antonio C. and Hix, D.},
title = {The UAN: A User-Oriented Representation for Direct Manipulation Interface Designs},
year = {1990},
issue_date = {July 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/98188.98191},
doi = {10.1145/98188.98191},
abstract = {Many existing interface representation techniques, especially those associated with UIMS, are constructional and focused on interface implementation, and therefore do not adequately support a user-centered focus. But it is in the behavioral domain of the user that interface designers and evaluators do their work. We are seeking to complement constructional methods by providing a tool-supported technique capable of specifying the behavioral aspects of an interactive system–the tasks and the actions a user performs to accomplish those tasks. In particular, this paper is a practical introduction to use of the User Action Notation (UAN), a task- and user-oriented notation for behavioral representation of asynchronous, direct manipulation interface    designs. Interfaces are specified in UAN as a quasihierarchy of asynchronous tasks. At the lower levels, user actions are associated with feedback and system state changes. The notation makes use of visually onomatopoeic symbols and is simple enough to read with little instruction. UAN is being used by growing numbers of interface developers and researchers. In addition to its design role, current research is investigating how UAN can support production and maintenance of code and documentation.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {181–203},
numpages = {23}
}

@article{10.1145/96105.96113,
author = {Morrissey, J. M.},
title = {Imprecise Information and Uncertainty in Information Systems},
year = {1990},
issue_date = {Apr. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/96105.96113},
doi = {10.1145/96105.96113},
abstract = {Information systems exist to model, store, and retrieve all types of data. Problems arise when some of the data are missing or imprecisely known or when an attribute is not applicable to a particular object. A consistent and useful treatment of such exceptions is necessary. The approach taken here is to allow any attribute value to be a regular precise value, a string denoting that the value is missing, a string denoting that the attribute is not applicable, or an imprecise value. The imprecise values introduce uncertainty into query evaluation, since it is no longer obvious which objects should be retrieved. To handle the uncertainty, two set of objects are retrieved in response to every query: the set of objects that are known to satisfy with complete certainty and the set that possibly satisfies the query with various degrees of uncertainty. Two methods of estimating this uncertainty, based on information theory, are proposed. The measure of uncertainty is used to rank objects for presentation to a user.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {159–180},
numpages = {22}
}

@article{10.1145/96105.96111,
author = {Shasha, Dennis and Wang, Tsong-Li},
title = {New Techniques for Best-Match Retrieval},
year = {1990},
issue_date = {Apr. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/96105.96111},
doi = {10.1145/96105.96111},
abstract = {A scheme to answer best-match queries from a file containing a collection of objects is described. A best-match query is to find the objects in the file that are closest (according to some (dis)similarity measure) to a given target.Previous work [5, 331] suggests that one can reduce the number of comparisons required to achieve the desired results using the triangle inequality, starting with a data structure for the file that reflects some precomputed intrafile distances. We generalize the technique to allow the optimum use of any given set of precomputed intrafile distances. Some empirical results are presented which illustrate the effectiveness of our scheme, and its performance relative to previous algorithms.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {140–158},
numpages = {19}
}

@article{10.1145/96105.96109,
author = {Moss, J. Eliot B.},
title = {Design of the Mneme Persistent Object Store},
year = {1990},
issue_date = {Apr. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/96105.96109},
doi = {10.1145/96105.96109},
abstract = {The Mneme project is an investigation of techniques for integrating programming language and database features to provide better support for cooperative, information-intensive tasks such as computer-aided software engineering. The project strategy is to implement efficient, distributed, persistent programming languages. We report here on the Mneme persistent object store, a fundamental component of the project, discussing its design and initial prototype. Mneme stores objects in a simple and general format, preserving object identity and object interrelationships. Specific goals for the store include portability, extensibility (especially with respect to object management policies), and performance. The model of memory that the store aims at is a single, cooperatively-shared heap, distributed across a collection of networked computers. The initial prototype is intended mainly to explore performance issues and to support object-oriented persistent programming languages. We include performance measurements from the prototype as well as more qualitative results.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {103–139},
numpages = {37}
}

@article{10.1145/96105.96107,
author = {Watters, Carolyn and Shepherd, Michael A.},
title = {A Transient Hypergraph-Based Model for Data Access},
year = {1990},
issue_date = {Apr. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/96105.96107},
doi = {10.1145/96105.96107},
abstract = {Two major methods of accessing data in current database systems are querying and browsing. The more traditional query method returns an answer set that may consist of data values (DBMS), items containing the answer (full text), or items referring the user to items containing the answer (bibliographic). Browsing within a database, as best exemplified by hypertext systems, consists of viewing a database item and linking to related items on the basis of some attribute or attribute value.A model of data access has been developed that supports both query and browse access methods. The model is based on hypergraph representation of data instances. The hyperedges and nodes are manipulated through a set of operators to compose new nodes and to instantiate new links dynamically, resulting in transient hypergraphs. These transient hypergraphs are virtual structures created in response to user queries, and lasting only as long as the query session. The model provides a framework for general data access that accommodates user-directed browsing and querying, as well as traditional models of information and data retrieval, such as the Boolean, vector space, and probabilistic models. Finally, the relational database model is shown to provide a reasonable platform for the implementation of this transient hypergraph-based model of data access.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {77–102},
numpages = {26}
}

@article{10.1145/78915.78918,
author = {H\"{a}mm\"{a}inen, Heikki and Eloranta, Eero and Alasuvanto, Jari},
title = {Distributed Form Management},
year = {1990},
issue_date = {Jan. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/78915.78918},
doi = {10.1145/78915.78918},
abstract = {An open architecture for distributed form management is described. The model employs object-orientation in describing organizational units as well as individual users as entities with uniform external interfaces. Each entity is represented by an autonomous user agent which operates on local and migrating forms. The form concept encapsulates data, layout, and rules into a unified object which is the basic unit of presentation, processing, storage, and communication. All functionality of the system appears in rules of form classes and all data in instances of these form classes. This approach applies the techniques of computer supported cooperative work to provide a flexible mechanism for interpersonal, intraoffice, and interoffice procedures. The main challenge is to organize the collaboration without affecting the autonomy of individual user agents. In this respect, the contribution of the model is the mechanism for form migration. The dynamic integration of forms into different agents is solved with the coordinated interchange of form classes. A specific inheritance scheme provides the desired flexibility by separating the interrelated private and public form operations within each agent. The paper first describes the architecture by starting from a single agent and moving progressively towards a set of cooperating agents. Then an agent implementation called PAGES is described, experiences reported, and the open issues discussed. A typical distributed ordering procedure is used as an example throughout the text.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {50–76},
numpages = {27}
}

@article{10.1145/78915.78917,
author = {Bookstein, Abraham and Klein, Shmuel T.},
title = {Compression, Information Theory, and Grammars: A Unified Approach},
year = {1990},
issue_date = {Jan. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/78915.78917},
doi = {10.1145/78915.78917},
abstract = {Text compression is of considerable theoretical and practical interest. It is, for example, becoming increasingly important for satisfying the requirements of fitting a large database onto a single CD-ROM. Many of the compression techniques discussed in the literature are model based. We here propose the notion of a formal grammar as a flexible model of text generation that encompasses most of the models offered before as well as, in principle, extending the possibility of compression to a much more general class of languages. Assuming a general model of text generation, a derivation is given of the well known Shannon entropy formula, making possible a theory of information based upon text representation rather than on communication. The ideas are shown to apply to a number of commonly used text models. Finally, we focus on a Markov model of text generation, suggest an information theoretic measure of similarity between two probability distributions, and develop a clustering algorithm based on this measure. This algorithm allows us to cluster Markov states, and thereby base our compression algorithm on a smaller number of probability distributions than would otherwise have been required. A number of theoretical consequences of this approach to compression are explored, and a detailed example is given.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {27–49},
numpages = {23}
}

@article{10.1145/78915.78916,
author = {Lee, Jintae and Malone, Thomas W.},
title = {Partially Shared Views: A Scheme for Communicating among Groups That Use Different Type Hierarchies},
year = {1990},
issue_date = {Jan. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/78915.78916},
doi = {10.1145/78915.78916},
abstract = {Many computer systems are based on various types of messages, forms, or other objects. When users of such systems need to communicate with people who use different object types, some kind of translation is necessary. In this paper, we explore the space of general solutions to this translation problem and propose a scheme that synthesizes these solutions. After first illustrating the problem in the Object Lens system, we identify two partly conflicting objectives that any translation scheme should satisfy: preservation of meaning and autonomous evolution of group languages. Then we partition the space of possible solutions to this problem in terms of the set theoretic relations between group languages and a common language. This leads to five primary solution classes and we illustrate and evaluate each one. Finally, we describe a composite scheme, called Partially Shared Views, that combines many of the best features of the other schemes. A key insight of the analysis is that partially shared type hierarchies allow “foreign” object types to be automatically translated into their nearest common “ancestor” types. The partial interoperability attained in this way makes possible flexible standards from which people can benefit from whatever agreements they do have without having to agree on everything. Even though our examples deal primarily with extensions to the Object Lens system, the analysis also suggests how other kinds of systems, such as EDI applications, might exploit specialization hierarchies of object types to simplify the translation problem.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–26},
numpages = {26}
}

@article{10.1145/76158.76893,
author = {Pernici, B. and Barbic, F. and Maiocchi, R. and Fugini, M. G. and Rames, J. R. and Rolland, C.},
title = {C-TODOS: An Automatic Tool for Office System Conceptual Design},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/76158.76893},
doi = {10.1145/76158.76893},
abstract = {Designers of office information systems, which share various features with information systems and software development, need to carefully consider special issues such as document and communication flows, user roles, user interfaces, and available technology.The ESPRIT Project, Automatic TOols for Designing Office Information Systems (TODOS), proposes an integrated environment for office design with tools for requirements collection and analysis, conceptual design, rapid prototyping, and architecture selection.Conceptual design is a central phase of office system design: It provides correct and complete functional requirements from which the office prototype will be developed and the final architecture chosen. C-TODOS, the conceptual design support tool developed within TODOS, is presented in this paper. The purpose of C-TODOS is to give the designer tools for supporting conceptual modeling activities with the goal of obtaining correct, consistent, and good quality office-functional specifications.This paper presents C-TODOS within the TODOS development environment and describes the basic features of the tool: the TODOS Conceptual Model, the Specification Database, and the Modeling, Query and Consistency Checking Modules. The use of C-TODOS, through illustration of the development of a test case, and possible future research are discussed.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {378–419},
numpages = {42}
}

@article{10.1145/76158.76892,
author = {Afsarmanesh, Hamideh and McLeod, Dennis},
title = {The 3DIS: An Extensible Object-Oriented Information Management Environment},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/76158.76892},
doi = {10.1145/76158.76892},
abstract = {The 3-Dimensional Information Space (3DIS) is an extensible object-oriented framework for information management. It is specifically oriented toward supporting the database requirements for data-intensive information system applications in which (1) information objects of various levels of abstraction and modalities must be accommodated, (2) descriptive and structural information (metadata) is rich and dynamic, and (3) users who are not database experts must be able to design, manipulate, and evolve databases. In response to these needs, the 3DIS provides an approach in which data and the descriptive information about data are handled uniformly in an extensible framework. The 3DIS provides a simple, geometric, and formal representation of data which forms a basis for understanding, defining, and manipulating databases. Several prototype implementations based upon the 3DIS have been designed and implemented and are in experimental use.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {339–377},
numpages = {39}
}

@article{10.1145/76158.76891,
author = {Olson, Margrethe H.},
title = {Work at Home for Computer Professionals: Current Attitudes and Future Prospects},
year = {1989},
issue_date = {Oct. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/76158.76891},
doi = {10.1145/76158.76891},
abstract = {The subject of this paper is work performed in the home with computer and communications technology, also known as telecommuting. The article reports on two studies of work at home: a quasi-experimental field study of organizational telecommuting pilot programs, and an attitude survey comparing computer professionals who work at home to employees doing similar jobs in traditional office settings. The results of the field study demonstrated that working in the home had little impact on employee performance; however, supervisors were not comfortable with remote workers and preferred their employees to be on site. In the survey, work in the home was related to lower job satisfaction, lower organizational commitment, and higher role conflict. The survey also included computer professionals who worked at home in addition to the regular work day. The author suggests that performing additional unpaid work in the home after regular work hours may be an important trend that merits further investigation. The studies demonstrate that while computer and communications technology have the potential to relax constraints on information work in terms of space and time, in today's traditional work environments, corporate culture and management style limit acceptance of telecommuting as a substitute for office work.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {317–338},
numpages = {22}
}

@article{10.1145/65943.65949,
author = {Metzler, Douglas P. and Haas, Stephanie W.},
title = {The Constituent Object Parser: Syntactic Structure Matching for Information Retrieval},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/65943.65949},
doi = {10.1145/65943.65949},
abstract = {The Constituent Object Parser is a shallow syntactic parser designed to produce dependency tree representations of syntactic structure that can be used to specify the intended meanings of a sentence more precisely than can the key terms of the sentence alone. It is intended to improve the precision/recall performance of information retrieval and similar text processing applications by providing more powerful matching procedures. The dependency tree representation and the relationship between the intended use of this parser and its design is described, and several problems concerning the processing of ambiguous structures are discussed.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {292–316},
numpages = {25}
}

@article{10.1145/65943.65948,
author = {Campagnoni, F. R. and Ehrlich, Kate},
title = {Information Retrieval Using a Hypertext-Based Help System},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/65943.65948},
doi = {10.1145/65943.65948},
abstract = {Hypertext offers users a simple, flexible way to navigate through electronic information systems but at the potential risk of becoming lost in the network of interconnected pieces of information. A study was conducted on information retrieval using a commercial hypertext-based help system. It was found that the predominant search strategy was “browsing” (characterized by scanning tables of contents and paging through topics), rather than employing the indexes ("analytical search"). Although subjects did not get lost, individuals with better spatial visualization skills, as measured by a standardized test, were faster at retrieving information and returned to the top of the information hierarchy less often than those with poorer spatial visualization skills. These results support previous studies that have found a strong preference by users for browsing in hypertext systems and extend those findings to a new domain (help), a different type of user interface, and a different information architecture. In addition, the results demonstrate the importance of spatial visualization ability for efficient navigation and information retrieval in a hierarchical hypertext system.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {271–291},
numpages = {21}
}

@article{10.1145/65943.65947,
author = {Smith, Philip J. and Shute, Steven J. and Galdes, Beb and Chignell, Mark H.},
title = {Knowledge-Based Search Tactics for an Intelligent Intermediary System},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/65943.65947},
doi = {10.1145/65943.65947},
abstract = {Research on the nature of knowledge-based systems for bibliographic information retrieval is summarized. Knowledge-based search tactics are then considered in terms of their role in the functioning of a semantically based search system for bibliographic information retrieval, EP-X. This system uses such tactics to actively assist users in defining or refining their topics of interest. It does so by applying these tactics to a knowledge base describing topics in a particular domain and to a database describing the contents of individual documents in terms of these topics. This paper, then, focuses on the two central concepts behind EP-X: semantically based search and knowledge-based search tactics.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {246–270},
numpages = {25}
}

@article{10.1145/65943.65946,
author = {Klein, Shmuel T. and Bookstein, Abraham and Deerwester, Scott},
title = {Storing Text Retrieval Systems on CD-ROM: Compression and Encryption Considerations},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/65943.65946},
doi = {10.1145/65943.65946},
abstract = {The emergence of the CD-ROM as a storage medium for full-text databases raises the question of the maximum size database that can be contained by this medium. As an example, the problem of storing the Tr\'{e}sor de la Langue Fran\c{c}aise on a CD-ROM is examined in this paper. The text alone of this database is 700 megabytes long, more than a CD-ROM can hold. In addition, the dictionary and concordance needed to access these data must be stored. A further constraint is that some of the material is copyrighted, and it is desirable that such material be difficult to decode except through software provided by the system. Pertinent approaches to compression of the various files are reviewed, and the compression of the text is related to the problem of data encryption: Specifically, it is shown that, under simple models of text generation, Huffman encoding produces a bit-string indistinguishable from a representation of coin flips.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {230–245},
numpages = {16}
}

@article{10.1145/65943.65945,
author = {Raghavan, Vijay and Bollmann, Peter and Jung, Gwang S.},
title = {A Critical Investigation of Recall and Precision as Measures of Retrieval System Performance},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/65943.65945},
doi = {10.1145/65943.65945},
abstract = {Recall and precision are often used to evaluate the effectiveness of information retrieval systems. They are easy to define if there is a single query and if the retrieval result generated for the query is a linear ordering. However, when the retrieval results are weakly ordered, in the sense that several documents have an identical retrieval status value with respect to a query, some probabilistic notion of precision has to be introduced. Relevance probability, expected precision, and so forth, are some alternatives mentioned in the literature for this purpose. Furthermore, when many queries are to be evaluated and the retrieval results averaged over these queries, some method of interpolation of precision values at certain preselected recall levels is needed. The currently popular approaches for handling both a weak ordering and interpolation are found to be inconsistent, and the results obtained are not easy to interpret. Moreover, in cases where some alternatives are available, no comparative analysis that would facilitate the selection of a particular strategy has been provided. In this paper, we systematically investigate the various problems and issues associated with the use of recall and precision as measures of retrieval system performance. Our motivation is to provide a comparative analysis of methods available for defining precision in a probabilistic sense and to promote a better understanding of the various issues involved in retrieval performance evaluation.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {205–229},
numpages = {25}
}

@article{10.1145/65943.65944,
author = {Fuhr, Norbert},
title = {Optimum Polynomial Retrieval Functions Based on the Probability Ranking Principle},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/65943.65944},
doi = {10.1145/65943.65944},
abstract = {We show that any approach to developing optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs (fl, dm) are mapped onto description vectors x(fl, dm), and a polynomial function e(x) is developed such that it yields estimates of the probability of relevance P(R | x (fl, dm) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multivalued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models and it needs large samples of relevance feedback data for its application.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {183–204},
numpages = {22}
}

@article{10.1145/65935.65939,
author = {G\"{u}ting, Ralf Hartmut and Zicari, Roberto and Choy, David M.},
title = {An Algebra for Structured Office Documents},
year = {1989},
issue_date = {April 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/65935.65939},
doi = {10.1145/65935.65939},
abstract = {We describe a data model for structured office information objects, which we generically call “documents,” and a practically useful algebraic language for the retrieval and manipulation of such objects. Documents are viewed as hierarchical structures; their layout (presentation) aspect is to be treated separately. The syntax and semantics of the language are defined precisely in terms of the formal model, an extended relational algebra.The proposed approach has several new features, some of which are particularly useful for the management of office information. The data model is based on nested sequences of tuples rather than nested relations. Therefore, sorting and sequence operations and the explicit handling of duplicates can be described by the model. Furthermore, this is the first model based on a many-sorted instead of a one-sorted algebra, which means that atomic data values as well as nested structures are objects of the algebra. As a consequence, arithmetic operations, aggregate functions, and so forth can be treated inside the model and need not be introduced as query language extensions to the model. Many-sorted algebra also allows arbitrary algebra expressions (with Boolean result) to be admitted as selection or join conditions and the results of arbitrary expressions to be embedded into tuples. In contrast to other formal models, this algebra can be used directly as a rich query language for office documents with precisely defined semantics.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {123–157},
numpages = {35}
}

@article{10.1145/65935.65937,
author = {Lee, Dik Lun and Leng, Chun-Wu},
title = {Partitioned Signature Files: Design Issues and Performance Evaluation},
year = {1989},
issue_date = {April 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/65935.65937},
doi = {10.1145/65935.65937},
abstract = {A signature file acts as a filtering mechanism to reduce the amount of text that needs to be searched for a query. Unfortunately, the signature file itself must be exhaustively searched, resulting in degraded performance for a large file size. We propose to use a deterministic algorithm to divide a signature file into partitions, each of which contains signatures with the same “key.” The signature keys in a partition can be extracted and represented as the partition's key. The search can then be confined to the subset of partitions whose keys match the query key. Our main concern here is to study methods for obtaining the keys and their performance in terms of their ability to reduce the search space.Owing to the reduction of search space, partitioning a signature file has a direct benefit in a sequential search (single-processor) environment. In a parallel environment, search can be conducted in parallel effectively by allocating one or more partitions to a processor. Partitioning the signature tile with a deterministic method (as opposed to a random partitioning scheme) provides intraquery parallelism as well as interquery parallelism.In this paper, we outline the criteria for evaluating partitioning schemes. Three algorithms are described and studied. An analytical study of the performance of the algorithms is provided and the results are verified with simulation.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {158–180},
numpages = {23}
}

@article{10.1145/65935.65936,
author = {Sciore, Edward},
title = {Object Specialization},
year = {1989},
issue_date = {April 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/65935.65936},
doi = {10.1145/65935.65936},
abstract = {Specialization hierarchies typically are treated as type-level constructs and are used to define various inheritance mechanisms. In this paper we consider specialization at the level of objects. We show that doing so creates a more flexible and powerful notion of inheritance by allowing objects to define their own inheritance path. Object specialization can also be used to model certain forms of versioning, implement data abstraction, and provide a “classless” prototype-based language interface to the user.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {103–122},
numpages = {20}
}

@article{10.1145/64789.64993,
author = {Tompa, Frank WM.},
title = {A Data Model for Flexible Hypertext Database Systems},
year = {1989},
issue_date = {Jan. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/64789.64993},
doi = {10.1145/64789.64993},
abstract = {Hypertext and other page-oriented databases cannot be schematized in the same manner as record-oriented databases. As a result, most hypertext databases implicitly employ a data model based on a simple, unrestricted graph. This paper presents a hypergraph model for maintaining page-oriented databases in such a way that some of the functionality traditionally provided by database schemes can be available to hypertext databases. In particular, the model formalizes identification of commonality in the structure, set-at-a-time database access, and definition of user-specific views. An efficient implementation of the model is also discussed.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {85–100},
numpages = {16}
}

@article{10.1145/64789.64992,
author = {Utting, Kenneth and Yankelovich, Nicole},
title = {Context and Orientation in Hypermedia Networks},
year = {1989},
issue_date = {Jan. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/64789.64992},
doi = {10.1145/64789.64992},
abstract = {The core of hypermedia's power lies in the complex networks of links that can be created within and between documents. However, these networks frequently overwhelm the user and become a source of confusion. Within Intermedia, we have developed the Web View-a tool for viewing and navigating such networks with a minimum of user confusion and disorientation. The key factors in the Web View's success are a display that combines a record of the user's path through the network with a map of the currently available links; a scope line that summarizes the number of documents and links in the network; and a set of commands that permit the user to open documents directly from the Web View.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {58–84},
numpages = {27}
}

@article{10.1145/64789.64791,
author = {Stotts, P. David and Furuta, Richard},
title = {Petri-Net-Based Hypertext: Document Structure with Browsing Semantics},
year = {1989},
issue_date = {Jan. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/64789.64791},
doi = {10.1145/64789.64791},
abstract = {We present a formal definition of the Trellis model of hypertext and describe an authoring and browsing prototype called αTrellis that is based on the model. The Trellis model not only represents the relationships that tie individual pieces of information together into a document (i.e., the adjacencies), but specifies the browsing semantics to be associated with the hypertext as well (i.e., the manner in which the information is to be visited and presented). The model is based on Petri nets, and is a generalization of existing directed graph-based forms of hypertext. The Petri net basis permits more powerful specification of what is to be displayed when a hypertext is browsed and permits application of previously developed Petri net analysis techniques to verify properties of the hypertext. A number of useful hypertext constructs, easily described in the Trellis model, are presented. These include the synchronization of simultaneous traversals of separate paths through a hypertext, the incorporation of access controls into a hypertext (i.e., specifying nodes that can be proven to be accessible only to certain classes of browsers), and construction of multiple specialized (tailored) versions from a single hypertext.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {3–29},
numpages = {27}
}

@article{10.1145/64789.64790,
author = {Egan, Dennis E. and Remde, Joel R. and Gomez, Louis M. and Landauer, Thomas K. and Eberhardt, Jennifer and Lochbaum, Carol C.},
title = {Formative Design Evaluation of Superbook},
year = {1989},
issue_date = {Jan. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/64789.64790},
doi = {10.1145/64789.64790},
abstract = {SuperBook is a hypertext browsing system designed to improve the usability of conventional documents. Successive versions of SuperBook were evaluated in a series of behavioral studies. Students searched for information in a statistics text. presented either in conventional printed form or in SuperBook form. The best version of SuperBook enabled students to answer search questions more quickly and accurately than they could with the conventional text. Students wrote higher quality “open-book” essays using SuperBook than they did with the conventional text, and their subjective ratings of the documentation strongly favored SuperBook.This work is a case study of formative design-evaluation. Behavioral evaluation of the first version of SuperBook showed how design factors and user strategies affected search and established baseline performance measures with printed text. The second version of SuperBook was implemented with the goal of improving search accuracy and speed. User strategies that had proved effective in the first study were made very easy and attractive to use. System response time for common operations was greatly improved. Behavioral evaluation of the new SuperBook demonstrated its superiority to printed text and suggested additional improvements that were incorporated into “MiteyBook,” a SuperBook implementation for PC-size screens. Search with MiteyBook proved to be approximately 25 percent faster and 25 percent more accurate than that obtained with a conventional printed book.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {30–57},
numpages = {28}
}

@article{10.1145/58566.59299,
author = {Trigg, Randall H.},
title = {Guided Tours and Tabletops: Tools for Communicating in a Hypertext Environment},
year = {1988},
issue_date = {Oct. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/58566.59299},
doi = {10.1145/58566.59299},
abstract = {The author of a complex hypertext document is often faced with the problem of conveying the document's meaning to future readers through a shared computer environment. Two tools implemented in the NoteCards hypertext environment, guided tours and tabletops, allow authors to employ annotation, graphic layout, and ordered presentation when communicating to readers. This paper describes these tools and gives examples of their use. Issues of remote pointing arising from an application in legal argumentation are discussed as well as early work on the use of these tools to support sharing of hypertext strategies among NoteCards users.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {398–414},
numpages = {17}
}

@article{10.1145/58566.59298,
author = {Lai, Kum-Yew and Malone, Thomas W. and Yu, Keh-Chiang},
title = {Object Lens: A “Spreadsheet” for Cooperative Work},
year = {1988},
issue_date = {Oct. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/58566.59298},
doi = {10.1145/58566.59298},
abstract = {Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users can represent information about people, tasks, products, messages, and many other kinds of information in a form that can be processed intelligently by both people and their computers. By collecting these objects in customizable folders, users can create their own displays which summarize selected information from the objects in table or tree formats. Finally, by creating semiautonomous agents, users can specify rules for automatically processing this information in different ways at different times.The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {332–353},
numpages = {22}
}

@article{10.1145/58566.59297,
author = {Conklin, Jeff and Begeman, Michael L.},
title = {GIBIS: A Hypertext Tool for Exploratory Policy Discussion},
year = {1988},
issue_date = {Oct. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/58566.59297},
doi = {10.1145/58566.59297},
abstract = {This paper describes an application-specific hypertext system designed to facilitate the capture of early design deliberations. It implements a specific method, called Issue Based Information Systems (IBIS), which has been developed for use on large, complex design problems. The hypertext system described here, gIBIS (for graphical IBIS), makes use of color and a high-speed relational database server to facilitate building and browsing typed IBIS networks. Further, gIBIS is designed to support the collaborative construction of these networks by any number of cooperating team members spread across a local area network. Early experiments suggest that the IBIS method is still incomplete, but there is a good match between the tool and method even in this experimental version.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {303–331},
numpages = {29}
}

@article{10.1145/58566.58568,
author = {Eveland, J. D. and Bikson, T. K.},
title = {Work Group Structures and Computer Support: A Field Experiment},
year = {1988},
issue_date = {Oct. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/58566.58568},
doi = {10.1145/58566.58568},
abstract = {It is frequently suggested that work groups that have computer technology to support activities such as text editing, data manipulation, and communication develop systematically different structures and working processes from groups that rely on more conventional technologies such as memos, phone calls, and meetings. However, cross-sectional or retrospective research designs do not allow this hypothesis to be tested with much power. This field experiment created two task forces, each composed equally of recently retired employees and employees still at work but eligible to retire. They were given the identical tasks of preparing reports for their company on retirement planning issues, but they were randomly assigned to different technology conditions. One group had full conventional office support; the other had, in addition, networked microcomputers with electronic mail and routine office software. Structured interviews were conducted four times during the year-long project; in addition, electronic mail activity was logged in the on-line group. Although both groups produced effective reports, the two differed significantly in the kind of work they produced, the group structures that emerged, and evaluations of their own performance. Although the standard group was largely dominated by the employees through the extensive reliance on informal meetings, the electronic technology used by the other task force allowed the retirees to exercise primary leverage. We conclude that use of computer support for cooperative work results in both quantitative and qualitative changes but that effective participation in such electronically supported groups requires significant investments of time and energy on the part of its members to master the technology and a relatively high level of assistance during the learning process.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {354–379},
numpages = {26}
}

@article{10.1145/58566.58567,
author = {Mackay, Wendy E.},
title = {Diversity in the Use of Electronic Mail: A Preliminary Inquiry},
year = {1988},
issue_date = {Oct. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/58566.58567},
doi = {10.1145/58566.58567},
abstract = {This paper describes a series of interviews that examine the ways that professional office workers use electronic mail to manage their daily work. The purpose is to generate hypotheses for future research. A number of implications for the design of flexible mail systems are discussed.Two principal claims are made. First, the use of electronic mail is strikingly diverse, although not infinitely so. Individuals vary both in objective measures of mail use and in preferred strategies for managing work electronically. Feelings of control are similarly diverse and are related to the size of the user's inbox, numbers of folders, and subscriptions to distribution lists. This diversity implies that one's own experiences with electronic mail are unlikely to provide sufficient understanding of other's uses of mail. Mail designers should thus seek flexible primitives that capture the important dimensions of use and provide flexibility for a wide range of users.The second claim is that electronic mail is more than just a communication system. Users archive messages for subject retrieval, prioritize messages to sequence work activities, and delegate tasks via mail. A taxonomy of work management is proposed in which mail is used for information management, time management, and task management activities. Directions for future research are suggested.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {380–397},
numpages = {18}
}

@article{10.1145/45945.48028,
author = {Neches, Robert},
title = {Knowledge-Based Tools to Promote Shared Goals and Terminology between Interface Designers},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/45945.48028},
doi = {10.1145/45945.48028},
abstract = {Two tools that support cooperation are described: one for the construction of consistent and principled human-computer interfaces and the other for the construction of AI knowledge bases. These tools provide a central repository for design knowledge that otherwise would not be easily shared among users. The AI knowledge representation technology upon which the tools are founded is first described. A knowledge-based approach to interface construction is discussed, and how that approach applies to detecting design conflicts and inconsistencies stemming from two different kinds of team communication failure is illustrated. Next, a knowledge acquisition aid that is utilized within the interface construction paradigm and that also illustrates the same approach to supporting cooperative work is described. Finally, four sources of difficulty in team design efforts, which this approach seeks to address, are reviewed.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {215–231},
numpages = {17}
}

@article{10.1145/45945.48027,
author = {Motro, Amihai},
title = {VAGUE: A User Interface to Relational Databases That Permits Vague Queries},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/45945.48027},
doi = {10.1145/45945.48027},
abstract = {A specific query establishes a rigid qualification and is concerned only with data that match it precisely. A vague query establishes a target qualification and is concerned also with data that are close to this target. Most conventional database systems cannot handle vague queries directly, forcing their users to retry specific queries repeatedly with minor modifications until they match data that are satisfactory. This article describes a system called VAGUE that can handle vague queries directly. The principal concept behind VAGUE is its extension to the relational data model with data metrics, which are definitions of distances between values of the same domain. A problem with implementing data distances is that different users may have different interpretations for the notion of distance. VAGUE incorporates several features that enable it to adapt itself to the individual views and priorities of its users.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {187–214},
numpages = {28}
}

@article{10.1145/45945.45946,
author = {Pahlavan, K.},
title = {Wireless Intraoffice Networks},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/45945.45946},
doi = {10.1145/45945.45946},
abstract = {An overview of the existing and growing demands for wireless office information networks is provided, and the existing research activities are assessed in some detail. The radio frequency (RF) and infrared (IR) communication technologies are examined as candidates for wireless intraoffice communications. The available bandwidths, according to federal regulations and characteristics of the channel for RF communications, are given. Digital narrow-band and wideband spread-spectrum RF communications are assessed in terms of supportable data rate or number of simultaneous users in one cell of a cellular architecture in an office environment. Various limitations of IR communications are discussed and existing systems and architectures are reviewed.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {277–302},
numpages = {26}
}

@article{10.1145/45945.214327,
author = {Pollock, Stephen},
title = {A Rule-Based Message Filtering System},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/45945.214327},
doi = {10.1145/45945.214327},
abstract = {Much computerized support for knowledge workers has consisted of tools to handle low-level functions such as distribution, storage, and retrieval of information. However, the higher level processes of making decisions and taking actions with respect to this information have not been supported to the same degree. This paper describes the ISCREEN prototype system for screening text messages. ISCREEN includes a high-level interface for users to define rules, a component that screens text messages, and a conflict detection component that examines rules for inconsistencies. An explanation component uses text generation to answer user queries about past or potential system actions based on Grice's conversational maxims.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {232–254},
numpages = {23}
}

@article{10.1145/45945.214325,
author = {Rice, Ronald E. and Shook, Douglas E.},
title = {Access to, Usage of, and Outcomes from an Electronic Messaging System},
year = {1988},
issue_date = {July 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/45945.214325},
doi = {10.1145/45945.214325},
abstract = {This study examines relationships among perceived accessibility to an electronic messaging system (EMS), computer-monitored and reported usage of the system by approximately 100 employees of one division of an aerospace firm, user's job type, perceived appropriateness of the EMS, and reported outcomes such as changes in effectiveness and use of paper-based media. Greater accessibility resulted in more usage and reported increases in effectiveness. Physical distance to a terminal affects the associations of other aspects of accessibility with usage and has a greater influence on these associations earlier in one's adoption process. Differences in job type showed statistically significant associations with usage, independent of the influence of accessibility. Computer-monitored and reported usage measures were only moderately correlated and were differentially associated with the access measures and with the two outcomes. The article ends by discussing implications for implementation and evaluation of computer-based communication systems, theories of media characteristics and information value, and methodological issues in using computer-monitored usage data.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {255–276},
numpages = {22}
}

@article{10.1145/45941.45944,
author = {Lee, Ronald M.},
title = {Bureaucracies as Deontic Systems},
year = {1988},
issue_date = {April 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/45941.45944},
doi = {10.1145/45941.45944},
abstract = {Bureaucratic offices are not only for clerical work, but more important, they are for officiating in the sense of issuing directives, granting permissions, enforcing prohibitions, waiving obligations, and so forth. Bureaucracies are thus deontic systems for organizational and social control. Conventional information processing approaches are inadequate for capturing these aspects of bureaucratic modeling. A logic-based representation that emphasizes deontic and performative aspects is proposed.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {87–108},
numpages = {22}
}

@article{10.1145/45941.45943,
author = {Flores, Fernando and Graves, Michael and Hartfield, Brad and Winograd, Terry},
title = {Computer Systems and the Design of Organizational Interaction},
year = {1988},
issue_date = {April 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/45941.45943},
doi = {10.1145/45941.45943},
abstract = {The goal of this paper is to relate theory to invention and application in the design of systems for organizational communication and management. We propose and illustrate a theory of design, technology, and action that we believe has been missing in the mainstream of work on office systems. At the center of our thinking is a theory of language as social action, which differs from the generally taken-for-granted understandings of what goes on in an organization. This approach has been presented elsewhere, and our aim here is to examine its practical implications and assess its effectiveness in the design of The Coordinator, a workgroup productivity system that is in widespread commercial use on personal computers.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {153–172},
numpages = {20}
}

@article{10.1145/45941.45942,
author = {Holt, Anatol W.},
title = {Diplans: A New Language for the Study and Implementation of Coordination},
year = {1988},
issue_date = {April 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/45941.45942},
doi = {10.1145/45941.45942},
abstract = {In this paper the reader is introduced to coordination in the workplace as an object of scientific study and computer automation. Diplans are the expressions of a new graphical language used to describe plans of operation in human organizations. With diplans, systems of constraint, which may or may not take the form of procedure definitions, can be specified. Among the special strengths of diplans is their ability to render explicit the interactive aspects of complex work distributed over many people and places—in other words, coordination. Diplans are central to coordination technology, a new approach to developing support for cooperative work on heterogeneous computer networks.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {109–125},
numpages = {17}
}

@article{10.1145/45941.383895,
author = {Suchman, Lucy},
title = {Designing with the User: Book Review of <i>Computers and Democracy: A Scandinavian Challenge,</i> G. Bjerknes, P. Ehn, and M. Kyng, Eds. Gower Press, Brookfield, VT, 1987},
year = {1988},
issue_date = {April 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/45941.383895},
doi = {10.1145/45941.383895},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {173–183},
numpages = {11}
}

@article{10.1145/45941.214328,
author = {Auram\"{a}ki, Esa and Lehtinen, Erkki and Lyytinen, Kalle},
title = {A Speech-Act-Based Office Modeling Approach},
year = {1988},
issue_date = {April 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/45941.214328},
doi = {10.1145/45941.214328},
abstract = {In this paper methods and principles that help to analyze offices as systems of communicative action are explored. In communicative action, office agents create commitments through symbolic means. A SAMPO (Speech-Act-based office Modeling aPprOach), which studies office activities as a series of speech acts creating, maintaining, modifying, reporting, and terminating commitments, is presented. The main steps and methods in the office system specification are outlined and their application illustrated through a simple example. In the final section advantages and disadvantages in the SAMPO are noted and some research directions for the future are suggested.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {126–152},
numpages = {27}
}

@article{10.1145/42279.45947,
author = {Croft, W. Bruce and Savino, Pasquale},
title = {Implementing Ranking Strategies Using Text Signatures},
year = {1988},
issue_date = {Jan. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/42279.45947},
doi = {10.1145/42279.45947},
abstract = {Signature files provide an efficient access method for text in documents, but retrieval is usually limited to finding documents that contain a specified Boolean pattern of words. Effective retrieval requires that documents with similar meanings be found through a process of plausible inference. The simplest way of implementing this retrieval process is to rank documents in order of their probability of relevance. In this paper techniques are described for implementing probabilistic ranking strategies with sequential and bit-sliced signature tiles and the limitations of these implementations with regard to their effectiveness are pointed out. A detailed comparison is made between signature-based ranking techniques and ranking using term-based document representatives and inverted files. The comparison shows that term-based representations are at least competitive (in terms of efficiency) with signature files and, in some situations, superior.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {42–62},
numpages = {21}
}

@article{10.1145/42279.42281,
author = {Bertino, Elisa and Rabbiti, Fausto and Gibbs, Simon},
title = {Query Processing in a Multimedia Document System},
year = {1988},
issue_date = {Jan. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/42279.42281},
doi = {10.1145/42279.42281},
abstract = {Query processing in a multimedia document system is described. Multimedia documents are information objects containing formatted data, text, image, graphics, and voice. The query language is based on a conceptual document model that allows the users to formulate queries on both document content and structure. The architecture of the system is outlined, with focus on the storage organization in which both optical and magnetic devices can coexist. Query processing and the different strategies evaluated by our optimization algorithm are discussed.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–41},
numpages = {41}
}

@article{10.1145/42279.42280,
author = {Postel, Jonathan B. and Finn, Gregory G. and Katz, Alan R. and Reynolds, Joyce K.},
title = {An Experimental Multimedia Mail System},
year = {1988},
issue_date = {Jan. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/42279.42280},
doi = {10.1145/42279.42280},
abstract = {A computer-based experimental multimedia mail system that allows the user to read, create, edit, send, and receive messages containing text, images, and voice is discussed.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {63–81},
numpages = {19}
}

@article{10.1145/42196.42266,
author = {Clement, Andrew and Gotlieb, C. C.},
title = {Evolution of an Organizational Interface: The New Business Department at a Largeinsurance Firm},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/42196.42266},
doi = {10.1145/42196.42266},
abstract = {This paper describes how the work organization and computer system of the New Business Department at a large life insurance firm have interacted and evolved over time. The dynamics of interaction are explained largely in terms of the economic incentive to reduce the length of transaction-processing chains and the more political goal of extending managerial control. It is argued that examining the interaction of organizations and computer systems can contribute to a better theoretical understanding of the development of large computer systems and offer guidance to designers of user-computer interfaces. A graphical technique for depicting organizational interfaces is presented.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {328–339},
numpages = {12}
}

@article{10.1145/42196.42246,
author = {Rada, Roy and Martin, Brian K.},
title = {Augmenting Thesauri for Information Systems},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/42196.42246},
doi = {10.1145/42196.42246},
abstract = {A thesaurus can be a critical component of an office information system. Access to various sets of documents can be facilitated by thesauri and by the connections that are made among thesauri. In the projects described in this paper, the thesauri are stored and manipulated through a relational database management system. The system detects inheritance properties in a thesaurus and uses them to guide a human expert in decisions about how to augment the thesaurus. New strategies will extend our ability to augment existing thesauri.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {378–392},
numpages = {15}
}

@article{10.1145/42196.42200,
author = {Whang, Kyu-Young and Ammann, Art and Bolmarcich, Anthony and Hanrahan, Maria and Hochgesang, Guy and Huang, Kuan-Tsae and Khorasani, Al and Krishnamurthy, Ravi and Sockut, Gary and Sweeney, Paula and Waddle, Vance and Zloof, Mosh\'{e}},
title = {Office-by-Example: An Integrated Office System and Database Manager},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/42196.42200},
doi = {10.1145/42196.42200},
abstract = {Office-by-Example (OBE) is an integrated office information system that has been under development at IBM Research. OBE, an extension of Query-by-Example, supports various office features such as database tables, word processing, electronic mail, graphics, images, and so forth. These seemingly heterogeneous features are integrated through a language feature called example elements. Applications involving example elements are processed by the database manager, an integrated part of the OBE system. In this paper we describe the facilities and architecture of the OBE system and discuss the techniques for integrating heterogeneous objects.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {393–427},
numpages = {35}
}

@article{10.1145/42196.42199,
author = {Gould, John D. and Salaun, Josiane},
title = {Behavioral Experiments on Handmarkings},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/42196.42199},
doi = {10.1145/42196.42199},
abstract = {Handmarkings or handwritten editing marks can be used as direct editing commands to an interactive computer system. Five exploratory experiments studied the potential value of handmarkings for editing text and pictures, as well as for some specific results. Circles are the most frequently used scoping mark, and arrows are the most frequently used operator and target indicators. Experimental comparisons showed that handmarkings have the potential to be faster than keyboards and mice for editing tasks. Their ultimate value will, however, depend on the style and details of their user-interface implementation.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {358–377},
numpages = {20}
}

@article{10.1145/42196.42198,
author = {Ehrlich, Susan F.},
title = {Strategies for Encouraging Successful Adoption of Office Communication Systems},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/42196.42198},
doi = {10.1145/42196.42198},
abstract = {The adoption of new computer communication systems into organizations requires behavioral change. Planning for successful adoption requires knowledge of individual organizational communication patterns and the relationship between those patterns and particular communication system solutions. This paper documents a sequence of studies of organizational communication. Needs for office communication systems were identified, as were social and psychological factors temporarily inhibiting their use. Strategies for assuring smooth adoption of such systems are highlighted.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {340–357},
numpages = {18}
}

@article{10.1145/42196.42197,
author = {Kaye, A. Roger and Karam, Gerald M.},
title = {Cooperating Knowledge-Based Assistants for the Office},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/42196.42197},
doi = {10.1145/42196.42197},
abstract = {This paper presents an approach to high-level support of office workers by embedding office knowledge in a network of distributed cooperating knowledge-based or expert “assistants” and servers. These knowledge-based systems incorporate both factual and procedural knowledge and are capable of making use of existing conventional office technology. They constitute a form of computer-supported cooperative work. We describe a common architecture for our assistants and servers that incorporates several key features. Our systems are capable of supporting concurrent multiple consultations or tasks and have facilities for the interruption and resumption of consultations as appropriate. The various assistants and servers, which may reside on different machines, cooperate in solving problems or completing tasks by passing messages. We propose a taxonomy of the general office knowledge normally used by office workers, together with a frame and rule-based knowledge representation scheme. We also describe an experimental system, written in PROLOG, that incorporates the above design principles.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {297–326},
numpages = {30}
}

@article{10.1145/27641.28059,
author = {Sassone, Peter G.},
title = {Cost-Benefit Methodology for Office Systems},
year = {1987},
issue_date = {July 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/27641.28059},
doi = {10.1145/27641.28059},
abstract = {The time savings times salary (TSTS) approach is a widely used methodology for the financial justification of office information systems, yet its theoretical basis is largely unexplored. In this paper, we identify its underlying economic model, including five critical assumptions. We find that the model, though somewhat restrictive, is not unreasonable. However, we find that the time-saving-times-salary calculation, per se, is implicitly based on a very particular assumption about how saved time will be used. This assumption has neither a behavioral nor normative basis, and we conclude that the TSTS calculation is not meaningful in most cases. An alternate approach, the hedonic wage model, is proposed. This model overcomes most of the deficiencies of the TSTS approach, although it has somewhat greater data requirements and computational complexity. A case study illustrating the use of the hedonic wage model is presented.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {273–289},
numpages = {17}
}

@article{10.1145/27641.28058,
author = {Brown, Polly S. and Gould, John D.},
title = {An Experimental Study of People Creating Spreadsheets},
year = {1987},
issue_date = {July 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/27641.28058},
doi = {10.1145/27641.28058},
abstract = {Nine experienced users of electronic spreadsheets each created three spreadsheets. Although participants were quite confident that their spreadsheets were accurate, 44 percent of the spreadsheets contained user-generated programming errors. With regard to the spreadsheet creation process, we found that experienced spreadsheet users spend a large percentage of their time using the cursor keys, primarily for the purpose of moving the cursor around the spreadsheet. Users did not spend a lot of time planning before launching into spreadsheet creation, nor did they spend much time in a separate, systematic debugging stage. Participants spent 21 percent of their time pausing, presumably reading and/or thinking, prior to the initial keystrokes of spreadsheet creation episodes.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {258–272},
numpages = {15}
}

@article{10.1145/27641.28057,
author = {Faloutsos, Christos and Christodoulakis, Stavros},
title = {Description and Performance Analysis of Signature File Methods for Office Filing},
year = {1987},
issue_date = {July 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/27641.28057},
doi = {10.1145/27641.28057},
abstract = {Signature files have attracted a lot of interest as an access method for text and specifically for messages in the office environment. Messages are stored sequentially in the message file, whereas their hash-coded abstractions (signatures) are stored sequentially in the signature file. To answer a query, the signature file is examined first, and many nonqualifying messages are immediately rejected. In this paper we examine the problem of designing signature extraction methods and studying their performance. We describe two old methods, generalize another one, and propose a new method and its variation. We provide exact and approximate formulas for the dependency between the false drop probability and the signature size for all the methods, and we show that the proposed method (VBC) achieves approximately ten times smaller false drop probability than the old methods, whereas it is well suited for collections of documents with variable document sizes.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {237–257},
numpages = {21}
}

@article{10.1145/27641.27642,
author = {Chang, Shi-Huo and Leung, L.},
title = {A Knowledge-Based Message Management System},
year = {1987},
issue_date = {July 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/27641.27642},
doi = {10.1145/27641.27642},
abstract = {The design approach of a knowledge-based message management system is described. A linguistic message filter is used to filter out junk messages. Relevant messages are then processed by an expert system, driven by user-defined alerter rules. An alerter rule base for a secretarial office is illustrated. Further research topics in knowledge-base design, evaluation, and learning are also discussed.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {213–236},
numpages = {24}
}

@article{10.1145/27636.28056,
author = {Stefik, M. and Bobrow, D. G. and Foster, G. and Lanning, S. and Tatar, D.},
title = {WYSIWIS Revised: Early Experiences with Multiuser Interfaces},
year = {1987},
issue_date = {April 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/27636.28056},
doi = {10.1145/27636.28056},
abstract = {WYSIWIS (What You See Is What I See) is a foundational abstraction for multiuser interfaces that expresses many of the characteristics of a chalkboard in face-to-face meetings. In its strictest interpretation, it means that everyone can also see the same written information and also see where anyone else is pointing. In our attempts to build software support for collaboration in meetings, we have discovered that WYSIWIS is crucial, yet too inflexible when strictly enforced. This paper is about the design issues and choices that arose in our first generation of meeting tools based on WYSIWIS. Several examples of multiuser interfaces that start from this abstraction are presented. These tools illustrate that there are inherent conflicts between the needs of a group and the needs of individuals, since user interfaces compete for the same display space and meeting time. To help minimize the effect of these conflicts, constraints were relaxed along four key dimensions of WYSIWIS: display space, time of display, subgroup population, and congruence of view. Meeting tools must be designed to support the changing needs of information sharing during process transitions, as subgroups are formed and dissolved, as individuals shift their focus of activity, and as the group shifts from multiple parallel activities to a single focused activity and back again.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {147–167},
numpages = {21}
}

@article{10.1145/27636.27640,
author = {Greif, Irene and Sarin, Sunil},
title = {Data Sharing in Group Work},
year = {1987},
issue_date = {April 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/27636.27640},
doi = {10.1145/27636.27640},
abstract = {Data sharing is fundamental to computer-supported cooperative work: People share information through explicit communication channels and through their coordinated use of shared databases. This paper examines the data management requirements of group work applications on the basis of experience with three prototype systems and on observations from the literature. Database and object management technologies that support these requirements are briefly surveyed, and unresolved issues in the particular areas of access control and concurrency control are identified for future research.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {187–211},
numpages = {25}
}

@article{10.1145/27636.27639,
author = {Delisle, Norman M. and Schwartz, Mayer D.},
title = {Contexts—a Partitioning Concept for Hypertext},
year = {1987},
issue_date = {April 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/27636.27639},
doi = {10.1145/27636.27639},
abstract = {Hypertext systems provide good information management support for a wide variety of documentation efforts. These efforts range from developing software to writing a book. However, existing hypertext systems provide poor support for collaboration among teams of authors. This paper starts by briefly describing properties of several existing hypertext systems. Then several models for forming partitions in a hypertext database are examined and contexts, a partitioning scheme that supports multiperson cooperative efforts, are introduced. The semantic issues involved in defining contexts are explored in detail.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {168–186},
numpages = {19}
}

@article{10.1145/27636.27638,
author = {Cook, Peter and Ellis, Clarence and Graf, Mike and Rein, Gail and Smith, Tom},
title = {Project Nick: Meetings Augmentation and Analysis},
year = {1987},
issue_date = {April 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/27636.27638},
doi = {10.1145/27636.27638},
abstract = {The Software Technology Program of MCC is investigating the early part of the design process, before requirements are established, for large-scale distributed systems. Face-to-face meetings are an important activity during this phase of a project since they provide a medium for direction, exploration, and consensus building. Project Nick is attempting to apply automated facilities to the process, conduct, and semantic capture of design meetings. Primary topics covered in this paper are meeting analysis, meeting augmentation, and a model of meeting progression that serves as the framework for our work.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {132–146},
numpages = {15}
}

@article{10.1145/27636.27637,
author = {Malone, Thomas W. and Grant, Kenneth R. and Lai, Kum-Yew and Rao, Ramana and Rosenblitt, David},
title = {Semistructured Messages Are Surprisingly Useful for Computer-Supported Coordination},
year = {1987},
issue_date = {April 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/27636.27637},
doi = {10.1145/27636.27637},
abstract = {This paper argues that using a set of semistructured message templates is surprisingly helpful in designing a variety of computer-based communication and coordination systems. Semistructured messages can help provide automatic aids for (1) composing messages to be sent, (2) selecting, sorting, and prioritizing messages that are received, (3) responding automatically to some messages, and (4) suggesting likely responses to other messages. The use of these capabilities is illustrated in a range of applications including electronic mail, computer conferencing, calendar management, and task tracking. The applications show how ideas from artificial intelligence (such as inheritance and production rules) and ideas from user interface design (such as interactive graphical editors) can be combined in novel ways for dealing with semistructured messages. The final part of the paper discusses how communities can evolve a useful set of message type definitions.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {115–131},
numpages = {17}
}

@article{10.1145/22890.23001,
author = {Tsichritzis, D. and Fiume, E. and Gibbs, S. and Nierstrasz, O.},
title = {KNOs: KNowledge Acquisition, Dissemination, and Manipulation Objects},
year = {1987},
issue_date = {Jan. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/22890.23001},
doi = {10.1145/22890.23001},
abstract = {Most object-oriented systems lack two useful facilities: the ability of objects to migrate to new environments and the ability of objects to acquire new operations dynamically. This paper proposes Knos, an object-oriented environment that supports these actions. Knos' operations, data structures, and communication mechanisms are discussed. Knos objects “learn” by exporting and importing new or modified operations. The use of such objects as intellectual support tools is outlined. In particular, various applications involving cooperation, negotiation, and apprenticeship among objects are described.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {96–112},
numpages = {17}
}

@article{10.1145/22890.23000,
author = {Purdy, Alan and Schuchardt, Bruce and Maier, David},
title = {Integrating an Object Server with Other Worlds},
year = {1987},
issue_date = {Jan. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/22890.23000},
doi = {10.1145/22890.23000},
abstract = {Object-oriented database servers are beginning to appear on the commercial market in response to a demand by application developers for increased modeling power in database systems. Before these new servers can enhance the productivity of application designers, systems designers must provide simple interfaces to them from both procedural and object-oriented languages. This paper first describes a successful interface between an object server and two procedural languages (C and Pascal). Because C and Pascal do not support the object-oriented paradigm application, designers using these languages must deal with database objects in less than natural ways. Fortunately, workstations supporting object-oriented languages have the potential for interacting with database objects in a much more integrated manner. To integrate these object-oriented workstations with an object server, we provide a design framework based on the notion of workstation agent objects representing principal objects in the database. We distinguish two types of agents: proxies, which forward most messages to the principal objects, and deputies, which can cache state for their principal and act with more autonomy. The interaction of cache, transaction, and message management strategies makes the implementation of deputies a nontrivial problem. The agent metaphor is being used currently to integrate an object server with a Smalltalk-8O™ workstation.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {27–47},
numpages = {21}
}

@article{10.1145/22890.22945,
author = {Banerjee, Jay and Chou, Hong-Tai and Garza, Jorge F. and Kim, Won and Woelk, Darrell and Ballou, Nat and Kim, Hyoung-Joo},
title = {Data Model Issues for Object-Oriented Applications},
year = {1987},
issue_date = {Jan. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/22890.22945},
doi = {10.1145/22890.22945},
abstract = {Presented in this paper is the data model for ORION, a prototype database system that adds persistence and sharability to objects created and manipulated in object-oriented applications. The ORION data model consolidates and modifies a number of major concepts found in many object-oriented systems, such as objects, classes, class lattice, methods, and inheritance. These concepts are reviewed and three major enhancements to the conventional object-oriented data model, namely, schema evolution, composite objects, and versions, are elaborated upon. Schema evolution is the ability to dynamically make changes to the class definitions and the structure of the class lattice. Composite objects are recursive collections of exclusive components that are treated as units of storage, retrieval, and integrity enforcement. Versions are variations of the same object that are related by the history of their derivation. These enhancements are strongly motivated by the data management requirements of the ORION applications from the domains of artificial intelligence, computer-aided design and manufacturing, and office information systems with multimedia documents.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {3–26},
numpages = {24}
}

@article{10.1145/22890.22891,
author = {Hornick, Mark F. and Zdonik, Stanley B.},
title = {A Shared, Segmented Memory System for an Object-Oriented Database},
year = {1987},
issue_date = {Jan. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/22890.22891},
doi = {10.1145/22890.22891},
abstract = {This paper describes the basic data model of an object-oriented database and the basic architecture of the system implementing it. In particular, a secondary storage segmentation scheme and a transaction-processing scheme are discussed. The segmentation scheme allows for arbitrary clustering of objects, including duplicates. The transaction scheme allows for many different sharing protocols ranging from those that enforce serializability to those that are nonserializable and require communication with the server only on demand. The interaction of these two features is described such that segment-level transfer and object-level locking is achieved.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {70–95},
numpages = {26}
}

@article{10.1145/9760.9764,
author = {Christodoulakis, S. and Theodoridou, M. and Ho, F. and Papa, M. and Pathria, A.},
title = {Multimedia Document Presentation, Information Extraction, and Document Formation in MINOS: A Model and a System},
year = {1986},
issue_date = {Oct. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/9760.9764},
doi = {10.1145/9760.9764},
abstract = {MINOS is an object-oriented multimedia information system that provides integrated facilities for creating and managing complex multimedia objects. In this paper the model for multimedia documents supported by MINOS and its implementation is described. Described in particular are functions provided in MINOS that exploit the capabilities of a modern workstation equipped with image and voice input-output devices to accomplish an active multimedia document presentation and browsing within documents. These functions are powerful enough to support a variety of office applications. Also described are functions provided for the extraction of information from multimedia documents that exist in a large repository of information (multimedia document archiver) and functions that select and transform this information. Facilities for information sharing among objects of the archiver are described; an interactive multimedia editor that is used for the extraction and interactive creation of new information is outlined; finally, a multimedia document formatter that is used to synthesize a new multimedia document from extracted and interactively generated information is presented.This prototype system runs on a SUN-3 workstation running UNIX'". An Instavox, directly addressable, analog device is used to store voice segments.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
pages = {345–383},
numpages = {39}
}

@article{10.1145/9760.9763,
author = {Hirschheim, R. A.},
title = {Understanding the Office: A Social-Analytic Perspective},
year = {1986},
issue_date = {Oct. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/9760.9763},
doi = {10.1145/9760.9763},
abstract = {In order to apply office automation in a meaningful fashion, it is apparent that some understanding of the office is necessary. Most descriptive studies of the office have placed great emphasis on manifest office actions, suggesting that offices are the embodiment of these actions. The meanings of these actions or tasks, however, have been given scant attention. There exist a number of office activity or task taxonomies, but they do little more than provide a simple and limited structure through which to conceive of an office. From a social-analytic perspective this appears to be overly simplistic and misses the richness of social action in an office. Focusing on the overt and manifest aspects of the office may very well lead to its misrepresentation. This paper takes a critical look at the way offices are conceived in the office automation literature and suggests alternatives that may provide a better understanding of the real functions of an office.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
pages = {331–344},
numpages = {14}
}

@article{10.1145/9760.9762,
author = {Motro, Amihai},
title = {SEAVE: A Mechanism for Verifying User Presuppositions in Query Systems},
year = {1986},
issue_date = {Oct. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/9760.9762},
doi = {10.1145/9760.9762},
abstract = {Every information system incorporates a database component, and a frequent activity of users of information systems is to present it with queries. These queries reflect the presuppositions of their authors about the system and the information it contains. With most query processors, queries that are based on erroneous presuppositions often result in null answers. These fake nulls are misleading, since they do not point out the user's erroneous presuppositions (and can even be interpreted as their affirmation). This article describes the SEAVE mechanism for extracting presuppositions from queries and verifying their correctness. The verification is done against three repositories of information: the actual data, their integrity constraints, and their completeness assertions. Consequently, queries that reflect erroneous presuppositions are answered with informative messages instead of null answers, and user-system communication is thus improved (an aspect that is particularly important in systems that often are accessed by naive users). First, the principles of SEAVE are described abstractly. Then, specific algorithms for implementing it with relational databases are presented, including a new method for storing knowledge and an efficient algorithm for processing queries against the knowledge.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
pages = {312–330},
numpages = {19}
}

@article{10.1145/9760.9761,
author = {Hauzeur, Bernard M.},
title = {A Model for Naming, Addressing and Routing},
year = {1986},
issue_date = {Oct. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/9760.9761},
doi = {10.1145/9760.9761},
abstract = {Naming and addressing are areas in which there is still a need for clarification. Many definitions for names, addresses, and routes have been proposed, but the exact relations among these concepts are obscure. A taxonomy of names, addresses, and routes is presented. First, we identify names and routes as the essential concepts of communication. Then, addresses are introduced as an intermediate form that eases the process of mapping between names and routes; an original definition of an address is thus proposed. Relations among names, addresses, and routes are explained with the concept of mapping. On this basis, a general model relating names, addresses, and routes is built and then applied recursively throughout a layered architecture, leading to a layered naming and addressing model which may play the same role for naming and addressing features that the OS1 reference model plays for the definition of services and protocols. Finally, the model is particularized to a typical network architecture. The model may also be applied to non-OSI layered systems; naming, addressing, and routing issues in any network architecture could be a particular instance of this layered model.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
pages = {293–311},
numpages = {19}
}

@article{10.1145/214427.214432,
author = {Hewitt, Carl},
title = {Offices Are Open Systems},
year = {1986},
issue_date = {July 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/214427.214432},
doi = {10.1145/214427.214432},
abstract = {This paper is intended as a contribution to analysis of the implications of viewing offices as open systems. It takes a prescriptive stance on how to establish the information-processing foundations for taking action and making decisions in office work from an open systems perspective. We propose due process as a central activity in organizational information processing. Computer systems are beginning to play important roles in mediating the ongoing activities of organizations. We expect that these roles will gradually increase in importance as computer systems take on more of the authority and responsibility for ongoing activities. At the same time we expect computer systems to acquire more of the characteristics and structure of human organizations.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {271–287},
numpages = {17},
keywords = {debate, open systems, logic, microtheories, decision making, negotiation, due process, offices}
}

@article{10.1145/214427.214431,
author = {Gerson, Elihu M. and Star, Susan Leigh},
title = {Analyzing Due Process in the Workplace},
year = {1986},
issue_date = {July 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/214427.214431},
doi = {10.1145/214427.214431},
abstract = {Every office is an open system, and the products of office work are the result of decentralized negotiations. Changing patterns of task organization and alliance inevitably give rise to inconsistent knowledge bases and procedures. This implies that there are no globally correct answers to problems addressed by OISs. Rather, systems must deal with multiple competing, possibly irreconcilable, solutions. Articulating alternative solutions is the problem of due process. This problem and its consequences are illustrated by a case study of a rate-setting group in a large health insurance firm.There is no formal solution to the problem of due process. But it must be solved in practice if distributed intelligent OISs are to be developed. We propose an alternative approach based on the work of social scientists concerned with analyzing analogous problems in human organization. Solution of the due process problem hinges on developing local closures to the problem faced by an organization. This means analyzing (a) local, tacit knowledge and its transfer ability; (b) articulation work, that is, reconciling incommensurate assumptions and procedures.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {257–270},
numpages = {14}
}

@article{10.1145/214427.214430,
author = {Davison, Jay W. and Zdonik, Stanley B.},
title = {A Visual Interface for a Database with Version Management},
year = {1986},
issue_date = {July 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/214427.214430},
doi = {10.1145/214427.214430},
abstract = {This paper describes a graphical interface to an experimental database system which incorporates a built-in version control mechanism that maintains a history of the database development and changes. The system is an extension of ISIS [6], Interface for a Semantic Information System, a workstation-based, graphical database programming tool developed at Brown University. ISIS supports a graphical interface to a modified subset of the Semantic Data Model (SDM) [7]. The ISIS extension introduces a transaction mechanism that interacts with the version control facilities.A series of version control support tools have been added to ISIS to provide a notion of history to user-created databases. The user can form new versions of three types of ISIS objects: a class definition object (a type), the set of instances of a class (the content), and an entity. A version-viewing mechanism is provided to allow for the comparison of various object versions. Database operations are grouped together in atomic units to form transactions, which are stored as entities in the database. A sample session demonstrates the capabilities of version and transaction control during the creation and manipulation of database objects.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {226–256},
numpages = {31},
keywords = {transaction processing, version control, semantic data model, visual interfaces, historical database}
}

@article{10.1145/214427.214429,
author = {Gasser, Les},
title = {The Integration of Computing and Routine Work},
year = {1986},
issue_date = {July 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/214427.214429},
doi = {10.1145/214427.214429},
abstract = {Most computing serves as a resource or tool to support other work: performing complex analyses for engineering projects, preparing documents, or sending electronic mail using office automation equipment, etc. To improve the character, quality, and ease of computing work, we must understand how automated systems actually are integrated into the work they support. How do people actually adapt to computing as a resource? How do they deal with the unreliability in hardware, software, or operations; data inaccuracy; system changes; poor documentation; inappropriate designs; etc.; which are present in almost every computing milieu, even where computing is widely used and considered highly successful? This paper presents some results of a detailed empirical study of routine computer use in several organizations. We present a theoretical account of computing work and use it to explain a number of observed phenomena, such as:How people knowingly use “false” data to obtain desired analytical results by tricking their systems.  How organizations come to rely upon complex, critical computer systems despite significant, recurrent, known errors and inaccurate data.  How people work around inadequate computing systems by using manual or duplicate systems, rather than changing their systems via maintenance or enhancement.  In addition, the framework for analyzing computing and routine work presented here proves useful for representing and reasoning about activity in multiactor systems in general, and in understanding how better to integrate organizations of people and computers in which work is coordinated.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {205–225},
numpages = {21},
keywords = {computing and work, articulation work, workarounds, social analysis of computing, multiagent systems, integration of computing, computing in organizations}
}

@article{10.1145/214427.214428,
author = {Woo, Carson C. and Lochovsky, Frederick H.},
title = {Supporting Distributed Office Problem Solving in Organizations},
year = {1986},
issue_date = {July 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/214427.214428},
doi = {10.1145/214427.214428},
abstract = {To improve the effectiveness of office workers in their decision making, office systems have been built to support (rather than replace) their judgment. However, these systems model office work in a centralized environment, and/or they can only support a single office worker. Office work that is divided into specialized domains handled by different office workers (where cooperation is needed in order to accomplish the work) is not supported. In this paper, we will present a model that supports office problem solving in a logically distributed environment. (In some systems, information is geographically distributed for performance purposes rather than for conceptual need. The term, logically, is therefore used to indicate the logical need of organizing information without having to worry about the physical location of the information.) In particular, cooperative tools that can be used to support office workers during the process of their problem solving is discussed.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {185–204},
numpages = {20},
keywords = {cooperative tools, office communication, managerial office work, object-oriented environment}
}

@article{10.1145/6168.6172,
author = {Motro, Amihai},
title = {BAROQUE: A Browser for Relational Databases},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/6168.6172},
doi = {10.1145/6168.6172},
abstract = {The standard, most efficient method to retrieve information from databases can be described as systematic retrieval: The needs of the user are described in a formal query, and the database management system retrieves the data promptly. There are several situations, however, in which systematic retrieval is difficult or even impossible. In such situations exploratory search (browsing) is a helpful alternative. This paper describes a new user interface, called BAROQUE, that implements exploratory searches in relational databases. BAROQUE requires few formal skills from its users. It does not assume knowledge of the principles of the relational data model or familiarity with the organization of the particular database being accessed. It is especially helpful when retrieval targets are vague or cannot be specified satisfactorily. BAROQUE establishes a view of the relational database that resembles a semantic network, and provides several intuitive functions for scanning it. The network integrates both schema and data, and supports access by value. BAROQUE can be implemented on top of any basic relational database management system but can be modified to take advantage of additional capabilities and enhancements often present in relational systems.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {164–181},
numpages = {18}
}

@article{10.1145/6168.6171,
author = {Hudson, Scott E. and King, Roger},
title = {A Generator of Direct Manipulation Office Systems},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/6168.6171},
doi = {10.1145/6168.6171},
abstract = {A system for generating direct manipulation office systems is described. In these systems, the user directly manipulates graphical representations of office entities instead of dealing with these entities abstractly through a command language or menu system. These systems employ a new semantic data model to describe office entities. New techniques based on attribute grammars and incremental attribute evaluation are used to implement this data model in an efficient manner. In addition, the system provides a means of generating sophisticated graphics-based user interfaces that are integrated with the underlying semantic model. Finally, the generated systems contain a general user reversal and recovery (or undo) mechanism that allows them to be much more tolerant of human errors.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {132–163},
numpages = {32}
}

@article{10.1145/6168.6170,
author = {Ho, Cheng-Seen and Hong, Yang-Chang and Kuo, Te-Son},
title = {A Society Model for Office Information Systems},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/6168.6170},
doi = {10.1145/6168.6170},
abstract = {A society model, which characterizes the behavior and procedure of offices, is proposed. It is our belief that an office system capable of dealing with all real office problems only through the modeling of the internal behavior of an office can be developed. In this society model, office entities are viewed as agents. An agent is modeled as a microsociety of interacting knowledge sources. Within the microsociety, there exists a microknowledge exchange system, which provides a set of microknowledge exchange protocols as a coordination system among those knowledge sources during their cooperative reasoning process. An office is then modeled as a society of various interacting agents using their knowledge to complete the office goals cooperatively. It is this unified view that allows offices to be modeled in a flexible and general way.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {104–131},
numpages = {28}
}

@article{10.1145/6168.6169,
author = {Bui, Tung X. and Jarke, Matthias},
title = {Communications Design for Co-OP: A Group Decision Support System},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/6168.6169},
doi = {10.1145/6168.6169},
abstract = {Decision Support Systems (DSSs), computer-based systems intended to assist managers in preparing and analyzing decisions, have been single-user systems for most of the past decade. Only recently has DSS research begun to study the implications of the fact that most complex managerial decisions involve multiple decision makers and analysts. A number of tools for facilitating group decisions have been proposed under the label Group Decision Support Systems (GDSSs).One of the most important functions of a GDSS is to provide problem-oriented services for communication among decision makers. On the basis of an analysis of the communication requirements in various group decision settings, this paper presents an architecture for defining and enforcing dynamic application-level protocols that organize decision group interaction. The architecture has been implemented on a network of personal computers in Co-oP, a GDSS for cooperative group decision making based on interactive, multiple-criteria decision methods.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {81–103},
numpages = {23}
}

@article{10.1145/5401.5405,
author = {Jones, William P. and Dumais, Susan T.},
title = {The Spatial Metaphor for User Interfaces: Experimental Tests of Reference by Location versus Name},
year = {1986},
issue_date = {Jan. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/5401.5405},
doi = {10.1145/5401.5405},
abstract = {The enduring dichotomy between spatial and symbolic modes of representation and retrieval acquires an added pragmatic dimension through recent developments in computer-based information retrieval. The standard name-based approach to object reference is now supplemented on some systems by a spatial alternative-often driven by an office or desktop metaphor. Little rigorous evidence is available, however, to support the supposition that spatial memory in itself is more effective than symbolic memory.The accuracy of spatial versus symbolic reference was assessed in three experiments. In Experiment 1 accuracy of location reference in a location-only filing condition was initially comparable to that in a name-only condition, but deteriorated much more rapidly with increases in the number of objects filed. In Experiment 2 subjects placed objects in a two-dimensional space containing landmarks (drawings of a desk, table, filing cabinets, etc.) designed to evoke an office metaphor, and in Experiment 3 subjects placed objects in an actual, three-dimensional mock office. Neither of these enhancements served to improve significantly the accuracy of location reference, and performance remained below that of a name-only condition in Experiment 1. The results raise questions about the utility of spatial metaphor over symbolic filing and highlight the need for continuing research in which considerations of technological and economic feasibility are balanced by considerations of psychological utility.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {42–63},
numpages = {22}
}

@article{10.1145/5401.5404,
author = {Martin, P. and Tsichritzis, D.},
title = {Complete Logical Routings in Computer Mail Systems},
year = {1986},
issue_date = {Jan. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/5401.5404},
doi = {10.1145/5401.5404},
abstract = {The logical routing of a message in a computer mail system involves the identification and location of the set of intended recipients for that message. This function is carried out by the naming and addressing mechanism of the mail system. An important property of that mechanism is that it should be able to identify and locate all the intended recipients of a message, so that, once submitted, a message will not become lost or stuck in the system. We first discuss message addressing schemes, which are a framework for dealing with the naming and addressing problem. Message addressing schemes can also serve as a basis for the analysis of some of the properties of logical message routing within a system. We examine the conditions necessary for a complete message addressing scheme, that is, one that guarantees to deliver all possible messages.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {64–80},
numpages = {17}
}

@article{10.1145/5401.5403,
author = {Donahue, James and Widom, Jennifer},
title = {Whiteboards: A Graphical Database Tool},
year = {1986},
issue_date = {Jan. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/5401.5403},
doi = {10.1145/5401.5403},
abstract = {The “Whiteboards” system is intended to be an electronic equivalent of the whiteboards and corkboards that we have in our offices. A Whiteboard database has similar qualities of storing disparate collections of data and saving their spatial location in a window to help with organization. A Whiteboard database can contain references to arbitrary entities: text files, notes, programs, tools, pictures, etc. Whiteboards runs as an application in the Cedar programming environment developed at the Xerox Palo Alto Research Center.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {24–41},
numpages = {18}
}

@article{10.1145/5401.5402,
author = {Trigg, Randall H. and Weiser, Mark},
title = {TEXTNET: A Network-Based Approach to Text Handling},
year = {1986},
issue_date = {Jan. 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/5401.5402},
doi = {10.1145/5401.5402},
abstract = {Textnet is a new system for structuring text. The Textnet approach uses one uniform data structure to capture graphlike pools of text, as well as embedded hierarchical structures. By using a semantic network formalism of nodes connected by typed links, the relationships between neighboring pieces of text are made explicit. Also described is our partial implementation of the Textnet approach, which makes use of an object-oriented window/menu-driven user interface. Users peruse the network by moving among object menus or by reading text along a path through the network. In addition, critiquing, reader linking, searching, and jumping are easily accessible operations. Finally, the results of a short trial with users are presented.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–23},
numpages = {23}
}

@article{10.1145/4656.4660,
author = {Biermann, Alan W. and Fineman, Linda and Gilbert, Kermit C.},
title = {An Imperative Sentence Processor for Voice Interactive Office Applications},
year = {1985},
issue_date = {Oct. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/4656.4660},
doi = {10.1145/4656.4660},
abstract = {An imperative sentence processor that enables a user to manipulate text with connected speech and touch-graphics input is described. The processor includes capabilities to follow dialogue focus, execute a variety of imperative commands, and handle nested noun groups, pronouns, and other phenomena. A micromodel of the system, giving enough of the structure to enable the reader to observe internal mechanisms in considerable detail, is included. This processor is designed to be transportable to a number of other office automation domains such as calendar management, message-passing, and desk calculation. Various examples and statistics related to its behavior in the text manipulation application are given. The system has been implemented in PASCAL and can run on any machine that supports this language.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {321–346},
numpages = {26}
}

@article{10.1145/4656.4659,
author = {King, Roger and Stanley, Carolyn},
title = {Ensuring Court Admissibility of Computer-Generated Records},
year = {1985},
issue_date = {Oct. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/4656.4659},
doi = {10.1145/4656.4659},
abstract = {An informal methodology is described for optimizing the likelihood of computer-generated records being admissible in a U.S. court of law. This methodology is intended for individuals who are converting to automated office procedures, as well as for those whose businesses are already highly computerized. However, this paper does not purport to be a formal legal guide; rather, it is intended as an overview of this issue.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {398–412},
numpages = {15}
}

@article{10.1145/4656.4658,
author = {Buchman, Cary and Berry, Daniel M. and Gonczarowski, Jakob},
title = {DITROFF/FFORTID, an Adaptation of the UNIX/DITROFF for Formatting Bidirectional Text},
year = {1985},
issue_date = {Oct. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/4656.4658},
doi = {10.1145/4656.4658},
abstract = {DITROFF/FFORTID, a collection of pre- and postprocessors for the UNIX DITROFF (Device Independent Typesetter RunOFF) is described. DITROFF/FFORTID permits formatting of text involving a mixture of languages written from left to right and from right to left, such as English and Hebrew. The programs are table driven or macro-generated to permit them to be used for any languages written from left to right and from right to left so long as fonts with the proper character sets can be mounted on a typesetting device supported by DITROFF. The preprocessors are set up to permit phonetic, unidirectional input of all of the alphabets needed using only the two alphabets (each case counts as an alphabet) available on the input device. These macro-generated preprocessors can be adjusted to the user's pronunciation, the language's rules about a letter's form, depending on its position in the word, and the language of the user's input keyboard. The postprocessor is set up to properly change direction of formatting when the text switches to a language written in a different direction. The collection of programs is also designed to allow use of any of DITROFF's preprocessors, such as PIC, EQN, TBL, and the various device drivers.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {380–397},
numpages = {18}
}

@article{10.1145/4656.4657,
author = {Peels, Arno J. H. and Janssen, Norbert J. M. and Nawijn, Wop},
title = {Document Architecture and Text Formatting},
year = {1985},
issue_date = {Oct. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/4656.4657},
doi = {10.1145/4656.4657},
abstract = {The formalization of the architecture of documents and text formatting are the central issues of this paper. Besides a fundamental and theoretical approach toward these topics, an overview is presented of the COBATEF system. The COBATEF system is a context-based text formatting system, for which a software, as well as a hardware, implementation is available.A unique feature of the system is its automatic text-element recognition mechanism, which is context based and consequently takes advantage of the implicit structure of text. A predefined layout for each type of text element then opens the way for a fully automatic text-processing system in which user control information can be reduced to an absolute minimum.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {347–369},
numpages = {23}
}

@article{10.1145/4656.214329,
author = {Panko, Raymond R.},
title = {Productivity Trends in Certain Office-Intensive Sectors of the U.S. Federal Government},
year = {1985},
issue_date = {Oct. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/4656.214329},
doi = {10.1145/4656.214329},
abstract = {It is often said that office productivity is virtually stagnant, increasing only about 4 percent every 10 years. The methodology used to estimate this 4 percent figure is examined and found to be inaccurate! There is no known way to estimate overall national office productivity trends. Productivity trends in a single part of the economy, however, can be examined, namely, office-intensive sectors of the U.S. federal government. Productivity in these sectors is found to be anything but stagnant, having increased 1.7 percent annually from 1967 to 1981 and 3.0 percent annually from 1977 through 1981.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {370–379},
numpages = {10}
}

@article{10.1145/4229.4234,
author = {Dannenberg, Roger B. and Hibbard, Peter G.},
title = {A Butler Process for Resource Sharing on Spice Machines},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/4229.4234},
doi = {10.1145/4229.4234},
abstract = {A network of personal computers may contain a large amount of distributed computing resources. For a number of reasons it is desirable to share these resources, but sharing is complicated by issues of security and autonomy. A process known as the Butler addresses these problems and provides support for resource sharing. The Butler relies upon a capability-based accounting system called the Banker to monitor the use of local resources.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {234–252},
numpages = {19}
}

@article{10.1145/4229.4233,
author = {Heimbigner, Dennis and McLeod, Dennis},
title = {A Federated Architecture for Information Management},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/4229.4233},
doi = {10.1145/4229.4233},
abstract = {An approach to the coordinated sharing and interchange of computerized information is described emphasizing partial, controlled sharing among autonomous databases. Office information systems provide a particularly appropriate context for this type of information sharing and exchange. A federated database architecture is described in which a collection of independent database systems are united into a loosely coupled federation in order to share and exchange information. A federation consists of components (of which there may be any number) and a single federal dictionary. The components represent individual users, applications, workstations, or other components in an office information system. The federal dictionary is a specialized component that maintains the topology of the federation and oversees the entry of new components. Each component in the federation controls its interactions with other components by means of an export schema and an import schema. The export schema specifies the information that a component will share with other components, while the import schema specifies the nonlocal information that a component wishes to manipulate. The federated architecture provides mechanisms for sharing data, for sharing transactions (via message types) for combining information from several components, and for coordinating activities among autonomous components (via negotiation). A prototype implementation of the federated database mechanism is currently operational on an experimental basis.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {253–278},
numpages = {26}
}

@article{10.1145/4229.4232,
author = {Thoma, G. R. and Suthasinekul, S. and Walker, F. L. and Cookson, J. and Rashidian, M.},
title = {A Prototype System for the Electronic Storage and Retrieval of Document Images},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/4229.4232},
doi = {10.1145/4229.4232},
abstract = {A prototype system has been implemented for electronic scanning, digitization, storage, retrieval, and display of images of biomedical documents. Paper documents are scanned and digitized at a scan density of 200 picture elements (pels) per inch by either a high-speed loose-leaf scanner with an automatic document transport or a book scanner with a manual book holder. Each scanner employs a high-resolution charge-coupled device (CCD) linear array operating at a sampling rate close to 10 MHz. The analog output signal of the CCD array is digitized into 1 bit per pixel two-tone images by means of dynamic thresholding. The digitized images are stored on magnetic disks to be processed and will eventually be transferred onto optical disks for archival storage. Existing on-line bibliographic databases developed by the National Library of Medicine are used as directories for the retrieval of document images. These images are displayed at a resolution of 200 pels/inch in both soft-copy (raster-refreshed CRT) and hard-copy forms.This prototype system, developed as part of a research and development program, offers the opportunity to investigate the areas of document image enhancement, image compression, and omnifont text recognition and to conduct experiments designed to answer key questions on the role of electronic document storage and retrieval technology in library information processing and the preservation of library documents.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {279–291},
numpages = {13}
}

@article{10.1145/4229.4231,
author = {Nicholson, Robert T.},
title = {Usage Patterns in an Integrated Voice and Data Communications System},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/4229.4231},
doi = {10.1145/4229.4231},
abstract = {Recently, office communication systems have begun to integrate voice recordings into their mail and data communications facilities. The study of usage patterns on one such system shows that voice is used for informal, person-to-person communications, as opposed to the formal content of typed messages. Voice messages are generally sent to fewer recipients (often only one), and sometimes replace face-to-face meetings.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {307–314},
numpages = {8}
}

@article{10.1145/4229.4230,
author = {Harris, Sidney E. and Brightman, Harvey J.},
title = {Design Implications of a Task-Driven Approach to Unstructured Cognitive Tasks in Office Work},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/4229.4230},
doi = {10.1145/4229.4230},
abstract = {Previous research in modeling office activities has been primarily oriented toward office work that is structured and organized. In this paper we report on efforts to develop a new methodology for needs assessment evaluation. We use the Critical Task Method to identify the “bottleneck cognitive tasks” of principals with an unstructured work profile. Data were collected on the computer-support needs of faculty researchers, and the findings indicate that a “knowledge-based” design offers the most promise for delivering effective support. In addition, the systems design suggests the integration of text, data, voice, and images.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {292–306},
numpages = {15}
}

@article{10.1145/3914.3985,
author = {Epstein, Samuel S.},
title = {Transportable Natural Language Processing through Simplicity—the PRE System},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3914.3985},
doi = {10.1145/3914.3985},
abstract = {PRE (Purposefully Restricted English) is a restricted English database query language whose implementation has addressed engineering goals, namely, habitability, interapplication transportability, performance, and use with a reliable database management system that supports large numbers of concurrent users and large databases. Habitability has not been demonstrated, but initial indications are encouraging. The other goals have clearly been achieved. The existence of the PRE system demonstrates that an explicitly “minimalist” approach to natural language processing can facilitate achievement of transportability.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {107–120},
numpages = {14}
}

@article{10.1145/3914.3984,
author = {Marsh, Elaine and Friedman, Carol},
title = {Transporting the Linguistic String Project System from a Medical to a Navy Domain},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3914.3984},
doi = {10.1145/3914.3984},
abstract = {The Linguistic String Project (LSP) natural language processing system has been developed as a domain-independent natural language processing system. Initially utilized for processing sets of medical messages and other texts in the medical domain, it has been used at the Naval Research Laboratory for processing Navy messages about shipboard equipment failures. This paper describes the structure of the LSP system and the features that make it transportable from one domain to another. The processing procedures encourage the isolation of domain-specific information, yet take advantage of the syntactic and semantic similarities between the medical and Navy domains. From our experience in transporting the LSP system, we identify the features that are required for transportable natural language systems.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {121–140},
numpages = {20}
}

@article{10.1145/3914.3983,
author = {Thompson, Bozena H. and Thompson, Frederick B.},
title = {ASK is Transportable in Half a Dozen Ways},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3914.3983},
doi = {10.1145/3914.3983},
abstract = {This paper is a discussion of the technical issues and solutions encountered in making the ASK System transportable. A natural language system can be “transportable” in a number of ways. Although transportability to a new domain is most prominent, other ways are also important if the system is to have viability in the commercial marketplace.On the one hand, transporting a system to a new domain may start with the system prior to adding any domain of knowledge and extend it to incorporate the new domain. On the other hand, one may wish to add to a system that already has knowledge of one domain the knowledge concerning a second domain, that is, to extend the system to cover this second domain. In the context of ASK, it has been natural to implement extending and then achieve transportability as a special case.In this paper, we consider six ways in which the ASK System can be extended to include new capabilities:Special-purpose applications, such as those to accommodate standard office tasks, would make use of these various means of extension.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {185–203},
numpages = {19}
}

@article{10.1145/3914.3982,
author = {Hafner, Carole D. and Godden, Kurt},
title = {Portability of Syntax and Semantics in DATALOG},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3914.3982},
doi = {10.1145/3914.3982},
abstract = {This paper presents a discussion of the techniques developed and problems encountered during the design, implementation, and experimental use of a portable natural language processor. Datalog (for “database dialogue") is an experimental natural language query system, which was designed to achieve a maximum degree of portability and extendibility. Datalog uses a three-level architecture to provide both portability of syntax to new and extended tasks and portability of semantics to new database applications. The implementation of each of the three levels, the structures and conventions that control the interactions among them, and the way in which different aspects of the design contribute to portability are described. Finally, two specific, implemented examples are presented, showing how it was possible to transport or extend Datalog by changing only one “layer” of the system's knowledge and achieve correct processing of the extended input by the entire system.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {141–164},
numpages = {24}
}

@article{10.1145/3914.3981,
author = {Slocum, Jonathan and Justus, Carol F.},
title = {Transportability to Other Languages: The Natural Language Processing Project in the AI Program at MCC},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3914.3981},
doi = {10.1145/3914.3981},
abstract = {We discuss a recently launched, long-term project in natural language processing, the primary concern of which is that natural language applications be transportable among human languages. In particular, we seek to develop system tools and linguistic processing techniques that are themselves language-independent to the maximum extent practical. In this paper we discuss our project goals and outline our intended approach, address some cross-linguistic requirements, and then present some new linguistic data that we feel support our approach.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {204–230},
numpages = {27}
}

@article{10.1145/3914.3915,
author = {Damerau, Fred J.},
title = {Problems and Some Solutions in Customization of Natural Language Database Front Ends},
year = {1985},
issue_date = {April 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3914.3915},
doi = {10.1145/3914.3915},
abstract = {This paper is concerned with some of the issues arising in the development of a domain-independent English interface to IBM SQL-based program products. The TQA system falls into the class of multilayered natural language processing systems. As a result, there is a large number of potential points at which customization to a particular database can be done. Of these, we discuss procedures that affect the reader, the lexicon, the lowest level of grammar rules, the semantic interpreter, and the output formatter. Our tests lead us to believe that the approach we are taking will make it possible for database administrators to generate robust English interfaces to particular databases without help from linguistic experts.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {165–184},
numpages = {20}
}

@article{10.1145/3864.3869,
author = {King, Roger and McLeod, Dennis},
title = {A Database Design Methodology and Tool for Information Systems},
year = {1985},
issue_date = {Jan. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3864.3869},
doi = {10.1145/3864.3869},
abstract = {A model and methodology for describing the information objects in an office information system and how such objects flow among the components of such a system are presented. The model and methodology support the specification of information objects at multiple levels of abstraction. An interactive prototype design tool based on the methodology and model has been designed and experimentally implemented.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {2–21},
numpages = {20}
}

@article{10.1145/3864.3868,
author = {Kincaid, Christine M. and Dupont, Pierre B. and Kaye, A. R.},
title = {Electronic Calendars in the Office: An Assessment of User Needs and Current Technology},
year = {1985},
issue_date = {Jan. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3864.3868},
doi = {10.1145/3864.3868},
abstract = {Manufacturers of integrated electronic office systems have included electronic versions of the calendar in almost every system they offer. This paper describes a survey of office workers, carried out to examine their use both of paper calendars and of electronic calendars that are commercially available as part of integrated office systems. It assesses the degree to which electronic calendars meet the needs of users. Our survey shows that the simple paper calendar is a tool whose power and flexibility is matched by few, if any, of the current commercially available electronic calendars. Recommendations for features that should be included in electronic calendars and automatic schedulers are included.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {89–102},
numpages = {14}
}

@article{10.1145/3864.3867,
author = {Gould, John D. and Lewis, Clayton and Barnes, Vincent},
title = {Cursor Movement during Text Editing},
year = {1985},
issue_date = {Jan. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3864.3867},
doi = {10.1145/3864.3867},
abstract = {Nine participants used a full-screen computer text editor (XEDIT) with an IBM 3277 terminal to edit marked-up documents at each of three cursor speeds (3.3, 4.7, and 11.0 cm/s). These speeds occur when a user continuously holds down an arrow key to move the cursor more than one character position (i.e., in  repeat or typamatic mode). Results show that cursor speed did not seem to act as a pacing device for the entire editing task. Since cursor speed is a form of system response, this finding is in contrast with the generally found positive relation between system-response time and user-response time. Participants preferred the Fast cursor speed, however. Overall, more than one-third of all keystrokes were used to move the cursor. We estimate that 9-14 percent of editing time was spent controlling and moving the cursor, regardless of cursor speed.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {22–34},
numpages = {13}
}

@article{10.1145/3864.3866,
author = {Hevner, Alan R. and Wu, O. Q. and Yao, S. B.},
title = {Query Optimization on Local Area Networks},
year = {1985},
issue_date = {Jan. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3864.3866},
doi = {10.1145/3864.3866},
abstract = {Local area networks are becoming widely used as the database communication framework for sophisticated information systems. Databases can be distributed among stations on a network to achieve the advantages of performance, reliability, availability, and modularity. Efficient distributed query optimization algorithms are presented here for two types of local area networks: address ring networks and broadcast networks. Optimal algorithms are designed for simple queries. Optimization principles from these algorithms guide the development of effective heuristic algorithms for general queries on both types of networks. Several examples illustrate distributed query processing on local area networks.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {35–62},
numpages = {28}
}

@article{10.1145/3864.3865,
author = {Weyer, Stephen A. and Borning, Alan H.},
title = {A Prototype Electronic Encyclopedia},
year = {1985},
issue_date = {Jan. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3864.3865},
doi = {10.1145/3864.3865},
abstract = {We describe a prototype electronic encyclopedia implemented on a powerful personal computer, in which user interface, media presentation, and knowledge representation techniques are applied to improving access to a knowledge resource. In itself, an electronic encyclopedia is an important information resource, but this work also illustrates the issues and approaches for many types of electronic information retrieval environments. In the prototype we make dynamic use of the structure and semantics of the text articles and index of an existing encyclopedia, while experimenting with other forms of representation, such as simulation and videodisc images. We present a long-term vision of an intelligent user-interface agent; summarize previous work related to futuristic encyclopedias, electronic books, decision support systems, and knowledge libraries; and outline current and potential research directions.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {63–88},
numpages = {26}
}

@article{10.1145/2275.357411,
author = {Faloutsos, Chris and Christodoulakis, Stavros},
title = {Signature Files: An Access Method for Documents and Its Analytical Performance Evaluation},
year = {1984},
issue_date = {Oct. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/2275.357411},
doi = {10.1145/2275.357411},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {267–288},
numpages = {22}
}

@article{10.1145/2275.2279,
author = {Higgins, Christopher A. and Safayeni, Frank R.},
title = {A Critical Appraisal of Task Taxonomies as a Tool for Studying Office Activities},
year = {1984},
issue_date = {Oct. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/2275.2279},
doi = {10.1145/2275.2279},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {331–339},
numpages = {9}
}

@article{10.1145/2275.2278,
author = {Mazer, Murray S. and Lochovsky, Frederick H.},
title = {Logical Routing Specification in Office Information Systems},
year = {1984},
issue_date = {Oct. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/2275.2278},
doi = {10.1145/2275.2278},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {303–330},
numpages = {28}
}

@article{10.1145/2275.2277,
author = {Paddock, Charles E. and Scamell, Richard W.},
title = {Office Automation Projects and Their Impact on Organization, Planning, and Control},
year = {1984},
issue_date = {Oct. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/2275.2277},
doi = {10.1145/2275.2277},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {289–302},
numpages = {14}
}

@article{10.1145/1206.357413,
author = {Yao, S. Bing and Hevner, Alan R. and Shi, Zhongzhi and Luo, Dawei},
title = {FORMANAGER: An Office Forms Management System},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/1206.357413},
doi = {10.1145/1206.357413},
journal = {ACM Trans. Inf. Syst.},
month = aug,
pages = {235–262},
numpages = {28}
}

@article{10.1145/1206.357412,
author = {Ellis, Clarence A.},
title = {Editor's Introduction},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/1206.357412},
doi = {10.1145/1206.357412},
journal = {ACM Trans. Inf. Syst.},
month = aug,
pages = {171–172},
numpages = {2}
}

@article{10.1145/1206.1485,
author = {Panko, Raymond R.},
title = {38 Offices:  Analyzing Needs in Individual Offices},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/1206.1485},
doi = {10.1145/1206.1485},
journal = {ACM Trans. Inf. Syst.},
month = aug,
pages = {226–234},
numpages = {9}
}

@article{10.1145/1206.1484,
author = {Radicati, Siranush},
title = {Managing Transient Internetwork Links in the Xerox Internet},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/1206.1484},
doi = {10.1145/1206.1484},
journal = {ACM Trans. Inf. Syst.},
month = aug,
pages = {213–225},
numpages = {13}
}

@article{10.1145/1206.1483,
author = {Croft, W Bruce and Lefkowitz, Lawrence S.},
title = {Task Support in an Office System},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/1206.1483},
doi = {10.1145/1206.1483},
journal = {ACM Trans. Inf. Syst.},
month = aug,
pages = {197–212},
numpages = {16}
}

@article{10.1145/1206.1207,
author = {Ahlsen, Matts and Bjornerstedt, Anders and Britts, Stefan and Hulten, Christer and Soderlund, Lars},
title = {An Architecture for Object Management in OIS},
year = {1984},
issue_date = {July 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/1206.1207},
doi = {10.1145/1206.1207},
journal = {ACM Trans. Inf. Syst.},
month = aug,
pages = {173–196},
numpages = {24}
}

@article{10.1145/521.523,
author = {Culnan, Mary J.},
title = {The Dimensions of Accessibility to Online Information:  Implications for Implementing Office Information Systems},
year = {1984},
issue_date = {April 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/521.523},
doi = {10.1145/521.523},
journal = {ACM Trans. Inf. Syst.},
month = may,
pages = {141–150},
numpages = {10}
}

@article{10.1145/521.522,
author = {Trauth, Eileen M. and Kwan, Stephen K and Barber, Susanna},
title = {Channel Selection and Effective Communication for Managerial Decision Making},
year = {1984},
issue_date = {April 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/521.522},
doi = {10.1145/521.522},
journal = {ACM Trans. Inf. Syst.},
month = may,
pages = {123–140},
numpages = {18}
}

@article{10.1145/521.357416,
author = {Bracchi, Giampio and Pernici, Barbara},
title = {The Design Requirements of Office Systems},
year = {1984},
issue_date = {April 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/521.357416},
doi = {10.1145/521.357416},
journal = {ACM Trans. Inf. Syst.},
month = may,
pages = {151–170},
numpages = {20}
}

@article{10.1145/521.357415,
author = {Lyngbaek, Peter and McLeod, Dennis},
title = {Object Management in Distributed Information Systems},
year = {1984},
issue_date = {April 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/521.357415},
doi = {10.1145/521.357415},
journal = {ACM Trans. Inf. Syst.},
month = may,
pages = {96–122},
numpages = {27}
}

@article{10.1145/521.357414,
author = {Terry, Douglas B. and Andler, Sten},
title = {The COSIE Communications Subsystem: Support for Distributed Office Applications},
year = {1984},
issue_date = {April 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/521.357414},
doi = {10.1145/521.357414},
journal = {ACM Trans. Inf. Syst.},
month = may,
pages = {79–95},
numpages = {17}
}

@article{10.1145/357417.357422,
author = {Tsichritzis, D.},
title = {Message Addressing Schemes},
year = {1984},
issue_date = {Jan. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357417.357422},
doi = {10.1145/357417.357422},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {58–77},
numpages = {20}
}

@article{10.1145/357417.357421,
author = {Hanson, Stephen Jos\'{e} and Kraut, Robert E. and Farber, James M.},
title = {Interface Design and Multivariate Analysis of UNIX Command Use},
year = {1984},
issue_date = {Jan. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357417.357421},
doi = {10.1145/357417.357421},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {42–57},
numpages = {16}
}

@article{10.1145/357417.357420,
author = {Kelley, J. F.},
title = {An Iterative Design Methodology for User-Friendly Natural Language Office Information Applications},
year = {1984},
issue_date = {Jan. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357417.357420},
doi = {10.1145/357417.357420},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {26–41},
numpages = {16}
}

@article{10.1145/357417.357418,
author = {Ballard, Bruce W. and Lusth, John C. and Tinkham, Nancy L.},
title = {LDC-1: A Transportable, Knowledge-Based Natural Language Processor for Office Environments},
year = {1984},
issue_date = {Jan. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357417.357418},
doi = {10.1145/357417.357418},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–25},
numpages = {25}
}

@article{10.1145/357442.357445,
author = {Suchman, Lucy A.},
title = {Office Procedure as Practical Action: Models of Work and System Design},
year = {1983},
issue_date = {Oct. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/357442.357445},
doi = {10.1145/357442.357445},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {320–328},
numpages = {9}
}

@article{10.1145/357442.357444,
author = {Gibbs, Simon and Tsichritzis, Dionysis},
title = {A Data Modeling Approach for Office Information Systems},
year = {1983},
issue_date = {Oct. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/357442.357444},
doi = {10.1145/357442.357444},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {299–319},
numpages = {21}
}

@article{10.1145/357442.357443,
author = {Gould, John D. and Boies, Stephen J.},
title = {Human Factors Challenges in Creating a Principal Support Office System—the Speech Filing System Approach},
year = {1983},
issue_date = {Oct. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/357442.357443},
doi = {10.1145/357442.357443},
journal = {ACM Trans. Inf. Syst.},
month = oct,
pages = {273–298},
numpages = {26}
}

@article{10.1145/357436.357440,
author = {Mack, Robert L. and Lewis, Clayton H. and Carroll, John M.},
title = {Learning to Use Word Processors: Problems and Prospects},
year = {1983},
issue_date = {July 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/357436.357440},
doi = {10.1145/357436.357440},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {254–271},
numpages = {18}
}

@article{10.1145/357436.357439,
author = {Oppen, Derek C. and Dalal, Yogen K.},
title = {The Clearinghouse: A Decentralized Agent for Locating Named Objects in a Distributed Environment},
year = {1983},
issue_date = {July 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/357436.357439},
doi = {10.1145/357436.357439},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {230–253},
numpages = {24}
}

@article{10.1145/357436.357438,
author = {Smith, Stephen A. and Benjamin, Robert I.},
title = {Projecting Demand for Electronic Communications in Automated Offices},
year = {1983},
issue_date = {July 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/357436.357438},
doi = {10.1145/357436.357438},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {211–229},
numpages = {19}
}

@article{10.1145/357436.357437,
author = {Israel, Jay E. and Linden, Theodore A.},
title = {Authentication in Office System Internetworks},
year = {1983},
issue_date = {July 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/357436.357437},
doi = {10.1145/357436.357437},
journal = {ACM Trans. Inf. Syst.},
month = jul,
pages = {193–210},
numpages = {18}
}

@article{10.1145/357431.357435,
author = {Brotz, Douglas K.},
title = {Message System Mores: Etiquette in Laurel},
year = {1983},
issue_date = {April 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/357431.357435},
doi = {10.1145/357431.357435},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {179–192},
numpages = {14}
}

@article{10.1145/357431.357434,
author = {Allen, Robert B. and Scerbo, M. W.},
title = {Details of Command-Language Keystrokes},
year = {1983},
issue_date = {April 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/357431.357434},
doi = {10.1145/357431.357434},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {159–178},
numpages = {20}
}

@article{10.1145/357431.357433,
author = {Stonebraker, Michael and Stettner, Heidi and Lynn, Nadene and Kalash, Joseph and Guttman, Antonin},
title = {Document Processing in a Relational Database System},
year = {1983},
issue_date = {April 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/357431.357433},
doi = {10.1145/357431.357433},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {143–158},
numpages = {16}
}

@article{10.1145/357431.357432,
author = {Nutt, Gary J.},
title = {An Experimental Distributed Modeling System},
year = {1983},
issue_date = {April 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/357431.357432},
doi = {10.1145/357431.357432},
journal = {ACM Trans. Inf. Syst.},
month = apr,
pages = {117–142},
numpages = {26}
}

@article{10.1145/357423.357430,
author = {Malone, Thomas W.},
title = {How Do People Organize Their Desks? Implications for the Design of Office Information Systems},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357430},
doi = {10.1145/357423.357430},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {99–112},
numpages = {14}
}

@article{10.1145/357423.357429,
author = {Tsichritzis, Dennis and Christodoulakis, Stavros},
title = {Message Files},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357429},
doi = {10.1145/357423.357429},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {88–98},
numpages = {11}
}

@article{10.1145/357423.357428,
author = {Srihari, Sargur N. and Hull, Jonathan J. and Choudhari, Ramesh},
title = {Integrating Diverse Knowledge Sources in Text Recognition},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357428},
doi = {10.1145/357423.357428},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {68–87},
numpages = {20}
}

@article{10.1145/357423.357427,
author = {Barber, Gerald},
title = {Supporting Organizational Problem Solving with a Work Station},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357427},
doi = {10.1145/357423.357427},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {45–67},
numpages = {23}
}

@article{10.1145/357423.357426,
author = {Bailey, Andrew D. and Gerlach, James H. and McAfee, R. Preston and Whinston, Andrew B.},
title = {An OIS Model for Internal Accounting Control Evaluation},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357426},
doi = {10.1145/357423.357426},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {25–44},
numpages = {20}
}

@article{10.1145/357423.357425,
author = {Purvy, Robert and Farrell, Jerry and Klose, Paul},
title = {The Design of Star's Records Processing: Data Processing for the Noncomputer Professional},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357425},
doi = {10.1145/357423.357425},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {3–24},
numpages = {22}
}

@article{10.1145/357423.357424,
author = {Limb, John O.},
title = {Editor's Introduction},
year = {1983},
issue_date = {Jan. 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/357423.357424},
doi = {10.1145/357423.357424},
journal = {ACM Trans. Inf. Syst.},
month = jan,
pages = {1–2},
numpages = {2}
}

