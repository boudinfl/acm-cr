@inproceedings{10.1145/2254129.2254131,
author = {Akerkar, Rajendra and B\u{a}dic\u{a}, Costin and Burdescu, Dumitru Dan},
title = {Desiderata for Research in Web Intelligence, Mining and Semantics},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254131},
doi = {10.1145/2254129.2254131},
abstract = {The Web has an immense impact on our daily activities at work, home, and leisure. As a result, more effective and efficient methods and technologies are needed to make the most of the Web's practically unlimited potential. The new Web-related research directions include intelligent methods usually associated with the areas of Computational Intelligence, Semantic Web, Soft Computing, and Data Mining. In this article, the necessity for research on Web intelligence, mining and semantics (WIMS) is discussed together with ways in which a wide range of research is benefiting this area for the long-term. Also the WIMS conference's goal and structure are presented.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {0},
numpages = {5},
keywords = {web semantics, web intelligence, big data information retrieval, web mining, social networks},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254133,
author = {Simperl, Elena},
title = {Crowdsourcing Semantic Data Management: Challenges and Opportunities},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254133},
doi = {10.1145/2254129.2254133},
abstract = {Linked Data refers to a set of guidelines and best practices for publishing and accessing structured data on the Web. It builds upon established Web technologies, in particular HTTP and URIs, extended with Semantic Web representation formats and protocols such as RDF, RDFS, OWL and SPARQL, by which data from different sources can be shared, interconnected and used beyond the application scenarios for which it was originally created. RDF is a central building block of the Linked Data technology stack. It is a graph-based data model based on the idea of making statements about (information and non-information) resources on the Web in terms of triples of the form subject predicate object. The object of any RDF triple may be used in the subject position in other triples, leading to a directed, labeled graph typically referred to as an 'RDF graph'. Both nodes and edges in such graphs are identified via URIs; nodes represent Web resources, while edges stand for attributes of such resources or properties connecting them. Schema information can be expressed using languages such as RDFS and OWL, by which resources can be typed as classes described in terms of domain-specific attributes, properties and constraints. RDF graphs can be natively queried using the query language SPARQL. A SPARQL query is composed of graph patterns and can be stored as RDF triples together with any RDF domain model using SPIN to facilitate the definition of constraints and inference rules in ontologies.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {1},
numpages = {3},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254134,
author = {Pan, Jeff Z.},
title = {"Closing" Some Doors for the Open Semantic Web},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254134},
doi = {10.1145/2254129.2254134},
abstract = {John McCarthy defines Artificial Intelligence (AI) as the science and engineering of making intelligent machines, especially intelligent computer systems. To build intelligent systems, many of AI researchers, including experts in machine learning and data mining, focus on building "smart applications", which perform complex transformations and manipulations on raw data to discover insights and hidden patterns. On the other hand, the Semantic Web, which exploits the state of the art technologies (in particular ontology reasoning) from Knowledge Representation, a well established branch of AI, attempts to build intelligent systems based on "smart data", which is annotated and described by ontological vocabulary. The "smart application" and "smart data" directions constitute two major approaches to intelligent system. The former is generally the inductive approach that exploits the pattern of large amount of data. The later is generally the deductive approach that exploits the possibilities of even a small fraction of data. These two approaches complement each other in many complex scenarios:• mining technologies can be used to help discover knowledges from huge data sets;• semantic technologies can be used to check if the discovered knowledge are consistent with the existing knowledge and, if so, exploit them so as to meet application requirements.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {2},
numpages = {2},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254136,
author = {Ermolayev, Vadim and Davidovsky, Maxim},
title = {Agent-Based Ontology Alignment: Basics, Applications, Theoretical Foundations, and Demonstration},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254136},
doi = {10.1145/2254129.2254136},
abstract = {In this paper, we describe the structure and outline the content of the tutorial on Agent-Based Ontology Alignment. The tutorial is planned in two parts with an overall timeframe of 2 hours. Part 1 covers the basics of ontology alignment -- basic definitions; problem statements and problem classification based on the settings; the applications of ontology alignment and the requirements to ontology alignment solutions. Part 2 is more advanced in a sense that it overviews and analyses agent-based frameworks for ontology alignment and offers a demonstration of an agent-based system that solves one of the problems of ontology alignment. The tutorial offers a walkthrough problem in ontology alignment -- ontology instance migration, which receives a more in-depth treatment throughout the tutorial. A walkthrough example of the two very simple Biblio ontologies is also used to make the narration consistent.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {3},
numpages = {12},
keywords = {ontology alignment, knowledge-based application, agent, ontology instance migration, negotiation, argumentation, ontology, information flow},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254137,
author = {Cuel, Roberta and Tokarchuck, Oksana and Kaczmarek, Monika and Dzikowski, Jakub and Simperl, Elena and undefinedazaruk, Szymon},
title = {Making Your Semantic Application Addictive: Incentivizing Users!},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254137},
doi = {10.1145/2254129.2254137},
abstract = {Since many semantic content creation methods and initiatives have been developed, a fully automatic process cannot be implemented. As a consequence, many application designers are interested in the question of how to motivate users to become a part of this endeavor, compensating the limitations of purely machine-driven content creation techniques. Methods from areas as diverse as community support, participation management, usability engineering, mechanism design, and social computing, can be applied to analyze semantically enabled applications, and design incentivized variants thereof. Building on top of these theories, we revisit fundamental design issues of semantic-content authoring technology focusing on the identification of a set of incentives that drives people to contribute, and on the ways such incentives can be translated into guidelines for technology and application designers. In order to show some best practices that designers should take into account encouraging large-scale user participation in semantic applications, we describe an experiment conducted with students of the Poznan University of Economics. Following the empirical findings and insights gained during the experimental operations, we propose some general guidelines, which provide software developers with a baseline to create semantics-based technologies and end-user applications that are not just functional, but facilitate and encourage user participation.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {4},
numpages = {8},
keywords = {semantic content authoring, software design, case study, experiment, human contributions, incentivized semantic applications, incentives, motivations},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254138,
author = {Mladeni\'{c}, Dunja and Grobelnik, Marko and Fortuna, Bla\v{z} and Rusu, Delia},
title = {Text Stream Processing},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254138},
doi = {10.1145/2254129.2254138},
abstract = {The aim of this tutorial is to present an overview of text stream processing starting with a description and properties of text streams, and continuing with a series of text processing techniques and their applicability to text streams. Among the text processing techniques we are going to describe entity extraction and resolution, event and fact extraction, word sense disambiguation, sentiment analysis, summarization, social network analysis, all in the context of text streams.The goal is to present the list of problems and challenges arising when processing text streams and to show how they can be approached using text mining, natural language processing and semantic analysis techniques and tools. The tutorial will describe available approaches and show some demos on text data streams, using publicly available tools.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {5},
numpages = {5},
keywords = {sentiment analysis, text stream, semantic web, web mining, social network analysis, word sense disambiguation, topic detection, entity recognition},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254139,
author = {Stan, Johann and Maret, Pierre},
title = {Semantic Metadata Management in Web 2.0},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254139},
doi = {10.1145/2254129.2254139},
abstract = {Interoperability between systems dealing with social data is a major challenge for the Social and Semantic Web. This tutorial talk compares the different models that have been proposed by the Semantic Web Community for capturing social content in social media sites(e.g. information about users and shared content). Several questions will be addressed related to these models: What are the existing models that allow to semantically capture and describe information about users, annotations in the social Web? What are the characteristics of such models? What are the differences between those models? The main objective of this talk is the mapping of such models to a set of high-level criteria that helps researchers and developers make their decision of which model to choose whenever there is a need to use a semantic metadata model and how to federate them.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {6},
numpages = {10},
keywords = {information systems, semantic web, knowledge representation, tutorial},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254140,
author = {Bassiliades, Nick},
title = {Agents and Knowledge Interoperability in the Semantic Web Era},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254140},
doi = {10.1145/2254129.2254140},
abstract = {This tutorial will discuss about issues, technologies and tools that concern the way that the Semantic Web affects knowledge and information interchange among intelligent agents in multi-agent systems, as well as reasoning interoperability. First, the tutorial will discuss how semantic web rules and ontologies interact with each other in order to be used as the agent's internal knowledge base for environment awareness and decision making. Then, interoperability between reasoning systems for agents will be discussed. The issues involved in all the previous discussion will be exemplified using actual implemented tools for semantic web reasoning in multi-agents systems.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {7},
numpages = {13},
keywords = {multiagent systems, knowledge interoperability, semantic web, ontologies, reasoning engines, rules},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254142,
author = {Ciortea, Andrei and Krupa, Yann and Vercouter, Laurent},
title = {Designing Privacy-Aware Social Networks: A Multi-Agent Approach},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254142},
doi = {10.1145/2254129.2254142},
abstract = {People do not generally mind that some personal information is shared, but that it is shared in the wrong ways and with inappropriate others. We introduce a model for the automatic detection of incompatible relationships among agents in a virtual community. We define this model to the aim of adding to the PrivaCIAS framework a new layer that follows the theory of contextual integrity in more depth. We describe in detail the implementation of a proof of concept privacy-aware photo-sharing social network that we had developed for Android smartphones. The social network was built on the extended PrivaCIAS framework, and thus illustrates its applicability in helping users to preserve privacy.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {8},
numpages = {8},
keywords = {contextual integrity, multi-agent systems, privacy, social networking, normative organizations},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254143,
author = {Bhat, Sajid Yousuf and Abulaish, Muhammad},
title = {A Density-Based Approach for Mining Overlapping Communities from Social Network Interactions},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254143},
doi = {10.1145/2254129.2254143},
abstract = {In this paper, we propose a density-based community detection method, CMiner, which exploits the interaction graph of online social networks to identify overlapping community structures. Based on the average reciprocated interactions of a node in the network, a new distance function is defined to find the similarity between a pair of nodes. The proposed method also provides a basic solution for automatic determination of the neighborhood threshold, which is a non-trivial problem for applying density-based clustering methods. Considering the local neighborhood of a node p, the distance function is used to determine the distance between the node p and its neighbors in the interaction graph to identify core nodes, which are then used to define overlapping communities. On comparing the experimental results with clique percolation and other related methods, we found that CMiner is comparable to the state-of-the-art methods and is also computationally faster.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {9},
numpages = {7},
keywords = {social network analysis, overlapping community detection, density-based clustering, community finding},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254144,
author = {Kardara, Magdalini and Papadakis, George and Papaoikonomou, Thanos and Tserpes, Konstantinos and Varvarigou, Theodora},
title = {Influence Patterns in Topic Communities of Social Media},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254144},
doi = {10.1145/2254129.2254144},
abstract = {Users of Social Media typically gather into communities on the basis of some common interest. Their interactions inside these on-line communities follow several, interesting patterns. For example, they differ in the level of influence they exert to the rest of the group: some community members are actively involved, affecting a large part of the community with their actions, while the majority comprises plain participants (e.g., information consumers). Identifying users of the former category lies on the focus of interest of many recent works, as they can be employed in a variety of applications, like targeted marketing.In this paper, we build on previous research that examined influencers in the context of a popular Social Media web site, namely Twitter. Unlike existing works that consider its user base as a whole, we focus on communities that are created on-the-fly by people that post messages about a particular topic (i.e., topic communities). We examine a large and representative sample of real-world communities and evaluate to which extent their influential users determine the aggregate behavior of the entire community. To this end, we consider a practical use case: we check whether the community's overall sentiment stems from the aggregate sentiment of this core group. We also examine the dynamics of groups of influencers by assessing the strength of the ties between them. In addition, we identify patterns in the content produced by influencers and the relation between influencers of different communities. Our experiments lead to interesting conclusions that highlight many aspects of influencers' activity inside topic communities; thus, they form the basis for intelligent, data mining techniques that can automatically discover influencers in the context of a community.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {10},
numpages = {12},
keywords = {social media, social influence, topic communities},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254145,
author = {Weitzel, Leila and Quaresma, Paulo and de Oliveira, Jos\'{e} Palazzo M.},
title = {Measuring Node Importance on Twitter Microblogging},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254145},
doi = {10.1145/2254129.2254145},
abstract = {Social Networks (SN) are created whenever people interact with other people in online social networks, such as Twitter, Google+, Facebook and etc. Twitter is a social networking and micro-blogging service; it creates several new interesting social network structures. In this sense, our main goal is to investigate the power of retweet mechanism. The findings suggest that relations of "friendship" at Twitter are important but not enough. Still, the centrality measures of a node importance do not show how important users are. We uncovered some other principles that must be studied like, homophily phenomenon, the tendency of individuals to associate and bond with similar others.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {11},
numpages = {7},
keywords = {Twitter, node importance, retweet, social network analysis},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254146,
author = {Mokarizadeh, Shahab and K\"{u}ngas, Peep and Matskin, Mihhail},
title = {Exploring Information Diffusion in Network of Semantically Annotated Web Service Interfaces},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254146},
doi = {10.1145/2254129.2254146},
abstract = {Information diffusion has been studied between and within biosphere, microblogs, social networks, citation networks and other domains where the network structure is present. These studies have been useful for acquiring intrinsic knowledge for strategic decision making in related areas, such as planning online campaigns in case of microblogs and blogosphere. However, despite of the advances in services science, no study has been published on analyzing information diffusion in Web services networks.This paper presents a model for measuring information diffusion between commodities of annotated Web services' descriptions. First, we exploit our previously developed ontology learning and annotation mechanism to semantically annotate harvested Web services' interface descriptions. Next, Web services networks are constructed by matching semantically annotated and categorized interfaces. Then we apply the proposed information diffusion discovery model to the constructed Web services networks. We evaluate the proposed model on two case studies---information diffusion between Web services of national registries and among commodities of public Web services. The model indicates high potential of the proposed method in understanding interactions between individual service providers and service industries.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {12},
numpages = {10},
keywords = {information diffusion, web services networks, semantic web services},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254148,
author = {Giannakopoulos, George and Mavridi, Petra and Paliouras, Georgios and Papadakis, George and Tserpes, Konstantinos},
title = {Representation Models for Text Classification: A Comparative Analysis over Three Web Document Types},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254148},
doi = {10.1145/2254129.2254148},
abstract = {Text classification constitutes a popular task in Web research with various applications that range from spam filtering to sentiment analysis. To address it, patterns of co-occurring words or characters are typically extracted from the textual content of Web documents. However, not all documents are of the same quality; for example, the curated content of news articles usually entails lower levels of noise than the user-generated content of the blog posts and the other Social Media.In this paper, we provide some insight and a preliminary study on a tripartite categorization of Web documents, based on inherent document characteristics. We claim and support that each category calls for different classification settings with respect to the representation model. We verify this claim experimentally, by showing that topic classification on these different document types offers very different results per type. In addition, we consider a novel approach that improves the performance of topic classification across all types of Web documents: namely the n-gram graphs. This model goes beyond the established bag-of-words one, representing each document as a graph. Individual graphs can be combined into a class graph and graph similarities are then employed to position and classify documents into the vector space. Accuracy is increased due to the contextual information that is encapsulated in the edges of the n-gram graphs; efficiency, on the other hand, is boosted by reducing the feature space to a limited set of dimensions that depend on the number of classes, rather than the size of the vocabulary. Our experimental study over three large-scale, real-world data sets validates the higher performance of n-gram graphs in all three domains of Web documents.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {13},
numpages = {12},
keywords = {n-gram graphs, web document types, text classification},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254149,
author = {Papadakis, George and Kawase, Ricardo and Herder, Eelco},
title = {Client- and Server-Side Revisitation Prediction with SUPRA},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254149},
doi = {10.1145/2254129.2254149},
abstract = {Users of collaborative applications as well as individual users in their private environment return to previously visited Web pages for various reasons; apart from pages visited due to backtracking, they typically have a number of favorite or important pages that they monitor or tasks that reoccur on an infrequent basis. In this paper, we introduce a library of methods that facilitate revisitation through the effective prediction of the next page request. It is based on a generic framework that inherently incorporates contextual information, handling uniformly both server- and the client-side applications. Unlike other existing approaches, the methods it encompasses are real-time, since they do not rely on training data or machine learning algorithms. We evaluate them over two large, real-world datasets, with the outcomes suggesting a significant improvement over methods typically used in this context. We have also made our implementation and data publicly available, thus encouraging other researchers to use it as a benchmark and to extend it with new techniques for supporting user's navigational activity.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {14},
numpages = {12},
keywords = {revisitation prediction, web behavior, contextual support},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254150,
author = {Kamal, Ahmad and Abulaish, Muhammad and Anwar, Tarique},
title = {Mining Feature-Opinion Pairs and Their Reliability Scores from Web Opinion Sources},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254150},
doi = {10.1145/2254129.2254150},
abstract = {Due to proliferation of Web 2.0, there is an exponential growth in user generated contents in the form of customer reviews on the Web, containing precious information useful for both customers and manufacturers. However, most of the contents are stored in either unstructured or semi-structured format due to which distillation of knowledge from this huge repository is a challenging task. In this paper, we propose a text mining approach to mine product features, opinions and their reliability scores from Web opinion sources. A rule-based system is implemented, which applies linguistic and semantic analysis of texts to mine feature-opinion pairs that have sentence-level co-occurrence in review documents. The extracted feature-opinion pairs and source documents are modeled using a bipartite graph structure. Considering feature-opinion pairs as hubs and source documents as authorities, Hyperlink-Induced Topic Search (HITS) algorithm is applied to generate reliability score for each feature-opinion pair with respect to the underlying corpus. The efficacy of the proposed system is established through experimentation over customer reviews on different models of electronic products.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {15},
numpages = {7},
keywords = {feature identification, text mining, opinion mining, opinion reliability},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254151,
author = {Fan, Wei and Watanabe, Toyohide},
title = {Dynamic Prediction of Forthcoming Trends in Stock Prices from News Articles},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254151},
doi = {10.1145/2254129.2254151},
abstract = {In this paper, given a news article referring to one company, we decide whether it is a piece of good news that is followed by a moving-up trend in the company's stock market or a piece of bad news reversely. Additionally, we predict how will the fluctuation of stock price be influenced by the news article. The existing research work did not support flexible identification of the trends in stock price series, or take account of the case that temporal consecutive news articles may influence the stock market sensitively. In our proposed methods, we realize a more flexible and accurate investigation of correlation between news articles and stock prices. Experiments of our proposed methods yield high accuracy of prediction. The proposed mechanism for dynamically choosing sliding window to identify trends is also proven to be effective.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {16},
numpages = {9},
keywords = {sliding window, support vector regression, correlation, classification, information system},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254152,
author = {Sayyadiharikandeh, Mohsen and Ghodsi, Mohammad and Naghibi, Mohammad},
title = {PostRank: A New Algorithm for Incremental Finding of Persian Blog Representative Words},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254152},
doi = {10.1145/2254129.2254152},
abstract = {Dimension reduction techniques for text documents can be used for in the preprocessing phrase of blog mining, but these techniques can be more effective if they deal with the nature of the blogs properly. In this paper we propose a novel algorithm called PostRank using shallow approach to identify theme of the blog or blog representative words in order to reduce the dimensions of blogs. PostRank uses a graph-based syntactic representation of the weblog by taking into account some structural features of weblog. At the first step it models the blog as a complete graph and assumes the theme of the blog as a query applied to a search engine like Google and each post as a search result. It tries to rank the posts using Markov chain model like PageRank in Google. We used the ranking model under the assumption that top ranked nodes contain blog best representative words. Then it tries to identify post groups according to their scores. Finally this algorithm analyzes the first group using statistical methods(like TF-IDF) to identify blog representative words. Other groups are candidates of having blog theme after occurring change of theme to the blog. By arriving new instances of posts we try to update the blog graph by setting the initial scores of old nodes in the Markov chain to their final score from last run and continue the PostRank iterations until reaching convergence point. If half of the representative words have changed we would say that theme of the weblog has been changed.We evaluated our method on the Persianblog dataset and obtained promising results. The blogs have been assigned to ten representative words by human beings and the results of PostRank have been compared to them and results of old related algorithms in this area.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {17},
numpages = {6},
keywords = {dimension reduction-incremental-Markov chain},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254153,
author = {Hammerton, James A. and Granitzer, Michael and Harvey, Dan and Hristakeva, Maya and Jack, Kris},
title = {On Generating Large-Scale Ground Truth Datasets for the Deduplication of Bibliographic Records},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254153},
doi = {10.1145/2254129.2254153},
abstract = {Mendeley's crowd-sourced catalogue of research papers forms the basis of features such as the ability to search for papers, finding papers related to one currently being viewed and personalised recommendations. In order to generate this catalogue it is necessary to deduplicate the records uploaded from users' libraries and imported from external sources such as PubMed and arXiv. This task has been achieved at Mendeley via an automated system.However the quality of the deduplication needs to be improved. "Ground truth" data sets are thus needed for evaluating the system's performance but existing datasets are very small. In this paper, the problem of generating large scale data sets from Mendeley's database is tackled. An approach based purely on random sampling produced very easy data sets so approaches that focus on more difficult examples were explored. We found that selecting duplicates and non duplicates from documents with similar titles produced more challenging datasets. Additionally we established that a Solr-based deduplication system can achieve a similar deduplication quality to the fingerprint-based system currently employed. Finally, we introduce a large scale deduplication ground truth dataset that we hope will be useful to others tackling deduplication.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {18},
numpages = {12},
keywords = {bibliographic metadata, nearest neighbor search, fingerprinting, near duplicate detection},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254154,
author = {Granitzer, Michael and Hristakeva, Maya and Knight, Robert and Jack, Kris and Kern, Roman},
title = {A Comparison of Layout Based Bibliographic Metadata Extraction Techniques},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254154},
doi = {10.1145/2254129.2254154},
abstract = {Social research networks such as Mendeley and CiteULike offer various services for collaboratively managing bibliographic metadata. Compared with traditional libraries, metadata quality is of crucial importance in order to create a crowdsourced bibliographic catalog for search and browsing. Artifacts, in particular PDFs which are managed by the users of the social research networks, become one important metadata source and the starting point for creating a homogeneous, high quality, bibliographic catalog. Natural Language Processing and Information Extraction techniques have been employed to extract structured information from unstructured sources. However, given highly heterogeneous artifacts that cover a range of publication styles, stemming from different publication sources, and imperfect PDF processing tools, how accurate are metadata extraction methods in such real-world settings? This paper focuses on answering that question by investigating the use of Conditional Random Fields and Support Vector Machines on real-world data gathered from Mendeley and Linked-Data repositories. We compare style and content features on existing state-of-the-art methods on two newly created real-world data sets for metadata extraction. Our analysis shows that two-stage SVMs provide reasonable performance in solving the challenge of metadata extraction for crowdsourcing bibliographic metadata management.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {19},
numpages = {8},
keywords = {layout features, bibliographic metadata, research papers, metadata extraction},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254155,
author = {Men\'{e}ndez, H\'{e}ctor and Bello-Orgaz, Gema and Camacho, David},
title = {Features Selection from High-Dimensional Web Data Using Clustering Analysis},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254155},
doi = {10.1145/2254129.2254155},
abstract = {The features selection methodologies have become an important field of the data preprocessing techniques. These methods are applied to reduced the dimension of the attributes of different datasets to simplify their analysis. Some of the classical techniques used are wrapper approaches, heuristic functions and filters. The main problem of these approaches is that they usually are black box and computationally expensive algorithms. This work presents a new straightforward strategy to reduce the dimension of the attributes. This new methodology cares about the variables distribution and has been oriented to clustering analysis. It provides an easier human interpretation of the attributes selection strategy and the resulting clusters. Finally, this new approach has been experimentally tested using the FIFA World Cup web dataset, a well-known social-based statistical data with a high number of variables, to show how the features selection strategy find the most relevant variables.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {20},
numpages = {9},
keywords = {data projection, clustering techniques, FIFA, football, soccer, web mining, world cup, feature selection},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254156,
author = {Muntean, Maria and V\u{a}lean, Honoriu},
title = {Wrappers for Web Access Logs Feature Selection},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254156},
doi = {10.1145/2254129.2254156},
abstract = {The Web Usage Mining (WUM), a rather recent research field, corresponds to the process of knowledge discovery from databases (KDD) applied to the Web usage data. The quantity of the Web usage data to be analyzed and its poor quality (in particular the abundance of features to be analyzed) are the main problems in WUM.Considering the characteristics of Web log data and functions of every phase included in data preprocessing, this paper establishes a Web log data preprocessing algorithm based on feature selection. The implemented Wrapper Evaluation feature selection method use a Best First Search and a Greedy Stepwise Search and evaluate each of the attribute subsets according to Support Vector Machine learning scheme.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {21},
numpages = {7},
keywords = {accuracy, improvement, classification, feature selection},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254157,
author = {Bagheri, Mohammad An and Gao, Qigang},
title = {An Efficient Ensemble Classification Method Based on Novel Classifier Selection Technique},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254157},
doi = {10.1145/2254129.2254157},
abstract = {Individual classification models have recently been challenged by ensemble of classifiers, also known as multiple classifier system, which often shows better classification accuracy. In terms of merging the outputs of an ensemble of classifiers, classifier selection has not attracted as much attention as classifier fusion in the past, mainly because of its higher computational burden. In this paper, we propose a novel technique for improving classifier selection. In our method, the simple divide-and-conquer strategy is adapted in that a complex classification problem is divided into simpler binary sub-classification problems. The proposed ensemble classification technique has the following advantages: f) it requires much less computation than the existing ensemble classification methods. 2) It improves overall classification accuracy. 3) It is also suitable for tackling the classification problems which have a relatively large number of target classes. We conduct extensive experiments on a series of multi-class datasets from the UCI (University of California, Irvine) repository and compare several well-known classification approaches. The experimental results demonstrate the advanced performance of the proposed method.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {22},
numpages = {7},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254159,
author = {Bock, J\"{u}rgen and L\"{o}sch, Uta and Wang, Hai},
title = {Automatic Reasoner Selection Using Machine Learning},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254159},
doi = {10.1145/2254129.2254159},
abstract = {The ability to draw logical conclusions in ontologies from explicitly given axioms and facts is one of the key advantages of using semantic technologies. Based on the W3C recommendation of the Web Ontology Language (OWL) a variety of reasoners have been developed for this task. Different language profiles, reasoning algorithms, and special-purpose optimisation techniques have brought up reasoners with various strengths and weaknesses. Selecting the most suitable reasoner for a given reasoning scenario thus is a challenge. This paper presents an automatic reasoner selection approach based on machine learning techniques. The most important ontology and query features are identified and used for learning a model that can be used to predict the best performing reasoner for a given request. The approach is implemented as a strategy in a reasoning broker framework called HERAKLES. Using a training set consisting of 187 real-world ontologies found on the Internet, we evaluated four different machine learning techniques. The results show that a machine learning based reasoner selection strategy can predict the best performing reasoner for a given reasoning request with more than 77% accuracy.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {23},
numpages = {12},
keywords = {ontology reasoning, brokerage, logics, machine learning},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254160,
author = {Simic, Hrvoje},
title = {Predicate Trees: A Tool for Descriptive Subgraph Extraction},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254160},
doi = {10.1145/2254129.2254160},
abstract = {Extracting a subgraph descriptive of a single resource from a given RDF graph is an issue relevant to the Linked Data initiative, RDF triple stores and Semantic Web in general. Existing methods of subgraph extraction tend to be either simple and inexpressive, or else powerful and complex. This paper introduces a novel method of descriptive subgraph extraction as a new expression language and as a domain-specific language library in Scala, which aims to be more expressive than the former and easier to write and use than the latter methods. These expressions can then be translated into SPARQL, used directly on triple pattern matching interfaces for RDF graphs, or as DESCRIBE handlers in SPARQL engines. A comparison highlighting advantages and limitations of the new method is also given.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {24},
numpages = {9},
keywords = {SPARQL, linked data, scala, subgraph extraction, RDF data access},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254161,
author = {Llaves, Alejandro and Michels, Henry and Mau\'{e}, Patrick and Roth, Marcell},
title = {Semantic Event Processing in ENVISION},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254161},
doi = {10.1145/2254129.2254161},
abstract = {The Semantic Sensor Web provides a framework for the interoperable exchange and processing of observation data from heterogeneous sensor networks. Environmental monitoring applications deal with change detection in a spatio-temporal context. Here it is required to analyze vast amounts of sensor data in order to react to specific situations. In the ENVISION project, we explore how to enhance this process of sense&amp;respond by using Complex Event Processing (CEP) techniques. CEP allows defining situations of change in observable variables using event patterns. By combining event processing and semantic technologies we are able to process time-series of observations from different sources and communicate the inferred events to interested communities in near real-time.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {25},
numpages = {9},
keywords = {semantic sensor web, complex event processing, real-time sensor data},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254162,
author = {Hu, Yuh-Jong and Wu, Win-Nan and Cheng, Di-Rong},
title = {Towards Law-Aware Semantic Cloud Policies with Exceptions for Data Integration and Protection},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254162},
doi = {10.1145/2254129.2254162},
abstract = {The main issues related to cloud computing implementation are security, privacy, and law-awareness. We consider data protection with law-awareness as the major concern for cloud service providers (CSPs) and their customers. Therefore, we provide Law-as-a-Service (LaaS) for CSPs on our law-aware semantic cloud policy infrastructure. The semantic legal policies in compliance with the laws are enforced automatically at the super-peer to enable LaaS. This allows CSPs to deploy their cloud resources and services without worrying about law violations. Afterward, users could query data from the law-aware super-peer within a super-peer domain. Each query is also compliant with the laws. Policies are shown as a combination of OWL-DL ontologies and stratified Datalog rules with negation for a policy's exceptions handling through defeasible (or non-monotonic) reasoning. Finally, the proof-of-concepts prototype systems have been implemented for an H1N1 pandemic investigation scenario in the semantic cloud to justify our approach.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {26},
numpages = {12},
keywords = {privacy, privacy protection, Law-as-a-Service (LaaS), WWW, semantic cloud, legal policies, defeasible reasoning, semantic web, stratified datalog with negation, cloud computing},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254163,
author = {Capelle, Michel and Frasincar, Flavius and Moerland, Marnix and Hogenboom, Frederik},
title = {Semantics-Based News Recommendation},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254163},
doi = {10.1145/2254129.2254163},
abstract = {News item recommendation is commonly performed using the TF-IDF weighting technique in combination with the cosine similarity measure. However, this technique does not take into account the actual meaning of words. Therefore, we propose two new methods based on concepts and their semantic similarities, from which we derive the similarities between news items. Our first method, Synset Frequency -- Inverse Document Frequency (SF-IDF), is similar to TF-IDF, yet it does not use terms, but WordNet synonym sets. Additionally, our second method, Semantic Similarity (SS), makes use of five semantic similarity measures to compute the similarity between news items for news recommendation. Test results show that SF-IDF and SS outperform the TF-IDF method on the F1-measure.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {27},
numpages = {9},
keywords = {semantic similarity, user profiling, news personalization, semantic web, recommender systems, content-based recommender},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254164,
author = {Meditskos, Georgios and Bassiliades, Nick and Vrakas, Dimitris and Vlahavas, Ioannis},
title = {IRISPortal: A Semantic Portal for Industrial Risk Cases Management},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254164},
doi = {10.1145/2254129.2254164},
abstract = {In this paper, we describe the architecture and functionality of IRISPortal, a semantic portal that allows the management of industrial risk cases by exploiting state-of-the-art semantic technologies, such as the OWL 2 language and the OWLIM semantic repository. The portal allows the web-based management of risk cases that are modeled in terms of a risk ontology, assisting the domain experts to perform administrative tasks, such as adding, deleting and updating risk cases. Furthermore, the portal provides the functionality to the end-users for searching and browsing the modeled risk cases and their corresponding characteristics, based on the semantic relationships that derive from the ontology model after the reasoning procedure.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {28},
numpages = {8},
keywords = {rule-based reasoning, OWL, risk management, web application, semantic web},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254165,
author = {Wali, Bacem and Gibaud, Bernard},
title = {Semantic Annotation of Image Processing Tools},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254165},
doi = {10.1145/2254129.2254165},
abstract = {Collaborative biomedical imaging research raises the issue of coherently sharing data and processing tools involved in multicentric studies. Federative approaches are gaining increasing credibility and success to build distributed collaborative platforms. In the context of the NeuroLOG project, we designed the OntoNeuroLOG ontology as a cornerstone of our mediation layer. This contribution focuses on processing tools and is twofold. We propose an extension of the OntoNeuroLOG ontology to conceptualize shared processing tools and enable their semantic annotation. Leveraging this modeling, we propose a set of semantic treatments aimed at easing their sharing, their reuse and their invocation in the context of neuro-data processing workflows.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {29},
numpages = {12},
keywords = {web services composition, web services, semantic annotation},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254166,
author = {Stavropoulos, Thanos G. and Vrakas, Dimitris and Vlachava, Danai and Bassiliades, Nick},
title = {BOnSAI: A Smart Building Ontology for Ambient Intelligence},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254166},
doi = {10.1145/2254129.2254166},
abstract = {This work introduces an ontology for incorporating Ambient Intelligence in Smart Buildings. The ontology extends and benefits from existing ontologies in the field, but also adds classes needed to sufficiently model every aspect of a service-oriented smart building system. Namely, it includes concepts modeling all functionality (i.e. services, operations, inputs, outputs, logic, parameters and environmental conditions), QoS (resources, QoS parameters), hardware (smart devices, sensors and actuators, appliances, servers) users and context (user profiles, moods, location, rooms etc.). The ontology is instantiated and put to use at the Smart Building setting of the International Hellenic University, enabling knowledge representation in machine-interpretable form and hence is expected to enhance service-based intelligent applications.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {30},
numpages = {12},
keywords = {semantic web, ambient intelligence, ontologies},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254168,
author = {Paulheim, Heiko and F\"{u}mkranz, Johannes},
title = {Unsupervised Generation of Data Mining Features from Linked Open Data},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254168},
doi = {10.1145/2254129.2254168},
abstract = {The quality of the results of a data mining process strongly depends on the quality of the data it processes. A good result is more likely to obtain the more useful background knowledge there is in a dataset. In this paper, we present a fully automatic approach for enriching data with features that are derived from Linked Open Data, a very large, openly available data collection. We identify six different types of feature generators, which are implemented in our open-source tool FeGeLOD. In four case studies, we show that our approach can be applied to different problems, ranging from classical data mining to ontology learning and ontology matching on the semantic web. The results show that features generated from publicly available information may allow data mining in problems where features are not available at all, as well as help improving the results for tasks where some features are already available.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {31},
numpages = {12},
keywords = {feature generation, ontology learning, semantic web, machine learning, ontology matching, linked open data, data mining},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254169,
author = {Bettencourt, Nuno and Peixoto, Rafael and Silva, Nuno},
title = {Automatic Traceability Acquisition Framework},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254169},
doi = {10.1145/2254129.2254169},
abstract = {In this paper we will describe an automatic traceability acquisition framework for existing web applications and how to take advantage of acquired provenance information about user actions on the Internet, namely resource uploading. We will show how traceability information provided by common websites can be stored in available Linked Open Data repositories, thus enhancing cross-domain trust upon resources published on the World Wide Web. A framework such as this is also submitted to evaluation on the popular Word-Press web application, demonstrating how easily it can be deployed to existing web applications.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {32},
numpages = {7},
keywords = {user generated content, provenance, traceability, framework, action sensors},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254170,
author = {Fisichella, Marco and De Coi, Juri Luca and Kawase, Ricardo and Matera, Maristella},
title = {User Profile Based Activities in Flexible Processes},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254170},
doi = {10.1145/2254129.2254170},
abstract = {COOPER platform is a collaborative, open environment that leverages on the idea of flexible, user-centric process support. It allows cooperating team members to define collaborative processes and flexibly modify the process activities even during process execution. In this paper we describe how the incorporation of decentralized user data through mashups, allows the COOPER platform to support the definition and execution of the so called user profile based activities, i.e., process activities that are adapted based on the preferences of the process actors. We define two basic types of user profile based activities, namely user adapted activities and user conditional activities. The first are modeled according to the user profile data, while the second employs the same user data to enable automatic workflow decisions.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {33},
numpages = {10},
keywords = {user profiles, atomic activities, web application design, mashups, adaptive activities, flexible processes},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254172,
author = {Colhon, Mihaela and Simionescu, Radu},
title = {Deriving a Statistical Syntactic Parsing from a Treebank},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254172},
doi = {10.1145/2254129.2254172},
abstract = {The study presented in this article is dedicated to a syntactic parser for Romanian. The central goal of the presented technique is to learn a model which is able to discriminate between probability for a word to be head of another word in a dependency structure corresponding to a sentence in the considered language. The model described in this paper was trained on a dependency treebank linguistic resource and is intended to be used in order to develop a dependency syntactic parser.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {34},
numpages = {8},
keywords = {maximum entropy model, dependency relations, syntactic parsing, Romanian language},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254173,
author = {Das, Amitava and Bandyopadhyay, Sivaji and Gamb\"{a}ck, Bj\"{o}rn},
title = {Sentiment Analysis: What is the End User's Requirement?},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254173},
doi = {10.1145/2254129.2254173},
abstract = {In this paper we address the Sentiment Analysis problem from the end user's perspective. An end user might desire an automated at-a-glance presentation of the main points made in a single review or how opinion changes time to time over multiple documents. To meet the requirement we propose a relatively generic opinion 5Ws structurization, further used for textual and visual summary and tracking. The 5W task seeks to extract the semantic constituents in a natural language sentence by distilling it into the answers to the 5W questions: Who, What, When, Where and Why. The visualization system facilitates users to generate sentiment tracking with textual summary and sentiment polarity wise graph based on any dimension or combination of dimensions as they want i.e. "Who" are the actors and "What" are their sentiment regarding any topic, changes in sentiment during "When" and "Where" and the reasons for change in sentiment as "Why".},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {35},
numpages = {10},
keywords = {sentiment tracking, sentiment visualization, 5W structurization, sentiment summarization},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254174,
author = {Tagarelli, Andrea and Gullo, Francesco},
title = {Evaluating PageRank Methods for Structural Sense Ranking in Labeled Tree Data},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254174},
doi = {10.1145/2254129.2254174},
abstract = {Link analysis methods like the popular PageRank are increasingly being applied to lexical knowledge bases to deal with a number of natural language processing problems, including unsupervised word sense ranking and disambiguation. Compared to plain-text, the topic of sense ranking in semistructured data has been however studied marginally.This paper aims to bridge PageRank-based word sense ranking and tree-structured data. We propose PageRank-style methods for the structural sense ranking problem, which take into account tree structural relations as well as semantic relatedness in the constituents of tree data. The proposed methods are comparatively evaluated with existing Page-Rank methods for word sense disambiguation. Effectiveness and efficiency of PageRank methods have been assessed on various data with different domain vocabularies.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {36},
numpages = {12},
keywords = {semantic relatedness, tree-structured data, word sense disambiguation, WordNet, ranking},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254175,
author = {Daniil, Constantin and Dascalu, Mihai and Trausan-Matu, Stefan},
title = {Automatic Forum Analysis: A Thorough Method of Assessing the Importance of Posts, Discussion Threads and of Users' Involvement},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254175},
doi = {10.1145/2254129.2254175},
abstract = {Building a dependable hierarchy of users and posts by analyzing forums proves to be a complex and time consuming task, while its importance increases with the wider spread of Computer Supported Collaborative Learning (CSCL) environments. In this context, building a system that automatically assesses posts or utterances, predefined discussion threads and users seemed more than appropriate since no system addresses in detail this kind of task. In order to obtain a holistic perspective and a deep and thorough analysis, multiple factors were evaluated and a multistep algorithm was developed. Our approach uses a multi-layered architecture that best fits the task at hand. Manual adjustments of each weight were conducted in order to best fit the obtained results with those of human evaluators. Although improvements can be included in our approach, current results are optimistic by surpassing existing and conventional methods (e.g. number of posts, creation date of the account, votes given by other users, the moderator's appreciation).},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {37},
numpages = {9},
keywords = {social involvement, user assessment, post, thread, forum analysis},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254177,
author = {Kravari, Kalliopi and Bassiliades, Nick},
title = {Advanced Agent Discovery Services},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254177},
doi = {10.1145/2254129.2254177},
abstract = {The Semantic Web aims at augmenting the WWW with meaning, assisting people and machines in comprehending Web content and better satisfying their requests. Intelligent agents are considered to be greatly favored by Semantic Web technologies, because of the interoperability the latter will achieve. As a result, a plethora of multi-agent systems is already in use. One of the main problems in these systems is the lack of sufficient discovery and interaction monitoring tools. This paper reports on the design and implementation of advanced agent discovery services. These services are distinguished in two main categories; namely advanced semantic directory and discovery services (yellow pages) and trust-based discovery services which support among others interaction monitoring tools. Their implementation, including the associated graphical interface, was integrated into the EMERALD framework, a knowledge-based framework for interoperating agents. Finally, a software trade use case scenario is presented, which better displays the potential of the proposed approach.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {38},
numpages = {12},
keywords = {intelligent agents, semantic web, discovery services},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254178,
author = {Cuibus, Mihai and Potolea, Rodica},
title = {Adaptable Swarm Intelligence Framework},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254178},
doi = {10.1145/2254129.2254178},
abstract = {Modern software systems must be continuously adapted to current performance and usability requirements. Indicators like overhead, computational complexity, parameter tuning, or ease of design and implementation are getting increasingly harder to accomplish due to constant increase in system dimensions like code size, API (Application Programming Interface), deployment size, component communication, network lag etc. Furthermore, many entities rely on classic, highly deterministic algorithms that are little or not capable of changing strategies on the fly. Lately, bio-inspired algorithms have successfully tackled this problem with significant, positive results. We propose a framework that may prove useful in obtaining better performance by automatically selecting and combining the best swarm intelligence algorithms with the best parameter selection.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {39},
numpages = {7},
keywords = {swarm intelligence, ant colony optimization, genetic algorithms, adaptable, framework},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254179,
author = {Mitrovi\'{c}, Dejan and Geler, Zoltan and Ivanovi\'{c}, Mirjana},
title = {Distributed Distance Matrix Generator Based on Agents},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254179},
doi = {10.1145/2254129.2254179},
abstract = {The process of calculating similarities between different time series of a dataset -- i.e. a distance matrix -- is often very time-consuming, but can be sped-up significantly using distributed programming. This paper presents a distributed system for calculating the distance matrix that utilizes the agent technology. Software agents are employed to deal with dynamic properties of the computational network, such as sudden unavailability of a number of computers, as well as for load-balancing and task-sharing.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {40},
numpages = {6},
keywords = {software agents, distributed programming, time-series analysis},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254180,
author = {Pop, Cristina Bianca and Anghel, Ionut and Cioara, Tudor and Salomie, Ioan and Vartic, Iulia},
title = {A Swarm-Inspired Data Center Consolidation Methodology},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254180},
doi = {10.1145/2254129.2254180},
abstract = {This paper proposes a swarm-inspired data center consolidation methodology which aims at reducing the power consumption in data centers while ensuring the workload execution within the pre-established performance parameters. Each data center server is managed by an intelligent agent that deals with its power efficiency by implementing a bird's migration-inspired behavior to decide on the appropriate server consolidation actions. The selected actions are executed to achieve an optimal utilization of server computing resources thus lowering power consumption. The data center servers self-organize in logical clusters according to the birds V-formation self-organizing migration model. The results are promising showing that the swarm-inspired data center consolidation methodology optimizes the utilization ratio of the data center computing resources and achieves estimated power savings of about 16%.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {41},
numpages = {7},
keywords = {data center, server consolidation, birds V-formation, swarm optimization},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254181,
author = {Ilie, Sorin and B\u{a}dic\u{a}, Costin and B\u{a}dic\u{a}, Amelia and Sandu, Liviu and Sbora, Raluca and Ganzha, Maria and Paprzycki, Marcin},
title = {Information Flow in a Distributed Agent-Based Online Auction System},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254181},
doi = {10.1145/2254129.2254181},
abstract = {Recently we were involved in the development of a distributed agent-based English auction server. The focus of the work was on emphasizing the advantages brought by the multi-agent systems technology to the high-level of abstraction, modularity and performance of the server architecture, and its implementation. Less effort was spent on the analysis of its external functionalities and usability, as well as on approaching the implementation of a realistic system for online auctions. Therefore, in this paper we present our solution, in terms of information flow management, and its relation to the functionalities of the system for online auctions that incorporates our server. The main outcome of this work is a clean specification of the information exchanges between the agent and non-agent software components of the system. Special attention is also provided for the interoperability of the different data communication, and agent and non-agent software technologies that are employed for the implementation of the system.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {42},
numpages = {9},
keywords = {multi-agent system, software design},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254183,
author = {Duan, Huiying and Liu, Feifei},
title = {Building and Managing Reputation in the Environment of Chinese E-Commerce: A Case Study on Taobao},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254183},
doi = {10.1145/2254129.2254183},
abstract = {We propose a lightweight reputation model R-Rep, for resisting manipulative behavior in Reputation Systems. We present a manipulative behavior detection system CSI to detect the customers who provide manipulative ratings, and the vendors who intend to increase their reputation value in a strategic manner. Via analysing motivation of manipulative behavior, we specify features for identifying suspicious customers using clustering algorithm. Utilizing the inherent relationship between suspicious customers and suspicious vendors, the first set of suspicious vendors is identified by CSI. Meanwhile, using different pieces of information, which refer to non-anonymous ratings and anonymous ratings, the second and the third sets of suspicious vendors are detected by CSI. We designed two universal approaches RVA and BVA to compare different reputation models with regard to resisting manipulative behavior. The comparison approaches are applied to a set of suspicious vendors identified by CSI. Results show that, R-Rep outperforms two existing models, the reputation model employed by Taobao (the largest e-commerce site in China) and a Bayesian System. The two comparing approaches RVA and BVA have inherent consistency.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {43},
numpages = {10},
keywords = {trust management system, reputation system, reputation model, Taobao, manipulative behavior detection},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254184,
author = {Jordanous, Anna and Lawrence, K. Faith and Hedges, Mark and Tupman, Charlotte},
title = {Exploring Manuscripts: Sharing Ancient Wisdoms across the Semantic Web},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254184},
doi = {10.1145/2254129.2254184},
abstract = {Recent work in digital humanities has seen researchers increasingly producing online editions of texts and manuscripts, particularly in adoption of the TEI XML format for online publishing. The benefits of semantic web techniques are underexplored in such research, however, with a lack of sharing and communication of research information. The Sharing Ancient Wisdoms (SAWS) project applies linked data practices to enhance and expand on what is possible with these digital text editions. Focussing on Greek and Arabic collections of ancient wise sayings, which are often related to each other, we use RDF to annotate and extract semantic information from the TEI documents as RDF triples. This allows researchers to explore the conceptual networks that arise from these interconnected sayings. The SAWS project advocates a semantic-web-based methodology, enhancing rather than replacing current workflow processes, for digital humanities researchers to share their findings and collectively benefit from each other's work.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {44},
numpages = {12},
keywords = {RDF, ontology, TEI XML, semantic web, linked data, manuscripts, digital humanities, gnomologia},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254185,
author = {Banos, Vangelis and Stepanyan, Karen and Joy, Mike and Cristea, Alexandra I. and Manolopoulos, Yannis},
title = {Technological Foundations of the Current Blogosphere},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254185},
doi = {10.1145/2254129.2254185},
abstract = {In this paper, we review the technological foundations of the current Blogosphere. The review is primarily based on a large-scale evaluation of active blogs. The extensive list of examined technologies enables commenting on a range of widely adopted standards and potential trends in the Blogosphere. The evaluation has been conducted in the following stages:1. Retrieving and parsing a large set of blogs2. Identifying and quantifying the use of technologies such as web standards, adopted services, file formats and platforms.3. Analysing collected data and reporting the results4. Comparing the results with existing findings from the generic Web to identify similarities and differences in the Blogosphere.The presented work was performed as part of BlogForever (ICT No. 269963), an EC funded research project aiming to aggregate, preserve, manage and disseminate blogs. The results of this study are relevant within the context weblog preservation and weblog data extraction.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {45},
numpages = {11},
keywords = {web technologies, data extraction, blogosphere, blog technologies},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254186,
author = {Dung, Pham Quang and Florea, Adina Magda},
title = {A Literature-Based Method to Automatically Detect Learning Styles in Learning Management Systems},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254186},
doi = {10.1145/2254129.2254186},
abstract = {Efficiency and effectiveness of learning process can be improved by adaptations to learners' learning styles. But for the time being, most of existing education systems lack of adaptation or personalization; every learner is delivered the same learning contents. Many researchers have been studying to find out an efficient way of students' learning style identification for a better personalization. In our study, we concentrate on intelligent agents that can provide the learners with personal assistants to carry out learning activities according to their learning styles and knowledge level. In this paper, we present a new literature-based method that uses learners' behaviours on learning objects as indicators for estimating students' learning styles during an online course conducted in our POLCA learning management system. The evaluation of learning style estimation and adaptation from our experiment show a high precision. Together with the mentioned benefits of learning style adaptation, this result indicates that our method is capable for wide use.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {46},
numpages = {7},
keywords = {learning management system, adaptation, learning style detection, personalization},
location = {Craiova, Romania},
series = {WIMS '12}
}

@dataset{10.1145/review-2254129.2254186_R48159,
author = {Godwin, Stewart Mark},
title = {Review ID:R48159 for DOI: 10.1145/2254129.2254186},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2254129.2254186_R48159}
}

@inproceedings{10.1145/2254129.2254187,
author = {Faiz, Rim and Smine, Boutheina and Descl\'{e}s, Jean-Pierre},
title = {Relevant Learning Objects Extraction Based on Semantic Annotation of Documents},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254187},
doi = {10.1145/2254129.2254187},
abstract = {Users look frequently for learning information from the web or from databases to include them to their resources, or to use them in a learning process. In order to satisfy these user's needs, we proposed here a model which aims at automatically annotating texts with semantic metadata: learning category of textual segments. These metadata would allow us to search and extract learning information from texts indexed in that way. This model is build up from two parts: the first part consists on a semantic annotation of learning objects according to their semantic categories (definition, example, exercise, etc.). The second part uses automatic semantic annotation which is generated by the first part to create a semantic inverted index which is able to find relevant learning objects for queries associated with semantic categories. To sort the results according to their relevance, we apply the Rocchio's classification technique on the learning objects. We have implemented a system called SRIDoP, on the basis of the proposed model and we have verified its effectiveness.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {47},
numpages = {11},
keywords = {contextual exploration, semantic annotation, learning objects indexation},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254189,
author = {Chondrogiannis, Efthymios and Andronikou, Vassiliki and Mourtzoukos, Konstantinos and Tagaris, Anastasios and Varvarigou, Theodora},
title = {A Novel Query Rewriting Mechanism for Semantically Interlinking Clinical Research with Electronic Health Records},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254189},
doi = {10.1145/2254129.2254189},
abstract = {Electronic Health Records (EHRs) contain a rapidly increasing volume of data which is, in general, distributed in autonomous heterogeneous databases. An emerging trend is the secondary use of such data (in most cases anonymized for privacy reasons), for purposes other than healthcare, such as for generating accurate disorder epidemiology datasets, real world treatment progress assessment and patient selection for clinical trials among others. The structure and purpose of the EHRs pose significant limitations in the richness and the complexity of the questions to be posed. In fact, the latter case introduces a greater challenge; it requires that two different domains (in terms of semantics) need to be interlinked - clinical research and healthcare. This paper aims at presenting a novel SPARQL query rewriting mechanism as part of an ontology-based approach for interlinking clinical research with healthcare EHRs for supporting automatic selection of patients who satisfy the eligibility criteria of clinical trials.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {48},
numpages = {12},
keywords = {bioinformatics, query transformation, ontology alignment},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254190,
author = {Eleftherios, Karapetsas and Fukazawa, Yusuke and Ota, Jun},
title = {Genetically Optimizing Query Expansion for Retrieving Activities from the Web},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254190},
doi = {10.1145/2254129.2254190},
abstract = {Activities, defined as actions someone can accomplish or things one can create, are located all around the web contained in various How-To and DIY sites. In this paper we are presenting our research on a system focused on retrieving information about activities related to a simple query which is given as input. An overview of the system's design which is based on semantic query expansion is given along with detailed explanation of the optimization of the system's parameters through the use of genetic algorithms. Finally experimental results gathered from both an offline and a limited online evaluation are presented in order to test the efficiency of the system.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {49},
numpages = {8},
keywords = {conceptnet, optimization, query expansion, data mining, genetic algorithms},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254191,
author = {Luberg, Ago and Granitzer, Michael and Wu, Honghan and J\"{a}rv, Priit and Tammet, Tanel},
title = {Information Retrieval and Deduplication for Tourism Recommender Sightsplanner},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254191},
doi = {10.1145/2254129.2254191},
abstract = {This paper is about scraping web pages for tourism objects and resolving duplicates for a tourism recommender system Sightsplanner. Gathering information from different web portals, we end up having several versions of the same object in our database. It is very important that we can find out which objects are duplicates and merge those. Only unique objects are presented to the end user. The main focus of this paper is therefore on deduplication problem. We have implemented a duplication detection system and tuned the parameters manually to get up to 85% accuracy. In this paper we present a machine learning setup which we used to improve deduplication accuracy of tourism attractions by 13 percentage points to achieve 98% accuracy. All the steps in the process are presented along with problems we tackled.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {50},
numpages = {11},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254192,
author = {Al-akashi, Falah H. and Inkpen, Diana},
title = {Intelligent Web Page Retrieval Using Wikipedia Knowledge},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254192},
doi = {10.1145/2254129.2254192},
abstract = {In this paper, we present an intelligent web retrieval system that is able to rank webpages by using Wikipedia knowledge to enhance a standard vector space model. Our index contains separate information about the frequency of the terms in Wikpedia articles, in home pages, and in other types of web pages, instead of using a generic term frequency for the whole text collection. We also filter out spam. We present results on the ClueWeb collection, for two sets of queries, for an adhoc retrieval task and for a diversity task (which aims at retrieving not only relevant information, but also information for different aspects of the queries).},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {51},
numpages = {7},
keywords = {indexing, web retrieval, vector space model, home pages, query expansion, Wikipedia knowledge},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254193,
author = {Amami, Maha and Faiz, Rim and Elkhlifi, Aymen},
title = {A Framework for Biological Event Extraction from Text},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254193},
doi = {10.1145/2254129.2254193},
abstract = {In the biomedical domain, large experimental techniques such as DNA microarrays provide the scientist a huge textual data to search for the interactions between the components of biological systems (DNA, RNA, etc.), and how these interactions give rise to the function and behavior of that system. Recent researches focus on complex type of data which involves the change of the biological state, properties or a location of a biological entity, namely the biological event. In this paper, we develop a framework for biological event extraction from text.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {52},
numpages = {9},
keywords = {biological event template, kernel function, SVM, biological information extraction},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254195,
author = {B\u{a}descu, Miruna},
title = {Visualization of the European Environmental Data},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254195},
doi = {10.1145/2254129.2254195},
abstract = {The author has been a consultant for the European Environment Agency (EEA) for the past 12 years. In this capacity, she and her team were involved in developing tools for the environmental data collection, aggregation and analysis at European level. This paper presents the processes of collecting the data, its description and categorization according to semantic Web principles, its aggregation into a semantic database and eventually the ongoing project for the generation of different presentations layers (graphs, maps, charts, etc) using SPARQL queries.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {53},
numpages = {4},
keywords = {visualization, SPARQL, controlled vocabulary, linkeddata, European, dataset, environment, OWL, RDF},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254197,
author = {Popovici, Matei and Dobre, Ciprian},
title = {A Game-Theoretic Approach to Cooperation in Multi-Agent Systems},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254197},
doi = {10.1145/2254129.2254197},
abstract = {The development of semantic agent frameworks is strongly influenced by the means for representing and reasoning about knowledge. Nevertheless, when faced with decision-making in multi-agent environments, current approaches are limited in their ability to model strategic interactions. As a result, ontological approaches such as those based on OWL, offer only a reactive behavior for such interactions. We argue that a game-theoretic approach is more suitable when faced with modeling cooperation in Multi-Agent Systems. We introduce a new type of games, Boolean Games with Currency, which combine features of Boolean Games, with the transferable payoff setting. We also give a computational characterisation for a solution concept for coalitional stability: the core. We show that the core of a Boolean Game with Currency is always non-empty, and we prove the core membership problem to be co-NP complete.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {54},
numpages = {4},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254198,
author = {Mocanu, Irina and Florea, Adina Magda},
title = {A Multi-Agent Supervising System for Smart Environments},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254198},
doi = {10.1145/2254129.2254198},
abstract = {This paper presents a multi-agent architecture for a supervising system which is part of a new intelligent ambient system, called AmIHomCare. The supervising system detects the context of the person (using a domain ontology): the person location in the room together with the surrounding objects and its body posture. A sequence of these contexts is assembled in a daily activity, based on a set of rules, described by a stochastic context free grammar with attributes. Also the system predicts the next context and the next activity in order to detect emergencies in the smart environment.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {55},
numpages = {4},
keywords = {e-health, multi-agent system, ontology interrogation, activity recognition, smart environment},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254199,
author = {Kontopoulos, Efstratios and Zetta, Thetida and Bassiliades, Nick},
title = {Semantically-Enhanced Authoring of Defeasible Logic Rule Bases in the Semantic Web},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254199},
doi = {10.1145/2254129.2254199},
abstract = {The Semantic Web represents an initiative to improve the current Web, by augmenting content with semantics and encouraging cooperation among human and software agents. The development of the logic and proof layers of the Semantic Web is currently concentrating the related research effort and is vital, since these layers allow systems to infer new knowledge from existing information, assisting them in explaining their actions and, ultimately, increasing user trust towards the Semantic Web. However, there is a lack of applications that could contribute towards developing logic-based applications. Consequently, users resort to inadequate tools that offer syntactic support, without being able to support the user semantically as well. This work presents S2DRREd, a software tool that introduces a supplementary level of semantic assistance during rule base development. The tool allows creating meta-models of the main notions of the loaded rule sets and assists the user in authoring rule bases, independently of the explicitly chosen rule language syntax. The domain of application is defeasible logic, a type of logic that allows reasoning with incomplete and conflicting information and, as such, it can play an increasingly important role in a drastically dynamic environment like the Web.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {56},
numpages = {4},
keywords = {semantic web, rule bases, non-monotonic reasoning, defeasible logic, RuleML},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254200,
author = {Woundefinedniak, Pawe\l{} and Romanowski, Andrzej},
title = {Everyday Problems vs. UbiComp: A Case Study},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254200},
doi = {10.1145/2254129.2254200},
abstract = {It is widely accepted that ubiquitous computing (UbiComp) prototyping is one of the methods that can be used to anticipate how future systems are to be designed and what problems can be solved with computational devices. This paper discusses a number of small-scale projects in which researchers attempted to apply some of the UbiComp methodologies to finding solutions to fairly simple problems that surface during everyday campus life. The process aims at finding ways to discover how pervasive technology can affect even the most trivial aspects of human lives as well as trying to make more profound changes. The projects discussed in this paper include a tool for measuring and communicating campus room occupancy, a mobile mode-of-transport detector and a context-aware application for reducing domestic carbon footprint. The applications illustrate the vast possibilities that present mobile platforms offer to the UbiComp researcher and, most importantly, the opportunity to create large numbers of prototypes by numerous users that can be easily evaluated. The authors claim that the software fulfils many UbiComp prototyping requirements and gives great opportunities for field studies. Furthermore, the wide availability of prototyping techniques suggests that computer enthusiasts are now easily immersed in the experience of the UbiComp of the present and the future face of computing can be shaped by many. If, however, one is to verify the applicability of the prototyped systems, even more users must be involved in the UbiComp experience.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {57},
numpages = {4},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254201,
author = {Verhodubs, Olegs and Grundspenkis, Janis},
title = {Evolution of Ontology Potential for Generation of Rules},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254201},
doi = {10.1145/2254129.2254201},
abstract = {The main purpose of this paper is to evaluate the potential of OWL (Web Ontology Language) ontologies for generation of rules. It is assumed that OWL ontology expressions can serve as a material for rule extraction. It is necessary for Semantic Web Expert System development and it is expected that such Semantic Web Expert System (SWES) will be able to process ontologies from the Web with the purpose to supplement or even to develop its knowledge base. Available publications show that the problem of rule extraction from ontologies is not investigated deeply enough.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {58},
numpages = {4},
keywords = {artificial intelligence, expert systems, semantic web, ontologies},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254202,
author = {Mancas, Dan Viorel and Enescu, Nicolae Iulian},
title = {FOREX Application for BlackBerry Device},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254202},
doi = {10.1145/2254129.2254202},
abstract = {In this paper it is described our research and development work for implementing advanced software solutions, of a high quality standard, in the financial-banking domain, on mobile devices (such as Blackberry, iPhone, Android based devices etc), by using state-of-the-art technologies. The paper is focused on the implementation of a finance application which runs on BlackBerry smart phone devices and it is used for retrieving and displaying streaming interbank currency rates as well as global stock indices, commodities and real-time forex. The application includes news from Market News International also and gives an unprecedented market trend overview. The system design and implementation was co-financed through EU funds within the framework of the project "Embedded Software for Mobile Devices", project co-financed through European Fund of Regional Development.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {59},
numpages = {3},
keywords = {finance, chart, streaming, Blackberry, stocks},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254203,
author = {Lang, Helmut and Minker, Wolfgang},
title = {A Collaborative Web-Based Help-System},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254203},
doi = {10.1145/2254129.2254203},
abstract = {In this paper we present a novel help system that integrates material provided by various contributors into a single point of reference for user assistance. Therefore different kinds of resources are organized by means of collaborative tagging. To retrieve the content natural language is used to communicate with an avatar on a web page. The advantage of our approach has been verified by user testing. First-time users assisted by our system were able to perform a given task more efficiently than those performing the same task employing a system based on traditional help texts.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {60},
numpages = {5},
keywords = {computer assisted learning, HCI, user support},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254204,
author = {Elahi, Najeeb and Karlsen, Randi},
title = {User Behavior in Online Social Networks and Its Implications: A User Study},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254204},
doi = {10.1145/2254129.2254204},
abstract = {Online social networking service has attracted great interest in recent years. It has emerged as a major medium of communication as it has provided a platform for sharing personal information with vast network of friends. In this paper we present a different perspective of a social network, one that vague nature of friends relationship and show the association of users activities with gender, age and nationality. Results suggest that female are more conservative while accepting friends requests from stranger than males, and that the younger people are more active (and open). We also compare the social activities between two distinct nations -- Norway and Pakistan. Our study revealed that despite of vast differences between these two nations, the online social activities are quite similar. The knowledge gained through such results can aid in filtering, sorting and recommending information over social networks.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {61},
numpages = {4},
keywords = {user study of online social network, user behavior, social networks, social network analysis},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254205,
author = {Pe\v{s}ka, Ladislav and Vojt\'{a}\v{s}, Peter},
title = {Estimating Importance of Implicit Factors in E-Commerce Recommender Systems},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254205},
doi = {10.1145/2254129.2254205},
abstract = {In this paper, we discuss the importance of different types of implicit user feedback for creating useful recommendations on an e-commerce website. Each website user may provide us with many different types of implicit feedback and it is difficult to decide which one to use for recommendations.If our recommendation algorithm support using more implicit factors, we should also consider importance and "added value" of each factor.We have identified several widely used implicit factors and conducted real user online testing in order to compare their usefulness for recommending algorithms. We have also proposed some combinations of implicit factors and a test, to see if they improve recommendation performance in comparison with the single factor ones.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {62},
numpages = {4},
keywords = {user preference, implicit factor rating, online testing, recommender systems},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254206,
author = {Akermi, Imen and Faiz, Rim},
title = {Hybrid Method for Computing Word-Pair Similarity Based on Web Content},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254206},
doi = {10.1145/2254129.2254206},
abstract = {With the development of the Web, there is a great amount of information available on Web pages, which opens new perspectives for sharing information, allowing the collaborative construction of content. We took advantage of this shared information in our work in order to measure the similarity between words. Our measure uses on one hand, an online English dictionary provided by the Semantic Atlas project of the French National Centre for Scientific Research (CNRS) and on the other hand, a page counts based metric returned by a social website.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {63},
numpages = {4},
keywords = {information retrieval, semantic similarity, user-generated content, web search},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254207,
author = {Kraychev, Boris and Koychev, Ivan},
title = {Computationally Effective Algorithm for Information Extraction and Online Review Mining},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254207},
doi = {10.1145/2254129.2254207},
abstract = {The World Wide Web provides continuous sources of information with similar semantic structure like news feeds, user reviews and user comments on various topics. These sources are essential for the goal of online opinion mining. The paper proposes a computationally efficient algorithm for structured information extraction from web pages. The algorithm relies on a combination of analysis of structured data and natural language processing of text content. It maps HTML pages containing news, reviews or user comments to a custom designed RSS feed like structure. Such information usually includes the textual opinions, and factual information like publication date, product price, author name and influence. Due to the real time nature of the data sources the computational complexity of such a solution should be linear or close to linear. The computational complexity of the proposed algorithm is linear. In comparison similar previously published approaches have complexity no smaller than O(n2). Further we conduct experiments with real world data that achieves extraction accuracy of 84% to 92% which is comparable to the recent results in this field. Finally the paper discuses the results of the experiment and shares gained experience that can be useful for applying the algorithm in other domains.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {64},
numpages = {4},
keywords = {wrapper, tree matching, information extraction},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254208,
author = {Veselovsk\'{a}, Kate\v{r}ina},
title = {Sentence-Level Sentiment Analysis in Czech},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254208},
doi = {10.1145/2254129.2254208},
abstract = {This paper presents initial research in the area of sentiment analysis in Czech. We will describe a method for annotating Czech evaluative structures and analyze existing results for both manual and automatic annotation of the plain text data which represents the basis for further subjectivity clues learning.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {65},
numpages = {4},
keywords = {subjectivity, polarity annotation, sentiment analysis},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254209,
author = {Gy\H{o}r\"{o}di, Cornelia and Gy\H{o}r\"{o}di, Robert and Cornea, Mihai and Pecherle, George},
title = {Automated Internal Web Page Clustering for Improved Data Extraction},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254209},
doi = {10.1145/2254129.2254209},
abstract = {In this paper, we would like to present an algorithm to determine the repeating patterns inside the DOM tree of a webpage. By doing this we can cluster the content inside a web page and obtain more relevant structured data. The determined DOM structure can be used to mine other web pages that are similar in structure and one hop away from the initial targeted web page. Also, the clusters are similar in structure not in contents, and our method is based on in-page clustering. This is what differentiates our algorithm from similar technologies that work on entire web pages.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {66},
numpages = {4},
keywords = {tree, structure, web mining, web, clusters, DOM, patterns, information retrieval},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254210,
author = {Wu, Honghan and Luberg, Ago and Tammet, Tanel},
title = {Ranking Domain Objects by <i>Wisdom of Web Pages</i>},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254210},
doi = {10.1145/2254129.2254210},
abstract = {Collaborative ranking is a way to utilize the wisdom of crowd to recommend objects. It has shown to be very popular and effective in many domains. However, the wisdom of crowd is not easy to be obtained. It requires an active community and takes time to form the true wisdom. In this paper, we introduce an approach to exploit the wisdom of web pages for ranking domain objects as a substitute when the wisdom of crowd is not ready yet or not available at all. We evaluate our work on three real world datasets. The results show that web-page collaborative ranking is a promising way to imitate the wisdom of crowd.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {67},
numpages = {4},
keywords = {collaborative ranking, web mining, object ranking},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254211,
author = {Mih\u{a}escu, Marian Cristian},
title = {Classification of Users by Using Support Vector Machines},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254211},
doi = {10.1145/2254129.2254211},
abstract = {Proper classification of students is one of the key aspects in e-Learning environments. This paper uses support vector machines (SVM) for classifying users whose features are represented by the performed activity. The classification of students is performed at discipline level since the features are related only to general activities. The output of the process is represented by a set of classes. The obtained classes are further used for classifying new users, whose activity data has not been used for building the classifier.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {68},
numpages = {4},
keywords = {e-learning, support vector machines, student classification},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254212,
author = {Al-Jaloud, Faten and Hezam, Reem Bin and Aoun-Allah, Mohamed},
title = {Classifying Arabic Web Pages Toolkit},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254212},
doi = {10.1145/2254129.2254212},
abstract = {Our research deals with classification of Arabic web pages. This field is challenging because limited research has been done in this field so far, and currently available tools do not support Arabic language. The fact remains that Arabic has various complex and discrete characteristics as compared to those of other languages: highly inflectional and derivational, the writing direction, the change of characters shapes based on their location, the absence of capitalization, etc. We have developed an environment that consist of two parts: The learning phase which facilitates the essential preprocessing tasks for Arabic web pages using several methods and tools. The second part classifies a web page by applying the best parameters setups.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {69},
numpages = {4},
keywords = {Arabic text preprocessing, text classification, web content mining, Arabic web page classification},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254213,
author = {Hava, Ondrej and Skrbek, Miroslav and Kord\'{\i}k, Pavel},
title = {Document Classification with Supervised Latent Feature Selection},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254213},
doi = {10.1145/2254129.2254213},
abstract = {The classification of text documents to categories generally deals with large dimensionality of a structured representation of the documents. To favor generality over accuracy of the classifier some dimensionality reduction technique has to be applied. In the text we present classification algorithm that utilize hidden structures of uncorrelated topics extracted from training documents and their known categories not necessarily independent. The classifier is capable to include various methods of hidden feature selection. Three latent feature selection procedures are proposed and tested.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {70},
numpages = {4},
keywords = {singular value decomposition, dimensionality reduction, document classification},
location = {Craiova, Romania},
series = {WIMS '12}
}

@inproceedings{10.1145/2254129.2254214,
author = {Naffakhi, N. and Faiz, R.},
title = {Using Bayesian Networks Theory for Aggregated Search to XML Retrieval},
year = {2012},
isbn = {9781450309158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254129.2254214},
doi = {10.1145/2254129.2254214},
abstract = {In this paper, we are interested in aggregated search in structured XML documents. We present a structured information retrieval model based on the Bayesian networks theory. Query-terms and terms-elements relations are modeled through probability. In this model, the user's query starts a propagation process to recover the XML elements. Thus, instead of retrieving a whole document or a list of disjoint elements that are likely to answer partially the query, we attempt to built a virtual document that aggregates a set of elements, that are relevant all together. We evaluated our approach using the INEX 2009 collection and presented some empirical results for evaluating the impact of the aggregation approach.},
booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
articleno = {71},
numpages = {4},
keywords = {redundancy, Bayesian networks theory, XML documents, complementarity, aggregated search},
location = {Craiova, Romania},
series = {WIMS '12}
}

