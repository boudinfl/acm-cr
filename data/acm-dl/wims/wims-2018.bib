@inproceedings{10.1145/3227609.3227689,
author = {Auer, S\"{o}ren and Kovtun, Viktor and Prinz, Manuel and Kasprzik, Anna and Stocker, Markus and Vidal, Maria Esther},
title = {Towards a Knowledge Graph for Science},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227689},
doi = {10.1145/3227609.3227689},
abstract = {The document-centric workflows in science have reached (or already exceeded) the limits of adequacy. This is emphasized by recent discussions on the increasing proliferation of scientific literature and the reproducibility crisis. This presents an opportunity to rethink the dominant paradigm of document-centric scholarly information communication and transform it into knowledge-based information flows by representing and expressing information through semantically rich, interlinked knowledge graphs. At the core of knowledge-based information flows is the creation and evolution of information models that establish a common understanding of information communicated between stakeholders as well as the integration of these technologies into the infrastructure and processes of search and information exchange in the research library of the future. By integrating these models into existing and new research infrastructure services, the information structures that are currently still implicit and deeply hidden in documents can be made explicit and directly usable. This has the potential to revolutionize scientific work as information and research results can be seamlessly interlinked with each other and better matched to complex information needs. Furthermore, research results become directly comparable and easier to reuse. As our main contribution, we propose the vision of a knowledge graph for science, present a possible infrastructure for such a knowledge graph as well as our early attempts towards an implementation of the infrastructure.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {1},
numpages = {6},
keywords = {Science and Technology, Knowledge Graph, Libraries, Information Science, Research Infrastructure},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227688,
author = {Nguyen, Van Du and Truong, Hai Bang and Duong, Trong Hai and Merayo, Mercedes G. and Nguyen, Ngoc Thanh},
title = {A Comparative Study of Methods for Collective Prediction Determination Using Interval Estimates},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227688},
doi = {10.1145/3227609.3227688},
abstract = {Recently, research on the Wisdom of Crowd (WoC) has been widely expanded by supporting interval values as an additional representation of underlying predictions. Accordingly, instead of giving single values, ones can express their predictions on a given cognition problem in the form of interval values1. For such a representation, many methods have been proposed for aggregating underlying predictions based on their midpoints. In this case, of course, the outputs of the proposed methods are single values. In some situations, however, the aggregated prediction in the form of interval value can be better representation of underlying predictions. In the current study, we present a comparison of the use of different approaches for aggregating individual predictions including Interval Aggregation and MidPoint Aggregation. Experimental studies have been conducted to determine how do different aggregation methods influence the quality of the obtained collective prediction.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {2},
numpages = {6},
keywords = {interval estimates, Interval aggregation, wisdom of crowds},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227692,
author = {Djenouri, Youcef and Zimek, Arthur},
title = {Outlier Detection in Urban Traffic Data},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227692},
doi = {10.1145/3227609.3227692},
abstract = {This paper provides a summary of the tutorial on outlier detection in urban traffic data. We present existing solutions in three main categories: statistical techniques, similarity-based techniques, and techniques based on pattern analysis. The first category groups solutions employing statistical models to identify anomalies in traffic data. The second category groups solutions using distance measures and neighborhoods to derive local density estimates. The third category explores the correlation between traffic flow values by using concepts from pattern analysis. We explain and discuss example solutions for each category, and we outline perspectives on open questions and research challenges. We relate the solutions to a general view on the notion of locality, i.e., the context and reference used in the definition and comparison of outlierness, in order to gain a better understanding of the intuition, limitations, and benefits for the various outlier detection methods for urban traffic. This way, we hope to provide some guidance to practitioners for selecting the most suitable methods for their case.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {3},
numpages = {12},
keywords = {Outlier detection, Urban traffic data, Data mining},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227690,
author = {Buza, Krisztian},
title = {Time Series Classification and Its Applications},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227690},
doi = {10.1145/3227609.3227690},
abstract = {Time-series classification is one of the most important machine learning tasks related to time series. It is the common denominator in various recognition tasks, such as signature verification, person identification based on keystroke dynamics, detection of cardiovascular diseases and brain disorders (e.g. early stage of Alzheimer disease or dementia). This tutorial aims to give an introduction to the most prominent challenges, methods, evaluation protocols and biomedical applications related to time series classification. Besides the "conventional" time series classification task, early classification and semi-supervised classification will be considered. Both preprocessing techniques -- FFT, SAX, etc. -- and wide-spread classifiers -- such as similarity-based, feature-based, motif/shaplet-based classifiers and convolutional neural networks -- will be covered. As dynamic time warping (DTW) is the one of the key components of many time series classifiers, including recent ones based on deep learning, we will describe this technique in detail. Slides: http://www.biointelligence.hu/pdf/timeseriestutorial.pdf},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {4},
numpages = {4},
keywords = {tutorial, time series classification},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227691,
author = {Radovanovi\'{c}, Milo\v{s}},
title = {Hubs in Nearest-Neighbor Graphs: Origins, Applications and Challenges},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227691},
doi = {10.1145/3227609.3227691},
abstract = {The tendency of k-nearest neighbor graphs constructed from tabular data using some distance measure to contain hubs, i.e. points with in-degree much higher than expected, has drawn a fair amount of attention in recent years due to the observed impact on techniques used in many application domains. This companion paper will summarize the tutorial organized in three parts: (1) Origins, which will discuss the causes of the emergence of hubs (and their low in-degree counterparts, the anti-hubs), and their relationships with dimensionality, neighborhood size, distance concentration, and the notion of centrality; (2) Applications, where we will present some notable effects of (anti-)hubs on techniques for machine learning, data mining and information retrieval, identify two different approaches to handling hubs adopted by researchers -- through fighting or embracing their existence -- and review techniques and applications belonging to the two groups; and (3) Challenges, which will discuss work in progress, open problems, and areas with significant opportunities for hub-related research.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {5},
numpages = {4},
keywords = {hubness, Nearest neighbor graphs, machine learning, data mining, information retrieval},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227693,
author = {Savi\'{c}, Milo\v{s}},
title = {Analysis of Annotated Social and Information Networks: Methods and Applications},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227693},
doi = {10.1145/3227609.3227693},
abstract = {In order to understand, control or improve a complex system composed out of a large number of inter-related parts it is necessary to quantify, characterize and comprehend the structure and evolution of underlying complex networks. The last two decades have witnessed rapid growth in the number of studies analyzing networks representing complex real-world systems, leading to the emergence of network science, i.e. an interdisciplinary research field focused on metrics, algorithms and models that can reveal, reproduce and explain frequently observed structural and evolutionary characteristics of real-world networks. This companion paper briefly summarizes the content of a tutorial on methods for analyzing social and information networks in which nodes are augmented with various kinds of attributes. Special emphasis is given to methods for analyzing subgraphs in annotated networks, constructing their block models and mining attachment preferences. The presented methods are demonstrated on two case studies related to the evaluation of modularized semantic web ontologies and research collaboration.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {6},
numpages = {4},
keywords = {annotated networks, complex network analysis, information networks, social networks},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227650,
author = {Tuba, Eva and Jovanovic, Raka and Hrosik, Romana Capor and Alihodzic, Adis and Tuba, Milan},
title = {Web Intelligence Data Clustering by Bare Bone Fireworks Algorithm Combined with K-Means},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227650},
doi = {10.1145/3227609.3227650},
abstract = {Data mining and clustering are important elements of various applications in different fields. One of the areas were clustering is rather frequently used is web intelligence, which nowadays represents an important research area. Data collected from the web are usually very complex, dynamic, without structure and rather large. Traditional clustering techniques are not efficient enough and need to be improved. In this paper, we propose combination of recent swarm intelligence algorithm, bare bones fireworks algorithm, and k-means for clustering web intelligence data. The proposed method was compared with other approaches from literature. Based on the experimental results, it can be concluded that the proposed method has very promising characteristics in terms of the quality of clustering, as well as the execution time.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {7},
numpages = {8},
keywords = {web intelligence data, k-means, bare bones fireworks algorithm, swarm intelligence, clustering, web mining},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227649,
author = {Flisar, Jernej and Podgorelec, Vili},
title = {Document Enrichment Using DBPedia Ontology for Short Text Classification},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227649},
doi = {10.1145/3227609.3227649},
abstract = {Every day, millions of short-texts are generated for which effective tools for organization and retrieval are required. Because of the short length of these documents and of their extremely sparse representations, the traditional text classification methods are not effective. We propose a new approach that uses DBpedia Spotlight annotation tools, to identify relevant entities in text and enrich short text documents with concepts derived from those entities, represented in DBpedia ontology. Our experiments show that the proposed document enrichment approach is beneficial for classification of short texts, and is robust with respect to concept drifts and input sources. We report experimental results in three challenging collections, using a variety of classification methods. The results show that the use of DBpedia ontology significantly improves the classification performance of classifiers in short-text classification.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {8},
numpages = {9},
keywords = {text enrichment, ontology, short text classification, DBPedia},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227655,
author = {Vrban\v{c}i\v{c}, Grega and Fister, Iztok and Podgorelec, Vili},
title = {Swarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites Classification},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227655},
doi = {10.1145/3227609.3227655},
abstract = {In last decades, the web and online services have revolutionized the modern world. However, by increasing our dependence on online services, as a result, online security threats are also increasing rapidly. One of the most common online security threats is a so-called Phishing attack, the purpose of which is to mimic a legitimate website such as online banking, e-commerce or social networking website in order to obtain sensitive data such as user-names, passwords, financial and health-related information from potential victims. The problem of detecting phishing websites has been addressed many times using various methodologies from conventional classifiers to more complex hybrid methods. Recent advancements in deep learning approaches suggested that the classification of phishing websites using deep learning neural networks should outperform the traditional machine learning algorithms. However, the results of utilizing deep neural networks heavily depend on the setting of different learning parameters. In this paper, we propose a swarm intelligence based approach to parameter setting of deep learning neural network. By applying the proposed approach to the classification of phishing websites, we were able to improve their detection when compared to existing algorithms.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {9},
numpages = {8},
keywords = {optimization, neural networks, website classification, Machine learning, phishing},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227668,
author = {Spirovski, Kristijan and Stevanoska, Evgenija and Kulakov, Andrea and Popeska, Zaneta and Velinov, Goran},
title = {Comparison of Different Model's Performances in Task of Document Classification},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227668},
doi = {10.1145/3227609.3227668},
abstract = {Although the number of additional resources in Macedonian which can be used for solving information retrieval problem (or general Natural Language Processing problem) is very limited, models exist which are general enough and do not need additional knowledge about the language. This paper presents a document classification model, that doesn't rely on any language specific additional resources. The model is trained and tested on a set of news articles extracted from Macedonian websites, and each document is labeled with a class representing one of the twelve category sections from which the documents were extracted. The goal of this paper is to test different methods for feature selection and choice of vocabulary. Furthermore, we choose a model which gives the best accuracy for document classification task and we make sensitivity analysis on its architecture in order to further improve its performance. Although similar research already exists, this paper aims to combine different experiments and test them on Macedonian language documents. The models used in this paper are Random Forest (RF), Support Vector Machines (SVM) and Neural Network (NN). The performed experiments showed that the best accuracy is achieved when each document is represented as tf-idf vector, the vocabulary contains equal number of representative words from each class, and simple Neural Network with 3 hidden layers is used as a model. The main conclusion is that a language independent model for solving document classification problem can be successfully build for Macedonian language, achieving around 80% accuracy on the test set.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {10},
numpages = {12},
keywords = {Text classification, Random Forest, Feature extraction, SVM, Neural Networks, Vocabulary selection},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227659,
author = {Loukachevitch, Natalia and Ivanov, Kirill and Dobrov, Boris},
title = {Thesaurus-Based Topic Models and Their Evaluation},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227659},
doi = {10.1145/3227609.3227659},
abstract = {In this paper we study thesaurus-based topic models and evaluate them from the point of view of topic coherence. Thesaurus-based topic model enhances scores of related terms found in the same text, which means that the model encourages these terms to be in the same topics. We evaluate various variants of such models. At the first step, we carry out manual evaluation of the obtained topics. At the second step, we study the possibility to use the collected manual data for evaluating new variants of thesaurus-based models, propose a method and select the best of its parameters in cross-validation. At the third step, we apply the created evaluation method to estimate the influence of word frequencies on adding thesaurus relations during generating topic models.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {11},
numpages = {9},
keywords = {thesaurus, topic models, content-based analysis},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227644,
author = {Halvorsen, Jonas and Stolpe, Audun},
title = {Towards Practical Federation of BGPs in the Presence of Blank Nodes},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227644},
doi = {10.1145/3227609.3227644},
abstract = {Distributed query processing, when blank nodes might occur in sources and only the signature of sources are known, may in the worst case require that all possible query partitions be evaluated in order to ensure soundness and completeness of answers. The work presented in this paper attempts to push the boundary as to what query sizes and structures lies within practical feasibility. The presented approach utilizes semantic information obtained by probing sources for occurrences of blank nodes, interleaved in a recursive algorithm for calculating restricted growth strings, in order to detect and abort unfruitful branches in the partition generating process. The approach is evaluated against a well-known SPARQL benchmark, modified for the distributed case, and tentative conclusions regarding the effectiveness are drawn.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {12},
numpages = {12},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227647,
author = {Jang, Min-Hee and Kim, Sang-Wook and Loh, Woong-Kee and Won, Jung-Im},
title = {Approximate K-Nearest Neighbor Search Based on the Earth Mover's Distance for Efficient Content-Based Information Retrieval},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227647},
doi = {10.1145/3227609.3227647},
abstract = {The Earth Mover's Distance (EMD) is one of the most-widely used distance functions to measure the similarity between two multimedia objects. While providing good search results, the EMD is too much time-consuming to be used in large multimedia databases. To solve the problem, we propose an approximate k-nearest neighbor (k-NN) search method based on the EMD. First, the proposed method builds an index using the M-tree, a distance-based multi-dimensional index structure, to reduce the disk access overhead. When building the index, we reduce the number of features in the multimedia objects through dimensionality-reduction. When performing the k-NN search on the M-tree, we find a small set of candidates from the disk using the index and then perform the post-processing on them. Second, the proposed method uses the approximate EMD for index retrieval and post-processing to reduce the computational overhead of the EMD. To compensate the errors due to the approximation, the method provides a way of accuracy improvement of the approximate EMD. We performed extensive experiments to show the efficiency of the proposed method.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {13},
numpages = {7},
keywords = {k-nearest neighbor query, Earth mover's distance, Content-based information retrieval},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227661,
author = {Shi, Ling and Roman, Dumitru},
title = {Ontologies for the Real Property Domain},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227661},
doi = {10.1145/3227609.3227661},
abstract = {Real property, also known as real estate, realty or immovable property, is one of the most important assets for the world economy. Real property data is valuable input for decision makers in various domains. Real property data has temporal and spatial characteristics and is distributed across multiple systems. Integration of real property data from legal and business systems (possibly from different countries) with contextual data in related domains is a challenging task that requires cross-domain knowledge. Real property ontologies, capturing relevant domain knowledge in a structured way, are essential in the process of integrating real property data. This paper identifies key aspects of the real property domain from a data integration perspective, and surveys ontologies for real property and its related domains. It analyzes geospatial standards for representing geospatial concepts and attributes relevant to real properties, the Land Administration Domain Model and its implementations, and ontologies for real property transactions and for real property data integration. This survey aims to collect and compare existing real property ontologies and conceptual models, serving as a reference point for ontologies and conceptual models in the real property domain.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {14},
numpages = {8},
keywords = {Real property ontology, geospatial data, cadaster, LADM},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227675,
author = {Lakshen, Guma Abdulkhader and Janev, Valentina and Vrane\v{s}, Sanja},
title = {Challenges in Quality Assessment of Arabic DBpedia},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227675},
doi = {10.1145/3227609.3227675},
abstract = {The development of Semantic Web technology has fueled the creation of a large amount of Linked Open Data. DBpedia is a good example of an open data repository extracted from the crowd sourced knowledge base, Wikipedia. Because of the way Wikipedia and DBpedia were created, the information available there is more vulnerable to grammatical errors, inconsistency, structures, and, data type problems. The introduction of the Arabic chapter of DBpedia created additional problems due to the nature of the language, when it comes to quality assessment issues. In this paper 1, we focus on identifying challenges in quality assessment of Arabic DBpedia, as well as analysis of existing tools and methodologies used for Linked Data quality assessments.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {15},
numpages = {4},
keywords = {Tools, DBpedia, Quality assessment, Application, Quality dimensions},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227666,
author = {Brdjanin, Drazen and Banjac, Danijela and Banjac, Goran and Maric, Slavko},
title = {An Online Business Process Model-Driven Generator of the Conceptual Database Model},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227666},
doi = {10.1145/3227609.3227666},
abstract = {The paper presents an online two-phase business process model-driven generator of the conceptual database model. The generator is implemented as a web-based, platform-independent tool, in contrast to the existing tools that are dependent on some specific technological platform used for their implementation. Unlike the existing approaches, which are characterised by the direct synthesis of the target model based on business process models represented by a sole concrete notation such as BPMN, the presented generator uses an indirect two-phase approach, which is based on the introduction of a simple domain specific language as an intermediate layer between source and target notations. The implemented online generator enables automatic generation of the target data model represented by UML class diagram, based on business process models represented by two concrete notations: BPMN and UML activity diagram.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {16},
numpages = {9},
keywords = {UML activity diagram, model-driven, BPMN, conceptual database model, UML class diagram},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227667,
author = {Marenkov, Jevgeni and Robal, Tarmo and Kalja, Ahto},
title = {Guideliner: A Tool to Improve Web UI Development for Better Usability},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227667},
doi = {10.1145/3227609.3227667},
abstract = {With the increasing popularity of portable devices, web applications correspondence to usability guidelines becomes one of the key factors in user satisfaction and application success. Manual usability evaluation is time and resource consuming. Automated usability evaluation is a solution to overcome aforementioned problems. Existing solutions address the automated usability evaluation mostly during the testing phase of development. That introduces a delay between the moment when the code has been changed and the feedback developer receives, increasing the time and as a result the cost for defect to be fixed. This is a gap we are addressing with Guideliner -- evaluating the conformance of web UI to the set usability guidelines and providing feedback to the developer immediately after the UI has been modified.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {17},
numpages = {9},
keywords = {usability guidelines, web user interface, Web usability evaluation},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227676,
author = {Alzahrani, Mohammed and Georgieva, Lilia},
title = {Structural Modeling and Verification of Web Applications},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227676},
doi = {10.1145/3227609.3227676},
abstract = {The complex structure and rapid development of web applications can lead to vulnerabilities and flaws that can compromise sensitive data. Detecting these vulnerabilities at the early stages of development cycle ensures that they are easier and cheaper to fix. Structural modeling of web applications is becoming increasingly important for detection, and subsequent elimination of such flaws.In this paper we analyze structural models of web applications. We use the model checking tools Spin and Uppaal to model dynamic navigation flow. We simulate and verify time-bound navigation properties by examining the sequence of actions that a user would make when interacting with the application. We compare the usefulness of the modeling tools for analysis of users' behavior.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {18},
numpages = {4},
keywords = {and trust, web security, modeling, web applications, integrity, privacy},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227687,
author = {Bo\v{s}njak, Leon and Brumen, Bo\v{s}njak},
title = {Improving the Evaluation of Shoulder Surfing Attacks},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227687},
doi = {10.1145/3227609.3227687},
abstract = {Taking authentication methods' resilience against shoulder surfing attacks into account has become a necessity when evaluating novel textual and graphical schemes. Researchers are often quick to declare their new method safe against these attacks, while paying little attention to how the obtained results were measured and whether they are comparable to those of other methods. In this work, we highlight these issues and develop a solution: an ensemble of vulnerability metrics assessing methods' susceptibility to shoulder surfing attacks. We believe our approach provides insight into how shoulder surfing experiments could be improved in the future.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {19},
numpages = {2},
keywords = {Shoulder Surfing, Vulnerability Metrics, Textual Passwords, Graphical Passwords},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227643,
author = {Brati\'{c}, Brankica and Houle, Michael E. and Kurbalija, Vladimir and Oria, Vincent and Radovanovi\'{c}, Milo\v{s}},
title = {NN-Descent on High-Dimensional Data},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227643},
doi = {10.1145/3227609.3227643},
abstract = {K-nearest neighbor graphs (K-NNGs) are used in many data-mining and machine-learning algorithms. Naive construction of K-NNGs has a complexity of O(n2), which could be a problem for large-scale data sets. In order to achieve higher efficiency, many exact and approximate algorithms have been developed, including the NN-Descent algorithm of Dong, Charikar and Li. Empirical evidence suggests that the practical complexity of this algorithm is in \~{O}(n1.14), which is a significant improvement over brute force construction. However, NN-Descent has a major drawback --- it produces good results only on data of low intrinsic dimensionality. This paper presents an experimental analysis of this behavior, and investigates possible solutions. We link the quality of performance of NN-Descent with the phenomenon of hubness, defined as the tendency of intrinsically high-dimensional data to contain hubs --- points with high in-degrees in the K-NNG. We propose two approaches to alleviate the observed negative influence of hubs on NN-Descent performance.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {20},
numpages = {8},
keywords = {hubness, NN-Descent, k-nearest neighbor graph},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227646,
author = {Campos, Guilherme O. and Meira, Wagner and Zimek, Arthur},
title = {Outlier Detection in Graphs: On the Impact of Multiple Graph Models},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227646},
doi = {10.1145/3227609.3227646},
abstract = {Various previous works proposed techniques to detect outliers in graph data. Usually, some complex dataset is modeled as a graph and a technique for detecting outliers in graphs is applied. The impact of the graph model on the outlier detection capabilities of any method has been ignored. Here we assess the impact of the graph model on the outlier detection performance and the gains that may be achieved by using multiple graph models and combining the results obtained by these models. We show that assessing the similarity between graphs may be a guidance to determine effective combinations, as less similar graphs are complementary with respect to outlier information they provide and lead to better outlier detection.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {21},
numpages = {12},
keywords = {ensemble, outlier detection, multiple graph models},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227648,
author = {Ionita, Andrei and Pomp, Andr\'{e} and Cochez, Michael and Meisen, Tobias and Decker, Stefan},
title = {Where to Park? Predicting Free Parking Spots in Unmonitored City Areas},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227648},
doi = {10.1145/3227609.3227648},
abstract = {Several smart cities around the world have begun monitoring parking areas in order to estimate free spots and help drivers that are looking for parking. The current results are indeed promising, however, this approach is limited by the high costs of sensors that need to be installed throughout the city in order to achieve an accurate estimation rate. This work investigates the extension of estimating parking information from areas equipped with sensors to areas that are missing them. To this end, similarity values between city neighborhoods are computed based on background data, i.e., from geographic information systems. Using the derived similarity values, we analyze the adaptation of occupancy rates from monitored- to unmonitored parking areas.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {22},
numpages = {12},
keywords = {data mining, smart parking, semantic annotation, machine learning},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227652,
author = {Pe\v{s}i\'{c}, Sa\v{s}a and To\v{s}i\'{c}, Milenko and Ikovi\'{c}, Ognjen and Radovanovi\'{c}, Milo\v{s} and Ivanovi\'{c}, Mirjana and Bo\v{s}kovi\'{c}, Dragan},
title = {Bluetooth Low Energy Microlocation Asset Tracking (BLEMAT) in a Context-Aware Fog Computing System},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227652},
doi = {10.1145/3227609.3227652},
abstract = {In this paper we present a Bluetooth Low Energy Microlocation Asset Tracking system (BLEMAT) that performs real-time position estimation and asset tracking based on BLE beacons and scanners. It is built on a context-aware fog computing system comprising Internet of Things controllers, sensors and a cloud platform, helped by machine-learning models and techniques. The BLEMAT system offers detecting signal propagation obstacles, performing signal perturbation correction and beacon paths exploration as well as auto discovery and onboarding of fog controller devices. These are the key characteristics of semi-supervised indoor position estimation services. In this paper we have shown there are solid basis that a fog computing system can efficiently carry out semi-supervised machine learning procedures for high-precision indoor position estimation and space modeling without the need for detailed input information (i.e. floor plan, signal propagation map, scanner position). In addition, the fog computing system inherently brings high level of system robustness, integrity, privacy and trust.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {23},
numpages = {11},
keywords = {space modeling, machine learning, Fog computing, indoor positioning},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227653,
author = {Radovanovi\'{c}, Sandro and Deliba\v{s}i\'{c}, Boris and Jovanovi\'{c}, Milo\v{s} and Vuki\'{c}evi\'{c}, Milan and Suknovi\'{c}, Milija},
title = {Framework for Integration of Domain Knowledge into Logistic Regression},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227653},
doi = {10.1145/3227609.3227653},
abstract = {Traditionally, machine learning extracts knowledge solely based on data. However, huge volume of knowledge is available in other sources which can be included into machine learning models. Still, domain knowledge is rarely used in machine learning. We propose a framework that integrates domain knowledge in form of hierarchies into machine learning models, namely logistic regression. Integration of the hierarchies is done by using stacking (stacked generalization). We show that the proposed framework yields better results compared to standard logistic regression model. The framework is tested on the binary classification problem for predicting 30-days hospital readmission. Results suggest that the proposed framework improves AUC (area under the curve) compared to logistic regression models unaware of domain knowledge by 9% on average.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {24},
numpages = {8},
keywords = {Stacking, Domain knowledge, Logistic regression, Hospital readmission},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227673,
author = {Liu, Xin and Murata, Tsuyoshi and Kim, Kyoung-Sook},
title = {Measuring Graph Reconstruction Precisions: How Well Do Embeddings Preserve the Graph Proximity Structure?},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227673},
doi = {10.1145/3227609.3227673},
abstract = {Graph embedding aims at learning representations of nodes in a low dimensional vector space. Good embeddings should preserve proximity structure of the original graph and thus are expected to accurately reconstruct the graph. We propose a reconstruction procedure such that the reconstructed graph keeps the total number of weights of the original one. Then we assess the reconstruction precision using a global view based graph similarity metric called DeltaCon. Based on this metric, we found that the embeddings by the state-of-the-art techniques can only preserve part of the proximity structure and is insufficient to achieve high reconstruction accuracy.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {25},
numpages = {4},
keywords = {graph mining, dimension reduction, graph embedding, network representation learning, graph reconstruction},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227657,
author = {Karampelas, A. and Vouros, G. A.},
title = {Time and Space Efficient Large-Scale Link Discovery Using String Similarities},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227657},
doi = {10.1145/3227609.3227657},
abstract = {This paper proposes and evaluates time and space efficient methods for discovering links between matching entities in large data sets, using state of the art methods for measuring edit distance as a string similarity metric. The paper proposes and compares three filtering methods that build on a basic blocking technique to organize the target dataset, facilitating efficient pruning of dissimilar pairs. The proposed filtering methods are compared in terms of runtime and memory usage: The first method exploits the blocking structure using the triangle inequality in conjunction to the substring-matching criterion. The second method uses only the substring-matching criterion, while the third method uses the substring-matching criterion in conjunction to the frequency-matching criterion. Evaluation results show the pruning power of the different criteria used, also in comparison to the string matching functionality provided in LIMES and SILK, which are state-of-the-art tools for large-scale link discovery.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {26},
numpages = {9},
keywords = {filtering criterion, string matching, Link discovery, edit distance},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227670,
author = {Weichselbraun, Albert and Kuntschik, Philipp and Bra\c{s}oveanu, Adrian M.P.},
title = {Mining and Leveraging Background Knowledge for Improving Named Entity Linking},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227670},
doi = {10.1145/3227609.3227670},
abstract = {Knowledge-rich Information Extraction (IE) methods aspire towards combining classical IE with background knowledge obtained from third-party resources. Linked Open Data repositories that encode billions of machine readable facts from sources such as Wikipedia play a pivotal role in this development.The recent growth of Linked Data adoption for Information Extraction tasks has shed light on many data quality issues in these data sources that seriously challenge their usefulness such as completeness, timeliness and semantic correctness. Information Extraction methods are, therefore, faced with problems such as name variance and type confusability. If multiple linked data sources are used in parallel, additional concerns regarding link stability and entity mappings emerge.This paper develops methods for integrating Linked Data into Named Entity Linking methods and addresses challenges in regard to mining knowledge from Linked Data, mitigating data quality issues, and adapting algorithms to leverage this knowledge.Finally, we apply these methods to Recognyze, a graph-based Named Entity Linking (NEL) system, and provide a comprehensive evaluation which compares its performance to other well-known NEL systems, demonstrating the impact of the suggested methods on its own entity linking performance.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {27},
numpages = {11},
keywords = {Linked Data Quality Information Extraction, Semantic Technologies, Knowledge-rich Information Extraction, Named Entity Linking, Natural Language Processing},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227658,
author = {Santipantakis, Georgios M. and Kotis, Konstantinos I. and Vouros, George A. and Doulkeridis, Christos},
title = {RDF-Gen: Generating RDF from Streaming and Archival Data},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227658},
doi = {10.1145/3227609.3227658},
abstract = {Recent state-of-the-art approaches and technologies for generating RDF graphs from non-RDF data, use languages designed for specifying transformations or mappings to data of various kinds of format. This paper presents a new approach for the generation of ontology-annotated RDF graphs, linking data from multiple heterogeneous streaming and archival data sources, with high throughput and low latency. To support this, and in contrast to existing approaches, we propose embedding in the RDF generation process a close-to-sources data processing and linkage stage, supporting the fast template-driven generation of triples in a subsequent stage. This approach, called RDF-Gen, has been implemented as a SPARQL-based RDF generation approach. RDF-Gen is evaluated against the latest related work of RML and SPARQL-Generate, using real world datasets.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {28},
numpages = {10},
keywords = {RDF knowledge graph, data-to-RDF mapping, RDF generation},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227663,
author = {Veres, Csaba},
title = {Task Specific Disambiguation in a Web Page: Towards Symbiotic Annotation},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227663},
doi = {10.1145/3227609.3227663},
abstract = {We describe Information Systems where users employ semantic tagging to annotate resources accessible through a web browser. Semantic tags are disambiguated key terms assigned by users. To facilitate the procedure for human users, we investigated algorithms which automatically disambiguate words selected from the text, using the surrounding context. We found existing generic methods of Word Sense Disambiguation (WSD) to be insufficient, and developed several new algorithms which take into consideration the specific structural properties of the annotated resources. Our preliminary findings are that it is relatively straightforward to hand craft simple task specific disambiguation algorithms using freely available libraries. However it is difficult to surpass the performance of state-of-the-art general algorithms. We observe that part of the problem is caused by the fine grained word senses used in disambiguation, which makes agreement difficult. We propose a task specific measure of accuracy which, combined with the task specific disambiguation algorithm, provides a more satisfactory solution to the problem than generic approaches. That is, while the hand crafted disambiguation algorithm could not out-perform standard algorithms in a general measure of accuracy, it did lead to an overall solution for the tagging task which proved superior to the standard algorithms. The final solution is an example of symbiotic computing, in which the human and machine actors interact in a mutually beneficent manner to achieve an outcome.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {29},
numpages = {6},
keywords = {NLP, cognitive computing, symbiosis, ambiguity, tagging},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227674,
author = {Bra\c{s}oveanu, Adrian M.P. and Nixon, Lyndon J.B. and Weichselbraun, Albert},
title = {StoryLens: A Multiple Views Corpus for Location and Event Detection},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227674},
doi = {10.1145/3227609.3227674},
abstract = {The news media landscape tends to focus on long-running narratives. Correctly processing new information, therefore, requires considering multiple lenses when analyzing media content. Traditionally it would have been considered sufficient to extract the topics or entities contained in a text in order to classify it, but today it is important to also look at more sophisticated annotations related to fine-grained geolocation, events, stories and the relations between them. In order to leverage such lenses we propose a new corpus that offers a diverse set of annotations over texts collected from multiple media sources. We also showcase the framework used for creating the corpus, as well as how the information from the various lenses can be used in order to support different use cases in the EU project InVID for verifying the veracity of online video.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {30},
numpages = {4},
keywords = {Event detection, Named Entity Linking, Natural Language Processing, Fake news, Information Extraction, Geosemantics, Corpus},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227654,
author = {Mandi\'{c}, Milinko},
title = {Semantic Web Based Software Platform for Curriculum Harmonization},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227654},
doi = {10.1145/3227609.3227654},
abstract = {This paper presents a software platform for comparing informatics teacher education curricula. The ontological model of the chosen informatics teachers' curriculum from the Republic of Serbia and the reference informatics teachers' curriculum model were created. The semi-automatic software platform is based on the standard techniques and methods of ontology matching. The created ontological models of the teacher education curricula are compared using the developed software. Analysis of the results of comparison includes consideration of classes' matching, obtained system evaluation (by the expert team) and a harmonization of the Revised Bloom's taxonomy categories. Also, the obtained results are compared with the results obtained for other combinations of input ontological models (secondary informatics and informatics teacher education curricula models). The analysis of the results revealed the need to improve the content and structure of the observed model curricula as well as the limits of the developed system and possibilities of improving the software platform.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {31},
numpages = {9},
keywords = {informatics, ontology, teacher education curriculum, matching, alignment},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227656,
author = {Faizan, Ainuddin and Lohmann, Steffen},
title = {Automatic Generation of Multiple Choice Questions from Slide Content Using Linked Data},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227656},
doi = {10.1145/3227609.3227656},
abstract = {Assessment plays an important role in the process of learning. Multiple choice questions (MCQs) are suitable candidates to fulfill this role. We present an approach for automatically generating MCQs based on the content presented in slides. It extracts named entities from slides, and queries a knowledge base to create different varieties of MCQs and appropriate answer options. Users can choose between different levels of difficulty for the generated questions and answer options. The approach can be easily extended to generate other varieties of MCQs. Results from a user study confirm the applicability and appropriateness of the approach.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {32},
numpages = {8},
keywords = {Knowledge Graphs, Question Generation, Linked Data, Slides},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227662,
author = {Vesin, Boban and Kla\v{s}nja-Mili\'{c}evi\'{c}, Aleksandra and Mangaroska, Katerina and Ivanovi\'{c}, Mirjana and Jolak, Rodi and Stikkolorum, Dave and Chaudron, Michel},
title = {Web-Based Educational Ecosystem for Automatization of Teaching Process and Assessment of Students},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227662},
doi = {10.1145/3227609.3227662},
abstract = {The complexity of the teaching process at universities creates many challenges. It becomes much harder for teachers to observe, control and adjust the learning process. Teaching process can be enhanced with use of different educational systems that not only help students construct their knowledge, but also make this process the most effective and efficient. One of the processes that could be automated and supported is the assessment of students' assignments. Three e-learning systems are currently used at different universities for teaching software design basics. The goal of this paper is to propose new integrated tool that can be used in university courses to support different stages of learning and evaluation of students' assignments. Such integrated system will be used to simplify the correction process of software design assignments.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {33},
numpages = {9},
keywords = {e-learning, Students' assessment, software design},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227669,
author = {Melesko, Jaroslav and Kurilovas, Eugenijus},
title = {Semantic Technologies in E-Learning: Learning Analytics and Artificial Neural Networks in Personalised Learning Systems},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227669},
doi = {10.1145/3227609.3227669},
abstract = {The paper presents semantic clustering and artificial neural network (ANN) based learning analytics software agent for personalised adaptive multi-agent learning system. First of all, systematic literature review on application of ANN to personalise learning in Web of Science database was performed. After that, methodology of application of ANN and semantic clustering of learning material in personalised adaptive multi-agent learning system is presented. In the paper, personalisation in multi-agent learning system is based on learning styles model that requires the use of psychological questionnaire to determine student's learning styles. The results of filling in the questionnaire could be incorrect since some students may answer the questionnaire dishonestly, irresponsibly, or make mistakes in self-diagnosis. This results in creation of an incorrect student's model. This causes the system to provide suboptimal learning objects and scenarios to the student. The authors present a model of ANN based learning analytics agent to be used in the system. Proposed agent uses ANN to associate students' learning styles with their real behaviour within the learning environment. The key factor describing the behaviour of students within the system is the learning content they seek out independently. Clustering the visited documents based on semantic content categorizes students into groups. Belonging to a semantic cluster is one of the inputs that can be used to train ANN agent. After training, the agent could identify potentially faulty student models by looking for anomalous behaviour for those learning styles. Such problems can be resolved by providing alternative learning objects or scenarios to the students and observing their choices.1},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {34},
numpages = {7},
keywords = {Personalised learning systems, multagent systems, e-Learning, artificial neural networks, learning analytics},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227645,
author = {Zupanc, Kaja and Bosni\'{c}, Zoran},
title = {Increasing Accuracy of Automated Essay Grading by Grouping Similar Graders},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227645},
doi = {10.1145/3227609.3227645},
abstract = {Automated essay evaluation is a widely used practical solution for replacing time-consuming manual grading of student essays. Automated systems are used in combination with human graders in different high-stake assessments, where grading models are learned on essays datasets scored by different graders. Despite the unified grading rules, human graders can unintentionally introduce subjective bias into scores. Consequently, a grading model has to learn from a data that represents a noisy relationship between essay attributes and its grade. We propose an approach for separating a set of essays into subsets that represent similar graders, which uses an explanation methodology and clustering. The results confirm our assumption that learning from the ensemble of separated models can significantly improve the average prediction accuracy on artificial and real-world datasets.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {35},
numpages = {6},
keywords = {prediction accuracy, clustering, automated essay evaluation, explanations of predictions},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227665,
author = {Be\u{g}enilmi\c{s}, Erdem and Uskudarli, Suzan},
title = {Organized Behavior Classification of Tweet Sets Using Supervised Learning Methods},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227665},
doi = {10.1145/3227609.3227665},
abstract = {There is an increasing incidence in negative propaganda and fake news, which has recently gained lots of attention during the 2016 elections in United States, France, and United Kingdom. Bots and hired users collaborate to make messages seen and persist so they may spread and gain support. Assuming that most Twitter users post without predetermined, malicious intent, there is a need for automated detection of organized behavior to protect users from manipulation. This work proposes an automated approach to classify tweets with organized behavior. Supervised learning methods are used to classify the tweets by using a training data set with 850 records based on the analysis of over 200 million tweets. Our model gave promising results for detection of organized behavior and this motivated us to proceed with the generation of two more classifiers such as ["political", "non-political"] and ["pro-Trump", "pro-Hillary","neither"]. In each cases, the random forest algorithm consistently results in high scores with an average accuracy and f-measure above 0.95.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {36},
numpages = {9},
keywords = {Political propaganda, 2016 US presidential elections, supervised learning, Twitter, big data, social media analysis, organized behavior detection},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227651,
author = {Mukamakuza, Carine and Sacharidis, Dimitris and Werthner, Hannes},
title = {Mining User Behavior in Social Recommender Systems},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227651},
doi = {10.1145/3227609.3227651},
abstract = {Social recommender systems make use of the available information about social connections between users to improve the quality of the recommendations. The assumption is that if two users are connected, they are likely to have similar preferences, and thus the system should make similar recommendations. Recently many approaches have been proposed based around similar assumptions, whose validity however has not been systematically studied. In our work we make the first step towards examining whether there exist observable relationships between social connections and rating behavior in social recommenders. In particular, we examine publicly available datasets containing traces of rating behavior along with a social graph. Using techniques from social network analysis and statistics, we investigate whether heavy rates, having provided feedback on many items, are also popular, i.e., central in the social network, and vice versa. Our results indicate important connections between heaviness and popularity. Specifically, we find that heaviness implies popularity, and that the association is stronger among very heavy raters.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {37},
numpages = {6},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227664,
author = {Melidis, Damianos P. and Campero, Alvaro Veizaga and Iosifidis, Vasileios and Ntoutsi, Eirini and Spiliopoulou, Myra},
title = {Enriching Lexicons with Ephemeral Words for Sentiment Analysis in Social Streams},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227664},
doi = {10.1145/3227609.3227664},
abstract = {Lexical approaches for sentiment analysis like SentiWordNet rely upon a fixed dictionary of words with fixed sentiment, i.e., sentiment that does not change. With the rise of Web 2.0 however, what we observe more and more often is that words that are not sentimental per se, are often associated with positive/negative feelings, for example, "refugees", "Trump", "iphone". Typically, those feelings are temporary as responses to external events; for example, "iphone" sentiment upon latest iphone version release or "Trump" sentiment after USA withdraw from Paris climate agreement.In this work, we propose an approach for extracting and monitoring what we call ephemeral words from social streams; these are words that convey sentiment without being sentimental and their sentiment might change with time. Such sort of words cannot be part of a lexicon like SentiWordNet since their sentiment has an ephemeral character, however detecting such words and estimating their sentiment can significantly improve the performance of lexicon-based approaches, as our experiments show.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {38},
numpages = {8},
keywords = {sentiment classification, dictionary-based approaches, ephemeral words, lexicon enrichment},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227660,
author = {Ljaji\'{c}, Adela and Stankovi\'{c}, Milena and Marovac, Ulfeta},
title = {Detection of Negation in the Serbian Language},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227660},
doi = {10.1145/3227609.3227660},
abstract = {The number of documents written in the Serbian language is constantly increasing, hence the need for the computer processing of the same is increasingly relevant. It is impossible to process natural language without processing the individual phenomena which occur in the syntax of a language. One such phenomenon is negation, and its processing contributes to the improvement of the quality of document processing. In this paper, we present an algorithm for the detection of negation and the extent of negation that includes specific syntax rules. It is shown that at least 7.59% of the classical approach to negation processing and detection of its scope has been improved. We applied the proposed method for negation processing on the sentiment analysis of tweets and an improvement in the accuracy of sentiment determination of 9.66% was obtained.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {39},
numpages = {6},
keywords = {Grammar Rules, Serbian Language, Natural language Processing, Text Mining, Negation},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227671,
author = {Coba, Ludovik and Symeonidis, Panagiotis and Zanker, Markus},
title = {Replicating and Improving Top-N Recommendations in Open Source Packages},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227671},
doi = {10.1145/3227609.3227671},
abstract = {Collaborative filtering techniques have been studied extensively during the last decade. Many open source packages (Apache Mahout, LensKit, MyMediaLite, rrecsys etc.) have them implemented, but typically the top-N recommendation lists are only based on a highest predicted ratings approach. However, exploiting frequencies in the user/item neighbourhood for the formation of the top-N recommendation lists has been shown to provide superior accuracy results in offline simulations. In this paper, we have therefore implemented extensions to the open source recommendation package for the R language - denoted rrecsys - and compare its performance across open source packages for reasons of replicability. Our experimental results clearly demonstrate that using the most frequent items in neighborhood approach significantly outperforms the highest predicted rating approach on two public datasets.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {40},
numpages = {7},
keywords = {evaluation, Recommendation algorithms, Collaborative Filtering},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227672,
author = {Karlsen, Randi and Elahi, Najeeb and Andersen, Anders},
title = {Personalized Recommendation of Socially Relevant Images},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227672},
doi = {10.1145/3227609.3227672},
abstract = {We present a social image recommender system that offers a hybrid filtering approach, combining content- and knowledge-based filtering with a novel social-based filtering, that selects images of social interest to the user, by e.g. being posted by close friends or family. User activity on social media is used when generating a user profile reflecting user interests and social context, and images are recommended according to a combination of social relevance and topic of interest. Our system handles both cross-source user profiling and image recommendation across social media, currently focusing on images from Facebook and Flickr.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {41},
numpages = {4},
keywords = {Social Media, Image Recommendation, Social-based Filtering},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227681,
author = {B\u{a}dic\u{a}, Amelia and B\u{a}dic\u{a}, Costin and Buligiu, Ion and Ciora, Liviu},
title = {DEVS Modeling and Simulation Using BDI Agents: Preliminary Considerations},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227681},
doi = {10.1145/3227609.3227681},
abstract = {In this paper we propose a method for mapping DEVS simulation models to BDI multi-agent systems. Our work opens the possibility of reusing BDI multi-agent frameworks for the modeling and simulation of discrete event dynamic systems following the DEVS formalized approach. Moreover, thanks to the key features of the BDI architecture, we are are now able to systematically enhance simulation models with cognitive and intelligence aspects specific to BDI agents. Our method is demonstrated with the help of a simple, yet illustrative example that we developed using the Jason multi-agent systems development platform.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {42},
numpages = {8},
keywords = {multi-agent system, modeling and simulation, discrete event dynamic system, belief-desire-intention},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227683,
author = {G\^{a}teau, Benjamin},
title = {A Smart IoT Middleware for Comfort Management Based on Multi-Agent-System},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227683},
doi = {10.1145/3227609.3227683},
abstract = {In this paper we propose a new approach of comfort management based on a smart IoT middleware composed of a Knowledge Base (KB) and a Multi-Agent System (MAS). Those elements allow users in a room to interact with the system to request in a simple and natural way the change of one or more comfort elements (including temperature, humidity, luminosity, noise, ventilation and air quality). Shared knowledge fed by the IoT network is used by smart layers (KB and MAS) to reason and propose an action on one or more IoT devices. The implementation is based on underlying ontologies of comfort and actions, real-world IoT devices and a set of agents representing each actuator. These latter participate to the global system's organization by playing a specific role and by having to reach local goals. Distribution of tasks and emergence of behaviour will result in the selection of actions to execute in order to meet this request for comfort change.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {43},
numpages = {10},
keywords = {Internet of Things, Context-Awareness, Comfort Management, Building Automation System, Ontology, Multi-Agent Systems},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227684,
author = {Kuk, Kristijan and Stanojevi\'{c}, Aleksandar and Jovanovi\'{c}, Mihailo and Nedeljkovi\'{c}, Slobodan},
title = {Intelligent E-Service for Detecting Malicious Code Based Agent Technology},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227684},
doi = {10.1145/3227609.3227684},
abstract = {Implementation of new ICT technologies aims at improving government services all over the world. The main agent technology in ICT technology based artificial intelligence in the proposed e-service is that it recognizes a cyber-attack after the state has completed the e-form on the website approved by any citizen and sends out the obtained results of the computer scan. Intelligent e-service decides whether to post the threat to a computer emergency response team of the Ministry of Interior or reject it after the final danger parameters have been obtained. This 1paper presents possible support decision system in the process that detects malicious code.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {44},
numpages = {6},
keywords = {agent-based technology, cyber security, Intelligent e-service, e-government, CERT},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227682,
author = {H\"{o}lbl, Marko and Hrgarek, Luka and Ivanovi\'{c}, Mirjana and Welzer, Tatjana and Vidakovi\'{c}, Milan},
title = {Introducing Public-Key Infrastructure for SiebogJS JavaScript-Based Agent Middleware},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227682},
doi = {10.1145/3227609.3227682},
abstract = {Software agents are special type of software entities which are usually used in the field of distributed artificial intelligence, because of their capability to communicate, and their reactive and pro-active behaviour. An important factor in such an environment is security.In this paper, we address the security aspect of the SiebogJS agent middleware in regard to protecting the agent's programme code and/or payload. For this purpose we use the Public key infrastructure and its related concepts. These enable digital signing of programme code using digital certificates and thus prevent an attacker to inject or include malicious code into an agent or its pay-load. Additionally, we discuss challenges that arise when employing PKI in such an agent framework.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {45},
numpages = {6},
keywords = {Authentication, Security, Agents, Public key infrastructure},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227685,
author = {Iva\c{s}cu, Todor and Dini\c{s}, Adriana and Cincar, Kristijan},
title = {A Disease-Driven Nutrition Recommender System Based on a Multi-Agent Architecture},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227685},
doi = {10.1145/3227609.3227685},
abstract = {This paper presents a disease-driven nutrition recommender system based on intelligent agents, a rule engine and ontology approach. As nutrition plays a key role in improving the quality of life of the chronic disease patients, we propose a recommender system based on a Multi-agent architecture. For this work we also developed a knowledge store based on owl ontology that contains the food information related to diseases, i.e. which food is recommended and which is supposed to be avoided for a specific disease. Using a rule engine the system evaluates meals/recipes based on users' preferences but also taking into account what is recommended and restricted according to the conditions that they suffer from. Only the meals/recipes that satisfy these two criteria are recommended.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {46},
numpages = {5},
keywords = {Multi-agent architecture, Recommender system, Knowledge-based system, Nutrition, Health},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227686,
author = {Kostoska, Magdalena and Simjanoska, Monika and Koteska, Bojana and Bogdanova, Ana Madevska},
title = {Real-Time Smart Advisory Health System},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227686},
doi = {10.1145/3227609.3227686},
abstract = {This paper presents a novel hybrid distributed system whose main goal is to enable triage processing on available mobile devices and further propagation of the data and patient history. The injured persons' vital data are obtained from biosensors and are monitored using mobile applications. The system aims to ease the decision of priority in treatment, as well as to further monitor and alarm state change.We give overview of the system and we analyze the strengths and the weakness of the system given the hardware, software and communication components. We evaluate the system in different scenarios and we present the results.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {47},
numpages = {4},
keywords = {Information System, Biosensors, Health care system},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227677,
author = {Park, Sunnyeo and Yun, Shinhye and Kim, Hyunjin and Kwon, Ryunhwan and Ganser, John and Anthony, Smith},
title = {Forestry Monitoring System Using LoRa and Drone},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227677},
doi = {10.1145/3227609.3227677},
abstract = {The technology of the Internet of Things(IoT) has flourished in various industries and market around the world. The agricultural environment is one of the areas to benefit from IoT technologies. LoRa is one of the most used network radios in the IoT network technology infrastructure. LoRa is often used in agricultural IoT not only for its long-range but also due to very low power usage and significant cost advantage. This paper provides a study of LoRa networks in IoT technology in an agricultural environment. The study has been conducted for between a LoRa gateway and multiple sensor nodes. Due to the radio propagation issues encountered with forestry and other types of agriculture, we used a small drone with a gateway mounted on its fuselage that collects sensor data from nodes on the ground to test the feasibility of this communications method. The scenario tested to figure out whether the gateway attached on a drone that hovers over farm field can gather data from nodes on the ground. The aim of this project is to help farmers get environmental data over the geographically large farm field, and also the locations where are difficult or dangerous for them to access. The research took in a place in a tree farm near Purdue University, Indiana.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {48},
numpages = {8},
keywords = {Agriculture, Drone, IoT, LPWAN, LoRaWAN, LoRa},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227678,
author = {Cong, Phan Thanh and Toan, Nguyen Thanh and Hung, Nguyen Quoc Viet and Stantic, Bela},
title = {Minimizing Efforts in Reconciling Participatory Sensing Data},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227678},
doi = {10.1145/3227609.3227678},
abstract = {Participatory sensing has emerged as a new data collection paradigm, in which humans use their own devices (cell phone accelerometers, cameras, etc.) as sensors. This paradigm enables to collect a huge amount of data from the crowd for world-wide applications, without spending cost to buy dedicated sensors. Despite of this benefit, the data collected from human sensors are inherently uncertain due to no quality guarantee from the participants. Moreover, the participatory sensing data are time series that not only exhibit highly irregular dependencies on time, but also vary from sensor to sensor. To overcome these issues, we study in this paper the problem of reconciling probabilistic data from given (uncertain) time series collected by participatory sensors. More precisely, an iterative process is executed in which we exchange between two mutual reinforcing routines: (i) aggregating probabilistic time series from multiple sensors and expert input, (ii) validating them by expert knowledge with minimal effort. Through extensive experimentation, we demonstrate the efficiency and effectiveness of our approach on both real data and synthetic data.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {49},
numpages = {11},
keywords = {trust management, participatory sensing, probabilistic database},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227679,
author = {Stantic, Dejan and Jo, Jun},
title = {Multiscale Wavelet Method for Heart Abnormality Detection Within IoTs Environment},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227679},
doi = {10.1145/3227609.3227679},
abstract = {The Internet of Things (IoT) is one of the fastest emerging technologies with many different applications in a number of fields. Within the medical domain it is rapidly expanding the capabilities of the IoT technology. The adoption of the IoT to ECG monitoring has the potential to provide maximum information about the electrical activity of the heart as well as allows the large volume of information to be fully used. This paper proposes the idea of a system that utilizes the IoT with the pre-processing and feature extractions done with the use of discrete wavelet transforms and multiscale analysis. However, efficiency is an important issue due to large and complicated interconnections. The use of features rather than raw data makes the process efficient. We introduce multiscale concept based on modulus maxima and minima for feature extraction, which relies on relative distances from R peaks. We named it Gated multiscale selection and also extended this methodology and introduced a Linear multiscale approach. We have found that the specific Linear multiscale combinations achieve the highest accuracy in individual peak identifications and we demonstrated that the proposed method performs better than methods found in literature.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {50},
numpages = {11},
keywords = {ECG, multiscale analysis, internet of things, wavelet transform},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3227609.3227680,
author = {Chen, Jinyan and Becken, Susanne and Stantic, Bela},
title = {Sentiment Analytics of Chinese Social Media Posts},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227680},
doi = {10.1145/3227609.3227680},
abstract = {The growing number of social media users and their posts provide valuable data about the sentiment that they have toward different services as well as people. Recent advances in big data analytics and natural language processing provided means to automatically calculate sentiment in text. Sentiment analysis is method which can be used to analyze social media content, it basically converts social media post text into quantitative data. While significant work was directed toward sentiment analytics of English text there is limited attention toward sentiment analytic of Chinese language. In this work we propose and test method to identify sentiment in Chinese social media posts and to test our method we rely on posts sent by visitors of Great Barrier Reef by users of most popular Chinese social media platform Sina Weibo. We elaborate process of capturing, managing and also we describe method for sentiment calculation, which provided details of sentiment toward the different GBR destinations and demonstrate that the proposed method is effective to obtain information and to monitor visitors' opinion.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {51},
numpages = {7},
keywords = {Sentiment Analytics, Social media, Natural Language Processing},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

