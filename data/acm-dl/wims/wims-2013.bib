@inproceedings{10.1145/2479787.2479868,
author = {Camacho, David and R-Moreno, Maria D. and Akerkar, Rajendra},
title = {Challenges and Issues of Web Intelligence Research},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479868},
doi = {10.1145/2479787.2479868},
abstract = {The Web has an enormous influence on our everyday life. Thus, more efficient intelligent approaches and technologies are needed to make the most of the Web's unlimited potential. Intelligence can be achieved by making the Web knowing its own structures and content and by applying intelligent techniques to effectively access the resources. Semantic web was one of the significant steps towards Web Intelligence. In this editorial, we discuss some interesting challenges and issues in Web intelligence research. Also the WIMS conference's objective and activities are presented.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {0},
numpages = {4},
keywords = {web semantics, web mining, wisdom web, web intelligence},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479865,
author = {Sheth, Amit and Anantharam, Pramod},
title = {Physical Cyber Social Computing for Human Experience},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479865},
doi = {10.1145/2479787.2479865},
abstract = {Computing has a critical role in solving some of the grand challenges spanning health and wellbeing, sustainability, and prevention of crime. Traditionally, computing has focused on a single narrow view of the problem to provide solutions ignoring the essential human experience component. The availability of low-cost sensors and mobile devices leading to simultaneous and continuous access to events spanning physical, cyber, and social worlds demands rethinking of the traditional computational approaches. We propose Physical-Cyber-Social (PCS) computing, that takes a human centric and holistic view of computing by analyzing observations, knowledge, and experiences from physical, cyber, and social worlds. We exemplify real-world problems that demands the approach of PCS computing and outline the research challenges in building algorithms and techniques for PCS computing.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {1},
numpages = {7},
keywords = {physical-cyber-social systems, social computing, traffic analytics, healthcare, machine perception, semantic computing, intelligence, computing for human experience},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479866,
author = {Jung, Jason J.},
title = {Contextual Synchronization for Social Collaboration in Enterprises},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479866},
doi = {10.1145/2479787.2479866},
abstract = {Since computing environments in enterprises are dramatically changing, it is difficult to support collaboration among people in the enterprises. This paper claims that the context should be efficiently synchronized, in order to efficiently support collaborations between people (agents) in real-time. Thereby, we propose an ontology-based platform for acquainting the most relevant users (e.g., colleagues and classmates), according to their contexts. Two kinds of contexts are modeled with semantic information derived from ontologies; (i) personal context, and (ii) consensual context (which is integrated from several personal contexts). By using measurement criteria to compare them, context-based communities can be dynamically organized with respect to the similarities among several aspects of personal context. In particular, users can engage in complex collaborations related to multiple semantics. For experimentation, a social browsing system has been implemented based on context synchronization.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {2},
numpages = {2},
keywords = {social networks, contextual synchronization, collaborative work},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479867,
author = {G\'{o}mez-P\'{e}rez, Asunci\'{o}n and Vila-Suero, Daniel and Montiel-Ponsoda, Elena and Gracia, Jorge and Aguado-de-Cea, Guadalupe},
title = {Guidelines for Multilingual Linked Data},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479867},
doi = {10.1145/2479787.2479867},
abstract = {In this article, we argue that there is a growing number of linked datasets in different natural languages, and that there is a need for guidelines and mechanisms to ensure the quality and organic growth of this emerging multilingual data network. However, we have little knowledge regarding the actual state of this data network, its current practices, and the open challenges that it poses. Questions regarding the distribution of natural languages, the links that are established across data in different languages, or how linguistic features are represented, remain mostly unanswered. Addressing these and other language-related issues can help to identify existing problems, propose new mechanisms and guidelines or adapt the ones in use for publishing linked data including language-related features, and, ultimately, provide metrics to evaluate quality aspects. In this article we review, discuss, and extend current guidelines for publishing linked data by focusing on those methods, techniques and tools that can help RDF publishers to cope with language barriers. Whenever possible, we will illustrate and discuss each of these guidelines, methods, and tools on the basis of practical examples that we have encountered in the publication of the datos.bne.es dataset.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {3},
numpages = {12},
keywords = {linked data, multilingual, semantic web},
location = {Madrid, Spain},
series = {WIMS '13}
}

@dataset{10.1145/review-2479787.2479867_R49222,
author = {Mizera-Pietraszko, Jolanta},
title = {Review ID:R49222 for DOI: 10.1145/2479787.2479867},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2479787.2479867_R49222}
}

@inproceedings{10.1145/2479787.2479820,
author = {Marie, Nicolas and Gandon, Fabien and Legrand, Damien and Ribi\`{e}re, Myriam},
title = {Discovery Hub: A Discovery Engine on the Top of DBpedia},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479820},
doi = {10.1145/2479787.2479820},
abstract = {This paper supports the Discovery Hub demonstration proposal. Web growth, both in size and diversity, and users' growing expectations increase the need for innovative search approaches and technologies. Exploratory search systems are built specifically to help user in cognitive consuming search tasks like learning or investigation. Some of these systems are built on the top of linked data and use its semantic richness to provide cognitively-optimized search experiences. This paper presents the Discovery Hub operational prototype after detailing its Semantic Spreading Activation (SSA) algorithm. This latter processes linked data in on-the-fly and does not require partial or total results pre-processing. This on-the-fly processing offers advantages when addressing evolving linked data datasets and querying flexibility.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {4},
numpages = {6},
keywords = {exploratory search system, semantic web, composite interest query, linked data, spreading activation, discovery engine, semantic spreading activation, DBpedia},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479821,
author = {Anantharam, Pramod and Barnaghi, Payam and Sheth, Amit},
title = {Data Processing and Semantics for Advanced Internet of Things (IoT) Applications: Modeling, Annotation, Integration, and Perception},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479821},
doi = {10.1145/2479787.2479821},
abstract = {This tutorial presents tools and techniques for effectively utilizing the Internet of Things (IoT) for building advanced applications, including the Physical-Cyber-Social (PCS) systems. The issues and challenges related to IoT, semantic data modelling, annotation, knowledge representation (e.g. modelling for constrained environments, complexity issues and time/location dependency of data), integration, analysis, and reasoning will be discussed. The tutorial will describe recent developments on creating annotation models and semantic description frameworks for IoT data (e.g. such as W3C Semantic Sensor Network ontology). A review of enabling technologies and common scenarios for IoT applications from the data and knowledge engineering point of view will be discussed. Information processing, reasoning, and knowledge extraction, along with existing solutions related to these topics will be presented. The tutorial summarizes state-of-the-art research and developments on PCS systems, IoT related ontology development, linked data, domain knowledge integration and management, querying large-scale IoT data, and AI applications for automated knowledge extraction from real world data.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {5},
numpages = {5},
keywords = {inference, semantic sensor web, cyber-physical-social systems, modelling, traffic analytics, integration, healthcare, ontology, internet of things (IoT), reasoning, knowledge engineering, annotation},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479822,
author = {Voigt, Martin and Aleythe, Michael and Wehner, Peter},
title = {Towards Topics-Based, Semantics-Assisted News Search},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479822},
doi = {10.1145/2479787.2479822},
abstract = {Identifying upcoming topics from a news stream is a challenging and time consuming task for editors since they have to recognize proper keywords, actively search with them, and need to browse the located media assets. To this end, our goal is to enhance an existing newsroom environment to automatically detect upcoming global and regional topics which are suggested for editors further work. To understand the impact of a topic, we provide its evolution over the time and the relations to other subjects as helpful indicators. To achieve our goals, we designed and prototypically implemented an automatic, semantics-based workflow which heavily relies on non-ambiguous named entities extracted from the media assets. Further, we discuss the challenges encountered and point to proper solutions for building your own enterprise-scaled semantics-based application.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {6},
numpages = {7},
keywords = {topic recognition, news search, semantics, trend analysis},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479792,
author = {Zeleny, Jan and Burget, Radek},
title = {Cluster-Based Page Segmentation-a Fast and Precise Method for Web Page Pre-Processing},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479792},
doi = {10.1145/2479787.2479792},
abstract = {Segmenting a web page may be one of initial steps of information retrieval or content classification performed on that page. While there has been an extensive research in this area, the approaches usually focus either on performance or quality of the results. Vision based segmentation is one of the quality focused methods, which are considerably slow. This paper proposes an approach for boosting the performance of vision based algorithms. Our approach is based on concepts of modern web and a very common scenario in which an entire web site is processed at once. In this scenario, a great amount of performance boost can be gained by isomorphic mapping of previous results gathered from pages within the site to other pages on the same site. We provide the results of experiments performed on VIPS, the most common algorithm for page segmentation.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {7},
numpages = {12},
keywords = {vision-based page segmentation, template, VIPS, template detection, clustering},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479818,
author = {Bello-Orgaz, Gema and Camacho, David},
title = {Comparative Study of Text Clustering Techniques in Virtual Worlds},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479818},
doi = {10.1145/2479787.2479818},
abstract = {Virt-UAM (Virtual Worlds at Universidad Aut\'{o}noma de Madrid) platform allows to design and implement virtual spaces where a set of avatars can be intensively monitored using a set of tools which can be managed by an administrator. In a virtual world, the users can move and interact between them with a high degree of freedom. The movements, interactions and any other information related to the avatars conversations can be stored. Hence this data is available for processing and analysing to obtain the user behavioural patterns. Document clustering techniques have been intensively applied to automatically organize a document corpus into clusters or similar groups. The topic detection problem can be considered as a special case of document clustering, therefore, these techniques can be used over textual chat to detect clusters from the data, and then extract the conversation topics. Mahout(TM) machine learning library is an Apache(TM) project whose main goal is to build scalable machine learning libraries. This library provides a set of algorithms for data mining and for information retrieval ready to use. This paper shows a practical application of some of these available clustering mahout algorithms, in a virtual world-based scenario. These algorithms have been applied to extract the topics based on clusters obtained from the text messages. Finally, a comparative study of these document clustering algorithms used is presented.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {9},
numpages = {8},
keywords = {distance measures, avatar behaviours, clustering algorithms, mahout library, text clustering},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479807,
author = {Men\'{e}ndez, H\'{e}ctor D. and Plaza, Laura and Camacho, David},
title = {A Genetic Graph-Based Clustering Approach to Biomedical Summarization},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479807},
doi = {10.1145/2479787.2479807},
abstract = {Summarization techniques have become increasingly important over the last few years, specially in biomedical research, where information overload is major problem. Researchers of this area need a shorter version of the texts which contains all the important information while discarding irrelevant one. There are several applications which deal with this problem, however, these applications are sometimes less informative than the user needs. This work deals with this problem trying to improve a summarization graph-based process using genetic clustering techniques. Our automatic summaries are compared to those produced by several commercial and research summarizers, and demonstrate the appropriateness of using genetic techniques in automatic summarization.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {10},
numpages = {8},
keywords = {automatic summarization, natural language processing, summarization, clustering, genetic algorithms},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479790,
author = {Ben Ammar, Ali and Abdellatif, Abdelaziz and Ben Ghezala, Henda},
title = {MOWS: Macro and Micro Online Webview Selection},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479790},
doi = {10.1145/2479787.2479790},
abstract = {In this paper we present an approach, called MOWS, to select materialized webview in data--intensive websites (DIWS). A webview is a static instance of a dynamic web page. The materialization of webviews consists of storing the results of some requests on the server in order to avoid repetitive data generation from the sources. The aim is to improve the query response time. Our contribution in this work is to apply two steps for the selection of webviews. The first one is executed periodically and it consists of filtering the candidate webviews. It is called macro-selection. The second is executed online and it consists of selecting the materialized webviews. It is called micro-selection. Our experiment results show that our solution is very efficient to improve query response time especially for the websites with high size. For this type of websites, our approach overcomes the existing solutions and it improves their query response times by more than 70%.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {11},
numpages = {10},
keywords = {materialized webview, micro-selection, quality of service, web-usage mining, quality of data, materialization weight, selection, multi-constraint selection, macro-selection},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479797,
author = {Stavropoulos, Thanos G. and Vrakas, Dimitris and Vlahavas, Ioannis},
title = {Iridescent: A Tool for Rapid Semantic Annotation of Web Service Descriptions},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479797},
doi = {10.1145/2479787.2479797},
abstract = {Although the Semantic Web and Web Service technologies have already formed a synergy towards Semantic Web Services, their use remains limited. Potential adopters are usually discouraged by the number of different methodologies and the lack of tools, which both force them to acquire expert knowledge and commit to exhausting manual labor. This work proposes a novel functional and user-friendly graphical tool, named Iridescent, intended for both expert and non-expert users, to create and edit Semantic Web Service descriptions, following the SAWSDL recommendation. The tool's aim is twofold: to enable users manually create descriptions in a visual manner, providing a complete alternative to coding, and to semi-automate the process by matching elements and concepts and suggesting annotations. A state-of-the-art survey has been carried out to reveal critical points and requirements. The tool's functionality is presented along with usage scenarios that demonstrate how the tool and SAWSDL enable Intelligence in an Ambient Intelligence environment. Finally, Iridescent was methodically tested for its usability and evaluated by a range of both expert and non-expert users.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {12},
numpages = {9},
keywords = {web services, service-oriented architecture, semantic web tools, semantic web services},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479798,
author = {Kordomatis, Iraklis and Herzog, Christoph and Fayzrakhmanov, Ruslan R. and Kr\"{u}pl-Sypien, Bernhard and Holzinger, Wolfgang and Baumgartner, Robert},
title = {Web Object Identification for Web Automation and Meta-Search},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479798},
doi = {10.1145/2479787.2479798},
abstract = {Web object identification plays an important role in research fields such as information extraction, web automation, and web form understanding for building meta-search engines. In contrast to other works, we approach this problem by analyzing various spatial, visual, functional and textual characteristics of web pages. We compute 49 unique features for all visible web page elements, which are then applied to machine learning classifiers in order to identify similar elements on other previously unexamined web pages. We evaluate our approach with different scenarios by analyzing the relevance of the chosen features and the classification rate of the applied classifiers. These scenarios focus on understanding search forms from the transportation domain, particularly flight, train, and bus connections. The results of the evaluation are very promising.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {13},
numpages = {12},
keywords = {web object identification, web page visual representation, machine learning, web accessibility, web automation},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479794,
author = {Anantharam, Pramod and Srivastava, Biplav and Sheth, Amit},
title = {Utility-Driven Evolution Recommender for a Constrained Ontology},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479794},
doi = {10.1145/2479787.2479794},
abstract = {Ontology evolution continues to be an important problem that needs further research. Key challenges in ontology evolution and creation of a highly consumable ontology include accomodating: (a) the subtle changes in the meaning of a model element over time, (b) the changing relevance of various parts of the model to the user, and (c) the complexity in representing time-varying semantics of model elements in a dynamic domain.In this work, we address the challenge of evolving an ontology to keep up with the domain changes while focusing on the utility of its content for relevance and imposing constraints for performance. We propose a novel evidence accumulation framework as a principled approach for ontology evolution, which is sufficiently expressive and semantically clear. Our approach classifies model elements (e.g., concepts) into three categories: definitely relevant (that must be included in the ontology), potentially relevant (that can be kept as backup), and irrelevant (that should be removed). Further, our approach dynamically re-classifies models based on external triggers like evidence or internal triggers, like the age of a model in the ontology. As a result, users will have an ontology which is both effective and efficient. We evaluate our approach based on two measures - ontology concept retention and ontology concept placement. This comprehensive evaluation in a single framework is novel and we show that our approach yields promising results.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {14},
numpages = {11},
keywords = {ontology concept retention, ontology evolution, evolution strategy, ontology concept placement, evidence accumulation},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479791,
author = {Ra, Minyoung and Yoo, Donghee and No, Sungchun},
title = {Construction and Applicability of Military Ontology for Semantic Data Processing},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479791},
doi = {10.1145/2479787.2479791},
abstract = {Recently, ontology has been utilized as a crucial element in knowledge management and knowledge representation. In the military area, the importance of ontology is also increasing. If military ontology is provided, machines will be able to understand and automatically manage information from various military information systems. Hence, how to construct and apply military ontology has become a significant research challenge. In this paper, we present the construction of the military ontology based on the Mixed Ontology Building Methodology (MOBM) and describe four application services using the military ontology for semantic data processing in the Army Tactical Command Information System (ATCIS). From these services, we show that military ontology can be used for constructing intelligent military information systems.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {15},
numpages = {7},
keywords = {semantic web, military ontology, MOBM, semantic data processing, ATCIS},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479802,
author = {Veres, Csaba and Johansen, Kristian and Opdahl, Andreas},
title = {SynsetTagger: A Tool for Generating Ontologies from Semantic Tags},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479802},
doi = {10.1145/2479787.2479802},
abstract = {Semantic or "rich" tagging can be a source of valuable metadata which can be used for discovery and interoperability. We present a tool that uses semantic tags to construct lightweight ontologies which can provide valuable semantic metadata about the tagged resources, and can enhance interoperability and knowledge discovery on the basis of these tags. We illustrate the use of the tool with an example that shows its utility for a commercially relevant task.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {16},
numpages = {10},
keywords = {ontology, conceptual model, wordnet},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479799,
author = {Dal Mas, Massimiliano},
title = {Modelling Web User Synergism for the Similarity Measurement on the Ontology Matching: Reasoning on Web User Felling for Uncertain Evolving Systems},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479799},
doi = {10.1145/2479787.2479799},
abstract = {Though many ontology matching are characterized by various similarity measures this work introduces a method based on significant changes of "a web user feelings" on web content, represented by web object. The development of a web user synergism on the similarity measurements for the ontology alignment has been modeled in terms of the systems dynamic. The analysis of the model proposed was done according to the Bifurcation Analysis, while its validation was performed with the comparison between the model results and the users observations.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {17},
numpages = {8},
keywords = {dynamical system, usage mining, bifurcation theory, similarity, ontology matching, ontology, user behavior},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479806,
author = {Hu, Yuh-Jong and Cheng, Kua-Ping and Huang, Ya-Ling},
title = {Crafting a Balance between Big Data Utility and Protection in the Semantic Data Cloud},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479806},
doi = {10.1145/2479787.2479806},
abstract = {Structured big data of Personal Identifiable Information (PII) are acquired from everywhere and stored as microdata in a statistical database. Given a statistical disclosure control method, big data analysis and protection are enacted for outsourcing data sources. We flexibly glean the data utility to achieve effective data-driven decision-making. However, we still comply with the privacy protection principles while applying data analysis. In this paper, we propose three types of semantics-enabled policies for controlling access, handling data, and releasing data to craft a balance between data utility and protection. Structured big data are tagged with semantic metadata to enable semantics-enabled policy's direct processing and interpretation. Finally, we demonstrate how to craft a balance between data utility and protection with these types of semantics-enabled policies, combined with various statistical disclosure control methods.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {18},
numpages = {12},
keywords = {big data, semantics-enabled policy, world wide web, statistical disclosure control, data protection, data utility, semantic data cloud},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479789,
author = {Kawase, Ricardo and Fisichella, Marco and Nunes, Bernardo Pereira and Ha, Kyung-Hun and Bick, Markus},
title = {Automatic Classification of Documents in Cold-Start Scenarios},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479789},
doi = {10.1145/2479787.2479789},
abstract = {Document classification is key to ensuring quality of any digital library. However, classifying documents is a very time-consuming task. In addition, few or none of the documents in a newly created repository are classified. The non-classification of documents not only prevents users from finding information but also hinders the system's aptitude to recommend relevant items. Moreover, the lack of classified documents prevents any kind of machine learning algorithm to automatically annotate these items. In this work, we propose a novel approach to automatically classifying documents that differs from previous works in the sense that it exploits the wisdom of the crowds available on the Web. Our proposed strategy adapts an automatic tagging approach combined with a straightforward matching algorithm to classify documents in a given domain classification. To validate our findings, we compared our methods against the existing and performed a user evaluation with 61 participants to estimate the quality of the classifications. Results show that, in 72% of the cases, the automatic classification is relevant and well accepted by participants. In conclusion, automatic classification can facilitate access to relevant documents.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {19},
numpages = {10},
keywords = {user evaluation, information retrieval, digital libraries, automatic classification, cold-start},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479817,
author = {Traverso-Rib\'{o}n, Ignacio and Ru\'{\i}z-Rube, Iv\'{a}n and Dodero, Juan Manuel and Palomo-Duarte, Manuel},
title = {Open Data Framework for Sustainable Assessment in Software Forges},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479817},
doi = {10.1145/2479787.2479817},
abstract = {In a project-based learning experience, the detailed monitoring of the activities in which team members participate can be useful to evaluate their work. Using learning-oriented assessment procedures, supervisors can assess the teamwork abilities with a formative purpose. Evaluation strategies such as self-assessment, peer assessment and co-assessment are often used to make evaluation formative and sustainable. Conducting an assessment strategy is not easy for team members, since they need before to have a reasonable understanding of the evaluation process and criteria. This paper describes a learning-oriented evaluation methodology and a open data framework that can be applied to collaborative software development project settings. An evaluation rubric and a series of indicators that provide evidences about the developed skills have been elaborated and applied in a small-scale project-based course on Web Engineering. Projects were managed and developed with the help of an open source software forge that contains a ticketing tool for planning and tracking of tasks, a version control repository to save the software deliverables, and using a wiki to host text deliverables. The experience provides evidences in favor of using the assessment method and open data framework to make teamwork evaluation more sustainable.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {20},
numpages = {8},
keywords = {project-based learning, software forges, assessment},
location = {Madrid, Spain},
series = {WIMS '13}
}

@dataset{10.1145/review-2479787.2479817_R48899,
author = {Godwin, Stewart Mark},
title = {Review ID:R48899 for DOI: 10.1145/2479787.2479817},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2479787.2479817_R48899}
}

@inproceedings{10.1145/2479787.2479793,
author = {Le, Anh-Hoang and Lefevre, Marie and Cordier, Am\'{e}lie and Skaf-Molli, Hala},
title = {Collecting Interaction Traces in Distributed Semantic Wikis},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479793},
doi = {10.1145/2479787.2479793},
abstract = {In the Kolflow project, our general objective is to develop an assistance engine suitable for distributed applications. In order to provide contextualized and relevant assistance, we feed the assistance engine with interaction traces. Interaction traces record events occurring while users are interacting with applications. These traces become containers of valuable knowledge to providing assistance. Collecting interaction traces is a challenging issue that has been thoroughly studied in the context of local applications. In contrast, few approaches focus on collecting interaction traces in distributed applications. Yet, when applications are distributed, collecting interaction traces is even more challenging because new difficulties arise, such as data synchronization and multi-synchronous collaboration. In this paper, we propose a model and a tool for collecting traces in a distributed environment. The originality of the model is that it is tailored to fit distributed applications. We implemented the model in Collectra, a tool to collect interaction traces in distributed web applications. Collectra collects interaction traces and stores them in a dedicated trace-base management system. We report on the experiments we have conducted in order to evaluate performances of Collectra (both response time and memory space). Results of the experiments show that Collectra performs well and that it can be used to support the assistance tasks carried out by the assistance engine.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {21},
numpages = {11},
keywords = {user assistance, trace collection process, model of trace, distributed semantic wikis, interaction traces, trace-based reasoning},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479795,
author = {Moerland, Marnix and Hogenboom, Frederik and Capelle, Michel and Frasincar, Flavius},
title = {Semantics-Based News Recommendation with SF-IDF+},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479795},
doi = {10.1145/2479787.2479795},
abstract = {Content-based news recommendations are usually made by employing the cosine similarity and the TF-IDF weighting scheme for terms occurring in news messages and user profiles. Recent developments, such as SF-IDF, have elevated news recommendation to a new level of abstraction by additionally taking into account term meaning through the exploitation of synsets from semantic lexicons and the cosine similarity. Other state-of-the-art semantic recommenders, like SS, make use of semantic lexicon-driven similarities. A shortcoming of current semantic recommenders is that they do not take into account the various semantic relationships between synsets, providing only for a limited understanding of news semantics. Therefore, we extend the SF-IDF weighting technique by additionally considering the synset semantic relationships from a semantic lexicon. The proposed recommendation method, SF-IDF+, as well as SF-IDF and several semantic similarity lexicon-driven methods have been implemented in Ceryx, an extension to the Hermes news personalization service. An evaluation on a data set containing financial news messages shows that overall (by accounting for all considered cut-off values) SF-IDF+ outperforms TF-IDF, SS, and SF-IDF in terms of F1-scores.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {22},
numpages = {8},
keywords = {semantic web, user profiling, recommender systems, semantic similarity, content-based recommender, news personalization},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479796,
author = {Tahrat, Sabiha and Kergosien, Eric and Bringay, Sandra and Roche, Mathieu and Teisseire, Maguelonne},
title = {Text2Geo: From Textual Data to Geospatial Information},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479796},
doi = {10.1145/2479787.2479796},
abstract = {In this paper, we focus on methods for extracting spatial information in text documents. After presenting textual description of space and manual annotation of named entities, mainly location and organization, we present our proposal Text2Geo. It is a hybrid method which combines information extraction approach based on patterns with a supervised classification approach to explore context. We discuss some results obtained on the dataset of Thau lagoon.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {23},
numpages = {4},
keywords = {spatial information, geographic information retrieval, supervised classification, natural language processing},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479804,
author = {cherichi, Soumaya and Faiz, Rim},
title = {New Metric Measure for the Improvement of Search Results in Microblogs},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479804},
doi = {10.1145/2479787.2479804},
abstract = {In recent years, microblogging services like Twitter, draws the attention of users. These micro-blogs attract more and more users due to the ease and the speed of information sharing especially in real time. Microbloggers, while posting microblogs, search for fresh information related to their interests. Finding good results concerning the given subjects needs to consider the features of microblogs. Several works have proposed criteria for tweets search, but, this area is still not well exploited, consequently, search results are irrelevant. In this paper, we propose new features (for example audience and RetweetRank). We investigate the impact of these criteria on the search's results for relevant information. Finally, we propose a new metric to improve the results of the searches in microblogs. More accurately, we propose a research model that combines content relevance, tweet relevance and author relevance. Each type of relevance is characterized by a set of criteria such as audience to assess the relevance of the author, OOV (Out Of Vobulary) to measure the relevance of content and others. To evaluate our model, we used a corpus of subjective tweets talking about Tunisian actualities in 2012.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {24},
numpages = {7},
keywords = {social information retrieval, social network, measuring impact, micro-blog, relevant tweets, Twitter},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479809,
author = {Salekin, Asif and Tabassum, Jeniya and Jafar, Binte and Hasan, Masud},
title = {Extract and Rank Web Communities},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479809},
doi = {10.1145/2479787.2479809},
abstract = {A web community is a pattern in the WWW which is understood as a set of related web pages. In this paper, we propose an efficient algorithm to find the web communities on a given specific topic. Instead of working on the whole web graph, we work on a web domain, which we extract based on the topic specific search results. Therefore, the resulted communities are highly related with the search topic.The ranking of a community denotes the degree of relevance between the search query and the extracted communities. We introduce an approach for ranking the extracted communities based on their dense bipartite pattern. Ranking significantly improves the relevance of the extracted communities with the search topic.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {25},
numpages = {8},
keywords = {structured web search, dense bipartite graph, web community, web graph, domain graph, ranking web communities},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479801,
author = {Karlsen, Randi and Sundby, David and Nordbotten, Joan},
title = {Automatic Generation of Textual Image Collection Descriptions},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479801},
doi = {10.1145/2479787.2479801},
abstract = {Digital photo collections are growing rapidly in number and size, making location of relevant images increasingly difficult. Since very few image collections have a description of their content, an image seeker must manually locate image collections and use that collection's image retrieval system to determine if there are any relevant images for his/her need. Manually describing a large and growing image collection that may contain a variety of diverse themes, is a near impossible task. Thus some techniques for automatic generation of image collection descriptions are needed. Further, since most image retrieval systems use text-based queries, it is important that the collection description also be text-based. In the following, we present a system that can automatically generate an image collection description based on available metadata from all images in the collection. These metadata are extended, using information and services available on the Internet, to provide a rich description of the collection as a whole.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {26},
numpages = {11},
keywords = {textual image collection descriptors, image metadata expansion, automatic image collection description},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479803,
author = {Al-Dayel, Abeer and Ykhlef, Mourad},
title = {Query Paraphrasing Enhancement Using Artificial Bee Colony},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479803},
doi = {10.1145/2479787.2479803},
abstract = {Searching for information on the Web has become one of our most important and frequent activities. Sometimes, Web users may formulate a search query based upon their different levels of expertise or background knowledge, which may obscure some useful documents in retrieving results because the query vocabulary differs from the vocabulary within a particular document's collection. This raises the need for automatic query paraphrasing to generate different vocabulary term possibilities. In this study, we will improve a query paraphrasing technique using the artificial bee colony (ABC) algorithm in order to generate the most reliable paraphrased query from the initial search query automatically and without user supervision. Our proposed method shows an improvement in information retrieval performance compared with the genetic algorithm query paraphrasing system.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {27},
numpages = {6},
keywords = {query paraphrasing, information retrieval, artificial bee colony},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479810,
author = {Nageba, Ebrahim and Rubel, Paul and Fayn, Jocelyne},
title = {Semantic Agent System for Automatic Mobilization of Distributed and Heterogeneous Resources},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479810},
doi = {10.1145/2479787.2479810},
abstract = {Advanced information systems increasingly use diverse domain-specific resources like services, data, knowledge, etc. One of the today's ubiquitous computing challenges is to automate the mobilization of heterogeneous distributed resources and to allocate them to user-tasks. In this paper, we propose a semantic agent system to solve the problem of resources mobilization and allocation taking into account the continuous changes of the resources conditions. We first propose a formal model of an efficient Resources Mobilization Semantic Agent. Our proposed model is mainly based on ontological models representing basic entities of a collaborative environment as well as their interrelations, rules, inference engine, and object oriented components for resources data processing. Then we suggest mechanisms to handle the discovered resources in terms of updating, filtering, ranking, and allocating. We also provide an application example from the eHealth domain to demonstrate how the proposed semantic agent system can efficiently support the mobilization and allocation of different types of resources according to the user-tasks specifications and to the discovered resources conditions in terms of availability, accessibility, and capability.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {28},
numpages = {9},
keywords = {ontology, task-based computing, collaborative environment, rule-based reasoning, knowledge representation, resources management},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479805,
author = {Goodwin, Morten},
title = {Towards Automatic Assessment of Government Web Sites},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479805},
doi = {10.1145/2479787.2479805},
abstract = {This paper presents an approach for automatic assessment of web sites in large scale e-Government surveys. The approach aims at supplementing and to some extent replacing human evaluation which is typically the core part of these surveys.The heart of the solution is a colony inspired algorithm, called the lost sheep, which automatically locates targeted governmental material online. The algorithm centers around classifying link texts to determine if a web page should be downloaded for further analysis.The proposed algorithm is designed to work with minimum human interaction and utilize the available resources as best possible. Using the lost sheep, the people carrying out a survey will only provide sample data for a few web sites for each type of material sought after. The algorithm will automatically locate the same type of material in the other web sites part of the survey. This way it significantly reduces the need for manual work in large scale e-Government surveys.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {29},
numpages = {12},
keywords = {search, classification, crawling},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479808,
author = {Chung, Jin-Woo and Min, Hye-Jin and Kim, Joonyeob and Park, Jong C.},
title = {Enhancing Readability of Web Documents by Text Augmentation for Deaf People},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479808},
doi = {10.1145/2479787.2479808},
abstract = {Deaf people have particular difficulty in understanding text-based web documents because their mother language, or sign language, is essentially visually oriented. To enhance the readability of text-based web documents for deaf people, we propose a news display system that converts complex sentences in news articles into simple sentences and presents the relations among them with a graphical representation. In particular, we focus on the tasks of 1) identifying subordinate and embedded clauses in complex sentences, 2) relocating them for better readability and 3) displaying the relations among the clauses with the graphical representation. The results of our evaluation show that the proposed system does simplify complex sentences in news articles effectively while maintaining their intended meaning, suggesting that our system can be used in practice to help deaf people to access textual information.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {30},
numpages = {10},
keywords = {deaf people, text simplification, readability, web accessibility},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479811,
author = {Oliveira, Nuno and Cortez, Paulo and Areal, Nelson},
title = {Some Experiments on Modeling Stock Market Behavior Using Investor Sentiment Analysis and Posting Volume from Twitter},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479811},
doi = {10.1145/2479787.2479811},
abstract = {The analysis of microblogging data related with stock markets can reveal relevant new signals of investor sentiment and attention. It may also provide sentiment and attention indicators in a more rapid and cost-effective manner than other sources. In this study, we created several indicators using Twitter data and investigated their value when modeling relevant stock market variables, namely returns, trading volume and volatility. We collected recent data from nine major technological companies. Several sentiment analysis methods were explored, by comparing 5 popular lexical resources and two novel lexicons (emoticon based and the merge of all 6 lexicons) and sentiment indicators produced using two strategies (based on daily words and individual tweet classifications). Also, we measured posting volume associated with tweets related to the analyzed companies. While a short time period is considered (32 days), we found scarce evidence that sentiment indicators can explain these stock returns. However, interesting results were obtained when measuring the value of using posting volume for fitting trading volume and, in particular, volatility.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {31},
numpages = {8},
keywords = {volatility, text mining, sentiment analysis, trading volume, returns, microblogging data},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479812,
author = {Renteria-Agualimpia, Walter and L\'{o}pez-Pellicer, Francisco J. and Lacasta, Javier and Zarazaga-Soria, F. Javier and Muro-Medrano, Pedro R.},
title = {Identifying Hidden Geospatial Resources in Catalogues},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479812},
doi = {10.1145/2479787.2479812},
abstract = {Geonetwork systems are one of the most popular geographic resources catalogues on the Web. One of the key elements of the successful of Geonetwork is the Geospatial metadata. Geonetwork use the direct and indirect spatial references from the metadata to process the spatial queries. However the inconsistencies between direct and indirect spatial references generate imprecise results, the invisibility of potential resources, and consequently the omission of many important data. The visibility of resources in a collection often depends on the consistency of the descriptions that help to find resources. Spatially inconsistent metadata records can hide resources and make them irretrievable. This paper presents an automatic method based on the combination of spatial clustering, reverse geocoding, and information retrieval techniques able to measure and detect geosemantic inconsistencies in metadata collections. Experimental results with a large metadata dataset about Geospatial Web Services show that the use of this method provides not only significant advantage in terms of accuracy, but also a gain of geosemantic insight into the metadata. Approach like this could be used by semantic technologies to draw connection from unstructured geospatial information to data from other structured geospatial information.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {32},
numpages = {7},
keywords = {geocoding, validation, spatial clustering, geospatial web services, geospatial catalogues, metadata},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479813,
author = {Jmal, Jihene and Faiz, Rim},
title = {Customer Review Summarization Approach Using Twitter and SentiWordNet},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479813},
doi = {10.1145/2479787.2479813},
abstract = {Since E-commerce is becoming more and more popular, the number of customer reviews raises rapidly. Opinions on the Web affect our choices and decisions. Thus, it becomes necessary to automatically process a mixture of reviews and prepare to the customer the required information in an appropriate form. In the same context, we present a new approach of feature-based opinion summarization which aims to turn the customer reviews into scores that measure the customer satisfaction for a given product and its features. These scores are between 0 and 1 and can be used for decision making and then help users in their choices. We investigated opinions extracted from nouns, adjectives, verbs and adverbs contrary to previous researches which use essentially adjectives. Experimental results show that our method performs comparably to classic feature-based summarization methods.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {33},
numpages = {8},
keywords = {opinion mining, sentiment classification, feature-based opinion summarization, opinion strength, feature buzz summary},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479819,
author = {R-Moreno, Mar\'{\i}a D. and Cuesta, \'{A}lvaro and Barrero, David F.},
title = {Twitter Stream Analysis in Spanish},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479819},
doi = {10.1145/2479787.2479819},
abstract = {Social networks have opened to companies and politicians' new ways to understand what the clients and citizens are looking for. That is, companies need to understand what is happening in the market in order to be competitive. And politicians need to better understand what the people are worried about if they want to comply with the wishes of their voters. Until now, a significant amount of resources were dedicated to collect a small set of consumers or citizens opinions to conduct focus groups and surveys in pursuit of consumers or social insights. With the rise of social networks, things have changed. Companies and politicians now have the ability to gather more data than ever before on a large number of users in near real time and at a much lower cost.In this paper we present the architecture we are building on top of Twitter in order to extract and analyze the mood of the users against some events. In particular, we have analyzed the impact that the "Boston Marathon" event produced in the public opinion. During the observed time frame we have observed little social iteration and a high number of retweets in the Spanish-speaker twitter community.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {34},
numpages = {6},
keywords = {stream analysis, social networks, tweets, sentiment analysis, Twitter},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479788,
author = {Velardi, Paola and D'Antonio, Fulvio and Cucchiarelli, Alessandro},
title = {Open Domain Knowledge Extraction: Inference on a Web Scale},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479788},
doi = {10.1145/2479787.2479788},
abstract = {Though ontologies are considered central to foster the Semantic Web effort, their practical application on a Web scale is limited by the difficulty of building and maintaining high-coverage ontologies, for any of the almost unbounded number of social and technical domains mirrored on the Web. In this paper we present Open Knowledge Extraction (Open KE), a novel paradigm that creates a bridge between information retrieval, taxonomy learning and automated reasoning. Open KE builds on recently published algorithms for Open Information Extraction (Open IE) and automated taxonomy learning, which were shown able to extract information on a Web scale basis in an unsupervised manner. The key idea of Open KE is to generalize Open IE's lexicalized extractions with an automatically learned taxonomy. Lexicalized extractions are transformed in logic predicates, and used to populate a Semantic Model. An inference engine is then used to perform inductions and deductions. In this paper we describe the knowledge extraction workflow in its entirety, and apply it to a large-scale experiment in the domains of Artificial Intelligence and Virology.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {35},
numpages = {8},
keywords = {open information extraction, taxonomy learning, semantic web, ontology, automated reasoning},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479823,
author = {Voigt, Martin and Tietz, Vincent and Piccolotto, Nikolaus and Mei\ss{}ner, Klaus},
title = {Attract Me! How Could End-Users Identify Interesting Resources?},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479823},
doi = {10.1145/2479787.2479823},
abstract = {Recently, the interest in semantic web technologies increased in various domains, e.g., software engineering or biology. Since this technologies address the long tail of information domains with missing content types, the number of linked datasets will grow even more rapidly. Tech-savvy users and scientists benefit from this trend as they have the knowledge to created complex queries, and thus, to retrieve interesting subsets and answers. However, end-users have difficulties to understand the data's paradigm and need appropriate tool support to slice and dice the data to understandable parts or particular resources. In this paper, we propose a novel approach to enable end-users to browse huge semantic datasets, to detect, and to select interesting resources according to their specific tasks. Based on our evaluation results of two user studies using a web-based prototype we explain, which visualization and interaction techniques in combination with automatic filters are well-suited for novices.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {36},
numpages = {12},
keywords = {filtering, end-user, interaction, semantic web, linked data},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479824,
author = {Brunetti, Josep Maria},
title = {Design and Evaluation of Overview Components for Effective Semantic Data Exploration},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479824},
doi = {10.1145/2479787.2479824},
abstract = {The growing volumes of semantic data available in the Web result in the need for handling the Information Overload phenomenon. The potential of this amount of data is enormous but in most cases it is very difficult for users to visualize, explore and use this data, especially for lay-users without experience with Semantic Web technologies. The Visual Information-Seeking Mantra "Overview first, zoom and filter, then details-on-demand" proposed by Shneiderman describes how data should be presented in different stages to achieve an effective exploration. The overview is the first user task when dealing with a dataset. The objective is that the user is capable of getting an idea about the overall structure of the dataset. However, obtaining this overview cannot be easily done with the current semantic web browsers. Overviews become difficult to achieve with large heterogeneous datasets, which is typical in the Semantic Web. There is little or no support to obtain overview information quickly and easily at the beginning of the exploration of a new dataset. This can be a serious limitation when exploring a dataset for the first time, specially for lay-users. Our proposal is to reuse and adapt existing Information Architecture (IA) components to provide this overview to users. Such IA components are well known to Web users, as they are present in most web pages: navigation bars, site maps and site indexes. We complement them with treemaps, a visualization technique for displaying hierarchical data. We report about the design of these components as well as their evaluation with end-users performing real tasks.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {37},
numpages = {8},
keywords = {interaction, exploration, overview, linked data, hierarchy, semantic web},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479825,
author = {Polowinski, Jan},
title = {Towards RVL: A Declarative Language for Visualizing RDFS/OWL Data},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479825},
doi = {10.1145/2479787.2479825},
abstract = {Information on how to visualize RDF data is stored differently by each visualization tool to date. We propose the RDFS/OWL Visualization Language (RVL), a declarative language for sharing visualization settings as simple as CSS styles. The mapping definitions can be given a URI and shared along with the data to be visualized, they can be composed, extended and reused. The declarative approach has the benefit that this can be done independently of specific platforms. Unlike styling or presentation languages for RDF or pure visualization languages, RVL combines rich visual mapping capabilities with the direct awareness of RDFS/OWL language constructs.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {38},
numpages = {11},
keywords = {semantic web, visual mapping, visualization language, ontologies, linked data, visual encoding, RDFS/OWL},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479826,
author = {Rodriguez, B. Helena and Moissinac, Jean-Claude and Demeure, Isabelle},
title = {Soa2mSituation: An Interaction Situation Model for the Multimodal Web},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479826},
doi = {10.1145/2479787.2479826},
abstract = {The Soa2mSituation is a semantic model for specifying structure and behavior of multimodal interfaces according with the interaction context. Our research focuses on a multimodal model of services for the dynamic composition of interactive features in multimodal systems. We propose an interaction situation model to enhance the management of the interaction conditions in terms of roles, stereotypical activities and perception. The ontology is based on the upper-level ontology DOLCE+DnS Lite. It provides a flexible means for multimodal components annotation and context-aware presentation in a SOA architecture. This architecture is based on the W3C's Multimodal Interaction Architecture and Interfaces standard.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {39},
numpages = {12},
keywords = {interface services, context aware, ontologies, multimodal interaction, semantic interaction, pervasive computing, DOLCE, MMI architecture and interfaces},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479827,
author = {Tietz, Vincent and R\"{u}mpel, Andreas and Voigt, Martin and Siekmann, Philipp and Mei\ss{}ner, Klaus},
title = {Tool Support for Semantic Task Modeling},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479827},
doi = {10.1145/2479787.2479827},
abstract = {In the domain of Web applications, several model-based approaches have been introduced, supporting user-centered requirements engineering and thereon the identification of presentation elements and interaction techniques. Semantic application modeling and task decomposition provides promising results, especially for Web mashups. However, current tooling support lacks semantics-based and user-driven modeling facilities, making it unsuitable for matching algorithms and semantic mashup composition. This paper presents a novel concept for a task modeling tool, supporting ontology-based requirements specification of enterprise mashups. It smoothly integrates in a Web mashup development process. We show the feasibility of our approach with the help of a prototype that is evaluated by a small user study.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {40},
numpages = {12},
keywords = {mashups, task modeling, semantics},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479828,
author = {Graves, Alvaro},
title = {Creation of Visualizations Based on Linked Data},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479828},
doi = {10.1145/2479787.2479828},
abstract = {A common task with any relatively large amount of data is to create visual representations that help users to make sense of such data and observe trends that otherwise would be hard for them to appreciate. The creation of these visualizations usually requires some knowledge in a programming language, making it difficult for non-technical savvy users to create visualizations. In this paper we present Visualbox, a system that makes it easier for non-programmers to create web visualizations based on Linked Data. These visualizations can be accessed by any modern web browser and can be easily embedded in web pages and blogs. We describe how people can create visualizations using Visualbox and we show examples of work done by real users. Finally we present a study that shows that Visualbox makes it easier for users to create Linked Data-based visualizations.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {41},
numpages = {12},
keywords = {visualizations, linked data, semantic web, usability, visualization},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479829,
author = {Dal Mas, Massimiliano},
title = {Intelligent Interactive Multimedia System: Layered Ontological Video Contexts in a Folksonomy Driven Environment},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479829},
doi = {10.1145/2479787.2479829},
abstract = {This paper describes a partially developed method on going project for enabling an Intelligent Interactive Multimedia System based on ontological interaction on video clip shown on ubiquitous systems as a computer monitor, mobile or tablet. The paper aims to sketch a theoretical framework on a method for extracting and tracking objects in videos, based on various semantic attributes. It tackles a novel space (cyber-physical) of interaction between human and machine, in a creative way. We use a layered representation based on semantics-driven information to obtain spatiotemporal attributes of objects. The interface is created by extracting object information from the video with a Human Based Computation to obtain a richer semantics of attribute to bridge the semantic gap between words describing an image and its visual features. Users can navigate and manipulate objects displayed on video by associating semantic attributes and comments evaluated by the data and sentiment extraction. Folksonomy tags are extracted from users' comments to be used in a dynamical driven system (Folksodriven). We show some example applications of the proposed method like: advertisement inside the objects displayed on a video, an interface based on objects of interest video navigation, mask layer on an object of interest and a visual interaction for Smart City.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {42},
numpages = {9},
keywords = {natural language processing, intelligent information systems, semantics-driven information retrieval, human-oriented knowledge, recommender systems, human-computer interaction, knowledge-based application},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479830,
author = {Nemirovski, German and Nolle, Andreas and Sicilia, \'{A}lvaro and Ballarini, Ilaria and Corado, Vincenzo},
title = {Data Integration Driven Ontology Design, Case Study Smart City},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479830},
doi = {10.1145/2479787.2479830},
abstract = {Methods to design of formal ontologies have been in focus of research since the early nineties when their importance and conceivable practical application in engineering sciences had been understood. However, often significant customization of generic methodologies is required when they are applied in tangible scenarios. In this paper, we present a methodology for ontology design developed in the context of data integration. In this scenario, a targeting ontology is applied as a mediator for distinct schemas of individual data sources and, furthermore, as a reference schema for federated data queries. The methodology has been used and evaluated in a case study aiming at integration of buildings' energy and carbon emission related data. We claim that we have made the design process much more efficient and that there is a high potential to reuse the methodology.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {43},
numpages = {10},
keywords = {ontology design, ontology mapping, DL-lite family, semantic web, data integration, description logic},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479831,
author = {Corchero, Aitor and Domingo, Xavier and Garc\'{\i}a, Roberto},
title = {Semantic Sensor Web Data Exploration and Visualization for Intelligent Decision Support: Position Paper},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479831},
doi = {10.1145/2479787.2479831},
abstract = {To date, Semantic Sensor Web research and development has focused on establishing common techniques and practices that homogenize how to discover sensors, collect their data, integrate them, extract information from them, etc. However, as these issues are overcome and huge data bases of sensor data begin to emerge, the focus should change to improve the data management and the information overload, discarding the non relevant information from the relevant one, and on the other hand, allow easy and intuitive navigation through it. The objective is to move up the wisdom hierarchy and empower users so they can start discovering new relevant knowledge and making decissions based on that. In this position paper, we start drafting an architecture, aligned with current practices and standards, which facilitates the whole process: from data collecting and storing, to wisdom generation and navigation. Efforts will focus on empower users to spot trends or events in data. Moreover, the system will learn from the discoveries made by users so it can later automatise the detection of similar situations and integrate users wisdom.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {44},
numpages = {4},
keywords = {exploration, decision support, data, visualisation, sensor, semantic web},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479800,
author = {Peska, Ladislav and Vojtas, Peter},
title = {Negative Implicit Feedback in E-Commerce Recommender Systems},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479800},
doi = {10.1145/2479787.2479800},
abstract = {In this paper, we imagine the situation of a typical e-commerce portal employing personalized recommendation. Such website typically receives user feedback from their implicit behavior such as time on page, scrolling etc. The implicit feedback is generally understood as positive only, however we present several methods how to identify some of the implicit feedback as negative user preference, how to aggregate various feedback types together and how to recommend based on it.We have conducted several off-line experiments with real user data from travel agency website confirming that treating some implicit feedback as negative preference can significantly improve recommendation quality.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {45},
numpages = {4},
keywords = {fuzzy T-conorms, e-commerce success metrics, recommender systems, negative implicit feedback},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479815,
author = {Di Maio, Paola and Ure, Jenny},
title = {An Open Conceptual Framework for Operationalising Collective Awareness and Social Sensing},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479815},
doi = {10.1145/2479787.2479815},
abstract = {Substantial EU resources are being invested in research and practice emerging from the socio-technical convergence of networked technologies and social clusters, increasingly referred to as 'collective awareness' and 'social sensing' platforms. Novel concepts and tools are being developed to stimulate and promote technologies and environments, requiring some level of shared conceptualisation of the domain. This position paper identifies the need to capture and represent the knowledge and information in 'social sensing and collective awareness platforms' with minimal formalisms. It proposes steps toward the development of tools for collective development of shared conceptual models, to facilitate communication, knowledge sharing and collaboration in this emerging, and highly interdisciplinary research field.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {46},
numpages = {6},
keywords = {wiki, systems engineering, vocabulary, ontology, semantic},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2479787.2479814,
author = {Calmet, Jacques and Maret, Pierre},
title = {Toward a Trust Model for Knowledge-Based Communities},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479814},
doi = {10.1145/2479787.2479814},
abstract = {The ultimate goal of trust is to reach and make decisions based upon the available knowledge. We think that it is not enough to build trust on beliefs or on recommendation-based models. Our approach aims to implement it within a programming methodology inspired from the theorem proving domain. We propose a conceptual framework which transposes this to the context of virtual organizations. In this paper we describe our approach and partially illustrate it with a prototype system dedicated to information searching in the context of academic exchanges.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {47},
numpages = {5},
keywords = {trust, specification, knowledge},
location = {Madrid, Spain},
series = {WIMS '13}
}

