@inproceedings{10.1145/3326467.3326490,
author = {Fernandez, Aaron Carl T. and Devaraj, Madhavi},
title = {Computing the Linguistic-Based Cues of Fake News in the Philippines Towards Its Detection},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326490},
doi = {10.1145/3326467.3326490},
abstract = {Fake news deliberately beguiles its consumers to accept false or biased ideologies. But as menacing as it sounds to the society, it poses a good classification problem to computer science. This paper presents the disparity in writing style between legitimate news and fake news in the Philippines, and how effective these are as machine learning features. To capacitate this, credible news samples, as well as fake news samples in the Philippines were harvested online. The best feature set was consistent across all experiments and attained a precision of 94% on both the feature selection process and the test set of the final model. It also attained a precision of 93% on a more recent data collected, which was not part of the initial corpus constructed. Furthermore, this paper exhibits how legitimate and fake news in the Philippines can be differentiated just by their headline or content at a precision of 87% and 88%, respectively.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {1},
numpages = {9},
keywords = {Support Vector Machines, Natural Language Processing, Na\"{\i}ve Bayes, Logistic Regression, Feature Selection, Fake News},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326484,
author = {Primpeli, Anna and Bizer, Christian},
title = {Robust Active Learning of Expressive Linkage Rules},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326484},
doi = {10.1145/3326467.3326484},
abstract = {The goal of entity resolution, also known as duplicate detection and record linkage, is to identify all records in one or more data sets that refer to the same real-world entity. To achieve this goal, matching rules, encoding the matching patterns in the data, can be learned with the help of manually annotated record pairs. Active learning for entity resolution aims to minimize the human labeling effort by including the human into the learning loop and by selecting the most informative pairs for labeling. While active learning methods are quite successful at reducing the human labeling effort, we show that their performance decreases when applied to data sets having a large number of sparse attributes. We evaluate the ActiveGenLink active learning method using e-commerce data sets with such characteristics and observe that it is prone to suboptimal convergence points, thus producing highly varying results in different runs of the same experiment. In this paper we present our ongoing work on building a robust active learning method which is able to tackle the instability. Our method applies unsupervised matching of the record pairs as a first step. The unsupervised matching results are used afterwards for bootstrapping the active learning process and for preventing it from converging to suboptimal matching rules. The evaluation shows that the proposed method increases the robustness of the active learning process as it reduces the variation of the results of different runs by 10% to 16%.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {2},
numpages = {7},
keywords = {Missing Values, Entity Resolution, Active Learning, Web Data, Sparse Data, Genetic Programming},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326469,
author = {Simsek, Atakan and Karagoz, Pinar},
title = {Diversification in Wikipedia Enriched Advertisement Recommendation for Microblogs},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326469},
doi = {10.1145/3326467.3326469},
abstract = {Recommendation diversification, which is the action of suggesting dissimilar products, is an emerging and important issue in recommendation systems. Recent studies show that recommending diverse products increases customer satisfaction. This is valid for advertisement recommendation as well. In this study, we investigate the diversification performance of a new advertisement recommendation algorithm. In the algorithm, sentiment enhanced user profiling is further enhanced by using followee/follower property of microblogs. In advertisement matching, Wikipedia enrichment strategy is used. Evaluation on a set of real world data shows that this new algorithm has better diversification performance compared to generic keyword based matching strategy and a previous study that uses Wikipedia enrichment strategy.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {3},
numpages = {6},
keywords = {recommendation, Wikipedia, advertisement, diversification},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326468,
author = {Rafailidis, Dimitrios and Manolopoulos, Yannis},
title = {Can Virtual Assistants Produce Recommendations?},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326468},
doi = {10.1145/3326467.3326468},
abstract = {Virtual assistants, also known as intelligent conversational systems such as Google's Virtual Assistant and Apple's Siri, interact with human-like responses to users' queries and finish specific tasks. Meanwhile, existing recommendation technologies model users' evolving, diverse and multi-aspect preferences to generate recommendations in various domains/applications, aiming to improve the citizens' daily life by making suggestions. The repertoire of actions is no longer limited to the one-shot presentation of recommendation lists, which can be insufficient when the goal is to offer decision support for the user, by quickly adapting to his/her preferences through conversations. Such an interactive mechanism is currently missing from recommendation systems. This article sheds light on the gap between virtual assistants and recommendation systems in terms of different technological aspects. In particular, we try to answer the most fundamental research question, which are the missing technological factors to implement a personalized intelligent conversational agent for producing accurate recommendations while taking into account how users behave under different conditions. The goal is, instead of adapting humans to machines, to actually provide users with better recommendation services so that machines will be adapted to humans in daily life.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {4},
numpages = {6},
keywords = {conversational systems, chatbots, Virtual assistants, recommendation systems},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326486,
author = {Sahid, Galuh Tunggadewi and Mahendra, Rahmad and Budi, Indra},
title = {E-Commerce Merchant Classification Using Website Information},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326486},
doi = {10.1145/3326467.3326486},
abstract = {With the rapid growth of the e-commerce landscape, classifying e-commerce merchants has become an important task as it is an integral part of various processes in e-commerce. One of the examples is merchant on boarding, where the category of an e-commerce merchant has proven to be a good indicator of the risk of the merchant. However, since most of e-commerce businesses do not have brick-and-mortar stores from which we can assess it directly, the only source of information regarding the merchant itself is its website. Thus, we can view this problem as a web classification problem, where we classify e-commerce websites into a category. In this research, we aim to build an end-to-end classification system for e-commerce websites. There are a few challenges such as the number of pages to be processed, imbalanced dataset, and the language of e-commerce websites that can be mixed language. We built a website classification system and experimented with case study of Indonesian and English e-commerce webs, that are classified into 37 different categories. Our best result achieved an F-score of 0.83.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {5},
numpages = {10},
keywords = {Text processing, Classification, E-commerce, Web mining},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326487,
author = {Putra, Hadi Syah and Mahendra, Rahmad and Darari, Fariz},
title = {BudayaKB: Extraction of Cultural Heritage Entities from Heterogeneous Formats},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326487},
doi = {10.1145/3326467.3326487},
abstract = {Cultural heritage is the root of national identities, and contributes to tourism, economics, industry, and business. Digital preservation of cultural heritage is therefore crucial, particularly in a form that is easily processable by machines. Available cultural heritage information on Web sources (e.g., Wikipedia) is presented in multiple formats, such as free-form text, lists, and tables. Such formats, however, lack structures and links to other information sources. The provision of cultural heritage information as a knowledge base, that is both structured and linked, would pave new ways for consuming such information. In this paper, we propose an approach to extract entities of cultural heritage from diverse formats (i.e., text, lists, and tables), and to construct a knowledge base of cultural heritage entities, called BudayaKB, using RDF data model that provides an integrated, format-independent view. Our extraction approach follows on the observation that cultural heritage entities are often written down either with common noun descriptors (e.g., Jiwa temple) or hypernym-hyponym sentence patterns (e.g., ... Acehnese traditional weapons such as Rencong...). We evaluate our approach to Indonesian Wikipedia, and achieve a precision of 84% for extracting Indonesian cultural heritage entities. The extracted entities are then imported and linked to the Wikidata KB, allowing greater interoperability of cultural heritage information. BudayaKB is openly available at https://budayakb.cs.ui.ac.id/.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {6},
numpages = {9},
keywords = {Cultural heritage, Entity extraction, Knowledge base},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326492,
author = {Yi, Hongsuk and Bui, Khac-Hoai Nam and Jung, Heejin},
title = {Implementing A Deep Learning Framework for Short Term Traffic Flow Prediction},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326492},
doi = {10.1145/3326467.3326492},
abstract = {Traffic congestion in highway systems has become more serious. Recently, with the development of advanced technologies for intelligent transportation system, many studies focus on proposing new models and algorithms for time series analysis to predict short-term traffic flow. In this paper, we take a comprehensive study in implementing a deep learning framework for the short term traffic flow prediction in highway systems. Specifically, we apply long-short term memory for analyzing data in Gyeongbu Expressway of Korean transportation system. Experiments indicate promising results for predicting short term traffic flow in highway systems.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {7},
numpages = {8},
keywords = {long-short term memory, deep learning, traffic prediction, intelligent transportation system, highway systems},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326470,
author = {Wu, Hsin-Te and Zhan, Jun-Wei},
title = {A Clicks-and-Mortar Information Exchange Mechanism Based on Blockchain Technology},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326470},
doi = {10.1145/3326467.3326470},
abstract = {Nowadays, e-commerce has made its official way into the clicks-and-mortar era. The advantage of the clicks-and-mortar strategy is that it enjoys logistics support from the "mortar" counterpart, which complements any operational inadequacy on the side of the virtual website -- the "clicks" counterpart. In the future, the clicks-and-mortar model can facilitate the merging of different businesses and strategic partnerships that will diversify sales channels as well as client sources. When an Internet brand attempts to establish a physical distribution channel, it must take into consideration three aspects in which physical channels are inferior to the virtual marketplace: (1) issues of lease costs, (2) issues of merchandise inventory, and (3) issues of product profit. Among all, the most concerning issue is the inability to keep real-time tabs of sales conditions, which can lead to slow-moving inventory sitting on shelves of physical stores, accumulating dead stocks. The price of a merchandise may differ at a physical store and at the virtual marketplace; moreover, the two channels have different schedules and paces in updating products and hosting sales events, creating an information discrepancy between the physical store and the virtual store, which leads to price competition and client source competition between the physical store and the virtual store.This study utilizes blockchain technology to establish a clicks-and-mortar information exchange mechanism. The blockchain technology can be used to authenticate information accuracy and security, which can facilitate information integration between different information platforms of vendors. Meanwhile, in order to enhance the blockchain's security, dark web technology must be employed to elevate the security of the blockchains. Clicks-and-mortar requires not only market integration but also the formation of alliance or merging between different vendors. This study applied the concept of "group" to our blockchain mechanism so that e-commerce vendors of the same alliance can access each other's data, thereby facilitating the strategy of diversifying commerce. The study also conducted performance analysis and security analysis of our proposed mechanism, and the results confirm that our proposed method is indeed feasible.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {8},
numpages = {5},
keywords = {Circular Economy, BlockChain, Click-and-Mortar, Smart Contract},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326479,
author = {Han, Jongbeen and Kim, Heemin and Eom, Hyeonsang and Coignard, Jonathan and Wu, Kesheng and Son, Yongseok},
title = {Enabling SQL-Query Processing for Ethereum-Based Blockchain Systems},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326479},
doi = {10.1145/3326467.3326479},
abstract = {A blockchain is designed to make consistent and reliable agreement in an unreliable and decentralized environment. It also permits processing transactions, making smart contracts, which allows end users to perform the contracts without any intermediate entities. However, there are some challenges in retrieving the state in a smart contract on the blockchain. For example, an external database or user-defined data structures can be used to retrieve the data from a smart contract in a range, which can increase the management overhead and decrease the overall performance of the blockchain system. In this paper, we propose a scheme that enables SQL query operations in a blockchain system. In our proposed scheme, the register and query managers provide fast retrieval of range data without any user-defined data structure, and management at low cost without any external database, respectively. We have implemented our scheme on quorum which is an Ethereum-based blockchain system and evaluated it using a synthetic benchmark. The experimental results show that our system can improve the search performance up to about 22x compared with the existing system with low memory usage.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {9},
numpages = {7},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326471,
author = {Capistrano, Jose Lorenzo C. and Suarez, Jessie James P. and Naval, Prospero C.},
title = {SALSA: Detection of Cybertrolls Using Sentiment, Aggression, Lexical and Syntactic Analysis of Tweets},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326471},
doi = {10.1145/3326467.3326471},
abstract = {Trolls designed to create discord, chaos, and misinformation have been on the rise lately because of the heightened anonymity provided by the internet. Current methods of troll detection focus on identifying whether a user is a troll are based on various features outside a single instance of a post. We explore the possibility of using sentiment, aggression, lexical, and syntactic textual features to determine whether a tweet is meant to troll or not. From experiments and analysis, it was shown that these textual features are indeed sufficient for a classifier to perform well in detecting whether or not a tweet was meant to troll. Furthermore, we also show how these features are relevant for troll detection and how certain ways to combine these features can improve performance in terms of accuracy, precision, recall and F1 score.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {10},
numpages = {6},
keywords = {social media, natural language processing, text analysis, troll detection},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326481,
author = {Liu, Kwei-guu and Liu, Jyi-Shane},
title = {Social Event Magnitudes via Background Influences and Engagement Capacities and Its Applications},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326481},
doi = {10.1145/3326467.3326481},
abstract = {Outbreaks of social events can be viewed from two angles: anomalous changes of information or popular actions. Event detection algorithms focus on the former one, while the later one is measured by social event intensity, which is a rate to show how popular an action is in a social network at a given time. The rate is relatively intuitive and can give a holistic view about activity levels in a network, but its estimation isn't easy. Inspired by event detection algorithms, this study proposes an alternative measure, social event magnitude, by using the product of background influence and cooperation value. Background influence is extracted via non-backtracking matrices, and cooperation value is obtained via engagement capacities. This alternative measure does not just integrate multisource information, but also gives a holistic view about activity levels in a network. Social event magnitudes follow a long-tailed distribution; they can be visualized for changing activities and can be applied to online event detections.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {11},
numpages = {12},
keywords = {Spectral Algorithms, Non-Backtracking Matrix, Online Event Detection, Engagement Capacities},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326476,
author = {Male\v{c}ek, Ladislav and Balcar, \v{S}t\v{e}p\'{a}n and Pe\v{s}ka, Ladislav},
title = {LODBookRec: Linked Open Data for Books Recommendation},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326476},
doi = {10.1145/3326467.3326476},
abstract = {In this paper, we present the LODBookRec application. LODBookRec builds on top of Linked Open Data (LOD) knowledge about literature domain and provides information retrieval GUI to conveniently present this knowledge to the end users. As such, LODBookRec aims to contribute towards better utilization of LOD and provide a suitable platform for on-line evaluation of information retrieval methods, especially recommender systems. LODBookRec contains a basic search GUI and several recommendation methods, with the primary focus on item-based recommendations.The results of offline evaluation indicates that content-based recommendations utilizing attribute-based similarity of books provides best item-based recommendations w.r.t. recommendation relevance for both highly popular books as well as long-tail books. However, modification of the original algorithm via maximal margin relevance increases diversity of the recommended lists with a modest relevance penalties.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {12},
numpages = {6},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326477,
author = {Georgiou, Michalis and Tachmazidis, Ilias and Antoniou, Grigoris},
title = {Hypercat JSON-LD: A Semantically Enriched Catalogue Format for IoT},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326477},
doi = {10.1145/3326467.3326477},
abstract = {The rapidly increasing number of sensor networks and smart devices contributed to the generation of a huge amount of information. Information that is generated by various sources and is published in different formats high-lights interoperability as one of the key prerequisites for the success of the Internet of Things (IoT). Hypercat is a specification defining a lightweight JSON-based hypermedia catalogue, designed to serve the needs of the industry. In this paper, we extend the existing work on semantic enrichment of Hypercat by defining a JSON-LD based catalogue. The proposed JSON-LD specification provides a mapping mechanism between JSON and JSON-LD catalogues, while highlighting the fact that JSON-LD could be seamlessly adopted by the Hypercat community.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {13},
numpages = {12},
keywords = {Hypercat, Internet of things, JSON-LD, Linked Data, Semantic Web, Semantic Search},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326488,
author = {Yukselen, Murat and Mutlu, Alev and Karagoz, Pinar},
title = {Infuencee Oriented Topic Prediction: Investigating the Effect of Influence on the Author},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326488},
doi = {10.1145/3326467.3326488},
abstract = {In this paper, we study the problem of topic adoption prediction for an author within a social academic network. The previous efforts on the problem use topic similarity and topic adoption of co-authors. We model the problem with an influence detection point of view, and propose that the influence on the author is an important factor. Hence, we define a novel influencee prediction based feature. To this aim, in this work, an algorithm is proposed to calculate the influence propagated towards the author. The effect of this feature is explored together with and in comparison to other features used in the literature for the problem. The experiments conducted on Arnet Miner data set show that accumulated influence on author is effective for predicting topic adoption.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {14},
numpages = {9},
keywords = {information flow, link prediction, social networks},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326485,
author = {Lee, O-Joun and Jung, Jason J.},
title = {Character Network Embedding-Based Plot Structure Discovery in Narrative Multimedia},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326485},
doi = {10.1145/3326467.3326485},
abstract = {This study aims to discover plot structures of narrative multimedia (i.e., creative works that contain stories and are distributed through multimedia). Although a few studies have been conducted to extract subplots from narrative works based on occurrences of characters, the subplots do not always have distinctive compositions of characters. Therefore, we propose a method for discriminating the subplots based on overall social relationships among characters. To understand ways how a story is interwoven with subplots, it is important to describe how story lines in each subplot are developed and how subplots are split and rearranged. As a first step, we propose a measurement for estimating rapidity of story development based on changes in the social relationships among characters. Subsequently, we suggest a model for representing plot structures based on transitions among subplots, the narrative significance of each scene, and the main characters of each subplot. We anticipate that the plot structures can be applied for summarizing narrative multimedia regarding the story.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {15},
numpages = {9},
keywords = {Story Analytics, Computational Narrative, Plot Structure Discovery, Character Network},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326474,
author = {Lu, Pei-Hsuan and Wang, Pang-Chieh and Yu, Chia-Mu},
title = {Empirical Evaluation on Synthetic Data Generation with Generative Adversarial Network},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326474},
doi = {10.1145/3326467.3326474},
abstract = {Data release has been proven to be impactful in scientific research and business innovation. Nevertheless, the valuable data often contains personal information so that the data release also leads to privacy leakage. Releasing a synthetic data may be a solution for the problem of private data release. In this paper, we consider a generative adversarial networks (GAN)-based synthetic data generation. Furthermore, we perform extensive experiments to evaluate the data utility and risk of re-identification of our GAN-based solution.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {16},
numpages = {6},
keywords = {generative adversarial nework, data release, synthetic dataset},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326480,
author = {Lehmberg, Oliver and Bizer, Christian},
title = {Synthesizing N-Ary Relations from Web Tables},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326480},
doi = {10.1145/3326467.3326480},
abstract = {The Web contains a large number of relational HTML tables, which cover a multitude of different, often very specific topics. This rich pool of data has motivated a growing body of research on methods that use web table data to extend local tables with additional attributes or add missing facts to knowledge bases. Nearly all existing approaches for these tasks are limited to the extraction of binary relations from web tables, e.g. an unemployment number may only depend on the state. Inspecting randomly chosen tables on the Web quickly reveals that many relations in the tables are non-binary, e.g. unemployment numbers also depend on the point in time and the profession. Treating such n-ary relations as binary leads to data that cannot be interpreted correctly. The extraction of n-ary relations from web tables is complicated by two factors: 1. important attributes might be stated outside of the table; 2. relational web tables are usually too small for functional dependency discovery. This paper presents a method to synthesize n-ary relations from web tables for the use case of knowledge base extension. The method exploits information from the page around the table and stitches (combines) multiple tables from the same website. We apply the method to a corpus of 5 million web tables originating from 80 thousand different web sites and find that 38% of the synthesized relations are non-binary. We find different relations for the same dependent attribute, e.g. relations providing unemployment numbers based on time, location, or profession. By identifying groups of websites which provide these relations, we lay the foundation for applications in knowledge base augmentation and data search, which allow for a specific selection of relations that determine an attribute according to the applications' data requirements.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {17},
numpages = {12},
keywords = {Web Tables, Schema Extension, Schema Matching},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326475,
author = {Huynh, Tai and Zelinka, Ivan and Pham, Xuan Hau and Nguyen, Hien D.},
title = {Some Measures to Detect the Influencer on Social Network Based on Information Propagation},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326475},
doi = {10.1145/3326467.3326475},
abstract = {Determining the influencer for a brand plays an important role in the influence marketing. The influencer makes a brand approaching goal customers easily and quickly. There are many current methods to measure the influence of a user. In this paper, a model for representing a social network is presented. It includes two main objects: users and tags. This model can represent relationship between these objects clearly. Besides that, some influence measures are proposed. They represent the ability of the influence on other people by relationships between users and the concern to user's tags, as well as the speed of the user's tag propagation on the social network. Based on them, the problem about determining the influencer of a specific brand on a social network is solved. Our method is tested in practice and gets some positive results.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {18},
numpages = {6},
keywords = {Social pulse, Influencer, Information propagation, Centrality measure, Key Opinion Leaders},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326489,
author = {Sejwal, Vineet Kumar and Abulaish, Muhammad},
title = {Context-Based Rating Prediction Using Collaborative Filtering and Linked Open Data},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326489},
doi = {10.1145/3326467.3326489},
abstract = {Linked Open Data (LOD) consists of various knowledgebases, such as DBpedia, Yago, and Freebase, and uses structured data as features to conceptualize a domain of interest. During last few years, many researchers have shown how LOD can be utilized in various applications, including recommender systems that are used to map items and users generally on the basis of interest and similarity parameters. However, contextual features play an important role to improve the effectiveness of the recommender systems. In this paper, we propose a contextual feature-based rating prediction and recommendation technique using item-based collaborative filtering and LOD. To this end, we have generated a RDF graph representing items and their contextual features, which help to determine context-based similar items for recommendation using graph matching techniques. In order to extract contextual features for item profiling, we have used LOD and two famous movie data sources, Rotten Tomatoes and IMDB. We also propose a rating prediction model to predict the rating of the non-rated items with the help of the RDF graph and item-based collaborative filtering. The proposed approach is evaluated using mean absolute error and root mean square error, and performs significantly better in comparison to some of the standard baseline methods.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {19},
numpages = {9},
keywords = {RDF Graph, Context-Based Similarity, Collaborative Filtering, Linked Open Data, Recommender System},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326491,
author = {Sejwal, Vineet Kumar and Abulaish, Muhammad},
title = {Trust and Context-Based Rating Prediction Using Collaborative Filtering: A Hybrid Approach},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326491},
doi = {10.1145/3326467.3326491},
abstract = {In order to tackle the problem of information overload and effective recommendation based on users' preference, need, and interest a number of research contributions has been made for the development of recommender systems. However, certain challenges, such as data sparsity, profiling attack, and black-box recommendation still exist and hamper their prediction accuracy. In this paper, we propose a hybrid approach to predict user ratings by incorporating both trust and context of the users in traditional recommender systems using collaborative filtering method. The similarity between two users is computed using both trust value and context-based similarity. The trust value is based on three trust statements -- rating deviation, emotions, and reviews helpfulness. On the other hand, context-based similarity is based on four contextual features -- companion, place, day, and priority. The performance of the proposed trust- and context-based hybrid approach is analyzed using mean absolute error and root mean square error on a real dataset generated from two movie data sources (IMDB and Rotten Tomatoes), and it performs significantly better in comparison to some of the standard baseline methods. The rating prediction using only trust statements gives better results in comparison to other collaborative filtering approaches, such as user-based and item-based filtering approaches. Similarly, context-based collaborative filtering approach also outperforms standard collaborative filtering approaches. In addition, rating prediction using both trust- and context-based features performs better in comparison to only trust-based or context-based approaches.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {20},
numpages = {10},
keywords = {Trust-based recommendation, Collaborative filtering, Recommender system, Context-based recommendation, Trust network},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326482,
author = {Chang, Yu-Chia and Chen, Huan and Tsai, Chun-Wei},
title = {An Effective Deep Learning Framework for Detecting Misconduct of the Trucker},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326482},
doi = {10.1145/3326467.3326482},
abstract = {The traffic risks include malfunction of gears in the vehicle and some human misconducts while on the road. These misconducts of driver contain using the mobile phone, smoking, watching videos, reading books, and so forth. To prevent drivers from danger, in this paper, we will present an effective system to detect whether the drivers are doing those behaviors while driving by using the deep learning technologies. The proposed system adopts two different neural network architectures to improve its accuracy rate that are multilayer perceptron (MLP) and convolutional neural network (CNN). As expected, by training the video data from cameras installed in the truck, the proposed system could possibly distinguish the misconduct if the drivers are doing danger behaviors. The result of this paper shows that the proposed system practically provides a solution to recognize misconducts of the trucker with 90% accuracy of detecting abnormal situations.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {21},
numpages = {8},
keywords = {Deep learning, convolutional neural network, and traffic, multilayer perceptron},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326478,
author = {Lu, Yung-Feng and Xu, Jia-Lang and Chen, Mu-Yen},
title = {Using Text Mining to Analyze the Financial Patents},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326478},
doi = {10.1145/3326467.3326478},
abstract = {With the advancement and development of science and technology, Nowadays society is the development of information technology, cloud computing, mobile Internet, Internet of Things, block chain and information technology.The combination of finance and technology has made financial technology terms gradually emerging.. This research analyzes the patents of financial technology. However, Taiwan's financial technology patents are mostly G06Q-20 (payment plan, architecture or agreement), G06Q-30 (commercial, such as marketing, shopping, payment, auction or e-commerce). G06Q-40 (financial, investment or tax treatment, insurance).The research use text mining technology to analyze and understand Taiwan's trends and developments in financial technology. The research results show that G06Q-20 patents are biased towards information security and mobile payment. G06Q-30 patents favor shopping websites and advertising. G06Q-40 patents are biased towards diversity, such as securities, insurance, finance, and stocks.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {22},
numpages = {7},
keywords = {FinTech, Patent analysis, Text mining},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326483,
author = {Kastrati, Zenun and Imran, Ali Shariq and Kurti, Arianit},
title = {Transfer Learning to Timed Text Based Video Classification Using CNN},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326483},
doi = {10.1145/3326467.3326483},
abstract = {Open educational video resources are gaining popularity with a growing number of massive open online courses (MOOCs). This has created a niche for content providers to adopt effective solutions in automatically organizing and structuring of educational resources for maximum visibility. Recent advances in deep learning techniques are proving useful in managing and classifying resources into appropriate categories. This paper proposes one such convolutional neural network (CNN) model for classifying video lectures in a MOOC setting using a transfer learning approach. The model uses a time-aligned text transcripts corresponding to video lectures from six broader subject categories. Video lectures and their corresponding transcript dataset is gathered from the Coursera MOOC platform. Two different CNN models are proposed: i) CNN based classification using embeddings learned from our MOOC dataset, ii) CNN based classification using transfer learning. Word embeddings generated from two well known state-of-the-art pre-trained models Word2Vec and GloVe, are used in the transfer learning approach for the second case.The proposed CNN models are evaluated using precision, recall, and F1 score and the obtained performance is compared with both conventional and deep learning classifiers. The proposed CNN models have an F1 score improvement of 10-22 percentage points over DNN and conventional classifiers},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {23},
numpages = {9},
keywords = {Video Classification, Embedding, Machine Learning, DNN, Transfer Learning, MOOC, CNN},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326473,
author = {Koukopoulos, Zois and Koukopoulos, Dimitrios and Jung, Jason J.},
title = {Sustainability Services for Public Libraries within a Smart City Environment},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326473},
doi = {10.1145/3326467.3326473},
abstract = {Nowadays, public libraries should take the necessary initiatives in order to establish their position as the knowledge centers of modern smart cities. Facing a fierce competition from other knowledge sources like the Internet, public libraries should find alternative ways to reach new audiences among the citizens of a smart city. The offering of interesting, entertaining, engaging and exploitable digital services, along with the proven quality of library resources, could be a way towards that direction. The limited public budgets directed to the public libraries present an additional obstacle for the sustainability of those institutes. A solution to that problem could be the development of new exploitation digital services that a public library would provide to its visitors, individuals or businesses. In this work, we present a prototype digital system that supports the goal of sustainability for a modern public library. The system offers a wide variety of digital services that aim at attracting new audiences of library visitors, engaging them in spending more time within the library and creating new sources of revenue for the institute. The system helps in transforming the library into a social space by allowing visitors to form ad-hoc social networks. Trying to tackle the disadvantage of quantity in digital resources, the system supports the procedure of digitization of the library's physical resources through a participatory endeavor that involves the audience of library visitors under the supervision of library's personnel. We conducted a first evaluation of the proposed system by comparing it with three other digital systems, which operate in public libraries around the world with positive results.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {24},
numpages = {12},
keywords = {Public libraries, participatory digitization procedure, smart city, social spaces},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326472,
author = {Lin, Zuoquan and Chen, Hanxuan},
title = {A Probabilistic Model for Collaborative Filtering},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326472},
doi = {10.1145/3326467.3326472},
abstract = {We propose a probabilistic model that uses the early data to generate the prior distribution and the recent data to capture the change of the states of both users and items in collaborative filtering system. It keeps updating every time it receives new data and has a constant limit of the time cost of every updating, which is suitable to deal with large scale data for online recommendation. Experiments on real datasets show the improvement performance of our model over the existing time-aware recommender systems.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {25},
numpages = {8},
keywords = {hidden Markov model, recommender system, collaborative filtering},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326493,
author = {Ahmed, Hammad and Mun, Jonghyeok and Park, Yoosang and Choi, Jongsun},
title = {A Schema Generator for Collected Data from Wearable Devices for Reliable Data Ingestion},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326493},
doi = {10.1145/3326467.3326493},
abstract = {We are living in an era, where we have smart devices all around us, like smart phones, smart watches, and other devices. Data produced by these devices has a great importance, used either for providing services or for analyzing purpose. These devices produce data in large amount, with many different formats, which makes data ingestion a very challenging task, as this massive amount of data causes a tremendous problem in both structuring and storage of data. Furthermore, due to the different formats and unpredictable nature of devices, data validation is also required. Although, there are many different data ingestion tools available which serves the purpose of structuring the data, but validation of data is still a big challenge. Therefore, we proposed a Schema Generator which aims to auto generate a schema of the input file for a new device added to the system, and validates this schema against the input file using available ingestion tool. Additionally, the idea is to provide a user interface for creating a configuration file for ingestion tool, as creating it manually is a very strenuous process for new device data.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {26},
numpages = {4},
keywords = {big data, Data ingestion tools, IoT devices, wearable devices},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326494,
author = {Kim, Jeong Hee and Bae, Kitae and Hong, Jong Youl},
title = {Consumption Value System and Storytelling for Digital Advertising},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326494},
doi = {10.1145/3326467.3326494},
abstract = {Storytelling can be used in various ways in business. Storytelling marketing emphasizes a unique story and mythical meaning of the product, rather than its practical function. In this article, we will analyze various consumption values in a case study of coffee advertisement. In particular, advertising that appeals to utopian values will be analyzed and its actual impact will be discussed. If we communicate utopian values to consumers through various stories, business effects will be maximized, which will strengthen the brand image. The contribution of this study is that it relates the theory of consumption value system to the concept of storytelling. Therefore, we will draw conclusions about for the ways in which storytelling can be effectively used in advertising.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {27},
numpages = {4},
keywords = {Digital Advertising, Emotional Marketing, Storytelling, Consumption Value System},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326495,
author = {Hong, Jong Youl and Ko, Hoon and Kim, Jeong Hee},
title = {Cultural Intelligence and ARCS Model for Digital Era},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326495},
doi = {10.1145/3326467.3326495},
abstract = {The main aim of this study is to explore the theoretical foundations necessary for the development of cross-cultural training programs by integrating the ARCS motivation model into the cultural intelligence model to strengthen the motivation of the participants. Firstly, the cultural intelligence self-test, which can be directly applied to the cross-cultural training program, has been newly designed and presented based on a comprehensive analysis of the available research results. Furthermore, the ARCS model was introduced to the cultural intelligence learning process to suggest the ways to enhance the learning effect. In the design of cultural intelligence training programs, it is expected to be a more effective process by actively using the pedagogical research achievements called the ARCS model.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {28},
numpages = {4},
keywords = {Cultural Intelligence, Cross-Cultural Training, ARCS Model, Digital Era},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

@inproceedings{10.1145/3326467.3326496,
author = {Choi, Junho and Choi, Chang and Kim, SungHwan and Ko, Hoon},
title = {Medical Information Protection Frameworks for Smart Healthcare Based on IoT},
year = {2019},
isbn = {9781450361903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326467.3326496},
doi = {10.1145/3326467.3326496},
abstract = {The smart healthcare area is expanding its application to telemedicine, mobile health, EHR/EMR/PHR, wireless medical services, and precision medicine through a combination of Internet of Things (IoT) technologies. In the IoT environment, it is difficult to actively control packets and traffic using existing network technologies because multiple devices and sensors create different types of packets and cause variable traffic. Furthermore, it is difficult to apply various existing security technologies in the IoT environment because various services are provided using low-end sensor devices with limited performances. This study presented here aims to construct an IoT-based smart healthcare service security model. The security requirements for IoT environments are summarized while a framework for designing security areas for IoT services is proposed and applied to smart healthcare services. For this purpose, a medical information protection framework was designed to provide authentication, access control, network and system security, integrity, and confidentiality by investigating the characteristics of the smart healthcare environment.},
booktitle = {Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics},
articleno = {29},
numpages = {5},
keywords = {Medical Information System, Smart Healthcare, IoT Security},
location = {Seoul, Republic of Korea},
series = {WIMS2019}
}

