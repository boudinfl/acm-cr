@inproceedings{10.1145/3260180,
author = {Lee, Doheon},
title = {Session Details: Keynote Address},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3260180},
doi = {10.1145/3260180},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
numpages = {1},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390070,
author = {Kang, Chiyong and Yu, Hyeji and Yi, Gwan-Su},
title = {Detecting Type 2 Diabetes Causal Single Nucleotide Polymorphism Combinations from a Genome-Wide Association Study Dataset with Optimal Filtration},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390070},
doi = {10.1145/2390068.2390070},
abstract = {The identification of causal single nucleotide polymorphisms (SNPs) for complex diseases like type 2 diabetes (T2D) is a challenge because of the low statistical power of individual markers from a genome-wide association study (GWAS). SNP combinations are suggested to compensate for the low statistical power of individual markers, but SNP combinations from GWAS generate high computational complexity. Hence, we aim to detect T2D causal SNP combinations from a GWAS dataset with optimal filtration and to discover the biological meaning of the detected SNP combinations. Optimal filtration can enhance the statistical power of SNP combinations by comparing the error rates of SNP combinations from various Bonferroni thresholds and p-value range-based thresholds combined with linkage disequilibrium (LD) pruning. T2D causal SNP combinations are selected using random forests with variable selection from an optimal SNP dataset. The selected SNPs with SNP combinations are mapped with multi-dimensional levels of T2D-related information and gene set enrichment analysis (GSEA). A T2D causal SNP combination containing 101 SNPs from the Wellcome Trust Case Control Consortium (WTCCC) GWAS dataset are selected, with an error rate of 10.25%. Matching with known disease genes and gene sets revealed the relationships between T2D and SNP combinations. We propose a detection method for complex disease causal SNP combinations from an optimal SNP dataset by using random forests with variable selection. Mapping the biological meanings of detected SNP combinations can help uncover complex disease mechanisms.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {1–8},
numpages = {8},
keywords = {gsea, snp combination, snp, type 2 diabetes, random forests, gwas},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/3260181,
author = {Xu, Hua},
title = {Session Details: Mining Clinical Data and Text},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3260181},
doi = {10.1145/3260181},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
numpages = {1},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390072,
author = {Malyszko, Jacek and Filipowska, Agata},
title = {Lexicon-Free and Context-Free Drug Names Identification Methods Using Hidden Markov Models and Pointwise Mutual Information},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390072},
doi = {10.1145/2390068.2390072},
abstract = {The paper concerns the issue of extraction of medicine names from free text documents written in Polish. Using lexicon-based approaches, it is impossible to identify unknown or misspelled medicine names. In this paper, we present the results of experimentation on two methods: Hidden Markov Model (HMM) and Pointwise Mutual Information (PMI)-based approach. The experiment was to identify the medicine names without the use of lexicon or contextual information. The experimentation results show, that HMM may be used as one of several steps in drug names' identification (with F-score slightly below 70% for the test set), while the PMI can help in increasing the precision of results achieved using HMM, but with significant loss in recall.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {9–12},
numpages = {4},
keywords = {hidden markov models, pointwise mutual information, named entity recognition},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390073,
author = {Tang, Buzhou and Cao, Hongxin and Wu, Yonghui and Jiang, Min and Xu, Hua},
title = {Clinical Entity Recognition Using Structural Support Vector Machines with Rich Features},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390073},
doi = {10.1145/2390068.2390073},
abstract = {Named entity recognition (NER) is an important task for natural language processing (NLP) of clinical text. Conditional Random Fields (CRFs), a sequential labeling algorithm, and Support Vector Machines (SVMs), which is based on large margin theory, are two typical machine learning algorithms that have been widely applied to NER tasks, including clinical entity recognition. However, Structural Support Vector Machines (SSVMs), an algorithm that combines the advantages of both CRFs and SVMs, has not been investigated for clinical text processing. In this study, we applied the SSVMs algorithm to the Concept Extraction task of the 2010 i2b2 clinical NLP challenge, which was to recognize entities of medical problems, treatments, and tests from hospital discharge summaries. Using the same training (N = 27,837) and test (N = 45,009) sets in the challenge, our evaluation showed that the SSVMs-based NER system required less training time, while achieved better performance than the CRFs-based system for clinical entity recognition, when same features were used. Our study also demonstrated that rich features such as unsupervised word representations improved the performance of clinical entity recognition. When rich features were integrated with SSVMs, our system achieved a highest F-measure of 85.74% on the test set of 2010 i2b2 NLP challenge, which outperformed the best system reported in the challenge by 0.5%.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {13–20},
numpages = {8},
keywords = {support vector machines, named entity recognition, conditional random fields, structural support vector machines, natural language processing},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390074,
author = {Restificar, Angelo and Ananiadou, Sophia},
title = {Inferring Appropriate Eligibility Criteria in Clinical Trial Protocols without Labeled Data},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390074},
doi = {10.1145/2390068.2390074},
abstract = {We consider the user task of designing clinical trial protocols and propose a method that outputs the most appropriate eligibility criteria from a potentially huge set of candidates. Each document d in our collection D is a clinical trial protocol which itself contains a set of eligibility criteria. Given a small set of sample documents D', |D'|«|D|, a user has initially identified as relevant e.g., via a user query interface, our scoring method automatically suggests eligibility criteria from D by ranking them according to how appropriate they are to the clinical trial protocol currently being designed. We view a document as a mixture of latent topics and our method exploits this by applying a three-step procedure. First, we infer the latent topics in the sample documents using Latent Dirichlet Allocation (LDA) [3]. Next, we use logistic regression models to compute the probability that a given candidate criterion belongs to a particular topic. Lastly, we score each criterion by computing its expected value, the probability-weighted sum of the topic proportions inferred from the set of sample documents. Intuitively, the greater the probability that a candidate criterion belongs to the topics that are dominant in the samples, the higher its expected value or score. Results from our experiments indicate that our proposed method is 8 and 9 times better (resp., for inclusion and exclusion criteria) than randomly choosing from a set of candidates obtained from relevant documents. In user simulation experiments, we were able to automatically construct eligibility criteria that are on the average 75% and 70% (resp., for inclusion and exclusion criteria) similar to the correct eligibility criteria.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {21–28},
numpages = {8},
keywords = {clinical trials, eligibility criteria, unsupervised machine learning},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390075,
author = {Rao, Ashwani and Maiden, Kristin and Carterette, Ben and Ehrenthal, Deb},
title = {Predicting Baby Feeding Method from Unstructured Electronic Health Record Data},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390075},
doi = {10.1145/2390068.2390075},
abstract = {Obesity is one of the most important health concerns in United States and is playing an important role in rising rates of chronic health conditions and health care costs. The percentage of the US population affected with childhood obesity and adult obesity has been on a constant upward linear trend for past few decades. According to Center for Disease control and prevention 35.7% of US adults are obese and 17% of children aged 2-19 years are obese. Researchers and health care providers in the US and the rest of world studying obesity are interested in factors affecting obesity. One such interesting factor potentially related to development of obesity is type of feeding provided to babies. In this work we describe an electronic health record (EHR) data set of babies with feeding method contained in the narrative portion of the record. We compare five supervised machine learning algorithms for predicting feeding method as a discrete value based on text in the field. We also compare these algorithms in terms of the classification error and prediction probability estimates generated by them.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {29–34},
numpages = {6},
keywords = {classification, electronic health record, supervised machine learning, text mining},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390076,
author = {MacKinlay, Andrew D. and Verspoor, Karin M.},
title = {Extracting Structured Information from Free-Text Medication Prescriptions Using Dependencies},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390076},
doi = {10.1145/2390068.2390076},
abstract = {We explore an information extraction task where the goal is to determine the correct values for fields which are relevant to prescription drug administration such as dosage amount, frequency and route. The data set is a collection of prescriptions from a long-term health-care facility, a small subset of which we have manually annotated with values for these fields. We first examine a rule-based approach to the task, which uses a dependency parse of the prescription, achieving accuracies of 60-95% over various different fields, and 67.5% when all fields of the prescription are considered together. The outputs of such a system have potential applications in detecting irregularities in dosage delivery.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {35–40},
numpages = {6},
keywords = {medical prescriptions, electronic medical records, information extraction},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/3260182,
author = {Song, Min},
title = {Session Details: Mining Biological Data and Text},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3260182},
doi = {10.1145/3260182},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
numpages = {1},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390078,
author = {Kim, Sungchul and Lee, Sael and Yu, Hwanjo},
title = {Indexing Methods for Efficient Protein 3D Surface Search},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390078},
doi = {10.1145/2390068.2390078},
abstract = {This paper exploits efficient indexing techniques for protein structure search where protein structures are represented as vectors by 3D-Zernike Descriptor (3DZD). 3DZD compactly represents a surface shape of protein tertiary structure as a vector, and the simplified representation accelerates the structural search. However, further speed up is needed to address the scenarios where multiple users access the database simultaneously. We address this need for further speed up in protein structural search by exploiting two indexing techniques, i.e., iDistance and iKernel, on the 3DZDs. The results show that both iDistance and iKernel significantly enhance the searching speed. In addition, we introduce an extended approach for protein structure search based on indexing techniques that use the 3DZD characteristic. In the extended approach, index structure is constructured using only the first few of the numbers in the 3DZDs. To find the top-k similar structures, first top-10 x k similar structures are selected using the reduced index structure, then top-k structures are selected using similarity measure of full 3DZDs of the selected structures. Using the indexing techniques, the searching time reduced 69.6% using iDistance, 77% using iKernel, 77.4% using extended iDistance, and 87.9% using extended iKernel method.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {41–48},
numpages = {8},
keywords = {protein surface shape, database search, protein structure classification, 3d zernike descriptor, structure similarity},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390079,
author = {Ahn, Jaegyoon and Lee, Dae Hyun and Yoon, Youngmi and Yeu, Yunku and Park, Sanghyun},
title = {Protein Complex Prediction via Bottleneck-Based Graph Partitioning},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390079},
doi = {10.1145/2390068.2390079},
abstract = {Detecting protein complexes is one of essential and fundamental tasks in understanding various biological functions or processes. Therefore, precise identification of protein complexes is indispensible. For more precise detection of protein complexes, we propose a novel data structure which employs bottleneck proteins as partitioning points for detecting the protein complexes. The partitioning process allows overlapping between resulting protein complexes. We applied our algorithm to several PPI (Protein-Protein Interaction) networks of Saccharomyces cerevisiae and Homo sapiens, and validated our results using public databases of protein complexes. Our algorithm resulted in overlapping protein complexes with significantly improved F1 score, which comes from higher precision.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {49–56},
numpages = {8},
keywords = {bottleneck protein, protein-protein interaction, protein complex detection, network clustering},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390080,
author = {Kugaonkar, Rohit and Gangopadhyay, Aryya and Yesha, Yelena and Joshi, Anupam and Yesha, Yaacov and Grasso, Michael and Brady, Mary and Rishe, Napthali},
title = {Finding Associations among SNPS for Prostate Cancer Using Collaborative Filtering},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390080},
doi = {10.1145/2390068.2390080},
abstract = {Prostate cancer is the second leading cause of cancer related deaths among men. Because of the slow growing nature of prostate cancer, sometimes surgical treatment is not required for less aggressive cancers. Recent debates over prostate-specific antigen (PSA) screening have drawn new attention to prostate cancer. Genome-based screening can potentially help in assessing the risk of developing prostate cancer. Due to the complicated nature of prostate cancer, studying the entire genome is essential to find genomic traits. Due to the high cost of studying all Single Nucleotide Polymorphisms (SNPs), it is essential to find tag SNPs which can represent other SNPs. Earlier methods to find tag SNPs using associations between SNPs either use SNP's location information or are based on data of very few SNP markers in each sample. Our study is based on 2300 samples with 550,000 SNPs each. We have not used SNP location information or any predefined standard cut-offs to find tag SNPs. Our approach is based on using collaborative filtering methods to find pairwise associations among SNPs and thus list top-N tag SNPs. We have found 25 tag SNPs which have highest similarities to other SNPs. In addition we found 16 more SNPs which have high correlation with the known high risk SNPs that are associated with prostate cancer. We used some of these newly found SNPs with 5 different classification algorithms and observed some improvement in prostate cancer prediction accuracy over using the original known high risk SNPs.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {57–60},
numpages = {4},
keywords = {snp, tag snps, snp association, collaborative filtering, prostate cancer},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390081,
author = {Choi, Jaejoon and Kim, Kwangmin and Song, Min and Lee, Doheon},
title = {TNMCA: Generation and Application of Network Motif Based Inference Models for Drug Repositioning},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390081},
doi = {10.1145/2390068.2390081},
abstract = {Since the increase of the public biomedical data, Undiscovered Public Knowledge (UPK, proposed by Swanson) became an important research topic in the biological field. Drug repositioning is one of famous UPK tasks which infer alternative indications for approved drugs. Many researchers tried to find novel candidates of existing drugs, but these previous works are not fully automated which required manual modulations to desired tasks, and was not able to cover various biomedical entities. In addition, they had inference limitations that those works could infer only pre-defined cases using limited patterns. In this paper, we propose the Typed Network Motif Comparison Algorithm (TNMCA) to discover novel drug indications using topological patterns of data. Typed network motifs (TNM) are connected sub-graphs of data, which store types of data, instead of values of data. While previous researches depends on ABC model (or extension of it), TNMCA utilizes more generalized patterns as its inference models. Also, TNMCA can infer not only an existence of interaction, but also the type of the interaction. TNMCA is suited for multi-level biomedical interaction data as TNMs depend on the different types of entities and relations. We apply TNMCA to a public database, Comparative Toxicogenomics Database (CTD), to validate our method. The results show that TNMCA could infer meaningful indications with high performance (AUC=0.7469) compared to the ABC model (AUC=0.7050).},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {61–68},
numpages = {8},
keywords = {undiscovered public knowledge (upk), multi-type interaction networks, typed network motif, inference model, drug repositioning, typed network motif comparison algorithm (tnmca), knowledge inference},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390082,
author = {Lee, Junkyu and Kim, Seongsoon and Lee, Sunwon and Lee, Kyubum and Kang, Jaewoo},
title = {High Precision Rule Based PPI Extraction and Per-Pair Basis Performance Evaluation},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390082},
doi = {10.1145/2390068.2390082},
abstract = {Virtually all current PPI extraction studies focus on improving F-score, aiming to balance the performance on both precision and recall. However, in many realistic scenarios involving large corpora, one can benefit more from an extremely high precision PPI extraction tool than a high-recall counterpart. We also argue that the current "per-instance" basis performance evaluation method should be revisited. In order to address these problems, we introduce a new rule-based PPI extraction method equipped with a set of ultra-high precision extraction rules. We also propose a new "per-pair" basis performance metric, which is more pragmatic in practice. The proposed PPI extraction method achieves 95-96% per-pair and 94-97% per-instance precisions on the AIMed benchmark corpus.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {69–76},
numpages = {8},
keywords = {text mining, interaction extraction, entity relation extraction, ppi, biomedical text mining},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

@inproceedings{10.1145/2390068.2390083,
author = {Hwang, Woochang and Hwang, Youngdeuk and Lee, Sunjae and Lee, Doheon},
title = {Rule-Based Whole Body Modeling for Analyzing Multi-Compound Effects},
year = {2012},
isbn = {9781450317160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390068.2390083},
doi = {10.1145/2390068.2390083},
abstract = {Essential reasons including robustness, redundancy, and crosstalk of biological systems, have been reported to explain the limited efficacy and unexpected side-effects of drugs. Many pharmaceutical laboratories have begun to develop multi-compound drugs to remedy this situation, and some of them have shown successful clinical results. Simultaneous application of multiple compounds could increase efficacy as well as reduce side-effects through pharmacodynamics and pharmacokinetic interactions. However, such approach requires overwhelming cost of preclinical experiments and tests as the number of possible combinations of compound dosages increases exponentially. Computer model-based experiments have been emerging as one of the most promising solutions to cope with such complexity. Though there have been many efforts to model specific molecular pathways using qualitative and quantitative formalisms, they suffer from unexpected results caused by distant interactions beyond their localized models.Here we propose a rule-based whole-body modeling platform. We have tested this platform with Type 2 diabetes (T2D) model, which involves the malfunction of numerous organs such as pancreas, circulation system, liver, and muscle. We have extracted T2D-related 117 rules by manual curation from literature and different types of existing models. The results of our simulation show drug effect pathways of T2D drugs and how combination of drugs could work on the whole-body scale. We expect that it would provide the insight for identifying effective combination of drugs and its mechanism for the drug development.},
booktitle = {Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics},
pages = {77–84},
numpages = {8},
keywords = {drug effect, combination drug, rule-based simulation, type 2 diabetes, multi-scale modeling, whole-body simulation},
location = {Maui, Hawaii, USA},
series = {DTMBIO '12}
}

