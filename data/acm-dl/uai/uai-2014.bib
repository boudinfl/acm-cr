@inproceedings{10.5555/3020751.3020753,
author = {Acharyya, Sreangsu and Ghosh, Joydeep},
title = {MEMR: A Margin Equipped Monotone Retargeting Framework for Ranking},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We bring to bear the tools of convexity, margins and the newly proposed technique of monotone retargeting upon the task of learning permutations from examples. This leads to novel and efficient algorithms with guaranteed prediction performance in the online setting and on global optimality and the rate of convergence in the batch setting. Monotone retargeting efficiently optimizes over all possible monotone transformations as well as the finite dimensional parameters of the model. As a result we obtain an effective algorithm to learn transitive relationships over items. It captures the inherent combinatorial characteristics of the output space yet it has a computational burden not much more than that of a generalized linear model.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {2–11},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020754,
author = {Albrecht, Stefano V. and Ramamoorthy, Subramanian},
title = {On Convergence and Optimality of Best-Response Learning with Policy Types in Multiagent Systems},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {While many multiagent algorithms are designed for homogeneous systems (i.e. all agents are identical), there are important applications which require an agent to coordinate its actions without knowing a priori how the other agents behave. One method to make this problem feasible is to assume that the other agents draw their latent policy (or type) from a specific set, and that a domain expert could provide a specification of this set, albeit only a partially correct one. Algorithms have been proposed by several researchers to compute posterior beliefs over such policy libraries, which can then be used to determine optimal actions. In this paper, we provide theoretical guidance on two central design parameters of this method: Firstly, it is important that the user choose a posterior which can learn the true distribution of latent types, as otherwise suboptimal actions may be chosen. We analyse convergence properties of two existing posterior formulations and propose a new posterior which can learn correlated distributions. Secondly, since the types are provided by an expert, they may be inaccurate in the sense that they do not predict the agents' observed actions. We provide a novel characterisation of optimality which allows experts to use efficient model checking algorithms to verify optimality of types.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {12–21},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020755,
author = {Angelino, Elaine and Kohler, Eddie and Waterland, Amos and Seltzer, Margo and Adams, Ryan P.},
title = {Accelerating MCMC via Parallel Predictive Prefetching},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Parallel predictive prefetching is a new framework for accelerating a large class of widely-used Markov chain Monte Carlo (MCMC) algorithms. It speculatively evaluates many potential steps of an MCMC chain in parallel while exploiting fast, iterative approximations to the target density. This can accelerate sampling from target distributions in Bayesian inference problems. Our approach takes advantage of whatever parallel resources are available, but produces results exactly equivalent to standard serial execution. In the initial burn-in phase of chain evaluation, we achieve speedup close to linear in the number of available cores.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {22–31},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020756,
author = {Aravkin, Aleksandr and Becker, Stephen and Cevher, Volkan and Olsen, Peder},
title = {A Variational Approach to Stable Principal Component Pursuit},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce a new convex formulation for stable principal component pursuit (SPCP) to decompose noisy signals into low-rank and sparse representations. For numerical solutions of our SPCP formulation, we first develop a convex variational framework and then accelerate it with quasi-Newton methods. We show, via synthetic and real data experiments, that our approach offers advantages over the classical SPCP formulations in scalability and practical parameter selection.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {32–41},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020757,
author = {Arvaniti, Eirini and Claassen, Manfred},
title = {Markov Network Structure Learning via Ensemble-of-Forests Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Real world systems typically feature a variety of different dependency types and topologies that complicate model selection for probabilistic graphical models. We introduce the ensemble-of-forests model, a generalization of the ensemble-of-trees model of Meil\u{a} and Jaakkola (2006). Our model enables structure learning of Markov random fields (MRF) with multiple connected components and arbitrary potentials. We present two approximate inference techniques for this model and demonstrate their performance on synthetic data. Our results suggest that the ensemble-of-forests approach can accurately recover sparse, possibly disconnected MRF topologies, even in presence of non-Gaussian dependencies and/or low sample size. We applied the ensemble-of-forests model to learn the structure of perturbed signaling networks of immune cells and found that these frequently exhibit non-Gaussian dependencies with disconnected MRF topologies. In summary, we expect that the ensemble-of-forests model will enable MRF structure learning in other high dimensional real world settings that are governed by non-trivial dependencies.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {42–51},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020758,
author = {Bauters, Kim and Liu, Weiru and Hong, Jun and Sierra, Carles and Godo, Llu\'{\i}s},
title = {CAN(PLAN)+: Extending the Operational Semantics of the BDI Architecture to Deal with Uncertain Information},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The BDI architecture, where agents are modelled based on their beliefs, desires and intentions, provides a practical approach to develop large scale systems. However, it is not well suited to model complex Supervisory Control And Data Acquisition (SCADA) systems pervaded by uncertainty. In this paper we address this issue by extending the operational semantics of CAN(PLAN) into CAN(PLAN)+. We start by modelling the beliefs of an agent as a set of epistemic states where each state, possibly using a different representation, models part of the agent's beliefs. These epistemic states are stratified to make them commensurable and to reason about the uncertain beliefs of the agent. The syntax and semantics of a BDI agent are extended accordingly and we identify fragments with computationally efficient semantics. Finally, we examine how primitive actions are affected by uncertainty and we define an appropriate form of lookahead planning.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {52–61},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020759,
author = {Belanger, David and Passos, Alexandre and Riedel, Sebastian and McCallum, Andrew},
title = {Message Passing for Soft Constraint Dual Decomposition},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Dual decomposition provides the opportunity to build complex, yet tractable, structured prediction models using linear constraints to link together submodels that have available MAP inference routines. However, since some constraints might not hold on every single example, such models can often be improved by relaxing the requirement that these constraints always hold, and instead replacing them with soft constraints that merely impose a penalty if violated. A dual objective for the resulting MAP inference problem differs from the hard constraint problem's associated dual decomposition objective only in that the dual variables are subject to box constraints. This paper introduces a novel primal-dual block coordinate descent algorithm for minimizing this general family of box-constrained objectives. Through experiments on two natural language corpus-wide inference tasks, we demonstrate the advantages of our approach over the current alternative, based on copying variables, adding auxiliary submodels and using traditional dual decomposition. Our algorithm performs inference in the same model as was previously published for these tasks, and thus is capable of achieving the same accuracy, but provides a 2-10x speedup over the current state of the art.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {62–71},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020760,
author = {Bhattacharjya, Debarun and Kephart, Jeffrey O.},
title = {Bayesian Interactive Decision Support for Multi-Attribute Problems with Even Swaps},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Even swaps is a method for solving deterministic multi-attribute decision problems where the decision maker iteratively simplifies the problem until the optimal alternative is revealed (Hammond et al. 1998, 1999). We present a new practical decision support system that takes a Bayesian approach to guiding the even swaps process, where the system makes queries based on its beliefs about the decision maker's preferences and updates them as the interactive process unfolds. Through experiments, we show that it is possible to learn enough about the decision maker's preferences to measurably reduce the cognitive burden, i.e. the number and complexity of queries posed by the system.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {72–81},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020761,
author = {Bi, Wei and Wang, Liwei and Kwok, James T. and Tu, Zhuowen},
title = {Learning to Predict from Crowdsourced Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Crowdsourcing services like Amazon's Mechanical Turk have facilitated and greatly expedited the manual labeling process from a large number of human workers. However, spammers are often unavoidable and the crowdsourced labels can be very noisy. In this paper, we explicitly account for four sources for a noisy crowdsourced label: worker's dedication to the task, his/her expertise, his/her default labeling judgement, and sample difficulty. A novel mixture model is employed for worker annotations, which learns a prediction model directly from samples to labels for efficient out-of-sample testing. Experiments on both simulated and real-world crowdsourced data sets show that the proposed method achieves significant improvements over the state-of-the-art.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {82–91},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020762,
author = {Bui, Hung Hai and Huynh, Tuyen N. and Sontag, David},
title = {Lifted Tree-Reweighted Variational Inference},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We analyze variational inference for highly symmetric graphical models such as those arising from first-order probabilistic models. We first show that for these graphical models, the tree-reweighted variational objective lends itself to a compact lifted formulation which can be solved much more efficiently than the standard TRW formulation for the ground graphical model. Compared to earlier work on lifted belief propagation, our formulation leads to a convex optimization problem for lifted marginal inference and provides an upper bound on the partition function. We provide two approaches for improving the lifted TRW upper bound. The first is a method for efficiently computing maximum spanning trees in highly symmetric graphs, which can be used to optimize the TRW edge appearance probabilities. The second is a method for tightening the relaxation of the marginal poly-tope using lifted cycle inequalities and novel exchangeable cluster consistency constraints.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {92–101},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020763,
author = {Campbell, Trevor and How, Jonathan P.},
title = {Approximate Decentralized Bayesian Inference},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper presents an approximate method for performing Bayesian inference in models with conditional independence over a decentralized network of learning agents. The method first employs variational inference on each individual learning agent to generate a local approximate posterior, the agents transmit their local posteriors to other agents in the network, and finally each agent combines its set of received local posteriors. The key insight in this work is that, for many Bayesian models, approximate inference schemes destroy symmetry and dependencies in the model that are crucial to the correct application of Bayes' rule when combining the local posteriors. The proposed method addresses this issue by including an additional optimization step in the combination procedure that accounts for these broken dependencies. Experiments on synthetic and real data demonstrate that the decentralized method provides advantages in computational performance and predictive test likelihood over previous batch and distributed methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {102–111},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020764,
author = {Chaves, R. and Luft, L. and Maciel, T. O. and Gross, D. and Janzing, D. and Sch\"{o}lkopf, B.},
title = {Inferring Latent Structures via Information Inequalities},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {One of the goals of probabilistic inference is to decide whether an empirically observed distribution is compatible with a candidate Bayesian network. However, Bayesian networks with hidden variables give rise to highly non-trivial constraints on the observed distribution. Here, we propose an information-theoretic approach, based on the insight that conditions on entropies of Bayesian networks take the form of simple linear inequalities. We describe an algorithm for deriving entropic tests for latent structures. The well-known conditional independence tests appear as a special case. While the approach applies for generic Bayesian networks, we presently adopt the causal view, and show the versatility of the framework by treating several relevant problems from that domain: detecting common ancestors, quantifying the strength of causal influence, and inferring the direction of causation from two-variable marginals.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {112–121},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020765,
author = {Cuong, Nguyen Viet and Lee, Wee Sun and Ye, Nan},
title = {Near-Optimal Adaptive Pool-Based Active Learning with General Loss},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider adaptive pool-based active learning in a Bayesian setting. We first analyze two commonly used greedy active learning criteria: the maximum entropy criterion, which selects the example with the highest entropy, and the least confidence criterion, which selects the example whose most probable label has the least probability value. We show that unlike the non-adaptive case, the maximum entropy criterion is not able to achieve an approximation that is within a constant factor of optimal policy entropy. For the least confidence criterion, we show that it is able to achieve a constant factor approximation to the optimal version space reduction in a worst-case setting, where the probability of labelings that have not been eliminated is considered as the version space. We consider a third greedy active learning criterion, the Gibbs error criterion, and generalize it to handle arbitrary loss functions between labelings. We analyze the properties of the generalization and its variants, and show that they perform well in practice.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {122–131},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020766,
author = {Doran, Gary and Muandet, Krikamol and Zhang, Kun and Sch\"{o}lkopf, Bernhard},
title = {A Permutation-Based Kernel Conditional Independence Test},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Determining conditional independence (CI) relationships between random variables is a challenging but important task for problems such as Bayesian network learning and causal discovery. We propose a new kernel CI test that uses a single, learned permutation to convert the CI test problem into an easier two-sample test problem. The learned permutation leaves the joint distribution unchanged if and only if the null hypothesis of CI holds. Then, a kernel two-sample test, which has been studied extensively in prior work, can be applied to a permuted and an unpermuted sample to test for CI. We demonstrate that the test (1) easily allows the incorporation of prior knowledge during the permutation step, (2) has power competitive with state-of-the-art kernel CI tests, and (3) accurately estimates the null distribution of the test statistic, even as the dimensionality of the conditioning variable grows.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {132–141},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020767,
author = {Dubey, Avinava and Williamson, Sinead A. and Xing, Eric P.},
title = {Parallel Markov Chain Monte Carlo for Pitman-Yor Mixture Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The Pitman-Yor process provides an elegant way to cluster data that exhibit power law behavior, where the number of clusters is unknown or unbounded. Unfortunately, inference in Pitman-Yor process-based models is typically slow and does not scale well with dataset size. In this paper we present new auxiliary-variable representations for the Pitman-Yor process and a special case of the hierarchical Pitman-Yor process that allows us to develop parallel inference algorithms that distribute inference both on the data space and the model space. We show that our method scales well with increasing data while avoiding any degradation in estimate quality.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {142–151},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020768,
author = {Dud\'{\i}k, Miroslav and Frongillo, Rafael and Vaughan, Jennifer Wortman},
title = {Market Making with Decreasing Utility for Information},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study information elicitation in cost-function-based combinatorial prediction markets when the market maker's utility for information decreases over time. In the sudden revelation setting, it is known that some piece of information will be revealed to traders, and the market maker wishes to prevent guaranteed profits for trading on the sure information. In the gradual decrease setting, the market maker's utility for (partial) information decreases continuously over time. We design adaptive cost functions for both settings which: (1) preserve the information previously gathered in the market; (2) eliminate (or diminish) rewards to traders for the publicly revealed information; (3) leave the reward structure unaffected for other information; and (4) maintain the market maker's worst-case loss. Our constructions utilize mixed Bregman divergence, which matches our notion of utility for information.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {152–161},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020769,
author = {Dvijotham, Krishnamurthy and Fazel, Maryam and Todorov, Emanuel},
title = {Universal Convexification via Risk-Aversion},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We develop a framework for convexifying a general class of optimization problems. We analyze the suboptimality of the solution to the convexified problem relative to the original nonconvex problem, and prove additive approximation guarantees under some assumptions. In simple settings, the convexification procedure can be applied directly and standard optimization methods can be used. In the general case we rely on stochastic gradient algorithms, whose convergence rate can be bounded using the convexity of the underlying optimization problem. We then extend the framework to a general class of discrete-time dynamical systems where our convexification approach falls under the paradigm of risk-sensitive Markov Decision Processes. We derive the first model-based and model-free policy gradient optimization algorithms with guaranteed convergence to the optimal solution. We also present numerical results in different machine learning applications.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {162–171},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020770,
author = {El-Hay, Tal and Weissbrod, Omer and Eban, Elad and Zazzi, Maurizio and Incardona, Francesca},
title = {Structured Proportional Jump Processes},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Learning the association between observed variables and future trajectories of continuous-time stochastic processes is a fundamental task in dynamic modeling. Often the dynamics are non-homogeneous and involve a large number of interacting components. We introduce a conditional probabilistic model that captures such dynamics, while maintaining scalability and providing an explicit way to express the interrelation between the system components. The principal idea is a factorization of the model into two distinct elements: one depends only on time and the other depends on the system configuration. We developed a learning procedure, given either full or point observations, and tested it on simulated data. We applied the proposed modeling scheme to study large cohorts of diabetes and HIV patients, and demonstrate that the factorization helps shed light on the dynamics of these diseases.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {172–181},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020771,
author = {Elkind, Edith and Shah, Nisarg},
title = {Electing the Most Probable without Eliminating the Irrational: Voting over Intransitive Domains},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Picking the best alternative in a given set is a well-studied problem at the core of social choice theory. In some applications, one can assume that there is an objectively correct way to compare the alternatives, which, however, cannot be observed directly, and individuals' preferences over the alternatives (votes) are noisy estimates of this ground truth. The goal of voting in this case is to estimate the ground truth from the votes. In this paradigm, it is usually assumed that the ground truth is a ranking of the alternatives by their true quality. However, sometimes alternatives are compared using not one but multiple quality parameters, which may result in cycles in the ground truth as well as in the preferences of the individuals. Motivated by this, we provide a formal model of voting with possibly intransitive ground truth and preferences, and investigate the maximum likelihood approach for picking the best alternative in this case. We show that the resulting framework leads to polynomial-time algorithms, and also approximates the corresponding NP-hard problems in the classic framework.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {182–191},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020772,
author = {Ermis, Beyza and Bouchard, Guillaume},
title = {Iterative Splits of Quadratic Bounds for Scalable Binary Tensor Factorization},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Binary matrices and tensors are popular data structures that need to be efficiently approximated by low-rank representations. A standard approach is to minimize the logistic loss, well suited for binary data. In many cases, the number m of non-zero elements in the tensor is much smaller than the total number n of possible entries in the tensor. This creates a problem for large tensors because the computation of the logistic loss has a linear time complexity with n. In this work, we show that an alternative approach is to minimize the quadratic loss (root mean square error) which leads to algorithms with a training time complexity that is reduced from O(n) to O(m), as proposed earlier in the restricted case of alternating least-square algorithms. In addition, we propose and study a greedy algorithm that partitions the tensor into smaller tensors, each approximated by a quadratic upper bound. This technique provides a time-accuracy tradeoff between a fast but approximate algorithm and an accurate but slow algorithm. We show that this technique leads to a considerable speedup in learning of real world tensors.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {192–199},
numpages = {8},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020773,
author = {Fan, Xiannian and Malone, Brandon and Yuan, Changhe},
title = {Finding Optimal Bayesian Network Structures with Constraints Learned from Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Several recent algorithms for learning Bayesian network structures first calculate potentially optimal parent sets (POPS) for all variables and then use various optimization techniques to find a set of POPS, one for each variable, that constitutes an optimal network structure. This paper makes the observation that there is useful information implicit in the POPS. Specifically, the POPS of a variable constrain its parent candidates. Moreover, the parent candidates of all variables together give a directed cyclic graph, which often decomposes into a set of strongly connected components (SCCs). Each SCC corresponds to a smaller subproblem which can be solved independently of the others. Our results show that solving the constrained subproblems significantly improves the efficiency and scalability of heuristic search-based structure learning algorithms. Further, we show that by considering only the top p POPS of each variable, we quickly find provably very high quality networks for large datasets.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {200–209},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020774,
author = {Ferns, Norm and Precup, Doina},
title = {Bisimulation Metrics Are Optimal Value Functions},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bisimulation is a notion of behavioural equivalence on the states of a transition system. Its definition has been extended to Markov decision processes, where it can be used to aggregate states. A bisimulation metric is a quantitative analog of bisimulation that measures how similar states are from a the perspective of long-term behavior. Bisimulation metrics have been used to establish approximation bounds for state aggregation and other forms of value function approximation. In this paper, we prove that a bisimulation metric defined on the state space of a Markov decision process is the optimal value function of an optimal coupling of two copies of the original model. We prove the result in the general case of continuous state spaces. This result has important implications in understanding the complexity of computing such metrics, and opens up the possibility of more efficient computational methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {210–219},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020775,
author = {Foulds, James and Smyth, Padhraic},
title = {Annealing Paths for the Evaluation of Topic Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Statistical topic models such as latent Dirich-let allocation have become enormously popular in the past decade, with dozens of learning algorithms and extensions being proposed each year. As these models and algorithms continue to be developed, it becomes increasingly important to evaluate them relative to previous techniques. However, evaluating the predictive performance of a topic model is a computationally difficult task. Annealed importance sampling (AIS), a Monte Carlo technique which operates by annealing between two distributions, has previously been successfully used for topic model evaluation (Wallach et al., 2009b). This technique estimates the likelihood of a held-out document by simulating an annealing process from the prior to the posterior for the latent topic assignments, and using this simulation as an importance sampling proposal distribution.In this paper we introduce new AIS annealing paths which instead anneal from one topic model to another, thereby estimating the relative performance of the models. This strategy can exhibit much lower empirical variance than previous approaches, facilitating reliable per-document comparisons of topic models. We then show how to use these paths to evaluate the predictive performance of topic model learning algorithms by efficiently estimating the likelihood at each iteration of the training procedure. The proposed method achieves better held-out likelihood estimates for this task than previous algorithms with, in some cases, an order of magnitude less computation.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {220–229},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020776,
author = {Garnett, Roman and Osborne, Michael A. and Hennig, Philipp},
title = {Active Learning of Linear Embeddings for Gaussian Processes},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose an active learning method for discovering low-dimensional structure in high-dimensional Gaussian process (GP) tasks. Such problems are increasingly frequent and important, but have hitherto presented severe practical difficulties. We further introduce a novel technique for approximately marginalizing GP hyper-parameters, yielding marginal predictions robust to hyperparameter misspecification. Our method offers an efficient means of performing GP regression, quadrature, or Bayesian optimization in high-dimensional spaces.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {230–239},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020777,
author = {Geiger, Philipp and Janzing, Dominik and Sch\"{o}lkopf, Bernhard},
title = {Estimating Causal Effects by Bounding Confounding},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Assessing the causal effect of a treatment variable X on an outcome variable Y is usually difficult due to the existence of unobserved common causes. Without further assumptions, observed dependences do not even prove the existence of a causal effect from X to Y. It is intuitively clear that strong statistical dependences between X and Y do provide evidence for X influencing Y if the influence of common causes is known to be weak. We propose a framework that formalizes effect versus confounding in various ways and derive upper/lower bounds on the effect in terms of a priori given bounds on confounding. The formalization includes information theoretic quantities like information flow and causal strength, as well as other common notions like effect of treatment on the treated (ETT). We discuss several scenarios where upper bounds on the strength of confounding can be derived. This justifies to some extent human intuition which assumes the presence of causal effect when strong (e.g. close to deterministic) statistical relations are observed.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {240–249},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020778,
author = {Gelbart, Michael A. and Snoek, Jasper and Adams, Ryan P.},
title = {Bayesian Optimization with Unknown Constraints},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recent work on Bayesian optimization has shown its effectiveness in global optimization of difficult black-box objective functions. Many real-world optimization problems of interest also have constraints which are unknown a priori. In this paper, we study Bayesian optimization for constrained problems in the general case that noise may be present in the constraint functions, and the objective and constraints may be evaluated independently. We provide motivating practical examples, and present a general framework to solve such problems. We demonstrate the effectiveness of our approach on optimizing the performance of online latent Dirichlet allocation subject to topic sparsity constraints, tuning a neural network given test-time memory constraints, and optimizing Hamiltonian Monte Carlo to achieve maximal effectiveness in a fixed time, subject to passing standard convergence diagnostics.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {250–259},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020779,
author = {Ghosh, Soumya and Raptis, Michalis and Sigal, Leonid and Sudderth, Erik B.},
title = {Nonparametric Clustering with Distance Dependent Hierarchies},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The distance dependent Chinese restaurant process (ddCRP) provides a flexible framework for clustering data with temporal, spatial, or other structured dependencies. Here we model multiple groups of structured data, such as pixels within frames of a video sequence, or paragraphs within documents from a text corpus. We propose a hierarchical generalization of the ddCRP which clusters data within groups based on distances between data items, and couples clusters across groups via distances based on aggregate properties of these local clusters. Our hddCRP model subsumes previously proposed hierarchical extensions to the ddCRP, and allows more flexibility in modeling complex data. This flexibility poses a challenging inference problem, and we derive a MCMC method that makes coordinated changes to data assignments both within and between local clusters. We demonstrate the effectiveness of our hddCRP on video segmentation and discourse modeling tasks, achieving results competitive with state-of-the-art methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {260–269},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020780,
author = {Gopal, Siddharth and Yang, Yiming},
title = {Transformation-Based Probabilistic Clustering with Supervision},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {One of the common problems with clustering is that the generated clusters often do not match user expectations. This paper proposes a novel probabilistic framework that exploits supervised information in a discriminative and transferable manner to generate better clustering of unlabeled data. The supervision is provided by revealing the cluster assignments for some subset of the ground truth clusters and is used to learn a transformation of the data such that labeled instances form well-separated clusters with respect to the given clustering objective. This estimated transformation function enables us to fold the remaining unlabeled data into a space where new clusters hopefully match user expectations. While our framework is general, in this paper, we focus on its application to Gaussian and von Mises-Fisher mixture models. Extensive testing on 23 data sets across several application domains revealed substantial improvement in performance over competing methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {270–279},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020781,
author = {Gribkoff, Eric and Van den Broeck, Guy and Suciu, Dan},
title = {Understanding the Complexity of Lifted Inference and Asymmetric Weighted Model Counting},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we study lifted inference for the Weighted First-Order Model Counting problem (WFOMC), which counts the assignments that satisfy a given sentence in first-order logic (FOL); it has applications in Statistical Relational Learning (SRL) and Probabilistic Databases (PDB). We present several results. First, we describe a lifted inference algorithm that generalizes prior approaches in SRL and PDB. Second, we provide a novel dichotomy result for a non-trivial fragment of FO CNF sentences, showing that for each sentence the WFOMC problem is either in PTIME or #P-hard in the size of the input domain; we prove that, in the first case our algorithm solves the WFOMC problem in PTIME, and in the second case it fails. Third, we present several properties of the algorithm. Finally, we discuss limitations of lifted inference for symmetric probabilistic databases (where the weights of ground literals depend only on the relation name, and not on the constants of the domain), and prove the impossibility of a dichotomy result for the complexity of probabilistic inference for the entire language FOL.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {280–289},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020782,
author = {Grizou, Jonathan and Iturrate, I\~{n}aki and Montesano, Luis and Oudeyer, Pierre-Yves and Lopes, Manuel},
title = {Interactive Learning from Unlabeled Instructions},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Interactive learning deals with the problem of learning and solving tasks using human instructions. It is common in human-robot interaction, tutoring systems, and in human-computer interfaces such as brain-computer ones. In most cases, learning these tasks is possible because the signals are predefined or an ad-hoc calibration procedure allows to map signals to specific meanings. In this paper, we address the problem of simultaneously solving a task under human feedback and learning the associated meanings of the feedback signals. This has important practical application since the user can start controlling a device from scratch, without the need of an expert to define the meaning of signals or carrying out a calibration phase. The paper proposes an algorithm that simultaneously assign meanings to signals while solving a sequential task under the assumption that both, human and machine, share the same a priori on the possible instruction meanings and the possible tasks. Furthermore, we show using synthetic and real EEG data from a brain-computer interface that taking into account the uncertainty of the task and the signal is necessary for the machine to actively plan how to solve the task efficiently.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {290–299},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020783,
author = {Gu, Quanquan and Zhang, Tong and Han, Jiawei},
title = {Batch-Mode Active Learning via Error Bound Minimization},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Active learning has been proven to be quite effective in reducing the human labeling efforts by actively selecting the most informative examples to label. In this paper, we present a batch-mode active learning method based on logistic regression. Our key motivation is an out-of-sample bound on the estimation error of class distribution in logistic regression conditioned on any fixed training sample. It is different from a typical PAC-style passive learning error bound, that relies on the i.i.d. assumption of example-label pairs. In addition, it does not contain the class labels of the training sample. Therefore, it can be immediately used to design an active learning algorithm by minimizing this bound iteratively. We also discuss the connections between the proposed method and some existing active learning approaches. Experiments on benchmark UCI datasets and text datasets demonstrate that the proposed method outperforms the state-of-the-art active learning methods significantly.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {300–309},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020784,
author = {Gunter, Tom and Lloyd, Chris and Osborne, Michael A. and Roberts, Stephen J.},
title = {Efficient Bayesian Nonparametric Modelling of Structured Point Processes},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper presents a Bayesian generative model for dependent Cox point processes, alongside an efficient inference scheme which scales as if the point processes were modelled independently. We can handle missing data naturally, infer latent structure, and cope with large numbers of observed processes. A further novel contribution enables the model to work effectively in higher dimensional spaces. Using this method, we achieve vastly improved predictive performance on both 2D and 1D real data, validating our structured approach.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {310–319},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020785,
author = {Halloran, John T. and Bilmes, Jeff A. and Noble, William S.},
title = {Learning Peptide-Spectrum Alignment Models for Tandem Mass Spectrometry},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a peptide-spectrum alignment strategy that employs a dynamic Bayesian network (DBN) for the identification of spectra produced by tandem mass spectrometry (MS/MS). Our method is fundamentally generative in that it models peptide fragmentation in MS/MS as a physical process. The model traverses an observed MS/MS spectrum and a peptide-based theoretical spectrum to calculate the best alignment between the two spectra. Unlike all existing state-of-the-art methods for spectrum identification that we are aware of, our method can learn alignment probabilities given a dataset of high-quality peptide-spectrum pairs. The method, moreover, accounts for noise peaks and absent theoretical peaks in the observed spectrum. We demonstrate that our method outperforms, on a majority of datasets, several widely used, state-of-the-art database search tools for spectrum identification. Furthermore, the proposed approach provides an extensible framework for MS/MS analysis and provides useful information that is not produced by other methods, thanks to its generative structure.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {320–329},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020786,
author = {van Hasselt, Hado and Mahmood, A. Rupam and Sutton, Richard S.},
title = {Off-Policy TD(λ) with a True Online Equivalence},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Van Seijen and Sutton (2014) recently proposed a new version of the linear TD(λ) learning algorithm that is exactly equivalent to an online forward view and that empirically performed better than its classical counterpart in both prediction and control problems. However, their algorithm is restricted to on-policy learning. In the more general case of off-policy learning, in which the policy whose outcome is predicted and the policy used to generate data may be different, their algorithm cannot be applied. One reason for this is that the algorithm bootstraps and thus is subject to instability problems when function approximation is used. A second reason true online TD(λ) cannot be used for off-policy learning is that the off-policy case requires sophisticated importance sampling in its eligibility traces. To address these limitations, we generalize their equivalence result and use this generalization to construct the first online algorithm to be exactly equivalent to an off-policy forward view. We show this algorithm, named true online GTD(λ), empirically outperforms GTD(λ) (Maei, 2011) which was derived from the same objective as our forward view but lacks the exact online equivalence. In the general theorem that allows us to derive this new algorithm, we encounter a new general eligibility-trace update.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {330–339},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020787,
author = {Hyttinen, Antti and Eberhardt, Frederick and J\"{a}rvisalo, Matti},
title = {Constraint-Based Causal Discovery: Conflict Resolution with Answer Set Programming},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recent approaches to causal discovery based on Boolean satisfiability solvers have opened new opportunities to consider search spaces for causal models with both feedback cycles and unmeasured confounders. However, the available methods have so far not been able to provide a principled account of how to handle conflicting constraints that arise from statistical variability. Here we present a new approach that preserves the versatility of Boolean constraint solving and attains a high accuracy despite the presence of statistical errors. We develop a new logical encoding of (in)dependence constraints that is both well suited for the domain and allows for faster solving. We represent this encoding in Answer Set Programming (ASP), and apply a state-of-the-art ASP solver for the optimization task. Based on different theoretical motivations, we explore a variety of methods to handle statistical errors. Our approach currently scales to cyclic latent variable models with up to seven observed variables and outperforms the available constraint-based methods in accuracy.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {340–349},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020788,
author = {Ishihata, Masakazu and Iwata, Tomoharu},
title = {Generating Structure of Latent Variable Models for Nested Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Probabilistic latent variable models have been successfully used to capture intrinsic characteristics of various data. However, it is nontrivial to design appropriate models for given data because it requires both machine learning and domain-specific knowledge. In this paper, we focus on data with nested structure and propose a method to automatically generate a latent variable model for the given nested data, with the proposed method, the model structure is adjustable by its structural parameters. Our model can represent a wide class of hierarchical and sequential latent variable models including mixture models, latent Dirichlet allocation, hidden Markov models and their combinations in multiple layers of the hierarchy. Even when deeply-nested data are given, where designing a proper model is difficult even for experts, our method generate an appropriate model by extracting the essential information. We present an efficient variational inference method for our model based on dynamic programming on the given data structure. We experimentally show that our method generates correct models from artificial datasets and demonstrate that models generated by our method can extract hidden structures of blog and news article datasets.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {350–359},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020789,
author = {Iyer, Rishabh and Jegelka, Stefanie and Bilmes, Jeff},
title = {Monotone Closure of Relaxed Constraints in Submodular Optimization: Connections between Minimization and Maximization},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {It is becoming increasingly evident that many machine learning problems may be reduced to sub-modular optimization. Previous work addresses generic discrete approaches and specific relaxations. In this work, we take a generic view from a relaxation perspective. We show a relaxation formulation and simple rounding strategy that, based on the monotone closure of relaxed constraints, reveals analogies between minimization and maximization problems, and includes known results as special cases and extends to a wider range of settings. Our resulting approximation factors match the corresponding integrality gaps. For submodular maximization, a number of relaxation approaches have been proposed. A critical challenge for the practical applicability of these techniques, however, is the complexity of evaluating the multilinear extension. We show that this extension can be efficiently evaluated for a number of useful submodular functions, thus making these otherwise impractical algorithms viable for real-world machine learning problems.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {360–369},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020790,
author = {Jain, Vidit and Galhotra, Sainyam},
title = {Min-<i>d</i>-Occur: Ensuring Future Occurrences in Streaming Sets},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Given a set of n elements and a corresponding stream of its subsets, we consider the problem of selecting k elements that should appear in at least d such subsets arriving in the "near" future with high probability. For this min-d-occur problem, we present an algorithm that provides a solution with the success probability of at least 1 - O (kd log n/D + 1/n), where D is a known constant. Our empirical observations on two streaming data sets show that this algorithm achieves high precision and recall values. We further present a sliding window adaptation of the proposed algorithm to provide a continuous selection of these elements. In contrast to the existing work on predicting trends based on potential increase in popularity, our work focuses on a setting with provable guarantees.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {370–379},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020791,
author = {Kandemir, Melih and Hamprecht, Fred A.},
title = {Instance Label Prediction by Dirichlet Process Multiple Instance Learning},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a generative Bayesian model that predicts instance labels from weak (bag-level) supervision. We solve this problem by simultaneously modeling class distributions by Gaussian mixture models and inferring the class labels of positive bag instances that satisfy the multiple instance constraints. We employ Dirichlet process priors on mixture weights to automate model selection, and efficiently infer model parameters and positive bag instances by a constrained variational Bayes procedure. Our method improves on the state-of-the-art of instance classification from weak supervision on 20 benchmark text categorization data sets and one histopathology cancer diagnosis data set.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {380–389},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020792,
author = {Kinathil, Shamin and Sanner, Scott and Penna, Nicol\'{a}s Della},
title = {Closed-Form Solutions to a Subclass of Continuous Stochastic Games via Symbolic Dynamic Programming},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Zero-sum stochastic games provide a formalism to study competitive sequential interactions between two agents with diametrically opposing goals and evolving state. A solution to such games with discrete state was presented by Littman (Littman, 1994). The continuous state version of this game remains unsolved. In many instances continuous state solutions require nonlinear optimisation, a problem for which closed-form solutions are generally unavailable. We present an exact closed-form solution to a subclass of zero-sum continuous stochastic games that can be solved as a parameterised linear program by utilising symbolic dynamic programming. This novel technique is applied to calculate exact solutions to a variety of zero-sum continuous state stochastic games.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {390–399},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020793,
author = {Kishimoto, Akihiro and Marinescu, Radu},
title = {Recursive Best-First AND/OR Search for Optimization in Graphical Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The paper presents and evaluates the power of limited memory best-first search over AND/OR spaces for optimization tasks in graphical models. We propose Recursive Best-First AND/OR Search with Overestimation (RBFAOO), a new algorithm that explores the search space in a best-first manner while operating with restricted memory. We enhance RBFAOO with a simple overestimation technique aimed at minimizing the overhead associated with re-expanding internal nodes and prove correctness and completeness of RBFAOO. Our experiments show that RBFAOO is often superior to the current state-of-the-art approaches based on AND/OR search, especially on very hard problem instances.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {400–409},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020794,
author = {Koehler, Henning and Link, Sebastian},
title = {Saturated Conditional Independence with Fixed and Undetermined Sets of Incomplete Random Variables},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The implication problem for saturated conditional independence statements is studied in the presence of fixed and undetermined sets of incomplete random variables. Here, random variables are termed incomplete since they admit missing data. Two different notions of implication arise. In the classic notion of V-implication, a statement is implied jointly by a set of statements and a fixed set V of random variables. In the alternative notion of pure implication, a statement is implied by a given set of statements alone, leaving the set of random variables undetermined. A first axiomatization for V-implication is established that distinguishes purely implied from V-implied statements. Axiomatic, algorithmic and logical characterizations of pure implication are established. Pure implication appeals to applications in which the existence of random variables is uncertain, for example, when independence statements are integrated from different sources, when random variables are unknown or shall remain hidden.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {410–419},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020795,
author = {Kveton, Branislav and Wen, Zheng and Ashkan, Azin and Eydgahi, Hoda and Eriksson, Brian},
title = {Matroid Bandits: Fast Combinatorial Optimization with Learning},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A matroid is a notion of independence in combinatorial optimization which is closely related to computational efficiency. In particular, it is well known that the maximum of a constrained modular function can be found greedily if and only if the constraints are associated with a matroid. In this paper, we bring together the ideas of bandits and matroids, and propose a new class of combinatorial bandits, matroid bandits. The objective in these problems is to learn how to maximize a modular function on a matroid. This function is stochastic and initially unknown. We propose a practical algorithm for solving our problem, Optimistic Matroid Maximization (OMM); and prove two upper bounds, gap-dependent and gap-free, on its regret. Both bounds are sublinear in time and at most linear in all other quantities of interest. The gap-dependent upper bound is tight and we prove a matching lower bound on a partition matroid bandit. Finally, we evaluate our method on three real-world problems and show that it is practical.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {420–429},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020796,
author = {Li, Xin and Zhao, Feipeng and Guo, Yuhong},
title = {Multi-Label Image Classification with a Probabilistic Label Enhancement Model},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we present a novel probabilistic label enhancement model to tackle multi-label image classification problem. Recognizing multiple objects in images is a challenging problem due to label sparsity, appearance variations of the objects and occlusions. We propose to tackle these difficulties from a novel perspective by constructing auxiliary labels in the output space. Our idea is to exploit label combinations to enrich the label space and improve the label identification capacity in the original label space. In particular, we identify a set of informative label combination pairs by constructing a tree-structured graph in the label space using the maximum spanning tree algorithm, which naturally forms a conditional random field. We then use the produced label pairs as auxiliary new labels to augment the original labels and perform piecewise training under the framework of conditional random fields. In the test phase, max-product message passing is used to perform efficient inference on the tree graph, which integrates the augmented label pair classifiers and the standard individual binary classifiers for multi-label prediction. We evaluate the proposed approach on several image classification datasets. The experimental results demonstrate the superiority of our label enhancement model in terms of both prediction performance and running time comparing to the-state-of-the-art multi-label learning methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {430–439},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020797,
author = {Lacoste, Alexandre and Larochelle, Hugo and Marchand, Mario and Laviolette, Fran\c{c}ois},
title = {Sequential Model-Based Ensemble Optimization},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {One of the most tedious tasks in the application of machine learning is model selection, i.e. hyperparameter selection. Fortunately, recent progress has been made in the automation of this process, through the use of sequential model-based optimization (SMBO) methods. This can be used to optimize a cross-validation performance of a learning algorithm over the value of its hyperparameters. However, it is well known that ensembles of learned models almost consistently outperform a single model, even if properly selected. In this paper, we thus propose an extension of SMBO methods that automatically constructs such ensembles. This method builds on a recently proposed ensemble construction paradigm known as Agnostic Bayesian learning. In experiments on 22 regression and 39 classification data sets, we confirm the success of this proposed approach, which is able to outperform model selection with SMBO.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {440–448},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020798,
author = {Lan, Yanyan and Zhu, Yadong and Guo, Jiafeng and Niu, Shuzi and Cheng, Xueqi},
title = {Position-Aware ListMLE: A Sequential Learning Process for Ranking},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {ListMLE is a state-of-the-art listwise learning-to-rank algorithm, which has been shown to work very well in application. It defines the probability distribution based on Plackett-Luce Model in a top-down style to take into account the position information. However, both empirical contradiction and theoretical results indicate that ListMLE cannot well capture the position importance, which is a key factor in ranking. To amend the problem, this paper proposes a new listwise ranking method, called position-aware ListMLE (p-ListMLE for short). It views the ranking problem as a sequential learning process, with each step learning a subset of parameters which maximize the corresponding stepwise probability distribution. To solve this sequential multi-objective optimization problem, we propose to use linear scalarization strategy to transform it into a single-objective optimization problem, which is efficient for computation. Our theoretical study shows that p-ListMLE is better than ListMLE in statistical consistency with respect to typical ranking evaluation measure NDCG. Furthermore, our experiments on benchmark datasets demonstrate that the proposed method can significantly improve the performance of ListMLE and outperform state-of-the-art listwise learning-to-rank algorithms as well.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {449–458},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020799,
author = {Loic, Landrieu and Obozinski, Guillaume},
title = {Continuously Indexed Potts Models on Unoriented Graphs},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper introduces an extension to undirected graphical models of the classical continuous time Markov chains. This model can be used to solve a transductive or unsupervised multi-class classification problem at each point of a network defined as a set of nodes connected by segments of different lengths. The classification is performed not only at the nodes, but at every point of the edge connecting two nodes. This is achieved by constructing a Potts process indexed by the continuum of points forming the edges of the graph.We propose a homogeneous parameterization which satisfies Kolmogorov consistency, and show that classical inference and learning algorithms can be applied.We then apply our model to a problem from geomatics, namely that of labelling city blocks automatically with a simple typology of classes (e.g. collective housing) from simple properties of the shape and sizes of buildings of the blocks. Our experiments shows that our model outperform standard MRFs and a discriminative model like logistic regression.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {459–468},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020800,
author = {Lasko, Thomas A.},
title = {Efficient Inference of Gaussian-Process-Modulated Renewal Processes with Application to Medical Event Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The episodic, irregular and asynchronous nature of medical data render them difficult substrates for standard machine learning algorithms. We would like to abstract away this difficulty for the class of time-stamped categorical variables (or events) by modeling them as a renewal process and inferring a probability density over non-parametric longitudinal intensity functions that modulate the process. Several methods exist for inferring such a density over intensity functions, but either their constraints prevent their use with our potentially bursty event streams, or their time complexity renders their use intractable on our long-duration observations of high-resolution events, or both. In this paper we present a new efficient and flexible inference method that uses direct numeric integration and smooth interpolation over Gaussian processes. We demonstrate that our direct method is up to twice as accurate and two orders of magnitude more efficient than the best existing method (thinning). Importantly, our direct method can infer intensity functions over the full range of bursty to memoryless to regular events, which thinning and many other methods cannot do. Finally, we apply the method to clinical event data and demonstrate a simple example application facilitated by the abstraction.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {469–476},
numpages = {8},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020801,
author = {Lattimore, Tor and Crammer, Koby and Szepesv\'{a}ri, Csaba},
title = {Optimal Resource Allocation with Semi-Bandit Feedback},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study a sequential resource allocation problem involving a fixed number of recurring jobs. At each time-step the manager should distribute available resources among the jobs in order to maximise the expected number of completed jobs. Allocating more resources to a given job increases the probability that it completes, but with a cut-off. Specifically, we assume a linear model where the probability increases linearly until it equals one, after which allocating additional resources is wasteful. We assume the difficulty of each job is unknown and present the first algorithm for this problem and prove upper and lower bounds on its regret. Despite its apparent simplicity, the problem has a rich structure: we show that an appropriate optimistic algorithm can improve its learning speed dramatically beyond the results one normally expects for similar problems as the problem becomes resource-laden.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {477–486},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020802,
author = {Levine, Daniel and How, Jonathan P.},
title = {Quantifying Nonlocal Informativeness in High-Dimensional, Loopy Gaussian Graphical Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of selecting informative observations in Gaussian graphical models containing both cycles and nuisances. More specifically, we consider the subproblem of quantifying conditional mutual information measures that are nonlocal on such graphs. The ability to efficiently quantify the information content of observations is crucial for resource-constrained data acquisition (adaptive sampling) and data processing (active learning) systems. While closed-form expressions for Gaussian mutual information exist, standard linear algebraic techniques, with complexity cubic in the network size, are intractable for high-dimensional distributions. We investigate the use of embedded trees for computing nonlocal pairwise mutual information and demonstrate through numerical simulations that the presented approach achieves a significant reduction in computational cost over inversion-based methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {487–495},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020803,
author = {Li, Ping},
title = {CoRE Kernels},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The term "CoRE kernel" stands for correlation-resemblance kernel. In many real-world applications (e.g., computer vision), the data are often high-dimensional, sparse, and non-binary. We propose two types of (nonlinear) CoRE kernels for non-binary sparse data and demonstrate the effectiveness of the new kernels through a classification experiment. CoRE kernels are simple with no tuning parameters. However, training nonlinear kernel SVM can be costly in time and memory and may not be always suitable for truly large-scale industrial applications (e.g., search). In order to make the proposed CoRE kernels more practical, we develop basic probabilistic hashing (approximate) algorithms which transform nonlinear kernels into linear kernels.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {496–504},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020804,
author = {Lin, Ming and Jin, Rong and Zhang, Changshui},
title = {Efficient Sparse Recovery via Adaptive Non-Convex Regularizers with Oracle Property},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The main shortcoming of sparse recovery with a convex regularizer is that it is a biased estimator and therefore will result in a suboptimal performance in many cases. Recent studies have shown, both theoretically and empirically, that non-convex regularizer is able to overcome the biased estimation problem. Although multiple algorithms have been developed for sparse recovery with non-convex regularization, they are either computationally demanding or not equipped with the desired properties (i.e. optimal recovery error, selection consistency and oracle property). In this work, we develop an algorithm for efficient sparse recovery based on proximal gradient descent. The key feature of the proposed algorithm is introducing adaptive non-convex regularizers whose shrinking threshold vary over iterations. The algorithm is compatible with most popular non-convex regularizers, achieves a geometric convergence rate for the recovery error, is selection consistent, and most importantly has the oracle property. Based on the proposed framework, we suggest to use a so-called ACCQ regularizer, which is equivalent to zero proximal projection gap adaptive hard-thresholding. Experiments with both synthetic data sets and real images verify both the efficiency and effectiveness of the proposed method compared to the state-of-the-art methods for sparse recovery.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {505–514},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020805,
author = {Liu, Yuanyuan and Cheng, Hong and Shang, Fanhua and Cheng, James},
title = {Nuclear Norm Regularized Least Squares Optimization on Grassmannian Manifolds},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper aims to address a class of nuclear norm regularized least square (NNLS) problems. By exploiting the underlying low-rank matrix manifold structure, the problem with nuclear norm regularization is cast to a Riemannian optimization problem over matrix manifolds. Compared with existing NNLS algorithms involving singular value decomposition (SVD) of large-scale matrices, our method achieves significant reduction in computational complexity. Moreover, the uniqueness of matrix factorization can be guaranteed by our Grassmannian manifold method. In our solution, we first introduce the bilateral factorization into the original NNLS problem and convert it into a Grassmannian optimization problem by using a linearized technique. Then the conjugate gradient procedure on the Grassmannian manifold is developed for our method with a guarantee of local convergence. Finally, our method can be extended to address the graph regularized problem. Experimental results verified both the efficiency and effectiveness of our method.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {515–524},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020806,
author = {Lu, Yichao and Foster, Dean P.},
title = {Fast Ridge Regression with Randomized Principal Component Analysis and Gradient Descent},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a new two stage algorithm LING for large scale regression problems. LING has the same risk as the well known Ridge Regression under the fixed design setting and can be computed much faster. Our experiments have shown that LING performs well in terms of both prediction accuracy and computational efficiency compared with other large scale regression algorithms like Gradient Descent, Stochastic Gradient Descent and Principal Component Regression on both simulated and real datasets.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {525–532},
numpages = {8},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020807,
author = {Ma, Zhuang and Foster, Dean and Stine, Robert},
title = {Adaptive Monotone Shrinkage for Regression},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We develop an adaptive monotone shrinkage estimator for regression models with the following characteristics: i) dense coefficients with small but important effects; ii) a priori ordering that indicates the probable predictive importance of the features. We capture both properties with an empirical Bayes estimator that shrinks coefficients monotonically with respect to their anticipated importance. This estimator can be rapidly computed using a version of Pool-Adjacent-Violators algorithm. We show that the proposed monotone shrinkage approach is competitive with the class of all Bayesian estimators that share the prior information. We further observe that the estimator also minimizes Stein's unbiased risk estimate. Along with our key result that the estimator mimics the oracle Bayes rule under an order assumption, we also prove that the estimator is robust. Even without the order assumption, our estimator mimics the best performance of a large family of estimators that includes the least squares estimator, constant-λ ridge estimator, James-Stein estimator, etc. All the theoretical results are non-asymptotic. Simulation results and data analysis from a model for text processing are provided to support the theory.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {533–542},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020808,
author = {Maclaurin, Dougal and Adams, Ryan P.},
title = {Firefly Monte Carlo: Exact MCMC with Subsets of Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Markov chain Monte Carlo (MCMC) is a popular and successful general-purpose tool for Bayesian inference. However, MCMC cannot be practically applied to large data sets because of the prohibitive cost of evaluating every likelihood term at every iteration. Here we present Firefly Monte Carlo (FlyMC) an auxiliary variable MCMC algorithm that only queries the likelihoods of a potentially small subset of the data at each iteration yet simulates from the exact posterior distribution, in contrast to recent proposals that are approximate even in the asymptotic limit. FlyMC is compatible with a wide variety of modern MCMC algorithms, and only requires a lower bound on the per-datum likelihood factors. In experiments, we find that FlyMC generates samples from the posterior more than an order of magnitude faster than regular MCMC, opening up MCMC methods to larger datasets than were previously considered feasible.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {543–552},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020809,
author = {Marchant, Roman and Ramos, Fabio and Sanner, Scott},
title = {Sequential Bayesian Optimisation for Spatial-Temporal Monitoring},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian Optimisation has received considerable attention in recent years as a general methodology to find the maximum of costly-to-evaluate objective functions. Most existing BO work focuses on where to gather a set of samples without giving special consideration to the sampling sequence, or the costs or constraints associated with that sequence. However, in real-world sequential decision problems such as robotics, the order in which samples are gathered is paramount, especially when the robot needs to optimise a temporally non-stationary objective function. Additionally, the state of the environment and sensing platform determine the type and cost of samples that can be gathered. To address these issues, we formulate Sequential Bayesian Optimisation (SBO) with side-state information within a Partially Observed Markov Decision Process (POMDP) framework that can accommodate discrete and continuous observation spaces. We build on previous work using Monte-Carlo Tree Search (MCTS) and Upper Confidence bound for Trees (UCT) for POMDPs and extend it to work with continuous state and observation spaces. Through a series of experiments on monitoring a spatial-temporal process with a mobile robot, we show that our UCT-based SBO POMDP optimisation outperforms myopic and non-myopic alternatives.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {553–562},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020810,
author = {Marinescu, Radu and Dechter, Rina and Ihler, Alexander},
title = {AND/OR Search for Marginal MAP},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Marginal MAP problems are known to be very difficult tasks for graphical models and are so far solved exactly by systematic search guided by a join-tree upper bound. In this paper, we develop new AND/OR branch and bound algorithms for marginal MAP that use heuristics extracted from weighted mini-buckets enhanced with message-passing updates. We demonstrate the effectiveness of the resulting search algorithms against previous join-tree based approaches, which we also extend to accommodate high induced width models, through extensive empirical evaluations. Our results show not only orders-of-magnitude improvements over the state-of-the-art, but also the ability to solve problem instances well beyond the reach of previous approaches.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {563–572},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020811,
author = {Masegosa, Andr\'{e}s R.},
title = {Stochastic Discriminative EM},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Stochastic discriminative EM (sdEM) is an online-EM-type algorithm for discriminative training of probabilistic generative models belonging to the natural exponential family. In this work, we introduce and justify this algorithm as a stochastic natural gradient descent method, i.e. a method which accounts for the information geometry in the parameter space of the statistical model. We show how this learning algorithm can be used to train probabilistic generative models by minimizing different discriminative loss functions, such as the negative conditional log-likelihood and the Hinge loss. The resulting models trained by sdEM are always generative (i.e. they define a joint probability distribution) and, in consequence, allows to deal with missing data and latent variables in a principled way either when being learned or when making predictions. The performance of this method is illustrated by several text classification problems for which a multinomial naive Bayes and a latent Dirichlet allocation based classifier are learned using different discriminative loss functions.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {573–582},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020812,
author = {Matsubara, Takamitsu and G\'{o}mez, Vicen\c{c} and Kappen, Hilbert J.},
title = {Latent Kullback Leibler Control for Continuous-State Systems Using Probabilistic Graphical Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Kullback Leibler (KL) control problems allow for efficient computation of optimal control by solving a principal eigenvector problem. However, direct applicability of such framework to continuous state-action systems is limited. In this paper, we propose to embed a KL control problem in a probabilistic graphical model where observed variables correspond to the continuous (possibly high-dimensional) state of the system and latent variables correspond to a discrete (low-dimensional) representation of the state amenable for KL control computation. We present two examples of this approach. The first one uses standard hidden Markov models (HMMs) and computes exact optimal control, but is only applicable to low-dimensional systems. The second one uses factorial HMMs, it is scalable to higher dimensional problems, but control computation is approximate. We illustrate both examples in several robot motor control tasks.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {583–592},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020813,
author = {Meeds, Edward and Welling, Max},
title = {GPS-ABC: Gaussian Process Surrogate Approximate Bayesian Computation},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Scientists often express their understanding of the world through a computationally demanding simulation program. Analyzing the posterior distribution of the parameters given observations (the inverse problem) can be extremely challenging. The Approximate Bayesian Computation (ABC) framework is the standard statistical tool to handle these likelihood free problems, but they require a very large number of simulations. In this work we develop two new ABC sampling algorithms that significantly reduce the number of simulations necessary for posterior inference. Both algorithms use confidence estimates for the accept probability in the Metropolis Hastings step to adaptively choose the number of necessary simulations. Our GPS-ABC algorithm stores the information obtained from every simulation in a Gaussian process which acts as a surrogate function for the simulated statistics. Experiments on a challenging realistic biological problem illustrate the potential of these algorithms.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {593–602},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020814,
author = {Mladenov, Martin and Globerson, Amir and Kersting, Kristian},
title = {Lifted Message Passing as Reparametrization of Graphical Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Lifted inference approaches can considerably speed up probabilistic inference in Markov random fields (MRFs) with symmetries. Given evidence, they essentially form a lifted, i.e., reduced factor graph by grouping together indistinguishable variables and factors. Typically, however, lifted factor graphs are not amenable to off-the-shelf message passing (MP) approaches, and hence requires one to use either generic optimization tools, which would be slow for these problems, or design modified MP algorithms. Here, we demonstrate that the reliance on modified MP can be eliminated for the class of MP algorithms arising from MAP-LP relaxations of pairwise MRFs. Specifically, we show that a given MRF induces a whole family of MRFs of different sizes sharing essentially the same MAP-LP solution. In turn, we give an efficient algorithm to compute from them the smallest one that can be solved using off-the-shelf MP. This incurs no major overhead: the selected MRF is at most twice as large as the fully lifted factor graph. This has several implications for lifted inference. For instance, running MPLP results in the first convergent lifted MP approach for MAP-LP relaxations. Doing so can be faster than solving the MAP-LP using lifted linear programming. Most importantly, it suggests a novel view on lifted inference: it can be viewed as standard inference in a reparametrized model.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {603–612},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020815,
author = {Moore, David A. and Russell, Stuart},
title = {Fast Gaussian Process Posteriors with Product Trees},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Gaussian processes (GP) are a powerful tool for nonparametric regression; unfortunately, calculating the posterior variance in a standard GP model requires time O(n2) in the size of the training set. Previous work by Shen et al. (2006) used a k-d tree structure to approximate the posterior mean in certain GP models. We extend this approach to achieve efficient approximation of the posterior covariance using a tree clustering on pairs of training points, and demonstrate significant improvements in performance with negligible loss of accuracy.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {613–622},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020816,
author = {Neiswanger, Willie and Wang, Chong and Xing, Eric P.},
title = {Asymptotically Exact, Embarrassingly Parallel MCMC},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Communication costs, resulting from synchronization requirements during learning, can greatly slow down many parallel machine learning algorithms. In this paper, we present a parallel Markov chain Monte Carlo (MCMC) algorithm in which subsets of data are processed independently, with very little communication. First, we arbitrarily partition data onto multiple machines. Then, on each machine, any classical MCMC method (e.g., Gibbs sampling) may be used to draw samples from a posterior distribution given the data subset. Finally, the samples from each machine are combined to form samples from the full posterior. This embarrassingly parallel algorithm allows each machine to act independently on a subset of the data (without communication) until the final combination stage. We prove that our algorithm generates asymptotically exact samples and empirically demonstrate its ability to parallelize burn-in and sampling in several models.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {623–632},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020817,
author = {Neiswanger, Willie and Wang, Chong and Ho, Qirong and Xing, Eric P.},
title = {Modeling Citation Networks Using Latent Random Offsets},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Out of the many potential factors that determine which links form in a document citation network, two in particular are of high importance: first, a document may be cited based on its subject matter—this can be modeled by analyzing document content; second, a document may be cited based on which other documents have previously cited it—this can be modeled by analyzing citation structure. Both factors are important for users to make informed decisions and choose appropriate citations as the network grows. In this paper, we present a novel model that integrates the merits of content and citation analyses into a single probabilistic framework. We demonstrate our model on three real-world citation networks. Compared with existing baselines, our model can be used to effectively explore a citation network and provide meaningful explanations for links while still maintaining competitive citation prediction performance.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {633–642},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020818,
author = {Nguyen, Trung V. and Bonilla, Edwin V.},
title = {Collaborative Multi-Output Gaussian Processes},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce the collaborative multi-output Gaussian process (GP) model for learning dependent tasks with very large datasets. The model fosters task correlations by mixing sparse processes and sharing multiple sets of inducing points. This facilitates the application of variational inference and the derivation of an evidence lower bound that decomposes across inputs and outputs. We learn all the parameters of the model in a single stochastic optimization framework that scales to a large number of observations per output and a large number of outputs. We demonstrate our approach on a toy problem, two medium-sized datasets and a large dataset. The model achieves superior performance compared to single output learning and previous multi-output GP models, confirming the benefits of correlating sparsity structure of the outputs via the inducing points.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {643–652},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020819,
author = {van Ommen, Thijs},
title = {Combining Predictions from Linear Models When Training and Test Inputs Differ},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Methods for combining predictions from different models in a supervised learning setting must somehow estimate/predict the quality of a model's predictions at unknown future inputs. Many of these methods (often implicitly) make the assumption that the test inputs are identical to the training inputs, which is seldom reasonable. By failing to take into account that prediction will generally be harder for test inputs that did not occur in the training set, this leads to the selection of too complex models. Based on a novel, unbiased expression for KL divergence, we propose XAIC and its special case FAIC as versions of AIC intended for prediction that use different degrees of knowledge of the test inputs. Both methods substantially differ from and may outperform all the known versions of AIC even when the training and test inputs are iid, and are especially useful for deterministic inputs and under covariate shift. Our experiments on linear models suggest that if the test and training inputs differ substantially, then XAIC and FAIC predictively outperform AIC, BIC and several other methods including Bayesian model averaging.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {653–662},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020820,
author = {Panigrahy, Rina and Popat, Preyas},
title = {Optimal Amortized Regret in Every Interval},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Consider the classical problem of predicting the next bit in a sequence of bits. A standard performance measure is regret (loss in payoff) with respect to a set of experts. For example if we measure performance with respect to two constant experts one that always predicts 0's and another that always predicts 1's it is well known that one can get regret O(√T) with respect to the best expert by using, say, the weighted majority algorithm [LW89]. But this algorithm does not provide performance guarantee in any interval. There are other algorithms (see [BM07, FSSW97, Vov99]) that ensure regret O(√x log T) in any interval of length x. In this paper we show a randomized algorithm that in an amortized sense gets a regret of O(√x) for any interval when the sequence is partitioned into intervals arbitrarily. We empirically estimated the constant in the O() for T upto 2000 and found it to be small - around 2.1. We also experimentally evaluate the efficacy of this algorithm in predicting high frequency stock data.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {663–671},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020821,
author = {Pinto, Jervis and Fern, Alan},
title = {Learning Partial Policies to Speedup MDP Tree Search},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A popular approach for online decision making in large MDPs is time-bounded tree search. The effectiveness of tree search, however, is largely influenced by the action branching factor, which limits the search depth given a time bound. An obvious way to reduce action branching is to consider only a subset of potentially good actions at each state as specified by a provided partial policy. In this work, we consider offline learning of such partial policies with the goal of speeding up search without significantly reducing decision-making quality. Our first contribution is to study learning algorithms based on reducing our learning problem to i.i.d. supervised learning. We give a reduction-style analysis of three such algorithms, each making different assumptions, which relates the supervised learning objectives to the sub-optimality of search using the learned partial policies. Our second contribution is to describe concrete implementations of the algorithms within the popular framework of Monte-Carlo tree search. Finally, the third contribution is to evaluate the learning algorithms in two challenging MDPs with large action branching factors, showing that the learned partial policies can significantly improve the anytime performance of Monte-Carlo tree search.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {672–681},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020822,
author = {Platanios, Emmanouil Antonios and Blum, Avrim and Mitchell, Tom},
title = {Estimating Accuracy from Unlabeled Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the question of how unlabeled data can be used to estimate the true accuracy of learned classifiers. This is an important question for any autonomous learning system that must estimate its accuracy without supervision, and also when classifiers trained from one data distribution must be applied to a new distribution (e.g., document classifiers trained on one text corpus are to be applied to a second corpus). We first show how to estimate error rates exactly from unlabeled data when given a collection of competing classifiers that make independent errors, based on the agreement rates between subsets of these classifiers. We further show that even when the competing classifiers do not make independent errors, both their accuracies and error dependencies can be estimated by making certain relaxed assumptions. Experiments on two data real-world data sets produce estimates within a few percent of the true accuracy, using solely un-labeled data. These results are of practical significance in situations where labeled data is scarce and shed light on the more general question of how the consistency among multiple functions is related to their true accuracies.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {682–691},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020823,
author = {Reddi, Sashank J. and P\'{o}czos, Barnab\'{a}s},
title = {<i>K</i>-NN Regression on Functional Data with Incomplete Observations},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we study a general version of regression where each covariate itself is a functional data such as distributions or functions. In real applications, however, typically we do not have direct access to such data; instead only some noisy estimates of the true covariate functions/distributions are available to us. For example, when each covariate is a distribution, then we might not be able to directly observe these distributions, but it can be assumed that i.i.d. sample sets from these distributions are available. In this paper we present a general framework and a k-NN based estimator for this regression problem. We prove consistency of the estimator and derive its convergence rates. We further show that the proposed estimator can adapt to the local intrinsic dimension in our case and provide a simple approach for choosing k. Finally, we illustrate the applicability of our framework with numerical experiments.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {692–701},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020824,
author = {Rosenkrantz, Daniel J. and Marathe, Madhav V. and Ravi, S. S. and Vullikanti, Anil K.},
title = {Bayesian Inference in Treewidth-Bounded Graphical Models without Indegree Constraints},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present new polynomial time algorithms for inference problems in Bayesian networks (BNs) when restricted to instances that satisfy the following two conditions: they have bounded treewidth and the conditional probability table (CPT) at each node is specified concisely using an r-symmetric function for some constant r. Our polynomial time algorithms work directly on the unmoralized graph. Our results significantly extend known results regarding inference problems on treewidth bounded BNs to a larger class of problem instances. We also show that relaxing either of the conditions used by our algorithms leads to computational intractability.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {702–711},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020825,
author = {Salamatian, Salman and Fawaz, Nadia and Kveton, Branislav and Taft, Nina},
title = {SPPM: Sparse Privacy Preserving Mappings},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study the problem of a user who has both public and private data, and wants to release the public data, e.g. to a recommendation service, yet simultaneously wants to protect his private data from being inferred via big data analytics. This problem has previously been formulated as a convex optimization problem with linear constraints where the objective is to minimize the mutual information between the private and released data. This attractive formulation faces a challenge in practice because when the underlying alphabet of the user profile is large, there are too many potential ways to distort the original profile. We address this fundamental scalability challenge. We propose to generate sparse privacy-preserving mappings by recasting the problem as a sequence of linear programs and solving each of these incrementally using an adaptation of Dantzig-Wolfe decomposition. We evaluate our approach on several datasets and demonstrate that nearly optimal privacy-preserving mappings can be learned quickly even at scale.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {712–721},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020826,
author = {Shi, Tianlin and Tang, Da and Xu, Liwen and Moscibroda, Thomas},
title = {Correlated Compressive Sensing for Networked Data},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of recovering sparse correlated data on networks. To improve accuracy and reduce costs, it is strongly desirable to take the potentially useful side-information of network structure into consideration. In this paper we present a novel correlated compressive sensing method called CorrCS for networked data. By naturally extending Bayesian compressive sensing, we extract correlations from network topology and encode them into a graphical model as prior. Then we derive posterior inference algorithms for the recovery of jointly sparse and correlated networked data. First, we design algorithms to recover the data based on pairwise correlations between neighboring nodes in the network. Next, we generalize this model through a diffusion process to capture higher-order correlations. Both real-valued and binary data are considered. Our models are extensively tested on several real datasets from social and sensor networks and are shown to outperform baseline compressive sensing models in terms of recovery performance.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {722–731},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020827,
author = {Shrivastava, Anshumali and Li, Ping},
title = {Improved Densification of One Permutation Hashing},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The existing work on densification of one permutation hashing [24] reduces the query processing cost of the (K, L)-parameterized Locality Sensitive Hashing (LSH) algorithm with minwise hashing, from O(dKL) to merely O(d + KL), where d is the number of nonzeros of the data vector, K is the number of hashes in each hash table, and L is the number of hash tables. While that is a substantial improvement, our analysis reveals that the existing densification scheme in [24] is sub-optimal. In particular, there is no enough randomness in that procedure, which affects its accuracy on very sparse datasets.In this paper, we provide a new densification procedure which is provably better than the existing scheme [24]. This improvement is more significant for very sparse datasets which are common over the web. The improved technique has the same cost of O(d + KL) for query processing, thereby making it strictly preferable over the existing procedure. Experimental evaluations on public datasets, in the task of hashing based near neighbor search, support our theoretical findings.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {732–741},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020828,
author = {Srivastava, Siddharth and Russell, Stuart and Ruan, Paul and Cheng, Xiang},
title = {First-Order Open-Universe POMDPs},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Open-universe probability models, representable by a variety of probabilistic programming languages (PPLs), handle uncertainty over the existence and identity of objects—forms of uncertainty occurring in many real-world situations. We examine the problem of extending a declarative PPL to define decision problems (specifically, POMDPs) and identify non-trivial representational issues in describing an agent's capability for observation and action—issues that were avoided in previous work only by making strong and restrictive assumptions. We present semantic definitions that lead to POMDP specifications provably consistent with the sensor and actuator capabilities of the agent. We also describe a variant of point-based value iteration for solving open-universe POMDPs. Thus, we handle cases—such as seeing a new object and picking it up—that could not previously be represented or solved.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {742–751},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020829,
author = {Stanculescu, Ioan and Williams, Christopher K.I. and Freer, Yvonne},
title = {A Hierarchical Switching Linear Dynamical System Applied to the Detection of Sepsis in Neonatal Condition Monitoring},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we develop a Hierarchical Switching Linear Dynamical System (HSLDS) for the detection of sepsis in neonates in an intensive care unit. The Factorial Switching LDS (FSLDS) of Quinn et al. (2009) is able to describe the observed vital signs data in terms of a number of discrete factors, which have either physiological or artifactual origin. In this paper we demonstrate that by adding a higher-level discrete variable with semantics sepsis/non-sepsis we can detect changes in the physiological factors that signal the presence of sepsis. We demonstrate that the performance of our model for the detection of sepsis is not statistically different from the auto-regressive HMM of Stanculescu et al. (2013), despite the fact that their model is given "ground truth" annotations of the physiological factors, while our HSLDS must infer them from the raw vital signs data.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {752–761},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020830,
author = {Stratos, Karl and Kim, Do-kyum and Collins, Michael and Hsu, Daniel},
title = {A Spectral Algorithm for Learning Class-Based <i>n</i>-Gram Models of Natural Language},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The Brown clustering algorithm (Brown et al., 1992) is widely used in natural language processing (NLP) to derive lexical representations that are then used to improve performance on various NLP problems. The algorithm assumes an underlying model that is essentially an HMM, with the restriction that each word in the vocabulary is emitted from a single state. A greedy, bottom-up method is then used to find the clustering; this method does not have a guarantee of finding the correct underlying clustering. In this paper we describe a new algorithm for clustering under the Brown et al. model. The method relies on two steps: first, the use of canonical correlation analysis to derive a low-dimensional representation of words; second, a bottom-up hierarchical clustering over these representations. We show that given a sufficient number of training examples sampled from the Brown et al. model, the method is guaranteed to recover the correct clustering. Experiments show that the method recovers clusters of comparable quality to the algorithm of Brown et al. (1992), but is an order of magnitude more efficient.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {762–771},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020831,
author = {Sturlaugson, Liessman and Sheppard, John W.},
title = {Inference Complexity in Continuous Time Bayesian Networks},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The continuous time Bayesian network (CTBN) enables temporal reasoning by representing a system as a factored, finite-state Markov process. The CTBN uses a traditional Bayesian network (BN) to specify the initial distribution. Thus, the complexity results of Bayesian networks also apply to CTBNs through this initial distribution. However, the question remains whether propagating the probabilities through time is, by itself, also a hard problem. We show that exact and approximate inference in continuous time Bayesian networks is NP-hard even when the initial states are given.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {772–779},
numpages = {8},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020832,
author = {Talvitie, Erik},
title = {Model Regularization for Stable Sample Rollouts},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {When an imperfect model is used to generate sample rollouts, its errors tend to compound - a flawed sample is given as input to the model, which causes more errors, and so on. This presents a barrier to applying rollout-based planning algorithms to learned models. To address this issue, a training methodology called "hallucinated replay" is introduced, which adds samples from the model into the training data, thereby training the model to produce sensible predictions when its own samples are given as input. Capabilities and limitations of this approach are studied empirically. In several examples hallucinated replay allows effective planning with imperfect models while models trained using only real experience fail dramatically.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {780–789},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020833,
author = {Tenzer, Yaniv and Elidan, Gal},
title = {HELM: Highly Efficient Learning of Mixed Copula Networks},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Learning the structure of probabilistic graphical models for complex real-valued domains is a formidable computational challenge. This inevitably leads to significant modelling compromises such as discretization or the use of a simplistic Gaussian representation. In this work we address the challenge of efficiently learning truly expressive copula-based networks that facilitate a mix of varied copula families within the same model. Our approach is based on a simple but powerful bivariate building block that is used to highly efficiently perform local model selection, thus bypassing much of computational burden involved in structure learning. We show how this building block can be used to learn general networks and demonstrate its effectiveness on varied and sizeable real-life domains. Importantly, favorable identification and generalization performance come with dramatic runtime improvements. Indeed, the benefits are such that they allow us to tackle domains that are prohibitive when using a standard learning approaches.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {790–799},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020834,
author = {Tosi, Alessandra and Hauberg, S\"{o}ren and Vellido, Alfredo and Lawrence, Neil D.},
title = {Metrics for Probabilistic Geometries},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We investigate the geometrical structure of probabilistic generative dimensionality reduction models using the tools of Riemannian geometry. We explicitly define a distribution over the natural metric given by the models. We provide the necessary algorithms to compute expected metric tensors where the distribution over mappings is given by a Gaussian process. We treat the corresponding latent variable model as a Riemannian manifold and we use the expectation of the metric under the Gaussian process prior to define interpolating paths and measure distance between latent points. We show how distances that respect the expected metric lead to more appropriate generation of new data.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {800–808},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020835,
author = {Tran-Thanh, Long and Stavrogiannis, Lampros and Naroditskiy, Victor and Robu, Valentin and Jennings, Nicholas R and Key, Peter},
title = {Efficient Regret Bounds for Online Bid Optimisation in Budget-Limited Sponsored Search Auctions},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study the problem of an advertising agent who needs to intelligently distribute her budget across a sequence of online keyword bidding auctions. We assume the closing price of each auction is governed by the same unknown distribution, and study the problem of making provably optimal bidding decisions. Learning the distribution is done under censored observations, i.e. the closing price of an auction is revealed only if the bid we place is above it. We consider three algorithms, namely ε—First, Greedy Product-Limit (GPL) and LuekerLearn, respectively, and we show that these algorithms provably achieve Hannan-consistency. In particular, we show that the regret bound of ε—First is at most O(T⅔) with high probability. For the other two algorithms, we first prove that, by using a censored data distribution estimator proposed by Zeng [19], the empirical distribution of the closing market price converges in probability to its true distribution with a O(1/√t) rate, where t is the number of updates. Based on this result, we prove that both GPL and LuekerLearn achieve O(√T) regret bound with high probability. This in fact provides an affirmative answer to the research question raised in [1]. We also evaluate the abovementioned algorithms using real bidding data, and show that although GPL achieves the best performance on average (up to 90% of the optimal solution), its long running time may limit its suitability in practice. By contrast, LuekerLearn and ε— First proposed in this paper achieve up to 85% of the optimal, but with an exponential reduction in computational complexity (a saving up to 95%, compared to GPL).},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {809–818},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020836,
author = {Trivedi, Shubhendu and Wang, Jialei and Kpotufe, Samory and Shakhnarovich, Gregory},
title = {A Consistent Estimator of the Expected Gradient Outerproduct},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In high-dimensional classification or regression problems, the expected gradient outerproduct (EGOP) of the unknown regression function f, namely Ex (∇ f(X) · ∇f(X)⊤), is known to recover those directions v ∈ ℝd most relevant to predicting the output Y.However, just as in gradient estimation, optimal estimators of the EGOP can be expensive in practice. We show that a simple rough estimator, much cheaper in practice, suffices to obtain significant improvements on real-world nonparametric classification and regression tasks. Furthermore, we prove that, despite its simplicity, this rough estimator remains statistically consistent under mild conditions.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {819–828},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020837,
author = {Vovk, Vladimir and Petej, Ivan},
title = {Venn-Abers Predictors},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper continues study, both theoretical and empirical, of the method of Venn prediction, concentrating on binary prediction problems. Venn predictors produce probability-type predictions for the labels of test objects which are guaranteed to be well calibrated under the standard assumption that the observations are generated independently from the same distribution. We give a simple formalization and proof of this property. We also introduce Venn-Abers predictors, a new class of Venn predictors based on the idea of isotonic regression, and report promising empirical results both for Venn-Abers predictors and for their more computationally efficient simplified version.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {829–838},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020838,
author = {Wald, Yoav and Globerson, Amir},
title = {Tightness Results for Local Consistency Relaxations in Continuous MRFs},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Finding the MAP assignment in graphical models is a challenging task that generally requires approximations. One popular approximation approach is to use linear programming relaxations that enforce local consistency. While these are commonly used for discrete variable models, they are much less understood for models with continuous variables.Here we define local consistency relaxations of MAP for continuous pairwise Markov Random Fields (MRFs), and analyze their properties. We begin by providing a characterization of models for which this relaxation is tight. These turn out to be models that can be reparameterized as a sum of local convex functions. We also provide a simple formulation of this relaxation for Gaussian MRFs.Next, we show how the above insights can be used to obtain optimality certificates for loopy belief propagation (LBP) in such models. Specifically, we show that the messages of LBP can be used to calculate upper and lower bounds on the MAP value, and that these bounds coincide at convergence, yielding a natural stopping criterion which was not previously available.Finally, our results illustrate a close connection between local consistency relaxations of MAP and LBP. They demonstrate that in the continuous case, whenever LBP is provably optimal so is the local consistency relaxation.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {839–848},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020839,
author = {Wang, Yali and Brubaker, Marcus A. and Chaib-draa, Brahim and Urtasun, Raquel},
title = {Bayesian Filtering with Online Gaussian Process Latent Variable Models},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we present a novel non-parametric approach to Bayesian filtering, where the prediction and observation models are learned in an online fashion. Our approach is able to handle multimodal distributions over both models by employing a mixture model representation with Gaussian Processes (GP) based components. To cope with the increasing complexity of the estimation process, we explore two computationally efficient GP variants, sparse online GP and local GP, which help to manage computation requirements for each mixture component. Our experiments demonstrate that our approach can track human motion much more accurately than existing approaches that learn the prediction and observation models offline and do not update these models with the incoming data stream.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {849–857},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020840,
author = {Weller, Adrian and Jebara, Tony},
title = {Approximating the Bethe Partition Function},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {When belief propagation (BP) converges, it does so to a stationary point of the Bethe free energy F, and is often strikingly accurate. However, it may converge only to a local optimum or may not converge at all. An algorithm was recently introduced by Weller and Jebara for attractive binary pairwise MRFs which is guaranteed to return an ε-approximation to the global minimum of F in polynomial time provided the maximum degree Δ = O(log n), where n is the number of variables. Here we extend their approach and derive a new method based on analyzing first derivatives of F, which leads to much better performance and, for attractive models, yields a fully polynomial-time approximation scheme (FPTAS) without any degree restriction. Further, our methods apply to general (non-attractive) models, though with no polynomial time guarantee in this case, demonstrating that approximating log of the Bethe partition function, log ZB = - min F, for a general model to additive e-accuracy may be reduced to a discrete MAP inference problem. This allows the merits of the global Bethe optimum to be tested.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {858–867},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020841,
author = {Weller, Adrian and Tang, Kui and Sontag, David and Jebara, Tony},
title = {Understanding the Bethe Approximation: When and How Can It Go Wrong?},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Belief propagation is a remarkably effective tool for inference, even when applied to networks with cycles. It may be viewed as a way to seek the minimum of the Bethe free energy, though with no convergence guarantee in general. A variational perspective shows that, compared to exact inference, this minimization employs two forms of approximation: (i) the true entropy is approximated by the Bethe entropy, and (ii) the minimization is performed over a relaxation of the marginal polytope termed the local polytope. Here we explore when and how the Bethe approximation can fail for binary pairwise models by examining each aspect of the approximation, deriving results both analytically and with new experimental methods.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {868–877},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020842,
author = {Wu, Hao},
title = {A Bayesian Nonparametric Model for Spectral Estimation of Metastable Systems},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The identification of eigenvalues and eigenfunctions from simulation or experimental data is a fundamental and important problem for analysis of metastable systems, because the dominant spectral components usually contain a lot of essential information of the metastable dynamics on slow timescales. It has been shown that the dynamics of a strongly metastable system can be equivalently described as a hidden Markov model (HMM) under some technical assumptions and the spectral estimation can be performed through HMM learning. However, the spectral estimation with unknown number of dominant spectra is still a challenge in the framework of traditional HMMs, and the infinite HMMs developed based on stick-breaking processes cannot satisfactorily solved this problem either. In this paper, we analyze the difficulties of spectral estimation for infinite HMMs, and present a new nonparametric model called stick-breaking half-weighted model (SB-HWM) to address this problem. The SB-HWM defines a sparse prior of eigenvalues and can be applied to Bayesian inference of dominant eigenpairs of metastable systems in a nonparametric manner. We demonstrate by simulations the advantages of applying SB-HWM to spectral estimation.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {878–887},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020843,
author = {Wytock, Matt and Sra, Suvrit and Kolter, J. Zico},
title = {Fast Newton Methods for the Group Fused Lasso},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a new algorithmic approach to the group fused lasso, a convex model that approximates a multi-dimensional signal via an approximately piecewise-constant signal. This model has found many applications in multiple change point detection, signal compression, and total variation denoising, though existing algorithms typically using first-order or alternating minimization schemes. In this paper we instead develop a specialized projected Newton method, combined with a primal active set approach, which we show to be substantially faster that existing methods. Furthermore, we present two applications that use this algorithm as a fast subroutine for a more complex outer loop: segmenting linear regression models for time series data, and color image denoising. We show that on these problems the proposed method performs very well, solving the problems faster than state-of-the-art methods and to higher accuracy.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {888–897},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020844,
author = {Xiong, Liang and Schneider, Jeff},
title = {Learning from Point Sets with Observational Bias},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Many objects can be represented as sets of multidimensional points. A common approach to learning from these point sets is to assume that each set is an i.i.d. sample from an unknown underlying distribution, and then estimate the similarities between these distributions. In realistic situations, however, the point sets are often subject to sampling biases due to variable or inconsistent observation actions. These biases can fundamentally change the observed distributions of points and distort the results of learning. In this paper we propose the use of conditional divergences to correct these distortions and learn from biased point sets effectively. Our empirical study shows that the proposed method can successfully correct the biases and achieve satisfactory learning performance.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {898–906},
numpages = {9},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020845,
author = {van der Zander, Benito and Liundefinedkiewicz, Maciej and Textor, Johannes},
title = {Constructing Separators and Adjustment Sets in Ancestral Graphs},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Ancestral graphs (AGs) are graphical causal models that can represent uncertainty about the presence of latent confounders, and can be inferred from data. Here, we present an algorithmic framework for efficiently testing, constructing, and enumerating m-separators in AGs. Moreover, we present a new constructive criterion for covariate adjustment in directed acyclic graphs (DAGs) and maximal ancestral graphs (MAGs) that characterizes adjustment sets as m-separators in a subgraph. Jointly, these results allow to find all adjustment sets that can identify a desired causal effect with multivariate exposures and outcomes in the presence of latent confounding. Our results generalize and improve upon several existing solutions for special cases of these problems.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {907–916},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

@inproceedings{10.5555/3020751.3020846,
author = {Zhou, Chunlai and Wang, Mingyue and Qin, Biao},
title = {Belief-Kinematics Jeffrey's Rules in the Theory of Evidence},
year = {2014},
isbn = {9780974903910},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper studies the problem of revising beliefs using uncertain evidence in a framework where beliefs are represented by a belief function. We introduce two new Jeffrey's rules for the revision based on two forms of belief kinematics, an evidence-theoretic counterpart of probability kinematics. Furthermore, we provide two distance measures for belief functions and show that the two belief kinematics are optimal in the sense that they minimize their corresponding distance measures.},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
pages = {917–926},
numpages = {10},
location = {Quebec City, Quebec, Canada},
series = {UAI'14}
}

