@inproceedings{10.5555/3023638.3023639,
author = {Adel, Tameem and Urner, Ruth and Smith, Benn and Stashuk, Daniel and Lizotte, Daniel J.},
title = {Generative Multiple-Instance Learning Models for Quantitative Electromyography},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a comprehensive study of the use of generative modeling approaches for Multiple-Instance Learning (MIL) problems. In MIL a learner receives training instances grouped together into bags with labels for the bags only (which might not be correct for the comprised instances). Our work was motivated by the task of facilitating the diagnosis of neuromuscular disorders using sets of motor unit potential trains (MUPTs) detected within a muscle which can be cast as a MIL problem. Our approach leads to a state-of-the-art solution to the problem of muscle classification. By introducing and analyzing generative models for MIL in a general framework and examining a variety of model structures and components, our work also serves as a methodological guide to modelling MIL tasks. We evaluate our proposed methods both on MUPT datasets and on the MUSK1 dataset, one of the most widely used benchmarks for MIL.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {2–11},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023640,
author = {Ahmad, Sheeraz and Yu, Angela J.},
title = {Active Sensing as Bayes-Optimal Sequential Decision-Making},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Sensory inference under conditions of uncertainty is a major problem in both machine learning and computational neuroscience. An important but poorly understood aspect of sensory processing is the role of active sensing. Here, we present a Bayes-optimal inference and control framework for active sensing, C-DAC (Context-Dependent Active Controller). Unlike previously proposed algorithms that optimize abstract statistical objectives such as information maximization (Infomax) [Butko and Movellan, 2010] or one-step look-ahead accuracy [Najemnik and Geisler, 2005], our active sensing model directly minimizes a combination of behavioral costs, such as temporal delay, response error, and sensor repositioning cost. We simulate these algorithms on a simple visual search task to illustrate scenarios in which context-sensitivity is particularly beneficial and optimization with respect to generic statistical objectives particularly inadequate. Motivated by the geometric properties of the C-DAC policy, we present both parametric and non-parametric approximations, which retain context-sensitivity while significantly reducing computational complexity. These approximations enable us to investigate a more complex search problem involving peripheral vision, and we notice that the performance advantage of C-DAC over generic statistical policies is even more evident in this scenario.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {12–21},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023641,
author = {Amizadeh, Saeed and Thiesson, Bo and Hauskrecht, Milos},
title = {The Bregman Variational Dual-Tree Framework},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Graph-based methods provide a powerful tool set for many non-parametric frameworks in Machine Learning. In general, the memory and computational complexity of these methods is quadratic in the number of examples in the data which makes them quickly in-feasible for moderate to large scale datasets. A significant effort to find more efficient solutions to the problem has been made in the literature. One of the state-of-the-art methods that has been recently introduced is the Variational Dual-Tree (VDT) framework. Despite some of its unique features, VDT is currently restricted only to Euclidean spaces where the Euclidean distance quantifies the similarity. In this paper, we extend the VDT framework beyond the Euclidean distance to more general Bregman divergences that include the Euclidean distance as a special case. By exploiting the properties of the general Bregman divergence, we show how the new framework can maintain all the pivotal features of the VDT framework and yet significantly improve its performance in non-Euclidean domains. We apply the proposed framework to different text categorization problems and demonstrate its benefits over the original VDT.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {22–31},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023642,
author = {Bach, Stephen H. and Huang, Bert and London, Ben and Getoor, Lise},
title = {Hinge-Loss Markov Random Fields: Convex Inference for Structured Prediction},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Graphical models for structured domains are powerful tools, but the computational complexities of combinatorial prediction spaces can force restrictions on models, or require approximate inference in order to be tractable. Instead of working in a combinatorial space, we use hinge-loss Markov random fields (HL-MRFs), an expressive class of graphical models with log-concave density functions over continuous variables, which can represent confidences in discrete predictions. This paper demonstrates that HL-MRFs are general tools for fast and accurate structured prediction. We introduce the first inference algorithm that is both scalable and applicable to the full class of HL-MRFs, and show how to train HL-MRFs with several learning algorithms. Our experiments show that HL-MRFs match or surpass the predictive performance of state-of-the-art methods, including discrete models, in four application domains.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {32–41},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023643,
author = {Balasubramanian, Krishnakumar and Yu, Kai and Zhang, Tong},
title = {High-Dimensional Joint Sparsity Random Effects Model for Multi-Task Learning},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Joint sparsity regularization in multi-task learning has attracted much attention in recent years. The traditional convex formulation employs the group Lasso relaxation to achieve joint sparsity across tasks. Although this approach leads to a simple convex formulation, it suffers from several issues due to the looseness of the relaxation. To remedy this problem, we view jointly sparse multi-task learning as a specialized random effects model, and derive a convex relaxation approach that involves two steps. The first step learns the covariance matrix of the coefficients using a convex formulation which we refer to as sparse covariance coding; the second step solves a ridge regression problem with a sparse quadratic regularizer based on the co-variance matrix obtained in the first step. It is shown that this approach produces an asymptotically optimal quadratic regularizer in the multitask learning setting when the number of tasks approaches infinity. Experimental results demonstrate that the convex formulation obtained via the proposed model significantly outperforms group Lasso (and related multi-stage formulations).},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {42–51},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023644,
author = {Beame, Paul and Li, Jerry and Roy, Sudeepa and Suciu, Dan},
title = {Lower Bounds for Exact Model Counting and Applications in Probabilistic Databases},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The best current methods for exactly computing the number of satisfying assignments, or the satisfying probability, of Boolean formulas can be seen, either directly or indirectly, as building decision-DNNF (decision decomposable negation normal form) representations of the input Boolean formulas. Decision-DNNFs are a special case of d-DNNFs where d stands for deterministic. We show that any decision-DNNF can be converted into an equivalent FBDD (free binary decision diagram) - also known as a read-once branching program (ROBP or 1-BP) -with only a quasipolynomial increase in representation size in general, and with only a polynomial increase in size in the special case of monotone k-DNF formulas. Leveraging known exponential lower bounds for FBDDs, we then obtain similar exponential lower bounds for decision-DNNFs which provide lower bounds for the recent algorithms. We also separate the power of decision-DNNFs from d-DNNFs and a generalization of decision-DNNFs known as AND-FBDDs. Finally we show how these imply exponential lower bounds for natural problems associated with probabilistic databases.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {52–61},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023645,
author = {Belle, Vaishak and Levesque, Hector J.},
title = {Reasoning about Probabilities in Dynamic Systems Using Goal Regression},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Reasoning about degrees of belief in uncertain dynamic worlds is fundamental to many applications, such as robotics and planning, where actions modify state properties and sensors provide measurements, both of which are prone to noise. With the exception of limited cases such as Gaussian processes over linear phenomena, belief state evolution can be complex and hard to reason with in a general way. This paper proposes a framework with new results that allows the reduction of subjective probabilities after sensing and acting, both in discrete and continuous domains, to questions about the initial state only. We build on an expressive probabilistic first-order logical account by Bacchus, Halpern and Levesque, resulting in a methodology that, in principle, can be coupled with a variety of existing inference solutions.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {62–71},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023646,
author = {Bigot, Damien and Fargier, H\'{e}i\`{e}ne and Mengin, J\'{e}r\^{o}me and Zanuttini, Bruno},
title = {Probabilistic Conditional Preference Networks},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper proposes a "probabilistic" extension of conditional preference networks as a way to compactly represent a probability distributions over preference orderings. It studies the probabilistic counterparts of the main reasoning tasks, namely dominance testing and optimisation from the algorithmical and complexity viewpoints. Efficient algorithms for tree-structured probabilistic CP-nets are given. As a by-product we obtain a linear-time algorithm for dominance testing in standard, tree-structured CP-nets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {72–81},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023647,
author = {Bootkrajang, Jakramate and Kab\'{a}n, Ata},
title = {Boosting in the Presence of Label Noise},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Boosting is known to be sensitive to label noise. We studied two approaches to improve AdaBoost's robustness against labelling errors. One is to employ a label-noise robust classifier as a base learner, while the other is to modify the AdaBoost algorithm to be more robust. Empirical evaluation shows that a committee of robust classifiers, although converges faster than non label-noise aware AdaBoost, is still susceptible to label noise. However, pairing it with the new robust Boosting algorithm we propose here results in a more resilient algorithm under mislabelling.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {82–91},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023648,
author = {Boots, Byron and Gretton, Arthur and Gordon, Geoffrey J.},
title = {Hilbert Space Embeddings of Predictive State Representations},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Predictive State Representations (PSRs) are an expressive class of models for controlled stochastic processes. PSRs represent state as a set of predictions of future observable events. Because PSRs are defined entirely in terms of observable data, statistically consistent estimates of PSR parameters can be learned efficiently by manipulating moments of observed training data. Most learning algorithms for PSRs have assumed that actions and observations are finite with low cardinality. In this paper, we generalize PSRs to infinite sets of observations and actions, using the recent concept of Hilbert space embed-dings of distributions. The essence is to represent the state as one or more nonparametric conditional embedding operators in a Reproducing Kernel Hilbert Space (RKHS) and leverage recent work in kernel methods to estimate, predict, and update the representation. We show that these Hilbert space embeddings of PSRs are able to gracefully handle continuous actions and observations, and that our learned models outperform competing system identification algorithms on several prediction benchmarks.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {92–101},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023649,
author = {Borboudakis, Giorgos and Tsamardinos, Ioannis},
title = {Scoring and Searching over Bayesian Networks with Causal and Associative Priors},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A significant theoretical advantage of search-and-score methods for learning Bayesian Networks is that they can accept informative prior beliefs for each possible network, thus complementing the data. In this paper, a method is presented for assigning priors based on beliefs on the presence or absence of certain paths in the true network. Such beliefs correspond to knowledge about the possible causal and associative relations between pairs of variables. This type of knowledge naturally arises from prior experimental and observational data, among others. In addition, a novel search-operator is proposed to take advantage of such prior knowledge. Experiments show that, using path beliefs improves the learning of the skeleton, as well as the edge directions in the network.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {102–111},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023650,
author = {Brenner, Eliot and Sontag, David},
title = {SparsityBoost: A New Scoring Function for Learning Bayesian Network Structure},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We give a new consistent scoring function for structure learning of Bayesian networks. In contrast to traditional approaches to score-based structure learning, such as BDeu or MDL, the complexity penalty that we propose is data-dependent and is given by the probability that a conditional independence test correctly shows that an edge cannot exist. What really distinguishes this new scoring function from earlier work is that it has the property of becoming computationally easier to maximize as the amount of data increases. We prove a polynomial sample complexity result, showing that maximizing this score is guaranteed to correctly learn a structure with no false edges and a distribution close to the generating distribution, whenever there exists a Bayesian network which is a perfect map for the data generating distribution. Although the new score can be used with any search algorithm, we give empirical results showing that it is particularly effective when used together with a linear programming relaxation approach to Bayesian network structure learning.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {112–121},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023651,
author = {Brunskill, Emma and Li, Lihong},
title = {Sample Complexity of Multi-Task Reinforcement Learning},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Transferring knowledge across a sequence of reinforcement-learning tasks is challenging, and has a number of important applications. Though there is encouraging empirical evidence that transfer can improve performance in subsequent reinforcement-learning tasks, there has been very little theoretical analysis. In this paper, we introduce a new multi-task algorithm for a sequence of reinforcement-learning tasks when each task is sampled independently from (an unknown) distribution over a finite set of Markov decision processes whose parameters are initially unknown. For this setting, we prove under certain assumptions that the per-task sample complexity of exploration is reduced significantly due to transfer compared to standard single-task algorithms. Our multi-task algorithm also has the desired characteristic that it is guaranteed not to exhibit negative transfer: in the worst case its per-task sample complexity is comparable to the corresponding single-task algorithm.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {122–131},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023652,
author = {Bui, Hung Hai and Huynh, Tuyen N. and Riedel, Sebastian},
title = {Automorphism Groups of Graphical Models and Lifted Variational Inference},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Using the theory of group action, we first introduce the concept of the automorphism group of an exponential family or a graphical model, thus formalizing the general notion of symmetry of a probabilistic model. This automorphism group provides a precise mathematical framework for lifted inference in the general exponential family. Its group action partitions the set of random variables and feature functions into equivalent classes (called orbits) having identical marginals and expectations. Then the inference problem is effectively reduced to that of computing marginals or expectations for each class, thus avoiding the need to deal with each individual variable or feature. We demonstrate the usefulness of this general framework in lifting two classes of variational approximation for maximum a posteriori (MAP) inference: local linear programming (LP) relaxation and local LP relaxation with cycle constraints; the latter yields the first lifted variational inference algorithm that operates on a bound tighter than the local constraints.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {132–141},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023653,
author = {Chatterjee, Krishnendu and Chmel\'{\i}k, Martin},
title = {POMDPs under Probabilistic Semantics},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider partially observable Markov decision processes (POMDPs) with limit-average payoff, where a reward value in the interval [0,1] is associated to every transition, and the payoff of an infinite path is the long-run average of the rewards. We consider two types of path constraints: (i) quantitative constraint defines the set of paths where the payoff is at least a given threshold λ1 ∈ (0,1]; and (ii) qualitative constraint which is a special case of quantitative constraint with λ1 = 1. We consider the computation of the almost-sure winning set, where the controller needs to ensure that the path constraint is satisfied with probability 1. Our main results for qualitative path constraint are as follows: (i) the problem of deciding the existence of a finite-memory controller is EXPTIME-complete; and (ii) the problem of deciding the existence of an infinite-memory controller is undecidable. For quantitative path constraint we show that the problem of deciding the existence of a finite-memory controller is undecidable.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {142–151},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023654,
author = {Chen, Jie and Cao, Nannan and Low, Kian Hsiang and Ouyang, Ruofei and Tan, Colin Keng-Yan and Jaillet, Patrick},
title = {Parallel Gaussian Process Regression with Low-Rank Covariance Matrix Approximations},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Gaussian processes (GP) are Bayesian non-parametric models that are widely used for probabilistic regression. Unfortunately, it cannot scale well with large data nor perform real-time predictions due to its cubic time cost in the data size. This paper presents two parallel GP regression methods that exploit low-rank covariance matrix approximations for distributing the computational load among parallel machines to achieve time efficiency and scalability. We theoretically guarantee the predictive performances of our proposed parallel GPs to be equivalent to that of some centralized approximate GP regression methods: The computation of their centralized counterparts can be distributed among parallel machines, hence achieving greater time efficiency and scalability. We analytically compare the properties of our parallel GPs such as time, space, and communication complexity. Empirical evaluation on two real-world datasets in a cluster of 20 computing nodes shows that our parallel GPs are significantly more time-efficient and scalable than their centralized counterparts and exact/full GP while achieving predictive performances comparable to full GP.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {152–161},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023655,
author = {Cheng, Hao and Zhang, Xinhua and Schuurmans, Dale},
title = {Convex Relaxations of Bregman Divergence Clustering},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Although many convex relaxations of clustering have been proposed in the past decade, current formulations remain restricted to spherical Gaussian or discriminative models and are susceptible to imbalanced clusters. To address these shortcomings, we propose a new class of convex relaxations that can be flexibly applied to more general forms of Bregman divergence clustering. By basing these new formulations on normalized equivalence relations we retain additional control on relaxation quality, which allows improvement in clustering quality. We furthermore develop optimization methods that improve scalability by exploiting recent implicit matrix norm methods. In practice, we find that the new formulations are able to efficiently produce tighter clusterings that improve the accuracy of state of the art methods.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {162–171},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023656,
author = {Claassen, Tom and Mooij, Joris M. and Heskes, Tom},
title = {Learning Sparse Causal Models is Not NP-Hard},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper shows that causal model discovery is not an NP-hard problem, in the sense that for sparse graphs bounded by node degree k the sound and complete causal model can be obtained in worst case order N2(k+2) independence tests, even when latent variables and selection bias may be present. We present a modification of the well-known FCI algorithm that implements the method for an independence oracle, and suggest improvements for sample/real-world data versions. It does not contradict any known hardness results, and does not solve an NP-hard problem: it just proves that sparse causal discovery is perhaps more complicated, but not as hard as learning minimal Bayesian networks.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {172–181},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023657,
author = {Barlett, Mark and Cussens, James},
title = {Advances in Bayesian Network Learning Using Integer Programming},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of learning Bayesian networks (BNs) from complete discrete data. This problem of discrete optimisation is formulated as an integer program (IP). We describe the various steps we have taken to allow efficient solving of this IP. These are (i) efficient search for cutting planes, (ii) a fast greedy algorithm to find high-scoring (perhaps not optimal) BNs and (iii) tightening the linear relaxation of the IP. After relating this BN learning problem to set covering and the multidimensional 0-1 knapsack problem, we present our empirical results. These show improvements, sometimes dramatic, over earlier results.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {182–191},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023658,
author = {Drougard, Nicolas and Farges, Jean-Loup and Teichteil-K\"{o}nigsbuch, Florent and Dubois, Didier},
title = {Qualitative Possibilistic Mixed-Observable MDPs},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Possibilistic and qualitative POMDPs (π-POMDPs) are counterparts of POMDPs used to model situations where the agent's initial belief or observation probabilities are imprecise due to lack of past experiences or insufficient data collection. However, like probabilistic POMDPs, optimally solving π-POMDPs is intractable: the finite belief state space exponentially grows with the number of system's states. In this paper, a possibilistic version of Mixed-Observable MDPs is presented to get around this issue: the complexity of solving π-POMDPs, some state variables of which are fully observable, can be then dramatically reduced. A value iteration algorithm for this new formulation under infinite horizon is next proposed and the optimality of the returned policy (for a specified criterion) is shown assuming the existence of a "stay" action in some goal states. Experimental work finally shows that this possibilistic model outperforms probabilistic POMDPs commonly used in robotics, for a target recognition problem where the agent's observations are imprecise.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {192–201},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023659,
author = {Ermon, Stefano and Gomes, Carla P. and Sabharwal, Ashish and Selman, Bart},
title = {Optimization with Parity Constraints: From Binary Codes to Discrete Integration},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Many probabilistic inference tasks involve summations over exponentially large sets. Recently, it has been shown that these problems can be reduced to solving a polynomial number of MAP inference queries for a model augmented with randomly generated parity constraints. By exploiting a connection with max-likelihood decoding of binary codes, we show that these optimizations are computationally hard. Inspired by iterative message passing decoding algorithms, we propose an Integer Linear Programming (ILP) formulation for the problem, enhanced with new sparsification techniques to improve decoding performance. By solving the ILP through a sequence of LP relaxations, we get both lower and upper bounds on the partition function, which hold with high probability and are much tighter than those obtained with variational methods.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {202–211},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023660,
author = {Feldman, Zohar and Domshlak, Carmel},
title = {Monte-Carlo Planning: Theoretically Fast Convergence Meets Practical Efficiency},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Popular Monte-Carlo tree search (MCTS) algorithms for online planning, such as e-greedy tree search and UCT, aim at rapidly identifying a reasonably good action, but provide rather poor worst-case guarantees on performance improvement over time. In contrast, a recently introduced MCTS algorithm BRUE guarantees exponential-rate improvement over time, yet it is not geared towards identifying reasonably good choices right at the go. We take a stand on the individual strengths of these two classes of algorithms, and show how they can be effectively connected. We then rationalize a principle of "selective tree expansion", and suggest a concrete implementation of this principle within MCTS. The resulting algorithms favorably compete with other MCTS algorithms under short planning times, while preserving the attractive convergence properties of BRUE.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {212–221},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023661,
author = {Fu, Qiang and Wang, Huahua and Banerjee, Arindam},
title = {Bethe-ADMM for Tree Decomposition Based Parallel MAP Inference},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of maximum a posteriori (MAP) inference in discrete graphical models. We present a parallel MAP inference algorithm called Bethe-ADMM based on two ideas: tree-decomposition of the graph and the alternating direction method of multipliers (ADMM). However, unlike the standard ADMM, we use an inexact ADMM augmented with a Bethe-divergence based proximal function, which makes each subproblem in ADMM easy to solve in parallel using the sum-product algorithm. We rigorously prove global convergence of Bethe-ADMM. The proposed algorithm is extensively evaluated on both synthetic and real datasets to illustrate its effectiveness. Further, the parallel Bethe-ADMM is shown to scale almost linearly with increasing number of cores.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {222–231},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023662,
author = {Ganti, Ravi and Gray, Alexander G.},
title = {Building Bridges: Viewing Active Learning from the Multi-Armed Bandit Lens},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we propose a multi-armed bandit inspired, pool based active learning algorithm for the problem of binary classification. By carefully constructing an analogy between active learning and multi-armed bandits, we utilize ideas such as lower confidence bounds, and self-concordant regularization from the multi-armed bandit literature to design our proposed algorithm. Our algorithm is a sequential algorithm, which in each round assigns a sampling distribution on the pool, samples one point from this distribution, and queries the oracle for the label of this sampled point. The design of this sampling distribution is also inspired by the analogy between active learning and multi-armed bandits. We show how to derive lower confidence bounds required by our algorithm. Experimental comparisons to previously proposed active learning algorithms show superior performance on some standard UCI data-sets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {232–241},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023663,
author = {Geramifard, Alborz and Walsh, Thomas J. and Roy, Nicholas and How, Jonathan P.},
title = {Batch-IFDD for Representation Expansion in Large MDPs},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Matching pursuit (MP) methods are a promising class of feature construction algorithms for value function approximation. Yet existing MP methods require creating a pool of potential features, mandating expert knowledge or enumeration of a large feature pool, both of which hinder scalability. This paper introduces batch incremental feature dependency discovery (Batch-iFDD) as an MP method that inherits a provable convergence property. Additionally, Batch-iFDD does not require a large pool of features, leading to lower computational complexity. Empirical policy evaluation results across three domains with up to one million states highlight the scalability of Batch-iFDD over the previous state of the art MP algorithm.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {242–251},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023664,
author = {Gogate, Vibhav and Domingos, Pedro},
title = {Structured Message Passing},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we present structured message passing (SMP), a unifying framework for approximate inference algorithms that take advantage of structured representations such as algebraic decision diagrams and sparse hash tables. These representations can yield significant time and space savings over the conventional tabular representation when the message has several identical values (context-specific independence) or zeros (determinism) or both in its range. Therefore, in order to fully exploit the power of structured representations, we propose to artificially introduce context-specific independence and determinism in the messages. This yields a new class of powerful approximate inference algorithms which includes popular algorithms such as cluster-graph Belief propagation (BP), expectation propagation and particle BP as special cases. We show that our new algorithms introduce several interesting bias-variance trade-offs. We evaluate these trade-offs empirically and demonstrate that our new algorithms are more accurate and scalable than state-of-the-art techniques.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {252–261},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023665,
author = {Hajimirsadeghi, Hossein and Li, Jinling and Mori, Greg and Zaki, Mohamed and Sayed, Tarek},
title = {Multiple Instance Learning by Discriminative Training of Markov Networks},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce a graphical framework for multiple instance learning (MIL) based on Markov networks. This framework can be used to model the traditional MIL definition as well as more general MIL definitions. Different levels of ambiguity - the portion of positive instances in a bag - can be explored in weakly supervised data. To train these models, we propose a discriminative max-margin learning algorithm leveraging efficient inference for cardinality-based cliques. The efficacy of the proposed framework is evaluated on a variety of data sets. Experimental results verify that encoding or learning the degree of ambiguity can improve classification performance.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {262–271},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023666,
author = {Halpern, Yoni and Sontag, David},
title = {Unsupervised Learning of Noisy-or Bayesian Networks},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper considers the problem of learning the parameters in Bayesian networks of discrete variables with known structure and hidden variables. Previous approaches in these settings typically use expectation maximization; when the network has high treewidth, the required expectations might be approximated using Monte Carlo or variational methods. We show how to avoid inference altogether during learning by giving a polynomial-time algorithm based on the method-of-moments, building upon recent work on learning discrete-valued mixture models. In particular, we show how to learn the parameters for a family of bipartite noisy-or Bayesian networks. In our experimental results, we demonstrate an application of our algorithm to learning QMR-DT, a large Bayesian network used for medical diagnosis. We show that it is possible to fully learn the parameters of QMR-DT even when only the findings are observed in the training data (ground truth diseases unknown).},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {272–281},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023667,
author = {Hensman, James and Fusi, Nicol\`{o} and Lawrence, Neil D.},
title = {Gaussian Processes for Big Data},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be variationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our approach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {282–290},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023668,
author = {Honorio, Jean and Jaakkola, Tommi},
title = {Inverse Covariance Estimation for High-Dimensional Data in Linear Time and Space: Spectral Methods for Riccati and Sparse Models},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose maximum likelihood estimation for learning Gaussian graphical models with a Gaussian (ℓ22) prior on the parameters. This is in contrast to the commonly used Laplace (ℓ1) prior for encouraging sparseness. We show that our optimization problem leads to a Riccati matrix equation, which has a closed form solution. We propose an efficient algorithm that performs a singular value decomposition of the training data. Our algorithm is O(NT2)-time and O(NT)-space for N variables and T samples. Our method is tailored to high-dimensional problems (N ≫ T), in which sparseness promoting methods become intractable. Furthermore, instead of obtaining a single solution for a specific regularization parameter, our algorithm finds the whole solution path. We show that the method has logarithmic sample complexity under the spiked covariance model. We also propose sparsification of the dense solution with provable performance guarantees. We provide techniques for using our learnt models, such as removing unimportant variables, computing likelihoods and conditional distributions. Finally, we show promising results in several gene expressions datasets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {291–300},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023669,
author = {Hyttinen, Antti and Hoyer, Patrik O. and Eberhardt, Frederick and J\"{a}rvisalo, Matti},
title = {Discovering Cyclic Causal Models with Latent Variables: A General SAT-Based Procedure},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a very general approach to learning the structure of causal models based on d-separation constraints, obtained from any given set of overlapping passive observational or experimental data sets. The procedure allows for both directed cycles (feedback loops) and the presence of latent variables. Our approach is based on a logical representation of causal pathways, which permits the integration of quite general background knowledge, and inference is performed using a Boolean satisfiability (SAT) solver. The procedure is complete in that it exhausts the available information on whether any given edge can be determined to be present or absent, and returns "unknown" otherwise. Many existing constraint-based causal discovery algorithms can be seen as special cases, tailored to circumstances in which one or more restricting assumptions apply. Simulations illustrate the effect of these assumptions on discovery and how the present algorithm scales.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {301–310},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023670,
author = {Iwata, Tomoharu and Duvenaud, David and Ghahramani, Zoubin},
title = {Warped Mixtures for Nonparametric Cluster Shapes},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A mixture of Gaussians fit to a single curved or heavy-tailed cluster will report that the data contains many clusters. To produce more appropriate clusterings, we introduce a model which warps a latent mixture of Gaussians to produce nonparametric cluster shapes. The possibly low-dimensional latent mixture model allows us to summarize the properties of the high-dimensional clusters (or density manifolds) describing the data. The number of manifolds, as well as the shape and dimension of each manifold is automatically inferred. We derive a simple inference scheme for this model which analytically integrates out both the mixture parameters and the warping function. We show that our model is effective for density estimation, performs better than infinite Gaussian mixture models at recovering the true number of clusters, and produces interpretable summaries of high-dimensional datasets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {311–320},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023671,
author = {Iyer, Rishabh and Bilmes, Jeff},
title = {The Lov\'{a}Sz-Bregman Divergence and Connections to Rank Aggregation, Clustering, and Web Ranking},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We extend the recently introduced theory of Lov\'{a}sz Bregman (LB) divergences [19] in several ways. We show that they represent a distortion between a "score" and an "ordering", thus providing a new view of rank aggregation and order based clustering with interesting connections to web ranking. We show how the LB divergences have a number of properties akin to many permutation based metrics, and in fact have as special cases forms very similar to the Kendall-τ metric. We also show how the LB divergences subsume a number of commonly used ranking measures in information retrieval, like NDCG [22] and AUC [35]. Unlike the traditional permutation based metrics, however, the LB divergence naturally captures a notion of "confidence" in the orderings, thus providing a new representation to applications involving aggregating scores as opposed to just orderings. We show how a number of recently used web ranking models are forms of Lov\'{a}sz Bregman rank aggregation and also observe that a natural form of Mallow's model using the LB divergence has been used as conditional ranking models for the "Learning to Rank" problem.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {321–330},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023672,
author = {Khaled, Arindam and Hansen, Eric A. and Yuan, Changhe},
title = {Solving Limited-Memory Influence Diagrams Using Branch-and-Bound Search},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A limited-memory influence diagram (LIMID) generalizes a traditional influence diagram by relaxing the assumptions of regularity and no-forgetting, allowing a wider range of decision problems to be modeled. Algorithms for solving traditional influence diagrams are not easily generalized to solve LIMIDs, however, and only recently have exact algorithms for solving LIMIDs been developed. In this paper, we introduce an exact algorithm for solving LIMIDs that is based on branch-and-bound search. Our approach is related to the approach of solving an influence diagram by converting it to an equivalent decision tree, with the difference that the LIMID is converted to a much smaller decision graph that can be searched more efficiently.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {331–340},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023673,
author = {Koyejo, Oluwasanmi and Ghosh, Joydeep},
title = {Constrained Bayesian Inference for Low Rank Multitask Learning},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a novel approach for constrained Bayesian inference. Unlike current methods, our approach does not require convexity of the constraint set. We reduce the constrained variational inference to a parametric optimization over the feasible set of densities and propose a general recipe for such problems. We apply the proposed constrained Bayesian inference approach to multitask learning subject to rank constraints on the weight matrix. Further, constrained parameter estimation is applied to recover the sparse conditional independence structure encoded by prior precision matrices. Our approach is motivated by reverse inference for high dimensional functional neuroimaging, a domain where the high dimensionality and small number of examples requires the use of constraints to ensure meaningful and effective models. For this application, we propose a model that jointly learns a weight matrix and the prior inverse covariance structure between different tasks. We present experimental validation showing that the proposed approach outperforms strong baseline models in terms of predictive performance and structure recovery.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {341–350},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023674,
author = {Kumar, Akshat and Sheldon, Daniel and Srivastava, Biplav},
title = {Collective Diffusion over Networks: Models and Inference},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Diffusion processes in networks are increasingly used to model the spread of information and social influence. In several applications in computational sustainability such as the spread of wildlife, infectious diseases and traffic mobility pattern, the observed data often consists of only aggregate information. In this work, we present new models that generalize standard diffusion processes to such collective settings. We also present optimization based techniques that can accurately learn the underlying dynamics of the given contagion process, including the hidden network structure, by only observing the time a node becomes active and the associated aggregate information. Empirically, our technique is highly robust and accurately learns network structure with more than 90% recall and precision. Results on real-world flu spread data in the US confirm that our technique can also accurately model infectious disease spread.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {351–360},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023675,
author = {Lee, Sanghack and Honavar, Vasant},
title = {Causal Transportability of Experiments on Controllable Subsets of Variables: <i>Z</i>-Transportability},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce z-transportability, the problem of estimating the causal effect of a set of variables X on another set of variables Y in a target domain from experiments on any subset of controllable variables Z where Z is an arbitrary subset of observable variables V in a source domain. Z-Transportability generalizes z-identifiability, the problem of estimating in a given domain the causal effect of X on Y from surrogate experiments on a set of variables Z such that Z is disjoint from X. z-Transportability also generalizes transportability which requires that the causal effect of X on Y in the target domain be estimable from experiments on any subset of all observable variables in the source domain. We first generalize z-identifiability to allow cases where Z is not necessarily disjoint from X. Then, we establish a necessary and sufficient condition for z-transportability in terms of generalized z-identifiability and transportability. We provide a sound and complete algorithm that determines whether a causal effect is z-transportable; and if it is, produces a transport formula, that is, a recipe for estimating the causal effect of X on Y in the target domain using information elicited from the results of experimental manipulations of Z in the source domain and observational data from the target domain. Our results also show that do -calculus is complete for z-transportability.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {361–370},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023676,
author = {Maier, Marc and Marazopoulou, Katerina and Arbour, David and Jensen, David},
title = {A Sound and Complete Algorithm for Learning Causal Models from Relational Data},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The PC algorithm learns maximally oriented causal Bayesian networks. However, there is no equivalent complete algorithm for learning the structure of relational models, a more expressive generalization of Bayesian networks. Recent developments in the theory and representation of relational models support lifted reasoning about conditional independence. This enables a powerful constraint for orienting bivariate dependencies and forms the basis of a new algorithm for learning structure. We present the relational causal discovery (RCD) algorithm that learns causal relational models. We prove that RCD is sound and complete, and we present empirical results that demonstrate effectiveness.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {371–380},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023677,
author = {Malone, Brandon and Yuan, Changhe},
title = {Evaluating Anytime Algorithms for Learning Optimal Bayesian Networks},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Exact algorithms for learning Bayesian networks guarantee to find provably optimal networks. However, they may fail in difficult learning tasks due to limited time or memory. In this research we adapt several anytime heuristic search-based algorithms to learn Bayesian networks. These algorithms find high-quality solutions quickly, and continually improve the incumbent solution or prove its optimality before resources are exhausted. Empirical results show that the anytime window A* algorithm usually finds higher-quality, often optimal, networks more quickly than other approaches. The results also show that, surprisingly, while generating networks with few parents per variable are structurally simpler, they are harder to learn than complex generating networks with more parents per variable.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {381–390},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023678,
author = {Mau\'{a}, Denis D. and de Campos, Cassio P. and Benavoli, Alessio and Antonucci, Alessandro},
title = {On the Complexity of Strong and Epistemic Credal Networks},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Credal networks are graph-based statistical models whose parameters take values in a set, instead of being sharply specified as in traditional statistical models (e.g., Bayesian networks). The computational complexity of inferences on such models depends on the irrelevance/independence concept adopted. In this paper, we study inferential complexity under the concepts of epistemic irrelevance and strong independence. We show that inferences under strong independence are NP-hard even in trees with ternary variables. We prove that under epistemic irrelevance the polynomial time complexity of inferences in credal trees is not likely to extend to more general models (e.g. singly connected networks). These results clearly distinguish networks that admit efficient inferences and those where inferences are most likely hard, and settle several open questions regarding computational complexity.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {391–400},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023679,
author = {McInerney, James and Rogers, Alex and Jennings, Nicholas R.},
title = {Learning Periodic Human Behaviour Models from Sparse Data for Crowdsourcing Aid Delivery in Developing Countries},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In many developing countries, half the population lives in rural locations, where access to essentials such as school materials, mosquito nets, and medical supplies is restricted. We propose an alternative method of distribution (to standard road delivery) in which the existing mobility habits of a local population are leveraged to deliver aid, which raises two technical challenges in the areas optimisation and learning. For optimisation, a standard Markov decision process applied to this problem is intractable, so we provide an exact formulation that takes advantage of the periodicities in human location behaviour. To learn such behaviour models from sparse data (i.e., cell tower observations), we develop a Bayesian model of human mobility. Using real cell tower data of the mobility behaviour of 50,000 individuals in Ivory Coast, we find that our model outperforms the state of the art approaches in mobility prediction by at least 25% (in held-out data likelihood). Furthermore, when incorporating mobility prediction with our MDP approach, we find a 81.3% reduction in total delivery time versus routine planning that minimises just the number of participants in the solution path.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {401–410},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023680,
author = {Meshi, Ofer and Eban, Elad and Elidan, Gal and Globerson, Amir},
title = {Learning Max-Margin Tree Predictors},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Structured prediction is a powerful framework for coping with joint prediction of interacting outputs. A central difficulty in using this framework is that often the correct label dependence structure is unknown. At the same time, we would like to avoid an overly complex structure that will lead to intractable prediction. In this work we address the challenge of learning tree structured predictive models that achieve high accuracy while at the same time facilitate efficient (linear time) inference. We start by proving that this task is in general NP-hard, and then suggest an approximate alternative. Our CRANK approach relies on a novel Circuit-RANK regularizer that penalizes non-tree structures and can be optimized using a convex-concave procedure. We demonstrate the effectiveness of our approach on several domains and show that its accuracy matches that of fully connected models, while performing prediction substantially faster.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {411–420},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023681,
author = {Mezuman, Elad and Tarlow, Daniel and Globerson, Amir and Weiss, Yair},
title = {Tighter Linear Program Relaxations for High Order Graphical Models},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Graphical models with High Order Potentials (HOPs) have received considerable interest in recent years. While there are a variety of approaches to inference in these models, nearly all of them amount to solving a linear program (LP) relaxation with unary consistency constraints between the HOP and the individual variables. In many cases, the resulting relaxations are loose, and in these cases the results of inference can be poor. It is thus desirable to look for more accurate ways of performing inference. In this work, we study the LP relaxations that result from enforcing additional consistency constraints between the HOP and the rest of the model. We address theoretical questions about the strength of the resulting relaxations compared to the relaxations that arise in standard approaches, and we develop practical and efficient message passing algorithms for optimizing the LPs. Empirically, we show that the LPs with additional consistency constraints lead to more accurate inference on some challenging problems that include a combination of low order and high order terms.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {421–430},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023682,
author = {Mooij, Joris M. and Heskes, Tom},
title = {Cyclic Causal Discovery from Continuous Equilibrium Data},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a method for learning cyclic causal models from a combination of observational and interventional equilibrium data. Novel aspects of the proposed method are its ability to work with continuous data (without assuming linearity) and to deal with feedback loops. Within the context of biochemical reactions, we also propose a novel way of modeling interventions that modify the activity of compounds instead of their abundance. For computational reasons, we approximate the nonlinear causal mechanisms by (coupled) local linearizations, one for each experimental condition. We apply the method to reconstruct a cellular signaling network from the flow cytometry data measured by Sachs et al. (2005). We show that our method finds evidence in the data for feedback loops and that it gives a more accurate quantitative description of the data at comparable model complexity.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {431–439},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023683,
author = {Mooij, Joris M. and Janzing, Dominik and Sch\"{o}lkopf, Bernhard},
title = {From Ordinary Differential Equations to Structural Causal Models: The Deterministic Case},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We show how, and under which conditions, the equilibrium states of a first-order Ordinary Differential Equation (ODE) system can be described with a deterministic Structural Causal Model (SCM). Our exposition sheds more light on the concept of causality as expressed within the framework of Structural Causal Models, especially for cyclic models.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {440–448},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023684,
author = {Muandet, Krikamol and Sch\"{o}lkopf, Bernhard},
title = {One-Class Support Measure Machines for Group Anomaly Detection},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose one-class support measure machines (OCSMMs) for group anomaly detection. Unlike traditional anomaly detection, OCSMMs aim at recognizing anomalous aggregate behaviors of data points. The OCSMMs generalize well-known one-class support vector machines (OCSVMs) to a space of probability measures. By formulating the problem as quantile estimation on distributions, we can establish interesting connections to the OCSVMs and variable kernel density estimators (VKDEs) over the input space on which the distributions are defined, bridging the gap between large-margin methods and kernel density estimators. In particular, we show that various types of VKDEs can be considered as solutions to a class of regularization problems studied in this paper. Experiments on Sloan Digital Sky Survey dataset and High Energy Particle Physics dataset demonstrate the benefits of the proposed framework in real-world applications.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {449–458},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023685,
author = {Nagano, Kiyohito and Kawahara, Yoshinobu},
title = {Structured Convex Optimization under Submodular Constraints},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A number of discrete and continuous optimization problems in machine learning are related to convex minimization problems under submodular constraints. In this paper, we deal with a submodular function with a directed graph structure, and we show that a wide range of convex optimization problems under submodular constraints can be solved much more efficiently than general submodular optimization methods by a reduction to a maximum flow problem. Furthermore, we give some applications, including sparse optimization methods, in which the proposed methods are effective. Additionally, we evaluate the performance of the proposed method through computational experiments.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {459–468},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023686,
author = {Niinim\"{a}ki, Teppo and Koivisto, Mikko},
title = {Treedy: A Heuristic for Counting and Sampling Subsets},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Consider a collection of weighted subsets of a ground set N. Given a query subset Q of N, how fast can one (1) find the weighted sum over all subsets of Q, and (2) sample a subset of Q proportionally to the weights? We present a tree-based greedy heuristic, Treedy, that for a given positive tolerance d answers such counting and sampling queries to within a guaranteed relative error d and total variation distance d, respectively. Experimental results on artificial instances and in application to Bayesian structure discovery in Bayesian networks show that approximations yield dramatic savings in running time compared to exact computation, and that Treedy typically outperforms a previously proposed sorting-based heuristic.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {469–477},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023687,
author = {Niu, Shuzi and Lan, Yanyan and Guo, Jiafeng and Cheng, Xueqi},
title = {Stochastic Rank Aggregation},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper addresses the problem of rank aggregation, which aims to find a consensus ranking among multiple ranking inputs. Traditional rank aggregation methods are deterministic, and can be categorized into explicit and implicit methods depending on whether rank information is explicitly or implicitly utilized. Surprisingly, experimental results on real data sets show that explicit rank aggregation methods would not work as well as implicit methods, although rank information is critical for the task. Our analysis indicates that the major reason might be the unreliable rank information from incomplete ranking inputs. To solve this problem, we propose to incorporate uncertainty into rank aggregation and tackle the problem in both unsupervised and supervised scenario. We call this novel framework stochastic rank aggregation (St.Agg for short). Specifically, we introduce a prior distribution on ranks, and transform the ranking functions or objectives in traditional explicit methods to their expectations over this distribution. Our experiments on benchmark data sets show that the proposed St.Agg outperforms the baselines in both un-supervised and supervised scenarios.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {478–487},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023688,
author = {Oren, Sigal and Schapira, Michael and Tennenholtz, Moshe},
title = {Pay or Play},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce the class of pay or play games, which captures scenarios in which each decision maker is faced with a choice between two actions: one with a fixed payoff and another with a payoff dependent on others' selected actions. This is, arguably, the simplest setting that models selection among certain and uncertain outcomes in a multi-agent system. We study the properties of equilibria in such games from both a game-theoretic perspective and a computational perspective. Our main positive result establishes the existence of a semi-strong equilibrium in every such game. We show that although simple, pay or play games contain well-studied environments, e.g., vaccination games. We discuss the interesting implications of our results for these environments.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {488–497},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023689,
author = {Pacer, Michael and Williams, Joseph and Chen, Xi and Lombrozo, Tania and Griffiths, Thomas L.},
title = {Evaluating Computational Models of Explanation Using Human Judgments},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We evaluate four computational models of explanation in Bayesian networks by comparing model predictions to human judgments. In two experiments, we present human participants with causal structures for which the models make divergent predictions and either solicit the best explanation for an observed event (Experiment 1) or have participants rate provided explanations for an observed event (Experiment 2). Across two versions of two causal structures and across both experiments, we find that the Causal Explanation Tree and Most Relevant Explanation models provide better fits to human data than either Most Probable Explanation or Explanation Tree models. We identify strengths and shortcomings of these models and what they can reveal about human explanation. We conclude by suggesting the value of pursuing computational and psychological investigations of explanation in parallel.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {498–507},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023690,
author = {Perny, Patrice and Weng, Paul and Goldsmith, Judy and Hanna, Josiah P.},
title = {Approximation of Lorenz-Optimal Solutions in Multiobjective Markov Decision Processes},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper is devoted to fair optimization in Multiobjective Markov Decision Processes (MOMDPs). A MOMDP is an extension of the MDP model for planning under uncertainty while trying to optimize several reward functions simultaneously. This applies to multiagent problems when rewards define individual utility functions, or in multicriteria problems when rewards refer to different features. In this setting, we study the determination of policies leading to Lorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Pareto dominance that was introduced in Social Choice for the measurement of inequalities. In this paper, we introduce methods to efficiently approximate the sets of Lorenz-non-dominated solutions of infinite-horizon, discounted MOMDPs. The approximations are polynomial-sized subsets of those solutions.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {508–517},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023691,
author = {Marecki, Janusz and Petrik, Marek and Subramanian, Dharmashankar},
title = {Solution Methods for Constrained Markov Decision Process with Continuous Probability Modulation},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose solution methods for previously-unsolved constrained MDPs in which actions can continuously modify the transition probabilities within some acceptable sets. While many methods have been proposed to solve regular MDPs with large state sets, there are few practical approaches for solving constrained MDPs with large action sets. In particular, we show that the continuous action sets can be replaced by their extreme points when the rewards are linear in the modulation. We also develop a tractable optimization formulation for concave reward functions and, surprisingly, also extend it to non-concave reward functions by using their concave envelopes. We evaluate the effectiveness of the approach on the problem of managing delinquencies in a portfolio of loans.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {518–526},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023692,
author = {Quadrianto, Novi and Sharmanska, Viktoriia and Knowles, David A. and Ghahramani, Zoubin},
title = {The Supervised IBP: Neighbourhood Preserving Infinite Latent Feature Models},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a probabilistic model to infer supervised latent variables in the Hamming space from observed data. Our model allows simultaneous inference of the number of binary latent variables, and their values. The latent variables preserve neighbourhood structure of the data in a sense that objects in the same semantic concept have similar latent values, and objects in different concepts have dissimilar latent values. We formulate the supervised infinite latent variable problem based on an intuitive principle of pulling objects together if they are of the same type, and pushing them apart if they are not. We then combine this principle with a flexible Indian Buffet Process prior on the latent variables. We show that the inferred supervised latent variables can be directly used to perform a nearest neighbour search for the purpose of retrieval. We introduce a new application of dynamically extending hash codes, and show how to effectively couple the structure of the hash codes with continuously growing structure of the neighbourhood preserving infinite latent feature space.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {527–536},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023693,
author = {Ross, Stephane and Mineiro, Paul and Langford, John},
title = {Normalized Online Learning},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce online learning algorithms which are independent of feature scales, proving regret bounds dependent on the ratio of scales existent in the data rather than the absolute scale. This has several useful effects: there is no need to prenormalize data, the test-time and test-space complexity are reduced, and the algorithms are more robust.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {537–545},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023694,
author = {Ruozzi, Nicholas},
title = {Beyond Log-Supermodularity: Lower Bounds and the Bethe Partition Function},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A recent result has demonstrated that the Bethe partition function always lower bounds the true partition function of binary, log-supermodular graphical models. We demonstrate that these results can be extended to other interesting classes of graphical models that are not necessarily binary or log-supermodular: the ferromagnetic Potts model with a uniform external field and its generalizations and special classes of weighted graph homomorphism problems.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {546–555},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023695,
author = {Sgouritsa, Eleni and Janzing, Dominik and Peters, Jonas and Sch\"{o}lkopf, Bernhard},
title = {Identifying Finite Mixtures of Nonparametric Product Distributions and Causal Inference of Confounders},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a kernel method to identify finite mixtures of nonparametric product distributions. It is based on a Hilbert space embedding of the joint distribution. The rank of the constructed tensor is equal to the number of mixture components. We present an algorithm to recover the components by partitioning the data points into clusters such that the variables are jointly conditionally independent given the cluster. This method can be used to identify finite confounders.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {556–575},
numpages = {20},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023696,
author = {Shah, Amar and Ghahramani, Zoubin},
title = {Determinantal Clustering Process - a Nonparametric Bayesian Approach to Kernel Based Semi-Supervised Clustering},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Semi-supervised clustering is the task of clustering data points into clusters where only a fraction of the points are labelled. The true number of clusters in the data is often unknown and most models require this parameter as an input. Dirichlet process mixture models are appealing as they can infer the number of clusters from the data. However, these models do not deal with high dimensional data well and can encounter difficulties in inference. We present a novel nonparameteric Bayesian method to cluster data points without the need to prespecify the number of clusters or to model complicated densities from which data points are assumed to be generated from. The key insight is to use determinants of submatrices of a kernel matrix as a measure of how close together a set of points are. We explore some theoretical properties of the model and derive a natural Gibbs based algorithm with MCMC hyper-parameter learning. We test the model on various synthetic and real world data sets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {566–575},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023697,
author = {Shpitser, Ilya and Evans, Robin J. and Richardson, Thomas S. and Robins, James M.},
title = {Sparse Nested Markov Models with Log-Linear Parameters},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Hidden variables are ubiquitous in practical data analysis, and therefore modeling marginal densities and doing inference with the resulting models is an important problem in statistics, machine learning, and causal inference. Recently, a new type of graphical model, called the nested Markov model, was developed which captures equality constraints found in marginals of directed acyclic graph (DAG) models. Some of these constraints, such as the so called 'Verma constraint', strictly generalize conditional independence. To make modeling and inference with nested Markov models practical, it is necessary to limit the number of parameters in the model, while still correctly capturing the constraints in the marginal of a DAG model. Placing such limits is similar in spirit to sparsity methods for undirected graphical models, and regression models. In this paper, we give a log-linear parameterization which allows sparse modeling with nested Markov models. We illustrate the advantages of this parameterization with a simulation study.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {576–585},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023698,
author = {Sindhwani, Vikas and Minh, Ha Quang and Lozano, Aur\'{e}lie C.},
title = {Scalable Matrix-Valued Kernel Learning for High-Dimensional Nonlinear Multivariate Regression and Granger Causality},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a general matrix-valued multiple kernel learning framework for high-dimensional nonlinear multivariate regression problems. This framework allows a broad class of mixed norm regularizers, including those that induce sparsity, to be imposed on a dictionary of vector-valued Reproducing Kernel Hilbert Spaces. We develop a highly scalable and eigendecomposition-free algorithm that orchestrates two inexact solvers for simultaneously learning both the input and output components of separable matrix-valued kernels. As a key application enabled by our framework, we show how high-dimensional causal inference tasks can be naturally cast as sparse function estimation problems, leading to novel nonlinear extensions of a class of Graphical Granger Causality techniques. Our algorithmic developments and extensive empirical studies are complemented by theoretical analyses in terms of Rademacher generalization bounds.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {586–595},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023699,
author = {Soufiani, Hossein Azari and Parkes, David C. and Xia, Lirong},
title = {Preference Elicitation for General Random Utility Models},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper discusses General Random Utility Models (GRUMs). These are a class of parametric models that generate partial ranks over alternatives given attributes of agents and alternatives. We propose two preference elicitation scheme for GRUMs developed from principles in Bayesian experimental design, one for social choice and the other for personalized choice. We couple this with a general Monte-Carlo-Expectation-Maximization (MC-EM) based algorithm for MAP inference under GRUMs. We also prove uni-modality of the likelihood functions for a class of GRUMs. We examine the performance of various criteria by experimental studies, which show that the proposed elicitation scheme increases the precision of estimation.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {596–605},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023700,
author = {Spirtes, Peter},
title = {Calculation of Entailed Rank Constraints in Partially Non-Linear and Cyclic Models},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The Trek Separation Theorem (Sullivant et al. 2010) states necessary and sufficient conditions for a linear directed acyclic graphical model to entail for all possible values of its linear coefficients that the rank of various sub-matrices of the covariance matrix is less than or equal to n, for any given n. In this paper, I extend the Trek Separation Theorem in two ways: I prove that the same necessary and sufficient conditions apply even when the generating model is partially non-linear and contains some cycles. This justifies application of constraint-based causal search algorithms to data generated by a wider class of causal models that may contain non-linear and cyclic relations among the latent variables.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {606–615},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023701,
author = {Srivastava, Nitish and Salakhutdinov, Ruslan and Hinton, Geoffrey},
title = {Modeling Documents with a Deep Boltzmann Machine},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce a type of Deep Boltzmann Machine (DBM) that is suitable for extracting distributed semantic representations from a large unstructured collection of documents. We overcome the apparent difficulty of training a DBM with judicious parameter tying. This enables an efficient pretraining algorithm and a state initialization scheme for fast inference. The model can be trained just as efficiently as a standard Restricted Boltzmann Machine. Our experiments show that the model assigns better log probability to unseen data than the Replicated Softmax model. Features extracted from our model outperform LDA, Replicated Softmax, and DocNADE models on document retrieval and document classification tasks.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {616–624},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023702,
author = {Tenzer, Yaniv and Elidan, Gal},
title = {Speedy Model Selection (SMS) for Copula Models},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We tackle the challenge of efficiently learning the structure of expressive multivariate real-valued densities of copula graphical models. We start by theoretically substantiating the conjecture that for many copula families the magnitude of Spearman's rank correlation coefficient is monotonic in the expected contribution of an edge in network, namely the negative copula entropy. We then build on this theory and suggest a novel Bayesian approach that makes use of a prior over values of Spearman's rho for learning copula-based models that involve a mix of copula families. We demonstrate the generalization effectiveness of our highly efficient approach on sizable and varied real-life datasets.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {625–634},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023703,
author = {Tossou, Aristide C. Y. and Dimitrakakis, Christos},
title = {Probabilistic Inverse Reinforcement Learning in Unknown Environments},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of learning by demonstration from agents acting in unknown stochastic Markov environments or games. Our aim is to estimate agent preferences in order to construct improved policies for the same task that the agents are trying to solve. To do so, we extend previous probabilistic approaches for inverse reinforcement learning in known MDPs to the case of unknown dynamics or opponents. We do this by deriving two simplified probabilistic models of the demonstrator's policy and utility. For tractability, we use maximum a posteriori estimation rather than full Bayesian inference. Under a flat prior, this results in a convex optimisation problem. We find that the resulting algorithms are highly competitive against a variety of other methods for inverse reinforcement learning that do have knowledge of the dynamics.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {635–643},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023704,
author = {Tripp, Charles and Shachter, Ross},
title = {Approximate Kalman Filter Q-Learning for Continuous State-Space MDPs},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We seek to learn an effective policy for a Markov Decision Process (MDP) with continuous states via Q-Learning. Given a set of basis functions over state action pairs we search for a corresponding set of linear weights that minimizes the mean Bellman residual. Our algorithm uses a Kalman filter model to estimate those weights and we have developed a simpler approximate Kalman filter model that outperforms the current state of the art projected TD-Learning methods on several standard benchmark problems.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {644–653},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023705,
author = {Valko, Michal and Korda, Nathan and Munos, R\'{e}mi and Flaounas, Ilias and Cristianini, Nello},
title = {Finite-Time Analysis of Kernelised Contextual Bandits},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We tackle the problem of online reward maximisation over a large finite set of actions described by their contexts. We focus on the case when the number of actions is too big to sample all of them even once. However we assume that we have access to the similarities between actions' contexts and that the expected reward is an arbitrary linear function of the contexts' images in the related reproducing kernel Hilbert space (RKHS). We propose KernelUCB, a kernelised UCB algorithm, and give a cumulative regret bound through a frequentist analysis. For contextual bandits, the related algorithm GP-UCB turns out to be a special case of our algorithm, and our finite-time analysis improves the regret bound of GP-UCB for the agnostic case, both in the terms of the kernel-dependent quantity and the RKHS norm of the reward function. Moreover, for the linear kernel, our regret bound matches the lower bound for contextual linear bandits.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {654–663},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023706,
author = {Venugopal, Deepak and Gogate, Vibhav},
title = {Dynamic Blocking and Collapsing for Gibbs Sampling},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we investigate combining blocking and collapsing - two widely used strategies for improving the accuracy of Gibbs sampling - in the context of probabilistic graphical models (PGMs). We show that combining them is not straight-forward because collapsing (or eliminating variables) introduces new dependencies in the PGM and in computation-limited settings, this may adversely affect blocking. We therefore propose a principled approach for tackling this problem. Specifically, we develop two scoring functions, one each for blocking and collapsing, and formulate the problem of partitioning the variables in the PGM into blocked and collapsed subsets as simultaneously maximizing both scoring functions (i.e., a multi-objective optimization problem). We propose a dynamic, greedy algorithm for approximately solving this intractable optimization problem. Our dynamic algorithm periodically updates the partitioning into blocked and collapsed variables by leveraging correlation statistics gathered from the generated samples and enables rapid mixing by blocking together and collapsing highly correlated variables. We demonstrate experimentally the clear benefit of our dynamic approach: as more samples are drawn, our dynamic approach significantly outperforms static graph-based approaches by an order of magnitude in terms of accuracy.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {664–673},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023707,
author = {Vianna, Luis Gustavo Rocha and Vianna, Rocha and Sanner, Scott and de Barros, Leliane Nunes},
title = {Bounded Approximate Symbolic Dynamic Programming for Hybrid MDPs},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recent advances in symbolic dynamic programming (SDP) combined with the extended algebraic decision diagram (XADD) data structure have provided exact solutions for mixed discrete and continuous (hybrid) MDPs with piecewise linear dynamics and continuous actions. Since XADD-based exact solutions may grow intractably large for many problems, we propose a bounded error compression technique for XADDs that involves the solution of a constrained bilinear saddle point problem. Fortuitously, we show that given the special structure of this problem, it can be expressed as a bilevel linear programming problem and solved to optimality in finite time via constraint generation, despite having an infinite set of constraints. This solution permits the use of efficient linear program solvers for XADD compression and enables a novel class of bounded approximate SDP algorithms for hybrid MDPs that empirically offers order-of-magnitude speedups over the exact solution in exchange for a small approximation error.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {674–683},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023708,
author = {Weller, Adrian and Jebara, Tony},
title = {On MAP Inference by MWSS on Perfect Graphs},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Finding the most likely (MAP) configuration of a Markov random field (MRF) is NP-hard in general. A promising, recent technique is to reduce the problem to finding a maximum weight stable set (MWSS) on a derived weighted graph, which if perfect, allows inference in polynomial time. We derive new results for this approach, including a general decomposition theorem for MRFs of any order and number of labels, extensions of results for binary pairwise models with submodular cost functions to higher order, and an exact characterization of which binary pairwise MRFs can be efficiently solved with this method. This defines the power of the approach on this class of models, improves our toolbox and expands the range of tractable models.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {684–693},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023709,
author = {Xie, Pengtao and Xing, Eric P.},
title = {Integrating Document Clustering and Topic Modeling},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Document clustering and topic modeling are two closely related tasks which can mutually benefit each other. Topic modeling can project documents into a topic space which facilitates effective document clustering. Cluster labels discovered by document clustering can be incorporated into topic models to extract local topics specific to each cluster and global topics shared by all clusters. In this paper, we propose a multi-grain clustering topic model (MGCTM) which integrates document clustering and topic modeling into a unified framework and jointly performs the two tasks to achieve the overall best performance. Our model tightly couples two components: a mixture component used for discovering latent groups in document collection and a topic model component used for mining multi-grain topics including local topics specific to each cluster and global topics shared across clusters. We employ variational inference to approximate the posterior of hidden variables and learn model parameters. Experiments on two datasets demonstrate the effectiveness of our model.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {694–703},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023710,
author = {Zhao, Peilin and Hoi, Steven C. H. and Zhuang, Jinfeng},
title = {Active Learning with Expert Advice},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Conventional learning with expert advice methods assume a learner is always receiving the outcome (e.g., class labels) of every incoming training instance at the end of each trial. In real applications, acquiring the outcome from oracle can be costly or time consuming. In this paper, we address a new problem of active learning with expert advice, where the outcome of an instance is disclosed only when it is requested by the online learner. Our goal is to learn an accurate prediction model by asking the oracle the number of questions as small as possible. To address this challenge, we propose a framework of active forecasters for online active learning with expert advice, which attempts to extend two regular forecasters, i.e., Exponentially Weighted Average Forecaster and Greedy Forecaster, to tackle the task of active learning with expert advice. We prove that the proposed algorithms satisfy the Hannan consistency under some proper assumptions, and validate the efficacy of our technique by an extensive set of experiments.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {704–713},
numpages = {10},
location = {Bellevue, WA},
series = {UAI'13}
}

@inproceedings{10.5555/3023638.3023711,
author = {Zhang, Chao},
title = {Bennett-Type Generalization Bounds: Large-Deviation Case and Faster Rate of Convergence},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we present the Bennett-type generalization bounds of the learning process for i.i.d. samples, and then show that the generalization bounds have a faster rate of convergence than the traditional results. In particular, we first develop two types of Bennett-type deviation inequality for the i.i.d. learning process: one provides the generalization bounds based on the uniform entropy number; the other leads to the bounds based on the Rademacher complexity. We then adopt a new method to obtain the alternative expressions of the Bennett-type generalization bounds, which imply that the bounds have a faster rate o(N-½) of convergence than the traditional results O(N-½). Additionally, we find that the rate of the bounds will become faster in the large-deviation case, which refers to a situation where the empirical risk is far away from (at least not close to) the expected risk. Finally, we analyze the asymptotical convergence of the learning process and compare our analysis with the existing results.},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {714–722},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

