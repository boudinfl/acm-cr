@inproceedings{10.5555/3020548.3020550,
author = {Amin, Kareem and Kearns, Michael and Syed, Umar},
title = {Graphical Models for Bandit Problems},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce a rich class of graphical models for multi-armed bandit problems that permit both the state or context space and the action space to be very large, yet succinctly specify the payoffs for any context-action pair. Our main result is an algorithm for such models whose regret is bounded by the number of parameters and whose running time depends only on the treewidth of the graph substructure induced by the action space.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {1–10},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020551,
author = {Apsel, Udi and Brafman, Ronen I.},
title = {Extended Lifted Inference with Joint Formulas},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The First-Order Variable Elimination (FOVE) algorithm allows exact inference to be applied directly to probabilistic relational models, and has proven to be vastly superior to the application of standard inference methods on a grounded propositional model. Still, FOVE operators can be applied under restricted conditions, often forcing one to resort to propositional inference. This paper aims to extend the applicability of FOVE by providing two new model conversion operators: the first and the primary is joint formula conversion and the second is just-different counting conversion. These new operations allow efficient inference methods to be applied directly on relational models, where no existing efficient method could be applied hitherto. In addition, aided by these capabilities, we show how to adapt FOVE to provide exact solutions to Maximum Expected Utility (MEU) queries over relational models for decision under uncertainty. Experimental evaluations show our algorithms to provide significant speedup over the alternatives.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {11–18},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020552,
author = {Asmuth, John and Littman, Michael},
title = {Learning is Planning: Near Bayes-Optimal Reinforcement Learning via Monte-Carlo Tree Search},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayes-optimal behavior, while well-defined, is often difficult to achieve. Recent advances in the use of Monte-Carlo tree search (MCTS) have shown that it is possible to act near-optimally in Markov Decision Processes (MDPs) with very large or infinite state spaces. Bayes-optimal behavior in an unknown MDP is equivalent to optimal behavior in the known belief-space MDP, although the size of this belief-space MDP grows exponentially with the amount of history retained, and is potentially infinite. We show how an agent can use one particular MCTS algorithm, Forward Search Sparse Sampling (FSSS), in an efficient way to act nearly Bayes-optimally for all but a polynomial number of steps, assuming that FSSS can be used to act efficiently in any possible underlying MDP.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {19–26},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020553,
author = {Bachrach, Yoram and Meir, Reshef and Feldman, Michal and Tennenholtz, Moshe},
title = {Solving Cooperative Reliability Games},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Cooperative games model the allocation of profit from joint actions, following considerations such as stability and fairness. We propose the reliability extension of such games, where agents may fail to participate in the game. In the reliability extension, each agent only "survives" with a certain probability, and a coalition's value is the probability that its surviving members would be a winning coalition in the base game. We study prominent solution concepts in such games, showing how to approximate the Shapley value and how to compute the core in games with few agent types. We also show that applying the reliability extension may stabilize the game, making the core non-empty even when the base game has an empty core.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {27–34},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020554,
author = {Bellala, Gowtham and Stanley, Jason and Scott, Clayton and Bhavnani, Suresh K.},
title = {Active Diagnosis via AUC Maximization: An Efficient Approach for Multiple Fault Identification in Large Scale, Noisy Networks},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The problem of active diagnosis arises in several applications such as disease diagnosis, and fault diagnosis in computer networks, where the goal is to rapidly identify the binary states of a set of objects (e.g., faulty or working) by sequentially selecting, and observing, (noisy) responses to binary valued queries. Current algorithms in this area rely on loopy belief propagation for active query selection. These algorithms have an exponential time complexity, making them slow and even intractable in large networks. We propose a rank-based greedy algorithm that sequentially chooses queries such that the area under the ROC curve of the rank-based output is maximized. The AUC criterion allows us to make a simplifying assumption that significantly reduces the complexity of active query selection (from exponential to near quadratic), with little or no compromise on the performance quality.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {35–42},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020555,
author = {Bijral, Avleen S. and Ratliff, Nathan and Srebro, Nathan},
title = {Semi-Supervised Learning with Density Based Distances},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a simple, yet effective, approach to Semi-Supervised Learning. Our approach is based on estimating density-based distances (DBD) using a shortest path calculation on a graph. These Graph-DBD estimates can then be used in any distance-based supervised learning method, such as Nearest Neighbor methods and SVMs with RBF kernels. In order to apply the method to very large data sets, we also present a novel algorithm which integrates nearest neighbor computations into the shortest path search and can find exact shortest paths even in extremely large dense graphs. Significant runtime improvement over the commonly used Laplacian regularization method is then shown on a large scale dataset.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {43–50},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020556,
author = {Blocker, Alexander W. and Airoldi, Edoardo M.},
title = {Deconvolution of Mixing Time Series on a Graph},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In many applications we are interested in making inference on latent time series from indirect measurements, which are often low-dimensional projections resulting from mixing oraggregation. Positron emission tomography, super-resolution, and network traffic monitoring are some examples. Inference in such settings requires solving a sequence of ill-posed inverse problems, yt = Axt, where the projection mechanism provides information on A. We consider problems in which A specifies mixing on a graph of times series that are bursty and sparse. We develop a multilevel state-space model for mixing times series and an efficient approach to inference. A simple model is used to calibrate regularization parameters that lead to efficient inference in the multilevel state-space model. We apply this method to the problem of estimating point-to-point traffic flows on a network from aggregate measurements. Our solution outperforms existing methods for this problem, and our two-stage approach suggests an efficient inference strategy for multilevel models of multivariate time series.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {51–60},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020557,
author = {Celikkaya, E. Busra and Shelton, Christian R. and Lam, William},
title = {Factored Filtering of Continuous-Time Systems},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider filtering for a continuous-time, or asynchronous, stochastic system where the full distribution over states is too large to be stored or calculated. We assume that the rate matrix of the system can be compactly represented and that the belief distribution is to be approximated as a product of marginals. The essential computation is the matrix exponential. We look at two different methods for its computation: ODE integration and uniformization of the Taylor expansion. For both we consider approximations in which only a factored belief state is maintained. For factored uniformization we demonstrate that the KL-divergence of the filtering is bounded. Our experimental results confirm our factored uniformization performs better than previously suggested uniformization methods and the mean field algorithm.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {61–68},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020558,
author = {Chakraborty, Mithun and Das, Sanmay and Magdon-Ismail, Malik},
title = {Near-Optimal Target Learning with Stochastic Binary Signals},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study learning in a noisy bisection model: specifically, Bayesian algorithms to learn a target value V given access only to noisy realizations of whether V is less than or greater than a threshold θ. At step t = 0,1, 2,..., the learner sets threshold θt and observes a noisy realization of sign(V - θt). After T steps, the goal is to output an estimate V which is within an ε-tolerance of V. This problem has been studied, predominantly in environments with a fixed error probability q &lt; ½ for the noisy realization of sign (V - θt). In practice, it is often the case that q can approach ½, especially as θ → V, and there is little known when this happens. We give a pseudo-Bayesian algorithm which provably converges to V. When the true prior matches our algorithm's Gaussian prior, we show near-optimal expected performance. Our methods extend to the general multiple-threshold setting where the observation noisily indicates which of k ≥ 2 regions V belongs to.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {69–76},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020559,
author = {Chapman, Archie C. and Williamson, Simon A. and Jennings, Nicholas R.},
title = {Filtered Fictitious Play for Perturbed Observation Potential Games and Decentralised POMDPs},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Potential games and decentralised partially observable MDPs (Dec-POMDPs) are two commonly used models of multi-agent interaction, for static optimisation and sequential decisionmaking settings, respectively. In this paper we introduce filtered fictitious play for solving repeated potential games in which each player's observations of others' actions are perturbed by random noise, and use this algorithm to construct an online learning method for solving Dec-POMDPs. Specifically, we prove that noise in observations prevents standard fictitious play from converging to Nash equilibrium in potential games, which also makes fictitious play impractical for solving Dec-POMDPs. To combat this, we derive filtered fictitious play, and provide conditions under which it converges to a Nash equilibrium in potential games with noisy observations. We then use filtered fictitious play to construct a solver for Dec-POMDPs, and demonstrate our new algorithm's performance in a box pushing problem. Our results show that we consistently outperform the state-of-the-art Dec-POMDP solver by an average of 100% across the range of noise in the observation function.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {77–85},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020560,
author = {Charlin, Laurent and Zemel, Richard and Boutilier, Craig},
title = {A Framework for Optimizing Paper Matching},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {At the heart of many scientific conferences is the problem of matching submitted papers to suitable reviewers. Arriving at a good assignment is a major and important challenge for any conference organizer. In this paper we propose a framework to optimize paper-to-reviewer assignments. Our framework uses suitability scores to measure pairwise affinity between papers and reviewers. We show how learning can be used to infer suitability scores from a small set of provided scores, thereby reducing the burden on reviewers and organizers. We frame the assignment problem as an integer program and propose several variations for the paper-to-reviewer matching domain. We also explore how learning and matching interact. Experiments on two conference data sets examine the performance of several learning methods as well as the effectiveness of the matching formulations.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {86–95},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020561,
author = {Chatterjee, Shaunak and Russell, Stuart},
title = {A Temporally Abstracted Viterbi Algorithm},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Hierarchical problem abstraction, when applicable, may offer exponential reductions in computational complexity. Previous work on coarse-to-fine dynamic programming (CFDP) has demonstrated this possibility using state abstraction to speed up the Viterbi algorithm. In this paper, we show how to apply temporal abstraction to the Viterbi problem. Our algorithm uses bounds derived from analysis of coarse timescales to prune large parts of the state trellis at finer timescales. We demonstrate improvements of several orders of magnitude over the standard Viterbi algorithm, as well as significant speedups over CFDP, for problems whose state variables evolve at widely differing rates.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {96–104},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020562,
author = {Chen, Xi and Lin, Qihang and Kim, Seyoung and Carbonell, Jaime G. and Xing, Eric P.},
title = {Smoothing Proximal Gradient Method for General Structured Sparse Learning},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study the problem of learning high dimensional regression models regularized by a structured-sparsity-inducing penalty that encodes prior structural information on either input or output sides. We consider two widely adopted types of such penalties as our motivating examples: 1) overlapping group lasso penalty, based on the ℓ1/ℓ2 mixed-norm penalty, and 2) graph-guided fusion penalty. For both types of penalties, due to their non-separability, developing an efficient optimization method has remained a challenging problem. In this paper, we propose a general optimization approach, called smoothing proximal gradient method, which can solve the structured sparse regression problems with a smooth convex loss and a wide spectrum of structured-sparsity-inducing penalties. Our approach is based on a general smoothing technique of Nesterov. It achieves a convergence rate faster than the standard first-order method, subgradient method, and is much more scalable than the most widely used interior-point method. Numerical results are reported to demonstrate the efficiency and scalability of the proposed method.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {105–114},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020563,
author = {Choi, Arthur and Refaat, Khaled S. and Darwiche, Adnan},
title = {EDML: A Method for Learning Parameters in Bayesian Networks},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a method called EDML for learning MAP parameters in binary Bayesian networks under incomplete data. The method assumes Beta priors and can be used to learn maximum likelihood parameters when the priors are uninformative. EDML exhibits interesting behaviors, especially when compared to EM. We introduce EDML, explain its origin, and study some of its properties both analytically and empirically.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {115–124},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020564,
author = {Chun, SangIn and Shachter, Ross D.},
title = {Strictly Proper Mechanisms with Cooperating Players},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Prediction markets provide an efficient means to assess uncertain quantities from forecasters. Traditional and competitive strictly proper scoring rules have been shown to incentivize players to provide truthful probabilistic forecasts. However, we show that when those players can cooperate, these mechanisms can instead discourage them from reporting what they really believe. When players with different beliefs are able to cooperate and form a coalition, these mechanisms admit arbitrage and there is a report that will always pay coalition members more than their truthful forecasts. If the coalition were created by an intermediary, such as a web portal, the intermediary would be guaranteed a profit.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {125–134},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020565,
author = {Claassen, Tom and Heskes, Tom},
title = {A Logical Characterization of Constraint-Based Causal Discovery},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a novel approach to constraint-based causal discovery, that takes the form of straightforward logical inference, applied to a list of simple, logical statements about causal relations that are derived directly from observed (in)dependencies. It is both sound and complete, in the sense that all invariant features of the corresponding partial ancestral graph (PAG) are identified, even in the presence of latent variables and selection bias. The approach shows that every identifiable causal relation corresponds to one of just two fundamental forms. More importantly, as the basic building blocks of the method do not rely on the detailed (graphical) structure of the corresponding PAG, it opens up a range of new opportunities, including more robust inference, detailed accountability, and application to large models.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {135–144},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020566,
author = {Cortes, Corinna and Mohri, Mehryar and Rostamizadeh, Afshin},
title = {Ensembles of Kernel Predictors},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper examines the problem of learning with a finite and possibly large set of p base kernels. It presents a theoretical and empirical analysis of an approach addressing this problem based on ensembles of kernel predictors. This includes novel theoretical guarantees based on the Rademacher complexity of the corresponding hypothesis sets, the introduction and analysis of a learning algorithm based on these hypothesis sets, and a series of experiments using ensembles of kernel predictors with several data sets. Both convex combinations of kernel-based hypotheses and more general Lq-regularized non-negative combinations are analyzed. These theoretical, algorithmic, and empirical results are compared with those achieved by using learning kernel techniques, which can be viewed as another approach for solving the same problem.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {145–152},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020567,
author = {Cussens, James},
title = {Bayesian Network Learning with Cutting Planes},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The problem of learning the structure of Bayesian networks from complete discrete data with a limit on parent set size is considered. Learning is cast explicitly as an optimisation problem where the goal is to find a BN structure which maximises log marginal likelihood (BDe score). Integer programming, specifically the SCIP framework, is used to solve this optimisation problem. Acyclicity constraints are added to the integer program (IP) during solving in the form of cutting planes. Finding good cutting planes is the key to the success of the approach—the search for such cutting planes is effected using a sub-IP. Results show that this is a particularly fast method for exact BN learning.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {153–160},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020568,
author = {Deng, Kun and Pineau, Joelle and Murphy, Susan},
title = {Active Learning for Developing Personalized Treatment},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The personalization of treatment via bio-markers and other risk categories has drawn increasing interest among clinical scientists. Personalized treatment strategies can be learned using data from clinical trials, but such trials are very costly to run. This paper explores the use of active learning techniques to design more efficient trials, addressing issues such as whom to recruit, at what point in the trial, and which treatment to assign, throughout the duration of the trial. We propose a minimax bandit model with two different optimization criteria, and discuss the computational challenges and issues pertaining to this approach. We evaluate our active learning policies using both simulated data, and data modeled after a clinical trial for treating depressed individuals, and contrast our methods with other plausible active learning policies.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {161–168},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020569,
author = {Dudik, Miroslav and Hsu, Daniel and Kale, Satyen and Karampatziakis, Nikos and Langford, John and Reyzin, Lev and Zhang, Tong},
title = {Efficient Optimal Learning for Contextual Bandits},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We address the problem of learning in an online setting where the learner repeatedly observes features, selects among a set of actions, and receives reward for the action taken. We provide the first efficient algorithm with an optimal regret. Our algorithm uses a cost sensitive classification learner as an oracle and has a running time polylog(N), where N is the number of classification rules among which the oracle might choose. This is exponentially faster than all previous algorithms that achieve optimal regret in this setting. Our formulation also enables us to create an algorithm with regret that is additive rather than multiplicative in feedback delay as in all previous work.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {169–178},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020570,
author = {Dvijotham, Krishnamurthy and Todorov, Emanuel},
title = {A Unifying Framework for Linearly Solvable Control},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recent work has led to the development of an elegant theory of Linearly Solvable Markov Decision Processes (LMDPs) and related Path-Integral Control Problems. Traditionally, LMDPs have been formulated using stochastic policies and a control cost based on the KL divergence. In this paper, we extend this framework to a more general class of divergences: the R\'{e}nyi divergences. These are a more general class of divergences parameterized by a continuous parameter α that include the KL divergence as a special case. The resulting control problems can be interpreted as solving a risk-sensitive version of the LMDP problem. For α &gt; 0, we get risk-averse behavior (the degree of risk-aversion increases with a) and for α &lt; 0, we get risk-seeking behavior. We recover LMDPs in the limit as α → 0. This work generalizes the recently developed risk-sensitive path-integral control formalism which can be seen as the continuous-time limit of results obtained in this paper. To the best of our knowledge, this is a general theory of linearly solvable control and includes all previous work as a special case. We also present an alternative interpretation of these results as solving a 2-player (cooperative or competitive) Markov Game. From the linearity follow a number of nice properties including compositionality of control laws and a path-integral representation of the value function. We demonstrate the usefulness of the framework on control problems with noise where different values of α lead to qualitatively different control behaviors.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {179–186},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020571,
author = {Edakunni, Narayanan U. and Brown, Gavin and Kovacs, Tim},
title = {Boosting as a Product of Experts},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we derive a novel probabilistic model of boosting as a Product of Experts. We re-derive the boosting algorithm as a greedy incremental model selection procedure which ensures that addition of new experts to the ensemble does not decrease the likelihood of the data. These learning rules lead to a generic boosting algorithm - POE-Boost which turns out to be similar to the AdaBoost algorithm under certain assumptions on the expert probabilities. The paper then extends the POEBoost algorithm to POEBoost.CS which handles hypothesis that produce probabilistic predictions. This new algorithm is shown to have better generalization performance compared to other state of the art algorithms.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {187–194},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020572,
author = {Fard, Mahdi Milani and Pineau, Joelle and Szepesv\'{a}ri, Csaba},
title = {PAC-Bayesian Policy Evaluation for Reinforcement Learning},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian priors offer a compact yet general means of incorporating domain knowledge into many learning tasks. The correctness of the Bayesian analysis and inference, however, largely depends on accuracy and correctness of these priors. PAC-Bayesian methods overcome this problem by providing bounds that hold regardless of the correctness of the prior distribution. This paper introduces the first PAC-Bayesian bound for the batch reinforcement learning problem with function approximation. We show how this bound can be used to perform model-selection in a transfer learning scenario. Our empirical results confirm that PAC-Bayesian policy evaluation is able to leverage prior distributions when they are informative and, unlike standard Bayesian RL approaches, ignore them when they are misleading.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {195–202},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020573,
author = {Fargier, H\'{e}l\`{e}ne and Amor, Nahla Ben and Guezguez, Wided},
title = {On the Complexity of Decision Making in Possibilistic Decision Trees},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {When the information about uncertainty cannot be quantified in a simple, probabilistic way, the topic of possibilistic decision theory is often a natural one to consider. The development of possibilistic decision theory has lead to a series of possibilistic criteria, e.g pessimistic possibilistic qualitative utility, possibilistic likely dominance, binary possibilistic utility and possibilistic Choquet integrals. This paper focuses on sequential decision making in possibilistic decision trees. It proposes a complexity study of the problem of finding an optimal strategy depending on the monotonicity property of the optimization criteria which allows the application of dynamic programming that offers a polytime reduction of the decision problem. It also shows that possibilistic Choquet integrals do not satisfy this property, and that in this case the optimization problem is NP — hard.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {203–210},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020574,
author = {Fierens, Daan and Van den Broeck, Guy and Thon, Ingo and Gutmann, Bernd and Raedt, Luc De},
title = {Inference in Probabilistic Logic Programs Using Weighted CNF's},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Probabilistic logic programs are logic programs in which some of the facts are annotated with probabilities. Several classical probabilistic inference tasks (such as MAP and computing marginals) have not yet received a lot of attention for this formalism. The contribution of this paper is that we develop efficient inference algorithms for these tasks. This is based on a conversion of the probabilistic logic program and the query and evidence to a weighted CNF formula. This allows us to reduce the inference tasks to well-studied tasks such as weighted model counting. To solve such tasks, we employ state-of-the-art methods. We consider multiple methods for the conversion of the programs as well as for inference on the weighted CNF. The resulting approach is evaluated experimentally and shown to improve upon the state-of-the-art in probabilistic logic programming.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {211–220},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020575,
author = {Furmston, Thomas and Barber, David},
title = {Efficient Inference in Markov Control Problems},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Markov control algorithms that perform smooth, non-greedy updates of the policy have been shown to be very general and versatile, with policy gradient and Expectation Maximisation algorithms being particularly popular. For these algorithms, marginal inference of the reward weighted trajectory distribution is required to perform policy updates. We discuss a new exact inference algorithm for these marginals in the finite horizon case that is more efficient than the standard approach based on classical forward-backward recursions. We also provide a principled extension to infinite horizon Markov Decision Problems that explicitly accounts for an infinite horizon. This extension provides a novel algorithm for both policy gradients and Expectation Maximisation in infinite horizon problems.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {221–229},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020576,
author = {Giang, Phan H.},
title = {Dynamic Consistency and Decision Making under Vacuous Belief},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The ideas about decision making under ignorance in economics are combined with the ideas about uncertainty representation in computer science. The combination sheds new light on the question of how artificial agents can act in a dynamically consistent manner. The notion of sequential consistency is formalized by adapting the law of iterated expectation for plausibility measures. The necessary and sufficient condition for a certainty equivalence operator for Nehring-Puppe's preference to be sequentially consistent is given. This result sheds light on the models of decision making under uncertainty.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {230–237},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020577,
author = {Givoni, Inmar E. and Chung, Clement and Frey, Brendan J.},
title = {Hierarchical Affinity Propagation},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Affinity propagation is an exemplar-based clustering algorithm that finds a set of data-points that best exemplify the data, and associates each datapoint with one exemplar. We extend affinity propagation in a principled way to solve the hierarchical clustering problem, which arises in a variety of domains including biology, sensor networks and decision making in operational research. We derive an inference algorithm that operates by propagating information up and down the hierarchy, and is efficient despite the high-order potentials required for the graphical model formulation.We demonstrate that our method outperforms greedy techniques that cluster one layer at a time. We show that on an artificial dataset designed to mimic the HIV-strain mutation dynamics, our method outperforms related methods. For real HIV sequences, where the ground truth is not available, we show our method achieves better results, in terms of the underlying objective function, and show the results correspond meaningfully to geographical location and strain subtypes. Finally we report results on using the method for the analysis of mass spectra, showing it performs favorably compared to state-of-the-art methods.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {238–246},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020578,
author = {Gogate, Vibhav and Domingos, Pedro},
title = {Approximation by Quantization},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Inference in graphical models consists of repeatedly multiplying and summing out potentials. It is generally intractable because the derived potentials obtained in this way can be exponentially large. Approximate inference techniques such as belief propagation and variational methods combat this by simplifying the derived potentials, typically by dropping variables from them. We propose an alternate method for simplifying potentials: quantizing their values. Quantization causes different states of a potential to have the same value, and therefore introduces context-specific independencies that can be exploited to represent the potential more compactly. We use algebraic decision diagrams (ADDs) to do this efficiently. We apply quantization and ADD reduction to variable elimination and junction tree propagation, yielding a family of bounded approximate inference schemes. Our experimental tests show that our new schemes significantly outperform state-of-the-art approaches on many benchmark instances.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {247–255},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020579,
author = {Gogate, Vibhav and Domingos, Pedro},
title = {Probabilistic Theorem Proving},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Many representation schemes combining first-order logic and probability have been proposed in recent years. Progress in unifying logical and probabilistic inference has been slower. Existing methods are mainly variants of lifted variable elimination and belief propagation, neither of which take logical structure into account. We propose the first method that has the full power of both graphical model inference and first-order theorem proving (in finite domains with Herbrand interpretations). We first define probabilistic theorem proving, their generalization, as the problem of computing the probability of a logical formula given the probabilities or weights of a set of formulas. We then show how this can be reduced to the problem of lifted weighted model counting, and develop an efficient algorithm for the latter. We prove the correctness of this algorithm, investigate its properties, and show how it generalizes previous approaches. Experiments show that it greatly outperforms lifted variable elimination when logical structure is present. Finally, we propose an algorithm for approximate probabilistic theorem proving, and show that it can greatly outperform lifted belief propagation.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {256–265},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020580,
author = {Gu, Quanquan and Li, Zhenhui and Han, Jiawei},
title = {Generalized Fisher Score for Feature Selection},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Fisher score is one of the most widely used supervised feature selection methods. However, it selects each feature independently according to their scores under the Fisher criterion, which leads to a suboptimal subset of features. In this paper, we present a generalized Fisher score to jointly select features. It aims at finding an subset of features, which maximize the lower bound of traditional Fisher score. The resulting feature selection problem is a mixed integer programming, which can be reformulated as a quadratically constrained linear programming (QCLP). It is solved by cutting plane algorithm, in each iteration of which a multiple kernel learning problem is solved alternatively by multivariate ridge regression and projected gradient descent. Experiments on benchmark data sets indicate that the proposed method outperforms Fisher score as well as many other state-of-the-art feature selection methods.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {266–273},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020581,
author = {Guillory, Andrew and Bilmes, Jeff},
title = {Active Semi-Supervised Learning Using Submodular Functions},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider active, semi-supervised learning in an offline transductive setting. We show that a previously proposed error bound for active learning on undirected weighted graphs can be generalized by replacing graph cut with an arbitrary symmetric submodular function. Arbitrary non-symmetric sub-modular functions can be used via symmetrization. Different choices of submodular functions give different versions of the error bound that are appropriate for different kinds of problems. Moreover, the bound is deterministic and holds for adversarially chosen labels. We show exactly minimizing this error bound is NP-complete. However, we also introduce for any submodular function an associated active semi-supervised learning method that approximately minimizes the corresponding error bound. We show that the error bound is tight in the sense that there is no other bound of the same form which is better. Our theoretical results are supported by experiments on real data.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {274–282},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020582,
author = {Gutmann, Michael U. and Hirayama, Jun-ichiro},
title = {Bregman Divergence as General Framework to Estimate Unnormalized Statistical Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We show that the Bregman divergence provides a rich framework to estimate unnormalized statistical models for continuous or discrete random variables, that is, models which do not integrate or sum to one, respectively. We prove that recent estimation methods such as noise-contrastive estimation, ratio matching, and score matching belong to the proposed framework, and explain their interconnection based on supervised learning. Further, we discuss the role of boosting in un-supervised learning.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {283–290},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020583,
author = {Hajishirzi, Hannaneh and Hockenmaier, Julia and Mueller, Erik T. and Amir, Eyal},
title = {Reasoning about RoboCup Soccer Narratives},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper presents an approach for learning to translate simple narratives, i.e., texts (sequences of sentences) describing dynamic systems, into coherent sequences of events without the need for labeled training data. Our approach incorporates domain knowledge in the form of preconditions and effects of events, and we show that it outperforms state-of-the-art supervised learning systems on the task of reconstructing RoboCup soccer games from their commentaries.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {291–300},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020584,
author = {Hansen, Eric A.},
title = {Suboptimality Bounds for Stochastic Shortest Path Problems},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider how to use the Bellman residual of the dynamic programming operator to compute suboptimality bounds for solutions to stochastic shortest path problems. Such bounds have been previously established only in the special case that "all policies are proper," in which case the dynamic programming operator is known to be a contraction, and have been shown to be easily computable only in the more limited special case of discounting. Under the condition that transition costs are positive, we show that suboptimality bounds can be easily computed even when not all policies are proper. In the general case when there are no restrictions on transition costs, the analysis is more complex. But we present preliminary results that show such bounds are possible.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {301–310},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020585,
author = {Hartikainen, Jouni and S\"{a}rkk\"{a}, Simo},
title = {Sequential Inference for Latent Force Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Latent force models (LFMs) are hybrid models combining mechanistic principles with non-parametric components. In this article, we shall show how LFMs can be equivalently formulated and solved using the state variable approach. We shall also show how the Gaussian process prior used in LFMs can be equivalently formulated as a linear statespace model driven by a white noise process and how inference on the resulting model can be efficiently implemented using Kalman filter and smoother. Then we shall show how the recently proposed switching LFM can be reformulated using the state variable approach, and how we can construct a probabilistic model for the switches by formulating a similar switching LFM as a switching linear dynamic system (SLDS). We illustrate the performance of the proposed methodology in simulated scenarios and apply it to inferring the switching points in GPS data collected from car movement data in urban environment.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {311–318},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020586,
author = {Heinemann, Uri and Globerson, Amir},
title = {What Cannot Be Learned with Bethe Approximations},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We address the problem of learning the parameters in graphical models when inference is intractable. A common strategy in this case is to replace the partition function with its Bethe approximation. We show that there exists a regime of empirical marginals where such Bethe learning will fail. By failure we mean that the empirical marginals cannot be recovered from the approximated maximum likelihood parameters (i.e., moment matching is not achieved). We provide several conditions on empirical marginals that yield outer and inner bounds on the set of Bethe learn-able marginals. An interesting implication of our results is that there exists a large class of marginals that cannot be obtained as stable fixed points of belief propagation. Taken together our results provide a novel approach to analyzing learning with Bethe approximations and highlight when it can be expected to work or fail.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {319–326},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020587,
author = {Hoffman, Matthew and Brochu, Eric and de Freitas, Nando},
title = {Portfolio Allocation for Bayesian Optimization},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the posterior estimate of the objective. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm's performance.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {327–336},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020588,
author = {Poon, Hoifung and Domingos, Pedro},
title = {Sum-Product Networks: A New Deep Architecture},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The key limiting factor in graphical model inference and learning is the complexity of the partition function. We thus ask the question: what are general conditions under which the partition function is tractable? The answer leads to a new kind of deep architecture, which we call sum-product networks (SPNs). SPNs are directed acyclic graphs with variables as leaves, sums and products as internal nodes, and weighted edges. We show that if an SPN is complete and consistent it represents the partition function and all marginals of some graphical model, and give semantics to its nodes. Essentially all tractable graphical models can be cast as SPNs, but SPNs are also strictly more general. We then propose learning algorithms for SPNs, based on backpropagation and EM. Experiments show that inference and learning with SPNs can be both faster and more accurate than with standard deep networks. For example, SPNs perform image completion better than state-of-the-art deep networks for this task. SPNs also have intriguing potential connections to the architecture of the cortex.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {337–346},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020589,
author = {Honorio, Jean},
title = {Lipschitz Parametrization of Probabilistic Graphical Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We show that the log-likelihood of several probabilistic graphical models is Lipschitz continuous with respect to the ℓp-norm of the parameters. We discuss several implications of Lipschitz parametrization. We present an upper bound of the Kullback-Leibler divergence that allows understanding methods that penalize the ℓp-norm of differences of parameters as the minimization of that upper bound. The expected log-likelihood is lower bounded by the negative ℓp-norm, which allows understanding the generalization ability of probabilistic models. The exponential of the negative ℓp-norm is involved in the lower bound of the Bayes error rate, which shows that it is reasonable to use parameters as features in algorithms that rely on metric spaces (e.g. classification, dimensionality reduction, clustering). Our results do not rely on specific algorithms for learning the structure or parameters. We show preliminary results for activity recognition and temporal segmentation.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {347–354},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020590,
author = {Huang, Jonathan and Kapoor, Ashish and Guestrin, Carlos},
title = {Efficient Probabilistic Inference with Partial Ranking Queries},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Distributions over rankings are used to model data in various settings such as preference analysis and political elections. The factorial size of the space of rankings, however, typically forces one to make structural assumptions, such as smoothness, sparsity, or probabilistic independence about these underlying distributions. We approach the modeling problem from the computational principle that one should make structural assumptions which allow for efficient calculation of typical probabilistic queries. For ranking models, "typical" queries predominantly take the form of partial ranking queries (e.g., given a user's top-k favorite movies, what are his preferences over remaining movies?). In this paper, we argue that riffled independence factorizations proposed in recent literature [7, 8] are a natural structural assumption for ranking distributions, allowing for particularly efficient processing of partial ranking queries.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {355–362},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020591,
author = {Hyttinen, Antti and Eberhardt, Frederick and Hoyer, Patrik O.},
title = {Noisy-OR Models with Latent Confounding},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Given a set of experiments in which varying subsets of observed variables are subject to intervention, we consider the problem of identifiability of causal models exhibiting latent confounding. While identifiability is trivial when each experiment intervenes on a large number of variables, the situation is more complicated when only one or a few variables are subject to intervention per experiment. For linear causal models with latent variables Hyttinen et al. (2010) gave precise conditions for when such data are sufficient to identify the full model. While their result cannot be extended to discrete-valued variables with arbitrary cause-effect relationships, we show that a similar result can be obtained for the class of causal models whose conditional probability distributions are restricted to a 'noisy-OR' parameterization. We further show that identification is preserved under an extension of the model that allows for negative influences, and present learning algorithms that we test for accuracy, scalability and robustness.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {363–372},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020592,
author = {Inazumi, Takanori and Washio, Takashi and Shimizu, Shohei and Suzuki, Joe and Yamamoto, Akihiro and Kawahara, Yoshinobu},
title = {Discovering Causal Structures in Binary Exclusive-or Skew Acyclic Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Discovering causal relations among observed variables in a given data set is a main topic in studies of statistics and artificial intelligence. Recently, some techniques to discover an identifiable causal structure have been explored based on non-Gaussianity of the observed data distribution. However, most of these are limited to continuous data. In this paper, we present a novel causal model for binary data and propose a new approach to derive an identifiable causal structure governing the data based on skew Bernoulli distributions of external noise. Experimental evaluation shows excellent performance for both artificial and real world data sets.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {373–382},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020593,
author = {Janzing, Dominik and Sgouritsa, Eleni and Stegle, Oliver and Peters, Jonas and Sch\"{o}lkopf, Bernhard},
title = {Detecting Low-Complexity Unobserved Causes},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We describe a method that infers whether statistical dependences between two observed variables X and Y are due to a "direct" causal link or only due to a connecting causal path that contains an unobserved variable of low complexity, e.g., a binary variable.This problem is motivated by statistical genetics. Given a genetic marker that is correlated with a phenotype of interest, we want to detect whether this marker is causal or it only correlates with a causal one. Our method is based on the analysis of the location of the conditional distributions P(Y|x) in the simplex of all distributions of Y. We report encouraging results on semi-empirical data.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {383–391},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020594,
author = {Karampatziakis, Nikos and Langford, John},
title = {Online Importance Weight Aware Updates},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {An importance weight quantifies the relative importance of one example over another, coming up in applications of boosting, asymmetric classification costs, reductions, and active learning. The standard approach for dealing with importance weights in gradient descent is via multiplication of the gradient. We first demonstrate the problems of this approach when importance weights are large, and argue in favor of more sophisticated ways for dealing with them. We then develop an approach which enjoys an invariance property: that updating twice with importance weight h is equivalent to updating once with importance weight 2h. For many important losses this has a closed form update which satisfies standard regret guarantees when all examples have h = 1. We also briefly discuss two other reasonable approaches for handling large importance weights. Empirically, these approaches yield substantially superior prediction with similar computational performance while reducing the sensitivity of the algorithm to the exact setting of the learning rate. We apply these to online active learning yielding an extraordinarily fast active learning algorithm that works even in the presence of adversarial noise.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {392–399},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020595,
author = {Kim, Myunghwan and Leskovec, Jure},
title = {Modeling Social Networks with Node Attributes Using the Multiplicative Attribute Graph Model},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Networks arising from social, technological and natural domains exhibit rich connectivity patterns and nodes in such networks are often labeled with attributes or features. We address the question of modeling the structure of networks where nodes have attribute information. We present a Multiplicative Attribute Graph (MAG) model that considers nodes with categorical attributes and models the probability of an edge as the product of individual attribute link formation affinities. We develop a scalable variational expectation maximization parameter estimation method. Experiments show that MAG model reliably captures network connectivity as well as provides insights into how different attributes shape the network structure.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {400–409},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020596,
author = {Knowles, David A. and Ghahramani, Zoubin},
title = {Pitman-Yor Diffusion Trees},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce the Pitman Yor Diffusion Tree (PYDT) for hierarchical clustering, a generalization of the Dirichlet Diffusion Tree (Neal, 2001) which removes the restriction to binary branching structure. The generative process is described and shown to result in an exchangeable distribution over data points. We prove some theoretical properties of the model and then present two inference methods: a collapsed MCMC sampler which allows us to model uncertainty over tree structures, and a computationally efficient greedy Bayesian EM search algorithm. Both algorithms use message passing on the tree structure. The utility of the model and algorithms is demonstrated on synthetic and real world data, both continuous and binary.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {410–418},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020597,
author = {Kulesza, Alex and Taskar, Ben},
title = {Learning Determinantal Point Processes},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Determinantal point processes (DPPs), which arise in random matrix theory and quantum physics, are natural models for subset selection problems where diversity is preferred. Among many remarkable properties, DPPs offer tractable algorithms for exact inference, including computing marginal probabilities and sampling; however, an important open question has been how to learn a DPP from labeled training data. In this paper we propose a natural feature-based parameterization of conditional DPPs, and show how it leads to a convex and efficient learning formulation. We analyze the relationship between our model and binary Markov random fields with repulsive potentials, which are qualitatively similar but computationally intractable. Finally, we apply our approach to the task of extractive summarization, where the goal is to choose a small subset of sentences conveying the most important information from a set of documents. In this task there is a fundamental tradeoff between sentences that are highly relevant to the collection as a whole, and sentences that are diverse and not repetitive. Our parameterization allows us to naturally balance these two characteristics. We evaluate our system on data from the DUC 2003/04 multi-document summarization task, achieving state-of-the-art results.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {419–427},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020598,
author = {Kumar, Akshat and Zilberstein, Shlomo},
title = {Message-Passing Algorithms for Quadratic Programming Formulations of MAP Estimation},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Computing maximum a posteriori (MAP) estimation in graphical models is an important inference problem with many applications. We present message-passing algorithms for quadratic programming (QP) formulations of MAP estimation for pairwise Markov random fields. In particular, we use the concave-convex procedure (CCCP) to obtain a locally optimal algorithm for the non-convex QP formulation. A similar technique is used to derive a globally convergent algorithm for the convex QP relaxation of MAP. We also show that a recently developed expectation-maximization (EM) algorithm for the QP formulation of MAP can be derived from the CCCP perspective. Experiments on synthetic and real-world problems confirm that our new approach is competitive with max-product and its variations. Compared with CPLEX, we achieve more than an order-of-magnitude speedup in solving optimally the convex QP relaxation.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {428–435},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020599,
author = {Li, Minyi and Vo, Quoc Bao and Kowalczyk, Ryszard},
title = {An Efficient Protocol for Negotiation over Combinatorial Domains with Incomplete Information},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study the problem of agent-based negotiation in combinatorial domains. It is difficult to reach optimal agreements in bilateral or multi-lateral negotiations when the agents' preferences for the possible alternatives are not common knowledge. Self-interested agents often end up negotiating inefficient agreements in such situations. In this paper, we present a protocol for negotiation in combinatorial domains which can lead rational agents to reach optimal agreements under incomplete information setting. Our proposed protocol enables the negotiating agents to identify efficient solutions using distributed search that visits only a small subspace of the whole outcome space. Moreover, the proposed protocol is sufficiently general that it is applicable to most preference representation models in combinatorial domains. We also present results of experiments that demonstrate the feasibility and computational efficiency of our approach.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {436–444},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020600,
author = {Lim, Shiau Hong and Auer, Peter},
title = {Noisy Search with Comparative Feedback},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present theoretical results in terms of lower and upper bounds on the query complexity of noisy search with comparative feedback. In this search model, the noise in the feedback depends on the distance between query points and the search target. Consequently, the error probability in the feedback is not fixed but varies for the queries posed by the search algorithm. Our results show that a target out of n items can be found in O(log n) queries. We also show the surprising result that for k possible answers per query, the speedup is not log k (as for k-ary search) but only log log k in some cases.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {445–452},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020601,
author = {Liu, Qiang and Ihler, Alexander},
title = {Variational Algorithms for Marginal MAP},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Marginal MAP problems are notoriously difficult tasks for graphical models. We derive a general variational framework for solving marginal MAP problems, in which we apply analogues of the Bethe, tree-reweighted, and mean field approximations. We then derive a "mixed" message passing algorithm and a convergent alternative using CCCP to solve the BP-type approximations. Theoretically, we give conditions under which the decoded solution is a global or local optimum, and obtain novel upper bounds on solutions. Experimentally we demonstrate that our algorithms outperform related approaches. We also show that EM and variational EM comprise a special case of our framework.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {453–462},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020602,
author = {Louradour, J\'{e}r\^{o}me and Larochelle, Hugo},
title = {Classification of Sets Using Restricted Boltzmann Machines},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of classification when inputs correspond to sets of vectors with the same size. This setting occurs in many problems such as the classification of pieces of mail containing several pages, of web sites with several sections or of images that have been pre-segmented into smaller regions. We propose generalizations of the restricted Boltzmann machine (RBM) that are appropriate in this context and explore how to incorporate different assumptions about the relationship between the input sets and the target class within the RBM. In experiments on standard multiple-instance learning datasets, we demonstrate the competitiveness of approaches based on RBMs and apply the proposed variants to the problem of incoming mail classification.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {463–470},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020603,
author = {Ma, Jianbing and Liu, Weiru and Miller, Paul},
title = {Belief Change with Noisy Sensing in the Situation Calculus},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Situation calculus has been applied widely in artificial intelligence to model and reason about actions and changes in dynamic systems. Since actions carried out by agents will cause constant changes of the agents' beliefs, how to manage these changes is a very important issue. Shapiro et al. [22] is one of the studies that considered this issue. However, in this framework, the problem of noisy sensing, which often presents in real-world applications, is not considered. As a consequence, noisy sensing actions in this framework will lead to an agent facing inconsistent situation and subsequently the agent cannot proceed further. In this paper, we investigate how noisy sensing actions can be handled in iterated belief change within the situation calculus formalism. We extend the framework proposed in [22] with the capability of managing noisy sensings. We demonstrate that an agent can still detect the actual situation when the ratio of noisy sensing actions vs. accurate sensing actions is limited. We prove that our framework subsumes the iterated belief change strategy in [22] when all sensing actions are accurate. Furthermore, we prove that our framework can adequately handle belief introspection, mistaken beliefs, belief revision and belief update even with noisy sensing, as done in [22] with accurate sensing actions only.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {471–478},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020604,
author = {Malone, Brandon and Yuan, Changhe and Hansen, Eric A. and Bridges, Susan},
title = {Improving the Scalability of Optimal Bayesian Network Learning with External-Memory Frontier Breadth-First Branch and Bound Search},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Previous work has shown that the problem of learning the optimal structure of a Bayesian network can be formulated as a shortest path finding problem in a graph and solved using A* search. In this paper, we improve the scalability of this approach by developing a memory-efficient heuristic search algorithm for learning the structure of a Bayesian network. Instead of using A*, we propose a frontier breadth-first branch and bound search that leverages the layered structure of the search graph of this problem so that no more than two layers of the graph, plus solution reconstruction information, need to be stored in memory at a time. To further improve scalability, the algorithm stores most of the graph in external memory, such as hard disk, when it does not fit in RAM. Experimental results show that the resulting algorithm solves significantly larger problems than the current state of the art.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {479–488},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020605,
author = {Marinescu, Radu and Wilson, Nic},
title = {Order-of-Magnitude Influence Diagrams},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we develop a qualitative theory of influence diagrams that can be used to model and solve sequential decision making tasks when only qualitative (or imprecise) information is available. Our approach is based on an order-of-magnitude approximation of both probabilities and utilities and allows for specifying partially ordered preferences via sets of utility values. We also propose a dedicated variable elimination algorithm that can be applied for solving order-of-magnitude influence diagrams.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {489–496},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020606,
author = {Marlin, Benjamin M. and de Freitas, Nando},
title = {Asymptotic Efficiency of Deterministic Estimators for Discrete Energy-Based Models: Ratio Matching and Pseudolikelihood},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Standard maximum likelihood estimation cannot be applied to discrete energy-based models in the general case because the computation of exact model probabilities is intractable. Recent research has seen the proposal of several new estimators designed specifically to overcome this intractability, but virtually nothing is known about their theoretical properties. In this paper, we present a generalized estimator that unifies many of the classical and recently proposed estimators. We use results from the standard asymptotic theory for M-estimators to derive a generic expression for the asymptotic co-variance matrix of our generalized estimator. We apply these results to study the relative statistical efficiency of classical pseudolikelihood and the recently-proposed ratio matching estimator.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {497–505},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020607,
author = {Mimno, David},
title = {Reconstructing Pompeian Households},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A database of objects discovered in houses in the Roman city of Pompeii provides a unique view of ordinary life in an ancient city. Experts have used this collection to study the structure of Roman households, exploring the distribution and variability of tasks in architectural spaces, but such approaches are necessarily affected by modern cultural assumptions. In this study we present a data-driven approach to household archeology, treating it as an unsupervised labeling problem. This approach scales to large data sets and provides a more objective complement to human interpretation.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {506–513},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020608,
author = {Mnih, Volodymyr and Larochelle, Hugo and Hinton, Geoffrey E.},
title = {Conditional Restricted Boltzmann Machines for Structured Output Prediction},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic models that have recently been applied to a wide range of problems, including collaborative filtering, classification, and modeling motion capture data. While much progress has been made in training non-conditional RBMs, these algorithms are not applicable to conditional models and there has been almost no work on training and generating predictions from conditional RBMs for structured output problems. We first argue that standard Contrastive Divergence-based learning may not be suitable for training CRBMs. We then identify two distinct types of structured output prediction problems and propose an improved learning algorithm for each. The first problem type is one where the output space has arbitrary structure but the set of likely output configurations is relatively small, such as in multi-label classification. The second problem is one where the output space is arbitrarily structured but where the output space variability is much greater, such as in image denoising or pixel labeling. We show that the new learning algorithms can work much better than Contrastive Divergence on both types of problems.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {514–522},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020609,
author = {Mostafa, Hala and Lesser, Victor},
title = {Compact Mathematical Programs For DEC-MDPs With Structured Agent Interactions},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {To deal with the prohibitive complexity of calculating policies in Decentralized MDPs, researchers have proposed models that exploit structured agent interactions. Settings where most agent actions are independent except for few actions that affect the transitions and/or rewards of other agents can be modeled using Event-Driven Interactions with Complex Rewards (EDI-CR). Finding the optimal joint policy can be formulated as an optimization problem. However, existing formulations are too verbose and/or lack optimality guarantees. We propose a compact Mixed Integer Linear Program formulation of EDI-CR instances. The key insight is that most action sequences of a group of agents have the same effect on a given agent. This allows us to treat these sequences similarly and use fewer variables. Experiments show that our formulation is more compact and leads to faster solution times and better solutions than existing formulations.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {523–530},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020610,
author = {Narayanan B, Ananda and Ravindran, Balaraman},
title = {Fractional Moments on Bandit Problems},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Reinforcement learning addresses the dilemma between exploration to find profitable actions and exploitation to act according to the best observations already made. Bandit problems are one such class of problems in stateless environments that represent this explore/exploit situation. We propose a learning algorithm for bandit problems based on fractional expectation of rewards acquired. The algorithm is theoretically shown to converge on an e-optimal arm and achieve O(n) sample complexity. Experimental results show the algorithm incurs substantially lower regrets than parameter-optimized ε-greedy and SoftMax approaches and other low sample complexity state-of-the-art techniques.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {531–538},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020611,
author = {Nath, Swaprava and Zoeter, Onno and Narahari, Yadati and Dance, Christopher R.},
title = {Dynamic Mechanism Design for Markets with Strategic Resources},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The assignment of tasks to multiple resources becomes an interesting game theoretic problem, when both the task owner and the resources are strategic. In the classical, non-strategic setting, where the states of the tasks and resources are observable by the controller, this problem is that of finding an optimal policy for a Markov decision process (MDP). When the states are held by strategic agents, the problem of an efficient task allocation extends beyond that of solving an MDP and becomes that of designing a mechanism. Motivated by this fact, we propose a general mechanism which decides on an allocation rule for the tasks and resources and a payment rule to incentivize agents' participation and truthful reports.In contrast to related dynamic strategic control problems studied in recent literature, the problem studied here has interdependent values: the benefit of an allocation to the task owner is not simply a function of the characteristics of the task itself and the allocation, but also of the state of the resources. We introduce a dynamic extension of Mezzetti's two phase mechanism for interdependent valuations. In this changed setting, the proposed dynamic mechanism is efficient, within period ex-post incentive compatible, and within period ex-post individually rational.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {539–546},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020612,
author = {Jojic, Nebojsa and Perina, Alessandro},
title = {Multidimensional Counting Grids: Inferring Word Order from Disordered Bags of Words},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Models of bags of words typically assume topic mixing so that the words in a single bag come from a limited number of topics. We show here that many sets of bag of words exhibit a very different pattern of variation than the patterns that are efficiently captured by topic mixing. In many cases, from one bag of words to the next, the words disappear and new ones appear as if the theme slowly and smoothly shifted across documents (providing that the documents are somehow ordered). Examples of latent structure that describe such ordering are easily imagined. For example, the advancement of the date of the news stories is reflected in a smooth change over the theme of the day as certain evolving news stories fall out of favor and new events create new stories. Overlaps among the stories of consecutive days can be modeled by using windows over linearly arranged tight distributions over words. We show here that such strategy can be extended to multiple dimensions and cases where the ordering of data is not readily obvious. We demonstrate that this way of modeling covariation in word occurrences outperforms standard topic models in classification and prediction tasks in applications in biology, text modeling and computer vision.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {547–556},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020613,
author = {Niinim\"{a}ki, Teppo and Parviainen, Pekka and Koivisto, Mikko},
title = {Partial Order MCMC for Structure Discovery in Bayesian Networks},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a new Markov chain Monte Carlo method for estimating posterior probabilities of structural features in Bayesian networks. The method draws samples from the posterior distribution of partial orders on the nodes; for each sampled partial order, the conditional probabilities of interest are computed exactly. We give both analytical and empirical results that suggest the superiority of the new method compared to previous methods, which sample either directed acyclic graphs or linear orders on the nodes.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {557–564},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020614,
author = {Oh, Eunsoo and Kim, Kee-Eung},
title = {A Geometric Traversal Algorithm for Reward-Uncertain MDPs},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Markov decision processes (MDPs) are widely used in modeling decision making problems in stochastic environments. However, precise specification of the reward functions in MDPs is often very difficult. Recent approaches have focused on computing an optimal policy based on the minimax regret criterion for obtaining a robust policy under uncertainty in the reward function. One of the core tasks in computing the minimax regret policy is to obtain the set of all policies that can be optimal for some candidate reward function. In this paper, we propose an efficient algorithm that exploits the geometric properties of the reward function associated with the policies. We also present an approximate version of the method for further speed up. We experimentally demonstrate that our algorithm improves the performance by orders of magnitude.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {565–572},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020615,
author = {Osogami, Takayuki},
title = {Iterated Risk Measures for Risk-Sensitive Markov Decision Processes with Discounted Cost},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We demonstrate a limitation of discounted expected utility, a standard approach for representing the preference to risk when future cost is discounted. Specifically, we provide an example of the preference of a decision maker that appears to be rational but cannot be represented with any discounted expected utility. A straightforward modification to discounted expected utility leads to inconsistent decision making over time. We will show that an iterated risk measure can represent the preference that cannot be represented by any discounted expected utility and that the decisions based on the iterated risk measure are consistent over time.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {573–580},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020616,
author = {Pennock, David M. and Xia, Lirong},
title = {Price Updating in Combinatorial Prediction Markets with Bayesian Networks},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {To overcome the #P-hardness of computnig/updating prices in logarithm market scoring rule-based (LMSR-based) combinatorial prediction markets, Chen et al. [5] recently used a simple Bayesian network to represent the prices of securities in combinatorial prediction markets for tournaments, and showed that two types of popular securities are structure preserving. In this paper, we significantly extend this idea by employing Bayesian networks in general combinatorial prediction markets. We reveal a very natural connection between LMSR-based combinatorial prediction markets and probabilistic belief aggregation, which leads to a complete characterization of all structure preserving securities for decomposable network structures. Notably, the main results by Chen et al. [5] are corollaries of our characterization. We then prove that in order for a very basic set of securities to be structure preserving, the graph of the Bayesian network must be decomposable. We also discuss some approximation techniques for securities that are not structure preserving.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {581–588},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020617,
author = {Peters, Jonas and Mooij, Joris M. and Janzing, Dominik and Sch\"{o}lkopf, Bernhard},
title = {Identifiability of Causal Graphs Using Functional Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This work addresses the following question: Under what assumptions on the data generating process can one infer the causal graph from the joint distribution? The approach taken by conditional independence-based causal discovery methods is based on two assumptions: the Markov condition and faithfulness. It has been shown that under these assumptions the causal graph can be identified up to Markov equivalence (some arrows remain undirected) using methods like the PC algorithm. In this work we propose an alternative by defining Identifiable Functional Model Classes (IFMOCs). As our main theorem we prove that if the data generating process belongs to an IFMOC, one can identify the complete causal graph. To the best of our knowledge this is the first identifiability result of this kind that is not limited to linear functional relationships. We discuss how the IFMOC assumption and the Markov and faithfulness assumptions relate to each other and explain why we believe that the IFMOC assumption can be tested more easily on given data. We further provide a practical algorithm that recovers the causal graph from finitely many data; experiments on simulated data support the theoretical findings.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {589–598},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020618,
author = {P\'{o}czos, Barnab\'{a}s and Xiong, Liang and Schneider, Jeff},
title = {Nonparametric Divergence Estimation with Applications to Machine Learning on Distributions},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Low-dimensional embedding, manifold learning, clustering, classification, and anomaly detection are among the most important problems in machine learning. The existing methods usually consider the case when each instance has a fixed, finite-dimensional feature representation. Here we consider a different setting. We assume that each instance corresponds to a continuous probability distribution. These distributions are unknown, but we are given some i.i.d. samples from each distribution. Our goal is to estimate the distances between these distributions and use these distances to perform low-dimensional embedding, clustering/classification, or anomaly detection for the distributions. We present estimation algorithms, describe how to apply them for machine learning tasks on distributions, and show empirical results on synthetic data, real word images, and astronomical data sets.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {599–608},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020619,
author = {Polatkan, Gungor and Tuzel, Oncel},
title = {Compressed Inference for Probabilistic Sequential Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Hidden Markov models (HMMs) and conditional random fields (CRFs) are two popular techniques for modeling sequential data. Inference algorithms designed over CRFs and HMMs allow estimation of the state sequence given the observations. In several applications, estimation of the state sequence is not the end goal; instead the goal is to compute some function of it. In such scenarios, estimating the state sequence by conventional inference techniques, followed by computing the functional mapping from the estimate is not necessarily optimal. A more formal approach is to directly infer the final outcome from the observations. In particular, we consider the specific instantiation of the problem where the goal is to find the state trajectories without exact transition points and derive a novel polynomial time inference algorithm that outperforms vanilla inference techniques. We show that this particular problem arises commonly in many disparate applications and present experiments on three of them: (1) Toy robot tracking; (2) Single stroke character recognition; (3) Handwritten word recognition.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {609–618},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020620,
author = {Rao, Vinayak and Teh, Yee Whye},
title = {Fast MCMC Sampling for Markov Jump Processes and Continuous Time Bayesian Networks},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Markov jump processes and continuous time Bayesian networks are important classes of continuous time dynamical systems. In this paper, we tackle the problem of inferring unobserved paths in these models by introducing a fast auxiliary variable Gibbs sampler. Our approach is based on the idea of uniformization, and sets up a Markov chain over paths by sampling a finite set of virtual jump times and then running a standard hidden Markov model forward filtering-backward sampling algorithm over states at the set of extant and virtual jump times. We demonstrate significant computational benefits over a state-of-the-art Gibbs sampler on a number of continuous time Bayesian networks.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {619–626},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020621,
author = {Reyhani, Nima and Hino, Hideitsu and Vig\'{a}rio, Ricardo},
title = {New Probabilistic Bounds on Eigenvalues and Eigenvectors of Random Kernel Matrices},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Kernel methods are successful approaches for different machine learning problems. This success is mainly rooted in using feature maps and kernel matrices. Some methods rely on the eigenvalues/eigenvectors of the kernel matrix, while for other methods the spectral information can be used to estimate the excess risk. An important question remains on how close the sample eigenvalues/eigenvectors are to the population values. In this paper, we improve earlier results on concentration bounds for eigenvalues of general kernel matrices. For distance and inner product kernel functions, e.g. radial basis functions, we provide new concentration bounds, which are characterized by the eigenvalues of the sample covariance matrix. Meanwhile, the obstacles for sharper bounds are accounted for and partially addressed. As a case study, we derive a concentration inequality for sample kernel target-alignment.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {627–634},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020622,
author = {Rostamizadeh, Afshin and Agarwal, Alekh and Bartlett, Peter},
title = {Learning with Missing Features},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce new online and batch algorithms that are robust to data with missing features, a situation that arises in many practical applications. In the online setup, we allow for the comparison hypothesis to change as a function of the subset of features that is observed on any given round, extending the standard setting where the comparison hypothesis is fixed throughout. In the batch setup, we present a convex relaxation of a non-convex problem to jointly estimate an imputation function, used to fill in the values of missing features, along with the classification hypothesis. We prove regret bounds in the online setting and Rademacher complexity bounds for the batch i.i.d. setting. The algorithms are tested on several UCI datasets, showing superior performance over baseline imputation methods.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {635–642},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020623,
author = {Sanner, Scott and Delgado, Karina Valdivia and de Barros, Leliane Nunes},
title = {Symbolic Dynamic Programming for Discrete and Continuous State MDPs},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Many real-world decision-theoretic planning problems can be naturally modeled with discrete and continuous state Markov decision processes (DC-MDPs). While previous work has addressed automated decision-theoretic planning for DC-MDPs, optimal solutions have only been defined so far for limited settings, e.g., DC-MDPs having hyper-rectangular piecewise linear value functions. In this work, we extend symbolic dynamic programming (SDP) techniques to provide optimal solutions for a vastly expanded class of DC-MDPs. To address the inherent combinatorial aspects of SDP, we introduce the XADD — a continuous variable extension of the algebraic decision diagram (ADD) — that maintains compact representations of the exact value function. Empirically, we demonstrate an implementation of SDP with XADDs on various DC-MDPs, showing the first optimal automated solutions to DC-MDPs with linear and nonlinear piecewise partitioned value functions and showing the advantages of constraint-based pruning for XADDs.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {643–652},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020624,
author = {Schmidt, Mark and Alahari, Karteek},
title = {Generalized Fast Approximate Energy Minimization via Graph Cuts: α-Expansion β-Shrink Moves},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present α-expansion β-shrink moves, a simple generalization of the widely-used αβ-swap and α-expansion algorithms for approximate energy minimization. We show that in a certain sense, these moves dominate both αβ-swap and α-expansion moves, but unlike previous generalizations the new moves require no additional assumptions and are still solvable in polynomial-time. We show promising experimental results with the new moves, which we believe could be used in any context where α-expansions are currently employed.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {653–660},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020625,
author = {Shpitser, Ilya and Richardson, Thomas S. and Robins, James M.},
title = {An Efficient Algorithm for Computing Interventional Distributions in Latent Variable Causal Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Probabilistic inference in graphical models is the task of computing marginal and conditional densities of interest from a factorized representation of a joint probability distribution. Inference algorithms such as variable elimination and belief propagation take advantage of constraints embedded in this factorization to compute such densities efficiently. In this paper, we propose an algorithm which computes interventional distributions in latent variable causal models represented by acyclic directed mixed graphs (ADMGs). To compute these distributions efficiently, we take advantage of a recursive factorization which generalizes the usual Markov factorization for DAGs and the more recent factorization for ADMGs. Our algorithm can be viewed as a generalization of variable elimination to the mixed graph case. We show our algorithm is exponential in the mixed graph generalization of treewidth.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {661–670},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020626,
author = {Tarlow, Daniel and Givoni, Inmar E. and Zemel, Richard S. and Frey, Brendan J.},
title = {Graph Cuts is a Max-Product Algorithm},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The maximum a posteriori (MAP) configuration of binary variable models with sub-modular graph-structured energy functions can be found efficiently and exactly by graph cuts. Max-product belief propagation (MP) has been shown to be suboptimal on this class of energy functions by a canonical counterexample where MP converges to a suboptimal fixed point (Kulesza &amp; Pereira, 2008).In this work, we show that under a particular scheduling and damping scheme, MP is equivalent to graph cuts, and thus optimal. We explain the apparent contradiction by showing that with proper scheduling and damping, MP always converges to an optimal fixed point. Thus, the canonical counterexample only shows the suboptimality of MP with a particular suboptimal choice of schedule and damping. With proper choices, MP is optimal.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {671–680},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020627,
author = {Textor, Johannes and Liundefinedkiewicz, Maciej},
title = {Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Identifying and controlling bias is a key problem in empirical sciences. Causal diagram theory provides graphical criteria for deciding whether and how causal effects can be identified from observed (nonexperimental) data by covariate adjustment. Here we prove equivalences between existing as well as new criteria for adjustment and we provide a new simplified but still equivalent notion of d-separation. These lead to efficient algorithms for two important tasks in causal diagram analysis: (1) listing minimal covariate adjustments (with polynomial delay); and (2) identifying the subdiagram involved in biasing paths (in linear time). Our results improve upon existing exponential-time solutions for these problems, enabling users to assess the effects of covariate adjustment on diagrams with tens to hundreds of variables interactively in real time.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {681–688},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020628,
author = {Tur, Inma and Castelo, Robert},
title = {Learning Mixed Graphical Models from Data with <i>p</i> Larger than <i>n</i>},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Structure learning of Gaussian graphical models is an extensively studied problem in the classical multivariate setting where the sample size n is larger than the number of random variables p, as well as in the more challenging setting when p ≫ n. However, analogous approaches for learning the structure of graphical models with mixed discrete and continuous variables when p ≫ n remain largely unexplored. Here we describe a statistical learning procedure for this problem based on limited-order correlations and assess its performance with synthetic and real data.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {689–697},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020629,
author = {Ueno, Maomi},
title = {Robust Learning Bayesian Networks for Prior Belief},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recent reports have described that learning Bayesian networks are highly sensitive to the chosen equivalent sample size (ESS) in the Bayesian Dirichlet equivalence uniform (BDeu). This sensitivity often engenders some unstable or undesirable results. This paper describes some asymptotic analyses of BDeu to explain the reasons for the sensitivity and its effects. Furthermore, this paper presents a proposal for a robust learning score for ESS by eliminating the sensitive factors from the approximation of log-BDeu.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {698–707},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020630,
author = {van de Ven, Joop and Ramos, Fabio},
title = {Distributed Anytime MAP Inference},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a distributed anytime algorithm for performing MAP inference in graphical models. The problem is formulated as a linear programming relaxation over the edges of a graph. The resulting program has a constraint structure that allows application of the Dantzig-Wolfe decomposition principle. Subprograms are defined over individual edges and can be computed in a distributed manner. This accommodates solutions to graphs whose state space does not fit in memory. The decomposition master program is guaranteed to compute the optimal solution in a finite number of iterations, while the solution converges monotonically with each iteration. Formulating the MAP inference problem as a linear program allows additional (global) constraints to be defined; something not possible with message passing algorithms. Experimental results show that our algorithm's solution quality outperforms most current algorithms and it scales well to large problems.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {708–716},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020631,
author = {Steeg, Greg Ver and Galstyan, Aram},
title = {A Sequence of Relaxations Constraining Hidden Variable Models},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Many widely studied graphical models with latent variables lead to nontrivial constraints on the distribution of the observed variables. Inspired by the Bell inequalities in quantum mechanics, we refer to any linear inequality whose violation rules out some latent variable model as a "hidden variable test" for that model. Our main contribution is to introduce a sequence of relaxations which provides progressively tighter hidden variable tests. We demonstrate applicability to mixtures of sequences of i.i.d. variables, Bell inequalities, and homophily models in social networks. For the last, we demonstrate that our method provides a test that is able to rule out latent homophily as the sole explanation for correlations on a real social network that are known to be due to influence.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {717–726},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020632,
author = {Wellman, Michael P. and Hong, Lu and Page, Scott E.},
title = {The Structure of Signals: Causal Interdependence Models for Games of Incomplete Information},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Traditional economic models typically treat private information, or signals, as generated from some underlying state. Recent work has explicated alternative models, where signals correspond to interpretations of available information. We show that the difference between these formulations can be sharply cast in terms of causal dependence structure, and employ graphical models to illustrate the distinguishing characteristics. The graphical representation supports inferences about signal patterns in the interpreted framework, and suggests how results based on the generated model can be extended to more general situations. Specific insights about bidding games in classical auction mechanisms derive from qualitative graphical models.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {727–735},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020633,
author = {Wilson, Andrew Gordon and Ghahramani, Zoubin},
title = {Generalised Wishart Processes},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce a new stochastic process called the generalised Wishart process (GWP). It is a collection of positive semi-definite random matrices indexed by any arbitrary input variable. We use this process as a prior over dynamic (e.g. time varying) covariance matrices Σ(t). The GWP captures a diverse class of covariance dynamics, naturally handles missing data, scales nicely with dimension, has easily interpretable parameters, and can use input variables that include covariates other than time. We describe how to construct the GWP, introduce general procedures for inference and prediction, and show that it outperforms its main competitor, multivariate GARCH, even on financial data that especially suits GARCH.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {736–744},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020634,
author = {Yan, Feng and Xu, Zenglin and Qi, Yuan},
title = {Sparse Matrix-Variate Gaussian Process Blockmodels for Network Modeling},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We face network data from various sources, such as protein interactions and online social networks. A critical problem is to model network interactions and identify latent groups of network nodes. This problem is challenging due to many reasons. For example, the network nodes are interdependent instead of independent of each other, and the data are known to be very noisy (e.g., missing edges). To address these challenges, we propose a new relational model for network data, Sparse Matrix-variate Gaussian process Blockmodel (SMGB). Our model generalizes popular bilinear generative models and captures nonlinear network interactions using a matrix-variate Gaussian process with latent membership variables. We also assign sparse prior distributions on the latent membership variables to learn sparse group assignments for individual network nodes. To estimate the latent variables efficiently from data, we develop an efficient variational expectation maximization method. We compared our approaches with several state-of-the-art network models on both synthetic and real-world network datasets. Experimental results demonstrate SMGBs outperform the alternative approaches in terms of discovering latent classes or predicting unknown interactions.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {745–752},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020635,
author = {Yang, Jian-Bo and Tsang, Ivor W.},
title = {Hierarchical Maximum Margin Learning for Multi-Class Classification},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Due to myriads of classes, designing accurate and efficient classifiers becomes very challenging for multi-class classification. Recent research has shown that class structure learning can greatly facilitate multi-class learning. In this paper, we propose a novel method to learn the class structure for multi-class classification problems. The class structure is assumed to be a binary hierarchical tree. To learn such a tree, we propose a maximum separating margin method to determine the child nodes of any internal node. The proposed method ensures that two class-groups represented by any two sibling nodes are most separable. In the experiments, we evaluate the accuracy and efficiency of the proposed method over other multi-class classification methods on real world large-scale problems. The results show that the proposed method outperforms benchmark methods in terms of accuracy for most datasets and performs comparably with other class structure learning methods in terms of efficiency for all datasets.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {753–760},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020636,
author = {Yarkony, Julian and Ihler, Alexander T. and Fowlkes, Charless C.},
title = {Planar Cycle Covering Graphs},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We describe a new variational lower-bound on the minimum energy configuration of a planar binary Markov Random Field (MRF). Our method is based on adding auxiliary nodes to every face of a planar embedding of the graph in order to capture the effect of unary potentials. A ground state of the resulting approximation can be computed efficiently by reduction to minimum-weight perfect matching. We show that optimization of variational parameters achieves the same lower-bound as dual-decomposition into the set of all cycles of the original graph. We demonstrate that our variational optimization converges quickly and provides high-quality solutions to hard combinatorial problems 10-100x faster than competing algorithms that optimize the same bound.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {761–769},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020637,
author = {Yarkony, Julian and Morshed, Ragib and Ihler, Alexander T. and Fowlkes, Charless C.},
title = {Tightening MRF Relaxations with Planar Subproblems},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We describe a new technique for computing lower-bounds on the minimum energy configuration of a planar Markov Random Field (MRF). Our method successively adds large numbers of constraints and enforces consistency over binary projections of the original problem state space. These constraints are represented in terms of subproblems in a dual-decomposition framework that is optimized using subgradient techniques. The complete set of constraints we consider enforces cycle consistency over the original graph. In practice we find that the method converges quickly on most problems with the addition of a few subproblems and outperforms existing methods for some interesting classes of hard potentials.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {770–777},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020638,
author = {Yu, Yao-Liang and Schuurmans, Dale},
title = {Rank/Norm Regularization with Closed-Form Solutions: Application to Subspace Clustering},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {When data is sampled from an unknown sub-space, principal component analysis (PCA) provides an effective way to estimate the sub-space and hence reduce the dimension of the data. At the heart of PCA is the Eckart-Young-Mirsky theorem, which characterizes the best rank k approximation of a matrix. In this paper, we prove a generalization of the Eckart-Young-Mirsky theorem under all unitarily invariant norms. Using this result, we obtain closed-form solutions for a set of rank/norm regularized problems, and derive closed-form solutions for a general class of subspace clustering problems (where data is modelled by unions of unknown subspaces). From these results we obtain new theoretical insights and promising experimental results.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {778–785},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020639,
author = {Yu, Haohai and van Engelen, Robert},
title = {Measuring the Hardness of Stochastic Sampling on Bayesian Networks with Deterministic Causalities: The <i>k</i>-Test},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Approximate Bayesian inference is NP-hard. Dagum and Luby defined the Local Variance Bound (LVB) to measure the approximation hardness of Bayesian inference on Bayesian networks, assuming the networks model strictly positive joint probability distributions, i.e. zero probabilities are not permitted. This paper introduces the k-test to measure the approximation hardness of inference on Bayesian networks with deterministic causalities in the probability distribution, i.e. when zero conditional probabilities are permitted. Approximation by stochastic sampling is a widely-used inference method that is known to suffer from inefficiencies due to sample rejection. The k-test predicts when rejection rates of stochastic sampling a Bayesian network will be low, modest, high, or when sampling is intractable.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {786–795},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020640,
author = {Zhang, Chao and Tao, Dacheng},
title = {Risk Bounds for Infinitely Divisible Distribution},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we study the risk bounds for samples independently drawn from an infinitely divisible (ID) distribution. In particular, based on a martingale method, we develop two deviation inequalities for a sequence of random variables of an ID distribution with zero Gaussian component. By applying the deviation inequalities, we obtain the risk bounds based on the covering number for the ID distribution. Finally, we analyze the asymptotic convergence of the risk bound derived from one of the two deviation inequalities and show that the convergence rate of the bound is faster than the result for the generic i.i.d. empirical process (Mendelson, 2003).},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {796–803},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020641,
author = {Zhang, Kun and Peters, Jonas and Janzing, Dominik and Sch\"{o}lkopf, Bernhard},
title = {Kernel-Based Conditional Independence Test and Application in Causal Discovery},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Conditional independence testing is an important problem, especially in Bayesian network learning and causal discovery. Due to the curse of dimensionality, testing for conditional independence of continuous variables is particularly challenging. We propose a Kernel-based Conditional Independence test (KCI-test), by constructing an appropriate test statistic and deriving its asymptotic distribution under the null hypothesis of conditional independence. The proposed method is computationally efficient and easy to implement. Experimental results show that it outperforms other methods, especially when the conditioning set is large or the sample size is not very large, in which case other methods encounter difficulties.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {804–813},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020642,
author = {Zhang, Xinhua and Saha, Ankan and Vishwanathan, S. V.N.},
title = {Smoothing Multivariate Performance Measures},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A Support Vector Method for multivariate performance measures was recently introduced by Joachims (2005). The underlying optimization problem is currently solved using cutting plane methods such as SVM-Perf and BMRM. One can show that these algorithms converge to an e accurate solution in O(1/λε) iterations, where λ is the trade-off parameter between the regularizer and the loss function. We present a smoothing strategy for multivariate performance scores, in particular precision/recall break-even point and ROCArea. When combined with Nesterov's accelerated gradient algorithm our smoothing strategy yields an optimization algorithm which converges to an ε accurate solution in O*(min 1/ε, 1/√λε iterations. Furthermore, the cost per iteration of our scheme is the same as that of SVM-Perf and BMRM. Empirical evaluation on a number of publicly available datasets shows that our method converges significantly faster than cutting plane methods without sacrificing generalization ability.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {814–821},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020643,
author = {Zheng, Lu and Mengshoel, Ole and Chong, Jike},
title = {Belief Propagation by Message Passing in Junction Trees: Computing Each Message Faster Using GPU Parallelization},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Compiling Bayesian networks (BNs) to junction trees and performing belief propagation over them is among the most prominent approaches to computing posteriors in BNs. However, belief propagation over junction tree is known to be computationally intensive in the general case. Its complexity may increase dramatically with the connectivity and state space cardinality of Bayesian network nodes. In this paper, we address this computational challenge using GPU parallelization. We develop data structures and algorithms that extend existing junction tree techniques, and specifically develop a novel approach to computing each belief propagation message in parallel. We implement our approach on an NVIDIA GPU and test it using BNs from several applications. Experimentally, we study how junction tree parameters affect parallelization opportunities and hence the performance of our algorithm. We achieve speedups ranging from 0.68 to 9.18 for the BNs studied.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {822–830},
numpages = {9},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020644,
author = {Zhu, Jun and Xing, Eric P.},
title = {Sparse Topical Coding},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present sparse topical coding (STC), a non-probabilistic formulation of topic models for discovering latent representations of large collections of data. Unlike probabilistic topic models, STC relaxes the normalization constraint of admixture proportions and the constraint of defining a normalized likelihood function. Such relaxations make STC amenable to: 1) directly control the sparsity of inferred representations by using sparsity-inducing regularizers; 2) be seamlessly integrated with a convex error function (e.g., SVM hinge loss) for supervised learning; and 3) be efficiently learned with a simply structured coordinate descent algorithm. Our results demonstrate the advantages of STC and supervised MedSTC on identifying topical meanings of words and improving classification accuracy and time efficiency.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {831–838},
numpages = {8},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020645,
author = {Zscheischler, Jakob and Janzing, Dominik and Zhang, Kun},
title = {Testing Whether Linear Equations Are Causal: A Free Probability Theory Approach},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a method that infers whether linear relations between two high-dimensional variables X and Y are due to a causal influence from X to Y or from Y to X. The earlier proposed so-called Trace Method is extended to the regime where the dimension of the observed variables exceeds the sample size. Based on previous work, we postulate conditions that characterize a causal relation between X and Y. Moreover, we describe a statistical test and argue that both causal directions are typically rejected if there is a common cause. A full theoretical analysis is presented for the deterministic case but our approach seems to be valid for the noisy case, too, for which we additionally present an approach based on a sparsity constraint. The discussed method yields promising results for both simulated and real world data.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {839–848},
numpages = {10},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020647,
author = {Cavallo, Ruggiero},
title = {Incentives in Group Decision-Making with Uncertainty and Subjective Beliefs},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We address the problem of decision-making in group settings where there is uncertainty and disagreement about the utility that actions will yield. While previous mechanism design work deals with uncertainty by assuming agents are Bayesian with common prior beliefs, we instead take agent subjectivity more seriously, considering individual beliefs as primitives and eschewing any assumptions about their origins. Each individual brings his own private subjective beliefs about each action with respect to social welfare, which a decision-maker aims to maximize. Agents and the decision-maker revise beliefs based on those held by others; motivated by the psychological belief aggregation literature, we adopt a weighted averaging model, where the weight one agent assigns to another's beliefs can be thought of as the agent's "trust" in the other. Each agent—and also the decision-maker—has his own trust level for each other agent.For instance if there are two agents and two actions, with one agent expecting the social welfare of the first action to be 10 and the second to be 8, and the other agent expecting the social welfare of the first action to be 5 and the second to be 8, if the center trusts each agent equally he will prefer the second action. But since heterogeneity of agent (and decision-maker) trust levels can lead to conflicting revised-beliefs about which action is optimal, there is a problem of incentives. In the above example, even assuming a scheme that aligns all agents' incentives towards maximizing social welfare, if the first agent puts all weight on his own opinion and zero weight on the other's he can expect to benefit by overstating his beliefs about the superiority of the first action. The discrepancy between the agent's trust levels and those used by the decision-maker leads to manipulation.We provide a payment mechanism that yields truthful reporting and thus implementation of the decision-maker's desired choice in an ex post equilibrium for arbitrary beliefs and arbitrary trust levels. In other words, we solve the disensus problem that arises when agents (and perhaps the decision-maker) disagree about how to weigh each others' information in aggregating beliefs. The main contribution is to show that efficient choice is possible with strategic agents even when "efficient" is defined subjectively by the decision-maker (according to his particular trust levels) and the foundational assumption of Bayesian reasoning is abandoned. A stubborn weakness of the proposal is that it requires agent trust levels to be a priori known by the decision-maker, while in many practical settings they are likely to be essentially private.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {849},
numpages = {1},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020648,
author = {Colombo, Diego and Maathuis, Marloes H. and Kalisch, Markus and Richardson, Thomas S.},
title = {Learning High-Dimensional DAGs with Latent and Selection Variables},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {850},
numpages = {1},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020649,
author = {Hauser, Alain and B\"{u}hlmann, Peter},
title = {Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs (Abstract)},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {851},
numpages = {1},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020650,
author = {Listgarten, Jennifer and Kadie, Carl and Schadt, Eric E. and Heckerman, David},
title = {Correction for Hidden Confounders in the Genetic Analysis of Gene Expression},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Understanding the genetic underpinnings of disease is important for screening, treatment, drug development, and basic biological insight. One way of getting at such an understanding is to find out which parts of our DNA, such as single-nucleotide polymorphisms (SNPs), affect particular intermediary processes such as gene expression. Naively, such associations can be identified using a simple statistical test on all paired combinations of genetic variants and gene transcripts. However, a wide variety of confounders lie hidden in the data, leading to both spurious associations and missed associations if not properly addressed. We present a statistical model that jointly corrects for two particular kinds of hidden structure: genetic or population structure (e.g., race, family-relatedness), and microarray expression artifacts (e.g., batch effects), when these confounders are unknown. Applying our method to both real and synthetic, human and mouse data, we demonstrate the need for such a joint correction of confounders, and also the disadvantages of other possible approaches based on those in the current literature.},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {852},
numpages = {1},
location = {Barcelona, Spain},
series = {UAI'11}
}

@inproceedings{10.5555/3020548.3020651,
author = {Steeg, Greg Ver and Galstyan, Aram and Allahverdyan, Armen},
title = {Statistical Mechanics of Semi—Supervised Clustering in Sparse Graphs},
year = {2011},
isbn = {9780974903972},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
pages = {853},
numpages = {1},
location = {Barcelona, Spain},
series = {UAI'11}
}

