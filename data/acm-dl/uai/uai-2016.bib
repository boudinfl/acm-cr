@inproceedings{10.5555/3020948.3020950,
author = {Amin, Kareem and Singh, Satinder and Wellman, Michael P.},
title = {Gradient Methods for Stackelberg Security Games},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Stackelberg games are two-stage games in which the first player (called the leader) commits to a strategy, after which the other player (the follower) selects a best-response. These types of games have seen numerous practical application in security settings, where the leader (in this case, a defender) must allocate resources to protect various targets. Real world applications include the scheduling of US federal air marshals to international flights, and resource allocation at LAX airport. However, the best known algorithm for solving general Stackelberg games requires solving Integer Programs, and fails to scale beyond a few (significantly smaller than 100) number of leader actions, or follower types. In this paper, we present a new gradient-based approach for solving large Stackelberg games in security settings. Large-scale control problems are often solved by restricting the controller to a rich parameterized class of policies; the optimal control can then be computed using Monte Carlo gradient methods. We demonstrate that the same approach can be taken in a strategic setting. We evaluate our approach empirically, demonstrating that it can have negligible regret against the leader's true equilibrium strategy, while scaling to large games.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {2–11},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020951,
author = {Arbour, David and Marazopoulou, Katerina and Jensen, David},
title = {Inferring Causal Direction from Relational Data},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Inferring the direction of causal dependence from observational data is a fundamental problem in many scientific fields. Significant progress has been made in inferring causal direction from data that are independent and identically distributed (i.i.d.), but little is understood about this problem in the more general relational setting with multiple types of interacting entities. This work examines the task of inferring the causal direction of peer dependence in relational data. We show that, in contrast to the i.i.d. setting, the direction of peer dependence can be inferred using simple procedures, regardless of the form of the underlying distribution, and we provide a theoretical characterization on the identifiability of direction. We then examine the conditions under which the presence of confounding can be detected. Finally, we demonstrate the efficacy of the proposed methods with synthetic experiments, and we provide an application on real-world data.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {12–21},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020952,
author = {Azar, Mohammad Gheshlaghi and Dyer, Eva L. and K\"{o}rding, Konrad P.},
title = {Convex Relaxation Regression: Black-Box Optimization of Smooth Functions by Learning Their Convex Envelopes},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Finding efficient and provable methods to solve non-convex optimization problems is an outstanding challenge in machine learning and optimization theory. A popular approach used to tackle non-convex problems is to use convex relaxation techniques to find a convex surrogate for the problem. Unfortunately, convex relaxations typically must be found on a problem-by-problem basis. Thus, providing a general-purpose strategy to estimate a convex relaxation would have a wide reaching impact. Here, we introduce Convex Relaxation Regression (CoRR), an approach for learning convex relaxations for a class of smooth functions. The idea behind our approach is to estimate the convex envelope of a function f by evaluating f at a set of T random points and then fitting a convex function to these function evaluations. We prove that with probability greater than 1 - δ, the solution of our algorithm converges to the global optimizer of f with error O((log(1/δ/T)α) for some α &gt; 0. Our approach enables the use of convex optimization tools to solve non-convex optimization problems.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {22–31},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020953,
author = {Balog, Matej and Lakshminarayanan, Balaji and Ghahramani, Zoubin and Roy, Daniel M. and Teh, Yee Whye},
title = {The Mondrian Kernel},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce the Mondrian kernel, a fast random feature approximation to the Laplace kernel. It is suitable for both batch and online learning, and admits a fast kernel-width-selection procedure as the random features can be re-used efficiently for all kernel widths. The features are constructed by sampling trees via a Mondrian process [Roy and Teh, 2009], and we highlight the connection to Mondrian forests [Lakshminarayanan et al., 2014], where trees are also sampled via a Mondrian process, but fit independently. This link provides a new insight into the relationship between kernel methods and random forests.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {32–41},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020954,
author = {Balsubramani, Akshay and Ramdas, Aaditya},
title = {Sequential Nonparametric Testing with the Law of the Iterated Logarithm},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a new algorithmic framework for sequential hypothesis testing with i.i.d. data, which includes A/B testing, nonparametric two-sample testing, and independence testing as special cases. It is novel in several ways: (a) it takes linear time and constant space to compute on the fly, (b) it has the same power guarantee (up to a small factor) as a nonsequential version of the test with the same computational constraints, and (c) it accesses only as many samples as are required - its stopping time adapts to the unknown difficulty of the problem. All our test statistics are constructed to be zero-mean martingales under the null hypothesis, and the rejection threshold is governed by a uniform non-asymptotic law of the iterated logarithm (LIL). For nonparametric two-sample mean testing, we also provide a finite-sample power analysis, and the first non-asymptotic stopping time analysis for this class of problems. We verify our predictions for type I and II errors and stopping times using simulations.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {42–51},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020955,
author = {Boutilier, Craig and Lu, Tyler},
title = {Budget Allocation Using Weakly Coupled, Constrained Markov Decision Processes},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the problem of budget (or other resource) allocation in sequential decision problems involving a large number of concurrently running sub-processes, whose only interaction is through their consumption of budget. Our first contribution is the introduction of budgeted MDPs (BMDPs), an MDP model in which policies/values are a function of available budget, (c.f. constrained MDPs which are solved given a fixed budget). BMDPs allow one to explicitly trade off allocated budget and expected value. We show that optimal value functions are concave, non-decreasing in budget, and piecewise-linear in the finite horizon case, and can be computed by dynamic programming (and support ready approximation). Our second contribution is a method that exploits BMDP solutions to allocate budget to a large number of independent BMDPs, coupled only by their common budget pool. The problem can be cast as a multiple-choice knapsack problem, which admits an efficient, optimal greedy algorithm. Empirical results in an online advertising domain confirm the efficacy of our methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {52–61},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020956,
author = {Calandriello, Daniele and Lazaric, Alessandro and Valko, Michal},
title = {Analysis of Nystr\"{o}m Method with Sequential Ridge Leverage Score Sampling},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Large-scale kernel ridge regression (KRR) is limited by the need to store a large kernel matrix Kt. To avoid storing the entire matrix Kt, Nystr\"{o}m methods subsample a subset of columns of the kernel matrix, and efficiently find anapproximate KRR solution on the reconstructed Kt. The chosen subsampling distribution in turn affects the statistical and computational tradeoffs. For KRR problems, [16, 1] show that a sampling distribution proportional to the ridge leverage scores (RLSs) provides strong reconstruction guarantees for Kt. While exact RLSs are as difficult to compute as a KRR solution, we may be able to approximate them well enough. In this paper, we study KRR problems in a sequential setting and introduce the INK-ESTIMATE algorithm, that incrementally computes the RLSs estimates. INK-ESTIMATE maintains a small sketch of Kt, that at each step is used to compute an intermediate estimate of the RLSs. First, our sketch update does not require access to previously seen columns, and therefore a single pass over the kernel matrix is sufficient. Second, the algorithm requires a fixed, small space budget to run dependent only on the effective dimension of the kernel matrix. Finally, our sketch provides strong approximation guarantees on the distance ‖Kt - Kt‖2, and on the statistical risk of the approximate KRR solution at any time, because all our guarantees hold at any intermediate step.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {62–71},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020957,
author = {Chalupka, Krzysztof and Bischoff, Tobias and Perona, Pietro and Eberhardt, Frederick},
title = {Unsupervised Discovery of El Nino Using Causal Feature Learning on Microlevel Climate Data},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We show that the climate phenomena of El Ni\~{n}o and La Ni\~{n}a arise naturally as states of macro-variables when our recent causal feature learning framework (Chalupka et al., 2015, 2016) is applied to micro-level measures of zonal wind (ZW) and sea surface temperatures (SST) taken over the equatorial band of the Pacific Ocean. The method identifies these unusual climate states on the basis of the relation between ZW and SST patterns without any input about past occurrences of El Ni\~{n}o or La Ni\~{n}a. The simpler alternatives of (i) clustering the SST fields while disregarding their relationship with ZW patterns, or (ii) clustering the joint ZW-SST patterns, do not discover El Ni\~{n}o. We discuss the degree to which our method supports a causal interpretation and use a low-dimensional toy example to explain its success over other clustering approaches. Finally, we propose a new robust and scalable alternative to our original algorithm (Chalupka et al., 2016), which circumvents the need for high-dimensional density learning.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {72–81},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020958,
author = {Chandrasekaran, Muthukumaran and Eck, Adam and Doshi, Prashant and Soh, Leenkiat},
title = {Individual Planning in Open and Typed Agent Systems},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Open agent systems are multiagent systems in which one or more agents may leave the system at any time possibly resuming after some interval and in which new agents may also join. Planning in such systems becomes challenging in the absence of inter-agent communication because agents must predict if others have left the system or new agents are now present to decide on possibly choosing a different line of action. In this paper, we prioritize open systems where agents of differing types may leave and possibly reenter but new agents do not join. With the help of a realistic domain - wildfire suppression - we motivate the need for individual planning in open environments and present a first approach for robust decision-theoretic planning in such multiagent systems. Evaluations in domain simulations clearly demonstrate the improved performance compared to previous methods that disregard the openness.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {82–91},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020959,
author = {Chehreghani, Morteza Haghir and Chehreghani, Mostafa Haghir},
title = {Modeling Transitivity in Complex Networks},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {An important source of high clustering coefficient in real-world networks is transitivity. However, existing algorithms which model transitivity suffer from at least one of the following problems: i) they produce graphs of a specific class like bipartite graphs, ii) they do not give an analytical argument for the high clustering coefficient of the model, and iii) their clustering coefficient is still significantly lower than real-world networks. In this paper, we propose a new model for complex networks which is based on adding transitivity to scale-free models. We theoretically analyze the model and provide analytical arguments for its different properties. In particular, we calculate a lower bound on the clustering coefficient of the model which is independent of the network size, as seen in real-world networks. More than theoretical analysis, the main properties of the model are evaluated empirically and it is shown that the model can precisely simulate real-world networks from different domains with and different specifications.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {92–101},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020960,
author = {Chen, Xiangli and Monfort, Mathew and Ziebart, Brian D. and Carr, Peter},
title = {Adversarial Inverse Optimal Control for General Imitation Learning Losses and Embodiment Transfer},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We develop a general framework for inverse optimal control that distinguishes between rationalizing demonstrated behavior and imitating inductively inferred behavior. This enables learning for more general imitative evaluation measures and differences between the capabilities of the demonstrator and those of the learner (i.e., differences in embodiment). Our formulation takes the form of a zero-sum game between a learner attempting to minimize an imitative loss measure, and an adversary attempting to maximize the loss by approximating the demonstrated examples in limited ways. We establish the consistency and generalization guarantees of this approach and illustrate its benefits on real and synthetic imitation learning tasks.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {102–111},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020961,
author = {Chen, Junxiang and Dy, Jennifer},
title = {A Generative Block-Diagonal Model for Clustering},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Probabilistic mixture models are among the most important clustering methods. These models assume that the feature vectors of the samples can be described by a mixture of several components. Each of these components follows a distribution of a certain form. In recent years, there has been an increasing amount of interest and work in similarity-matrix-based methods. Rather than considering the feature vectors, these methods learn patterns by observing the similarity matrix that describes the pairwise relative similarity between each pair of samples. However, there are limited works in probabilistic mixture model for clustering with input data in the form of a similarity matrix. Observing this, we propose a generative model for clustering that finds the block-diagonal structure of the similarity matrix to ensure that the samples within the same cluster (diagonal block) are similar while the samples from different clusters (off-diagonal block) are less similar. In this model, we assume the elements in the similarity matrix follow one of beta distributions, depending on whether the element belongs to one of the diagonal blocks or to off-diagonal blocks. The assignment of the element to a block is determined by the cluster indicators that follow categorical distributions. Experiments on both synthetic and real data show that the performance of the proposed method is comparable to the state-of-the-art methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {112–121},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020962,
author = {Chen, Jianhui and Yang, Tianbao and Lin, Qihang and Zhang, Lijun and Chang, Yi},
title = {Optimal Stochastic Strongly Convex Optimization with a Logarithmic Number of Projections},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider stochastic strongly convex optimization with a complex inequality constraint. This complex inequality constraint may lead to computationally expensive projections in algorithmic iterations of the stochastic gradient descent (SGD) methods. To reduce the computation costs pertaining to the projections, we propose an Epoch-Projection Stochastic Gradient Descent (Epro-SGD) method. The proposed Epro-SGD method consists of a sequence of epochs; it applies SGD to an augmented objective function at each iteration within the epoch, and then performs a projection at the end of each epoch. Given a strongly convex optimization and for a total number of T iterations, Epro-SGD requires only log(T) projections, and meanwhile attains an optimal convergence rate of O(1/T), both in expectation and with a high probability. To exploit the structure of the optimization problem, we propose a proximal variant of Epro-SGD, namely Epro-ORDA, based on the optimal regularized dual averaging method. We apply the proposed methods on real-world applications; the empirical results demonstrate the effectiveness of our methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {122–131},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020963,
author = {Chen, Jinghui and Gu, Quanquan},
title = {Accelerated Stochastic Block Coordinate Gradient Descent for Sparsity Constrained Nonconvex Optimization},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose an accelerated stochastic block coordinate descent algorithm for nonconvex optimization under sparsity constraint in the high dimensional regime. The core of our algorithm is leveraging both stochastic partial gradient and full partial gradient restricted to each coordinate block to accelerate the convergence. We prove that the algorithm converges to the unknown true parameter at a linear rate, up to the statistical error of the underlying model. Experiments on both synthetic and real datasets backup our theory.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {132–141},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020964,
author = {Du, Changying and Du, Changde and Long, Guoping and He, Qing and Li, Yucheng},
title = {Online Bayesian Multiple Kernel Bipartite Ranking},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bipartite ranking aims to maximize the area under the ROC curve (AUC) of a decision function. To tackle this problem when the data appears sequentially, existing online AUC maximization methods focus on seeking a point estimate of the decision function in a linear or predefined single kernel space, and cannot learn effective kernels automatically from the streaming data. In this paper, we first develop a Bayesian multiple kernel bipartite ranking model, which circumvents the kernel selection problem by estimating a posterior distribution over the model weights. To make our model applicable to streaming data, we then present a kernelized online Bayesian passive-aggressive learning framework by maintaining a variational approximation to the posterior based on data augmentation. Furthermore, to efficiently deal with large-scale data, we design a fixed budget strategy which can effectively control online model complexity. Extensive experimental studies confirm the superiority of our Bayesian multi-kernel approach.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {142–151},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020965,
author = {Eggeling, Ralf and Koivisto, Mikko},
title = {Pruning Rules for Learning Parsimonious Context Trees},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We give a novel algorithm for finding a parsimonious context tree (PCT) that best fits a given data set. PCTs extend traditional context trees by allowing context-specific grouping of the states of a context variable, also enabling skipping the variable. However, they gain statistical efficiency at the cost of computational efficiency, as the search space of PCTs is of tremendous size. We propose pruning rules based on efficiently computable score upper bounds with the aim of reducing this search space significantly. While our concrete bounds exploit properties of the BIC score, the ideas apply also to other scoring functions. Empirical results show that our algorithm is typically an order-of-magnitude faster than a recently proposed memory-intensive algorithm, or alternatively, about equally fast but using dramatically less memory.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {152–161},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020966,
author = {Etesami, Jalal and Kiyavash, Negar and Zhang, Kun and Singhal, Kushagra},
title = {Learning Network of Multivariate Hawkes Processes: A Time Series Approach},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Learning the influence structure of multiple time series data is of great interest to many disciplines. This paper studies the problem of recovering the causal structure in network of multivariate linear Hawkes processes. In such processes, the occurrence of an event in one process affects the probability of occurrence of new events in some other processes. Thus, a natural notion of causality exists between such processes captured by the support of the excitation matrix. We show that the resulting causal influence network is equivalent to the Directed Information graph (DIG) of the processes, which encodes the causal factorization of the joint distribution of the processes. Furthermore, we present an algorithm for learning the support of excitation matrix of a class of multivariate Hawkes processes with exponential exciting functions (or equivalently the DIG). The performance of the algorithm is evaluated on synthesized multivariate Hawkes networks as well as a stock market and MemeTracker real-world dataset.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {162–171},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020967,
author = {Fagan, Francois and Bhandari, Jalaj and Cunningham, John P.},
title = {Elliptical Slice Sampling with Expectation Propagation},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Markov Chain Monte Carlo techniques remain the gold standard for approximate Bayesian inference, but their practical issues — including onerous runtime and sensitivity to tuning parameters — often lead researchers to use faster but typically less accurate deterministic approximations. Here we couple the fast but biased deterministic approximation offered by expectation propagation with elliptical slice sampling, a state-of-the-art MCMC method. We extend our hybrid deterministic-MCMC method to include recycled samples and analytical slices, and we rigorously prove the validity of each enhancement. Taken together, we show that these advances provide an order of magnitude gain in efficiency beyond existing state-of-the-art sampling techniques in Bayesian classification and multivariate gaussian quadrature problems.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {172–181},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020968,
author = {Flaxman, Seth and Sejdinovic, Dino and Cunningham, John P. and Filippi, Sarah},
title = {Bayesian Learning of Kernel Embeddings},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Kernel methods are one of the mainstays of machine learning, but the problem of kernel learning remains challenging, with only a few heuristics and very little theory. This is of particular importance in methods based on estimation of kernel mean embeddings of probability measures. For characteristic kernels, which include most commonly used ones, the kernel mean embedding uniquely determines its probability measure, so it can be used to design a powerful statistical testing framework, which includes non-parametric two-sample and independence tests. In practice, however, the performance of these tests can be very sensitive to the choice of kernel and its lengthscale parameters. To address this central issue, we propose a new probabilistic model for kernel mean embeddings, the Bayesian Kernel Embedding model, combining a Gaussian process prior over the Reproducing Kernel Hilbert Space containing the mean embedding with a conjugate likelihood function, thus yielding a closed form posterior over the mean embedding. The posterior mean of our model is closely related to recently proposed shrinkage estimators for kernel mean embeddings, while the posterior uncertainty is a new, interesting feature with various possible applications. Critically for the purposes of kernel learning, our model gives a simple, closed form marginal pseudolikelihood of the observed data given the kernel hyperparameters. This marginal pseudolikelihood can either be optimized to inform the hyperparameter choice or fully Bayesian inference can be used.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {182–191},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020969,
author = {Foulds, James and Geumlek, Joseph and Welling, Max and Chaudhuri, Kamalika},
title = {On the Theory and Practice of Privacy-Preserving Bayesian Data Analysis},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian inference has great promise for the privacy-preserving analysis of sensitive data, as posterior sampling automatically preserves differential privacy, an algorithmic notion of data privacy, under certain conditions (Dimitrakakis et al., 2014; Wang et al., 2015b). While this one posterior sample (OPS) approach elegantly provides privacy "for free," it is data inefficient in the sense of asymptotic relative efficiency (ARE). We show that a simple alternative based on the Laplace mechanism, the workhorse of differential privacy, is as asymptotically efficient as non-private posterior inference, under general assumptions. This technique also has practical advantages including efficient use of the privacy budget for MCMC. We demonstrate the practicality of our approach on a time-series analysis of sensitive military records from the Afghanistan and Iraq wars disclosed by the Wikileaks organization.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {192–201},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020970,
author = {Fox, Roy and Pakman, Ari and Tishby, Naftali},
title = {Taming the Noise in Reinforcement Learning via Soft Updates},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Model-free reinforcement learning algorithms, such as Q-learning, perform poorly in the early stages of learning in noisy environments, because much effort is spent unlearning biased estimates of the state-action value function. The bias results from selecting, among several noisy estimates, the apparent optimum, which may actually be suboptimal. We propose G-learning, a new off-policy learning algorithm that regularizes the value estimates by penalizing deterministic policies in the beginning of the learning process. We show that this method reduces the bias of the value-function estimation, leading to faster convergence to the optimal value and the optimal policy. Moreover, G-learning enables the natural incorporation of prior domain knowledge, when available. The stochastic nature of G-learning also makes it avoid some exploration costs, a property usually attributed only to on-policy algorithms. We illustrate these ideas in several examples, where G-learning results in significant improvements of the convergence rate and the cost of the learning process.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {202–211},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020971,
author = {Fu, Tianfan and Luo, Luo and Zhang, Zhihua},
title = {Quasi-Newton Hamiltonian Monte Carlo},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The Hamiltonian Monte Carlo (HMC) method has become significantly popular in recent years. It is the state-of-the-art MCMC sampler due to its more efficient exploration to the parameter space than the standard random-walk based proposal. The key idea behind HMC is that it makes use of first-order gradient information about the target distribution. In this paper, we propose a novel dynamics using second-order geometric information about the desired distribution. The second-order information is estimated by using a quasi-Newton method (say, the BFGS method), so it does not bring heavy computational burden. Moreover, our theoretical analysis guarantees that this dynamics remains the target distribution invariant. As a result, the proposed quasi-Newton Hamiltonian Monte Carlo (QNHMC) algorithm traverses the parameter space more efficiently than the standard HMC and produces a less correlated series of samples. Finally, empirical evaluation on simulated data verifies the effectiveness and efficiency of our approach. We also conduct applications of QNHMC in Bayesian logistic regression and online Bayesian matrix factorization problems.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {212–221},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020972,
author = {Futoma, Joseph and Sendak, Mark and Cameron, C. Blake and Heller, Katherine},
title = {Scalable Joint Modeling of Longitudinal and Point Process Data for Disease Trajectory Prediction and Improving Management of Chronic Kidney Disease},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A major goal in personalized medicine is the ability to provide individualized predictions about the future trajectory of a disease. Moreover, for many complex chronic diseases, patients simultaneously have additional comorbid conditions. Accurate determination of the risk of developing serious complications associated with a disease or its comorbidities may be more clinically useful than prediction of future disease trajectory in such cases. We propose a novel probabilistic generative model that can provide individualized predictions of future disease progression while jointly modeling the pattern of related recurrent adverse events. We fit our model using a scalable variational inference algorithm and apply our method to a large dataset of longitudinal electronic patient health records. Our model gives superior performance in terms of both prediction of future disease trajectories and of future serious events when compared to non-joint models. Our predictions are currently being utilized by our local accountable care organization during chart reviews of high risk patients.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {222–231},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020973,
author = {Gao, Tianxiang and Jojic, Vladimir},
title = {Degrees of Freedom in Deep Neural Networks},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we explore degrees of freedom in deep sigmoidal neural networks. We show that the degrees of freedom in these models are related to the expected optimism, which is the expected difference between test error and training error. We provide an efficient Monte-Carlo method to estimate the degrees of freedom for multi-class classification methods. We show that the degrees of freedom is less than the parameter count in a simple XOR network. We extend these results to neural nets trained on synthetic and real data and investigate the impact of network's architecture and different regularization choices. The degrees of freedom in deep networks is dramatically less than the number of parameters. In some real datasets, the number of parameters is several orders of magnitude larger than the degrees of freedom. Further, we observe that for fixed number of parameters, deeper networks have less degrees of freedom exhibiting a regularization-by-depth. Finally, we show that the degrees of freedom of deep neural networks can be used in a model selection criterion. This criterion has comparable performance to cross-validation with lower computational cost.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {232–241},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020974,
author = {Gaunt, Alex and Borsa, Diana and Bachrach, Yoram},
title = {Training Deep Neural Nets to Aggregate Crowdsourced Responses},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a new method for aggregating crowdsourced responses, based on a deep neural network. Once trained, the aggregator network gets as input the responses of multiple participants to the same set of questions, and outputs its prediction for the correct response to each question. We empirically evaluate our approach on a dataset of responses to a standard IQ questionnaire, and show it outperforms existing state-of-the-art methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {242–251},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020975,
author = {Gilbert, Hugo and Zanuttini, Bruno and Viappiani, Paolo and Weng, Paul and Nicart, Esther},
title = {Model-Free Reinforcement Learning with Skew-Symmetric Bilinear Utilities},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In reinforcement learning, policies are typically evaluated according to the expectation of cumulated rewards. Researchers in decision theory have argued that more sophisticated decision criteria can better model the preferences of a decision maker. In particular, Skew-Symmetric Bilinear (SSB) utility functions generalize von Neumann and Morgenstern's expected utility (EU) theory to encompass rational decision behaviors that EU cannot accommodate. In this paper, we adopt an SSB utility function to compare policies in the reinforcement learning setting. We provide a model-free SSB reinforcement learning algorithm, SSB Q-learning, and prove its convergence towards a policy that is e-optimal according to SSB. The proposed algorithm is an adaptation of fictitious play [Brown, 1951] combined with techniques from stochastic approximation [Borkar, 1997]. We also present some experimental results which evaluate our approach in a variety of settings.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {252–261},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020976,
author = {Gopalan, Raghuraman},
title = {Bridging Heterogeneous Domains with Parallel Transport for Vision and Multimedia Applications},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Accounting for different feature types across datasets is a relatively under-studied problem in domain adaptation. We address this heterogeneous adaptation setting using principles from parallel transport and hierarchical sparse coding. By learning generative subspaces from each domain, we first perform label-independent cross-domain feature mapping using parallel transport, and obtain a collection of paths (bridges) that could compensate domain shifts. We encode the information contained in these bridges into an expanded prior, and then integrate the prior into a hierarchical sparse coding framework to learn a selective subset of codes representing holistic data properties that are robust to domain change and feature type variations. We then utilize label information on the sparse codes to perform classification, or in the absence of labels perform clustering, and obtain improved results on several previously studied heterogeneous adaptation datasets. We highlight the flexibility of our approach by accounting for multiple heterogeneous domains in training as well as in testing, and by considering the zero-shot domain transfer scenario where there are data categories in testing which are not seen during training. In that process we also empirically show how existing heterogeneous adaptation solutions can benefit from the findings of our study.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {262–270},
numpages = {9},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020977,
author = {Honorio, Jean and Jaakkola, Tommi},
title = {Structured Prediction: From Gaussian Perturbations to Linear-Time Principled Algorithms},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Margin-based structured prediction commonly uses a maximum loss over all possible structured outputs (Altun &amp; Hofmann, 2003; Collins, 2004; Taskar et al., 2003). In natural language processing, recent work (Zhang et al., 2014; Zhang et al., 2015) has proposed the use of the maximum loss over random structured outputs sampled independently from some proposal distribution. This method is linear-time in the number of random structured outputs and trivially parallelizable. We study this family of loss functions in the PAC-Bayes framework under Gaussian perturbations (McAllester, 2007). Under some technical conditions and up to statistical accuracy, we show that this family of loss functions produces a tighter upper bound of the Gibbs decoder distortion than commonly used methods. Thus, using the maximum loss over random structured outputs is a principled way of learning the parameter of structured prediction models. Besides explaining the experimental success of (Zhang et al., 2014; Zhang et al., 2015), our theoretical results show that more general techniques are possible.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {271–278},
numpages = {8},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020978,
author = {Hu, Hanzhang and Grubb, Alexander and Bagnell, J. Andrew and Hebert, Martial},
title = {Efficient Feature Group Sequencing for Anytime Linear Prediction},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider anytime linear prediction in the common machine learning setting, where features are in groups that have costs. We achieve anytime (or interruptible) predictions by sequencing the computation of feature groups and reporting results using the computed features at interruption. We extend Orthogonal Matching Pursuit (OMP) and Forward Regression (FR) to learn the sequencing greedily under this group setting with costs. We theoretically guarantee that our algorithms achieve near-optimal linear predictions at each budget when a feature group is chosen. With a novel analysis of OMP, we improve its theoretical bound to the same strength as that of FR. In addition, we develop a novel algorithm that consumes cost 4B to approximate the optimal performance of any cost B, and prove that with cost less than 4B, such an approximation is impossible. To our knowledge, these are the first anytime bounds at all budgets. We test our algorithms on two real-world data-sets and evaluate them in terms of anytime linear prediction performance against cost-weighted Group Lasso and alternative greedy algorithms.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {279–288},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020979,
author = {Huynh, Viet and Phung, Dinh and Venkatesh, Svetha and Nguyen, XuanLong and Hoffman, Matt and Bui, Hung Hai},
title = {Scalable Nonparametric Bayesian Multilevel Clustering},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Multilevel clustering problems where the content and contextual information are jointly clustered are ubiquitous in modern datasets. Existing works on this problem are limited to small datasets due to the use of the Gibbs sampler. We address the problem of scaling up multilevel clustering under a Bayesian nonparametric setting, extending the MC2 model proposed in (Nguyen et al., 2014). We ground our approach in structured mean-field and stochastic variational inference (SVI) and develop a tree-structured SVI algorithm that exploits the interplay between content and context modeling. Our new algorithm avoids the need to repeatedly go through the corpus as in Gibbs sampler. More crucially, our method is immediately amendable to parallelization, facilitating a scalable distributed implementation on the Apache Spark platform. We conduct extensive experiments in a variety of domains including text, images, and real-world user application activities. Direct comparison with the Gibbs-sampler demonstrates that our method is an order-of-magnitude faster without loss of model quality. Our Spark-based implementation gains another order-of-magnitude speedup and can scale to large real-world datasets containing millions of documents and groups.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {289–298},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020980,
author = {Jojic, Nebojsa and Perina, Alessandro and Kim, Dongwoo},
title = {Hierarchical Learning of Grids of Microtopics},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The counting grid is a grid of microtopics, sparse word/feature distributions. The generative model associated with the grid does not use these microtopics individually, but in predefined groups which can only be (ad)mixed as such. Each allowed group corresponds to one of all possible overlapping rectangular windows into the grid. The capacity of the model is controlled by the ratio of the grid size and the window size. This paper builds upon the basic counting grid model and it shows that hierarchical reasoning helps avoid bad local minima, produces better classification accuracy and, most interestingly, allows for extraction of large numbers of coherent microtopics even from small datasets. We evaluate this in terms of consistency, diversity and clarity of the indexed content, as well as in a user study on word intrusion tasks. We demonstrate that these models work well as a technique for embedding raw images and discuss interesting parallels between hierarchical CG models and other deep architectures.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {299–308},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020981,
author = {Kersting, Hans and Hennig, Philipp},
title = {Active Uncertainty Calibration in Bayesian ODE Solvers},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {There is resurging interest, in statistics and machine learning, in solvers for ordinary differential equations (ODEs) that return probability measures instead of point estimates. Recently, Conrad et al. introduced a sampling-based class of methods that are 'well-calibrated' in a specific sense. But the computational cost of these methods is significantly above that of classic methods. On the other hand, Schober et al. pointed out a precise connection between classic Runge-Kutta ODE solvers and Gaussian filters, which gives only a rough probabilistic calibration, but at negligible cost overhead. By formulating the solution of ODEs as approximate inference in linear Gaussian SDEs, we investigate a range of probabilistic ODE solvers, that bridge the tradeoff between computational cost and probabilistic calibration, and identify the inaccurate gradient measurement as the crucial source of uncertainty. We propose the novel filtering-based method Bayesian Quadrature filtering (BQF) which uses Bayesian quadrature to actively learn the imprecision in the gradient measurement by collecting multiple gradient evaluations.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {309–318},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020982,
author = {Khan, Mohammad Emtiyaz and Babanezhad, Reza and Lin, Wu and Schmidt, Mark and Sugiyama, Masashi},
title = {Faster Stochastic Variational Inference Using Proximal-Gradient Methods with General Divergence Functions},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Several recent works have explored stochastic gradient methods for variational inference that exploit the geometry of the variational-parameter space. However, the theoretical properties of these methods are not well-understood and these methods typically only apply to conditionally-conjugate models. We present a new stochastic method for variational inference which exploits the geometry of the variational-parameter space and also yields simple closed-form updates even for non-conjugate models. We also give a convergence-rate analysis of our method and many other previous methods which exploit the geometry of the space. Our analysis generalizes existing convergence results for stochastic mirror-descent on non-convex objectives by using a more general class of divergence functions. Beyond giving a theoretical justification for a variety of recent methods, our experiments show that new algorithms derived in this framework lead to state of the art results on a variety of problems. Further, due to its generality, we expect that our theoretical analysis could also apply to other applications.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {319–328},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020983,
author = {Klami, Arto and Jitta, Aditya},
title = {Probabilistic Size-Constrained Microclustering},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Microclustering refers to clustering models that produce small clusters or, equivalently, to models where the size of the clusters grows sublinearly with the number of samples. We formulate probabilistic microclustering models by assigning a prior distribution on the size of the clusters, and in particular consider microclustering models with explicit bounds on the size of the clusters. The combinatorial constraints make full Bayesian inference complicated, but we manage to develop a Gibbs sampling algorithm that can efficiently sample from the joint cluster allocation of all data points. We empirically demonstrate the computational efficiency of the algorithm for problem instances of varying difficulty.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {329–338},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020984,
author = {Koc\'{a}k, Tom\'{a}\v{s} and Neu, Gergely and Valko, Michal},
title = {Online Learning with Erd\H{o}s-R\'{e}Nyi Side-Observation Graphs},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider adversarial multi-armed bandit problems where the learner is allowed to observe losses of a number of arms beside the arm that it actually chose. We study the case where all non-chosen arms reveal their loss with an unknown probability rt, independently of each other and the action of the learner. Moreover, we allow rt to change in every round t, which rules out the possibility of estimating rt by a well-concentrated sample average. We propose an algorithm which operates under the assumption that rt is large enough to warrant at least one side observation with high probability. We show that after T rounds in a bandit problem with N arms, the expected regret of our algorithm is of order O(√ΣTt-1 (1/rt) log N), given that rt ≥ log T/(2N - 2) for all t. All our bounds are within logarithmic factors of the best achievable performance of any algorithm that is even allowed to know exact values of rt.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {339–346},
numpages = {8},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020985,
author = {Kocak, Mustafa A. and Erkip, Elza and Shasha, Dennis E.},
title = {Conjugate Conformal Prediction for Online Binary Classification},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Binary classification (rain or shine, disease or not, increase or decrease) is a fundamental problem in machine learning. We present an algorithm that can take any standard online binary classification algorithm and provably improve its performance under very weak assumptions, given the right to refuse to make predictions in certain cases. The extent of improvement will depend on the data size, stability of the algorithm, and room for improvement in the algorithms performance. Our experiments on standard machine learning data sets and standard algorithms (k-nearest neighbors and random forests) show the effectiveness of our approach, even beyond what is possible using previous work on conformal predictors upon which our approach is based. Though we focus on binary classification, our theory could be extended to multiway classification. Our code and data are available upon request.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {347–356},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020986,
author = {Koriche, Fr\'{e}d\'{e}ric},
title = {Online Forest Density Estimation},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Online density estimation is the problem of predicting a sequence of outcomes, revealed one at a time, almost as well as the best expert chosen from a reference class of probabilistic models. The performance of each expert is measured with the log-likelihood loss. The class of experts examined in this paper is the family of discrete, acyclic graphical models, also known as Markov forests. By coupling Bayesian mixtures with symmetric Dirichlet priors for parameter learning, and a variant of "Follow the Perturbed Leader" strategy for structure learning, we derive an online forest density estimation algorithm that achieves a regret of \~{O}(√T), with a per-round time complexity that is quasi-quadratic in the input dimension. Using simple and flexible update rules, this algorithm can be easily adapted to predict with Markov trees or mixtures of Markov forests. Empirical results indicate that our online algorithm is a practical alternative to the state-of-the-art batch algorithms for learning tree-structured graphical models.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {357–366},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020987,
author = {Lan, Chao and Wang, Jianxin and Huan, Jun},
title = {Towards a Theoretical Understanding of Negative Transfer in Collective Matrix Factorization},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Collective matrix factorization (CMF) is a popular technique to improve the overall factorization quality of multiple matrices presuming they share the same latent factor. However, it suffers from performance degeneration when this assumption fails, an effect called negative transfer (n.t.). Although the effect is widely admitted, its theoretical nature remains a mystery to date.This paper presents a first theoretical understanding of n.t. in theory. Under the statistical mini-max framework, we derive lower bounds for the CMF estimator and gain two insights. First, the n.t. effect can be explained as the rise of a bias term in the standard lower bound, which depends only on the structure of factor space but neither the estimator nor samples. Second, the n.t. effect can be explained as the rise of an dth-root function on the learning rate, where d is the dimension of a Grassmannian containing the sub-spaces spanned by latent factors. These discoveries are also supported in simulation, and suggest n.t. may be more effectively addressed via model construction other than model selection.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {367–376},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020988,
author = {Le, Trung and Duong, Phuong and Dinh, Mi and Nguyen, Tu Dinh and Nguyen, Vu and Phung, Dinh},
title = {Budgeted Semi-Supervised Support Vector Machine},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Due to the prevalence of unlabeled data, semi-supervised learning has drawn significant attention and has been found applicable in many real-world applications. In this paper, we present the so-called Budgeted Semi-supervised Support Vector Machine (BS3VM), a method that leverages the excellent generalization capacity of kernel-based method with the adjacent and distributive information carried in a spectral graph for semi-supervised learning purpose. The fact that the optimization problem of BS3VM can be solved directly in the primal form makes it fast and efficient in memory usage. We validate the proposed method on several benchmark datasets to demonstrate its accuracy and efficiency. The experimental results show that BS3VM can scale up efficiently to the large-scale datasets where it yields a comparable classification accuracy while simultaneously achieving a significant computational speed-up compared with the baselines.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {377–386},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020989,
author = {Lee, Sanghack and Honavar, Vasant},
title = {A Characterization of Markov Equivalence Classes of Relational Causal Models under Path Semantics},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Relational Causal Models (RCM) generalize Causal Bayesian Networks so as to extend causal discovery to relational domains. We provide a novel and elegant characterization of the Markov equivalence of RCMs under path semantics. We introduce a novel representation of unshielded triples that allows us to efficiently determine whether an RCM is Markov equivalent to another. Under path semantics, we provide a sound and complete algorithm for recovering the structure of an RCM from conditional independence queries. Our analysis also suggests ways to improve the orientation recall of algorithms for learning the structure of RCM under bridge burning semantics as well.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {387–396},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020990,
author = {Lee, Dongeun and Lima, Rafael and Choi, Jaesik},
title = {Improving Imprecise Compressive Sensing Models},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Random sampling in compressive sensing (CS) enables the compression of large amounts of input signals in an efficient manner, which is useful for many applications. CS reconstructs the compressed signals exactly with overwhelming probability when incoming data can be sparsely represented with a few components. However, the theory of CS framework including random sampling has been focused on exact recovery of signal; impreciseness in signal recovery has been neglected. This can be problematic when there is uncertainty in the number of sparse components such as signal sparsity in dynamic systems that can change over time. We present a new theoretical framework that handles uncertainty in signal recovery from the perspective of recovery success and quality. We show that the signal recovery success in our model is more accurate than the success probability analysis in the CS framework. Our model is then extended to the case where the success or failure of signal recovery can be relaxed. We represent the number of components included in signal recovery with a right-tailed distribution and focus on recovery quality. Experimental results confirm the accuracy of our model in dynamic systems.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {397–406},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020991,
author = {Leibfried, Felix and Braun, Daniel A.},
title = {Bounded Rational Decision-Making in Feedforward Neural Networks},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bounded rational decision-makers transform sensory input into motor output under limited computational resources. Mathematically, such decision-makers can be modeled as information-theoretic channels with limited transmission rate. Here, we apply this formalism for the first time to multilayer feedforward neural networks. We derive synaptic weight update rules for two scenarios, where either each neuron is considered as a bounded rational decision-maker or the network as a whole. In the update rules, bounded rationality translates into information-theoretically motivated types of regularization in weight space. In experiments on the MNIST benchmark classification task for handwritten digits, we show that such information-theoretic regularization successfully prevents overfitting across different architectures and attains results that are competitive with other recent techniques like dropout, dropconnect and Bayes by backprop, for both ordinary and convolutional neural networks.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {407–416},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020992,
author = {Leike, Jan and Lattimore, Tor and Orseau, Laurent and Hutter, Marcus},
title = {Thompson Sampling is Asymptotically Optimal in General Environments},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We discuss a variant of Thompson sampling for nonparametric reinforcement learning in countable classes of general stochastic environments. These environments can be non-Markov, non-ergodic, and partially observable. We show that Thompson sampling learns the environment class in the sense that (1) asymptotically its value converges to the optimal value in mean and (2) given a recoverability assumption regret is sublinear.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {417–426},
numpages = {10},
keywords = {asymptotic optimality, discounting, general reinforcement learning, recoverability, AIXI, regret, thompson sampling},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020993,
author = {Leike, Jan and Taylor, Jessica and Fallenstein, Benya},
title = {A Formal Solution to the Grain of Truth Problem},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A Bayesian agent acting in a multi-agent environment learns to predict the other agents' policies if its prior assigns positive probability to them (in other words, its prior contains a grain of truth). Finding a reasonably large class of policies that contains the Bayes-optimal policies with respect to this class is known as the grain of truth problem. Only small classes are known to have a grain of truth and the literature contains several related impossibility results. In this paper we present a formal and general solution to the full grain of truth problem: we construct a class of policies that contains all computable policies as well as Bayes-optimal policies for every lower semicomputable prior over the class. When the environment is unknown, Bayes-optimal agents may fail to act optimally even asymptotically. However, agents based on Thompson sampling converge to play e-Nash equilibria in arbitrary unknown computable multi-agent environments. While these results are purely theoretical, we show that they can be computationally approximated arbitrarily closely.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {427–436},
numpages = {10},
keywords = {self-reflection, thompson sampling, multi-agent systems, AIXI, nash equilibrium, game theory, general reinforcement learning, asymptotic optimality},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020994,
author = {L\'{e}vesque, Julien-Charles and Gagn\'{e}, Christian and Sabourin, Robert},
title = {Bayesian Hyperparameter Optimization for Ensemble Learning},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we bridge the gap between hyperparameter optimization and ensemble learning by performing Bayesian optimization of an ensemble with regards to its hyperparameters. Our method consists in building a fixed-size ensemble, optimizing the configuration of one classifier of the ensemble at each iteration of the hyperparameter optimization algorithm, taking into consideration the interaction with the other models when evaluating potential performances. We also consider the case where the ensemble is to be reconstructed at the end of the hyperparameter optimization phase, through a greedy selection over the pool of models generated during the optimization. We study the performance of our proposed method on three different hyperparameter spaces, showing that our approach is better than both the best single model and a greedy ensemble construction over the models produced by a standard Bayesian optimization.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {437–446},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020995,
author = {Lewenberg, Yoad and Bachrach, Yoram and Bordeaux, Lucas and Kohli, Pushmeet},
title = {Political Dimensionality Estimation Using a Probabilistic Graphical Model},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper attempts to move beyond the left-right characterization of political ideologies. We propose a trait based probabilistic model for estimating the manifold of political opinion. We demonstrate the efficacy of our model on two novel and large scale datasets of public opinion. Our experiments show that although the political spectrum is richer than a simple left-right structure, peoples' opinions on seemingly unrelated political issues are very correlated, so fewer than 10 dimensions are enough to represent peoples' entire political opinion.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {447–456},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020996,
author = {Li, Shuangyin and Pan, Rong and Zhang, Yu and Yang, Qiang},
title = {Correlated Tag Learning in Topic Model},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {It is natural to expect that the documents in a corpus will be correlated, and these correlations are reflected by not only the words but also the observed tags in each document. Most previous works model this type of corpus, which are called the semi-structured corpus, without considering the correlations among the tags. In this work, we develop a Correlated Tag Learning (CTL) model for semi-structured corpora based on the topic model to enable the construction of the correlation graph among tags via a logistic normal participation process. For the inference of the CTL model, we devise a variational inference algorithm to approximate the posterior. In experiments, we visualize the tag correlation graph generated by the CTL model on the DBLP corpus and for the tasks of document retrieval and classification, the correlation graph among tags is helpful to improve the generalization performance compared with the state-of-the-art baselines.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {457–466},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020997,
author = {Li, Chun-Liang and P\'{o}czos, Barnab\'{a}s},
title = {Utilize Old Coordinates: Faster Doubly Stochastic Gradients for Kernel Methods},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {To address the scalability issue of kernel methods, random features are commonly used for kernel approximation (Rahimi and Recht, 2007). They map the input data to a randomized low-dimensional feature space and apply fast linear learning algorithms on it. However, to achieve high precision results, one might still need a large number of random features, which is infeasible in large-scale applications. Dai et al. (2014) address this issue by recomputing the random features of small batches in each iteration instead of pre-generating for the whole dataset and keeping them in the memory. The algorithm increases the number of random features linearly with iterations, which can reduce the approximation error to arbitrarily small. A drawback of this approach is that the large number of random features slows down the prediction and gradient evaluation after several iterations. We propose two algorithms to remedy this situation by "utilizing" old random features instead of adding new features in certain iterations. By checking the expected descent amount, the proposed algorithm selects "important" old features to update. The resulting procedure is surprisingly simple without enhancing the complexity of the original algorithm but effective in practice. We conduct empirical studies on both medium and large-scale datasets, such as ImageNet, to demonstrate the power of the proposed algorithms.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {467–476},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020998,
author = {Li, Chune and Mao, Yongyi and Zhang, Richong and Huai, Jinpeng},
title = {On Hyper-Parameter Estimation in Empirical Bayes: A Revisit of the MacKay Algorithm},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {An iterative procedure introduced in MacKay's evidence framework is often used for estimating the hyper-parameter in empirical Bayes. Despite its effectiveness, the procedure has stayed primarily as a heuristic to date. This paper formally investigates the mathematical nature of this procedure and justifies it as a well-principled algorithm framework. This framework, which we call the MacKay algorithm, is shown to be closely related to the EM algorithm under certain Gaussian assumption.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {477–486},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3020999,
author = {Liu, Bo and Zhang, Luwan and Liu, Ji},
title = {Dantzig Selector with an Approximately Optimal Denoising Matrix and Its Application in Sparse Reinforcement Learning},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Dantzig Selector (DS) is widely used in compressed sensing and sparse learning for feature selection and sparse signal recovery. Since the DS formulation is essentially a linear programming optimization, many existing linear programming solvers can be simply applied for scaling up. The DS formulation can be explained as a basis pursuit denoising problem, wherein the data matrix (or measurement matrix) is employed as the denoising matrix to eliminate the observation noise. However, we notice that the data matrix may not be the optimal denoising matrix, as shown by a simple counter-example. This motivates us to pursue a better denoising matrix for defining a general DS formulation. We first define the optimal denoising matrix through a minimax optimization, which turns out to be an NP-hard problem. To make the problem computationally tractable, we propose a novel algorithm, termed as "Optimal" Denoising Dantzig Selector (ODDS), to approximately estimate the optimal denoising matrix. Empirical experiments validate the proposed method. Finally, a novel sparse reinforcement learning algorithm is formulated by extending the proposed ODDS algorithm to temporal difference learning, and empirical experimental results demonstrate to outperform the conventional "vanilla" DS-TD algorithm.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {487–496},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021000,
author = {Liu, Qiang},
title = {Importance Weighted Consensus Monte Carlo for Distributed Bayesian Inference},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The recent explosion in big data has created a significant challenge for efficient and scalable Bayesian inference. In this paper, we consider a divide-and-conquer setting in which the data is partitioned into different subsets with communication constraints, and a proper combination strategy is used to aggregate the Monte Carlo samples drawn from the local posteriors based on the dataset subsets. We propose a new importance weighted consensus Monte Carlo method for efficient Bayesian inference in this setting. Our method outperforms the previous one-shot combination strategies in terms of accuracy, and is more computation- and communication-efficient than the previous iterative combination methods that require iterative re-sampling and communication steps. We provide two practical versions of our approach, and illustrate their properties both theoretically and empirically.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {497–506},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021001,
author = {Malioutov, Dmitry and Kumar, Abhishek and Yen, Ian E.H.},
title = {Large-Scale Submodular Greedy Exemplar Selection with Structured Similarity Matrices},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Exemplar clustering attempts to find a subset of data-points that summarizes the entire data-set in the sense of minimizing the sum of distances from each point to its closest exemplar. It has many important applications in machine learning including document and video summarization, data compression, scalability of kernel methods and Gaussian processes, active learning and feature selection. A key challenge in the adoption of exemplar clustering to large-scale applications has been the availability of accurate and scalable algorithms. We propose an approach that combines structured similarity matrix representations with submodular greedy maximization that can dramatically increase the scalability of exemplar clustering and still enjoys good approximation guarantees. Exploiting structured similarity matrices within the context of submodular greedy algorithms is by no means trivial, as naive approaches still require computing all the entries of the matrix. We propose a randomized approach based on sampling sign-patterns of columns of the similarity matrix and establish accuracy guarantees. We demonstrate significant computational speed-ups while still achieving highly accurate solutions, and solve problems with up-to millions of data-points in around a minute or less on a single commodity computer.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {507–516},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021002,
author = {McIntire, Mitchell and Ratner, Daniel and Ermon, Stefano},
title = {Sparse Gaussian Processes for Bayesian Optimization},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian optimization schemes often rely on Gaussian processes (GP). GP models are very flexible, but are known to scale poorly with the number of training points. While several efficient sparse GP models are known, they have limitations when applied in optimization settings.We propose a novel Bayesian optimization framework that uses sparse online Gaussian processes. We introduce a new updating scheme for the online GP that accounts for our preference during optimization for regions with better performance. We apply this method to optimize the performance of a free-electron laser, and demonstrate empirically that the weighted updating scheme leads to substantial improvements to performance in optimization.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {517–526},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021003,
author = {Narasimhan, Harikrishna and Parkes, David C.},
title = {A General Statistical Framework for Designing Strategy-Proof Assignment Mechanisms},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We develop a statistical framework for the design of a strategy-proof assignment mechanism that closely approximates a target outcome rule. The framework can handle settings with and without money, and allows the designer to employ techniques from machine learning to control the space of strategy-proof mechanisms searched over, by providing a rule class with appropriate capacity. We solve a sample-based optimization problem over a space of mechanisms that correspond to agent-independent price functions (virtual prices in the case of settings without money), subject to a feasibility constraint on the sample. A transformation is applied to the obtained mechanism to ensure feasibility on all type profiles, and strategy-proofness. We derive a sample complexity bound for our approach in terms of the capacity of the chosen rule class and provide applications for our results.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {527–536},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021004,
author = {Nguyen, An T. and Wallace, Byron C. and Lease, Matthew},
title = {A Correlated Worker Model for Grouped, Imbalanced and Multitask Data},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the important crowdsourcing problem of estimating worker confusion matrices, or sensitivities and specificities for binary classification tasks. In addition to providing diagnostic insights into worker performance, such estimates enable robust online task routing for classification tasks exhibiting imbalance and asymmetric costs. However, labeled data is often expensive and hence estimates must be made without much of it. This poses a challenge to existing methods. In this paper, we propose a novel model that captures the correlations between entries in confusion matrices. We applied this model in two practical scenarios: (1) an imbalanced classification task in which workers are known to belong to groups and (2) a multitask scenario in which labels for the same workers are available in more than one labeling task. We derive an efficient variational inference approach that scales to large datasets. Experiments on two real world citizen science datasets (biomedical citation screening and galaxy morphological classification) demonstrate consistent improvement over competitive baselines. We have made our source code available.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {537–546},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021005,
author = {Nutini, Julie and Sepehry, Behrooz and Laradji, Issam and Schmidt, Mark and Koepke, Hoyt and Virani, Alim},
title = {Convergence Rates for Greedy Kaczmarz Algorithms, and Faster Randomized Kaczmarz Rules Using the Orthogonality Graph},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The Kaczmarz method is an iterative algorithm for solving systems of linear equalities and inequalities, that iteratively projects onto these constraints. Recently, Strohmer and Vershynin [J. Fourier Anal. Appl., 15(2):262-278, 2009] gave a non-asymptotic convergence rate analysis for this algorithm, spurring numerous extensions and generalizations of the Kaczmarz method. Rather than the randomized selection rule analyzed in that work, in this paper we instead discuss greedy and approximate greedy selection rules. We show that in some applications the computational costs of greedy and random selection are comparable, and that in many cases greedy selection rules give faster convergence rates than random selection rules. Further, we give the first multi-step analysis of Kaczmarz methods for a particular greedy rule, and propose a provably-faster randomized selection rule for matrices with many pairwise-orthogonal rows.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {547–556},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021006,
author = {Orseau, Laurent and Armstrong, Stuart},
title = {Safely Interruptible Agents},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Reinforcement learning agents interacting with a complex environment like the real world are unlikely to behave optimally all the time. If such an agent is operating in real-time under human supervision, now and then it may be necessary for a human operator to press the big red button to prevent the agent from continuing a harmful sequence of actions—harmful either for the agent or for the environment—and lead the agent into a safer situation. However, if the learning agent expects to receive rewards from this sequence, it may learn in the long run to avoid such interruptions, for example by disabling the red button— which is an undesirable outcome. This paper explores a way to make sure a learning agent will not learn to prevent (or seek!) being interrupted by the environment or a human operator. We provide a formal definition of safe interruptibility and exploit the off-policy learning property to prove that either some agents are already safely interruptible, like Q-learning, or can easily be made so, like Sarsa. We show that even ideal, uncomputable reinforcement learning agents for (deterministic) general computable environments can be made safely interruptible.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {557–566},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021007,
author = {Paige, Brooks and Sejdinovic, Dino and Wood, Frank},
title = {Super-Sampling with a Reservoir},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce an alternative to reservoir sampling, a classic and popular algorithm for drawing a fixed-size subsample from streaming data in a single pass. Rather than draw a random sample, our approach performs an online optimization which aims to select the subset that provides the best overall approximation to the full data set, as judged using a kernel two-sample test. This produces subsets which minimize the worst-case relative error when computing expectations of functions in a specified function class, using just the samples from the subset. Kernel functions are approximated using random Fourier features, and the subset of samples itself is stored in a random projection tree. The resulting algorithm runs in a single pass through the whole data set, and has a per-iteration computational complexity logarithmic in the size of the subset. These "super-samples" subsampled from the full data provide a concise summary, as demonstrated empirically on mixture models and the MNIST dataset.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {567–576},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021008,
author = {Pe\~{n}a, Jose M.},
title = {Alternative Markov and Causal Properties for Acyclic Directed Mixed Graphs},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We extend Andersson-Madigan-Perlman chain graphs by (i) relaxing the semidirected acyclity constraint so that only directed cycles are forbidden, and (ii) allowing up to two edges between any pair of nodes. We introduce global, and ordered local and pairwise Markov properties for the new models. We show the equivalence of these properties for strictly positive probability distributions. We also show that when the random variables are continuous, the new models can be interpreted as systems of structural equations with correlated errors. This enables us to adapt Pearl's do-calculus to them. Finally, we describe an exact algorithm for learning the new models from observational and interventional data via answer set programming.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {577–586},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021009,
author = {Pennock, David M. and Syrgkanis, Vasilis and Vaughan, Jennifer Wortman},
title = {Bounded Rationality in Wagering Mechanisms},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Wagering mechanisms allow decision makers to inexpensively collect forecasts from groups of experts who reveal their information via bets with one another. Such mechanisms naturally induce a game in which strategic considerations come into play. What happens in the game depends on the reasoning power of the experts. At one extreme, if experts are fully rational, no-trade theorems imply no participation. At the other extreme, if experts ignore strategic considerations, even the least informed will wager as if his beliefs are correct. Economists have analyzed the former case and decision theorists the latter, but both are arguably unrealistic. In this paper, we adopt an intermediate model of bounded rationality in wagering mechanisms based on level-k reasoning. Under this model, overconfidence allows some participation to be sustained, but experts who realize they are at a relative disadvantage do bow out. We derive conditions on the particular wagering mechanism used under which participation is unbiased, and show that unbiasedness always implies truthful reports. We show that if participation is unbiased, then participation rates unavoidably fall as players' rationality increases, vanishing for large k. Finally, we zoom in on one particular information structure to give a complete characterization specifying the conditions under which mechanisms are unbiased and show how to maximize participation rates among all unbiased mechanisms.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {587–596},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021010,
author = {Perny, Patrice and Viappiani, Paolo and Boukhatem, Abdellah},
title = {Incremental Preference Elicitation for Decision Making under Risk with the Rank-Dependent Utility Model},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This work concerns decision making under risk with the rank-dependent utility model (RDU), a generalization of expected utility providing enhanced descriptive possibilities. We introduce a new incremental decision procedure, involving monotone regression spline functions to model both components of RDU, namely the probability weighting function and the utility function. First, assuming the utility function is known, we propose an elicitation procedure that incrementally collects preference information in order to progressively specify the probability weighting function until the optimal choice can be identified. Then, we present two elicitation procedures for the construction of a utility function as a monotone spline. Finally, numerical tests are provided to show the practical efficiency of the proposed methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {597–606},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021011,
author = {Petrik, Marek and Luss, Ronny},
title = {Interpretable Policies for Dynamic Product Recommendations},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In many applications, it may be better to compute a good interpretable policy instead of a complex optimal one. For example, a recommendation engine might perform better when accounting for user profiles, but in the absence of such loyalty data, assumptions would have to be made that increase the complexity of the recommendation policy. A simple greedy recommendation could be implemented based on aggregated user data, but another simple policy can improve on this by accounting for the fact that users come from different segments of a population. In this paper, we study the problem of computing an optimal policy that is interpretable. In particular, we consider a policy to be interpretable if the decisions (e.g., recommendations) depend only on a small number of simple state attributes (e.g., the currently viewed product). This novel model is a general Markov decision problem with action constraints over states. We show that this problem is NP hard and develop a Mixed Integer Linear Programming formulation that gives an exact solution when policies are restricted to being deterministic. We demonstrate the effectiveness of the approach on a real-world business case for a European tour operator's recommendation engine.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {607–616},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021012,
author = {Rahman, Tahrima and Gogate, Vibhav},
title = {Merging Strategies for Sum-Product Networks: From Trees to Graphs},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Learning the structure of sum-product networks (SPNs) - arithmetic circuits over latent and observed variables - has been the subject of much recent research. These networks admit linear time exact inference, and thus help alleviate one of the chief disadvantages of probabilistic graphical models: accurate probabilistic inference algorithms are often computationally expensive. Although, algorithms for inducing their structure from data have come quite far and often outperform algorithms that induce probabilistic graphical models, a key issue with existing approaches is that they induce tree SPNs, a small, inefficient sub-class of SPNs. In this paper, we address this limitation by developing post-processing approaches that induce graph SPNs from tree SPNs by merging similar sub-structures. The key benefits of graph SPNs over tree SPNs include smaller computational complexity which facilitates faster online inference, and better generalization accuracy because of reduced variance, at the cost of slight increase in the learning time. We demonstrate experimentally that our merging techniques significantly improve the accuracy of tree SPNs, achieving state-of-the-art performance on several real world benchmark datasets.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {617–626},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021013,
author = {Rong, Nan and Halpern, Joseph Y. and Saxena, Ashutosh},
title = {MDPs with Unawareness in Robotics},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We formalize decision-making problems in robotics and automated control using continuous MDPs and actions that take place over continuous time intervals. We then approximate the continuous MDP using finer and finer discretizations. Doing this results in a family of systems, each of which has an extremely large action space, although only a few actions are "interesting". We can view the decision maker as being unaware of which actions are "interesting". We an model this using MDPUs, MDPs with unawareness, where the action space is much smaller. As we show, MDPUs can be used as a general framework for learning tasks in robotic problems. We prove results on the difficulty of learning a near-optimal policy in an an MDPU for a continuous task. We apply these ideas to the problem of having a humanoid robot learn on its own how to walk.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {627–636},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021014,
author = {Rubenstein, Paul K. and Chwialkowski, Kacper P. and Gretton, Arthur},
title = {A Kernel Test for Three-Variable Interactions with Random Processes},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We apply a wild bootstrap method to the Lancaster three-variable interaction measure in order to detect factorisation of the joint distribution on three variables forming a stationary random process, for which the existing permutation bootstrap method fails. As in the i.i.d. case, the Lancaster test is found to outperform existing tests in cases for which two independent variables individually have a weak influence on a third, but that when considered jointly the influence is strong. The main contributions of this paper are twofold: first, we prove that the Lancaster statistic satisfies the conditions required to estimate the quantiles of the null distribution using the wild bootstrap; second, the manner in which this is proved is novel, simpler than existing methods, and can further be applied to other statistics.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {637–646},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021015,
author = {Ruiz, Francisco J. R. and Titsias, Michalis K. and Blei, David M.},
title = {Overdispersed Black-Box Variational Inference},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce overdispersed black-box variational inference, a method to reduce the variance of the Monte Carlo estimator of the gradient in black-box variational inference. Instead of taking samples from the variational distribution, we use importance sampling to take samples from an overdispersed distribution in the same exponential family as the variational approximation. Our approach is general since it can be readily applied to any exponential family distribution, which is the typical choice for the variational approximation. We run experiments on two non-conjugate probabilistic models to show that our method effectively reduces the variance, and the overhead introduced by the computation of the proposal parameters and the importance weights is negligible. We find that our overdispersed importance sampling scheme provides lower variance than black-box variational inference, even when the latter uses twice the number of samples. This results in faster convergence of the black-box inference procedure.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {647–656},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021016,
author = {Samo, Yves-Laurent Kom and Vervuurt, Alexander},
title = {Stochastic Portfolio Theory: A Machine Learning Perspective},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we propose a novel application of Gaussian processes (GPs) to financial asset allocation. Our approach is deeply rooted in Stochastic Portfolio Theory (SPT), a stochastic analysis framework introduced by Robert Fernholz that aims at flexibly analysing the performance of certain investment strategies in stock markets relative to benchmark indices. In particular, SPT has exhibited some investment strategies based on company sizes that, under realistic assumptions, outperform benchmark indices with probability 1 over certain time horizons. Galvanised by this result, we consider the inverse problem that consists of learning (from historical data) an optimal investment strategy based on any given set of trading characteristics, and using a user-specified optimality criterion that may go beyond outperforming a benchmark index. Although this inverse problem is of the utmost interest to investment management practitioners, it can hardly be tackled using the SPT framework. We show that our machine learning approach learns investment strategies that considerably outperform existing SPT strategies in the US stock market.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {657–665},
numpages = {9},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021017,
author = {Schulman, Leonard J. and Srivastava, Piyush},
title = {Stability of Causal Inference},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider the sensitivity of causal identification to small perturbations in the input. A long line of work culminating in papers by Shpitser and Pearl (2006) and Huang and Valtorta (2008) led to a complete procedure for the causal identification problem. In our main result in this paper, we show that the identification function computed by these procedures is in some cases extremely unstable numerically. Specifically, the "condition number" of causal identification can be of the order of Ω(exp(n0.49)) on an identifiable semi-Markovian model with n visible nodes. That is, in order to give an output accurate to d bits, the empirical probabilities of the observable events need to be obtained to accuracy d + Ω(n0.49) bits.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {666–675},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021018,
author = {Shah, Amar and Ghahramani, Zoubin},
title = {Markov Beta Processes for Time Evolving Dictionary Learning},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We develop Markov beta processes (MBP) as a model suitable for data which can be represented by a sparse set of latent features which evolve over time. Most time evolving nonparametric latent feature models in the literature vary feature usage, but maintain a constant set of features over time. We show that being able to model features which themselves evolve over time results in the MBP outperforming other beta process based models. Our construction utilizes Poisson process operations, which leave each transformed beta process marginally beta process distributed. This allows one to analytically marginalize out latent beta processes, exploiting conjugacy when we couple them with Bernoulli processes, leading to a surprisingly elegant Gibbs MCMC scheme considering the expressiveness of the prior. We apply the model to the task of denoising and interpolating noisy image sequences and in predicting time evolving gene expression data, demonstrating superior performance to other beta process based methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {676–685},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021019,
author = {Siddiqui, Md Amran and Fern, Alan and Dietterich, Thomas G. and Das, Shubhomoy},
title = {Finite Sample Complexity of Rare Pattern Anomaly Detection},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Anomaly detection is a fundamental problem for which a wide variety of algorithms have been developed. However, compared to supervised learning, there has been very little work aimed at understanding the sample complexity of anomaly detection. In this paper, we take a step in this direction by introducing a Probably Approximately Correct (PAC) framework for anomaly detection based on the identification of rare patterns. In analogy with the PAC framework for supervised learning, we develop sample complexity results that relate the complexity of the pattern space to the data requirements needed for PAC guarantees. We instantiate the general result for a number of pattern spaces, some of which are implicit in current state-of-the-art anomaly detectors. Finally, we design a new simple anomaly detection algorithm motivated by our analysis and show experimentally on several benchmark problems that it is competitive with a state-of-the-art detector using the same pattern space.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {686–695},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021020,
author = {Strouse, D J and Schwab, David J},
title = {The Deterministic Information Bottleneck},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Lossy compression fundamentally involves a decision about what is relevant and what is not. The information bottleneck (IB) by Tishby, Pereira, and Bialek formalized this notion as an information-theoretic optimization problem and proposed an optimal tradeoff between throwing away as many bits as possible, and selectively keeping those that are most important. Here, we introduce an alternative formulation, the deterministic information bottleneck (DIB), that we argue better captures this notion of compression. As suggested by its name, the solution to the DIB problem is a deterministic encoder, as opposed to the stochastic encoder that is optimal under the IB. We then compare the IB and DIB on synthetic data, showing that the IB and DIB perform similarly in terms of the IB cost function, but that the DIB vastly outperforms the IB in terms of the DIB cost function. Moreover, the DIB offered a 1-2 order of magnitude speedup over the IB in our experiments. Our derivation of the DIB also offers a method for continuously interpolating between the soft clustering of the IB and the hard clustering of the DIB.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {696–705},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021021,
author = {Sun, Wen and Capobianco, Roberto and Gordon, Geoffrey J. and Bagnell, J. Andrew and Boots, Byron},
title = {Learning to Smooth with Bidirectional Predictive State Inference Machines},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present the Smoothing Machine (SMACH, pronounced "smash"), a dynamical system learning algorithm based on chain Conditional Random Fields (CRFs) with latent states. Unlike previous methods, SMACH is designed to optimize prediction performance when we have information from both past and future observations. By leveraging Predictive State Representations (PSRs), we model beliefs about latent states through predictive states—an alternative but equivalent representation that depends directly on observable quantities. Predictive states enable the use of well-developed supervised learning approaches in place of local-optimum-prone methods like EM: we learn regressors or classifiers that can approximate message passing and marginalization in the space of predictive states. We provide theoretical guarantees on smoothing performance and we empirically verify the efficacy of SMACH on several dynamical system benchmarks.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {706–715},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021022,
author = {Sutera, Antonio and Louppe, Gilles and Huynh-Thu, V\^{a}n Anh and Wehenkel, Louis and Geurts, Pierre},
title = {Context-Dependent Feature Analysis with Random Forests},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In many cases, feature selection is often more complicated than identifying a single subset of input variables that would together explain the output. There may be interactions that depend on contextual information, i.e., variables that reveal to be relevant only in some specific circumstances. In this setting, the contribution of this paper is to extend the random forest variable importances framework in order (i) to identify variables whose relevance is context-dependent and (ii) to characterize as precisely as possible the effect of contextual information on these variables. The usage and the relevance of our framework for highlighting context-dependent variables is illustrated on both artificial and real datasets.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {716–725},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021023,
author = {Tan, Xi and Naqvi, Syed A. Z. and Qi, Alan Yuan and Heller, Katherine A. and Rao, Vinayak},
title = {Content-Based Modeling of Reciprocal Relationships Using Hawkes and Gaussian Processes},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {There has been growing interest in inferring implicit social structures using interaction data. This approach is motivated by the fact that entities organize themselves into groups having frequent interactions between each other. Unlike previous approaches that focused on subjectively declared relationships, the idea is to exploit the actual evidence at hand to reach conclusions about group formations, resulting in more objective data-driven inferences. To this end, [5] have employed Hawkes processes, and proposed a Hawkes IRM model to infer social structures from interaction data. A major factor that encourages the use of Hawkes processes is the capability to model reciprocity in the interaction between social entities. However, reciprocation is dynamically conditioned upon two key factors: the significance of each message sent by the sender, and the receptivity to each message received by the receiver. In the model proposed by [5], reciprocity is not affected by either of these factors, since the content of each message is not taken into account. In this paper, we extend the work of [5] by introducing Gaussian processes (GPs) into the Hawkes IRM model: based on the content of each message, GPs are used to model the message significance as well as receptivity. This allows us to more accurately capture the interactions among entities. The application of GPs also allows us to flexibly model the rates of reciprocal activities between two entities, allowing asymmetry in reciprocity to be captured more accurately. This leads to better cluster detection capability. Our model outperforms previous Hawkes and Poisson process-based models at predicting verbal, email, and citation activities.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {726–734},
numpages = {9},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021024,
author = {Tian, Lu and Xu, Pan and Gu, Quanquan},
title = {Forward Backward Greedy Algorithms for Multi-Task Learning with Faster Rates},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A large body of algorithms have been proposed for multi-task learning. However, the effectiveness of many multi-task learning algorithms highly depends on the structural regularization, which incurs bias in the resulting estimators and leads to slower convergence rate. In this paper, we aim at developing a multi-task learning algorithm with faster convergence rate. In particular, we propose a general estimator for multitask learning with row sparsity constraint on the parameter matrix, i.e., the number of nonzero rows in the parameter matrix being small. The proposed estimator is a nonconvex optimization problem. In order to solve it, we develop a forward backward greedy algorithm with provable guarantee. More specifically, we prove that the output of the greedy algorithm attains a sharper estimation error bound than many state-of-the-art multi-task learning methods. Moreover, our estimator enjoys model selection consistency under a mild condition. Thorough experiments on both synthetic and real-world data demonstrate the effectiveness of our method and back up our theory.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {735–744},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021025,
author = {Venugopal, Deepak and Sarkhel, Somdeb and Cherry, Kyle},
title = {Non-Parametric Domain Approximation for Scalable Gibbs Sampling in MLNs},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {MLNs utilize relational structures that are ubiquitous in real-world situations to represent large probabilistic graphical models compactly. However, as is now well-known, inference complexity is one of the main bottlenecks in MLNs. Recently, several approaches have been proposed that exploit approximate symmetries in the MLN to reduce inference complexity. These approaches approximate large domains containing many objects with much smaller domains of meta-objects (or cluster-centers), so that inference is considerably faster and more scalable. However, a drawback in most of these approaches is that it is typically very hard to tune the parameters (e.g., number of clusters) such that inference is both efficient and accurate. Here, we propose a novel non-parametric approach that trades-off solution quality with efficiency to automatically learn the optimal domain approximation. Further, we show how to perform Gibbs sampling effectively in a domain-approximated MLN by adapting the sampler according to the approximation. Our results on several benchmarks show that our approach is scalable, accurate and converges faster than existing methods.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {745–754},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021026,
author = {Wang, Dilin and Fisher, John and Liu, Qiang},
title = {Efficient Observation Selection in Probabilistic Graphical Models Using Bayesian Lower Bounds},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Real-world data often includes rich relational information, which can be leveraged to help predict unknown variables using a small amount of observed variables via a propagation effect. We consider the problem of selecting the best subset of variables to observe to maximize the overall prediction accuracy. Under the Bayesian framework, the optimal subset should be chosen to minimize the Bayesian optimal error rate, which, unfortunately, is critically challenging to calculate when the variables follow complex and high dimensional probabilistic distributions such as graphical models. In this paper, we propose to use a class of Bayesian lower bounds, including Bayesian Cramer Rao bounds as well as a novel extension of it to discrete graphical models, as surrogate criteria for optimal subset selection, providing a set of computationally efficient algorithms. Extensive experiments are presented to demonstrate our algorithm on both simulated and real-world datasets.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {755–764},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021027,
author = {Weller, Adrian},
title = {Characterizing Tightness of LP Relaxations by Forbidding Signed Minors},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider binary pairwise graphical models and provide an exact characterization (necessary and sufficient conditions observing signs of potentials) of tightness for the LP relaxation on the triplet-consistent polytope of the MAP inference problem, by forbidding an odd-K5 (complete graph on 5 variables with all edges repulsive) as a signed minor in the signed suspension graph. This captures signs of both singleton and edge potentials in a compact and efficiently testable condition, and improves significantly on earlier results. We provide other results on tightness of LP relaxations by forbidding minors, draw connections and suggest paths for future research.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {765–774},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021028,
author = {Wipf, David and Dong, Yue and Xin, Bo},
title = {Subspace Clustering with a Twist},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Subspace segmentation or clustering can be defined as the process of assigning subspace labels to a set of data points assumed to lie on the union of multiple low-dimensional, linear subspaces. Given that each point can be efficiently expressed using a linear combination of other points from the same subspace, a variety of segmentation algorithms built upon ℓ1, nuclear norm, and other convex penalties have recently shown state-of-the-art robustness on multiple benchmarks. However, what if instead of observing the original data points, we instead only have access to transformed, or 'twisted' so to speak, measurements? Here we consider underdetermined affine transformations that may arise in computer vision applications such as bidirectional reflectance distribution function (BRDF) estimation. Unfortunately most existing approaches, convex or otherwise, do not address this highly useful generalization. To fill this void, we proceed by deriving a probabilistic model that simultaneously estimates the latent data points and subspace memberships using simple EM update rules. Moreover, in certain restricted settings this approach is guaranteed to produce the correct clustering. Finally a wide range of corroborating empirical evidence, including a BRDF estimation task, speaks to the practical efficacy of this algorithm.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {775–784},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021029,
author = {Xia, Lirong},
title = {Bayesian Estimators as Voting Rules},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We investigate the fairness of Bayesian estimators (BEs) by viewing them as (irresolute) voting rules and evaluating them by satisfaction of desirable social choice axioms. We characterize the class of BEs that satisfy neutrality by the class of BEs with neutral structures. We prove that a BE with a neutral structure is a minimax rule if it further satisfies parameter connectivity. We prove that no BE satisfies strict Condorcet criterion. We also propose three new BEs of natural frameworks and investigate their computational complexity and satisfaction of monotonicity and Condorcet criterion.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {785–794},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021030,
author = {Xie, Pengtao and Kim, Jin Kyu and Zhou, Yi and Ho, Qirong and Kumar, Abhimanu and Yu, Yaoliang and Xing, Eric},
title = {Lighter-Communication Distributed Machine Learning via Sufficient Factor Broadcasting},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Matrix-parametrized models (MPMs) are widely used in machine learning (ML) applications. In large-scale ML problems, the parameter matrix of a MPM can grow at an unexpected rate, resulting in high communication and parameter synchronization costs. To address this issue, we offer two contributions: first, we develop a computation model for a large family of MPMs, which share the following property: the parameter update computed on each data sample is a rank-1 matrix, i.e. the outer product of two "sufficient factors" (SFs). Second, we implement a decentralized, peer-to-peer system, Sufficient Factor Broadcasting (SFB), which broadcasts the SFs among worker machines, and reconstructs the update matrices locally at each worker. SFB takes advantage of small rank-1 matrix updates and efficient partial broadcasting strategies to dramatically improve communication efficiency. We propose a graph optimization based partial broadcasting scheme, which minimizes the delay of information dissemination under the constraint that each machine only communicates with a subset rather than all of machines. Furthermore, we provide theoretical analysis to show that SFB guarantees convergence of algorithms (under full broadcasting) without requiring a centralized synchronization mechanism. Experiments corroborate SFB's efficiency on four MPMs.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {795–804},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021031,
author = {Yang, Peng and Zhao, Peilin and Hai, Zhen and Liu, Wei and Hoi, Steven C.H. and Li, Xiao-Li},
title = {Efficient Multi-Class Selective Sampling on Graphs},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A graph-based multi-class classification problem is typically converted into a collection of binary classification tasks via the one-vs.-all strategy, and then tackled by applying proper binary classification algorithms. Unlike the one-vs.-all strategy, we suggest a unified framework which operates directly on the multi-class problem without reducing it to a collection of binary tasks. Moreover, this framework makes active learning practically feasible for multi-class problems, while the one-vs.-all strategy cannot. Specifically, we employ a novel randomized query technique to prioritize the informative instances. This query technique based on the hybrid criterion of "margin" and "uncertainty" can achieve a comparable mistake bound with its fully supervised counterpart. To take full advantage of correctly predicted labels discarded in traditional conservative algorithms, we propose an aggressive selective sampling algorithm that can update the model even if no error occurs. Thanks to the aggressive updating strategy, the aggressive algorithm attains a lower mistake bound than its conservative competitors in expectation. Encouraging experimental results on real-world graph databases show that the proposed technique by querying an extremely small ratio of labels is able to accomplish better classification accuracy.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {805–814},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021032,
author = {Mohri, Mehryar and Yang, Scott},
title = {Adaptive Algorithms and Data-Dependent Guarantees for Bandit Convex Optimization},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present adaptive algorithms with strong data-dependent regret guarantees for the problem of bandit convex optimization. In the process, we develop a general framework from which the main previous results in this setting can be recovered. The key method is the introduction of adaptive regularization. By appropriately adapting the exploration scheme, we show that one can derive regret guarantees that can be significantly more favorable than those previously known. Moreover, our analysis also modularizes the problematic quantities in achieving the conjectured minimax optimal rates in the most general setting of the problem.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {815–824},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021033,
author = {Zhang, Kun and Zhang, Jiji and Huang, Biwei and Sch\"{o}lkopf, Bernhard and Glymour, Clark},
title = {On the Identifiability and Estimation of Functional Causal Models in the Presence of Outcome-Dependent Selection},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study the identifiability and estimation of functional causal models under selection bias, with a focus on the situation where the selection depends solely on the effect variable, which is known as outcome-dependent selection. We address two questions of identifiability: the identifiability of the causal direction between two variables in the presence of selection bias, and, given the causal direction, the identifiability of the model with outcome-dependent selection. Regarding the first, we show that in the framework of post-nonlinear causal models, once outcome-dependent selection is properly modeled, the causal direction between two variables is generically identifiable; regarding the second, we identify some mild conditions under which an additive noise causal model with outcome-dependent selection is to a large extent identifiable. We also propose two methods for estimating an additive noise model from data that are generated with outcome-dependent selection.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {825–834},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

@inproceedings{10.5555/3020948.3021034,
author = {Zong, Shi and Ni, Hao and Sung, Kenny and Ke, Nan Rosemary and Wen, Zheng and Kveton, Branislav},
title = {Cascading Bandits for Large-Scale Recommendation Problems},
year = {2016},
isbn = {9780996643115},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Most recommender systems recommend a list of items. The user examines the list, from the first item to the last, and often chooses the first attractive item and does not examine the rest. This type of user behavior can be modeled by the cascade model. In this work, we study cascading bandits, an online learning variant of the cascade model where the goal is to recommend K most attractive items from a large set of L candidate items. We propose two algorithms for solving this problem, which are based on the idea of linear generalization. The key idea in our solutions is that we learn a predictor of the attraction probabilities of items from their features, as opposing to learning the attraction probability of each item independently as in the existing work. This results in practical learning algorithms whose regret does not depend on the number of items L. We bound the regret of one algorithm and comprehensively evaluate the other on a range of recommendation problems. The algorithm performs well and outperforms all baselines.},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {835–844},
numpages = {10},
location = {Jersey City, New Jersey, USA},
series = {UAI'16}
}

