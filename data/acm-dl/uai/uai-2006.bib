@inproceedings{10.5555/3020419.3020420,
author = {Asavathiratham, Chalee},
title = {Linear Algebra Approach to Separable Bayesian Networks},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian Networks in which the conditional probability distribution can be separated into a function of only the marginal distribution of a node's parents, instead of the joint distributions. We describe the connection between an arbitrary Conditional Probability Table (CPT) and separable systems using linear algebra. We give an alternate proof to [Pfeffer00] on the equivalence of sufficiency and separability. We present a computational method for testing whether a given CPT is separable.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {1–6},
numpages = {6},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020421,
author = {Ashlagi, Itai and Monderer, Dov and Tennenholtz, Moshe},
title = {Robust Learning Equilibrium},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce robust learning equilibrium and apply it to the context of auctions.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {7–14},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020422,
author = {Bartels, Chris D. and Bilmes, Jeff A.},
title = {Non-Minimal Triangulations for Mixed Stochastic/Deterministic Graphical Models},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We observe that certain large-clique graph tri-angulations can be useful for reducing computational requirements when making queries on mixed stochastic/deterministic graphical models. We demonstrate that many of these large-clique triangulations are non-minimal and are thus unattainable via the elimination algorithm. We introduce ancestral pairs as the basis for novel triangulation heuristics and prove that no more than the addition of edges between ancestral pairs need be considered when searching for state space optimal triangulations in such graphs. Empirical results on random and real world graphs are given. We also present an algorithm and correctness proof for determining if a triangulation can be obtained via elimination, and we show that the decision problem associated with finding optimal state space triangulations in this mixed setting is NP-complete.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {15–22},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020423,
author = {Beal, Matthew J. and Krishnamurthy, Praveen},
title = {Gene Expression Time Course Clustering with Countably Infinite Hidden Markov Models},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Most existing approaches to clustering gene expression time course data treat the different time points as independent dimensions and are invariant to permutations, such as reversal, of the experimental time course. Approaches utilizing HMMs have been shown to be helpful in this regard, but are hampered by having to choose model architectures with appropriate complexities. Here we propose for a clustering application an HMM with a countably infinite state space; inference in this model is possible by recasting it in the hierarchical Dirichlet process (HDP) framework (Teh et al. 2006), and hence we call it the HDP-HMM. We show that the infinite model outperforms model selection methods over finite models, and traditional time-independent methods, as measured by a variety of external and internal indices for clustering on two large publicly available data sets. Moreover, we show that the infinite models utilize more hidden states and employ richer architectures (e.g. state-to-state transitions) without the damaging effects of overfitting.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {23–30},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020424,
author = {Bi, Yaxin and Guan, Jiwen},
title = {An Efficient Triplet-Based Algorithm for Evidential Reasoning},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Linear-time computational techniques have been developed for combining evidence which is available on a number of contending hypotheses. They offer a means of making the computation-intensive calculations involved more efficient in certain circumstances. Unfortunately, they restrict the orthogonal sum of evidential functions to the dichotomous structure — applies only to elements and their complements. In this paper, we present a novel evidence structure in terms of a triplet and a set of algorithms for evidential reasoning. The merit of this structure is that it divides a set of evidence into three subsets, distinguishing trivial evidential elements from important ones — focusing some particular elements. It avoids the deficits of the dichotomous structure in representing the preference of evidence and estimating the basic probability assignment of evidence. We have established a formalism for this structure and the general formulae for combining pieces of evidence in the form of the triplet, which have been theoretically and empirically justified.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {31–38},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020425,
author = {Bidyuk, Bozhena and Dechter, Rina},
title = {Cutset Sampling with Likelihood Weighting},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The paper extends the principle of cutset sampling over Bayesian networks, presented previously for Gibbs sampling, to likelihood weighting (LW). Cutset sampling is motivated by the Rao-Blackwell theorem which implies that sampling over a subset of variables requires fewer samples for convergence due to the reduction in sampling variance. The scheme exploits the network structure in selecting cutsets that allow efficient computation of the sampling distributions. In particular, as we show empirically, likelihood weighting over a loop-cutset (abbreviated LWLC), is time-wise cost-effective. We also provide an effective way for caching the probabilities of the generated samples which improves the performance of the overall scheme. We compare LWLC against regular liklihood-weighting and against Gibbs-based cutset sampling.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {39–46},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020426,
author = {Brito, Carlos and Pearl, Judea},
title = {Graphical Condition for Identification in Recursive SEM},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The paper concerns the problem of predicting the effect of actions or interventions on a system from a combination of (i) statistical data on a set of observed variables, and (ii) qualitative causal knowledge encoded in the form of a directed acyclic graph (DAG). The DAG represents a set of linear equations called Structural Equations Model (SEM), whose coefficients are parameters representing direct causal effects. Reliable quantitative conclusions can only be obtained from the model if the causal effects are uniquely determined by the data. That is, if there exists a unique parameterization for the model that makes it compatible with the data. If this is the case, the model is called identified. The main result of the paper is a general sufficient condition for identification of recursive SEM models.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {47–54},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020427,
author = {Cavallo, Ruggiero and Parkes, David C. and Singh, Satinder},
title = {Optimal Coordinated Planning amongst Self-Interested Agents with Private State},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Consider a multi-agent system in a dynamic and uncertain environment. Each agent's local decision problem is modeled as a Markov decision process (MDP) and agents must coordinate on a joint action in each period, which provides a reward to each agent and causes local state transitions. A social planner knows the model of every agent's MDP and wants to implement the optimal joint policy, but agents are self-interested and have private local state. We provide an incentive-compatible mechanism for eliciting state information that achieves the optimal joint plan in a Markov perfect equilibrium of the induced stochastic game. In the special case in which local problems are Markov chains and agents compete to take a single action in each period, we leverage Gittins allocation indices to provide an efficient factored algorithm and distribute computation of the optimal policy among the agents. Distributed, optimal coordinated learning in a multi-agent variant of the multi-armed bandit problem is obtained as a special case.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {55–62},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020428,
author = {Chan, Hei and Darwiche, Adnan},
title = {On the Robustness of Most Probable Explanations},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In Bayesian networks, a Most Probable Explanation (MPE) is a complete variable instantiation with the highest probability given the current evidence. In this paper, we discuss the problem of finding robustness conditions of the MPE under single parameter changes. Specifically, we ask the question: How much change in a single network parameter can we afford to apply while keeping the MPE unchanged? We will describe a procedure, which is the first of its kind, that computes this answer for all parameters in the Bayesian network in time O(n exp(w)), where n is the number of network variables and w is its treewidth.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {63–71},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020429,
author = {Charitos, Theodore and van der Gaag, Linda C.},
title = {Sensitivity Analysis for Threshold Decision Making with Dynamic Networks},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The effect of inaccuracies in the parameters of a dynamic Bayesian network can be investigated by subjecting the network to a sensitivity analysis. Having detailed the sensitivity functions involved in our previous work, we now study the effect of parameter inaccuracies on a recommended decision in view of a threshold decision-making model. We describe the effect of varying one or more parameters from a conditional probability table and present a computational procedure for establishing bounds between which assessments for these parameters can be varied without inducing a change in the recommended decision. We illustrate the various concepts by means of a real-life dynamic network in the field of infectious disease.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {72–79},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020430,
author = {Choi, Arthur and Darwiche, Adnan},
title = {A Variational Approach for Approximating Bayesian Networks by Edge Deletion},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider in this paper the formulation of approximate inference in Bayesian networks as a problem of exact inference on an approximate network that results from deleting edges (to reduce treewidth). We have shown in earlier work that deleting edges calls for introducing auxiliary network parameters to compensate for lost dependencies, and proposed intuitive conditions for determining these parameters. We have also shown that our earlier method corresponds to Iterative Belief Propagation (IBP) when enough edges are deleted to yield a polytree, and corresponds to some generalizations of IBP when fewer edges are deleted. In this paper, we propose a different criteria for determining auxiliary parameters based on optimizing the KL-divergence between the original and approximate networks. We discuss the relationship between the two methods for selecting parameters, shedding new light on IBP and its generalizations. We also discuss the application of our new method to approximating inference problems which are exponential in constrained treewidth, including MAP and nonmyopic value of information.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {80–89},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020431,
author = {Cowell, Robert G. and Lauritzen, Steffen L. and Mortera, Julia},
title = {MAIES: A Tool for DNA Mixture Analysis},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We describe an expert system, MAIES, under development for analysing forensic identification problems involving DNA mixture traces using quantitative peak area information. Peak area information is represented by conditional Gaussian distributions, and inference based on exact junction tree propagation ascertains whether individuals, whose profiles have been measured, have contributed to the mixture. The system can also be used to predict DNA profiles of unknown contributors by separating the mixture into its individual components. The use of the system is illustrated with an application to a real world example. The system implements a novel MAP (maximum a posteriori) search algorithm that is briefly described.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {90–97},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020432,
author = {Crammer, Koby and Globerson, Amir},
title = {Discriminative Learning via Semidefinite Probabilistic Models},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Discriminative linear models are a popular tool in machine learning. These can be generally divided into two types: linear classifiers, such as support vector machines (SVMs), which are well studied and provide state-of-the-art results, and probabilistic models such as logistic regression. One shortcoming of SVMs is that their output (known as the "margin") is not calibrated, so that it is difficult to incorporate such models as components of larger systems. This problem is solved in the probabilistic approach. We combine these two approaches above by constructing a model which is both linear in the model parameters and probabilistic, thus allowing maximum margin training with calibrated outputs. Our model assumes that classes correspond to linear sub-spaces (rather than to half spaces), a view which is closely related to concepts in quantum detection theory. The corresponding optimization problems are semidefinite programs which can be solved efficiently. We illustrate the performance of our algorithm on real world datasets, and show that it outperforms second-order kernel methods.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {98–105},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020433,
author = {Dani, Varsha and Madani, Omid and Pennock, David and Sanghai, Sumit and Galebach, Brian},
title = {An Empirical Comparison of Algorithms for Aggregating Expert Predictions},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Predicting the outcomes of future events is a challenging problem for which a variety of solution methods have been explored and attempted. We present an empirical comparison of a variety of online and offline adaptive algorithms for aggregating experts' predictions of the outcomes of five years of US National Football League games (1319 games) using expert probability elicitations obtained from an Internet contest called ProbabilitySports. We find that it is difficult to improve over simple averaging of the predictions in terms of prediction accuracy, but that there is room for improvement in quadratic loss. Somewhat surprisingly, a Bayesian estimation algorithm which estimates the variance of each expert's prediction exhibits the most consistent superior performance over simple averaging among our collection of algorithms.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {106–113},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020434,
author = {Dasgupta, Sanjoy and Hsu, Daniel and Verma, Nakul},
title = {A Concentration Theorem for Projections},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Suppose the random variable X ∈ ℝD has mean zero and finite second moments. We show that there is a precise sense in which almost all linear projections of X into ℝD (for d &lt; D) look like a scale-mixture of spherical Gaussians—specifically, a mixture of distributions N(0, σ2Id) where the the σ values follow the same distribution as ‖X‖/√D. The extent of this effect depends upon the ratio of d to D, and upon a particular coefficient of eccentricity of X's distribution.We explore this result in a variety of experiments.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {114–121},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020435,
author = {Degris, Thomas and Sigaud, Olivier and Wuillemin, Pierre-Henri},
title = {Chi-Square Tests Driven Method for Learning the Structure of Factored MDPs},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {SDYNA is a general framework designed to address large stochastic reinforcement learning (RL) problems. Unlike previous model-based methods in Factored MDPs (FMDPS), it incrementally learns the structure of a RL problem using supervised learning techniques. SPITI is an instantiation of SDYNA that uses decision trees as factored representations. First, we show that, in structured RL problems, SPITI learns the structure of FMDPs using Chi-Square tests and performs better than classical tabular model-based methods. Second, we study the generalization property of SPITI using a Chi-Square based measure of the accuracy of the model built by SPITI.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {122–129},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020436,
author = {Didelez, Vanessa},
title = {Asymmetric Separation for Local Independence Graphs},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Directed possibly cyclic graphs have been proposed by Didelez (2000) and Nodelmann et al. (2002) in order to represent the dynamic dependencies among stochastic processes. These dependencies are based on a generalization of Granger-causality to continuous time, first developed by Schweder (1970) for Markov processes, who called them local dependencies. They deserve special attention as they are asymmetric. In this paper we focus on their graphical representation and develop an asymmetric notion of separation. The properties of this graph separation as well as local independence are investigated in detail within a framework of asymmetric (semi)graphoids allowing insight into what information can be read off these graphs.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {130–137},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020437,
author = {Didelez, Vanessa and Dawid, A. Philip and Geneletti, Sara},
title = {Direct and Indirect Effects of Sequential Treatments},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper we review the notion of direct and indirect causal effect as introduced by Pearl (2001). We show how it can be formulated without counterfactuals, using regime indicators instead. This allows to consider the natural (in)direct effect as a special case of sequential treatments discussed by Dawid &amp; Didelez (2005) which immediately yields conditions for identifiability as well as a graphical way of checking identifiability.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {138–146},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020438,
author = {Eichler, Michael},
title = {Fitting Graphical Interaction Models to Multivariate Time Series},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Graphical interaction models have become an important tool for analysing multivariate time series. In these models, the interrelationships among the components of a time series are described by undirected graphs in which the vertices depict the components while the edges indictate possible dependencies between the components. Current methods for the identification of the graphical structure are based on nonparametric spectral estimation, which prevents application of common model selection strategies. In this paper, we present a parametric approach for graphical interaction modelling of multivariate stationary time series. The proposed models generalize covariance selection models to the time series setting and are formulated in terms of inverse covariances. We show that these models correspond to vector autoregressive models under conditional independence constraints encoded by undirected graphs. Furthermore, we discuss maximum likelihood estimation based on Whittle's approximation to the log-likelihood function and propose an iterative method for solving the resulting likelihood equations. The concepts are illustrated by an example.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {147–154},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020439,
author = {El-Hay, Tal and Friedman, Nir and Koller, Daphne and Kupferman, Raz},
title = {Continuous Time Markov Networks},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A central task in many applications is reasoning about processes that change over continuous time. Recently, Nodelman et al. introduced continuous time Bayesian networks (CTBNs), a structured representation for representing Continuous Time Markov Processes over a structured state space. In this paper, we introduce continuous time Markov networks (CTMNs), an alternative representation language that represents a different type of continuous-time dynamics, particularly appropriate for modeling biological and chemical systems. In this language, the dynamics of the process is described as an interplay between two forces: the tendency of each entity to change its state, which we model using a continuous-time proposal process that suggests possible local changes to the state of the system at different rates; and a global fitness or energy function of the entire system, governing the probability that a proposed change is accepted, which we capture by a Markov network that encodes the fitness of different states. We show that the fitness distribution is also the stationary distribution of the Markov process, so that this representation provides a characterization of a temporal process whose stationary distribution has a compact graphical representation. We describe the semantics of the representation, its basic properties, and how it compares to CTBNs. We also provide an algorithm for learning such models from data, and demonstrate its potential benefit over other learning approaches.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {155–164},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020440,
author = {Elidan, Gal and McGraw, Ian and Koller, Daphne},
title = {Residual Belief Propagation: Informed Scheduling for Asynchronous Message Passing},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Inference for probabilistic graphical models is still very much a practical challenge in large domains. The commonly used and effective belief propagation (BP) algorithm and its generalizations often do not converge when applied to hard, real-life inference tasks. While it is widely recognized that the scheduling of messages in these algorithms may have significant consequences, this issue remains largely unexplored. In this work, we address the question of how to schedule messages for asynchronous propagation so that a fixed point is reached faster and more often. We first show that any reasonable asynchronous BP converges to a unique fixed point under conditions similar to those that guarantee convergence of synchronous BP. In addition, we show that the convergence rate of a simple round-robin schedule is at least as good as that of synchronous propagation. We then propose residual belief propagation (RBP), a novel, easy-to-implement, asynchronous propagation algorithm that schedules messages in an informed way, that pushes down a bound on the distance from the fixed point. Finally, we demonstrate the superiority of RBP over state-of-the-art methods for a variety of challenging synthetic and real-life problems: RBP converges significantly more often than other methods; and it significantly reduces running time until convergence, even when other methods converge.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {165–173},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020441,
author = {Ferns, Norm and Castro, Pablo Samuel and Precup, Doina and Panangaden, Prakash},
title = {Methods for Computing State Similarity in Markov Decision Processes},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A popular approach to solving large probabilistic systems relies on aggregating states based on a measure of similarity. Many approaches in the literature are heuristic. A number of recent methods rely instead on metrics based on the notion of bisimulation, or behavioral equivalence between states (Givan et al., 2003; Ferns et al., 2004). An integral component of such metrics is the Kantorovich metric between probability distributions. However, while this metric enables many satisfying theoretical properties, it is costly to compute in practice. In this paper, we use techniques from network optimization and statistical sampling to overcome this problem. We obtain in this manner a variety of distance functions for MDP state aggregation that differ in the tradeoff between time and space complexity, as well as the quality of the aggregation. We provide an empirical evaluation of these tradeoffs.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {174–181},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020442,
author = {Friedman, Nir and Kupferman, Raz},
title = {Dimension Reduction in Singularly Perturbed Continuous-Time Bayesian Networks},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Continuous-time Bayesian networks (CTBNs) are graphical representations of multi-component continuous-time Markov processes as directed graphs. The edges in the network represent direct influences among components. The joint rate matrix of the multi-component process is specified by means of conditional rate matrices for each component separately. This paper addresses the situation where some of the components evolve on a time scale that is much shorter compared to the time scale of the other components. We prove that in the limit where the separation of scales is infinite, the Markov process converges (in distribution, or weakly) to a reduced, or effective Markov process that only involves the slow components. We also demonstrate that for a reasonable separation of scales (an order of magnitude) the reduced process is a good approximation of the marginal process over the slow components. We provide a simple procedure for building a reduced CTBN for this effective process, with conditional rate matrices that can be directly calculated from the original CTBN, and discuss the implications for approximate reasoning in large systems.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {182–191},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020443,
author = {Giang, Phan H.},
title = {A New Axiomatization for Likelihood Gambles},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper studies a new and more general axiomatization than one presented in [6] for preference on likelihood gambles. Likelihood gambles describe actions in a situation where a decision maker knows multiple probabilistic models and a random sample generated from one of those models but does not know prior probability of models. This new axiom system is inspired by Jensen's axiomatization of probabilistic gambles. Our approach provides a new perspective to the role of data in decision making under ambiguity.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {192–199},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020444,
author = {Givoni, Inmar and Cheung, Vincent and Frey, Brendan J.},
title = {Matrix Tile Analysis},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Many tasks require finding groups of elements in a matrix of numbers, symbols or class likelihoods. One approach is to use efficient bi- or tri-linear factorization techniques including PCA, ICA, sparse matrix factorization and plaid analysis. These techniques are not appropriate when addition and multiplication of matrix elements are not sensibly defined. More directly, methods like bi-clustering can be used to classify matrix elements, but these methods make the overly-restrictive assumption that the class of each element is a function of a row class and a column class. We introduce a general computational problem, 'matrix tile analysis' (MTA), which consists of decomposing a matrix into a set of non-overlapping tiles, each of which is defined by a subset of usually nonadjacent rows and columns. MTA does not require an algebra for combining tiles, but must search over an exponential number of discrete combinations of tile assignments. We describe a loopy BP (sum-product) algorithm and an ICM algorithm for performing MTA. We compare the effectiveness of these methods to PCA and the plaid method on hundreds of randomly generated tasks. Using double-gene-knockout data, we show that MTA finds groups of interacting yeast genes that have biologically-related functions.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {200–207},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020445,
author = {Guo, Yuhong and Schuurmans, Dale},
title = {Convex Structure Learning for Bayesian Networks: Polynomial Feature Selection and Approximate Ordering},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a new approach to learning the structure and parameters of a Bayesian network based on regularized estimation in an exponential family representation. Here we show that, given a fixed variable order, the optimal structure and parameters can be learned efficiently, even without restricting the size of the parent variable sets. We then consider the problem of optimizing the variable order for a given set of features. This is still a computationally hard problem, but we present a convex relaxation that yields an optimal "soft" ordering in polynomial time. One novel aspect of the approach is that we do not perform a discrete search over DAG structures, nor over variable orders, but instead solve a continuous convex relaxation that can then be rounded to obtain a valid network structure. We conduct an experimental comparison against standard structure search procedures over standard objectives, which cope with local minima, and evaluate the advantages of using convex relaxations that reduce the effects of local minima.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {208–216},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020446,
author = {Huang, Yimin and Valtorta, Marco},
title = {Pearl's Calculus of Intervention is Complete},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper is concerned with graphical criteria that can be used to solve the problem of identifying casual effects from nonexperimental data in a causal Bayesian network structure, i.e., a directed acyclic graph that represents causal relationships. We first review Pearl's work on this topic [Pearl, 1995], in which several useful graphical criteria are presented. Then we present a complete algorithm [Huang and Valtorta, 2006b] for the identifiability problem. By exploiting the completeness of this algorithm, we prove that the three basic do-calculus rules that Pearl presents are complete, in the sense that, if a causal effect is identifiable, there exists a sequence of applications of the rules of the do-calculus that transforms the causal effect formula into a formula that only includes observational quantities.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {217–224},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020447,
author = {Jaeger, Manfred},
title = {The AI&amp;M Procedure for Learning from Incomplete Data},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We investigate methods for parameter learning from incomplete data that is not missing at random. Likelihood-based methods then require the optimization of a profile likelihood that takes all possible missingness mechanisms into account. Optimizing this profile likelihood poses two main difficulties: multiple (local) maxima, and its very high-dimensional parameter space. In this paper a new method is presented for optimizing the profile likelihood that addresses the second difficulty: in the proposed AI&amp;M (adjusting imputation and maximization) procedure the optimization is performed by operations in the space of data completions, rather than directly in the parameter space of the profile likelihood. We apply the AI&amp;M method to learning parameters for Bayesian networks. The method is compared against conservative inference, which takes into account each possible data completion, and against EM. The results indicate that likelihood-based inference is still feasible in the case of unknown missingness mechanisms, and that conservative inference is unnecessarily weak. On the other hand, our results also provide evidence that the EM algorithm is still quite effective when the data is not missing at random.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {225–232},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020448,
author = {Kang, Changsung and Tian, Jin},
title = {Inequality Constraints in Causal Models with Hidden Variables},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a class of inequality constraints on the set of distributions induced by local interventions on variables governed by a causal Bayesian network, in which some of the variables remain unmeasured. We derive bounds on causal effects that are not directly measured in randomized experiments. We derive instrumental inequality type of constraints on nonexperimental distributions. The results have applications in testing causal models with observational or experimental data.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {233–240},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020449,
author = {Koivisto, Mikko},
title = {Advances in Exact Bayesian Structure Discovery in Bayesian Networks},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We consider a Bayesian method for learning the Bayesian network structure from complete data. Recently, Koivisto and Sood (2004) presented an algorithm that for any single edge computes its marginal posterior probability in O(n2n) time, where n is the number of attributes; the number of parents per attribute is bounded by a constant. In this paper we show that the posterior probabilities for all the n(n - 1) potential edges can be computed in O(n2n) total time. This result is achieved by a forward-backward technique and fast M\"{o}bius transform algorithms, which are of independent interest. The resulting speedup by a factor of about n2 allows us to experimentally study the statistical power of learning moderate-size networks. We report results from a simulation study that covers data sets with 20 to 10,000 records over 5 to 25 discrete attributes.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {241–248},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020450,
author = {Kuroki, Manabu and Cai, Zhihong},
title = {Stratified Analysis of "Probabilities of Causation"},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {This paper derives new bounds for the probabilities of causation defined by Pearl (2000), namely, the probability that one observed event was a necessary (or sufficient, or both) cause of another. Tian and Pearl (2000a, 2000b) showed how to bound these probabilities using information from experimental and observational studies, with minimal assumptions about the data-generating process. We derive narrower bounds using covariates measurements that might be available in the studies. In addition, we provide identifiable case under no-prevention assumption and discuss the covariate selection problem from the viewpoint of estimation accuracy. These results provides more accurate information for public policy, legal determination of responsibility and personal decision making.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {249–256},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020451,
author = {Langford, John and Oliveira, Roberto and Zadrozny, Bianca},
title = {Predicting Conditional Quantiles via Reduction to Classification},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We show how to reduce the process of predicting conditional quantiles (and the median in particular) to solving classification. The accompanying theoretical statement shows that the regret of the classifier bounds the regret of the quantile regression under a quantile loss. We also test this reduction empirically against existing quantile regression methods on large real-world datasets and discover that it provides state-of-the-art performance.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {257–264},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020452,
author = {Laskey, Kathryn B. and Xu, Ning and Chen, Chun-Hung},
title = {Propagation of Delays in the National Airspace System},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The National Airspace System (NAS) is a large and complex system with thousands of interrelated components: administration, control centers, airports, airlines, aircraft, passengers, etc. The complexity of the NAS creates many difficulties in management and control. One of the most pressing problems is flight delay. Delay creates high cost to airlines, complaints from passengers, and difficulties for airport operations. As demand on the system increases, the delay problem becomes more and more prominent. For this reason, it is essential for the Federal Aviation Administration to understand the causes of delay and to find ways to reduce delay. Major contributing factors to delay are congestion at the origin airport, weather, increasing demand, and air traffic management (ATM) decisions such as the Ground Delay Programs (GDP). Delay is an inherently stochastic phenomenon. Even if all known causal factors could be accounted for, macro-level national airspace system (NAS) delays could not be predicted with certainty from micro-level aircraft information. This paper presents a stochastic model that uses Bayesian Networks (BNs) to model the relationships among different components of aircraft delay and the causal factors that affect delays. A case study on delays of departure flights from Chicago O'Hare international airport (ORD) to Hartsfield-Jackson Atlanta International Airport (ATL) reveals how local and system level environmental and human-caused factors combine to affect components of delay, and how these components contribute to the final arrival delay at the destination airport.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {265–272},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020453,
author = {Lebanon, Guy},
title = {Sequential Document Representations and Simplicial Curves},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The popular bag of words assumption represents a document as a histogram of word occurrences. While computationally efficient, such a representation is unable to maintain any sequential information. We present a continuous and differentiable sequential document representation that goes beyond the bag of words assumption, and yet is efficient and effective. This representation employs smooth curves in the multinomial simplex to account for sequential information. In contrast to n-grams the new representation is able to robustly model long rage sequential trends in the document. We discuss the representation and its geometric properties and demonstrate its applicability for the task of text classification.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {273–280},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020454,
author = {Lee, Dongryeol and Gray, Alexander},
title = {Faster Gaussian Summation: Theory and Experiment},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We provide faster algorithms for the problem of Gaussian summation, which occurs in many machine learning methods. We develop two new extensions - an O(Dp) Taylor expansion for the Gaussian kernel with rigorous error bounds and a new error control scheme integrating any arbitrary approximation method - within the best discrete-algorithmic framework using adaptive hierarchical data structures. We rigorously evaluate these techniques empirically in the context of optimal bandwidth selection in kernel density estimation, revealing the strengths and weaknesses of current state-of-the-art approaches for the first time. Our results demonstrate that the new error control scheme yields improved performance, whereas the series expansion approach is only effective in low dimensions (five or less).},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {281–288},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020455,
author = {Lee, Seunghwan Han},
title = {Reasoning about Uncertainty in Metric Spaces},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We set up a model for reasoning about metric spaces with belief theoretic measures. The uncertainty in these spaces stems from both probability and metric structures. To represent both aspect of uncertainty, we choose an expected distance function as a measure of uncertainty. A formal logical system is constructed for the reasoning about expected distance. Soundness and completeness are shown for this logic. For reasoning on product metric spaces with uncertainty, a new metric is defined and shown to have good properties.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {289–297},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020456,
author = {Littman, Michael L. and Ravi, Nishkam and Talwar, Arjun and Zinkevich, Martin},
title = {An Efficient Optimal-Equilibrium Algorithm for Two-Player Game Trees},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Two-player complete-information game trees are perhaps the simplest possible setting for studying general-sum games and the computational problem of finding equilibria. These games admit a simple bottom-up algorithm for finding subgame perfect Nash equilibria efficiently. However, such an algorithm can fail to identify optimal equilibria, such as those that maximize social welfare. The reason is that, counterintuitively, probabilistic action choices are sometimes needed to achieve maximum payoffs. We provide a novel polynomial-time algorithm for this problem that explicitly reasons about stochastic decisions and demonstrate its use in an example card game.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {298–305},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020457,
author = {Madsen, Anders L},
title = {Belief Update in CLG Bayesian Networks with Lazy Propagation},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In recent years Bayesian networks (BNs) with a mixture of continuous and discrete variables have received an increasing level of attention. We present an architecture for exact belief update in Conditional Linear Gaussian BNs (CLG BNs). The architecture is an extension of lazy propagation using operations of Lauritzen &amp; Jensen [6] and Cowell [2]. By decomposing clique and separator potentials into sets of factors, the proposed architecture takes advantage of independence and irrelevance properties induced by the structure of the graph and the evidence. The resulting benefits are illustrated by examples. Results of a preliminary empirical performance evaluation indicate a significant potential of the proposed architecture.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {306–313},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020458,
author = {Mani, Subramani and Spirtes, Peter and Cooper, Gregory F.},
title = {A Theoretical Study of Y Structures for Causal Discovery},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Causal discovery from observational data in the presence of unobserved variables is challenging. Identification of so-called Y substructures is a sufficient condition for ascertaining some causal relations in the large sample limit, without the assumption of no hidden common causes. An example of a Y substructure is A → C, B → C, C → D. This paper describes the first asymptotically reliable and computationally feasible score-based search for discrete Y structures that does not assume that there are no unobserved common causes. For any parameterization of a directed acyclic graph (DAG) that has scores with the property that any DAG that can represent the distribution beats any DAG that can't, and for two DAGs that represent the distribution, if one has fewer parameters than the other, the one with the fewest parameter wins. In this framework there is no need to assign scores to causal structures with unobserved common causes. The paper also describes how the existence of a Y structure shows the presence of an unconfounded causal relation, without assuming that there are no hidden common causes.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {314–323},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020459,
author = {Mansinghka, V. K. and Kemp, C. and Tenenbaum, J. B. and Griffiths, T. L.},
title = {Structured Priors for Structure Learning},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Traditional approaches to Bayes net structure learning typically assume little regularity in graph structure other than sparseness. However, in many cases, we expect more systematicity: variables in real-world systems often group into classes that predict the kinds of probabilistic dependencies they participate in. Here we capture this form of prior knowledge in a hierarchical Bayesian framework, and exploit it to enable structure learning and type discovery from small datasets. Specifically, we present a nonparametric generative model for directed acyclic graphs as a prior for Bayes net structure learning. Our model assumes that variables come in one or more classes and that the prior probability of an edge existing between two variables is a function only of their classes. We derive an MCMC algorithm for simultaneous inference of the number of classes, the class assignments of variables, and the Bayes net structure over variables. For several realistic, sparse datasets, we show that the bias towards systematicity of connections provided by our model can yield more accurate learned networks than the traditional approach of using a uniform prior, and that the classes found by our model are appropriate.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {324–331},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020460,
author = {Marthi, Bhaskara and Russell, Stuart and Andre, David},
title = {A Compact, Hierarchically Optimal Q-Function Decomposition},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Previous work in hierarchical reinforcement learning has faced a dilemma: either ignore the values of different possible exit states from a subroutine, thereby risking suboptimal behavior, or represent those values explicitly thereby incurring a possibly large representation cost because exit values refer to nonlocal aspects of the world (i.e., all subsequent rewards). This paper shows that, in many cases, one can avoid both of these problems. The solution is based on recursively decomposing the exit value function in terms of Q-functions at higher levels of the hierarchy. This leads to an intuitively appealing runtime architecture in which a parent subroutine passes to its child a value function on the exit states and the child reasons about how its choices affect the exit value. We also identify structural conditions on the value function and transition distributions that allow much more concise representations of exit state distributions, leading to further state abstraction. In essence, the only variables whose exit values need be considered are those that the parent cares about and the child affects. We demonstrate the utility of our algorithms on a series of increasingly complex environments.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {332–340},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020461,
author = {Mei, Guobiao and Shelton, Christian R.},
title = {Visualization of Collaborative Data},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Collaborative data consist of ratings relating two distinct sets of objects: users and items. Much of the work with such data focuses on filtering: predicting unknown ratings for pairs of users and items. In this paper we focus on the problem of visualizing the information. Given all of the ratings, our task is to embed all of the users and items as points in the same Euclidean space. We would like to place users near items that they have rated (or would rate) high, and far away from those they would give low ratings. We pose this problem as a real-valued non-linear Bayesian network and employ Markov chain Monte Carlo and expectation maximization to find an embedding. We present a metric by which to judge the quality of a visualization and compare our results to Eigentaste, locally linear embedding and co-occurrence data embedding on three real-world datasets.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {341–348},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020462,
author = {Milch, Brian and Russell, Stuart},
title = {General-Purpose MCMC Inference over Relational Structures},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Tasks such as record linkage and multi-target tracking, which involve reconstructing the set of objects that underlie some observed data, are particularly challenging for probabilistic inference. Recent work has achieved efficient and accurate inference on such problems using Markov chain Monte Carlo (MCMC) techniques with customized proposal distributions. Currently, implementing such a system requires coding MCMC state representations and acceptance probability calculations that are specific to a particular application. An alternative approach, which we pursue in this paper, is to use a general-purpose probabilistic modeling language (such as BLOG) and a generic Metropolis-Hastings MCMC algorithm that supports user-supplied proposal distributions. Our algorithm gains flexibility by using MCMC states that are only partial descriptions of possible worlds; we provide conditions under which MCMC over partial worlds yields correct answers to queries. We also show how to use a context-specific Bayes net to identify the factors in the acceptance probability that need to be computed for a given proposed move. Experimental results on a citation matching task show that our general-purpose MCMC engine compares favorably with an application-specific system.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {349–358},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020463,
author = {Murray, Iain and Ghahramani, Zoubin and MacKay, David J. C.},
title = {MCMC for Doubly-Intractable Distributions},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Markov Chain Monte Carlo (MCMC) algorithms are routinely used to draw samples from distributions with intractable normalization constants. However, standard MCMC algorithms do not apply to doubly-intractable distributions in which there are additional parameter-dependent normalization terms; for example, the posterior over parameters of an undirected graphical model. An ingenious auxiliary-variable scheme (M\o{}ller et al., 2004) offers a solution: exact sampling (Propp and Wilson, 1996) is used to sample from a Metropolis-Hastings proposal for which the acceptance probability is tractable. Unfortunately the acceptance probability of these expensive updates can be low. This paper provides a generalization of M0ller et al. (2004) and a new MCMC algorithm, which obtains better acceptance probabilities for the same amount of exact sampling, and removes the need to estimate model parameters before sampling begins.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {359–366},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020464,
author = {Pena, Jose M. and Nilsson, Roland and Bj\"{o}rkegren, Johan and Tegn\'{e}r, Jesper},
title = {Identifying the Relevant Nodes without Learning the Model},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We propose a method to identify all the nodes that are relevant to compute all the conditional probability distributions for a given set of nodes. Our method is simple, efficient, consistent, and does not require learning a Bayesian network first. Therefore, our method can be applied to high-dimensional databases, e.g. gene expression databases.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {367–374},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020465,
author = {Pfeffer, Avi},
title = {Approximate Separability for Weak Interaction in Dynamic Systems},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {One approach to monitoring a dynamic system relies on decomposition of the system into weakly interacting subsystems. An earlier paper introduced a notion of weak interaction called separability, and showed that it leads to exact propagation of marginals for prediction. This paper addresses two questions left open by the earlier paper: can we define a notion of approximate separability that occurs naturally in practice, and do separability and approximate separability lead to accurate monitoring? The answer to both questions is affirmative. The paper also analyzes the structure of approximately separable decompositions, and provides some explanation as to why these models perform well.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {375–384},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020466,
author = {Porteous, Ian and Ihler, Alex and Smyth, Padhraic and Welling, Max},
title = {Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick Breaking Representation},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Nonparametric Bayesian approaches to clustering, information retrieval, language modeling and object recognition have recently shown great promise as a new paradigm for unsupervised data analysis. Most contributions have focused on the Dirichlet process mixture models or extensions thereof for which efficient Gibbs samplers exist. In this paper we explore Gibbs samplers for infinite complexity mixture models in the stick breaking representation. The advantage of this representation is improved modeling flexibility. For instance, one can design the prior distribution over cluster sizes or couple multiple infinite mixture models (e.g., overtime) at the level of their parameters (i.e., the dependent Dirichlet process model). However, Gibbs samplers for infinite mixture models (as recently introduced in the statistics literature) seem to mix poorly over cluster labels. Among others issues, this can have the adverse effect that labels for the same cluster in coupled mixture models are mixed up. We introduce additional moves in these samplers to improve mixing over cluster labels and to bring clusters into correspondence. An application to modeling of storm trajectories is used to illustrate these ideas.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {385–392},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020467,
author = {Pralet, C\'{e}dric and Schiex, Thomas and Verfaillie, G\'{e}rard},
title = {From Influence Diagrams to Multi-Operator Cluster DAGs},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {There exist several architectures to solve influence diagrams using local computations, such as the Shenoy-Shafer, the HUGIN, or the Lazy Propagation architectures. They all extend usual variable elimination algorithms thanks to the use of so-called "potentials". In this paper, we introduce a new architecture, called the Multi-operator Cluster DAG architecture, which can produce decompositions with an improved constrained induced-width, and therefore induce potentially exponential gains. Its principle is to benefit from the composite nature of influence diagrams, instead of using uniform potentials, in order to better analyze the problem structure.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {393–400},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020468,
author = {Ramsey, Joseph and Spirtes, Peter and Zhang, Jiji},
title = {Adjacency-Faithfulness and Conservative Causal Inference},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Most causal discovery algorithms in the literature exploit an assumption usually referred to as the Causal Faithfulness or Stability Condition. In this paper, we highlight two components of the condition used in constraint-based algorithms, which we call "Adjacency-Faithfulness" and "Orientation-Faithfulness." We point out that assuming Adjacency-Faithfulness is true, it is possible to test the validity of Orientation-Faithfulness. Motivated by this observation, we explore the consequence of making only the Adjacency-Faithfulness assumption. We show that the familiar PC algorithm has to be modified to be correct under the weaker, Adjacency-Faithfulness assumption. The modified algorithm, called Conservative PC (CPC), checks whether Orientation-Faithfulness holds in the orientation phase, and if not, avoids drawing certain causal conclusions the PC algorithm would draw. However, if the stronger, standard causal Faithfulness condition actually obtains, the CPC algorithm outputs the same pattern as the PC algorithm does in the large sample limit.We also present a simulation study showing that the CPC algorithm runs almost as fast as the PC algorithm, and outputs significantly fewer false causal arrowheads than the PC algorithm does on realistic sample sizes.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {401–408},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020469,
author = {Sanner, Scott and Boutilier, Craig},
title = {Practical Linear Value-Approximation Techniques for First-Order MDPs},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recent work on approximate linear programming (ALP) techniques for first-order Markov Decision Processes (FOMDPs) represents the value function linearly w.r.t. a set of first-order basis functions and uses linear programming techniques to determine suitable weights. This approach offers the advantage that it does not require simplification of the first-order value function, and allows one to solve FOMDPs independent of a specific domain instantiation. In this paper, we address several questions to enhance the applicability of this work: (1) Can we extend the first-order ALP framework to approximate policy iteration and if so, how do these two algorithms compare? (2) Can we automatically generate basis functions and evaluate their impact on value function quality? (3) How can we decompose intractable problems with universally quantified rewards into tractable subproblems? We propose answers to these questions along with a number of novel optimizations and provide a comparative empirical evaluation on problems from the ICAPS 2004 Probabilistic Planning Competition.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {409–417},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020470,
author = {Schaeffer, Monika and Parr, Ronald},
title = {Efficient Selection of Disambiguating Actions for Stereo Vision},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In many domains that involve the use of sensors, such as robotics or sensor networks, there are opportunities to use some form of active sensing to disambiguate data from noisy or unreliable sensors. These disambiguating actions typically take time and expend energy. One way to choose the next disambiguating action is to select the action with the greatest expected entropy reduction, or information gain. In this work, we consider active sensing in aid of stereo vision for robotics. Stereo vision is a powerful sensing technique for mobile robots, but it can fail in scenes that lack strong texture. In such cases, a structured light source, such as vertical laser line, can be used for disambiguation. By treating the stereo matching problem as a specially structured HMM-like graphical model, we demonstrate that for a scan line with n columns and maximum stereo disparity d, the entropy minimizing aim point for the laser can be selected in O(nd) time - cost no greater than the stereo algorithm itself. A typical HMM formulation would suggest at least O(nd2) time for the entropy calculation alone.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {418–427},
numpages = {10},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020471,
author = {Shenoy, Prakash P.},
title = {Inference in Hybrid Bayesian Networks Using Mixtures of Gaussians},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The main goal of this paper is to describe a method for exact inference in general hybrid Bayesian networks (BNs) (with a mixture of discrete and continuous chance variables). Our method consists of approximating general hybrid Bayesian networks by a mixture of Gaussians (MoG) BNs. There exists a fast algorithm by Lauritzen-Jensen (LJ) for making exact inferences in MoG Bayesian networks, and there exists a commercial implementation of this algorithm. However, this algorithm can only be used for MoG BNs. Some limitations of such networks are as follows. All continuous chance variables must have conditional linear Gaussian distributions, and discrete chance nodes cannot have continuous parents. The methods described in this paper will enable us to use the LJ algorithm for a bigger class of hybrid Bayesian networks. This includes networks with continuous chance nodes with non-Gaussian distributions, networks with no restrictions on the topology of discrete and continuous variables, networks with conditionally deterministic variables that are a nonlinear function of their continuous parents, and networks with continuous chance variables whose variances are functions of their parents.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {428–436},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020472,
author = {Shpitser, Ilya and Pearl, Judea},
title = {Identification of Conditional Interventional Distributions},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The subject of this paper is the elucidation of effects of actions from causal assumptions represented as a directed graph, and statistical knowledge given as a probability distribution. In particular, we are interested in predicting distributions on post-action outcomes given a set of measurements. We provide a necessary and sufficient graphical condition for the cases where such distributions can be uniquely computed from the available information, as well as an algorithm which performs this computation whenever the condition holds. Furthermore, we use our results to prove completeness of do-calculus [Pearl, 1995] for the same identification problem, and show applications to sequential decision making.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {437–444},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020473,
author = {Silander, Tomi and Myllym\"{a}ki, Petri},
title = {A Simple Approach for Finding the Globally Optimal Bayesian Network Structure},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We study the problem of learning the best Bayesian network structure with respect to a decomposable score such as BDe, BIC or AIC. This problem is known to be NP-hard, which means that solving it becomes quickly infeasible as the number of variables increases. Nevertheless, in this paper we show that it is possible to learn the best Bayesian network structure with over 30 variables, which covers many practically interesting cases. Our algorithm is less complicated and more efficient than the techniques presented earlier. It can be easily parallelized, and offers a possibility for efficient exploration of the best networks consistent with different variable orderings. In the experimental part of the paper we compare the performance of the algorithm to the previous state-of-the-art algorithm. Free source-code and an online-demo can be found at http://b-course.hiit.fi/bene.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {445–452},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020474,
author = {Silva, Ricardo and Ghahramani, Zoubin},
title = {Bayesian Inference for Gaussian Mixed Graph Models},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce priors and algorithms to perform Bayesian inference in Gaussian models defined by acyclic directed mixed graphs. Such a class of graphs, composed of directed and bi-directed edges, is a representation of conditional independencies that is closed under marginalization and arises naturally from causal models which allow for unmeasured confounding. Monte Carlo methods and a variational approximation for such models are presented. Our algorithms for Bayesian inference allow the evaluation of posterior distributions for several quantities of interest, including causal effects that are not identifiable from data alone but could otherwise be inferred where informative prior knowledge about confounding is available.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {453–460},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020475,
author = {Snelson, Edward and Ghahramani, Zoubin},
title = {Variable Noise and Dimensionality Reduction for Sparse Gaussian Processes},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {The sparse pseudo-input Gaussian process (SPGP) is a new approximation method for speeding up GP regression in the case of a large number of data points N. The approximation is controlled by the gradient optimization of a small set of M 'pseudo-inputs', thereby reducing complexity from O(N3) to O(M2N). One limitation of the SPGP is that this optimization space becomes impractically big for high dimensional data sets. This paper addresses this limitation by performing automatic dimensionality reduction. A projection of the input space to a low dimensional space is learned in a supervised manner, alongside the pseudo-inputs, which now live in this reduced space. The paper also investigates the suitability of the SPGP for modeling data with input-dependent noise. A further extension of the model is made to make it even more powerful in this regard - we learn an uncertainty parameter for each pseudo-input. The combination of sparsity, reduced dimension, and input-dependent noise makes it possible to apply GPs to much larger and more complex data sets than was previously practical. We demonstrate the benefits of these methods on several synthetic and real world problems.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {461–468},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020476,
author = {Stavens, David and Thrun, Sebastian},
title = {A Self-Supervised Terrain Roughness Estimator for off-Road Autonomous Driving},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Accurate perception is a principal challenge of autonomous off-road driving. Perceptive technologies generally focus on obstacle avoidance. However, at high speed, terrain roughness is also important to control shock the vehicle experiences. The accuracy required to detect rough terrain is significantly greater than that necessary for obstacle avoidance.We present a self-supervised machine learning approach for estimating terrain roughness from laser range data. Our approach compares sets of nearby surface points acquired with a laser. This comparison is challenging due to uncertainty. For example, at range, laser readings may be so sparse that significant information about the surface is missing. Also, a high degree of precision is required when projecting laser readings. This precision may be unavailable due to latency or error in pose estimation. We model these sources of error as a multivariate polynomial. The coefficients of this polynomial are obtained through a self-supervised learning process. The "labels" of terrain roughness are automatically generated from actual shock, measured when driving over the target terrain. In this way, the approach provides its own training labels. It "transfers" the ability to measure terrain roughness from the vehicle's inertial sensors to its range sensors. Thus, the vehicle can slow before hitting rough terrain.Our experiments use data from the 2005 DARPA Grand Challenge. We find our approach is substantially more effective at identifying rough surfaces and assuring vehicle safety than previous methods - often by as much as 50%.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {469–476},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020477,
author = {Steck, Harald},
title = {Ranking by Dependence—a Fair Criteria},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Estimating the dependences between random variables, and ranking them accordingly, is a prevalent problem in machine learning. Pursuing frequentist and information-theoretic approaches, we first show that the p-value and the mutual information can fail even in simplistic situations. We then propose two conditions for regularizing an estimator of dependence, which leads to a simple yet effective new measure. We discuss its advantages and compare it to well-established model-selection criteria. Apart from that, we derive a simple constraint for regularizing parameter estimates in a graphical model. This results in an analytical approximation for the optimal value of the equivalent sample size, which agrees very well with the more involved Bayesian approach in our experiments.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {477–484},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020478,
author = {Strehl, Alexander L. and Li, Lihong and Littman, Michael L.},
title = {Incremental Model-Based Learners with Formal Learning-Time Guarantees},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Model-based learning algorithms have been shown to use experience efficiently when learning to solve Markov Decision Processes (MDPs) with finite state and action spaces. However, their high computational cost due to repeatedly solving an internal model inhibits their use in large-scale problems. We propose a method based on real-time dynamic programming (RTDP) to speed up two model-based algorithms, RMAX and MBIE (model-based interval estimation), resulting in computationally much faster algorithms with little loss compared to existing bounds. Specifically, our two new learning algorithms, RTDP-RMAX and RTDP-IE, have considerably smaller computational demands than RMAX and MBIE. We develop a general theoretical framework that allows us to prove that both are efficient learners in a PAC (probably approximately correct) sense. We also present an experimental evaluation of these new algorithms that helps quantify the tradeoff between computational and experience demands.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {485–493},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020479,
author = {Subramanya, Amarnag and Raj, Alvin and Bilmes, Jeff and Fox, Dieter},
title = {Recognizing Activities and Spatial Context Using Wearable Sensors},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We introduce a new dynamic model with the capability of recognizing both activities that an individual is performing as well as where that individual is located. Our approach is novel in that it utilizes a dynamic graphical model to jointly estimate both activity and spatial context over time based on the simultaneous use of asynchronous observations consisting of GPS measurements, and a small mountable sensor board. Joint inference is quite desirable as it has the ability to improve accuracy of the model and consistency of the location and activity estimates. The parameters of our model are trained on partially labeled data. We apply virtual evidence to improve data annotation, giving the user high flexibility when labeling training data. We present results indicating the performance gains achieved by virtual evidence for data annotation and the joint inference performed by our system.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {494–502},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020480,
author = {Warmuth, Manfred K. and Kuzmin, Dima},
title = {A Bayesian Probability Calculus for Density Matrices},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {One of the main concepts in quantum physics is a density matrix, which is a symmetric positive definite matrix of trace one. Finite probability distributions can be seen as a special case when the density matrix is restricted to be diagonal.We develop a probability calculus based on these more general distributions that includes definitions of joints, conditionals and formulas that relate these, including analogs of the Theorem of Total Probability and various Bayes rules for the calculation of posterior density matrices. The resulting calculus parallels the familiar "conventional" probability calculus and always retains the latter as a special case when all matrices are diagonal.Whereas the conventional Bayesian methods maintain uncertainty about which model has the highest data likelihood, the generalization maintains uncertainty about which unit direction has the largest variance. Surprisingly the bounds also generalize: as in the conventional setting we upper bound the negative log likelihood of the data by the negative log likelihood of the MAP estimator.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {503–511},
numpages = {9},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020481,
author = {Welling, Max and Parise, Sridevi},
title = {Bayesian Random Fields: The Bethe-Laplace Approximation},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {While learning the maximum likelihood value of parameters of an undirected graphical model is hard, modelling the posterior distribution over parameters given data is harder. Yet, undirected models are ubiquitous in computer vision and text modelling (e.g. conditional random fields). But where Bayesian approaches for directed models have been very successful, a proper Bayesian treatment of undirected models in still in its infant stages. We propose a new method for approximating the posterior of the parameters given data based on the Laplace approximation. This approximation requires the computation of the covariance matrix over features which we compute using the linear response approximation based in turn on loopy belief propagation. We develop the theory for conditional and "unconditional" random fields with or without hidden variables. In the conditional setting we introduce a new variant of bagging suitable for structured domains. Here we run the loopy max-product algorithm on a "super-graph" composed of graphs for individual models sampled from the posterior and connected by constraints. Experiments on real world data validate the proposed methods.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {512–519},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020482,
author = {Weng, Paul},
title = {Axiomatic Foundations for a Class of Generalized Expected Utility: Algebraic Expected Utility},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we provide two axiomatizations of algebraic expected utility, which is a particular generalized expected utility, in a von Neumann-Morgenstern setting, i.e. uncertainty representation is supposed to be given and here to be described by a plausibility measure valued on a semiring, which could be partially ordered. We show that axioms identical to those for expected utility entail that preferences are represented by an algebraic expected utility. This algebraic approach allows many previous propositions (expected utility, binary possibilistic utility,...) to be unified in a same general framework and proves that the obtained utility enjoys the same nice features as expected utility: linearity, dynamic consistency, autoduality of the underlying uncertainty representation, autoduality of the decision criterion and possibility of modeling decision maker's attitude toward uncertainty.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {520–527},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020483,
author = {Wiegerinck, Wim and van den Broek, Bart and Kappen, Bert},
title = {Stochastic Optimal Control in Continuous Space-Time Multi-Agent Systems},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Recently, a theory for stochastic optimal control in non-linear dynamical systems in continuous space-time has been developed (Kappen, 2005). We apply this theory to collaborative multi-agent systems. The agents evolve according to a given non-linear dynamics with additive Wiener noise. Each agent can control its own dynamics. The goal is to minimize the accumulated joint cost, which consists of a state dependent term and a term that is quadratic in the control. We focus on systems of non-interacting agents that have to distribute themselves optimally over a number of targets, given a set of end-costs for the different possible agent-target combinations. We show that optimal control is the combinatorial sum of independent single-agent single-target optimal controls weighted by a factor proportional to the end-costs of the different combinations. Thus, multi-agent control is related to a standard graphical model inference problem. The additional computational cost compared to single-agent control is exponential in the tree-width of the graph specifying the combinatorial sum times the number of targets. We illustrate the result by simulations of systems with up to 42 agents.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {528–535},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020484,
author = {Wood, Frank and Griffiths, Thomas L. and Ghahramani, Zoubin},
title = {A Non-Parametric Bayesian Method for Inferring Hidden Causes},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We present a non-parametric Bayesian approach to structure learning with hidden causes. Previous Bayesian treatments of this problem define a prior over the number of hidden causes and use algorithms such as reversible jump Markov chain Monte Carlo to move between solutions. In contrast, we assume that the number of hidden causes is unbounded, but only a finite number influence observable variables. This makes it possible to use a Gibbs sampler to approximate the distribution over causal structures. We evaluate the performance of both approaches in discovering hidden causes in simulated data, and use our non-parametric approach to discover hidden causes in a real medical dataset.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {536–543},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020485,
author = {Xu, Zhao and Tresp, Volker and Yu, Kai and Kriegel, Hans-Peter},
title = {Infinite Hidden Relational Models},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Relational learning analyzes the probabilistic constraints between the attributes of entities and relationships. We extend the expressiveness of relational models by introducing for each entity (or object) an infinite-dimensional latent variable as part of a Dirichlet process (DP) mixture model. We discuss inference in the model, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant process. We extended the Chinese restaurant process to be applicable to relational modeling. We discuss how information is propagated in the network of latent variables, reducing the necessity for extensive structural learning. In the context of a recommendation engine our approach realizes a principled solution for recommendations based on features of items, features of users and relational information. Our approach is evaluated in three applications: a recommendation system based on the Movie-Lens data set, the prediction of gene function using relational information and a medical recommendation system.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {544–551},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020486,
author = {Zhang, Zhihua and Jordan, Michael I.},
title = {Bayesian Multicategory Support Vector Machines},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {We show that the multi-class support vector machine (MSVM) proposed by Lee et al. (2004) can be viewed as a MAP estimation procedure under an appropriate probabilistic interpretation of the classifier. We also show that this interpretation can be extended to a hierarchical Bayesian architecture and to a fully-Bayesian inference procedure for multi-class classification based on data augmentation. We present empirical results that show that the advantages of the Bayesian formalism are obtained without a loss in classification accuracy.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {552–559},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

@inproceedings{10.5555/3020419.3020487,
author = {Zuk, Or and Margel, Shiri and Domany, Eytan},
title = {On the Number of Samples Needed to Learn the Correct Structure of a Bayesian Network},
year = {2006},
isbn = {0974903922},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Bayesian Networks (BNs) are useful tools giving a natural and compact representation of joint probability distributions. In many applications one needs to learn a Bayesian Network (BN) from data. In this context, it is important to understand the number of samples needed in order to guarantee a successful learning. Previous works have studied BNs sample complexity, yet they mainly focused on the requirement that the learned distribution will be close to the original distribution which generated the data. In this work, we study a different aspect of the learning task, namely the number of samples needed in order to learn the correct structure of the network. We give both asymptotic results (lower and upper-bounds) on the probability of learning a wrong structure, valid in the large sample limit, and experimental results, demonstrating the learning behavior for feasible sample sizes.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {560–567},
numpages = {8},
location = {Cambridge, MA, USA},
series = {UAI'06}
}

