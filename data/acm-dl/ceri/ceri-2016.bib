@inproceedings{10.1145/2934732.2940298,
author = {Gonzalo, Julio},
title = {Monitoring Reputation in the Wild Online West},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2940298},
doi = {10.1145/2934732.2940298},
abstract = {Monitoring Online Reputation has already become a key part of Public Relations for organizations and individuals; and current search technologies do not suffice to help reputation experts to cope with the vast stream of online content relevant to their clients. One of the reasons is that the amount of relevant content for medium and large companies and typical public figures is too large to be handled manually, but too small to be handled with the statistical techniques that are typically effective at Web scale.In the talk we will overview some of the main challenges that Information Access Technologies must face to assist online reputation experts in their monitoring tasks, and present some of the results obtained by the UNED research group in the areas of:• Entity Name Disambiguation: in order to track online content mentioning an entity (companies, organizations, brands, individuals, etc.), recall is essential and queries are, as a consequence, short and potentially ambiguous (consider company names such as Blackberry, Orange or Apple). Automatic filtering of irrelevant content is a crucial preliminary step to perform a reputational analysis of online content.• Topic Tracking for Reputation Analysis: Once the stream of relevant content mentioning the entity of interest is isolated, experts need to identify conversations, i.e., issues related to the client that may have an effect on their reputation. These are usually fine-grained topics with a large variability in terms of size, and they are not trivial to detect with conventional techniques.• Alert detection and Reputational priority: One of the main challenges of reputation monitoring is detecting issues before they explode and become serious Public Relations problems. A necessary step is determining, for new topics, what is their priority from a reputational point of view, and which should be treated immediately (reputation alerts).• Identification and Profiling of Opinion Makers: a key issue for effective alert detection is listening to opinion makers, i.e. people with audience and perceived authority whose opinion influences the state of public opinion. While offline authorities and opinion makers are usually a few, easy to identify individuals, in online media detecting opinion makers is a challenging task.• Automatic Generation of Reputation Reports (Reputation-Oriented Summarization): Ideally, an automatic reputation monitoring system would be able to fulfill all the above tasks, and synthesize the analysis in a summary (a reputation report). We will discuss how to build such a summary from a computational point of view, and how it differs from conventional summarization tasks.In the talk we will make a special emphasis on the features of the Replab test collections for Online Reputation Monitoring, which provide over half a million manual annotations provided by reputation experts on Twitter data, and are the basis of UNED experiments in the field.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {1},
numpages = {1},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2940297,
author = {Oliver, Nuria},
title = {Data-Driven Human Behavior Models: Opportunities and Challenges},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2940297},
doi = {10.1145/2934732.2940297},
abstract = {We live in a world of data, of big data, a big part of which has been generated by humans through their interactions with both the physical and digital world. A key element in the exponential growth of human behavioral data is the mobile phone. There are more mobile phones in the world as humans which has turned the mobile phone into the piece of technology with the highest levels of adoption in human history. We carry them with us all through the day (and night, in many cases), leaving digital traces of our physical interactions. Mobile phones have become sensors of human activity both in the large scale and also as the most personal devices.In my talk, I present some of the work that we are doing at Telefonica Research in the area of modeling humans from human behavioral data collected from mobile phones. The data may be data that is automatically collected by the mobile network infrastructure --in particular Call Detail Records or CDRs---or data that is collected by an experimental mobile application through a user study. All projects entail data analytics and machine learning in order to build accurate models of individual or aggregate behavior.In particular, I describe four projects: (1) a project to automatically infer personality from Call Detail Records [1]; (2) MobiScore, a project to automatically assess a credit score from Call Detail Records [2]; Borapp, a mobile app that is able to detect boredom from patterns of phone usage [3] and a project to automatically predict crime hotspots in a city from human dynamics and demographic data [4].I conclude by highlighting opportunities and challenges associated with building data-driven models of human behavior.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {2},
numpages = {1},
keywords = {Computational Social Sciences, Data-driven Human Behavior Modeling, Machine Learning, Artificial Intelligence},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934734,
author = {Losada, David E. and Parapar, Javier},
title = {Injecting Multiple Psychological Features into Standard Text Summarisers},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934734},
doi = {10.1145/2934732.2934734},
abstract = {Automatic Text Summarisation is an essential technology to cope with the overwhelming amount of documents that are daily generated. Given an information source, such as a webpage or a news article, text summarisation consists of extracting content from it and present it in a condensed form for human consumption. Summaries are crucial to facilitate information access. The reader is provided with the key information in a concise and fluent way. This speeds up navigation through large repositories of data. With the rapid growth of online contents, creating manual summaries is not an option. Extractive summarisation methods are based on selecting the most important sentences from the input. To meet this aim, a ranking of candidate sentences is often built from a reduced set of sentence features. In this paper, we show that that many features derived from psychological studies are valuable for constructing extractive summaries. These features encode psychological aspects of communication and are a good guidance for selecting salient sentences. We use Quantitative Text Analysis tools for extracting these features and inject them into state-of-the-art extractive summarisers. Incorporating these novel components into existing extractive summarisers requires to combine and weight a high number of sentence features. In this respect, we show that Particle Swarm Optimisation is a viable approach to set the feature's weights. Following standard evaluation practice (DUC benchmarks), we also demonstrate that our novel summarisers are highly competitive.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {3},
numpages = {8},
keywords = {LIWC, Summarisation, PSO, psychological features},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934735,
author = {Iglesias-Franjo, Est\'{\i}baliz and Vilares, Jes\'{u}s},
title = {Any Papyrus about "a Hand over a Stool and a Bread Loaf, Followed by a Boat"? Dealing with Hieroglyphic Texts in IR},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934735},
doi = {10.1145/2934732.2934735},
abstract = {Digital Heritage deals with the use of computing and information technologies for the preservation and study of the human cultural legacy. Within this context, we present here a Text Retrieval system developed specifically to work with Egyptian hieroglyphic texts for its use by Egyptologists and Linguists in the study and preservation of Ancient Egyptian scripts. We intend to make it freely available to the Egyptology research community. To the best of our knowledge this is the first tool of its kind.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {4},
numpages = {8},
keywords = {digital heritage, manuel de codage, egyptology, Text retrieval, egyptian hieroglyphs},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934733,
author = {Mosbah, Mawloud and Boucheham, Bachir},
title = {Improving the Performance of Color-Based Signatures through Dynamic Selection of Adequate CCV-Threshold},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934733},
doi = {10.1145/2934732.2934733},
abstract = {Color Coherence Vector (CCV) is an indexing method derived from histograms signature that attempts to integrate spatial information in these structures. Owing to its remarkable importance, many recent works have addressed CCV signature and some early indexing methods have been inspired from it. An essential issue with CCV is how to set the threshold value allowing distinction between coherent and non-coherent regions. Usually, this threshold, whose value has dramatic impact on CBIR performances, is set statically by the developer of the CBIR system. In this paper, we focus on the CCV threshold value through proposing two algorithms setting it dynamically according to the image query. The first algorithm belongs to the soft computing and relies on features fusion mechanism. The second one belongs to the cloud computing paradigm and relies on Google Image Engine. The two proposed algorithms belong to the pseudo relevance feedback approach that does not require any user assistance. The experiments conducted on the Wang database (COREL-1K) reveals that the proposed algorithms yield very promising results where they enhance CCV performances with fixed threshold and they are efficient compared to the features Fusion mechanism when considering the indexing time.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {5},
numpages = {4},
keywords = {CBIR, Recall, CCV, Precision, Dynamic Threshold},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934746,
author = {Fern\'{a}ndez, Diego and da Silva, Xacobe Mac\'{\i}a and N\'{o}voa, Francisco J. and Cacheda, Fidel and Carneiro, V\'{\i}ctor},
title = {Using Collaborative Filtering in a New Domain: Traffic Analysis},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934746},
doi = {10.1145/2934732.2934746},
abstract = {The importance of information systems is increasing every day. In order to ensure their right operation, it is necessary to analyze a huge amount of traffic generated by different devices. However, classical techniques for operation and management are reactive and not proactive, what can evolve in a failure in the system.In this work we propose a new approach where we analyze network traffic using Collaborative Filtering. In other domains, these systems have proved to filter thousands of items according to user needs and tastes. They can predict user preferences and recommend relevant items for the user. In this sense, in this new domain, relevant items are data flows, so our goal is to recommend flows which are related to the traffic already captured.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {6},
numpages = {8},
keywords = {Recommender Systems, OCCF, unary ratings, Collaborative Filtering, IDS, Computer Networks, network flows},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934742,
author = {Ezpeleta, Enaitz and Zurutuza, Urko and Hidalgo, Jos\'{e} Mar\'{\i}a G\'{o}mez},
title = {Short Messages Spam Filtering Using Personality Recognition},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934742},
doi = {10.1145/2934732.2934742},
abstract = {In this era of smartphones and online social networks, short messages communications tools are growing up, attracting spam and non-legitimate campaigns. Those campaigns, besides being an illegal online activities, are a direct threat to the privacy of the users. Previous short messages spam filtering techniques focus on automatic text classification and while none of them take message personality feature into account. Focusing on phone Short Message Service (SMS) messages, this work demonstrates that it is possible to improve spam filtering in short message services using personality recognition techniques. Using a publicly available labelled (spam/legitimate) SMS dataset, we apply personality recognition techniques to each message and aggregate the personality feature to the original dataset, creating a new one. We compare the results of the best classifiers and filters over the different datasets (with and without personality) in order to demonstrate the influence of the personality. Experiments show that personality feature helps to improve SMS spam filtering improving both the accuracy, reaching to a 98.94%, and the false positive rates.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {7},
numpages = {7},
keywords = {Spam, Personality, SMS},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934747,
author = {S\'{a}nchez, Pablo and Bellog\'{\i}n, Alejandro and Cantador, Iv\'{a}n},
title = {Studying the Effect of Data Structures on the Efficiency of Collaborative Filtering Systems},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934747},
doi = {10.1145/2934732.2934747},
abstract = {Recommender systems is an active research area where the major focus has been on how to improve the quality of generated recommendations, but less attention has been paid on how to do it in an efficient way. This aspect is increasingly important because the information to be considered by recommender systems is growing exponentially. In this paper we study how different data structures affect the performance of these systems. Our results with two public datasets provide relevant insights regarding the optimal data structures in terms of memory and time usages. Specifically, we show that classical data structures like Binary Search Trees and Red-Black Trees can beat more complex and popular alternatives like Hash Tables.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {8},
numpages = {4},
keywords = {Efficiency, Collaborative Filtering, Data Structures},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934737,
author = {Valcarce, Daniel and Parapar, Javier and Barreiro, \'{A}lvaro},
title = {Additive Smoothing for Relevance-Based Language Modelling of Recommender Systems},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934737},
doi = {10.1145/2934732.2934737},
abstract = {The use of Relevance-Based Language Models for top-N recommendation has become a promising line of research. Previous works have used collection-based smoothing methods for this task. However, a recent analysis on RM1 (an estimation of Relevance-Based Language Models) in document retrieval showed that this type of smoothing methods demote the IDF effect in pseudo-relevance feedback. In this paper, we claim that the IDF effect from retrieval is closely related to the concept of novelty in recommendation. We perform an axiomatic analysis of the IDF effect on RM2 concluding that this kind of smoothing methods also demotes the IDF effect in recommendation. By axiomatic analysis, we find that a collection-agnostic method, Additive smoothing, does not demote this property. Our experiments confirm that this alternative improves the accuracy, novelty and diversity figures of the recommendations.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {9},
numpages = {8},
keywords = {Relevance-Based Language Models, Recommender systems, collaborative filtering},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934740,
author = {de Campos, Luis M. and Fern\'{a}ndez-Luna, Juan M. and Huete, Juan F.},
title = {Comparing Monolithic and Committee-Based Profiles for Politician Recommendation},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934740},
doi = {10.1145/2934732.2934740},
abstract = {In a parliamentary setting, citizen could be interested in knowing those Members of Parliament (MPs) who are working in different areas or involved in the resolution of some people's problems. These topics of interest are usually represented by means of a profile. In this paper, the politicians' profiles are built considering the speeches in parliamentary sessions. However, in most of the cases a single profile is not the best alternative to represent MPs' interests because the specific terms related to a given topic are mixed with others, so that the MPs' preferences are diluted. The alternative is to build different subprofiles containing each one the most representative keywords for each topic, creating in this way a richer representation. We present a first approach to build subprofiles based on the MPs' speeches in different committee and plenary sessions, which will be compared, in terms of performance, to monolithic profiles for an MP content-based recommendation task.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {10},
numpages = {8},
keywords = {Members of Parliaments, Profiles, Subprofiles, Information Retrieval, Content-based Recommendation},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934745,
author = {Tomeo, Paolo and Fern\'{a}ndez-Tob\'{\i}as, Ignacio and Di Noia, Tommaso and Cantador, Iv\'{a}n},
title = {Exploiting Linked Open Data in Cold-Start Recommendations with Positive-Only Feedback},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934745},
doi = {10.1145/2934732.2934745},
abstract = {In recommender systems, user preferences can be acquired either explicitly by means of ratings, or implicitly --e.g., by processing text reviews, and by mining item browsing and purchasing records. Most existing collaborative filtering approaches have been designed to deal with numerical ratings, such as the 5-star ratings in Amazon and Netflix, for both rating prediction and item ranking (a.k.a. top-N recommendation) tasks. In many e-commerce and social network sites, however, user preferences are usually expressed in the form of binary and unary (positive-only) ratings, such as the thumbs up/down in YouTube and the likes in Facebook, respectively. Moreover, in these cases, the well-known problem of cold-start --i.e., the scarcity of user preferences-- is highly remarkable. To address this situation, we explore a number of graph-based and matrix factorization recommendation models that jointly exploit user ratings and item metadata. In this work, such metadata are automatically obtained from DBpedia --the queriable and structured version of Wikipedia which is considered as the core knowledge repository of the Linked Open Data initiative--, and the models are evaluated with a Facebook dataset covering three distinct domains, namely books, movies and music. The results achieved in our experiments show that the proposed hybrid recommendation models, which exploit rating and semantic data, outperform content-based and collaborative filtering baselines.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {11},
numpages = {8},
keywords = {DBpedia, Facebook, Recommender systems, hybrid recommendation, cold-start, positive-only feedback, Linked Data},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934736,
author = {Pamp\'{\i}n, Humberto Jes\'{u}s Corona and Peleteiro, Ana},
title = {A Time-Aware Exploration of RecSys15 Challenge Dataset},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934736},
doi = {10.1145/2934732.2934736},
abstract = {E-commerce is currently one of the main applications of recommender systems, since it generates vast amounts of data that can be used to make predictions and analyse users's behaviour. In this paper we present an overview of the public dataset used for the RecSys Challenge 2015. We describe the basic statistical properties of this dataset and how events (clicks and purchases) are distributed over products (items) and users (sessions). We also present a time-aware analysis of the dataset, with the aim to better understand the change of user behaviour within time cycles, and how it affects the activity in user purchases. We further study the relation between categories, the solely type of metadata present in this completely anonymised dataset. We are interested both in how these categories are distributed and how users and items interact with them. Finally, along the paper we explain the implications that the results obtained from our analysis may have when building models for the challenge.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {12},
numpages = {4},
keywords = {E-commerce, Recommender Systems, Dataset exploration},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934743,
author = {Menk, Alan and Sebasti\'{a}, Laura},
title = {Predicting the Human Curiosity from Users' Profiles on Facebook},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934743},
doi = {10.1145/2934732.2934743},
abstract = {Nowadays, social networks store a massive amount of data, which can say a lot about our personality. Given the ease to access the internet everywhere at any time, many people use social networks in daily life, reflecting in a certain way their behaviour from the "real world" to the "virtual world", by storing in social networks what they like, hate, feel, where they travel to, their relationships, opinions, etc. Once obtained the access to this data, some authors have tried to infer the personality of the individual without the use of long questionnaires, only working with data in an implicit way, that is, transparently to user. In this scenario, our work is focused on predicting just one of the human personality traits, the Curiosity. In this paper, we analyse the information that can be extracted from the users' profile on Facebook and the set of features that can be used to describe their degree of curiosity. Finally, we generate a prediction model in the form of a decision tree.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {13},
numpages = {8},
keywords = {Social Network, Data Mining, Personality, Curiosity},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934744,
author = {Claude, Francisco and Konow, Roberto and Ladra, Susana},
title = {Fast Compressed-Based Strategies for Author Profiling of Social Media Texts},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934744},
doi = {10.1145/2934732.2934744},
abstract = {Given a text, it may be useful to determine the age, gender, native language, nationality, personality and other demographic attributes of its author. This task is called author profiling, and has been studied by different areas, especially from linguistics and natural language processing, by extracting different content- and style-based features from training documents and then using various machine learning approaches.In this paper we address the author profiling task by using several compression-inspired strategies. More specifically, we generate different models to identify the age and the gender of the author of a given document without analysing or extracting specific features from the textual content, making them style-oblivious approaches.We compare and analyse their behaviour over datasets of different nature. Our results show that by using simple compression-inspired techniques we are able to obtain very competitive results in terms of accuracy and we are orders of magnitude faster for the evaluation phase when compared to other state-of-the-art complex and resource-demanding techniques.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {14},
numpages = {6},
keywords = {compression-based classification, author profiling, age and gender prediction, entropy},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934748,
author = {Tramullas, Jes\'{u}s and Garrido-Picazo, Piedad and S\'{a}nchez-Casab\'{o}n, Ana I.},
title = {Research on Wikipedia Vandalism: A Brief Literature Review},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934748},
doi = {10.1145/2934732.2934748},
abstract = {Research on vandalism in Wikipedia has been of interest for the last decade. This paper performs a literature review on the subject, with the goal of identifying the main research topics and approaches, methods and techniques used. 67 papers have been reviewed. Results showed that the authorship of three-quarters of papers are from Computer Science researchers. Other identified authors come from Humanities and Social Sciences, and Education. Main topic is the detection of vandalism, although there is a increasing interest about content quality. The most commonly used technique is machine learning, based on feature analysis. It draws attention to the lack of research on information behavior of vandals.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {15},
numpages = {4},
keywords = {vandalism, Wikipedia, literature review},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934738,
author = {Flores, Enrique and Moreno, Lidia and Rosso, Paolo},
title = {Detecting Source Code Re-Use with Ensemble Models},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934738},
doi = {10.1145/2934732.2934738},
abstract = {Source code re-use has been usually faced from a compiler perspective. Considering the source code as a piece of text, we are able to use natural language techniques for the detection of source code re-use. This paper describes the use of ensemble models in the task of source code re-use detection. Ensembles of Information Retrieval (IR) models are constructed using common classifiers. The IR-inspired models are compared with the ensembles in C and Java programming languages. The use of ensemble classifiers shows promising results for detecting source code re-use.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {16},
numpages = {7},
keywords = {re-use detection, source code re-use retrieval, source code re-use, ensemble classifiers},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934739,
author = {Moreno, Valent\'{\i}n and G\'{e}nova, Gonzalo and Alejandres, Manuela and Fraga, Anabel},
title = {Automatic Classification of Web Images as UML Diagrams},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934739},
doi = {10.1145/2934732.2934739},
abstract = {Our purpose in this research is to develop a methodology to automatically and efficiently classify web images as UML static diagrams, and to produce a computer tool that implements this function. The tool receives as input a bitmap file (in different formats) and tells whether the image corresponds to a diagram. The tool does not require that the images are explicitly or implicitly tagged as UML diagrams. The tool extracts graphical characteristics from each image (such as grayscale histogram, color histogram and elementary geometric forms) and uses a combination of rules to classify it. The rules are obtained with machine learning techniques (rule induction) from a sample of 19000 web images manually classified by experts. In this work we do not consider the textual contents of the images.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {17},
numpages = {8},
keywords = {UML diagram recognition, Rule induction, Image processing},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934741,
author = {Reyes-Alvarez, Liudmila and Fern\'{a}ndez, Jaime and Rodr\'{\i}guez-Mu\~{n}iz, Luis J. and D\'{\i}az, Irene},
title = {Ontological Models for Information Retrieval of Product-Service: Trends and Open Issues},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934741},
doi = {10.1145/2934732.2934741},
abstract = {More and more companies need a model for product-service information retrieval. All businesses agree on the need of a common vocabulary among customers, commercial partners and suppliers. Building ontologies as models of knowledge representation about product-service information is increasingly seen as a key to enable interoperability between software agents and people on the Web or through to network connections. In addition, in recent years it has strengthened the alliance between industry and scientific research communities. The development of ontology-based smart catalogs captures their attention. This work surveys ontological models for information retrieval on product-service in the industry. Research trends previously addressed and open issues are discussed. Besides, some of the solutions on functionality and behavior of ontologies-based product-service are presented as an alternative to achieve an optimal level during information retrieval using smart catalogs in business scenarios.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {18},
numpages = {10},
keywords = {Ontology, Product-Service, Business sceneries, Functionality and behavior, Ontological models},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934749,
author = {Vitelli, Maria Carmela and D\'{\i}az, Irene and Troiano, Luigi},
title = {A Method to Generate Equiprobale Runs in TFPG Models},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934749},
doi = {10.1145/2934732.2934749},
abstract = {FDIR functionalities play a key role in several fields and a lot of techniques and methods have been developed in order to make them possible. TFPG is a causal model that captures the temporal aspects of failure propagation in a wide variety of engineering systems. As other sources of information, they require to be stored and retrieved. A key to index and query a TFPG documental base is in the sequence of events, i.e. runs, they are able to model. In this paper we propose a method to produce equiprobable runs of the TFPG model that can be used as support to index generation.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {19},
numpages = {7},
keywords = {Linear Extensions, FDIR},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934751,
author = {Blank, Daniel and Henrich, Andreas},
title = {Assessing Interestingness and Importance of Information Retrieval Course Topics in a Course for Three Different Target Groups},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934751},
doi = {10.1145/2934732.2934751},
abstract = {Teaching an information retrieval (IR) course for three different target groups is challenging. These target groups are i) resident students at the University of Bamberg, Germany ii) remote full-time students from other Bavarian universities, and iii) remote but part-time students from all parts of Germany which usually study the course besides their day-to-day work relationship. As a consequence, we have participants with heterogeneous previous knowledge and potentially different expectations with respect to the course content.In this paper we will only briefly describe the didactic aspects and challenges of the course. The clear focus of the paper lies on an in-depth quantitative evaluation how various IR topics presented in the lectures and tutorials fit the needs of the different target groups. We evaluate interestingness and importance of the course topics according to the students' impressions. The goal of the evaluation is to get hints for future refinements of IR course content---in general but also with respect to the needs of different target groups.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {20},
numpages = {8},
keywords = {Distance Learning, Teaching Information Retrieval, Evaluation of Course Content},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934750,
author = {Johnson, Frances},
title = {Evaluating Usability: A Two-Fold Assessment},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934750},
doi = {10.1145/2934732.2934750},
abstract = {This paper presents the progressive application of methods used in usability assessment to a single system, Searchit, a meta-search engine used by some academic libraries in the UK to allow a search across a range of databases as well as in the library's own collection. Students studying on a course in Information Retrieval Systems at Manchester Metropolitan University assessed its usability using methods of heuristic based inspections, cognitive walkthrough and in the collection of behavioural data from a user study. Both the value and the limitations of these methods are exemplified in the resulting demonstration of what can be learnt about the usability of Searchit, and what can be learnt about the information searching and the users of the system. The exercise accomplishes a two-fold assessment, of the system usability and of the activity of information search. The students acquire skills in employing usability methods and the opportunity to learn about the search activities the retrieval system is designed to support.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {21},
numpages = {7},
keywords = {user experience, evaluation, information retrieval, Usability},
location = {Granada, Spain},
series = {CERI '16}
}

@inproceedings{10.1145/2934732.2934752,
author = {MacFarlane, Andrew and Russell-Rose, Tony},
title = {Search Strategy Formulation: A Framework For Learning},
year = {2016},
isbn = {9781450341417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934732.2934752},
doi = {10.1145/2934732.2934752},
abstract = {Healthcare information professionals perform systematic literature reviews to gather the evidence needed to answer specific research questions and formulate policy. However, performing a systematic review is a resource-intensive and time consuming undertaking, often taking years to complete. Moreover, the output relies heavily on the quality of the initial search strategy in ensuring that the scope is sufficiently exhaustive and not biased by easily accessible studies. In this paper we introduce a structured methodology and a framework for learning which together aim to embody best practices from the community and provide support for many of the common issues in search strategy development.},
booktitle = {Proceedings of the 4th Spanish Conference on Information Retrieval},
articleno = {22},
numpages = {8},
keywords = {systematic reviews, Information retrieval, education, training},
location = {Granada, Spain},
series = {CERI '16}
}

