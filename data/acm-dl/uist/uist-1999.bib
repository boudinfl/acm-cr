@inproceedings{10.1145/320719.322577,
author = {Smith, Randall B. and Taivalsaari, Antero},
title = {Generalized and Stationary Scrolling},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322577},
doi = {10.1145/320719.322577},
abstract = {We present a generalized definition of scrolling that unifies a wide range of existing interaction techniques, from conventional scrolling through pan and zoom systems and fish-eye views. Furthermore it suggests a useful class of new scrolling techniques in which objects do not move across the display. These “stationary scrolling” techniques do not exhibit either of two problems that plague spatial scrolling system: discontinuity in salience and the undermining of the user's spatial memory.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {1–9},
numpages = {9},
keywords = {scrolling, window management, portable devices},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322578,
author = {Perlin, Ken and Meyer, Jon},
title = {Nested User Interface Components},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322578},
doi = {10.1145/320719.322578},
abstract = {Nested User Interface Components combine the concepts of Zooming User Interfaces (ZUIs) with recursive nesting of active graphical user interface widgets. The resulting system of recursively nesting interface components has a number of desirable properties. The level of detail of the view of any widget component and its children, as well as the responsiveness of that component to the user's actions, can be tuned to the current visible size of that component on the screen.We distinguish between the interaction style of a component, and the semantic result that it produces. Only the latter is used to determine the geographic parameters for that component. In this way, very large and layered control problems can be presented to the user as a cohesive and readily navigable visual surface. It becomes straightforward to layout interaction semantics that are best handled by recursion, such as filters composed of nested expressions.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {11–18},
numpages = {8},
keywords = {control hierarchies, widgets, nested interfaces, zooming user interfaces, property editing},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322579,
author = {Vronay, David and Smith, Marc and Drucker, Steven},
title = {Alternative Interfaces for Chat},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322579},
doi = {10.1145/320719.322579},
abstract = {We describe some common problems experienced by users of computer-based text chat, and show how many of these problems relate to the loss of timing-specific information. We suggest that thinking of chat as a real-time streaming media data type, with status and channel indicators, might solve some of these problems. We then present a number of alternative chat interfaces along with results from user studies comparing and contrasting them both with each other and with the standard chat interface. These studies show some potential, but indicate that more work needs to be done.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {19–26},
numpages = {8},
keywords = {visualization, streaming media, time-based media, chat, computer-mediated communication},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322580,
author = {Fraser, Mike and Benford, Steve and Hindmarsh, Jon and Heath, Christian},
title = {Supporting Awareness and Interaction through Collaborative Virtual Interfaces},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322580},
doi = {10.1145/320719.322580},
abstract = {This paper explores interfaces to virtual environments supporting multiple users. An interface to an environment allowing interaction with virtual artefacts is constructed, drawing on previous proposals for 'desktop' virtual environments. These include the use of Peripheral Lenses to support peripheral awareness in collaboration; and extending the ways in which users' actions are represented for each other. Through a qualitative analysis of a design task, the effect of the proposals is outlined. Observations indicate that, whilst these designs go some way to re-constructing physical co-presence in terms of awareness and interaction through the environment, some issues remain. Notably, peripheral distortion in supporting awareness may cause problematic interactions with and through the virtual world; and extended representations of actions may still allow problems in re-assembling the composition of others' actions. We discuss the potential for: designing representations for distorted peripheral perception; and explicitly displaying the course of action in object-focused interaction.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {27–36},
numpages = {10},
keywords = {user presentation, peripheral lenses, collaborative virtual environments, action representation},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322581,
author = {Xiong, Rebecca and Donath, Judith},
title = {PeopleGarden: Creating Data Portraits for Users},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322581},
doi = {10.1145/320719.322581},
abstract = {Many on-line interaction environments have a large number of users. It is difficult for the participants, especially new ones, to form a clear mental image about those with whom they are interacting. How can we compactly convey information about these participants to each other? We propose the data portrait, a novel graphical representation of users based on their past interactions. Data portraits can inform users about each other and the overall social environment. We use a flower metaphor for creating individual data portraits, and a garden metaphor for combining these portraits to represent an on-line environment. We will review previous work in visualizing both individuals and groups. We will then describe our visualizations, explain how to create them, and show how they can be used to address user questions.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {37–44},
numpages = {8},
keywords = {data portraits, information visualization, interaction context, user-centered visualization},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322582,
author = {Rekimoto, Jun},
title = {Time-Machine Computing: A Time-Centric Approach for the Information Environment},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322582},
doi = {10.1145/320719.322582},
abstract = {This paper describes the concept of Time-Machine Computing (TMC), a time-centric approach to organizing information on computers. A system based on Time-Machine Computing allows a user to visit the past and the future states of computers. When a user needs to refer to a document that he/she was working on at some other time, he/she can travel in the time dimension and the system restores the computer state at that time. Since the user's activities on the system are automatically archived, the user's daily workspace is seamlessly integrated into the information archive. The combination of spatial information management of the desktop metaphor and time traveling allows a user to organize and archive information without being bothered by folder hierarchies or the file classification problems that are common in today's desktop environments. TMC also provides a mechanism for linking multiple applications and external information sources by exchanging time information. This paper describes the key features of TMC, a time-machine desktop environment called “TimeScape,” and several time-oriented application integration examples.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {45–54},
numpages = {10},
keywords = {desktop environment, time traveling, time-machine computing, inter-application communication, document management, information visualization},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322583,
author = {Dourish, Paul and Edwards, W. Keith and LaMarca, Anthony and Salisbury, Michael},
title = {Using Properties for Uniform Interaction in the Presto Document System},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322583},
doi = {10.1145/320719.322583},
abstract = {Most document or information management systems rely on hierarchies to organise documents (e.g. files, email messages or web bookmarks). However, the rigid structures of hierarchical schemes do not mesh well with the more fluid nature of everyday document practices. This paper describes Presto, a prototype system that allows users to organise their documents entirely in terms of the properties those documents hold for users. Properties provide a uniform mechanism for managing, coding, searching, retrieving and interacting with documents. We concentrate in particular on the challenges that property-based approaches present and the architecture we have developed to tackle them.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {55–64},
numpages = {10},
keywords = {document properties, document management, document interfaces, interaction models},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322584,
author = {Miller, Robert C. and Myers, Brad A.},
title = {Synchronizing Clipboards of Multiple Computers},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322584},
doi = {10.1145/320719.322584},
abstract = {This paper describes a new technique for transferring data between computers, the synchronized clipboard. Multiple computers can share a synchronized clipboard for all clipboard operations, so that data copied to the clipboard from one computer, using the standard Copy command, can be pasted directly on another computer using the standard Paste command. Synchronized clipboards are well-suited for a single user moving data among several computers in close proximity. We describe an implementation of synchronized clipboards that works across a wide range of existing systems, including 3Com PalmPilots, Microsoft Windows PCs, Unix workstations, and other Java-capable platforms. Our implementation adds no noticeable overhead to local copy and paste operations.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {65–66},
numpages = {2},
keywords = {data transfer, pick-and-drop, Java, distributed systems, file transfer, synchronized clipboard, network clipboard, ubiquitous computing, Pebbles, drag-and-drop},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322585,
author = {Moore, Darnell J. and Want, Roy and Harrison, Beverly L. and Gujar, Anuj and Fishkin, Ken},
title = {Implementing Phicons: Combining Computer Vision with Infrared Technology for Interactive Physical Icons},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322585},
doi = {10.1145/320719.322585},
abstract = {This paper describes a novel physical icon [3] (“phicon”) based system that can be programmed to issue a range of commands about what the user wishes to do with handdrawn whiteboard content. Through the phicon's UI, a command to process whiteboard context is issued using infrared signaling in combination with image processing and a ceiling-mounted camera system. We leverage camera systems that are already used for capturing whiteboard content [4] by further augmenting these systems to detect the presence and location of IR beacons within an image. An HDLC-based protocol and a built-in IR transmitter are used to send these signals.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {67–68},
numpages = {2},
keywords = {phicons, computer vision, ubiquitous computing, HDLC, infrared, physical UI, image processing, tangible user interfaces, physical icons},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322586,
author = {Mukai, Toshiro and Seki, Susumu and Nakazawa, Masayuki and Watanuki, Keiko and Miyoshi, Hideo},
title = {Multimodal Agent Interface Based on Dynamical Dialogue Model: MAICO: Multimodal Agent Interface for Communication},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322586},
doi = {10.1145/320719.322586},
abstract = {In this paper, we describe a multimodal interface prototype system based on Dynamical Dialogue Model. This system not only integrates information of speech and gestures, but also controls the response timing in order to realize a smooth interaction between user and computer. Our approach consists of human-human dialogue analysis, and computational modeling of dialogue.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {69–70},
numpages = {2},
keywords = {dynamics, back channels, multimodal interface, dynamical dialogue model, nonverbal information, response timing},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322587,
author = {Anderson, David and Frankel, James L. and Marks, Joe and Leigh, Darren and Sullivan, Eddie and Yedidia, Jonathan and Ryall, Kathy},
title = {Building Virtual Structures with Physical Blocks},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322587},
doi = {10.1145/320719.322587},
abstract = {We describe a tangible interface for building virtual structures using physical building blocks. We demonstrate two applications of our system. In one version, the blocks are used to construct geometric models of objects and structures for a popular game, Quake II™. In another version, buildings created with our blocks are rendered in different styles, using intelligent decoration of the building model.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {71–72},
numpages = {2},
keywords = {tangible user interfaces, transmedia},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322588,
author = {Badros, Greg J. and Borning, Alan and Marriott, Kim and Stuckey, Peter},
title = {Constraint Cascading Style Sheets for the Web},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322588},
doi = {10.1145/320719.322588},
abstract = {Cascading Style Sheets have been introduced by the W3C as a mechanism for controlling the appearance of HTML documents. In this paper, we demonstrate how constraints provide a powerful unifying formalism for declaratively understanding and specifying style sheets for web documents. With constraints we can naturally and declaratively specify complex behavior such as inheritance of properties and cascading of conflicting style rules. We give a detailed description of a constraint-based style sheet model, CCSS, which is compatible with virtually all of the CSS 2.0 specification. It allows more flexible specification of layout, and also allows the designer to provide multiple layouts that better meet the desires of the user and environmental restrictions. We also describe a prototype extension of the Amaya browser that demonstrates the feasibility of CCSS.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {73–82},
numpages = {10},
keywords = {constraints, CSS, Cassowary, page layout, HTML, style sheets, world wide web, cascading style sheets, CCSS},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322589,
author = {Vander Zanden, Bradley T. and Halterman, Richard L.},
title = {Reducing the Storage Requirements of Constraint Dataflow Graphs},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322589},
doi = {10.1145/320719.322589},
abstract = {Most one-way constraint solvers use directed dataflow graphs to represent the dependencies among variables in a constraint. Unfortunately, dataflow graphs require a great deal of storage. These storage costs can help push a large application into virtual memory, thus significantly degrading interactive performance. Reducing the storage costs of dataflow graphs is therefore an important goal in constraint research. This paper describes a study that makes two contributions to solving this problem:},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {83–92},
numpages = {10},
keywords = {dataflow constraints, space optimization, user interface toolkits, one-way},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322590,
author = {Hudson, Scott E. and John, Bonnie E. and Knudsen, Keith and Byrne, Michael D.},
title = {A Tool for Creating Predictive Performance Models from User Interface Demonstrations},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322590},
doi = {10.1145/320719.322590},
abstract = {A central goal of many user interface development tools has been to make the construction of high quality interfaces easy enough that iterative design approaches could be a practical reality. In the last 15 years significant advances in this regard have been achieved. However, the evaluation portion of the iterative design process has received relatively little support from tools. Even though advances have also been made in usability evaluation methods, nearly all evaluation is still done “by hand,” making it more expensive and difficult than it might be. This paper considers a partial implementation of the CRITIQUE usability evaluation tool that is being developed to help remedy this situation by automating a number of evaluation tasks. This paper will consider techniques used by the system to produce predictive models (keystroke level models and simplified GOMS models) from demonstrations of sample tasks in a fraction of the time needed by conventional handcrafting methods. A preliminary comparison of automatically generated models with models created by an expert modeler show them to produce very similar predictions (within 2%). Further, because they are automated, these models promise to be less subject to human error and less affected by the skill of the modeler.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {93–102},
numpages = {10},
keywords = {GOMS, event logs, toolkits, tool support for evaluation, task modeling},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322591,
author = {Hinckley, Ken and Sinclair, Mike and Hanson, Erik and Szeliski, Richard and Conway, Matt},
title = {The VideoMouse: A Camera-Based Multi-Degree-of-Freedom Input Device},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322591},
doi = {10.1145/320719.322591},
abstract = {The VideoMouse is a mouse that uses a camera as its input sensor. A real-time vision algorithm determines the six degree-of-freedom mouse posture, consisting of 2D motion, tilt in the forward/back and left/right axes, rotation of the mouse about its vertical axis, and some limited height sensing. Thus, a familiar 2D device can be extended for three-dimensional manipulation, while remaining suitable for standard 2D GUI tasks. We describe techniques for mouse functionality, 3D manipulation, navigating large 2D spaces, and using the camera for lightweight scanning tasks.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {103–112},
numpages = {10},
keywords = {multi-degree-of-freedom input, interaction technique, tilt sensing, input devices, camera-based input, rotation},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322592,
author = {Siio, Itiro and Masui, Toshiyuki and Fukuchi, Kentaro},
title = {Real-World Interaction Using the FieldMouse},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322592},
doi = {10.1145/320719.322592},
abstract = {We introduce an inexpensive position input device called the FieldMouse, with which a computer can tell the position of the device on paper or any flat surface without using special input tablets or position detection devices. A FieldMouse is a combination of an ID recognizer like a barcode reader and a mouse which detects relative movement of the device. Using a FieldMouse, a user first detects an ID on paper by using the barcode reader, and then drags it from the ID using the mouse. If the location of the ID is known, the location of the dragged FieldMouse can also be calculated by adding the amount of movement from the ID to the position of the FieldMouse. Using a FieldMouse in this way, any flat surface can work as a pointing device that supports absolute position input, just by putting an ID tag somewhere on the surface. A FieldMouse can also be used for enabling a graphical user interface (GUI) on paper or on any flat surface by analyzing the direction and the amount of mouse movement after detecting an ID. In this paper, we introduce how a FieldMouse can be used in various situations to enable computing in real-world environments.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {113–119},
numpages = {7},
keywords = {barcode, FieldMouse, mouse, real-world programming, active book, augmented reality, real-world inferface, input device, scroll browser, paper-GUI},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322593,
author = {Truong, Khai N. and Abowd, Gregory D. and Brotherton, Jason A.},
title = {Personalizing the Capture of Public Experiences},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322593},
doi = {10.1145/320719.322593},
abstract = {In this paper, we describe our work on developing a system to support the personalization of a captured public experience. Specifically, we are interested in providing students with the ability to personalize the capture of the lecture experiences as part of the Classroom 2000 project. We discuss the issues and challenges involved in designing a system that performs live integration of personal streams of information with multiple other streams of information made available to it through an environment designed to capture public information.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {121–130},
numpages = {10},
keywords = {capture and access application, ubiquitous computing, pen-based note-taking, personalization, educational application},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322594,
author = {Lewis, Jason E. and Weyers, Alex},
title = {ActiveText: A Method for Creating Dynamic and Interactive Texts},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322594},
doi = {10.1145/320719.322594},
abstract = {This paper describes ActiveText, a method for creating dynamic and interactive texts. ActiveText uses an object-based hierarchy to represent texts. This hierarchy makes it easy to work with the ASCII component and pixel component of the text at the same time. Static, dynamic and interactive properties of text can be easily intermixed and layered. The user can enter and edit text, adjust static and dynamic layout, apply dynamic and interactive behaviors, and adjust their parameters with a common set of tools and a common interface. Support for continuous editing allows the user to sketch dynamically. A prototype application called It's Alive! has been implemented to explore the ActiveText functionality. The documents produced by It's Alive! can be of use in a wide-range of areas, including chat-spaces, email, web-sites, fiction and poetry writing, and low-end film &amp; video titling.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {131–140},
numpages = {10},
keywords = {interactive text, typography, dynamic sketching, dynamic typograpyy, continuous editing},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322595,
author = {Heiner, Jeremy M. and Hudson, Scott E. and Tanaka, Kenichiro},
title = {The Information Percolator: Ambient Information Display in a Decorative Object},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322595},
doi = {10.1145/320719.322595},
abstract = {Most current interface designs require that the user focus their attention on them in order to be of value. However, as the price of computation falls, and computational capabilities make their way into many everyday objects, the demand for attention from many different directions may begin to seriously reduce the usefulness of these computational objects. Ambient information displays are intended to fit in a part of the interface design space that does not have this property. They are designed to convey background or context information that the user may or may not wish to attend to at any given time. Ambient Displays are designed to work primarily in the periphery of a user's awareness, moving to the center of attention only when appropriate and desirable. This paper describes a new ambient information display that is designed to give a rich medium of expression placed within an aesthetically pleasing decorative object. This display — the Information Percolator — is formed by air bubbles rising up tubes of water. By properly controlling the release of air, a set of pixels which scroll up the display is created. This allows a rendition of any (small, black and white) image to be displayed. The detailed design and construction of this display device will be considered, along with several applications.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {141–148},
numpages = {8},
keywords = {ubiquitous computing, tangible interfaces, manipulating demand for attention, ambient displays, aesthetics},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322596,
author = {Tolba, Osama and Dorsey, Julie and McMillan, Leonard},
title = {Sketching with Projective 2D Strokes},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322596},
doi = {10.1145/320719.322596},
abstract = {Freehand sketching has long had appeal as an artistic medium for conceptual design because of its immediacy in capturing and communicating design intent and visual experience. We present a sketching paradigm that supports the early stages of design by preserving the fluidity of traditional freehand drawings. In addition, it attempts to fill the gap between 2D drawing programs, which have fixed views, and 3D modeling programs that allow arbitrary views. We implement our application as a two-dimensional drawing program that utilizes a projective representation of points — i.e. points that lie on the surface of a unit sphere centered at the viewpoint. This representation facilitates the production of novel re-projections generated from an initial perspective sketch and gives the user the impression of being immersed in the drawing or space. We describe a method for aligning a sketch drawn outside the system using its vanishing points, allowing the integration of computer sketching and freehand sketching on paper in an iterative manner. The user interface provides a virtual camera, projective grids to guide in the construction of proportionate scenes, and the ability to underlay sketches with other drawings or photographic panoramas.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {149–157},
numpages = {9},
keywords = {panoramas, grids, illustration, vanishing points, view alignment, perspective},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322597,
author = {Honda, Masaaki and Igarashi, Takeo and Tanaka, Hidehiko and Sakai, Shuichi},
title = {Integrated Manipulation: Context-Aware Manipulation of 2D Diagrams},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322597},
doi = {10.1145/320719.322597},
abstract = {Diagram manipulation in conventional CAD systems requires frequent mode switching and explicit placement of the pivot for rotation and scaling. In order to simplify this process, we propose an interaction technique called integrated manipulation, where the user can move, rotate, and scale without mode switching. In addition, the pivot for rotation and scaling automatically snaps to a contact point during moving operation. We performed a user study is performed using our prototype system and a commercial CAD system. The results showed that users could perform a diagram manipulation task much more rapidly using our technique.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {159–160},
numpages = {2},
keywords = {drawing editors, interaction techniques, CAD, direct manipulation},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322598,
author = {Balakrishnan, Ravin and Fitzmaurice, George and Kurtenbach, Gordon and Buxton, William},
title = {Digital Tape Drawing},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322598},
doi = {10.1145/320719.322598},
abstract = {Tape drawing is the art of creating sketches on large scale upright surfaces using black photographic tape. Typically used in the automotive industry, it is an important part of the automotive design process that is currently not computerized. We analyze and describe the unique aspects of tape drawing, and use this knowledge to design and implement a digital tape drawing system. Our system retains the fundamental interaction and visual affordances of the traditional media while leveraging the power of the digital media. Aside from the practical aspect of our work, the interaction techniques developed have interesting implications for current theories of human bimanual interaction.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {161–169},
numpages = {9},
keywords = {large-scale displays, tape drawing, two-handed input, interaction techniques, automotive design},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322599,
author = {Balakrishnan, Ravin and Hinckley, Ken},
title = {The Role of Kinesthetic Reference Frames in Two-Handed Input Performance},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322599},
doi = {10.1145/320719.322599},
abstract = {We present experimental work which explores how the match (or mismatch) between the input space of the hands and the output space of a graphical display influences two-handed input performance. During interaction with computers, a direct correspondence between the input and output spaces is often lacking. Not only are the hands disjoint from the display space, but the reference frames of the hands may in fact be disjoint from one another if two separate input devices (e.g. two mice) are used for two-handed input. In general, we refer to the workspace and origin within which the hands operate as kinesthetic reference frames. Our goal is to better understand how an interface designer's choice of kinesthetic reference frames influences a user's ability to coordinate two-handed movements, and to explore how the answer to this question may depend on the availability of visual feedback. Understanding this issue has implications for the design of two-handed interaction techniques and input devices, as well as for the reference principle of Guiard's Kinematic Chain model of human bimanual action. Our results suggest that the Guiard reference principle is robust with respect to variances in the kinesthetic reference frames as long as appropriate visual feedback is present.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {171–178},
numpages = {8},
keywords = {two-handed input, interaction techniques, visual feedback, kinesthesia, Guiard theory, input},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322600,
author = {Heiner, Jeremy M. and Hudson, Scott E. and Tanaka, Kenichiro},
title = {Linking and Messaging from Real Paper in the Paper PDA},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322600},
doi = {10.1145/320719.322600},
abstract = {It is well known that paper is a very fluid, natural, and easy to use medium for manipulating some kinds of information. It is familiar, portable, flexible, inexpensive, and offers good readability properties. Paper also has well known limitations when compared with electronic media. Work in hybrid paper electronic interfaces seeks to bring electronic capabilities to real paper in order to obtain the best properties of each. This paper describes a hybrid paper electronic system — the Paper PDA — which is designed to allow electronic capabilities to be employed within a conventional paper notebook, calendar, or organizer. The Paper PDA is based on a simple observation: a paper notebook can be synchronized with a body of electronic information much like an electronic PDA can be synchronized with information hosted on a personal computer. This can be accomplished by scanning, recognizing and processing its contents, then printing a new copy. This paper introduces the Paper PDA concept and considers interaction techniques and applications designed to work within the Paper PDA. The StickerLink technique supports on-paper hyperlinking using removable paper stickers. Two applications are also considered which look at aspects of electronic communications via the Paper PDA.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {179–186},
numpages = {8},
keywords = {hybrid paper electronic interfaces, interaction on paper, hyperlinking, augmented reality, interaction techniques},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322601,
author = {Bj\"{o}rk, Staffan and Holmquist, Lars Erik and Redstr\"{o}m, Johan and Bretan, Ivan and Danielsson, Rolf and Karlgren, Jussi and Franz\'{e}n, Kristofer},
title = {WEST: A Web Browser for Small Terminals},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322601},
doi = {10.1145/320719.322601},
abstract = {We describe WEST, a WEb browser for Small Terminals, that aims to solve some of the problems associated with accessing web pages on hand-held devices. Through a novel combination of text reduction and focus+context visualization, users can access web pages from a very limited display environment, since the system will provide an overview of the contents of a web page even when it is too large to be displayed in its entirety. To make maximum use of the limited resources available on a typical hand-held terminal, much of the most demanding work is done by a proxy server, allowing the terminal to concentrate on the task of providing responsive user interaction. The system makes use of some interaction concepts reminiscent of those defined in the Wireless Application Protocol (WAP), making it possible to utilize the techniques described here for WAP-compliant devices and services that may become available in the near future.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {187–196},
numpages = {10},
keywords = {WAP (wireless application protocol), hand-held devices, focus+context visualization, flip zooming, text reduction, proxy systems, web browser},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

@inproceedings{10.1145/320719.322602,
author = {Moran, Thomas P. and Saund, Eric and Van Melle, William and Gujar, Anuj U. and Fishkin, Kenneth P. and Harrison, Beverly L.},
title = {Design and Technology for Collaborage: Collaborative Collages of Information on Physical Walls},
year = {1999},
isbn = {1581130759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/320719.322602},
doi = {10.1145/320719.322602},
abstract = {A Collaborage is a collaborative collage of physically represented information on a surface that is connected with electronic information, such as a physical In/Out board connected to a people-locator database. The physical surface (board) contains items that are tracked by camera and computer vision technology. Events on the board trigger electronic services. This paper motivates this concept, presents three different applications, describes the system architecture and component technologies, and discusses several design issues.},
booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
pages = {197–206},
numpages = {10},
keywords = {collaboration, tangible UI, roomware, physical-virtual},
location = {Asheville, North Carolina, USA},
series = {UIST '99}
}

