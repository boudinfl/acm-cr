@inproceedings{10.1109/WI.2006.197,
title = {Welcome Message from Conference Chairs},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.197},
doi = {10.1109/WI.2006.197},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {xix–xx},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.198,
title = {Welcome Message from Program Chair},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.198},
doi = {10.1109/WI.2006.198},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {xxi–xxii},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.199,
title = {WI'06 and IAT'06 Conference Organization},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.199},
doi = {10.1109/WI.2006.199},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {xxiii–xxiv},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.136,
title = {Program Committee},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.136},
doi = {10.1109/WI.2006.136},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {xxv–xxvii},
numpages = {3},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.200,
title = {WI'06 Non-PC Reviewers},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.200},
doi = {10.1109/WI.2006.200},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {xxviii},
numpages = {1},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.123,
author = {Poggio, Tomaso},
title = {Neuroscience: New Insights for AI?},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.123},
doi = {10.1109/WI.2006.123},
abstract = {Understanding the processing of information in our cortex is a significant part of understanding how the brain works and of understanding intelligence itself, arguably one of the greatest problems in science today. In particular, our visual abilities are computationally amazing and we are still far from imitating them with computers. Thus, visual cortex may well be a good proxy for the rest of the cortex and indeed for intelligence itself. But despite enormous progress in the physiology and anatomy of the visual cortex, our understanding of the underlying computations remains fragmentary. This position paper is based on the very recent, surprising realization that we may be on the verge of developing an initial quantitative theory of visual cortex, faithful to known physiology and able to mimic human performance in difficult recognition tasks, outperforming current computer vision systems. The proof of principle was provided by a preliminary model that, spanning several levels from biophysics to circuitry to the highest system level, describes information processing in the feedforward pathway of the ventral stream of primate visual cortex. The thesis of this paper is that -- finally -- neurally plausible computational models are beginning to provide powerful new insights into the key problem of how the brain works, and how to implement learning and intelligence in machines.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {3–8},
numpages = {6},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.157,
author = {Foster, Ian},
title = {Service-Oriented Science: Scaling EScience Impact},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.157},
doi = {10.1109/WI.2006.157},
abstract = {Computational approaches to problem solving have proven their worth in many fields of science, allowing the collection and analysis of unprecedented quantities of data, and the exploration via simulation of previously obscure phenomena. New "systems" approaches in fields as diverse as biology [12], earthquake science [11], and environmental science [3] are enabled by, and are spurring the further development of, such computational approaches. But as computational and system-level science methods become increasingly sophisticated, we must ask: how do we scale their impact, from the specialist to entire communities [7]?},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {9–10},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.179,
author = {Harmelen, Frank van},
title = {Two Obvious Intuitions: Ontology-Mapping Needs Background Knowledge and Approximation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.179},
doi = {10.1109/WI.2006.179},
abstract = {Ontology mapping (or: ontology alignment, or integration) is one of the most active areas the Semantic Web area. An increasing amount of ontologies are becoming available in recent years, and if the Semantic Web is to be taken seriously, the problem of ontology mapping must be solved. Numerous approaches are being proposed, a yearly competition is being organized, and a number of survey papers have appeared.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {11},
numpages = {1},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.43,
author = {Skowron, Andrzej},
title = {Approximate Reasoning in MAS: Rough Set Approach},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.43},
doi = {10.1109/WI.2006.43},
abstract = {In modeling multiagent systems for real-life problems, techniques for approximate reasoning about vague concepts and dependencies (ARVCD) are necessary. We discuss an approach to approximate reasoning based on rough sets. In particular, we present a number of basic concepts such as approximation spaces, concept approximation, rough inclusion, construction of information granules in calculi of information granules, and perception logic. The approach to ARVCD is illustrated by examples relative to interactions of agents, ontology approximation, adaptive hierarchical learning of compound concepts and skills, behavioral pattern identification, planning, conflict analysis and negotiations, and perception-based reasoning.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {12–18},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.69,
author = {Andre, Elisabeth},
title = {Engaging in a Conversation with Synthetic Agents along the Virtuality Continuum},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.69},
doi = {10.1109/WI.2006.69},
abstract = {During the last decade research groups as well as a number of commercial software developers have started to deploy embodied conversational characters in the user interface especially in those application areas where a close emulation of multimodal human-human communication is needed. Incarnations of such characters differ widely in type and amount of embodiment - starting from simplistic cartoon-style 2D representations of faces, fully embodied virtual humans in 3D virtual worlds to physically embodied androids co-habiting the user's real world. Despite of their variety, most of these characters have one thing in common: In order to enter the user's physical world, they need to be physical themselves. My talk focuses on challenges that arise when embedding synthetic conversational agents in the user's physical world.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {19–20},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.86,
author = {Dey, Lipika and Rastogi, Ashish Chandra and Kumar, Sachin},
title = {Generating Concept Ontologies through Text Mining},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.86},
doi = {10.1109/WI.2006.86},
abstract = {Designing mechanisms for creating concept ontologies automatically is an important research problem. In this work we have proposed a rough-set based mechanism to generate concept ontologies with concepts mined from documents. When the concept ontology is mined from preclassified documents, the output signifies the core set of domain concepts and their inter-relationships that define the categories, as well as the inter-category relationships. When the ontology is mined from a heterogeneous collection, the documents are first clustered into homogeneous groups and then mined for concepts. Rough set based lower and upper approximations have been used to identify core concepts and associated concepts for a domain or a group. The scheme has been tested over multiple domains.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {23–32},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.70,
author = {Wongthongtham, P. and Chang, E. and Dillon, T. S.},
title = {Enhancing Software Engineering Project Information through Software Engineering Ontology Instantiations},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.70},
doi = {10.1109/WI.2006.70},
abstract = {Software engineering project information is frequently evolving and queried to reflect project development changes in the software requirements or in the design process, to incorporate additional functionality to systems or to allow incremental improvement and the like. Therefore, the project information needs enhancement to ease up-to-date ontological information and to ease communication. Ontologies are widely used for capturing and organising knowledge of a particular domain of interest. We propose the use of software engineering ontology instantiations and enrichment to capture the software engineering project information.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {33–37},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.126,
author = {Zhang, Jianzhong},
title = {Origin-Destination Network Tomography with Bayesian Inversion Approach},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.126},
doi = {10.1109/WI.2006.126},
abstract = {Origin-destination (OD) network tomography problem is the estimation of OD traffic counts from measurable traffic counts at router interfaces. In this paper the problem is formulated as a linear inverse problem with additive noise and is resolved using Bayesian inversion approach. Both OD traffic counts and noise are modelled as Gaussian random functions, and are represented by Karhunen-Lo\`{e}ve expansion, respectively. The posterior random function of OD traffic counts given the link counts is also represented as the Karhunen-Lo\`{e}ve expansion. With the singular system of routing matrix, we thus can found the optimal estimator of OD traffic counts analytically.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {38–44},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.164,
author = {Buriol, Luciana S. and Castillo, Carlos and Donato, Debora and Leonardi, Stefano and Millozzi, Stefano},
title = {Temporal Analysis of the Wikigraph},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.164},
doi = {10.1109/WI.2006.164},
abstract = {Wikipedia is an online encyclopedia, available in more than 100 languages and comprising over 1 million articles in its English version. If we consider each Wikipedia article as a node and each hyperlink between articles as an arc we have a "Wikigraph", a graph that represents the link structure of Wikipedia. The Wikigraph differs from other Web graphs studied in the literature by the fact that there are explicit timestamps associated with each node's events. This allows us to do a detailed analysis of the Wikipedia evolution over time. In the first part of this study we characterize this evolution in terms of users, editions and articles; in the second part, we depict the temporal evolution of several topological properties of the Wikigraph. The insights obtained from the Wikigraphs can be applied to large Web graphs from which the temporal data is usually not available.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {45–51},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.118,
author = {Falkowski, Tanja and Bartelheimer, Jorg and Spiliopoulou, Myra},
title = {Mining and Visualizing the Evolution of Subgroups in Social Networks},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.118},
doi = {10.1109/WI.2006.118},
abstract = {A social network consists of people who interact in some way such as members of online communities sharing information via the WWW. To learn more about how to facilitate community building e.g. in organizations, it is important to analyze the interaction behavior of their members over time. So far, many tools have been provided that allow for the analysis of static networks and some for the temporal analysis of networks - however only on the vertex and edge level. In this paper we propose two approaches to analyze the evolution of two different types of online communities on the level of subgroups: The first method consists of statistical analyses and visualizations that allow for an interactive analysis of subgroup evolutions in communities that exhibit a rather membership structure. The second method is designed for the detection of communities in an environment with highly fluctuating members. For both methods, we discuss results of experiments with real data from an online student community.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {52–58},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.71,
author = {Garcia, Graciela and Cobos, Ruth},
title = {ESMAP: A Multi-Agent Platform for Extending a Knowledge Management System},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.71},
doi = {10.1109/WI.2006.71},
abstract = {For more than one decade Knowledge Management has taken advantage of some abilities that software agents are endowed with. Agent features such as autonomy, cooperation, communication, and learning capacity have been used to improve the performance of Knowledge Management applications. In this paper we outline our proposal for implementing a Jade-based multi-agent platform to enhance the potential of KnowCat: a fully consolidated, thoroughly tested and validated Knowledge Management system which has been in active use at Universidad Aut\'{o}noma de Madrid (Spain) since 1998. We also give a succinct description of the agent platform architecture and a brief presentation of its current status.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {59–65},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.61,
author = {Jamali, Mohsen and Abolhassani, Hassan},
title = {Different Aspects of Social Network Analysis},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.61},
doi = {10.1109/WI.2006.61},
abstract = {A social network is a set of people (or organizations or other social entities) connected by a set of social relationships, such as friendship, co-working or information exchange. Social network analysis focuses on the analysis of patterns of relationships among people, organizations, states and such social entities. Social network analysis provides both a visual and a mathematical analysis of human relationships. Web can also be considered as a social network. Social networks are formed between Web pages by hyperlinking to other Web pages. In this paper a state of the art survey of the works done on social network analysis ranging from pure mathematical analyses in graphs to analyzing the social networks in Semantic Web is given. The main goal is to provide a road map for researchers working on different aspects of Social Network Analysis.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {66–72},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.108,
author = {Kawachi, Yumi and Yoshii, Shinichiro and Furukawa, Masashi},
title = {Labeled Link Analysis for Extracting User Characteristics in E-Commerce Activity Network},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.108},
doi = {10.1109/WI.2006.108},
abstract = {This paper proposes an approach to characterize user activity in e-commerce, especially in Internet auctions. It is considered that users are connected to each other through their transactions. The connectivity makes an extensive complex network where users' intentions and behaviors are reflected in the network structure. That is to say, the network is composed of nodes as users and links as transactions between two users. Moreover, the links have one label that indicates a category type of transacted goods such as "book", "fashion", "music" among others. In order to characterize user activities in the network, a modified HITS algorithm is proposed. The results of the analysis using real data collected from an Internet Auction site show characteristics of each user. Since the method takes advantage of network structures, evaluation values for the user characteristics that have been obtained illustrate not only the tendency of category types of goods that the users have transacted but also the tendency of relationships with other users. The characteristics are influenced by both direct and indirect connections among users. Our final goal is to construct a system that can personalize and profile users for marketing in e-commerce.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {73–80},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.115,
author = {Lim, Ee-Peng and Vuong, Ba-Quy and Lauw, Hady Wirawan and Sun, Aixin},
title = {Measuring Qualities of Articles Contributed by Online Communities},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.115},
doi = {10.1109/WI.2006.115},
abstract = {Using open source Web editing software (e.g., wiki), online community users can now easily edit, review and publish articles collaboratively. While much useful knowledge can be derived from these articles, content users and critics are often concerned about their qualities. In this paper, we develop two models, namely basic model and peer review model, for measuring the qualities of these articles and the authorities of their contributors. We represent collaboratively edited articles and their contributors in a bipartite graph. While the basic model measures an article's quality using both the authorities of contributors and the amount of contribution from each contributor, the peer review model extends the former by considering the review aspect of article content. We present results of experiments conducted on some Wikipedia pages and their contributors. Our result show that the two models can effectively determine the articles' qualities and contributors' authorities using the collaborative nature of online communities.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {81–87},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.109,
author = {Makrehchi, Masoud and Kamel, Mohamed S.},
title = {Learning Social Networks from Web Documents Using Support Vector Classifiers},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.109},
doi = {10.1109/WI.2006.109},
abstract = {Automatic generation of a social network requires extracting pair-wise relations of the individuals. In this research, Learning social network from incomplete relationship data is proposed. It is assumed that only a small subset of relations between the individuals is known. With this assumption, the social network extraction is translated into a text classification problem. The relations between two individuals are modeled by merging their document vectors and the given relations are used as labels of training data. By this transformation, a text classifier such as SVM is used for learning the unknown relations. We show that there is a link between the intrinsic sparsity of social networks and class distribution imbalance of the training data. In order to re-balance the unbalanced training data, a minority class down-sampling strategy is employed. The proposed framework is applied to a true FOAF (Friend Of A Friend) database and evaluated by the macro-averaged F-measure.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {88–94},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.180,
author = {Matsumura, Naohiro and Sasaki, Yoshihiro},
title = {Understanding Leadership Behavior in Human Influence Network},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.180},
doi = {10.1109/WI.2006.180},
abstract = {We determined the results of the questionnaire for 97 staff members working in dot-jp, a non-profit organization in Japan, to understand the degrees of satisfaction of staff members with leaders. We then extracted human influence networks from the archives of e-mail used at dotjp to understand relationships between leaders and other staff members. By integrating these two approaches, we revealed ideal leadership behavior. We discovered that leaders should receive messages from staff members as well as send messages to construct reliable relationships. Otherwise, leaders become smug and lose trusts from other staff members.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {95–102},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.111,
author = {Naruse, Keitaro and Kubo, Masao},
title = {Lognormal Distribution of BBS Articles and Its Social and Generative Mechanism},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.111},
doi = {10.1109/WI.2006.111},
abstract = {The objective of this paper is to understand an aspect of human social interaction in public bulletin board systems (BBSs). We try to answer the question of why and how a long and hot chain of articles often emerges in BBSs. This paper presents the following three contributions. (1) Empirical results: we measured and analyzed actual BBS logs, and found that the number of articles submitted by each individual in an article chain follows a lognormal distribution. (2) Model: to investigate why the distribution emerges through individual activities, we developed a simple model of voluntary submission activity for each individual. With only this simple mechanism, the lognormal distribution shown in actual data is reproduced. (3) Analytical solution: we showed that the model generates a lognormal distribution when the number of members in a BBS community is constant, and the individuals in a community are homogeneous.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {103–112},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.146,
author = {Khan, Javed I. and Shaikh, Sajid},
title = {Relationship Algebra for Computing in Social Networks and Social Network Based Applications},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.146},
doi = {10.1109/WI.2006.146},
abstract = {Online communities are the latest phenomena on the Internet. At the heart of each community lies a social network. In this paper, we show a generalized framework to understand and reason in social networks. Previously, researchers have attempted to use inference-specific type of relationships. In this paper, we propose a framework to represent and reason with general case of social relationship network in a formal way. We call it relationship algebra. This paper presents this algebra and then shows how this algebra can be used for various interesting computations on a social network weaved in the virtual communities.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {113–116},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.133,
author = {Li, Wenbin and Zhong, Ning and Liu, Jiming and Yao, Yiyu and Liu, Chunnian},
title = {Perspective of Applying the Global E-Mail Network},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.133},
doi = {10.1109/WI.2006.133},
abstract = {Recently, research on social network and Web Intelligence (WI) has shown that social intelligence techniques act as the imperative channel for automated email-centric tasks. This paper gives a complete picture of what can we do in the global social e-mail network and how to do. Our main contributions include: (1) we describe two mechanisms for implementing applications in the global social e-mail network; (2) we design Operable E-mail for communicating in that network. To our best knowledge, it is the first time to discuss how to implement social intelligence in such a network under the notion of WI. We believe that this work consequentially explores a new and absolutely necessarily needed research field of WI.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {117–120},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.202,
author = {Lo, Shuchuan and Lin, Chingching},
title = {WMR--A Graph-Based Algorithm for Friend Recommendation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.202},
doi = {10.1109/WI.2006.202},
abstract = {More and more people make friends on the Internet. Most of the community websites generate the friend recommendation lists by search engine. Search engine is not an efficient mechanism because the database is too huge that search engine produces many unnecessary and unordered friend lists. However, there is little research discussing the issue of the recommendation quality of friend on the Internet. In this study, we propose a new recommendation algorithm named weighted minimum-message ratio (WMR) which generates a limited, ordered and personalized friend lists by the real message interaction number among web members. We chose 30 potential members from a community website as our experimental cases in this study. The result shows that the best recommended friend number for a target member is 15 and the precision and recall are 15% and 8% for testing prediction, respectively. This result is acceptable compared with book recommendation in which the testing precision and recall are 3% and 14%, respectively.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {121–128},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.14,
author = {Shen, Haifeng and Sun, Chengzheng and Zhou, Suiping and Phyo, Zaw Wai},
title = {A Generic WebDAV-Based Document Repository Manager for Collaborative Systems},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.14},
doi = {10.1109/WI.2006.14},
abstract = {Collaborative Document Repository Manager (CDRM) is one of the three key components in a collaborative editing system. It provides a repository for storing shared documents and a portal for managing shared documents, initiating collaborative editing sessions, and viewing session information. While most collaborative systems have been using ad hoc and tightly-coupled CDRMs, our work is to provide a generic WebDAV-based CDRM to take advantage of WebDAV's ubiquitous accessibility, directly writable medium, and access transparency. This WebDAV-based CDRM has been deployed into the CoOffice (Collaborative Office) and the CoStarOffice (Collaborative StarOffice) systems for evaluation, demonstration, and usability study.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {129–136},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.185,
author = {Perkio, Jukka and Tuulos, Ville and Hermersdorf, Marion and Nyholm, Heli and Salminen, Jukka and Tirri, Henry},
title = {Utilizing Rich Bluetooth Environments for Identity Prediction and Exploring Social Networks as Techniques for Ubiquitous Computing},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.185},
doi = {10.1109/WI.2006.185},
abstract = {Personal identification and using that information is in the heart of many ubiquitous systems. We present two complementary techniques, namely personal identification without directly observing the subject, and using that information for understanding the social relations between the subjects. We show that with certain presumptions it is possible to predict one's identity with reasonable certainty only by observing one's Bluetooth neighborhood without the need to directly observe the subject. We also show how this information can be used for exploring the social relations between the subjects.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {137–144},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.156,
author = {Malone, James},
title = {Semantic-Based Workflow Composition for Video Processing in the Grid},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.156},
doi = {10.1109/WI.2006.156},
abstract = {We outline the problem of automatic video processing for the EcoGrid [1]. This poses many challenges as there is a vast amount of raw data that need to be analysed effectively and efficiently. Furthermore, ecological data are subject to environmental changes and are exception-prone, hence their qualities vary. As manual processing by humans can be time and labour intensive, video and image processing tools can go some way to addressing such problems since they are computationally fast. However, most video analyses that utilise a combination of these tools are still done manually. We propose a semantic-based hybrid workflow composition method that strives to provide automation to speed up this process. The requirements for such a system are presented, whereby we aim for a solution that best satisfies these requirements and that overcomes the limitations of existing Grid workflow composition systems.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {161–165},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.66,
author = {Wang, Chengwei},
title = {Dynamic Access Control Prediction for Ordered Service Sequence in Grid Environment},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.66},
doi = {10.1109/WI.2006.66},
abstract = {When facing the emerging circumstance that the Internet and business globalization have replaced the separation that was typical of the traditional business paradigm, especially the workflow and grid environment, challenges have been made to the traditional static access control model. To solve these challenges, we present a Dynamic Access Control Prediction mechanism for service workflow base on Markov chain. We abstract the service workflow in workflow and/or grid to an Ordered Service Sequence and through calculating the executable probability of service in OSS, we create an authorization policy based on the probability value dynamically. A simulation method of the mechanism is presented and practiced in ChinaGrid project.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {145–151},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.78,
author = {Bailey, James},
title = {Fast Discovery of Interesting Collections of Web Services},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.78},
doi = {10.1109/WI.2006.78},
abstract = {Web Services are beginning to play a major role in future Web architectures and software applications. One of the most important research directions in the area of Web services is the development of techniques for automatically discovering collections of services that satisfy a set of interestingness constraints. Discovery of interesting collections of Web services is a challenging problem, however, due to the high complexity involved. In this paper, we present a new method for discovery of interesting collections of Web services, according to user specified cost constraints. We show that this task is closely related to the well-known problem of computing the transversals of a hypergraph. We experimentally evaluate our approach and show that pruning and partitioning techniques can significantly improve running time.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {152–160},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.89,
author = {Thein, Nilar and Naing, Thinn Thu},
title = {Grid Security Framework for Managing the Certificate},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.89},
doi = {10.1109/WI.2006.89},
abstract = {The certificate is a central concept in Grid Security Infrastructure authentication. The certificate guarantees the authenticity of the data, thus effectively authenticating the sender. In this paper, we propose a secure certificate authentication framework using Counting Process to interact trusty for Grid users .We intend to apply this approach in secured performance on Grids as well as in grid application for authenticating users, protecting attacks, and recovering failed systems. The main idea presented in this paper is to add counting process and matching method into RSA algorithm to apply in Grid certificate authentication.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {166–169},
numpages = {4},
keywords = {Authentication method and Authorization method, RSA public key, Certificate, Counting Process},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.154,
author = {Selvi, S. Thamarai and Balachandar, R. A. and Vijayakumar, K. and Mohanram, N. and Vandana, M. and Raman, Rajagopalan},
title = {Semantic Discovery of Grid Services Using Functionality Based Matchmaking Algorithm},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.154},
doi = {10.1109/WI.2006.154},
abstract = {With this paper, we propose a matchmaking system that performs matchmaking of requested grid services with that of advertised ones to discover the best suitable services. The matchmaking algorithm implemented in our matchmaking system considers functionality of the requested service as critical factor for faster and accurate discovery of services. Unlike conventional matchmaking algorithm where service discovery is based on Inputs and Outputs, our algorithm retrieves services similar to the one requested based on functionality in addition to Inputs and Outputs.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {170–173},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.101,
author = {Shi, Wei and Wu, Jian and Li, Ying and Kuang, Li},
title = {Intelligent Transportation Information Sharing and Service Integration in Semantic Grid Environment},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.101},
doi = {10.1109/WI.2006.101},
abstract = {ITSGrid is an undergoing joint engineering project designed and developed by advanCed Computing aNd sysTem (CCNT) Lab in Zhejiang University and Hangzhou Enjoyor Electronics Co. Ltd (Enjoyor). The new features of ITSGrid are originated from two important research projects -- DartGrid and DartFlow, and one key engineering project -- JTang Application Server, in CCNT Lab. Its goal is to build an integrated intelligent transportation information and service platform (ITISP), to integrate traffic data resources collected by Enjoyor and cooperate existing ITS subsystems and services deployed by Enjoyor, finally serve for transportation construction in China. During building this project, we utilize systematically the Grid technology, the Semantic Web technology, the Web Service technology, the Messaging Oriented Middleware technology.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {174–180},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.131,
author = {Bade, Korinna and Nurnberger, Andreas},
title = {Personalized Hierarchical Clustering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.131},
doi = {10.1109/WI.2006.131},
abstract = {A hierarchical structure can provide efficient access to information contained in a collection of documents. However, such a structure is not always available, e.g. for a set of documents a user has collected over time in a single folder or the results of a web search. We therefore investigate in this paper how we can obtain a hierarchical structure automatically, taking into account some background knowledge about the way a specific user would structure the collection. More specifically, we adapt a hierarchical agglomerative clustering algorithm to take into account user specific constraints on the clustering process. Such an algorithm could be applied, e.g., for user specific clustering of Web search results, where the user's constraints on the clustering process are given by a hierarchical folder or bookmark structure. Besides the discussion of the algorithm itself, we motivate application scenarios and present an evaluation of the proposed algorithm on benchmark data.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {181–187},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.96,
author = {Chen, Jinlin and Zhong, Ping and Cook, Terry},
title = {Improving Index Compression Using Cluster Information},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.96},
doi = {10.1109/WI.2006.96},
abstract = {The clustering property of document collections in Web search engines provides valuable information for improving index compression. By clustering d-gaps of an inverted list and then encoding clustered and nonclustered d-gaps using different codes, we can tailor to the specific properties of different d-gaps and achieve better compression ratio. Further improvement on index compression can be achieved by adaptively adjusting the cluster threshold for inverted lists. Based on these ideas, in this paper we propose adaptive cluster based mixed codes for inverted file index compression. Experiment results show that codes using adaptive cluster based mixed approach have better performance in terms of compression ratio and lower complexity comparing to interpolative code which is considered as one of the most efficient bitwise codes at present.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {188–194},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.132,
author = {Cheng, Victor and Li, C. H.},
title = {Personalized Spam Filtering with Semi-Supervised Classifier Ensemble},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.132},
doi = {10.1109/WI.2006.132},
abstract = {The proliferation of unsolicited emails, also known as spam, poses significant burden to email users worldwide. Recent researches on spam filtering have shown that high accuracies can be obtained if labeled emails examples are available from the particular user of the spam filter. However, the time consuming process of providing personalized labeled training examples is often inconvenient or impossible due to privacy issues. In this paper, a semi-supervised personalized spam filter based on classifier ensemble is proposed that classifies user's emails accurately by learning on both generic labeled emails and personalized unlabeled emails. The proposed multi-stage classification process begins learning a SVM model from labeled generic data. Unlabeled user's emails are then fed to this SVM to generate personalized labeled data for constructing personalized naive Bayes classifiers. Furthermore, some personalized labeled examples are generated by exploiting rare word distributions and then fed into a semi-supervised classifier. The multi-stage results are integrated with SVMs learned from generic labeled emails to produce the final classification results. Experimental results show that the proposed approaches can significantly increases the classification accuracy in spam filtering.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {195–201},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.142,
author = {Crabtree, Daniel and Andreae, Peter and Gao, Xiaoying},
title = {Query Directed Web Page Clustering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.142},
doi = {10.1109/WI.2006.142},
abstract = {Web page clustering methods categorize and organize search results into semantically meaningful clusters that assist users with search refinement; but finding clusters that are semantically meaningful to users is difficult. In this paper, we describe a new web page clustering algorithm, QDC, which uses the user's query as part of a reliable measure of cluster quality. The new algorithm has five key innovations: a new query directed cluster quality guide that uses the relationship between clusters and the query, an improved cluster merging method that generates semantically coherent clusters by using cluster description similarity in additional to cluster overlap, a new cluster splitting method that fixes the cluster chaining or cluster drifting problem, an improved heuristic for cluster selection that uses the query directed cluster quality guide, and a new method of improving clusters by ranking the pages by relevance to the cluster. We evaluate QDC by comparing its clustering performance against that of four other algorithms on eight data sets (four use full text data and four use snippet data) by using eleven different external evaluation measurements. We also evaluate QDC by informally analysing its real world usability and performance through comparison with six other algorithms on four data sets. QDC provides a substantial performance improvement over other web page clustering algorithms.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {202–210},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.183,
author = {Harit, Gaurav and Chaudhury, Santanu and Ghosh, Hiranmay},
title = {Using Multimedia Ontology for Generating Conceptual Annotations and Hyperlinks in Video Collections},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.183},
doi = {10.1109/WI.2006.183},
abstract = {To enable seamless integration of video information on the semantic web, we require that the knowledge of a video domain be formally specified in an ontology. We present a novel approach for defining video domain concepts in an ontology using properties that can be observed from the media. We use the ontology specified knowledge for recognizing concepts relevant to a video scene by making observations for the media properties of concepts as well as making inferences from other ontological concept definitions and relations. For this purpose we introduce new language constructs to OWL (Web Ontology Language), which are used to specify the inherently uncertain nature of media observations. The new constructs also allow additional semantics concerned with the association of media properties with concepts. We propose the use of Bayesian network as the reasoning mechanism for doing inferencing tasks in the presence of uncertainty. The video is annotated with the relevant concepts defined in the ontology. These conceptual annotations are used to create hyperlinks in the video collection.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {211–217},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.116,
author = {Hofgesang, Peter I.},
title = {Methodology for Preprocessing and Evaluating the Time Spent on Web Pages},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.116},
doi = {10.1109/WI.2006.116},
abstract = {On the web, the intention of a user is mostly hidden. To approximate user intention and characterise user behaviour researches in web usage mining mainly exploit two types of information: order and frequency of visited pages. However, several studies in information retrieval and humancomputer interaction have suggested that the time spent on web pages (TSP) is an important measure of user intention and page relevance. In our paper we provide a methodology to preprocess the TSP. In addition, we present a real-world testbed that provides an unbiased environment and representative, real-world data in specific web domains. The environment can be used to evaluate user interest indicators and importance measures, to validate clustering algorithms and for a broad selection of other validation problems. As a case study, we define a testbed on online retail shop data and evaluate, among others, the relevance of TSP.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {218–225},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.151,
author = {Li, Yuefeng and Zhong, Ning},
title = {Rough Association Rule Mining in Text Documents for Acquiring Web User Information Needs},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.151},
doi = {10.1109/WI.2006.151},
abstract = {It is a big challenge to apply data mining techniques for effective Web information gathering because of duplications and ambiguities of data values (e.g., terms). To provide an effective solution to this challenge, this paper first explains the relationship between association rules and rough set based decision rules. It proves that a decision pattern is a kind of closed pattern. It also presents a novel concept of rough association rules in order to improve the effectiveness of association rule mining. The premise of a rough association rule consists of a set of terms and a frequency distribution of terms. The distinct advantage of rough association rules is that they contain more specific information than normal association rules. It is also feasible to update rough association rules dynamically to produce effective results.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {226–232},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.72,
author = {Luo, Feng and Wang, James Z. and Promislow, Eric},
title = {Exploring Local Community Structures in Large Networks},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.72},
doi = {10.1109/WI.2006.72},
abstract = {In this paper, we extend the concept of degree from single vertex to sub-graph, and present a formal definition of module/community in a network based on this extension. A new locally optimized algorithm is designed to find the module for a given source vertex in a network. Our analysis shows that the complexity of this algorithm is O(K2d), where K is the number of vertices to be explored in the sub-graph and d is the average degree of the vertices in the sub-graph. Based on this algorithm, we implement a JAVA tool, MoNet, for exploring local community structures in large networks. Using this tool to analyze a co-purchase network from Amazon shows that there are local community structures in this network. Further analyses on these local community structures demonstrate that media items are much easier to form compact local modules than book items do, indicating that recommending digital media items to customers based on co-purchasing information in the online store will be more efficient than recommending books.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {233–239},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.113,
author = {Masum, Shaikh Mostafa Al and Ishizuka, Mitsuru},
title = {Making Topic-Specific Report and Multimodal Presentation Automatically by Mining the Web Resources},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.113},
doi = {10.1109/WI.2006.113},
abstract = {Due to availability and accessibility of enormous internet-based resources and dynamic nature of web pages, the task of information retrieval is becoming more challenging and gradually tricky. This paper describes about agent based autonomous system, Automatic Report to Presentation (ARP), with the notion of autonomous information service emerging as the result of integration among natural language processing, web intelligence, and character-based agent interaction. The system, ARP, automatically builds a report on a topic or search phrase(s) given by a user by fetching a set of web-pages; and then parsing; summarizing, affect-sensing and correlating information extracted from those. The system also makes a concise presentation automatically and, a group of character based software-agents autonomously present the topic in a story-telling manner employing text-to- speech engine with accompanied content-rich slides, different gestures and affects.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {240–246},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.47,
author = {Ni, Xiaochuan and Wu, Xiaoyuan and Yu, Yong},
title = {Automatic Identification of Chinese Weblogger's Interests Based on Text Classification},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.47},
doi = {10.1109/WI.2006.47},
abstract = {Chinese weblogs have been expanded in an incredible speed in recent years. There is plentiful personal information in weblogs. In this paper, we propose a text classification based approach to automatically identify the interests of a weblogger. To solve the problems arising out of classifying weblog documents, the technique of heterogeneous classifiers combination is used here. We also use hierarchical classification technique to identify much specific interests. Experiments show that our interest identification approach has a high accuracy and, for most webloggers in our experiments, their interests implied in the contents of blogs could be well identified by using this approach.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {247–253},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.120,
author = {Oh, Jong-Hoon and Isahara, Hitoshi},
title = {Mining the Web for Transliteration Lexicons: Joint-Validation Approach},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.120},
doi = {10.1109/WI.2006.120},
abstract = {The Web provides the largest data collection, which reflects language use in daily life. With the advent of new technology and the flood of information on the Web, it has become quite common to create new terms supporting new concepts and translate these terms into non-Latin languages with "transliteration" referring to "translation by sound". Cross-language natural language processing applications, such as machine translation and cross-language information retrieval, usually need a translation dictionary, which affects the quality of the applications. However, the transliteration lexicons are usually unregistered in the translation dictionary. To address the problem, here, we present a transliteration lexicon acquisition model that mines the Web for transliteration lexicons. In this paper, we describe techniques of comparing phonetic-similarity to recognize transliteration pair candidates on the Web and of finding the correct transliteration pairs based on joint-validation. The techniques were evaluated against manually constructed transliteration lexicons. Our experiments revealed that the techniques effectively found transliteration lexicons on the Web.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {254–261},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.147,
author = {Viermetz, Maximilian and Stolz, Carsten and Gedov, Vassil and Skubacz, Michal},
title = {Relevance and Impact of Tabbed Browsing Behavior on Web Usage Mining},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.147},
doi = {10.1109/WI.2006.147},
abstract = {The rapid growth of the Internet has pushed the research and development of web usage mining ever more into focus. Web usage mining and its applications have become critical to the business world. These analyses rest in turn on the ability to develop a clear understanding of the actions a user has taken. So far, the temporal order of clicks has been taken to be equal to the structural order of a session. With the advent of the newest browser generation where the use of multiple tabs has become a common feature, the above assumption does not necessarily hold any more. It is crucial to understand how the use of multiple tabs impacts on web usage mining, especially on the understanding of a session and its reconstruction. In order to analyze this new browsing behavior, we introduce a generic browsing model extending the traditional serial or single window model to cover the use of multiple tabs. Based on this model, we present and analyze an approach to detect use of multiple tabs within sessions. The existence and increasing prominence of the use of multiple tabs is shown by this approach to be of relevance to business analysis as well as research results.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {262–269},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.9,
author = {Weng, Cheng G. and Poon, Josiah},
title = {A Data Complexity Analysis on Imbalanced Datasets and an Alternative Imbalance Recovering Strategy},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.9},
doi = {10.1109/WI.2006.9},
abstract = {The imbalance dataset problem arises in many domains, such as web page search, scam sites detection. In this paper, we propose an alternative re-sampling approach to deal with imbalance datasets. We demonstrate this approach with a concrete implementation and it has shown promising results when compared to other standard approaches that deals with imbalance dataset. We have also performed an analysis of the data complexity to help understand imbalanced dataset, which has also shown to be a promising approach.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {270–276},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.170,
author = {Zhang, Jianping and Qin, Jason and Yan, Qiuming},
title = {The Role of URLs in Objectionable Web Content Categorization},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.170},
doi = {10.1109/WI.2006.170},
abstract = {By analyzing a set of access attempts by teenagers to pornographic websites, we found that more than half of them are image searches and visits to websites with little text information. It is obvious that textual content-based filters cannot correctly categorize such access attempts. This paper describes a novel URL-based objectionable content categorization approach and its application to web filtering. In this approach, we break the URL into a sequence of n-grams with a range of n's and then a machine learning algorithm is applied to the n-gram representation of URLs to learn a classifier of pornographic websites. We showed empirically that the URL-based approach is able to correctly identify many of the objectionable web pages. We also demonstrated that the optimum web filtering results could be achieved when it was used with a content-based approach in a production environment.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {277–283},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.36,
author = {Zhou, Baoyao and Hui, Siu Cheung and Fong, Alvis C. M.},
title = {An Effective Approach for Periodic Web Personalization},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.36},
doi = {10.1109/WI.2006.36},
abstract = {Periodic web personalization aims to recommend the most relevant resources to a user during a specific time period by analyzing the periodic access patterns of the user from web usage logs. In this paper, we propose a novel web usage mining approach for supporting effective periodic web personalization. The proposed approach first constructs a user behavior model, called Personal Web Usage Lattice, from web usage logs using the fuzzy Formal Concept Analysis technique. Based on the Personal Web Usage Lattice, resources that the user is most probably interested in during a given period can be deduced efficiently. This approach enables the costly personalized resources preparation process to be done in advance rather than in real-time. The performance evaluation of the proposed periodic web personalization approach is also given in the paper.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {284–292},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.82,
author = {An, Jiyuan and Chen, Yi-Ping Phoebe},
title = {Finding Short Patterns to Classify Text Documents},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.82},
doi = {10.1109/WI.2006.82},
abstract = {Many classification methods have been proposed to find patterns in text documents. However, according to Occam's razor principle, "the explanation of any phenomenon should make as few assumptions as possible", short patterns usually have more explainable and meaningful for classifying text documents. In this paper, we propose a depth-first pattern generation algorithm, which can find out short patterns from text document more effectively, comparing with breadth-first algorithm.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {293–296},
numpages = {4},
keywords = {depth-first., breadth-first, rule generation, Document Categorization},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.41,
author = {Berger, Helmut and Dittenbach, Michael and Merkl, Dieter},
title = {Analyzing the Effect of Document Representation on Machine Learning Approaches in Multi-Class e-Mail Filtering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.41},
doi = {10.1109/WI.2006.41},
abstract = {This paper reports on experiments in multi-class document categorization with supervised machine learning techniques. The document collection consists of of a set of personal e-mail messages. Two distinct document representation formalisms are employed to characterize these messages, namely a standard word-based approach and a character n-gram document representation. Based on these document representations, the categorization performance of five machine learning approaches is assessed and a comparison is given. In principle, both document representation yielded comparable results with the various classifiers. However, the results for the n-gram-based document representation were definitely better in case of an aggressive feature selection strategy.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {297–300},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.201,
author = {Campos, Ricardo and Dias, Gael and Nunes, Celia},
title = {WISE: Hierarchical Soft Clustering of Web Page Search Results Based on Web Content Mining Techniques},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.201},
doi = {10.1109/WI.2006.201},
abstract = {Typically, search engines are low precision in response to a query, retrieving lots of useless web pages, and missing some other important ones. In this paper, we study the problem of the hierarchical clustering of web pages search results. In particular, we propose an architecture called WISE [1], a meta-search engine that automatically builds clusters of related web pages embodying one meaning of the query. These clusters are then hierarchically organized and labeled with a phrase representing the key concept of the cluster and the corresponding web documents. The system which is a web-based interface (soon available at wise.di.ubi.pt), introduces some interesting new ideas, such as the pre-selection of the retrieved web pages, the capacity to statistically detect phrases within documents and the representation of documents based on their most relevant key concepts by using web content mining techniques. The final step of the system is supported by a graph-based overlapping clustering algorithm which groups the selected documents into a hierarchy of clusters.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {301–304},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.27,
author = {Chen, Yao-Tsung and Chen, Meng Chang},
title = {A Study of \chi^2-Test for Text Categorization},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.27},
doi = {10.1109/WI.2006.27},
abstract = {In this paper, we propose the chi^2-classifier employing the chi^2-test to test the homogeneity of two random samples of term vectors for text categorization decision. First, the properties of chi^2-test for text categorization are studied. One of the advantages of chi^2-test is that its significance level alpha is the same as the miss rate that provides a foundation for theoretical performance guarantee. The chi^2-classifier also considers term aggregation and selection methods to improve the categorization performance. Generally cosine similarity with TF*IDF weighting function performs reasonably well in text categorization. However, the performance of cosine similarity depends on the given threshold value, and its categorization performance may fluctuate even near the optimal threshold value. To alleviate the problems, the chi^2-classifier proposes a combination of chi^2-test and cosine similarity. Extensive experiment results have verified the properties of chi^2-test and performance of the combined classifier.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {305–308},
numpages = {4},
keywords = {I.2.6.g Machine Learning, H.2.8.I Text mining, G.3g Nonparametric statistics},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.45,
author = {Dittenbach, Michael and Berger, Helmut and Merkl, Dieter},
title = {Automated Concept Discovery from Web Resources},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.45},
doi = {10.1109/WI.2006.45},
abstract = {The task of researching information on a particular topic using the Web is mainly accomplished by using keyword-based search engines. Although this approach provides a good starting point, it remains a tedious task to collect additional information that puts this topic in greater context. In this paper we present ConceptWorld, an instrument to automatically discover various facets of a topic of interest by extracting concepts from Web documents. The result materializes as a network of semantic concepts with their various contextual interrelations and provides a holistic view on the topic of interest.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {309–312},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.50,
author = {Dong, Lei and Watters, Carolyn and Duffy, Jack and Shepherd, Michael},
title = {Binary Cybergenre Classification Using Theoretic Feature Measures},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.50},
doi = {10.1109/WI.2006.50},
abstract = {In this study, we conducted an investigation on automatic genre classification for three common types of web pages addressing the effect of three theoretic feature selection measures, a range of feature set size, and three machine classifiers on the accuracy of the web page classification in the context of a set of controlled experiments. Our results are encouraging and we conclude that for binary classification tasks, at least for these web page genres, it is possible to reach satisfying results with small content-based feature sets generated with a sound feature selection measure and furthermore there is no evidence of interaction between these feature selection measures and the machine classifiers used.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {313–316},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.165,
author = {Hoebel, Natascha and Kaufmann, Sascha and Tolle, Karsten and Zicari, Roberto V.},
title = {The Design of Gugubarra 2.0: A Tool for Building and Managing Profiles of Web Users},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.165},
doi = {10.1109/WI.2006.165},
abstract = {In [6] we have introduced the concept of non-obvious user profiles (NOPs) to capture the hypothetical interest of web users. In this paper we present the design principles and rules of our Gugubarra engine, which is a tool to calculate and visualize these non-obvious user profiles.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {317–320},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.80,
author = {Ingvaldsen, Jon Espen and Gulla, Jon Atle and Laegreid, Tarjei and Sandal, Paul Christian},
title = {Financial News Mining: Monitoring Continuous Streams of Text},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.80},
doi = {10.1109/WI.2006.80},
abstract = {This paper addresses the problem of extracting, analyzing and synthesizing valuable information from continuous text streams covering financial information. A text mining framework combining elements from information retrieval, information extraction and natural language processing has been implemented. The framework is utilized to extract information regarding key actors in the domain, how they relate to each other, and how these characteristics evolve over time.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {321–324},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.32,
author = {Khasawneh, Natheer and Chan, Chien-Chung},
title = {Active User-Based and Ontology-Based Web Log Data Preprocessing for Web Usage Mining},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.32},
doi = {10.1109/WI.2006.32},
abstract = {User identification and session identification are two major steps in preprocessing web log data for web usage mining. This paper introduces a fast active user-based user identification algorithm with time complexity O(n). The algorithm uses both an IP address and a finite users' inactive time to identify different users in the web log. Website ontology is useful for identifying website structure and break points for browsing behavior. For session identification, we present an ontology-based method that utilizes the website structure and functionalities to identify different sessions.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {325–328},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.153,
author = {Kudelka, Milos and Snasel, Vaclav and Lehecka, Ondrej and El-Qawasmeh, Eyas},
title = {Semantic Analysis of Web Pages Using Web Patterns},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.153},
doi = {10.1109/WI.2006.153},
abstract = {This paper introduces a novel method for semantic analysis of web pages. Analysis is performed with regard to unwritten and empirically proven agreement between users and web designers using web patterns. This method is based on extraction of patterns which are characteristics for concrete domain. Patterns provide formalization of the agreement and allow assignment of semantics to parts of web pages. Experimental results verify the effectives of the proposed method.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {329–333},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.163,
author = {Lin, Xu-Dong and Peng, Hong and Liu, Bo},
title = {Support Vector Machines for Text Categorization in Chinese Question Classification},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.163},
doi = {10.1109/WI.2006.163},
abstract = {Question classification plays a crucial important role in the question answering system because categorizing a given question is beneficial to identify an answer in the documents. The goal of question classification is to accurately assign labels to question based on expected answer type. Recently, many machine learning algorithms are used for question classification. However many research results show that SVM perform best in this task, because it is well known to work well for nonlinear, sparse, high dimensional problems. In this experiment, we perform the One-against-One SVM algorithm and a feature extraction method of Chinese questions to get high classification accuracy.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {334–337},
numpages = {4},
keywords = {Semantic Dependency Relationship, Feature Extraction, Support Vector Machines, Question Classification},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.171,
author = {Mori, Masaki and Miura, Takao and Shioya, Isamu},
title = {Topic Detection and Tracking for News Web Pages},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.171},
doi = {10.1109/WI.2006.171},
abstract = {This paper propose a new approach to observe, summarize and track events from a collection of news Web Pages. Given a set of temporal Web pages, we obtain valid timestamp from Web pages and detect events by means of clustering. Then we track events by using KeyGraph based on the clusters and abstract the clusters by using SuffixTree. We examine some experimental results and show the usefulness of our approach.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {338–342},
numpages = {5},
keywords = {Web Abstraction, Web Mining, TDT},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.75,
author = {Murata, Tsuyoshi and Saito, Kota},
title = {Extracting Users' Interests from Web Log Data},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.75},
doi = {10.1109/WI.2006.75},
abstract = {Analyzing users' Web log data and extracting their interests of Web-watching behaviors are important and challenging research topics of Web usage mining. Users visit their favorite sites and sometimes search new sites by performing keyword search on search engines. Users' Web-watching behaviors can be regarded as a graph since visited Web sites and entered search keywords are connected with each other in a time sequence. We call this graph a site-keyword graph. This paper describes a method for clarifying users' interests based on an analysis of the site-keyword graph. The method is for extracting subgraphs representing users' main interests from a site-keyword graph which is generated from augmented Web audience measurement data (Web log data). Experimental results show that our new method succeeds in finding subgraphs which contain most of the sites that users are interested in.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {343–346},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.81,
author = {Okubo, Yoshiaki and Haraguchi, Makoto},
title = {Finding Conceptual Document Clusters with Improved Top-N Formal Concept Search},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.81},
doi = {10.1109/WI.2006.81},
abstract = {In this paper, we discuss a method for conceptual clustering of documents. Our cluster is defined with the notion of Formal Concept Analysis which can provide a conceptual meaning for each document cluster. Our clustering is formalized as a Top-N delta-valid formal concept problem. We improve our previous clique search-based algorithm for the problem so that it can be applied to larger scale datasets. For more efficient computation, we present some pruning rules based on theoretical properties of formal concepts. A depth-first branch-and-bound algorithm with the prunings is designed. Our experimental results show valuable clusters can be extracted from a collection of web documents. Moreover, the algorithm outperforms some fast algorithms for mining closed itemsets equivalent to formal concepts.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {347–351},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.191,
author = {Choy, Sheung-On and Lui, Andrew K.},
title = {Web Information Retrieval in Collaborative Tagging Systems},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.191},
doi = {10.1109/WI.2006.191},
abstract = {Collaborative tagging on the web has been quickly gaining ground as a new paradigm for web information retrieval, discovering and filtering. There are a number of successful deployments of collaborative tagging systems that effectively recruits the activity of human users into collecting and annotating vast amounts of web resources. They lead to an emergent categorization of web resources in terms of tags, and create a different kind of web directory. However, the current ways of exploration in the tagging space are limited, which cannot get the most out of the real value of it. This paper presents our methodology, observations, and experimental results in the way we propose how to improve the user experience in exploring information captured by collaborative tagging systems.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {352–355},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.94,
author = {Ren, Jiadong and Zhang, Xiaojian and Peng, Huili},
title = {IMFTS: High-Speed Mining Frequent Traversal Sequences with Bidirectional Constraints},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.94},
doi = {10.1109/WI.2006.94},
abstract = {An important application of sequential mining technique is frequent traversal sequence (FTS) mining. However, the web data grows quickly, some data may be outdated, and previous FTS may be changed when the database is updated. We have to re-mine FTS from the updated database, but re-finding FTS will consume too much execution time. In this paper, a novel structure, IE-LATTICE (improved extended lattice) is designed to store the previous FTS. An efficient algorithm based on bidirectional constraint, IMFTS (incremental mining frequent traversal sequence) is proposed, which utilizes the previous mining results and constraint strategy to discover the new FTS just from the added and deleted part of the database. Experimental results show that IMFTS algorithm efficiently reduces the execution time for mining FTS.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {356–360},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.98,
author = {Rios, Sebastian A. and Velasquez, Juan D. and Vera, Eduardo S. and Yasuda, Hiroshi and Aoki, Terumasa},
title = {Improving Web Site Content Using a Concept-Based Knowledge Discovery Process},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.98},
doi = {10.1109/WI.2006.98},
abstract = {Nowadays many organizations and enterprises have a web site to help accomplish several business goals from sales to customer support. A very important activity for today's managers is how to improve the experience of visitors in their web site and make it more effective. Several techniques that use knowledge from visitors' browsing behavior have shown good results to perform such task. However, how to introduce semantics into web usage mining techniques is still a challenge. This work presents a way to obtain a semantic classification of visitors' sessions using a conceptual mining process. We performed experiments in a real web site.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {361–365},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.59,
author = {Teng, Chun-Yuan and Chen, Hsin-Hsi},
title = {Detection of Bloggers' Interests: Using Textual, Temporal, and Interactive Features},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.59},
doi = {10.1109/WI.2006.59},
abstract = {As the blogs have become pervasive media in these years, the number of bloggers has increased at an exponential rate. Mining the bloggers' characteristics, such as age, gender, emotions, etc., has attracted much attention recently. In this paper, we describe our work on the detection of bloggers' interest from three kinds of important features containing in blogs. Textual features include the interest-related words. Temporal features are used to analyze bloggers' posting frequency in order to model the strength of bloggers' interest. Interactive features are represented by the comments posted by bloggers to identify the bloggers' interactivity in blogsphere. By incorporating textual, temporal, and interactive features, our system can be able to automatically identify the interest of bloggers. Experimental results in several topics show that these features work well in the detection of bloggers' interest.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {366–369},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.167,
author = {Tseng, Yi-Feng and Kao, Hung-Yu},
title = {The Mining and Extraction of Primary Informative Blocks and Data Objects from Systematic Web Pages},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.167},
doi = {10.1109/WI.2006.167},
abstract = {With the fast development of Internet, the Web has already been an enormous database so far, which contains extremely abundant information. Most of Web pages are represented their content by using a list of objects, such as search engine results, product information of shopping Web sites and so on, and these objects form the primary information of each page. In this paper, we focus on the issues of mining primary information and the constituted object groups. The system is divided into three major phases: (1) By transforming each Web page into corresponding tree structures, our system can visit all regions of the Web page in an efficient way, and detects the informative parts. (2) We design and quantize several novel features according to the characters of regions of a Web page. (3) A weighting model is proposed that calculates the important degree of each region, we then extract the primary information of the Web pages. The experimental result proves our system can be applied to a large number of Web pages with different themes and styles to find the correct primary information and the list of corresponding objects.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {370–373},
numpages = {4},
keywords = {DOM, Information Extraction, Block Importance},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.57,
author = {Vuong, Le Phong Bao and Gao, Xiaoying and Zhang, Mengjie},
title = {Data Extraction from Semi-Structured Web Pages by Clustering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.57},
doi = {10.1109/WI.2006.57},
abstract = {This paper introduces an approach to the use of clustering for data extraction from semi-structured Web pages. A variant Hierarchical Agglomerative Clustering (HAC) algorithm K-neighbours-HAC is developed which uses the similarities of the data format (HTML tags) and the data content (text string values) to group similar text tokens into clusters. Using these clusters, similar text tokens are identi- fied as data fields and extracted as target information. The approach is examined and compared with a number of existing information extraction systems on two different sets of web pages and the results suggest that the new approach is effective for web information extraction and that it outperforms all of the existing approaches on these web sites.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {374–377},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.121,
author = {Wei, Yu-Chuan and Lin, Ming-Shun and Chen, Hsin-Hsi},
title = {Name Disambiguation in Person Information Mining},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.121},
doi = {10.1109/WI.2006.121},
abstract = {This paper considers five features, personal titles, community chains, terms, temporal expressions, and hostnames for personal name disambiguation. In 9 test data sets covering 3 ambiguous personal names, we address the issues of awareness degree of an entity, the source of materials and web pages in different areas. Two approaches, single-clusterer and cascaded multiple-clusterer, are proposed. In the experiments, the proposed features are quite useful; the multiple-clusterer approach is better than the single-clusterer approach; and expanding community chains using the web has positive effects on personal name disambiguation.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {378–381},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.76,
author = {Yamada, Takayuki and Sakano, Daisaku and Yasumura, Yoshiaki and Uehara, Kuniaki},
title = {Extraction of Reliable Reputation Information Using Contributor's Stance},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.76},
doi = {10.1109/WI.2006.76},
abstract = {This paper describes a method for extracting reliable reputation on the Web. In this research, reliable reputation is the information that has an opposite polarity value of contributor's stance (positive or negative). We call this information "fair reputation". In order to extract fair reputations, we develop the following two tasks. The first task is classification of feedback documents into positive or negative classes. For this task, we propose a classification method using 'Document level reputation' that can determine the polarity value of the document. The second task is extraction and classification of reputations. Using the classified reputations, we extract "fair reputations". The experimental results using movie reviews showed that the proposed method could classify feedback documents more correctly than the previous method, and that fair reputations are useful for evaluating reputations.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {382–385},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.189,
author = {Yang, Kai-Hsiang and Chiou, Kun-Yan and Lee, Hahn-Ming and Ho, Jan-Ming},
title = {Web Appearance Disambiguation of Personal Names Based on Network Motif},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.189},
doi = {10.1109/WI.2006.189},
abstract = {Searching for information about a particular person is a common activity on search engines. However, current search engines do not provide any special function for search a person. Previous research has solved the problem by using additional background knowledge, such as a friend list, to cluster the searched web pages. However, it is still difficult to retrieve and choose suitable background knowledge. In this paper, we propose a Web Appearance Disambiguation (WAD) system to solve the problem by only using the hyperlink structures between web pages. The key idea of the WAD system is to find out smaller node motifs as evidences of close relationship between pages for clustering searched web pages. Our experimental results show that, under no background knowledge, the performance of the WAD system achieves 70% for the F-measure.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {386–389},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.110,
author = {Zhao, Jing and He, Jing},
title = {Learning to Generate Labels for Organizing Search Results from a Domain-Specified Corpus},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.110},
doi = {10.1109/WI.2006.110},
abstract = {Organizing Web search results into labeled categories is a difficult but very useful task. The idea is to group the many results that each user query generates into well-labeled categories, so that users can find it much easier to browse these results. In the past, clustering-based methods have been applied to solve the search-result organization problem, but it has been difficult to extract the human-readable descriptions for these clusters. An alternative solution to this problem is to generate a series of labels from search results firstly, and then assign documents to relevant labels to form labeled categories. In this approach, a major task is how to generate the labels for the documents. In this paper, we propose a novel label generation method: Firstly, we extract some phrases as candidates of labels based on the search results, and adopt a binary classifier as our learning model to classify these label candidates into useful or meaningless label category. Then, the candidates in the useful label category form the final results. As our method is applied on the search results which are retrieved from a domain-specified corpus instead of general corpus, there're some special features of the labels for classification. Experimental results show that the accuracy of our system is nearly 10% higher than using the mutual information criterion, which is an unsupervised method for solving this problem, to do the label selection.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {390–396},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.105,
author = {Abulaish, Muhammad and Dey, Lipika},
title = {Interoperability among Distributed Overlapping Ontologies--A Fuzzy Ontology Framework},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.105},
doi = {10.1109/WI.2006.105},
abstract = {Ontologies are proposed as a means for knowledge sharing among applications but, it is often not possible to converge to a single unambiguous ontology that is acceptable to all knowledge engineers. Different ontologies vary greatly in terms of the level of detail of their representations, as well as the nature of their underlying logical specifications. Interoperability among different ontologies becomes essential to gain from the power of the existing domain ontologies. In this paper we have proposed a fuzzy ontology framework in which a concept descriptor is represented as a fuzzy relation which encodes the degree of a property value using a fuzzy membership function. Other than concept descriptors, the semantic relations in the ontology like ISA, HAS-PART etc. are also associated a strength of association. The strength of association between two concepts determines the "uniformity" with which these two concepts have been defined identically across different ontologies. The fuzzy ontology framework provides appropriate support for application integration by identifying the most likely location of a particular term in the ontology.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {397–403},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.28,
author = {Bao, Jie and Caragea, Doina and Honavar, Vasant},
title = {A Tableau-Based Federated Reasoning Algorithm for Modular Ontologies},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.28},
doi = {10.1109/WI.2006.28},
abstract = {Many real world applications of ontologies call for reasoning with modular ontologies. We describe a tableau-based reasoning algorithm based on Package-based Description Logics (P-DL), an modular ontology language that extends description logics. Unlike Classical approaches that assume a single centralized, consistent ontology, the proposed algorithm adopts a federated approach to reasoning with modular ontologies wherein each ontology module has associated with it, a local reasoner. The local reasoners communicate with each other as needed in an asynchronous fashion. Hence, the proposed approach offers an attractive approach to reasoning with multiple, autonomously developed ontology modules, in settings where it is neither possible nor desirable to integrate all involved modules into a single centralized ontology.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {404–410},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.83,
author = {Eiter, Thomas and Ianni, Giovambattista and Schindlauer, Roman and Tompits, Hans and Wang, Kewen},
title = {Forgetting in Managing Rules and Ontologies},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.83},
doi = {10.1109/WI.2006.83},
abstract = {The language of HEX-programs under the answer-set semantics is designed for interoperating with heterogeneous sources via external atoms and for meta-reasoning via higher-order literals in the context of the Semantic Web. As an important technique in managing knowledge bases, the notion of forgetting has received increasing interest in the knowledge-representation area. In this paper, we introduce a semantics-based theory of forgetting for HEX-programs and, in turn, for a class of OWL/RDF(S) ontologies which allows to fully employ semantic information in managing ontologies like editing, merging, aligning, and redundancy removal.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {411–419},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.55,
author = {Karoui, Lobna and Aufaure, Marie-Aude and Bennacer, Nacera},
title = {Context-Based Hierarchical Clustering for the Ontology Learning},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.55},
doi = {10.1109/WI.2006.55},
abstract = {Ontologies provide a common layer which plays a major role in supporting information exchange and sharing. In this paper, we focus on the ontological concept extraction process from HTML documents. In order to improve this process, we propose an unsupervised hierarchical clustering algorithm namely "Contextual Ontological Concept Extraction" (COCE) which is an incremental use of the partitioning algorithm Kmeans and is guided by a structural context. Our context exploits the html structure and the location of words to select the semantically closer cooccurrents for each word and to improve the words weighting. Guided by this context definition, we perform an incremental clustering that refines the context of each word clusters to obtain semantically extracted concepts. The COCE algorithm offers the choice between either an automatic execution or a user's interaction. We experiment our algorithm on HTML documents related to the tourism domain. Our results show how the execution of our context-based algorithm which implements an incremental process and a successive refinement of clusters improves their conceptual quality and the relevance of the extracted ontological concepts.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {420–427},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.11,
author = {Lam, Sik Chun and Pan, Jeff Z. and Sleeman, Derek and Vasconcelos, Wamberto},
title = {A Fine-Grained Approach to Resolving Unsatisfiable Ontologies},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.11},
doi = {10.1109/WI.2006.11},
abstract = {In the Semantic Web, inconsistencies in OWL on- tologies may easily occur. Existing approaches ei- ther identify the minimally unsatisfiable sub-ontologies or calculate the maximally satisfiable sub-ontologies. However practical problems remain; it is not clear which axioms or which parts of axioms should be se- lected for repair, and how to repair those axioms. In this paper, we address this limitation by proposing a fine-grained approach to resolving unsatisfiable ontolo- gies. We revise the axiom tracing technique first pro- posed by Baader and Hollunder, so as to track which parts of the problematic axioms cause the unsatisfiabil- ity. Moreover, we support ontology users in rewriting problematic axioms. In order to minimise the impact of changes and prevent unintended entailment loss, harm- ful and helpful changes are identified and provided as guidelines. Based on the methods described we present a preliminary version of an interactive debugging tool and demonstrate its applicability in practice.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {428–434},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.148,
author = {Li, Yingjie and Yu, Xueli and Geng, Lili and Wang, Li},
title = {Research on Reasoning of the Dynamic Semantic Web Services Composition},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.148},
doi = {10.1109/WI.2006.148},
abstract = {The Description Logic, which possesses strong knowledge representation and reasoning capabilities, is the logic basis of the Semantic Web ontology languages such as OWL and OWL-S, but OWL and OWL-S are deficient in the semantic modeling of the dynamic services composition and also do not consider the user preferences in the dynamic services composition. The AI planning, which provides an effective method for solving the planning problem and task decomposition in AI, possesses better modeling capability of the action state transformation, but the AI planning is limited in the knowledge representation and reasoning capabilities. Based on the merits of the Description Logic, OWL-S and the AI planning, this paper extends the OWL-S model, proposes a service composition mechanism and testifies its feasibility in Description Logic. The results show that this composition mechanism can not only be feasible but also be helpful for the semantic modeling of the services composite process in the Semantic Web.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {435–441},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.119,
author = {Milne, David and Medelyan, Olena and Witten, Ian H.},
title = {Mining Domain-Specific Thesauri from Wikipedia: A Case Study},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.119},
doi = {10.1109/WI.2006.119},
abstract = {Domain-specific thesauri are high-cost, high-maintenance, high-value knowledge structures. We show how the classic thesaurus structure of terms and links can be mined automatically from Wikipedia. In a comparison with a professional thesaurus for agriculture we find that Wikipedia contains a substantial proportion of its concepts and semantic relations; furthermore it has impressive coverage of contemporary documents in the domain. Thesauri derived using our techniques capitalize on existing public efforts and tend to reflect contemporary language usage better than their costly, painstakingly-constructed manual counterparts.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {442–448},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.158,
author = {Morneau, Maxime and Mineau, Guy W. and Corbett, Dan},
title = {SeseiOnto: Interfacing NLP and Ontology Extraction},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.158},
doi = {10.1109/WI.2006.158},
abstract = {For many years, information retrieval tools have been used to try to solve the information overload problem which was accentuated by the coming of age of the World Wide Web. Some tools used Boolean search, others, natural language based processing (NLP). Ontology-based techniques were proposed to improve the quality of the search but none were widely adopted since they did not statistically enhance either the recall or the precision of the search. However, when it comes to information extraction, they may be of significant help. Their integration in professional search engines has been rather slow, partially due to the fact that the ontology building process is time consuming. In this paper, we describe the SeseiOnto software, which uses simple artificial intelligence techniques to improve information extraction and retrieval. To assist the NLP-based information retrieval on a corpus of documents, SeseiOnto employs an automatically generated ontology. Under our experiments, we found that SeseiOnto obtained results comparable to a traditional search engine, while providing a natural language interface to its user.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {449–455},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.92,
author = {Schonhofen, Peter},
title = {Identifying Document Topics Using the Wikipedia Category Network},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.92},
doi = {10.1109/WI.2006.92},
abstract = {In the last few years the size and coverage of Wikipe- dia, a freely available on-line encyclopedia has reached the point where it can be utilized similar to an ontology or tax- onomy to identify the topics discussed in a document. In this paper we will show that even a simple algorithm that exploits only the titles and categories of Wikipedia articles can characterize documents by Wikipedia categories sur- prisingly well. We test the reliability of our method by pre- dicting categories ofWikipedia articles themselves based on their bodies, and by performing classification and cluster- ing on 20 Newsgroups and RCV1, representing documents by their Wikipedia categories instead of their texts.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {456–462},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.99,
author = {Tenier, S. and Toussaint, Y. and Napoli, A. and Polanco, X.},
title = {Instantiation of Relations for Semantic Annotation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.99},
doi = {10.1109/WI.2006.99},
abstract = {This paper presents a methodology for the semantic annotation of web pages with individuals of a domain ontology. While most semantic annotation systems can recognize knowledge units, they usually do not establish explicit relations between them. The method presented identifies the individuals which should be related among the whole set of individuals and codes them as role instances within an OWL ontology. This is done by using a correspondance between the tree structure of a web page and the semantics of the information it contains.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {463–472},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.65,
author = {Deng, Shuang and Peng, Hong},
title = {Document Classification Based on Support Vector Machine Using a Concept Vector Model},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.65},
doi = {10.1109/WI.2006.65},
abstract = {This paper proposes a new method for document categorization, based on support vector machine (SVM) using a concept vector model (CVM). The traditional document classification usually ignores the semantic relations among the keywords or documents. To effectively solve the semantic problem, the domain ontology is used to capture the semantic information among different terms or keywords in the documents. Using the concept vector model, domain-related semantic information more exactly from documents can be extracted. In the model, concept vector is extracted from a document by the matching method. According to concept features of the documents, documents are classified into a suitable category by SVM. The experimental results show that our CVM method yields higher accuracy compared to the traditional term-based vector space model (VSM) methods.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {473–476},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.16,
author = {Fan, Lisa and Li, Botang},
title = {A Hybrid Model of Image Retrieval Based on Ontology Technology and Probabilistic Ranking},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.16},
doi = {10.1109/WI.2006.16},
abstract = {There are hundreds of millions of images available on the current World Wide Web. The demand for image retrieval online is growing dramatically. For multimedia documents, the typical keyword-based retrieval method has encountered problems mainly in the areas of: 1) the quality of the search result; 2) the usage of the system. With the advent and development of the Semantic Web, information retrieval can widely take advantage of this technology which is expected as the next generation of internet. However, before shifting up to the Semantic Web generation, there are still numerous resources on the current Web without semantic annotation. In this paper, we propose a hybrid retrieval method which is based on the current Web, keyword-based annotation structure, and combining Ontology-guided reasoning and probabilistic ranking. A Web application for image retrieval using our proposed approach has been implemented. Furthermore, the system offers recommendations to the user to demonstrate the effectiveness of the model. Experimental results show that the image retrieval recall and precision rates increase by using the proposed hybrid approach.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {477–480},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.95,
author = {Fang, Jun and Guo, Lei and Wang, XiaoDong and Chen, Liang and Yang, Ning and Yang, WeiLi},
title = {Importance of Entities in Knowledge},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.95},
doi = {10.1109/WI.2006.95},
abstract = {There is a growing need for managing importance of entities in knowledge system in order to realize the full potential of knowledge. How to calculate the importance of entities automatically is the primary issue. We argue that importance of entities in knowledge is dynamic, the importance is changed along with the using of ontology; and different groups of user have different criteria of importance. In this paper, a novel weight assignment method which takes usage and structure properties of ontology into account is proposed. When considering the usage information of ontology, we analyze paths that are used to respond to queries; and use the frequency of entities included in the paths to produce the optimal weight assignment for the assumption of high importance of entities which included in paths that respond to queries. After get the initial weight of entities, a pervasion algorithm which considers the structure of ontology is used to compute the final weight of entities. Weight of a node is high if the node has many incoming links and the incoming links and nodes which these links are from have high scores. Experiment show effectiveness of this weight assignment method.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {481–484},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.174,
author = {Hoang, Hanh Huu and Andjomshoaa, Amin and Tjoa, A Min},
title = {Towards a New Approach for Information Retrieval in the SemanticLIFE Digital Memory Framework},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.174},
doi = {10.1109/WI.2006.174},
abstract = {This paper presents a new approach in guiding users to formulate unambiguous queries based on their common nature of asking for information. The approach known as the "front-end approach" gives users an overview about the system data through a "virtual data component" which stores the merged metadata of data storage sources. Based on this component, users are aware of their stored data while generating requests. This approach reduces the ambiguities in users' requests at very early stage; and this makes the query refinement process easily fulfill users' demands.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {485–488},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.184,
author = {Haydarlou, A. R. and Oey, M. A. and Overeinder, B. J. and Brazier, F. M. T.},
title = {Using Semantic Web Technology for Self-Management of Distributed Object-Oriented Systems},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.184},
doi = {10.1109/WI.2006.184},
abstract = {Automated support for management of complex distributed object-oriented systems is a challenge: selfmanagement the goal. A self-management system needs to reason about the behaviour of the distributed entities in a system, and act when necessary. The knowledge needed is multi-leveled: different levels of concepts and rules need to be represented. This paper explores the requirements that hold for representing this knowledge in self-managed distributed object-oriented systems, and explores the potential of Semantic Web technology in this context. A model for self-management knowledge and a simplified version of a real-life use case are used to illustrate the potential.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {489–493},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.24,
author = {Hoon, Gan Keng and Keong, Phang Keat and Kong, Tang Enya},
title = {A Semantic Learning Approach for Mapping Unstructured Query to Web Resources},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.24},
doi = {10.1109/WI.2006.24},
abstract = {The search that involves structured web resources like XML data, services is still lagging of its own method and relying on contemporary search systems. This paper presents a method that learns semantics from structured information of these resources. Instead of committing the semantic meaning of resources to strict and formal vocabularies like ontology or data dictionary, we are interested to interpret the meaning based on the natural context of the resources. The semantics are used in search process, i.e. query reasoning and resource selection, to provide better answer in terms of context relevancy and clearer result description.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {494–497},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.23,
author = {Khaing, Aye Aye and Thein, Ni Lar},
title = {A Persistent Labeling Scheme for Dynamic Ordered XML Trees},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.23},
doi = {10.1109/WI.2006.23},
abstract = {XML is becoming the new standard for the exchange and publishing of data over the Internet. Documents obeying the XML standard can be viewed as trees basically the parse tree of the document. XML database systems often give each item in the document (node in the tree) a unique logical identifier (called a label) and use those labels for an efficient processing of queries, in particular queries involving structural conditions or testing for changes in the document content. Therefore several path indexing and numbering schemes have been proposed. XML data on the Web are subjected to frequent updates. During the update on XML data, most of these approaches will need to recompute existing labels, which is rather time consuming. The goal of our labeling scheme is to design a persistent structural labeling scheme that supports the representation of ancestor-descendant relationship and sibling relationship between nodes. Moreover our labeling scheme supports insertion of new nodes at arbitrary positions in the XML tree without re-labeling and without conflicting existing labels.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {498–501},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.56,
author = {Khan, Javed I. and Ma, Yongbin and Hardas, Manas},
title = {Course Composition Based on Semantic Topical Dependency},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.56},
doi = {10.1109/WI.2006.56},
abstract = {This paper describes an approach that can facilitate composition of course materials by machine assistance over the web using semantic web technology. A Semantic Topic Graph (STG) that encodes the conceptual knowledge metadata space is used as the front-end to the course resources. STG provides ontologies and properties of the concepts space and course materials are then connected with respect to their relation to this concept space. A course composer system is demonstrated which can intelligently compose various course materials based on pedagogical consideration. Some interesting comparisons of human guided machine-composed courses with real human composed courses in use in US graduate programs are shown.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {502–505},
numpages = {4},
keywords = {Ontology, RDF, and Composition Algorithm, Semantic Topic Graph},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.85,
author = {Lam, Toby H. W.},
title = {Fuzzy Ontology Map--A Fuzzy Extension of the Hard-Constraint Ontology},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.85},
doi = {10.1109/WI.2006.85},
abstract = {In Semantic Web, descriptive markup languages, such as Resource Description Framework (RDF) and Ontology Web Language (OWL), were proposed to model the web content in a machine-readable way. Since these ontology markup languages deals with hard semantics in the description and manipulation of crisp data. It is not able to represent uncertain information. The work described in this paper is about developing an extension of the current ontology representation which supports uncertain information modeling. The extension is called Fuzzy Ontology Map (FOM) which is based on fuzzy theory and graph theory. FOM is a connection matrix which collects the membership value between classes in the ontology. We define a set of algorithms for inferring fuzzy relationship in the FOM.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {506–509},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.150,
author = {Liu, Sheng and Zhang, Jian},
title = {Retrieving and Matching RDF Graphs by Solving the Satisfiability Problem},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.150},
doi = {10.1109/WI.2006.150},
abstract = {The Resource Description Framework (RDF) has been ac- cepted as a standard for semantic representation of re- sources. Efficient methods and tools are needed to solve problems emerging from RDF based systems, for exam- ple, checking equality of two RDF graphs and retrieving subgraphs from another RDF graph. This paper proposes a method that encodes these problems into satisfiability (SAT) instances and solves them by employing efficient SAT solvers. A prototype tool is implemented and preliminary experimental results are given.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {510–513},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.90,
author = {Mikroyannidis, Alexander and Theodoulidis, Babis},
title = {Heraclitus II: A Framework for Ontology Management and Evolution},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.90},
doi = {10.1109/WI.2006.90},
abstract = {Ontologies are commonly used as a semantically rich knowledge base in systems that specialize in management of unstructured information. However, the knowledge that ontologies represent is not static, but evolves over time, thus requiring appropriate ontology management and evolution mechanisms. This paper presents Heraclitus II, a framework for ontology management and evolution in the context of information management systems. By addressing specific needs of such systems, Heraclitus II aims at providing an easily maintained and constantly updated knowledge base.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {514–521},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.87,
author = {Peng, Yefei and He, Daqing and Mao, Ming},
title = {Geographic Named Entity Disambiguation with Automatic Profile Generation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.87},
doi = {10.1109/WI.2006.87},
abstract = {Knowledge rich approach of processing documents has been viewed as a method to improve over simple bag-of- word representation. Extracting location information from documents and link them to some ontology such as world gazetteer through a disambiguation process becomes an interesting and important topic. Lacking of training data is a problem in disambiguation method. In this paper we described a method to automatically extract training data from large collection of documents based on local context disambiguation, and then sense profiles are generated automatically for disambiguation use. Another topic of this paper is to describe a linear combination method to combine different types of evidences of disambiguation. We explored three different evidences including location sense context in training documents, local neighbor context, and the popularity of individual location sense. Our results show that combining the three evidences generates reasonable results.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {522–525},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.48,
author = {Sie, Shun-hong and Yeh, Jian-hua},
title = {Automatic Ontology Generation Using Schema Information},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.48},
doi = {10.1109/WI.2006.48},
abstract = {This paper discusses the automatic ontology generation process in a digital library. Traditional automatic ontology generation uses hierarchical clustering to group similar terms, and the result hierarchy is usually not satisfactory for human's recognition. Human-provided knowledge network presents strong semantic features, but this generation process is both labor-intensive and inconsistent under large scale scenario. The method proposed in this paper combines the results of specific knowledge network and automatic ontology generation from metadata in a digital library, which produces a human-readable, semantic-oriented hierarchy. This generation process can efficiently reduce manual classification efforts, which is an exhausting task for human beings. An evaluation method is also proposed in this paper to verify the quality of the result hierarchy.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {526–531},
numpages = {6},
keywords = {cluster partitioning, hierarchical clustering, concept hierarchy, ontology, digital library.},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.49,
author = {Tao, Xiaohui and Li, Yuefeng and Zhong, Ning and Nayak, Richi},
title = {Automatically Acquiring Training Sets for Web Information Gathering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.49},
doi = {10.1109/WI.2006.49},
abstract = {The traditional techniques rely on human effort to acquire training sets, which is expensive and inefficient. In this paper we present an alternative method to automatically acquire training sets without heavy investment of user efforts. The proposed method tends to fill a gap for effectiveness of using Web data in Web mining, and contributes to Web information gathering. The evaluation shows that the method is adequate to yield an promising achievement.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {532–535},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.100,
author = {Wang, Chao and Lu, Jie and Zhang, Guangquan},
title = {Integration of Ontology Data through Learning Instance Matching},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.100},
doi = {10.1109/WI.2006.100},
abstract = {Information integration with the aid of ontology can roughly be divided into two levels: schema level and data level. Most research has been focused on the schema level, i.e., mapping/matching concepts and properties in different ontologies with each other. However, the data level integration is equally important, especially in the decentralized Semantic Web environment. Noticing that ontology data (in the form of instances of concepts) from different sources often have different perspectives and may overlap with each other, we develop a matching method that utilizes the features of ontology and employs the machine learning approach to integrate those instances. By exploring ontology features, this method performs better than other general methods, which is revealed in our experiments. Through the process that implements the matching method, ontology data can be integrated together to offer more sophisticated services.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {536–539},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.190,
author = {Wu, Terry Chia-Wei and Hsu, Wen-Lian},
title = {Web Directory Integration Using Conditional Random Fields},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.190},
doi = {10.1109/WI.2006.190},
abstract = {The purpose of integrating web directories is to transfer instances from a source to a target directory. Unlike con-ventional text categorization, in directory integration, there is extra information about the source directory that can be used to improve the classification accuracy. Many approaches exploit the measured similarity between two corresponding classes to enhance traditional text classifi-ers. These methods perform well if the topics of two classes are very similar, but they could lead to misclassifi-cation if the topics are dissimilar. We propose a directory integration approach based on the conditional random fields (CRFs) model, and model the integration process using a finite-state model. The advantage of using CRFs is that the transition features naturally include information about the relations between classes. Our results show that CRFs outperform conven-tional text classifiers. In addition, CRFs allow us to apply complex features to integrate the information about the contents of class and their labels. The performance of our approach can be improved by applying these features, especially for instances whose source and target classes are moderately similar.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {540–543},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.175,
author = {Xu, Youwei and Tang, Shengqun and Yang, Yan and Xu, Yang},
title = {Towards a Selective Inference Platform Based on OWL},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.175},
doi = {10.1109/WI.2006.175},
abstract = {In this paper we propose an selective inference platform based on OWL language. The platform includes a visual ontology design toolkit(VO-Editor) and a selective inference algorithm engine based on graph. We introduce the VO-editor and propose the principle of selective inference algorithm. At last, a case of budget travel system is used to interpret how the platform is performed.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {544–547},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.114,
author = {Xu, Zhuoming and Zhang, Shichao and Dong, Yisheng},
title = {Mapping between Relational Database Schema and OWL Ontology for Deep Annotation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.114},
doi = {10.1109/WI.2006.114},
abstract = {Creating mappings between database schema and Web ontology is a preconditioning process in the generation of ontological annotations for dynamic Web page contents extracted from the database. In this paper, a practical approach to creating mappings between a relational database schema and an OWL ontology is presented. The approach can automatically construct the mappings by following a set of predefined heuristic rules based on the conceptual correspondences between the schema and the ontology. This automatic mapping is implemented as the core functionality in a prototype tool D2OMapper that has some assistant functions to help the user manually create and maintain the mappings. Case studies show that the proposed approach is effective and the produced mappings can be applied to semantic annotation of database-based, dynamic Web pages.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {548–552},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.173,
author = {Zhou, Jiehan and Niemela, Eila},
title = {Toward Semantic QoS Aware Web Services: Issues, Related Studies and Experience},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.173},
doi = {10.1109/WI.2006.173},
abstract = {Semantic QoSaware Web services incorporating the emerging Web services in the QoSaware system development are promoting ServiceOriented Software Engineering (SOSE). To identify the steps toward semantic quality of service (QoS)aware Web services, this paper examines previous studies related to semantic QoSaware Web services, including QoSaware Web service architectures, QoS classification, QoS ontology, QoS specification languages, and Web service creation tools. Moreover, a case study is presented to discuss the gaps between our current quality driven software development approach and the semantic QoSaware Web services.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {553–557},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.186,
author = {Zhou, Xujuan and Wu, Sheng-Tang and Li, Yuefeng and Xu, Yue and Lau, Raymond Y. K. and Bruza, Peter D.},
title = {Utilizing Search Intent in Topic Ontology-Based User Profile for Web Mining},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.186},
doi = {10.1109/WI.2006.186},
abstract = {It is well known that taking the Web user profiles into account can enhance the effectiveness of Web mining systems. However, due to the dynamic and complex nature of Web users, automatically acquiring worthwhile user profiles was found to be very challenging. Ontology-based user profile can possess more accurate user information. This research emphasizes on acquiring search intentions information. This paper presents a new approach of developing user profile for Web searching. The model considers the user's search intentions by the process of PTM (Pattern-Taxonomy Model). Initial experiments show that the user profile based on search intention is more useful than the generic PTM user profile. Developing user profile that contains user search intentions is essential for effective Web search and retrieval.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {558–564},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.159,
author = {Fung, T. H.},
title = {Specifications and Rapid Prototyping of Multi-Agent Systems through Coloured Petri Net Represented in Abductive Logic Programming (CPN-LP)},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.159},
doi = {10.1109/WI.2006.159},
abstract = {Specifications and prototyping are valuable means to help software engineers when developing complicated systems. In this paper, we propose a method for specifying a multi-agent system using coloured Petri net (CPN). By representing the coloured Petri net as an abductive logic programming (which is an extension of logic (LP) programming and is purely based on classical logic), a prototype is immediately resulted. Every inference step of the implementation of the prototype can be regarded as a kind of equivalence preserved transformation. We call our framework CPN-LP and use an example on Dutch auction protocol to illustrate its application.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {565–571},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.84,
author = {Zhang, Shiwu and Liu, Jiming},
title = {From Local Behaviors to the Dynamics in an Agent Network},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.84},
doi = {10.1109/WI.2006.84},
abstract = {A social network can be modelled by a multi-agent system, in which the interaction among agents is represented as a service transaction process. In this paper, we present a service-based agent network to simulate and study the dynamics of social networks. In the network, the profiles of agents and service-based interactions are defined deliberately. Autonomy is emphasized as the ability of agents to manage their behaviors according to the local environment and their profiles. The experimental results reveal that network performance, network topology and the profiles of agents all evolve along with local behaviors. The over-shoot phenomenon in the evolution of network is discovered and analyzed. The discoveries are meaningful for understanding the relationship between network dynamics and local behaviors.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {572–580},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.129,
author = {Picard, David and Cord, Matthieu},
title = {Performances of Mobile-Agents for Interactive Image Retrieval},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.129},
doi = {10.1109/WI.2006.129},
abstract = {In this paper, we present a system for image retrieval over a network of computer based on "ant-like" mobileagents. Image databases are hosted on the network, and the user wants to find all the images matching a specific concept (cars, flower, Italy, etc...). Usually, content based image retrieval systems (CBIR) do not consider the dispertion of the data among the network. We train a SVM classifier with examples annotated by the user and then launch mobile agents which explore the network in order to retrieve the most relevant images. Several interactive session (launching of agents then annotation of the results) are made to improve the classifier. Experiments are made both to see the influence of localization of the search concept on the quality of the learning, and to focus on the quality of the agent based solution compared to a centralizing system within a fixed amount of time for the interaction.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {581–586},
numpages = {6},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.68,
author = {Binder, Walter and Constantinescu, Ion and Faltings, Boi},
title = {Efficient Service Composition Using Zero-Suppressed Reduced Ordered Binary Decision Diagrams},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.68},
doi = {10.1109/WI.2006.68},
abstract = {Recent algorithms for automated service composition issue many complex queries to service directories. As service directories are shared resources, they may become performance bottlenecks. In order to increase scalability, we introduce a compact directory digest, which is distributed to clients and includes all information needed for automated service composition. Therefore, complex directory queries during service composition can be avoided. We encode a directory digest as a Zero-Suppressed Reduced Ordered Binary Decision Diagram (ZDD). In several steps, we refine a simple service composition algorithm in order to leverage the ZDD representation. Introducing specialized ZDD operations, we achieve a service composition algorithm that scales very well with an increasing size of the directory digest.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {587–593},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.25,
author = {Chen, Liming and Yang, Xueqiang and Tao, Feng},
title = {A Semantic Web Service Based Approach for Augmented Provenance},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.25},
doi = {10.1109/WI.2006.25},
abstract = {Provenance is becoming increasingly important in service-oriented distributed computing environments in which services are dynamically discovered and composed into workflows for problem solving, and disbanded later. This paper proposes a Semantic Web Service (SWS) based approach to creating and exploiting rich provenance data -- the so-called augmented provenance. Augmented provenance enhances conventional provenance data with extensive metadata and semantics, enabling large scale sharing and deep reuse. We present a general architecture for the approach and discuss mechanisms for modelling, capturing, recording and querying provenance data. The approach has been applied to a real world application in which tools and GUIs are developed to facilitate provenance management. Application experiences are discussed.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {594–600},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.124,
author = {Herrero, Pilar and Bosque, Jose Luis and Salvadores, Manuel and Perez, Maria S.},
title = {On Board: Sharing Resources in a Collaborative Grid-TV Environment},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.124},
doi = {10.1109/WI.2006.124},
abstract = {The TV environment is not so different from any other grid computing scenario, as different TV channels can need to share multimedia information and resources to achieve some specific purposes on time. In this paper, we present a web service specification to manage awareness in collaborative grid environments, WS-AMBLE. This specification has been designed by merging web services with multi-agents theories and principles to provide an autonomous, efficient and independent management of the amount of resources available in TV environment. WSAMBLE implementation makes easier the collaboration and cooperation among different TV channels. In this paper, we also present some experimental results carried out over a real and heterogeneous grid environment with the end of emphasizing the performance improvements that WS-AMBLE has in a Grid-TV environment.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {601–607},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.155,
author = {Sriharee, Natenapa},
title = {Semantic Web Services Discovery Using Ontology-Based Rating Model},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.155},
doi = {10.1109/WI.2006.155},
abstract = {Growing attention has been paid to semantic service discovery using ontology-based service description for locating desired services. The service description can be enriched by linking it to a more refined ontology-based specification which represents particular characteristics of the service, including rating. This paper proposes an ontology-based rating model for service quality. Services are rated for quality by a third-party organisation that assigns scores in terms of ontological values. The services will be retrieved by a matching algorithm that follows a flexible match approach and they will be ranked based on service consumers' preference criteria. Using ratings, service discovery can enable service consumers to accurately locate, with confidence, quality services that meet their requirements.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {608–616},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.39,
author = {Chen, Ing-Yi and Huang, Chao-Chi},
title = {An SOA-Based Software Development Management System},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.39},
doi = {10.1109/WI.2006.39},
abstract = {The object of the research was to develop a deployment management framework that supported dynamic reconfiguration for home gateway services. This system uses a Service Oriented Architecture (SOA) that contains four subsystems. These include: a management agent, a deployment management server, a process management module, and an operation portal. The architecture of this system not only improves the efficiency of application delivery, but also provides a platform that can effectively support process changes when needed.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {617–620},
numpages = {4},
keywords = {Service-Oriented Architecture, Deployment Management, OSGi, Home Gateway},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.26,
author = {Ganjisaffar, Yasser and Abolhassani, Hassan and Neshati, Mahmood and Jamali, Mohsen},
title = {A Similarity Measure for OWL-S Annotated Web Services},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.26},
doi = {10.1109/WI.2006.26},
abstract = {Measuring semantic similarity of web services has several benefits and most of the proposed service discovery algorithms are based on measuring the similarity of the requested service with each of the advertised services. In this paper, we propose a method for measuring the similarity of web services which are annotated with OWL-S ontology. First, a semantic similarity measure for determining the similarity of OWL concepts is discussed and then based on this measure, the functional similarity of services is defined. Then it is showed that the precision of algorithms that only take into account the functional properties of services for measuring their similarity are low. Therefore the textual descriptions of web services are also taken into account and the textual similarity of services is also calculated. Then it is showed how Neural Networks can be used for combining these two measures for a better compound measure. The proposed technique is applied to a sample test collection and experimental results are presented which demonstrate the effectiveness of the idea.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {621–624},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.176,
author = {Jiang, Jinlei and Yang, Guangwen and Shi, Meilin},
title = {Towards a Transaction Model for Services in Grid Environment},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.176},
doi = {10.1109/WI.2006.176},
abstract = {The harmonic convergence of service-oriented computing and grid results in the emergence of service grid and makes grid technology evolve into business domain. Along this evolution, the problem of transaction support becomes crucial because it is transaction that determines the adoption and success of business grid applications at most time. However, existing transaction models are not applicable in service grid environment. Though many new models have been suggested, they still have some deficiencies. In this paper, a new model is proposed based on the analysis of existing work. Take the behavior of services, the interdependence between them and the high-level requirement on transaction properties as the starting points, the proposed model is easy to implement and suitable for grid environment.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {625–628},
numpages = {4},
keywords = {Semantics, QoS, Transaction Management, Function Equivalent, Service Grid},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.73,
author = {Kuang, Li and Li, Ying and Deng, Shuiguang and Wu, Jian and Shi, Wei and Wu, Zhaohui},
title = {Expressing Service and Query Behavior Using \pi-Calculus for Matchmaking},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.73},
doi = {10.1109/WI.2006.73},
abstract = {Service discovery becomes a key to accelerating the evolution of web services as the number of services is expected to increase dramatically. Foregoing work on service discovery is primarily based on the interfaces of services through the use of ontology. Ongoing work targets at service behavior, with not only individual message exchanges being captured, but also constraints between these message exchanges. In this paper, we propose a formal approach to expressing the service and query behavior using ?-calculus for service matchmaking. The resulting ?-calculus expressions of services and queries are precise in defining single operations involving message exchanges as well as execution sequence between operations. Based on the formalizations, service matchmaking between a service query and a service description is reasoned through the capability of ?-calculus. Expressing service behavior using ?-calculus is expected to be a promising way to realize intelligent service discovery.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {629–632},
numpages = {4},
keywords = {Service Behavior, Web Service, Service Matchmaking, pi-calculus},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.195,
author = {Liu, Chuanchang and Peng, Yong and Chen, Junliang},
title = {Web Services Description Ontology-Based Service Discovery Model},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.195},
doi = {10.1109/WI.2006.195},
abstract = {Goal Web services description languages and service discovery algorithms are two keys to deal with the service discovery problem. Based on the analysis of the current Web services description languages, the paper designs a goal Web services description ontology which can depict the functional features, the performance features and the semantic features of Web services. On the principle of enhancing efficiency and quality of the service discovery, the paper presents a Web services feature elements-based service discovery model, and implements a prototype system in the tourist domain.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {633–636},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.74,
author = {Lu, Zheng and Li, Shiyan and Ghose, Aditya and Hyland, Peter},
title = {Extending Semantic Web Service Description by Service Assumption},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.74},
doi = {10.1109/WI.2006.74},
abstract = {Unlike a traditional software module, which runs within a predictable domain, Web Services are autonomous software agents running in a heterogeneous execution environment. Because of distributed responsibilities, ownership and control, it is often not feasible to acquire all information needed for the service composition. These characteristics of autonomy and heterogeneity are fundamental to service oriented computing but make it inherently difficult to avoid service conflicts. To reason about and adapt to a changing environment, in this work, we will extend current OWL-S by introducing the concept of service assumptions which allow reasoning with incomplete information. Furthermore, together with the proposed service assumptions, a sequence of rules is proposed to describe all permitted behaviors in service composition context.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {637–643},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.145,
author = {Mustapha, S. M. F. D. Syed},
title = {Relation-Based Case Retrieval Approach for Web Services Selection},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.145},
doi = {10.1109/WI.2006.145},
abstract = {Web service selection has been a challenging task for automated workflow composition. This is mainly due to the heterogeneity of the web service structure, non-standardization of registry format and complexity in capturing the semantic part of the web service functionalities. Relation-based Case Retrieval (RCR) establishes the relationship between cases and the web service invocation information. The cases contain the business proposals and the business operations in which they are measured using similarity function. RCR builds the cluster information of the cases that is able to 1) search replacement for the unavailability of the web services, 2) find dissimilarities in the repeated requests and 3) determine partiality in matching. RCR approach allows the retrieval of web services independently from the semantic and syntactic description of web service structure or registry format.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {644–648},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.194,
author = {Paliwal, Aabhas V. and Adam, Nabil R. and Xiong, Hui and Bornhovd, Christof},
title = {Web Service Discovery via Semantic Association Ranking and Hyperclique Pattern Discovery},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.194},
doi = {10.1109/WI.2006.194},
abstract = {Semantic Web technology is a promising first step for automated web service discovery. Most current approaches for web service discovery cater to semantic web services, i.e., web services that have associated semantic descriptions. It is unrealistic, however, to expect all new services to have associated semantic descriptions. Furthermore, the descriptions of the vast majority of already existing services do not have explicitly associated semantics. In this paper we present a novel approach for web service discovery that combines semantic and statistical association metrics. Semantic metrics are based on the semantic aspects of relevant ontology. Statistical association metrics are based on the association aspects of web services instances (their inputs and outputs). Specifically, our approach exploits semantic relationship ranking for establishing semantic relevance, and a hyperclique pattern discovery method for grouping web service parameters into meaningful associations. These associations combined by the semantic relevance are then leveraged to discover and rank web services.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {649–652},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.8,
author = {Song, William and Zhou, Mingquan},
title = {A Contextual Based Semantic Modeling Approach to Task-Service Formation in Virtual Organization},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.8},
doi = {10.1109/WI.2006.8},
abstract = {Virtual organizations are considered to be an independent mechanism, which manages to bridge the users' goals and requirements to the grid/web resources and services. To form the workflow for a virtual organization we need to find a sequence of interrelated services (the grid/web resources) matched to given users' requirements. It is crucial to find a semantic description for virtual organizations in order to analyze various components, such as tasks, services, and resources, and hence to make virtual organization workflows through semantic matching between tasks and services. In this paper, we propose a contextual based semantic description approach to the semantic description of virtual organization components, tasks and services. The contextual information for a resource or a service or a task is the information provided in the application domains and the pre-defined (standardized) service ontology descriptions. We also propose a semantic matching theory for matching the tasks with the services.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {653–656},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.7,
author = {Vo, Quoc Bao and Padgham, Lin},
title = {A Component-Based Approach to Automated Web Service Composition},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.7},
doi = {10.1109/WI.2006.7},
abstract = {There is great promise in the idea of having web services available on the internet, that can be flexibly composed to achieve more complex services, which can themselves then also be used as components in other contexts. However it is challenging to realise this idea, without essentially programming the composition using some process language such as WS-BPEL or OWL-S process descriptions. This paper presents a mechanism for specifying the external interface to composite and component services, and then deriving an appropriate internal model to realise a functioning composition. We present a conversation specification language for defining interaction protocols and investigate the issue of synchronous and asynchronous communication between the composite service and the component services.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {657–661},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.40,
author = {Wang, Hai and Li, Zengzhi and Fan, Lin},
title = {An Unabridged Method Concerning Capability Matchmaking of Web Services},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.40},
doi = {10.1109/WI.2006.40},
abstract = {In recent years web services has become prevalent and be looked as the best way in constructing distributed system over the Internet. Matchmaking is the key technique concerning web services because it is the foundation of doing service discovering and composition. The matchmaking of web services consists of the so called IOPE matchmaking. The capability information carried by IO is different from PE. The IO is the signature of the services while the PE is the actual capability description of the services. The technique used to describe and manipulate IO is different from PE. Previous work are mainly concentrate on the matchmaking of IO. The PE are still lack of means to deal with. In this paper we proposed a method based on Description Logic to resolve this problem. The main contribution about this method is the possibility of doing the whole semantic matchmaking just using one Description Logic reasoner.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {662–665},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.10,
author = {Xu, Meng and Chen, Junliang and Peng, Yong and Mei, Xiang and Liu, Chuanchang},
title = {A Dynamic Semantic Association-Based Web Service Composition Method},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.10},
doi = {10.1109/WI.2006.10},
abstract = {With the development of Web Service, it is critical to compose existing Web Services dynamically based on the need of users. This paper analyzes semantic association between services and proposes a dynamic web service composition approach based on Dynamic Semantic Association between services (DSAC). DSAC discovers the dynamic semantic of services when they are executing, integrates IO interface-match method and services' semantic relation ontology to get candidate successive services. This semi-automatically method could get an optimized service matchmaking results, ensure efficiency while composing services. The prototype and experiments show that DSAC can help user select proper services simply and is quite feasible for solving problems with real world sizes.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {666–672},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.54,
author = {Bezerra, Byron Leite Dantas and Carvalho, Francisco de Assis T. and Filho, Valmir Macario},
title = {C^2: A Collaborative Recommendation System Based on Modal Symbolic User Profile},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.54},
doi = {10.1109/WI.2006.54},
abstract = {Recommendation Systems have become an important tool to cope with the information overload problem by acquiring information about the user behavior. However, the process of getting user personal data may vary in many different ways, and can be done implicitly (through actions) or explicitly (through rates). After tracing actions or getting rates of the user, Computational Recommendation Technologies use information filtering techniques to recommend items. In this paper we describe an approach to improve the recommendation quality in the first moments the user interacts with the system. The main idea is: (1) first of all, we describe the items with the general users opinion about them; and (2) after this, we use modal symbolic structures to save this content in the user profile. The proposed methodology outperforms, concerning the Find Good Items task measured by half-life utility metric, other approaches based on the following techniques: Cognitive Filtering, Social Filtering and hybrid methods.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {673–679},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.18,
author = {Castillo, Carlos and Nelli, Alberto and Panconesi, Alessandro},
title = {A Memory-Efficient Strategy for Exploring the Web},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.18},
doi = {10.1109/WI.2006.18},
abstract = {Search engines rely on Web crawlers to create an index of the Web. Web crawlers explore the Web downloading pages and finding links to new pages to be explored. At any given moment, there are a number of pages waiting to be downloaded in the crawler queue. We study the growth of this queue of pending pages during a crawl of a large subset of the Web. In a normal breadth-first crawler, the queue quickly grows very large. We present a strategy for managing the pending queue that reduces its maximum size by 50% while preserving the coverage and quality of the pages visited. This can be applied to general purpose Web crawlers as well as topic-specific crawling, peer-to-peer search, on-demand Web crawling, and other environments in which memory usage has to be kept to a minimum.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {680–686},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.127,
author = {Lin, Zhenjiang and King, Irwin and Lyu, Michael R.},
title = {PageSim: A Novel Link-Based Similarity Measure for the World Wide Web},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.127},
doi = {10.1109/WI.2006.127},
abstract = {The requirement for measuring the similarity between web pages arises in many applications on the Web, such as web searching engine and web document classification. According to the unique characteristics of the Web, which are huge, rapidly growing, high dynamic, and untrustworthy, we propose a novel link-based similarity measure called PageSim. Based on the strategy of PageRank score propagation, PageSim is efficient, scalable, stable, and "fairly" robust, and therefore is applicable to the Web. We present intuitions behind the PageSim model, and outline the model with mathematical definitions. We also suggest the pruning technique for efficient computation of PageSim scores, and conduct experiments to illustrate the effectiveness and specialities of PageSim.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {687–693},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.192,
author = {Navrat, Pavol and Kovacik, Martin},
title = {Web Search Engine as a Bee Hive},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.192},
doi = {10.1109/WI.2006.192},
abstract = {A new approach to web search that is based on a bee hive metaphor is presented. We proposed a modified model of a bee hive. Our model comprises of a dance floor, an auditorium, and a dispatch room. We have shown that the model is a true model of a bee hive in the sense it simulates several kinds of its typical behaviour. However, more importantly it is a simple model that describes some processes taking place in web search. Our model incorporates also several kinds of uncertainty. The experiments show that uncertainty increases robustness of the search and makes it actually more efficient.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {694–701},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.137,
author = {Yang, Kai-Hsiang and Ho, Jan-Ming},
title = {Proof: A DHT-Based Peer-to-Peer Search Engine},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.137},
doi = {10.1109/WI.2006.137},
abstract = {In this paper we focus on building a large scale keyword search service over structured Peer-to-Peer (P2P) networks. Current state-of-the-art keyword search approaches for structured P2P systems are based on inverted list intersection. However, the biggest challenge in those approaches is that when the indices are distributed over peers, a simple query may cause a large amount of data to be transmitted over the network. We propose a new P2P keyword search scheme, called "Proof', to reduce network traffic for queries. The key idea is storing a content summary for each web page in the inverted list, so that a query can be processed by only transmitting a small size of candidate results. Our simulation results showed that, compared with previous DHT-based P2P systems, Proof can dramatically reduce network traffic and computation time. It provides 100% precision and 90.09% recall of search results, at an acceptable cost of storage overhead, even when the number of peers and documents increases continually.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {702–708},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.13,
author = {Zhong, Ping and Chen, Jinlin},
title = {A Generalized Hidden Markov Model Approach for Web Information Extraction},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.13},
doi = {10.1109/WI.2006.13},
abstract = {A Generalized Hidden Markov Model (GHMM) which extends traditional HMMs by making use of Web-specific information for Web information extraction is presented in this paper. Web content blocks are used instead of content terms as basic extraction unit in our approach. Besides, instead of using the traditional sequential state transition order, the state transition orders of GHMMs are detected based on layout structures of the corresponding web pages. Furthermore, multiple emission features are applied instead of single emission feature. In this way GHMMs can better accommodate Web information extraction. Experiments show promising results of GHMMs.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {709–718},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.144,
author = {Aciar, Silvana and Zhang, Debbie and Simoff, Simeon and Debenham, John},
title = {Recommender System Based on Consumer Product Reviews},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.144},
doi = {10.1109/WI.2006.144},
abstract = {Consumer reviews, opinions and shared experiences in the use of a product is a powerful source of information about consumer preferences that can be used in recommender systems. Despite the importance and value of such information, there is no comprehensive mechanism that formalizes the opinions selection and retrieval process and the utilization of retrieved opinions due to the difficulty of extracting information from text data. In this paper, a new recommender system that is built on consumer product reviews is proposed. A prioritizing mechanism is developed for the system. The proposed approach is illustrated using the case study of a recommender system for digital cameras.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {719–723},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.130,
author = {Carvalho, Carla and Jorge, Alipio M. and Soares, Carlos},
title = {Personalization of E-Newsletters Based on Web Log Analysis and Clustering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.130},
doi = {10.1109/WI.2006.130},
abstract = {We present a methodology for the personalization of e-newsletters based on the analysis of user access logs. To approach the problem we have used clustering on the set of users, described by their web access patterns. Our work is evaluated using a case study with real data from e-newsletters sent by mail to users of a web portal, and can be adapted to similar situations. Positive results were obtained, indicating that the methodology is able to automatically select contents for a personalized e-newsletter.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {724–727},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.15,
author = {Ch, Venkata Sudhakar Reddy and Chaudhary, Banshi. D.},
title = {A Hierarchy of Search Engines Based on ODP Concepts},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.15},
doi = {10.1109/WI.2006.15},
abstract = {This paper reports a query probing strategy which exploits concept hierarchy of Open Directory Project (ODP) to discover knowledge about search engines. In this strategy, keywords are selected on the basis of frequency analysis of words appearing in descriptions of URLs associated with a concept. The selected keywords, their senses and the words adjacent to these keywords are used in construction of query phrases. Each search engine is probed with these query phrases and their first page result is evaluated to identify number of overlaps, unique links, duplicates, dead links and freshness of documents. An application has been designed and implemented to rank search engines based on above query probing strategy and evaluation measures. This application also creates an RDF file to store the results of evaluation. The results obtained with this application are presented and results have been validated with the queries extracted from log files.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {728–731},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.21,
author = {Chen, Zhouyao and Wu, Ou and Zhu, Mingliang and Hu, Weiming},
title = {A Novel Web Page Filtering System by Combining Texts and Images},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.21},
doi = {10.1109/WI.2006.21},
abstract = {With the rapid development of the Internet, people benefit much from the sharing of information. Meanwhile, the WWW era is a double-edged sword which spreads harmful and erotic content widely. In this paper, a new statistical approach has been exploited by combining the results of two or more different classification methods using our filtering system. We first briefly introduce the classification of discrete texts, continuous texts and images separately, and then describe the specific way we have been exploring to merge the text and image classification result. Also there is a section illustrating our system framework. Finally we assess our method by demonstrating the experimental results and comparing it to some common-used filtering methods.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {732–735},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.20,
author = {Dimou, Christos and Batzios, Alexandros and Symeonidis, Andreas L. and Mitkas, Pericles A.},
title = {A Multi-Agent Simulation Framework for Spiders Traversing the Semantic Web},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.20},
doi = {10.1109/WI.2006.20},
abstract = {Although search engines traditionally use spiders for traversing and indexing the web, there has not yet been any methodological attempt to model, deploy and test learning spiders. The flourishing of the Semantic Web provides un- derstandable information that may improve the accuracy of search engines. In this paper, we introduce BioSpider, an agent-based simulation framework for developing and test- ing autonomous, intelligent, semantically-focused web spi- ders. BioSpider assumes a direct analogy of the problem at hand with a multi-variate ecosystem, where each mem- ber is self-maintaining. The population of the ecosystem comprises cooperative spiders incorporating communica- tion, mobility and learning skills, striving to improve effi- ciency. Genetic algorithms and classifier rules have been employed for spider adaptation and learning. A set of ex- periments has been performed in order to qualitatively test the efficacy and applicability of the proposed approach.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {736–739},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.166,
author = {Domenech, Josep and Sahuquillo, Julio and Gil, Jose A. and Pont, Ana},
title = {The Impact of the Web Prefetching Architecture on the Limits of Reducing User's Perceived Latency},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.166},
doi = {10.1109/WI.2006.166},
abstract = {Web prefetching is a technique that has been researched for years to reduce the latency perceived by users. For this purpose, several web prefetching architectures have been used, but no comparative study has been performed to identify the best architecture dealing with prefetching. This paper analyzes the impact of the web prefetching architecture focusing on the limits of reducing the user's perceived latency. To this end, the factors that constrain the predictive power of each architecture are analyzed and these theoretical limits are quantified. Experimental results show that the best element of the web architecture to locate a single prediction engine is the proxy, whose implementation could reduce the perceived latency up to 67%. Schemes for collaborative predictors located at diverse elements of the web architecture are also analyzed. These predictors could dramatically reduce the perceived latency, reaching a potential limit of about 97% for a mixed proxy-server collaborative prediction engine.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {740–744},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.52,
author = {Guo, Yan and Li, Kui and Zhang, Kai and Zhang, Gang},
title = {Board Forum Crawling: A Web Crawling Method for Web Forum},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.52},
doi = {10.1109/WI.2006.52},
abstract = {We present a new method of Board Forum Crawling to crawl Web forum. This method exploits the organized characteristics of the Web forum sites and simulates human behavior of visiting Web Forums. The method starts crawling from the homepage, and then enters each board of the site, and then crawls all the posts of the site directly. Board Forum Crawling can crawl most meaningful information of a Web forum site efficiently and simply. We experimentally evaluated the effectiveness of the method on real Web forum sites by comparing with the traditional breadth-first crawling. We also used this method in a real project, and 12000 Web forum sites have been crawled successfully. These results show the effectiveness of our method.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {745–748},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.12,
author = {Hou, Yuexian and Zhu, Honglei and He, Pilian},
title = {A Framework of Feedback Search Engine Motivated by Content Relevance Mining},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.12},
doi = {10.1109/WI.2006.12},
abstract = {Most current web search engines generate search results by analyzing queries and relevance between queries and web-pages. However, as the number of web-pages grows, this approach appears to be less efficient in finding relevant information. In many situations, search engines cannot determine what kind of information users want. We propose a framework of Feedback Search Engine (FSE), which not only analyzes the relevance between queries and web-pages but also uses clickthrough data to evaluate page-to-page relevance and re-generate content relevant search results. The efficient algorithms facilitating the framework are described. Making use of dynamical re-generating search results, FSE can provide its users more accurate and personalized information.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {749–752},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.19,
author = {Jamali, Mohsen and Sayyadi, Hassan and Hariri, Babak Bagheri and Abolhassani, Hassan},
title = {A Method for Focused Crawling Using Combination of Link Structure and Content Similarity},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.19},
doi = {10.1109/WI.2006.19},
abstract = {The rapid growth of the world-wide web poses unprecedented scaling challenges for general-purpose crawlers and search engines. A focused crawler aims at selectively seek out pages that are relevant to a pre-defined set of topics. Besides specifying topics by some keywords, it is customary also to use some exemplary documents to compute the similarity of a given web document to the topic. In this paper we introduce a new hybride focused crawler, which uses link structure of documents as well as similarity of pages to the topic to crawl the web},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {753–756},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.162,
author = {Han, Peng and Wang, Zhimei and Li, Zhiyun and Kramer, Bernd and Yang, Fan},
title = {Substitution or Complement: An Empirical Analysis on the Impact of Collaborative Tagging on Web Search},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.162},
doi = {10.1109/WI.2006.162},
abstract = {Recently collaborative tagging has received great attention as a public effort to create and share annotations on the web pages. In this paper, we conducted an empirical study on how this user added descriptions associated with web resources can be used to enhance the existing web search paradigm. Comprehensive experiments have been performed on data collected from del.icio.us, one of the most popular collaborative tagging website. Some useful conclusions on the usage of different tags have been drawn from our data analysis. Based on these insights, we proposed an innovative tag enhanced exploratory web search framework.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {757–760},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.34,
author = {Liu, Yan and Wang, Qiang and Wang, QingXian and Liu, Yao and Wei, Liang},
title = {An Adaptive Scoring Method for Block Importance Learning},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.34},
doi = {10.1109/WI.2006.34},
abstract = {The estimation of the block importance could be defined as a learning problem. First, a vision-based page segmentation algorithm is used to partition a Web page into semantic blocks. Then spatial features and content features are used to represent each block. Considering the difference of Web pages, an entropy-based method is adopted to analyze the individual contribution of each feature to the overall effectiveness in the given page. Thus, the entropy value of each feature is used to obtain feature's weight utilized in the further scoring algorithm. Experiments compare the influence both by adaptive weight and by constant weight. The result indicates that the BlockEvaluator algorithm could highly enhance the flexibility in the learning of block importance. The approach is tested with several important Web sites and achieves precise results, correctly extracting 96.2% of news in a set of 2430 pages distributed among 10 different sites.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {761–764},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.91,
author = {Maneeroj, Saranya and Bhattarakosol, Pattarasinee},
title = {Hybrid System Based on Intelligent Neighbor Formation Algorithm},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.91},
doi = {10.1109/WI.2006.91},
abstract = {Currently, people prefer shopping interesting items from the Internet. Therefore, e-business had installed recommender systems to support users in selecting products as quick as possible. The responsibility of the recommender system is to propose interesting items to the target users in order to gain their interests. Unfortunately, the existing recommender systems have some imperfect function under some certain situations. This paper proposed the INFA that improves the qualities of neighbors by detailing features of users' preferences. Moreover, in the neighbor forming process, the consideration domain of agreements is classified into two independent domains: the positive, and the negative agreements. Furthermore, the MNBT has improved the ability of recommender under the situation of no opinion from neighbors, or no existing neighbors.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {765–768},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.143,
author = {Nabeshima, Hidetomo and Miyagawa, Reiko and Suzuki, Yuki and Iwanuma, Koji},
title = {Rapid Synthesis of Domain-Specific Web Search Engines Based on Semi-Automatic Training-Example Generation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.143},
doi = {10.1109/WI.2006.143},
abstract = {In this paper, we propose two kinds of semi-automatic training-example generation algorithms for rapidly synthesizing a domain-specific Web search engine. We use the keyword spice model, as a basic framework, which is an excellent approach for building a domain-specific search engine with high precision and high recall. The keyword spice model, however, requires a huge amount of training examples which should be classified by hand. For overcoming this problem, we propose two kinds of refinement algorithms based on semi-automatic training-example generation: (i) the sample decision tree based approach, and (ii) the similarity based approach. These approaches make it possible to build a highly accurate domain-specific search engine with a little time and effort. The experimental results show that our approaches are very effective and practical for the personalization of a general-purpose search engine.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {769–772},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.125,
author = {Pryczek, Michal and Szczepaniak, Piotr S.},
title = {On Textual Documents Classification Using Fourier Domain Scoring},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.125},
doi = {10.1109/WI.2006.125},
abstract = {Recently, Fourier and cosine discrete transformations have been proposed for textual document ranking. The advantage of the methods is that not only the count of a frequency term within documentis used; the spatial information about presence of the term is also considered. Here, this novel approach is used to improve performance of classifiers.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {773–777},
numpages = {5},
keywords = {spatial information., word signal, text classification, text representation, Information retrieval, discrete transforms},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.149,
author = {Gori, Marco and Pucci, Augusto},
title = {Research Paper Recommender Systems: A Random-Walk Based Approach},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.149},
doi = {10.1109/WI.2006.149},
abstract = {Every day researchers from all over the world have to filter the huge mass of existing research papers with the crucial aim of finding out useful publications related to their current work. In this paper we propose a research paper recommending algorithm based on the Citation Graph and random-walker properties. The PaperRank algorithm is able to assign a preference score to a set of documents contained in a digital library and linked one each other by bibliographic references. A data set of papers extracted by ACM Portal has been used for testing and very promising performances have been measured.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {778–781},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.51,
author = {Wang, Ernest Dawei and Luo, Qiong and Yang, Dongqing and Tang, Shiwei},
title = {Binary Search Join between an IR System and an RDBMS},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.51},
doi = {10.1109/WI.2006.51},
abstract = {Integrating relational database technologies into Web Information Retrieval enables users to ask complex queries beyond traditional keyword searches over web pages. One approach to this integration is to have a software layer on top of an Information Retrieval (IR) system and an RDBMS (Relational Database Management System). A core operation in this top layer is to join the intermediate results from the two underlying systems (called the IR results and the DB results correspondingly) in order to produce the final ranked results for each query. Unfortunately, most conventional join algorithms are inefficient for this operation. In this paper, we propose one simple join algorithm called Binary Search Join (BSJ) for the operation of joining the IR results and the DB results. This algorithm takes advantage of the fact that the IR results are already ranked by relevance and that the DB results are already sorted by the join attribute. It scans the IR results and for each IR result tuple performs a binary search over the DB results. We analytically and empirically study the performance of BSJ in comparison with several conventional join algorithms on a repository of Chinese news web pages. The experiment results prove that BSJ works best in most cases.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {782–785},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.97,
author = {Wang, Qiang and Liu, Yan and Luo, Jun Yong and Ning, Jing and Yao, Qing},
title = {Improving Link Analysis through Considering Hosts and Blocks},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.97},
doi = {10.1109/WI.2006.97},
abstract = {Link analysis has shown great potential in web structure mining. Most existing link analysis methods treat a web page as a node, a hyperlink as an edge in the web graph. However, in reality, a web page's importance is also affected by its semantic factor, the structure of WWW, and other factors. Therefore, traditional link analysis methods may not be so precise in reality. It is observed that the WWW has three layers: host layer, web page layer and host layer. Based on this concept, it is considered merging the host-page relationship and the page-block relationship to improve the result of link analysis. Experiment results demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {786–789},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.62,
author = {Weng, Li-Tung and Xu, Yue and Li, Yuefeng and Nayak, Richi},
title = {Distributed Recommender Profiling and Selection with Gittins Indices},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.62},
doi = {10.1109/WI.2006.62},
abstract = {Most existing recommender systems nowadays operate in a single organizational base, and very often they do not have sufficient resources to be used in order to generate quality recommendations. Therefore, it would be beneficial if recommender systems of different organizations can cooperate together to share their resources and recommendations. In this paper, we present a distributed recommender system model that consists of multiple recommender systems from different organizations. With the hope to provide better recommendation service to users, the recommender systems can improve their performances by sharing their recommendations cooperatively. A recommender selection technique based on the Gittins indices [4] is presented in this paper, and it makes selections based on the stability, average performance and selection frequency of the recommenders.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {790–793},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.112,
author = {Yuvarani, M. and Iyengar, N. Ch. S. N. and Kannan, A.},
title = {LSCrawler: A Framework for an Enhanced Focused Web Crawler Based on Link Semantics},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.112},
doi = {10.1109/WI.2006.112},
abstract = {The traditional process of focused web crawler is to harvest a collection of web documents that are focused on the topical subspaces. The intricacy of focused crawlers is identifying the next most important and relevant link to follow. Focused Crawlers mostly rely on probabilistic models for predicting the relevancy of the documents. The Web documents are well characterized by the hypertext and the hypertext can be used to determine the relevance of the document to the search domain. The semantics of the link characterizes the semantics of the document referred. In this article, a novel, and distinctive focused crawler named LSCrawler has been proposed. This LSCrawler system retrieves documents by speculating the relevancy of the document based on the keywords in the link and the surrounding text of the link. The relevancy of the documents is reckoned measuring the semantic similarity between the keywords in the link and the taxonomy hierarchy of the specific domain. The system exhibits better recall as it exploits the semantic of the keywords in the link.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {794–800},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.134,
author = {An, Xiangdong and Jutla, Dawn and Cercone, Nick},
title = {Privacy Preserving Multiagent Probabilistic Reasoning about Ambiguous Contexts: A Case Study},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.134},
doi = {10.1109/WI.2006.134},
abstract = {Contexts in ubiquitous environments, either sensed or interpreted, are usually ambiguous. However, to provide context-aware services and applications, agents in the environments need to have an as clear as possible understanding of their contexts. Ambiguous contexts can be made clearer by agents using inference based on their domain knowledge, local and global evidence. Bayesian networks have been proposed to represent and reason about uncertain contexts under the single agent paradigm. In distributed multiagent systems, multiply sectioned Bayesian networks (MSBNs) provide a coherent framework for distributed multiagent probabilistic inference, where agents' privacy is respected. In this paper, we propose to apply MSBNs to uncertain contexts representation and reasoning in ubiquitous environments.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {801–807},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.30,
author = {Hanakawa, Noriko and Ikemiya, Nao},
title = {A Web Browser for Ajax Approach with Asynchronous Communication Model},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.30},
doi = {10.1109/WI.2006.30},
abstract = {We can receive large information from various web sites using the Internet. The web sites are important means to collect the required information in researching, learning, and even in commerce activities. Importance of web browsers grows increasingly as web sites increase. Web browsers are powerful tools to refer to web sites. However, due to necessary of synchronous communication with web servers, operationality of web pages on web browser is not better than operationality of desktop applications. Therefore, we propose a new web browser for Ajax approach with asynchronous communication model. Our web browser can improve the operationality that is equivalent to the operationality of desktop applications without revising program codes of the web applications. A feature of the browser is partial updating of a web page even if the web application does not adopt Ajax approach. As a result of experiments, we have confirmed improvement of operationality of "Yahoo auction sites" on our web browser when the load of the web server increases.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {808–814},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.58,
author = {Hsu, Ya-Wen and Moon, Naureen and Singh, Rahul},
title = {Designing Interaction Paradigms for Web-Information Search and Retrieval},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.58},
doi = {10.1109/WI.2006.58},
abstract = {As the complexity of the information available on the web increases, the role of user-data interaction paradigms is becoming increasingly critical for the success of web information retrieval. Recent years have witnessed significant advances in techniques for indexing and querying web data. However, in the same period, limited advancements have been made in developing paradigms and researching algorithmic issues associated with the design of interfaces for web-search. In this paper, we propose a novel paradigm for enabling multiple-perspective query and interaction in web search. Underlying the proposed metaphor are information and pattern analysis techniques that help determine semantic correlations between web pages, identify and extract information critical for intuitive understanding and hypothesis generation, and support effective and multiple-perspective interactions between users and the data. We provide a comprehensive study on the effectiveness and efficiency of the proposed approach in query-retrieval scenarios involving complex information goals. Our investigations point to the importance of developing novel ways to mediate interactions during web-search and will be useful in the development of the next generation of real-world solutions for web information retrieval.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {815–822},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.5,
author = {Itoh, Masahiko and Tanaka, Yuzuru},
title = {3D Component-Based Visualization Framework for Generating Simple 3D Applications Using Web Services},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.5},
doi = {10.1109/WI.2006.5},
abstract = {In this paper, we propose a component-based framework for generating simple 3D applications that aid users in the use of Web services without the need for programming. These days we can get lots of information through Web services. By using Web services, we can reduce the need to buy data packages and construct special databases in order to generate 3D information visualization systems or 3D simulation systems. Basically, we need to write some scripts or programs to access Web services. Therefore, it is difficult for users to use interactively through a graphical user interface, especially in a 3D virtual environment. Our framework uses the 3D meme media system IntelligentBox as its platform. All functions for accessing Web services are provided by 3D proxy components. Users have only to operate 3D interactive components and create composite components in order to create applications that use Web services. Users input values by means of specialized interface components, thereby creating requests to Web services, and changing visualization parameters. In this way, users can easily compose simple applications with a combination of arbitrary 3D components.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {823–830},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.67,
author = {Xiang, Peifeng and Yang, Xin and Shi, Yuanchun},
title = {Effective Page Segmentation Combining Pattern Analysis and Visual Separators for Browsing on Small Screens},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.67},
doi = {10.1109/WI.2006.67},
abstract = {Page segmentation plays a key role in browsing on small screens. It breaks a large page into smaller segments according to their semantic relationships. Then, various approaches such as single column adaptation and thumbnail view with zooming links can be implemented based on these page segments. However, for current flexible web pages, segmentation remains a challenging task. This paper proposes an effective automatic segmentation method which combining pattern analysis and visual separators. The basic idea is that a page's semantic structure is largely reflected by repeated continuous patterns and visual separators, which coincides with human's visual perception. The proposed method works in three steps: generating a refined tag tree from the DOM tree, recognizing and merging inexact patterns recursively, and segmenting the others by visual separators. Our experimental results show that the proposed method outperforms existing methods, especially for pages automatically generated from templates.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {831–840},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.181,
author = {Gursky, Peter and Horvath, Tomas and Novotny, Robert and Vanekova, Veronika and Vojtas, Peter},
title = {UPRE: User Preference Based Search System},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.181},
doi = {10.1109/WI.2006.181},
abstract = {We present a middleware system UPRE enabling personalized web search for users with different preferences. The input for UPRE is user evaluation of some objects in scale from the worst to the best. Our model is inspired by existing models of distributed middleware search. We use both inductive and deductive tasks to find user preferences and consequently best objects.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {841–844},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.172,
author = {Lee, Eunshil and Kang, Jinbeom and Choi, Joongmin and Yang, Jaeyoung},
title = {Topic-Specific Web Content Adaptation to Mobile Devices},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.172},
doi = {10.1109/WI.2006.172},
abstract = {Mobile content adaptation is a technology of effectively representing the contents originally built for the desktop PC on wireless mobile devices. Previous approaches for Web content adaptation are mostly device-dependent. Also, the content transformation to suit to a smaller device is done manually. As a result, the user has difficulty in selecting relevant information from a heavy volume of contents since the context information related to the content is not provided. To resolve these problems, this paper proposes an enhanced method of Web content adaptation for mobile devices. In our system, the process of Web content adaptation consists of 4 stages including block filtering, block title extraction, block content summarization, and personalization through learning. As a result of learning, personalization is realized by showing the information for the relevant block at the top of the content list.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {845–848},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.193,
author = {Zhang, Fuzhi and Song, Zhizheng and Zhang, He},
title = {Web Service Based Architecture and Ontology Based User Model for Cross-System Personalization},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.193},
doi = {10.1109/WI.2006.193},
abstract = {Personalized support for users becomes even more important, when service access takes place in open and dynamic service-oriented environment. This paper shows how to realize personalized service support in cross-system/service environments based on ontology and Web service technologies. First, we introduce the related approaches for supporting cross-system personalization and give their insufficiency respectively. Aimed at the problems we propose a Web service based architecture for cross-system personalization. The loosely coupled structure of Web service can easily integrate personalization service from various information systems and provide seamless access to the users. In order to reuse user models we also present an ontology based user model to support cross-system personalization. Compared with the existing approaches, our approach can effectively support the various existing personalized systems and user models, and the realization of cross-system personalization is more simply and efficiently.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {849–852},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.161,
author = {Zhou, Xuan and Li, Qing and Ludwig, Lars and Chen, Yuliu},
title = {Subject-Oriented Knowledge Formalization: Method and Prototype},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.161},
doi = {10.1109/WI.2006.161},
abstract = {The Web is looking for intelligence, however the traditional knowledge representation methods are inadequate to facilitate human-machine interaction since they mainly focus on the results of the interaction, i.e. the knowledge in the "object" form. Based the analysis on machine languages and natural languages, we argued that a subject-oriented knowledge formalization supported by controlled natural language is an important way to bring human intelligence to the Web. Thus human-machine interaction should shift into the "What You Think Is What You Get (WYTIWYG)" paradigm. This user friendly method is useful when a large number of personal experiences are needed for sharing and reuse.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {853–858},
numpages = {6},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.122,
author = {Deora, Vikas and Contes, Arnaud and Rana, Omer F. and Rajbhandari, Shrija and Wootten, Ian and Tamas, Kifor and Varga, Laszlo Z.},
title = {Navigating Provenance Information for Distributed Healthcare Management},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.122},
doi = {10.1109/WI.2006.122},
abstract = {Provenance information provides a useful basis to verify whether a particular application behavior has been adhered to. This is particularly useful to evaluate the basis for a particular outcome, as a result of a process, and to verify if the process involved in making the decision conforms to some pre-defined set of rules. This is significant in a healthcare scenario, where it is necessary to demonstrate that patient data has been processed in a particular way. Understanding how provenance information may be recorded, stored, and subsequently analyzed by a decision maker is therefore significant in a service oriented architecture, which involves the use of third party services over which the decision maker does not have control. The aggregation of data from multiple sources of patient information plays an important part in subsequent treatments that are proposed for a patient. A tool to navigate through and analyze such provenance information is proposed, based on the use of a portal framework that allows different views on provenance information to co-exist. The portal enables users to add custom portlets enabling application specific views that would facilitate particular decision making.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {859–865},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.6,
author = {Hoeber, Orland and Yang, Xue Dong},
title = {A Comparative User Study of Web Search Interfaces: HotMap, Concept Highlighter, and Google},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.6},
doi = {10.1109/WI.2006.6},
abstract = {Users of traditional web search engines commonly find it difficult to evaluate the results of their web searches. We suggest the use of information visualization and interactive visual manipulation as methods for improving the ability of users to evaluate the results of a web search. In this paper, we present the results of a user study that compared the search results interface provided by Google to that of two systems we have developed: HotMap and Concept Highlighter. We found that users were able to perform their searches faster with HotMap, were able to find more relevant documents with Concept Highlighter, and generally ranked these interfaces higher than Google with respect to subjective measures. When given a choice between these interfaces, participants ranked HotMap the highest, followed by Google and Concept Highlighter. These results indicate that even though the list-based representation of search results are common among search engines, visual and interactive interfaces to web search results can be more efficient, effective, and satisfying to the users.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {866–874},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.103,
author = {Hoeber, Orland and Yang, Xue Dong},
title = {Interactive Web Information Retrieval Using WordBars},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.103},
doi = {10.1109/WI.2006.103},
abstract = {It is common for web searchers to have difficulties crafting queries to fulfill their information needs. Even when they provide a good query, users often find it challenging to evaluate the results of their web searches. Sources of these problems include the lack of support for query refinement, and the static nature of the list-based representations of web search results. To address these issues, we have developed WordBars, an interactive tool for web information retrieval. WordBars visually represents the frequencies of the terms found in the first 100 document surrogates returned from the initial query. This system allows the users to interactively re-sort the search results based on the frequencies of the selected terms within the document surrogates, as well as to add and remove terms from the query, generating a new set of search results. Examples illustrate how WordBars can provide valuable support for query refinement and search results exploration, both when specific and vague initial queries are provided.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {875–882},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.135,
author = {Nishimoto, Ippei and Toda, Masashi},
title = {Process-Recollective Refinding on the Web},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.135},
doi = {10.1109/WI.2006.135},
abstract = {The recent growth of search technology has enabled people to find information more easily. However, most people need to refind information on a daily basis. Finding and refinding are different activities and require different types of support. However, current refinding support systems don't consider this point. This has caused several problems: PVR, loss of contextual information, and difference in search experiences. We discuss these problems and their solutions from a cognitive perspective. We propose a process-recollective refinding support system based on this discussion. We demonstrate a novel approach to refinding information on the web and a specific system as an example.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {883–892},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.22,
author = {Ahmad, Raheel and Rahimi, Shahram},
title = {A Perception Based, Domain Specific Expert System for Question-Answering Support},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.22},
doi = {10.1109/WI.2006.22},
abstract = {The current search engine technologies mostly use a keyword based searching mechanism, which does not have any deductive abilities. There is an urgent need for a more intellgent question-answering system that will provide a more intuitive, natural language interface, and more accurate and direct search results. The introduction of Computing with Words (CwW) provides a new theoretical base for developing frameworks with support for dealing with information in natural language. This paper proposes a domain specific question-answering system based on Fuzzy Expert Systems using CwW. In order to perform the translation of natural language based information into a standard format for use with CwW, Probabilistic Context-Free Grammar is used.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {893–896},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.33,
author = {Anagnostopoulos, Ioannis and Stavropoulos, Photis},
title = {Adopting Wildlife Experiments for Web Evolution Estimations: The Role of an AI Web Page Classifier},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.33},
doi = {10.1109/WI.2006.33},
abstract = {This paper proposes a statistical approach for estimating the evolution of web pages in directories. The proposal is based on the capture-recapture method used in wildlife biological studies in an animal, bird or fish populations, and it is modified according to the necessary assumptions and amendments for applying the experiments in a search engine directory. During these experiments, web pages are considered as animals and the specific types of web pages as particular species of animals whose abundance, birth, death and survival rates are estimated. The population is open, meaning that new web pages are submitted to the search engine directory, while others are removed from the directory indexes, resembling to emigration/immigration processes in nature. The role of the biologist who recognizes the species under study and records their history is assigned to a web page classifier, which is trained under the Open Directory's (DMOZ project) taxonomy. The classifier is a three layer Probabilistic Neural Network capable of identifying and categorizing web pages, on the basis of information filtering. A virtual experiment is simulated based on the classifier performance over real web pages, while the results are quite promising.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {897–901},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.88,
author = {Gu, Ling and Zhang, Yan-Qing},
title = {Granular Web Shopping Experts},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.88},
doi = {10.1109/WI.2006.88},
abstract = {Finding a product with high quality and reasonable price online is a difficult task due to uncertainty of Web data and queries. In order to handle the uncertainty problem, the granular Web Shopping Expert, a new type-2 fuzzy online decision support system, is proposed. The Web Shopping Expert based on the interval type-2 fuzzy inference system provides reasonable granular decisions for online users. This general framework can be used in other online e- Business applications.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {902–904},
numpages = {3},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.196,
author = {Huang, Qiang and Smith, J. S. and Li, Tuo},
title = {Web-Based Distributed Embedded Gateway System Design},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.196},
doi = {10.1109/WI.2006.196},
abstract = {Web-Based distributed control and monitoring systems has been developed. The system offers multi-network integration, real-time operations [1] and cross-platform solution. The commanding message is received from a long distance connection and sent to the local controller nodes to perform and required operations. Status information for the local controller nodes is gathered from individual nodes and sent back via the long distance connection.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {905–908},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.104,
author = {Shimazu, Keiko and Arisawa, Tatsuya and Saito, Isao},
title = {Interdisciplinary Contents Management Using 5W1H Interface for Metadata},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.104},
doi = {10.1109/WI.2006.104},
abstract = {In this paper, we propose a metadata exchange interface for interdisciplinary contents-sharing. The interface is obtained by introducing the research results of a specific sociological study. We have developed a Contents Management (CM) System on intra-university network to test the feasibility of our interface. The main feature of our system is its function of focusing searches in Web documents. Our interface module converts tag-labels into items of 5W1H. By conducting an experimental use of our system, we confirmed that the module on it is very important for contents sharing across various disciplines.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {909–912},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.37,
author = {Xu, Congfu and Wang, Jinlong},
title = {An Efficient Incremental Algorithm for Frequent Itemsets Mining in Distorted Databases with Granular Computing},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.37},
doi = {10.1109/WI.2006.37},
abstract = {In order to preserve individual privacy, original data is distorted with the perturbation technique, and with the support reconstruction method, frequent itemsets can be mined from the distorted database. Due to this, mining process can be apart from being error-prone, expensively, in the dynamic update environment, more expensive in terms of time as compared to the original database. Some methods proposed try to solve this problem, but still not efficient. To improve so, this paper makes use of a method based on Granular Computing (GrC) in incremental mining, which is efficient and accuracy in support computation. The experiment results show the efficiency of our algorithm.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {913–918},
numpages = {6},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.187,
author = {Dichev, Christo and Dicheva, Darina},
title = {View-Based Semantic Search and Browsing},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.187},
doi = {10.1109/WI.2006.187},
abstract = {In this paper we address the issue of defining and using views in information seeking tasks in the context of topic-centered learning repositories. We propose an extension of the Topic Maps model with views and an approach for a view-based retrieval that improves the search of relevant resources. We have implemented this extension in the educational topic maps environment TM4L. The provided support enables users to retrieve resources by specifying view descriptors derived from their current tasks or goals.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {919–925},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.42,
author = {Tang, Yi and Dong, Xiangning},
title = {Anting: An Adaptive Scanning Method for Computer Worms},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.42},
doi = {10.1109/WI.2006.42},
abstract = {Computer worms can self-propagate over a network and are becoming a critical risk to the network based applications. To propagate over the network, the worms need to scan many IP addresses to find vulnerable hosts. This paper addresses the worm scanning strategies with subsidiary information. Inspired by the natural ants, we propose an adaptive scanning method, named Anting, for worms. To perform focused scanning on the parts of most clustered vulnerable systems, each worm will record some scanning results to help deciding its next scanning direction. The new born worms can also inherit those results from its parent worms. Each worm decides its scanning direction on its local estimation to the densities of reachable addresses or vulnerable hosts in different parts of subspaces. The simple individual behaviors of worms are aggregated as a collective behavior in global to perform efficient scanning. We argue that this scanning method is more efficient when the vulnerable hosts are not uniformly distributed. We also conduct some simulated experiments to validate this method.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {926–932},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.160,
author = {Yoshikawa, Shohei and Kamiryo, Takahiko and Yasumura, Yoshiaki and Uehara, Kuniaki},
title = {Strategy Acquisition of Agents in Multi-Issue Negotiation},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.160},
doi = {10.1109/WI.2006.160},
abstract = {This paper presents a method for acquiring a strategy of an agent in multi-issue negotiation. This method learns how to make a concession to an opponent for realizing win-win negotiation. To learn the concession strategy, we adopt reinforcement learning. First, an agent receives a proposal from an opponent. The agent recognizes a negotiation state using the difference between their proposals and difference between their concessions. According to the state, the agent makes a proposal by reinforcement learning. A reward of the learning is a profit of an agreement and punishment of negotiation breakdown. The experimental results showed that agents could acquire a negotiation strategy that avoids negotiation breakdown and increases profits of an agreement. As a result, agents can acquire the action policy that strikes a balance between cooperation and competition.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {933–939},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.140,
author = {Wu, Hao-tian and Cheung, Yiu-ming},
title = {Public Authentication of 3D Mesh Models},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.140},
doi = {10.1109/WI.2006.140},
abstract = {In this paper, a public-key scheme is proposed to authenticate 3D mesh models. It is well known that digital signature schemes can be used for data authentication by generating a separate signature and appending it to the file. Another way is divide the original data into two parts: the content to be authenticated and the cover content. In the embedding process, the signature of the first part is generated and imperceptibly embedded within the cover content to form the signed content. In the authentication process, a new hash value is produced from the signed content and compared with the value decrypted from the retrieved signature for tamper detection. Before we implement such a scheme on polygonal meshes, mesh partitioning technique is used to divide them into patches with a fixed amount of vertices. For each patch, a corresponding signature is generated to replace the least significant bits of vertex coordinates within it so that the tamper can be localized. The experimental results have shown the promising results.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {940–948},
numpages = {9},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.152,
author = {Almuhammadi, Sultan and Sui, Nien T.},
title = {Safe Credential-Based Trust Protocols: A Framework},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.152},
doi = {10.1109/WI.2006.152},
abstract = {Trust in semantic web is established by either credentials or reputation. Credential-based trust protocols assume the possession of credentials and transfer them between parties in order to establish trust. Since credentials can be private data, the act of providing private credentials implies poor privacy management even if transferred through secure (encrypted) channels. Exchanging private credentials is a major risk in critical applications since it eases unauthorized usage of private data. This paper presents a framework for safe trust protocols that interactively proves the possession of credentials without the need of exchanging them.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {949–952},
numpages = {4},
keywords = {zero-knowledge proofs, Trust protocols, agents, semantic web.},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.29,
author = {Jian, Chengfeng and Zhang, Meiyu and Lu, Cunju},
title = {A Uniform Product Knowledge Representation Semantic Model},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.29},
doi = {10.1109/WI.2006.29},
abstract = {Aimed at the uniform knowledge representation including STEP and SGML in the virtual organization, XOEM+OWL is put forward which is the semantic model faced on the uniform product knowledge representation on the multi Heterogeneous Product Information. And then the correspondent mapping between STEP Schema Graph and OWL Schema Graph are build as Cos(sc,oc),so we can get the semantic pattern matching degree for the semantic representation on the product information. At last the example is presented.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {953–956},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.139,
author = {Gebski, Matthew and Penev, Alex and Wong, Raymond K.},
title = {Protocol Identification of Encrypted Network Traffic},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.139},
doi = {10.1109/WI.2006.139},
abstract = {New means of communication are constantly emerg- ing, some of which may constitute resource mis- use of an organisation's network system. Identify- ing the protocols used is straight-forward when in- specting network logs, but we focus on the problem of identifying the underlying protocol present in an unknown TCP connection. Actions are difficult to detect if the underlying protocol is encrypted and tunneled through a proxy server or SSH. We use a graph-comparison approach to build profiles of sev- eral protocols, and attempt to classify an unknown, encrypted protocol against these profiles using only the visible behaviour of the protocol being tunneled-- the size, timing and direction of packets.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {957–960},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.169,
author = {Golub, Koraljka},
title = {The Role of Different Thesauri Terms and Captions in Automated Subject Classification},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.169},
doi = {10.1109/WI.2006.169},
abstract = {The paper aims to explore to what degree different types of terms in Engineering Information (Ei) thesaurus and classification scheme influence automated subject classification performance. Preferred terms, their synonyms, broader, narrower, related terms, and captions are examined in combination with a stemmer and a stop-word list. The algorithm comprises string-to-string matching between words in the documents to be classified and words in term lists derived from the Ei thesaurus and classification scheme. The data collection for evaluation consists of some 35000 scientific paper abstracts from the Compendex database. A subset of the Ei thesaurus and classification scheme is used, comprising 92 classes at up to five hierarchical levels from General Engineering. The results show that preferred terms perform best, whereas captions perform worst. Stemming in most cases shows to improve performance, whereas the stop-word list does not have a significant impact.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {961–965},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.60,
author = {Hu, Jia and Zhong, Ning},
title = {Developing Mining-Grid Centric e-Finance Portal},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.60},
doi = {10.1109/WI.2006.60},
abstract = {E-finance industry is rapidly transforming and evolving toward more dynamic, flexible and intelligent solutions. This paper describes a model with dynamic multi-level workflows corresponding to a multi-layer Grid architecture, for multi-aspect analysis in building e-finance portals on theWisdomWeb. The application and research demonstrate that mining-grid centric three-layer Grid architecture is effective for developing intelligent risk management and decision making financial systems.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {966–969},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.168,
author = {Jianping, Xing and Lin, Zhao and Lingguo, Meng},
title = {The Research of a New Workflow Model with Step-Task Layers Based on XML Documents},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.168},
doi = {10.1109/WI.2006.168},
abstract = {The research of Workflow technology has been an active area for many years. Modeling of workflow is arguably the most important issue. In this paper, a workflow model with two layers named as S-T workflow model is created which is based on directed cyclic graph. We separate control node and task node in two layers. Step layer describes process control logic and task layer parallels concrete affairs to make the workflow clear. We address the modeling strategy at first, and then depict the features of S-T workflow model in detail, and propose arithmetic to verify the soundness of modeling structure. Besides, the parsing process of documents, and the design format of documents are also given in this paper.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {970–973},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.53,
author = {Yan, Li and Zhixue, Liu and Juan, Xu},
title = {Business Process Integration of Third-Party Logistics Service Providers in E-Commerce},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.53},
doi = {10.1109/WI.2006.53},
abstract = {This paper is focused on analyzing business processes integration of third-party logistics service providers (3PLs) in e-commerce. 3PLs are often selected to take charge of the logistics design, delivery, storage, and transportation in a supply chain with their professional and value-added services. This paper establishes a framework of 3PLs business processes, which includes strategic processes, operational processes and enabling processes. To integrate the processes, this paper proposes a logistics management information system and studies the key information techniques.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {974–977},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.178,
author = {Liu, Shuhua and Lindroos, Johnny},
title = {Towards Fast Digestion of IMF Staff Reports with Automated Text Summarization Systems},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.178},
doi = {10.1109/WI.2006.178},
abstract = {In this paper we present a series of experiments carried out adopting varying summarization schemes for summarizing the IMF staff reports. The summaries produced by the system are evaluated by comparing to the staff-written executive summaries included in the original reports. The results and learned lessons are analyzed and discussed.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {978–982},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.31,
author = {May, Madeth and George, Sebastien and Prevot, Patrick},
title = {A Web-Based System for Observing and Analyzing Computer Mediated Communications},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.31},
doi = {10.1109/WI.2006.31},
abstract = {Tracking data of user's activities resulting from Computer Mediated Communication (CMC) tools (forum, chat, etc.) is often carried out in an ad-hoc manner, which either confines the reusability of data in different purposes or makes data exploitation difficult. Our research works are biased toward methodological challenges involved in designing and developing a generic system for tracking user's activities while interacting with asynchronous communication tools like discussion forums. We present in this paper, an approach for building a Web-based system for observing and analyzing user activity on any type of discussion forums.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {983–986},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.77,
author = {Rebelo, Carmen and Brito, Pedro Quelhas and Soares, Carlos and Jorge, Alipio},
title = {Factor Analysis to Support the Visualization and Interpretation of Clusters of Portal Users},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.77},
doi = {10.1109/WI.2006.77},
abstract = {Clusterings based on many variables are difficult to visualize and interpret. We present a methodology based on Factor Analysis (FA) which can be used for that purpose. FA generates a small set of variables which encode most of the information in the original variables. We apply the methodology to segment the users of a web portal, using access log data. It not only makes it simpler to visualize and understand the clusters which are obtained on the original variables but it also helps the analyst in selecting some of the original variables for further analysis of those clusters.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {987–990},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.63,
author = {Wolstencroft, Martin and Rana, Omer F. and Davies, J. Huw},
title = {Distributed Storage of High-Volume Environmental Simulation Data: Mantle Modelling},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.63},
doi = {10.1109/WI.2006.63},
abstract = {A feasibility study of a peer-to-peer distributed storage system for the archiving of large datasets produced by the Earth mantle modelling code TERRA is presented. The manner in which the nature of such data affects the indexing, duplication and performance requirements of such a system is analysed and a data-oriented overlay network to improve efficiency is proposed. Duplication methods are analysed and test bed performance measured.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {991–996},
numpages = {6},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.102,
author = {Gilleron, Remi and Marty, Patrick and Tommasi, Marc and Torre, Fabien},
title = {Interactive Tuples Extraction from Semi-Structured Data},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.102},
doi = {10.1109/WI.2006.102},
abstract = {This paper studies from a machine learning viewpoint the problem of extracting tuples of a target n-ary relation from tree structured data like XML or XHTML documents. Our system can extract, without any post-processing, tuples for all data structures including nested, rotated and cross tables. The wrapper induction algorithm we propose is based on two main ideas. It is incremental: partial tuples are extracted by increasing length. It is based on a representation-enrichment procedure: partial tuples of length i are encoded with the knowledge of extracted tuples of length i - 1. The algorithm is then set in a friendly interactive wrapper induction system for Web documents. We evaluate our system on several information extraction tasks over corporate Web sites. It achieves state-of-the-art results on simple data structures and succeeds on complex data structures where previous approaches fail. Experiments also show that our interactive framework significantly reduces the number of user interactions needed to build a wrapper.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {997–1004},
numpages = {8},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.17,
author = {Tan, Saravadee Sae and Hoon, Gan Keng and Kong, Tang Enya},
title = {A Lazy Approach for Category Model Construction Using Training Texts},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.17},
doi = {10.1109/WI.2006.17},
abstract = {Categories are used to organize information and knowledge in directory system, folder etc. As the amount of information increase and the types of information diversify, it is common to have more categories created. As the number of categories increases, it becomes more difficult to organize, manage and look up information from existing categories. In this paper, categories are annotated with concept features to facilitate the access, retrieval and sharing of information in the categories. We have observed that training texts is crucial in learning the concept of a category and serves as a good measure to help human to construct the category model. Hence, we present a study on training texts selection and evaluate the effectiveness of training texts, as well as its capability to complement human's knowledge in constructing the category model. Experimental evaluation shows that using training texts approach in category model construction gives promising results in both effectiveness and complement measures.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1005–1011},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.182,
author = {Wan, Xiaojun and Yang, Jianwu and Xiao, Jianguo},
title = {Using Cross-Document Random Walks for Topic-Focused Multi-Document},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.182},
doi = {10.1109/WI.2006.182},
abstract = {Graph-ranking based methods have been developed for generic multi-document summarization in recent years and they make uniform use of the relationships between sentences to extract salient sentences. This paper proposes to integrate the relevance of the sentences to the specified topic into the graph-ranking based method for topic-focused multi-document summarization. The crossdocument relationships and the within-document relationships between sentences are differentiated and we apply the graph-ranking based method using each individual kind of sentence relationships and explore their relative importance for topic-focused multi-document summarization. Experimental results on DUC2003 and DUC2005 demonstrate the great importance of the cross-document relationships between sentences for topic-focused multi-document summarization. Even the approach based only on the cross-document sentence relationships can perform better than or at least as well as the approaches based on both kinds of sentence relationships.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1012–1018},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.79,
author = {Yuan, Lin and Zou, Hengming},
title = {Fast Rollup on Recursive Hierarchy in OLAP},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.79},
doi = {10.1109/WI.2006.79},
abstract = {Rollup, a key operation in OLAP queries, is to aggregate multidimensional data on dimensional hierarchies. While the operation can be efficiently implemented on regular hierarchies in data warehouse, its application to recursive hierarchies proved to be problematic. Due to the stratification restriction, aggregate is not permitted to be wrapped within SQL recursion. Representing rollup operations on recursive hierarchies as SQL recursive queries will cause considerable overhead and is thus inefficient. This paper proposes an iteration-based evaluation strategy that aims to solve this inefficiency problem in OLAP queries. In our solution, aggregation on recursive hierarchies is modeled as a binary operator tree that is stored in its postfix notation and executed by a push down stack. We also demonstrate how to seamlessly embed this novel strategy into data warehouse that is based on ORDBMS. Experiment results show that our proposed solution is quite efficient compared with the SQL recursive evaluation strategy.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1019–1028},
numpages = {10},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.138,
author = {Greco, Gianluigi and Ianni, Giovambattista and Lio, Vincenzino and Palopoli, Luigi},
title = {Protection Techniques from Information Extraction},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.138},
doi = {10.1109/WI.2006.138},
abstract = {Information extraction technologies meet the market need for automatic tools for extracting semi-structured information from web pages. However, pages may change over time due to different reasons, ranging from restyling pages to on-purpose modifications brought about into pages in order to puzzle Web wrappers. In this paper we deal with this latter scenario, by studying the issue of on-purpose wrapper spoiling and its relationship to wrapping. We present an architecture and a tool implementing a wrapper spoiling system, and discuss some practical spoiling techniques which are also experimentally tested.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1029–1033},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.35,
author = {Ji, Junzhong and Zhang, Ning and Liu, Chunnian and Zhong, Ning},
title = {An Ant Colony Optimization Algorithm for Learning Classification Rules},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.35},
doi = {10.1109/WI.2006.35},
abstract = {Ant Colony Optimization (ACO) algorithm has been applied to data mining recently. Aiming at Ant Miner, a classification rule learning algorithm based on ACO, this paper presents an enhanced Ant Miner, which includes two main contributions. Firstly, a rule punishing operator is employed to reduce the number of rules and the number of conditions. Secondly, an adaptive state transition rule and a mutation operator are applied to the algorithm to speed up the convergence rate. The results of experiments on some data sets demonstrate that the Enhanced Ant-Miner can quickly discover better classification rules which have roughly competitive predicative accuracy and short rules.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1034–1037},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.93,
author = {Chang, Yao-Sheng and He, Kuan-Yu and Yu, Scott and Lu, Wen-Hsiang},
title = {Identifying User Goals from Web Search Results},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.93},
doi = {10.1109/WI.2006.93},
abstract = {With the fast growth of the Web, users often suffer from the problem of information overload since many existing search engines response lots of non-relevant documents containing query terms based on the search mechanism of keyword matching. In fact, it is eagerly expected by both users and search engine developers to reduce overloaded information by understanding user goals clearly. In this paper, we intend to utilize Web search results to identify user goals. We propose one novel probabilistic inference model which effectively employs syntactic features to discover a variety of confined user goals.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1038–1041},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.106,
author = {Nayak, Richi},
title = {Investigating Semantic Measures in XML Clustering},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.106},
doi = {10.1109/WI.2006.106},
abstract = {This paper discusses the influence of semantic computation in structural data such as XML for clustering similar data. We study how the semantic similarity at individual element level influences the overall similarity of documents. The empirical results indicate that the semantic measures do not play an important role in finding clusters in structural data such as XML.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1042–1045},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.46,
author = {Chin, Ong Siou and Kulathuramaiyer, Narayanan and Yeo, Alvin W.},
title = {Automatic Discovery of Concepts from Text},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.46},
doi = {10.1109/WI.2006.46},
abstract = {Existing mechanisms for concept discovery tend to pick up all possible relationships between terms in a document based on roles of terms identified [3]. The proposed work aims to enhance this discovery process by employing machine learning and semantic modelling. We explore a framework for automatically discovering labeled clusters from a large collection of documents. The aim of this framework is to enable the extraction of concepts and to structure these into labeled concepts for use by text processing applications such as text summarization and text categorization. We have developed a mechanism for automatically inducing a set of words that captures the meaning of a collection of documents. The WordNet lexical database is used to extract root meanings and to determine relationships amongst these terms.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1046–1049},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.141,
author = {Wang, Xiuli and Wang, Yongji and Zhou, Hui},
title = {QSCM: Engineering QoS in Web-Based Software Configuration Management System},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.141},
doi = {10.1109/WI.2006.141},
abstract = {The conventional Software Configuration Management (SCM) tools have shown their weakness in large and complex software systems with the development of modern software. This paper provides a better SCM tool with high availability to facilitate software development process. A novel approach named Quality of Service (QoS)-based SCM (QSCM) is presented, which introduces QoS guarantee techniques at the application level to web-based SCM system in order to improve SCM system's performance. QSCM classifies users together with SCM activities and treats with requests according to their priority. When the server is overloaded, it stops treatment with new requests so that to avoid from crash. The work described here is a first step towards this goal.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1050–1056},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.128,
author = {Mikroyannidis, Alexander and Theodoulidis, Babis and Persidis, Andreas},
title = {PARMENIDES: Towards Business Intelligence Discovery from Web Data},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.128},
doi = {10.1109/WI.2006.128},
abstract = {The amounts of heterogeneous data that are available on the web have made information management a seriously complicated task. In the context of the present work, PARMENIDES, a business-oriented framework for information management on the web is introduced. Semantic information is extracted from web data and warehoused in a way that enables its efficient retrieval and reasoning towards the support for business intelligence tasks. The capabilities of the PARMENIDES approach are demonstrated via a case study based on the life sciences domain.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1057–1060},
numpages = {4},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.107,
author = {Patel, S. and Bataveljic, O. and Lisboa, P. J. and Hawkins, C. and Rajan, R.},
title = {IShakti--Crossing the Digital Divide in Rural India},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.107},
doi = {10.1109/WI.2006.107},
abstract = {This paper describes iShakti, a real-world, Intelligent, Interactive and Adaptive Web application. At present, iShakti is deployed across 1000 rural kiosks in India, covering 5000 villages and reaching 1 million people. Further scale up is underway, expected to cover tens of thousands of villages within the next 2 years. iShakti is a "virtual information and marketing channel', deploying leading-edge technology in a developing-world environment. It allows rich interactions with people in previously "mediadark' regions, with easy access to high-value community development services coupled with engaging and scalable market and brand development activities. The impact is already being felt -- iShakti is giving some of the most deprived and disempowered people more choice and control over their lives, and providing significant independent revenue for the iShakti entrepreneurs. Computational Intelligence is both in the design as well as the personalisation and synchronisation algorithms. The project was nominated as a finalist of the Stockholm Challenge (Economic Development category), an international award for ICT projects in "underserved' regions of the world [1].},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1061–1065},
numpages = {5},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.177,
author = {Ziegler, Cai-Nicolas and Skubacz, Michal},
title = {Towards Automated Reputation and Brand Monitoring on the Web},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.177},
doi = {10.1109/WI.2006.177},
abstract = {The ever-increasing growth of the Web as principal provider of news and opinions makes it impossible for individuals to manually spot and analyze all information of particular importance for global large-scale corporations. Hence, automated means, identifying upcoming topics of utter relevance and monitoring the reputation of a brand as well as its competitors, are becoming indispensable. In this paper, we present a platform for analyzing Web data for such purposes, adopting different semantic perspectives and providing the market analyst with a flexible suite of instruments. We focus on two of these tools and outline their particular utility for research and exploration.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1066–1072},
numpages = {7},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.64,
author = {Eiter, Thomas and Ianni, Giovambattista and Schindlauer, Roman and Tompits, Hans},
title = {Dlvhex: A Prover for Semantic-Web Reasoning under the Answer-Set Semantics},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.64},
doi = {10.1109/WI.2006.64},
abstract = {We present the system dlvhex, a solver for HEX-programs, which are nonmonotonic logic programs admitting both higher-order atoms as well as external atoms. Higher-order features are widely acknowledged as being useful for various tasks, including meta-reasoning. Furthermore, the possibility to exchange knowledge with external sources in a fully declarative paradigm such as answer-set programming (ASP) becomes increasingly important, in particular in view of applications in the Semantic-Web area. Through external atoms, HEX-programs can deal with external knowledge and reasoners of various nature, such as RDF datasets or description-logics knowledge bases.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1073–1074},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.117,
author = {Hoon, Gan Keng and Tan, Saravadee Sae and Gan, Bryan},
title = {MICE^3: An Information Desktop on the Web},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.117},
doi = {10.1109/WI.2006.117},
abstract = {Resembling the desktop of personal computer in which files and applications are stored, MICE^3 desktop is a web-based information desktop where individual can keep and manage resources such as links to web sites and services, as well as web sources and documents. Resources on the desktop are represented in web directory structure and annotated with information such as concepts, entities, etc. Categories are used to organize resources in the directory. Each category is annotated with concept learnt from the contents of the category. MICE^3 desktop allows users to exploit information and knowledge from their resources. Users can retrieve information by navigating the directory structure, look up the resource index or searching the resource contents. The desktop also allows users to effectively manage their resources by enabling them to enhance categories with concept. The concept is further used to assist user in organizing resources into their directory.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1075–1076},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.38,
author = {Isogai, Takashi and Fukumoto, Taro and Sawamura, Hajime},
title = {An Integrated Argumentation Environment for Arguing Agents},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.38},
doi = {10.1109/WI.2006.38},
abstract = {We present an integrated environment for argument-based agent systems, which allows agents to participate in argumentation in the Internet environment, to design knowledge bases, to make and analyze arguments and so on. We demonstrate its usability and advantages on the lines of our LMA-based argumentation scenario.},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1077–1078},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.188,
author = {Lo, Anthony and Alhajj, Reda and Barker, Ken},
title = {VIREX: Interactive Approach for Database Querying and Integration by Re-Engineering Relational Data into XML},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.188},
doi = {10.1109/WI.2006.188},
abstract = {VIREX is a user-oriented novel approach for visual-querying of relational databases and converting the result into XML. VIREX works even when the catalogue of the relational database is missing; it extracts the required catalogue information by analyzing the database content. Further, VIREX allows the user to define views by specifying on the interactive diagram certain factors to be considered while converting relational data into XML. As a result, VIREX displays on the screen the XML schema that satisfies the specified characteristics and generates colored (easy to read) XML document(s).},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1079–1080},
numpages = {2},
series = {WI '06}
}

@inproceedings{10.1109/WI.2006.44,
title = {Author Index},
year = {2006},
isbn = {0769527477},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI.2006.44},
doi = {10.1109/WI.2006.44},
booktitle = {Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence},
pages = {1081–1085},
numpages = {5},
series = {WI '06}
}

