@inproceedings{10.5555/2740769.2740771,
author = {Cartledge, Charles L. and Nelson, Michael L.},
title = {When Should I Make Preservation Copies of Myself?},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We investigate how different replication policies ranging from least aggressive to most aggressive affect the level of preservation achieved by autonomic processes used by web objects (WOs). Based on simulations of small-world graphs of WOs created using the Unsupervised Small-World algorithm, we report quantitative and qualitative results for graphs ranging in order from 10 to 5000 WOs. Our results show that a moderately aggressive replication policy makes the best use of distributed host resources by not causing spikes in CPU resources nor spikes in LAN activity while meeting preservation goals.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {1–10},
numpages = {10},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740772,
author = {Marshall, Catherine C. and Shipman, Frank M.},
title = {An Argument for Archiving Facebook as a Heterogeneous Personal Store},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {A decade ago, the locus of activity for our digital belongings---photos, email, videos, documents, and the like---was on our personal computers. Now the situation is different. Not only is personal media born-digital, it may also spend its entire life stored online in social media services and cloud stores, and locally on portable devices. Studies have revealed that most people lack the requisite skills to archive their digital belongings, regardless of where they are stored; furthermore people value the context offered by these large-scale, socially intertwined online stores. So why not archive the contents of a major social media service like Facebook to ensure the permanence of a meaningful portion of peoples' personal digital belongings? Rather than being delighted by this idea, participants in a study of digital ownership have expressed squeamishness about institutional efforts to archive social media: Facebook is not only viewed as private and vulnerable to violations of content ownership, but also as lacking long-term value. However, measures such as data embargoes, aggregation, and permissions mitigate participants' fears and objections to some extent. In this paper, we will use an example of biographical research, coupled with the results of a recent study, to argue that Facebook should be archived by a public institution.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {11–20},
numpages = {10},
keywords = {personal information, social networks, historical research, archive, Facebook, social media},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740773,
author = {Day, Michael and MacDonald, Ann and Kimura, Akiko and Pennock, Maureen},
title = {Implementing Digital Preservation Strategy: Developing Content Collection Profiles at the British Library},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The British Library is increasingly a digital library. Through both digitization and acquisition, it has built up significant collections of digital content covering a very wide range of content types. Most recently, the extension of legal deposit provisions to non-print works in 2013 has meant that it - working in conjunction with the other UK legal deposit libraries - has begun to collect new categories of digital content, including periodic harvests of the UK Web domain. In order to support this, the Library has also invested heavily in developing scalable infrastructures for the acquisition, storage and management of large amounts of digital content. The British Library Digital Preservation Strategy, 2013-2016 is focused on the embedding of digital sustainability as an organizational principle across the Library and to help manage preservation risks and challenges across all digital collection content lifecycles. This practice paper describes work being undertaken by the Digital Preservation Team at the British Library to develop content profiles of high-level digital collections that will support the implementation of the strategy, in particular for the capture of long-term preservation requirements.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {21–24},
numpages = {4},
keywords = {digital preservation, content collection profiles},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740774,
author = {Kelly, Mat and Nelson, Michael L. and Weigle, Michele C.},
title = {The Archival Acid Test: Evaluating Archive Performance on Advanced HTML and JavaScript},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {When preserving web pages, archival crawlers sometimes produce a result that varies from what an end-user expects. To quantitatively evaluate the degree to which an archival crawler is capable of comprehensively reproducing a web page from the live web into the archives, the crawlers' capabilities must be evaluated. In this paper, we propose a set of metrics to evaluate the capability of archival crawlers and other preservation tools using the Acid Test concept. For a variety of web preservation tools, we examine previous captures within web archives and note the features that produce incomplete or unexpected results. From there, we design the test to produce a quantitative measure of how well each tool performs its task.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {25–28},
numpages = {4},
keywords = {web archiving, web crawler, digital preservation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740776,
author = {Akbar, Monika and Shaffer, Clifford A. and Fan, Weiguo and Fox, Edward A.},
title = {Recommendation Based on Deduced Social Networks in an Educational Digital Library},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Discovering useful resources can be difficult in digital libraries with large content collections. Many educational digital libraries (edu-DLs) host thousands of resources. One approach to avoiding information overload involves modeling user behavior. But this often depends on user feedback, along with the demographic information found in user account profiles, in order to model and predict user interests. However, edu-DLs often host collections with open public access, allowing users to navigate through the system without needing to provide identification. With few identifiable users, building models linked to user accounts provides insufficient data to recommend useful resources. Analyzing user activity on a per-session basis, to deduce a latent user network, can take place even without user profiles or prior use history. The resulting Deduced Social Network (DSN) can be used to improve DL services. An example of a DSN is a graph whose nodes are sessions and whose edges connect two sessions that view the same resource. In this paper we present a recommendation framework for edu-DLs that depends on deduced connections between users. Results show that a recommendation system built from DSN-dependent parameters can improve performance compared to when only text similarity between resources is used. Our approach can potentially improve recommendation for DL resources when implicit user activities (e.g., view, click, search) are abundant but explicit user activities (e.g., account creation, rating, comment) are unavailable.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {29–38},
numpages = {10},
keywords = {recommendation, deduced social network},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740777,
author = {Gollub, Tim and V\"{o}lske, Michael and Hagen, Matthias and Stein, Benno},
title = {Dynamic Taxonomy Composition via Keyqueries},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper presents an unsupervised framework for dynamic, subject-oriented taxonomy composition in digital libraries, which can naturally integrate existing library classification systems. The taxonomy classes in our approach correspond to so-called keyqueries that are run against the digital library's full-text retrieval system. Given a document, a keyquery is a set of few keywords for which the document achieves a high relevance score. Keyqueries can hence be viewed as a general and concise description of the returned retrieval results. The keyquery framework addresses important problems of static classification systems: overlarge classes and overly complex taxonomy structures. If, for instance, a leaf class grows to an indigestible size, keyqueries for the contained documents provide a suitable split mechanism. Since queries are well-known to library users from their daily web search experience, they increase the structural complexity in a transparent way.The paper presents also a strategy for taxonomy-based library exploration. Given a user's information need in the form of library documents, we synthesize a hierarchy of keyqueries that covers this library subset. We manage to solve this difficult set covering problem on-the-fly by combining inverted and reverted indexes along with heuristic search space pruning within a map-reduce application. An empirical evaluation with an ACM collection of scientific papers demonstrates the efficiency and effectiveness of our taxonomy composition framework.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {39–48},
numpages = {10},
keywords = {classification systems, dynamic taxonomy composition, big data problem, reverted index, keyquery},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740778,
author = {Otegi, Arantxa and Agirre, Eneko and Clough, Paul},
title = {Personalised PageRank for Making Recommendations in Digital Cultural Heritage Collections},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper we describe the use of Personalised PageRank (PPR) to generate recommendations from a large collection of cultural heritage items. Various methods for computing item-to-item similarities are investigated, together with representing the collection as a network over which random walks can be taken. The network can represent similarity between item metadata, item co-occurrences in search logs, and the similarity of items based on linking them to Wikipedia articles and categories. To evaluate the use of PPR, search logs from Europeana are used to simulate user interactions. PPR on each information source is compared to a standard retrieval-based baseline, resulting in higher performance.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {49–52},
numpages = {4},
keywords = {recommender systems, random walks, cultural heritage},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740779,
author = {Friedrich, Tanja and Kempf, Andreas Oskar},
title = {Making Research Data Findable in Digital Libraries: A Layered Model for User-Oriented Indexing of Survey Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The growing amount of data in research and the aspired culture of data sharing make it necessary to improve data documentation in digital libraries. On these grounds we present a conceptual model for subject indexing of research data. Taking the example of social science survey data we inquire the applicability of established indexing principles. Based on these principles our research incorporates the special characteristics of social science survey data, leading us to a model of layered subject indexing.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {53–56},
numpages = {4},
keywords = {subject indexing, social science data, data documentation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740781,
author = {Gon\c{c}alves, Glauber D. and Figueiredo, Flavio and Almeida, Jussara M. and Gon\c{c}alves, Marcos A.},
title = {Characterizing Scholar Popularity: A Case Study in the Computer Science Research Community},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {A common live debate among scholars regards the popularity, productivity and impact of research. This paper aims to contribute to such discussion by quantifying the impact of various academic features on a scholar popularity throughout her career. Using a list of over 2 million publications in the Computer Science research area obtained from two large digital libraries, we analyze how features that capture the number and rate of publications, number and quality of publication venues, and the importance of the scholar in the co-authorship network relate to the scholar popularity. We also investigate the temporal dynamics of scholar popularity, identifying a few common profiles, and characterizing scholars in each profile according to their academic features.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {57–66},
numpages = {10},
keywords = {scholar popularity dynamics, academic scholar features, citation analysis},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740782,
author = {Silva, Thiago H. P. and Moro, Mirella M. and Silva, Ana Paula C. and Meira, Wagner and Laender, Alberto H. F.},
title = {Community-Based Endogamy as an Influence Indicator},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Evaluating researchers (individually or in groups) usually depends on qualifying their publications and influence. Here, we aid such crucial task by introducing two new metrics (C-Endo and Comb) that rely on the concept of endogamy for communities of authors who publish in conferences and journals, and produce patents. Endogamy here measures how tightly structured the groups of authors are within a community. We validate and evaluate the metrics by using real datasets, two ground-truth rankings and citation count. We also perform random sampling analysis to account for any unbalance from the ground-truth rankings. Overall, such a thorough evaluation shows that our metrics are successful in defining community-based endogamy as an influence indicator.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {67–76},
numpages = {10},
keywords = {research performance, bibliometric indicators},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740783,
author = {Pereira, Denilson Alves and da Silva, Eduardo Emanuel Braga and Esmin, Ahmed A. A.},
title = {Disambiguating Publication Venue Titles Using Association Rules},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Research agencies in several countries evaluate the impact of scientific publications of researcher groups to define their investments, and one of the main used metrics is the quality of the publication venues where their works were published. Several bibliometric indexes have been formulated by measuring the quality of a publication venue. However, given a set of citations extracted, for example, from curricula vitae of a researcher group, to effectively use bibliometric indexes to evaluate their quality it is necessary to identify correctly the publication venue title of each citation. This task is not easy, since there are not unique identifiers for publication venues. Frequently, citations contain abbreviated forms and acronyms, publication venues share similar titles, sometimes they change their titles, divide or merge, creating new ones. Traditional digital libraries deal with this problem by creating Authority Files. In this work, we present a twofold contribution: (i) the creation of a Computer Science publication venue authority file and (ii) the proposal of a method that uses association rules to disambiguate publication venue titles originated from citations. The disambiguator is a supervised learning method that uses the authority file to train a classifier, whose generated model is a set of association rules to identify publication venues. Experiments show that our method obtains better results than three state of art baselines.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {77–85},
numpages = {9},
keywords = {entity resolution, citation, authority file, publication venue, association rules},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740785,
author = {Trullemans, Sandra and Signer, Beat},
title = {From User Needs to Opportunities in Personal Information Management: A Case Study on Organisational Strategies in Cross-Media Information Spaces},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The efficient management of our daily information in physical and digital information spaces is a well-known problem. Current research on personal information management (PIM) aims to understand and improve organisational and re-finding activities. We present a case study about organisational strategies in cross-media information spaces, consisting of physical as well as digital information. In contrast to existing work, we provide a unified view on organisational strategies and investigate how re-finding cues differ across the physical and digital space. We further introduce a new mixing organisational strategy which is used in addition to the well-known filing and piling strategies. Last but not least, based on the results of our study we discuss opportunities and pitfalls for future descriptive PIM research and outline some directions for future PIM system design.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {87–96},
numpages = {10},
keywords = {personal information management (PIM), cross-media information spaces, organisational strategies, mixing},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740786,
author = {Park, Su Inn and Shipman, Frank},
title = {PerCon: A Personal Digital Library for Heterogeneous Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Systems are needed to support access to and analysis of large heterogeneous scientific datasets. We developed PerCon, a data management and analysis environment, to support such activities. PerCon processes and integrates data gathered via queries to existing data providers to create a personal digital library of data. Users may then search, browse, visualize and annotate the data as they proceed with analysis and interpretation. Interpretation in PerCon takes place in a visual workspace in which multiple data visualizations and annotations are placed into spatial arrangements based on the current task. The system watches for patterns in the user's data selection and organization and through mixed-initiative interaction assists users by suggesting potentially relevant data from unexplored data sources. PerCon's data location and analysis capabilities were evaluated in a controlled study with 24 users. Study participants had to locate and analyze heterogeneous weather and river data with and without the visual workspace and mixed-initiative interaction, respectively. Results indicate that the visual workspace facilitated information representation and aided in the identification of relationships between datasets. The system's suggestions encouraged data exploration, leading participants to identify more evidence of correlation among data streams and more potential interactions among weather and river data.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {97–106},
numpages = {10},
keywords = {spatial hypertext, heterogeneous data, mixed-initiative interaction, data analysis, management, visual interpretation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740787,
author = {Hinze, Annika and Alqurashi, Hayat and Vanderschantz, Nicholas and Timpany, Claire and Alzahrani, Saad},
title = {Social Information Behaviour in Physical Libraries: Implications for the Design of Digital Libraries},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Physical bookshops and libraries are visited by both individuals, and groups of patrons, while digital libraries are designed primarily for individual users. This paper reports on a study exploring the behaviour of groups of patrons in physical libraries, detailing their collaboration and communication during book searches. We aim to identify how characteristics such as location, time, environment, ambiance, layout and personal motivation play a role in a group's search and browsing behaviour. We report the findings of observations of group collaboration in academic and public libraries, and compare the observed book and library use techniques employed by patron groups. Further, we examine the support for group collaboration in digital libraries and discuss the implications of our observations for the design of digital libraries that support group collaboration and interaction among users. To that end, the paper suggests features and functions that could be added to DLs to enable asynchronous group communication and interaction.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {107–116},
numpages = {10},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740789,
author = {Wu, Zhaohui and Wu, Jian and Khabsa, Madian and Williams, Kyle and Chen, Hung-Hsuan and Huang, Wenyi and Tuarob, Suppawong and Choudhury, Sagnik Ray and Ororbia, Alexander and Mitra, Prasenjit and Giles, C. Lee},
title = {Towards Building a Scholarly Big Data Platform: Challenges, Lessons and Opportunities},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We introduce a big data platform that provides various services for harvesting scholarly information and enabling efficient scholarly applications. The core architecture of the platform is built on a secured private cloud, crawls data using a scholarly focused crawler that leverages a dynamic scheduler, processes by utilizing a map reduce based crawl-extraction-ingestion (CEI) workflow, and is stored in distributed repositories and databases. Services such as scholarly data harvesting, information extraction, and user information and log data analytics are integrated into the platform and provided by an OAI and RESTful API. We also introduce a set of scholarly applications built on top of this platform including citation recommendation and collaborator discovery.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {117–126},
numpages = {10},
keywords = {information extraction, big data, scholarly big data},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740790,
author = {Jurik, Bolette Ammitzb\o{}ll and Blekinge, Asger Askov and Ferneke-Nielsen, Rune Bruun and M\o{}ldrup-Dalum, Per},
title = {Bridging the Gap between Real World Repositories and Scalable Preservation Environments},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Integrating large scale processing environments, such as Hadoop, with traditional repository systems, such as Fedora Commons 3, have long proved a daunting task. In this paper we show how this integration can be achieved using software developed in the SCAPE project. The SCAPE integration is based on four steps: retrieving the metadata records from the repository, reading the records and their references to data files, updating the records, and storing them back in the repository. This allows full use of the Hadoop system for massively distributed processing without causing excessive load on the repository.We present a proof of concept integration based on repository systems at the Danish State and University Library and the Hadoop execution environment. As a sample collection we use data from the Newspaper Digitisation Project, a collection of more than 30 million JP2 images. The use case is to perform feature extraction and validation of the JP2 images. The validation is done against an institutional preservation policy expressed in the machine readable SCAPE Control Policy vocabulary. The feature extraction will be done using the Jpylyzer tool. We perform an experiment with various-sized sets of JP2 images, to test the scalability and correctness of the solution.We show that it is both possible and beneficial to use this approach when having to perform preservation actions on massive collections stored in traditional digital repositories.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {127–134},
numpages = {8},
keywords = {scalability, Apache Hadoop, JPEG 2000, integration, file characterisation, digital repository, preservation policies, digital preservation, preservation action},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740791,
author = {Chen, Yinlin and Fox, Edward A.},
title = {Using ACM DL Paper Metadata as an Auxiliary Source for Building Educational Collections},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Some digital libraries harvest metadata records from multiple content providers to build their collections. However, the quality and quantity of such metadata records are limited by what is harvested. To ensure collection growth, and to expand the scope beyond just what can be harvested, additional content acquisition methods are needed. Accordingly, we discuss how the Ensemble project (a pathway effort in the NSDL) is broadening its collection with the help of machine learning. Since Ensemble aims to aid computing education, we make use of ACM Digital Library records as a resource to help with transfer learning. We have built classifiers that can identify if a potential additional resource is about computing education. We approached this as a cross-domain text classification problem and developed suitable methods for feature extraction and bootstrapping for classifier training. Our experiments on three datasets of computing education metadata records show our approach can enhance the quality and quantity of records being added to Ensemble.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {137–140},
numpages = {4},
keywords = {transfer learning, digital library, classification, computing education},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740792,
author = {Wu, Zhaohui and Huang, Wenyi and Liang, Chen and Giles, C. Lee},
title = {Crowd-Sourcing Web Knowledge for Metadata Extraction},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We explore a new metadata extraction framework without human annotators with the ground truth harvested from Web. A new training sample is selected based on not only the uncertainty and representativeness in the unlabeled pool, but also on its availability and credibility in Web knowledge bases. We construct a dataset of 4329 books with valid metadata and evaluate our approach using 5 Web book databases as oracles. Empirical results demonstrate its effectiveness and efficiency.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {141–144},
numpages = {4},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740794,
author = {McKay, Dana and Smith, Wally and Chang, Shanton},
title = {Lend Me Some Sugar: Borrowing Rates of Neighbouring Books as Evidence for Browsing},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {There is more to choosing a book than simply keyword searching. Browsing is a fundamental part of the information seeking process, and one that information seekers profess to value, though it has attracted little study. This dearth of research is undoubtedly in part because browsing is nebulous and difficult to quantify. In this paper we use a large circulation dataset from an academic library consortium to examine whether books in the library stacks are loaned in clusters, with a view firstly to confirming the existence of book browsing that has been reported anecdotally, and secondly to quantifying its impact on loan patterns.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {145–154},
numpages = {10},
keywords = {libraries, books, digital libraries, log analysis, browsing, classification systems, information seeking},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740795,
author = {Lacasta, Javier and Lopez-Pellicer, Francisco J. and Renteria-Agualimpia, Walter and Nogueras-Iso, Javier},
title = {Improving the Visibility of Geospatial Data on the Web},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Geospatial information is a common resource used at personal and corporative levels for decision making. Nowadays, a relevant percentage of the geospatial data on the web is provided by standardized services. However, due to the deficiencies in the service content descriptions, the data required for a task are not easy to find. To improve the description of geospatial information on the Web, this work proposes a process to construct a Linked Data model of geospatial resources that allows semantic searching and browsing. This is done by crawling the web in search of available geospatial services, and enriching their descriptions with concepts from common knowledge organizations models. As use case, we have created a Linked Data model describing the Web Map Services published by Spanish organizations.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {155–164},
numpages = {10},
keywords = {web map service, semantic annotation, classification},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740796,
author = {Harris, Martyn and Levene, Mark and Zhang, Dell and Levene, Dan},
title = {The Anatomy of a Search and Mining System for Digital Humanities},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Samtla (Search And Mining Tools with Linguistic Analysis) is an online integrated research environment designed in collaboration with historians and linguists to facilitate the study of digitised texts written in any language. It currently supports the research of two corpora: the Genizah collection held by the Taylor-Schechter Genizah Research Unit in Cambridge University, and a collection of Aramaic incantation texts from late antiquity. In contrast to standard search engines and text mining systems that rely on the bag-of-words representation of text, Samtla provides the retrieval and discovery of fuzzy text patterns/motifs (aka "formulae" to historians), which is achieved through applying a character-based n-gram statistical language model built on top of a powerful generalised suffix tree data structure. This paper briefly describes the major components of Samtla and their underlying techniques.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {165–168},
numpages = {4},
keywords = {digital humanities, collaborative search, suffix tree, statistical language model, sequence alignment},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740797,
author = {Mets, \~{O}nne and Gstrein, Silvia and Gr\"{u}ndhammer, Veronika},
title = {Increasing the Visibility of Library Records via Consortial Search Engine},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper we describe a common search engine which currently comprises the records of public domain literature from 29 libraries across Europe. These libraries offer the EOD (eBooks on Demand) digitization on request service and make digitized materials available. The search engine (http://search.books2ebooks.eu) has been developed to enable users to browse the respective content simultaneously from several library catalogues. The current case study provides a description of the search engine, statistical trends of user engagement, and their implications. Our findings show the effectiveness of such collaboration, especially in terms of increasing the visibility of data and engaging new user groups. The lessons learned are to encourage the library community, including smaller language groups, for more active cooperation.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {169–172},
numpages = {4},
keywords = {library catalogues, federated search, information retrieval and browsing, evaluation, open source software, consortia, integration of datasets},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740799,
author = {Santana, Alan Filipe and Gon\c{c}alves, Marcos Andr\'{e} and Laender, Alberto H. F. and Ferreira, Anderson},
title = {Combining Domain-Specific Heuristics for Author Name Disambiguation},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Author name disambiguation has been one of the hardest problems faced by digital libraries since their early days. Historically, supervised solutions have empirically outperformed those based on heuristics, but with the burden of having to rely on manually labelled training sets for the learning process. Moreover, most supervised solutions just apply some type of generic machine learning solution and do not exploit specific knowledge about the problem. In this paper, we follow a similar reasoning, but in the opposite direction. Instead of extending an existing supervised solution, we propose a set of carefully designed heuristics and similarity functions and apply supervision only to optimize such parameters for each particular dataset. As our experiments show, the result is a very effective, efficient and practical author name disambiguation method that can be used in many different scenarios.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {173–182},
numpages = {10},
keywords = {name disambiguation, supervised methods},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740800,
author = {Smith, David A. and Cordell, Ryan and Dillon, Elizabeth Maddock and Stramp, Nick and Wilkerson, John},
title = {Detecting and Modeling Local Text Reuse},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Texts propagate through many social networks and provide evidence for their structure. We describe and evaluate efficient algorithms for detecting clusters of reused passages embedded within longer documents in large collections. We apply these techniques to two case studies: analyzing the culture of free reprinting in the nineteenth-century United States and the development of bills into legislation in the U.S. Congress. Using these divergent case studies, we evaluate both the efficiency of the approximate local text reuse detection methods and the accuracy of the results. These techniques allow us to explore how ideas spread, which ideas spread, and which subgroups shared ideas.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {183–192},
numpages = {10},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740801,
author = {Batjargal, Biligsaikhan and Kuyama, Takeo and Kimura, Fuminori and Maeda, Akira},
title = {Identifying the Same Records across Multiple Ukiyo-e Image Databases Using Textual Data in Different Languages},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper proposes a novel method for identifying the same records across multiple databases in different languages. In order to identify the same records, we calculate the similarities between records by comparing the text values of metadata elements. The proposed method, i.e. finding the same records across multiple databases, will help users to know which organization has a certain record and its customized versions regardless of languages and differences in formats. Although the proposed approach was demonstrated on Japanese Ukiyo-e databases, it might be applicable to other disciplines for bridging the gaps between databases in different languages.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {193–196},
numpages = {4},
keywords = {multilingual record linkage, humanities databases, Japanese arts, digital library, de-duplication},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740802,
author = {Meuschke, Norman and Gipp, Bela},
title = {Reducing Computational Effort for Plagiarism Detection by Using Citation Characteristics to Limit Retrieval Space},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper proposes a hybrid approach to plagiarism detection in academic documents that integrates detection methods using citations, semantic argument structure, and semantic word similarity with character-based methods to achieve a higher detection performance for disguised plagiarism forms. Currently available software for plagiarism detection exclusively performs text string comparisons. These systems find copies, but fail to identify disguised plagiarism, such as paraphrases, translations, or idea plagiarism. Detection approaches that consider semantic similarity on word and sentence level exist and have consistently achieved higher detection accuracy for disguised plagiarism forms compared to character-based approaches. However, the high computational effort of these semantic approaches makes them infeasible for use in real-world plagiarism detection scenarios. The proposed hybrid approach uses citation-based methods as a preliminary heuristic to reduce the retrieval space with a relatively low loss in detection accuracy. This preliminary step can then be followed by a computationally more expensive semantic and character-based analysis. We show that such a hybrid approach allows semantic plagiarism detection to become feasible even on large collections for the first time.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {197–200},
numpages = {4},
keywords = {citation analysis, plagiarism detection, information retrieval, large scale collections, disguised plagiarism, semantic analysis},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740804,
author = {Dalip, Daniel H. and Lima, Harlley and Gon\c{c}alves, Marcos Andr\'{e} and Cristo, Marco and Calado, P\'{a}vel},
title = {Quality Assessment of Collaborative Content with Minimal Information},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Content generated by users is one of the most interesting phenomena of published media. However, the possibility of unrestricted edition is a source of doubts about its quality. This issue has motivated many studies on how to automatically assess content quality in collaborative web sites. Generally, these studies use machine learning techniques to combine large number of quality indicators into a single value representing the overall quality of the document. This need for a high number of indicators, however, has detrimental implications both on the efficiency and on the effectiveness of the quality assessment algorithms. In this work, we exploit and extend a feature selection method based on the SPEA2 multi-objective genetic algorithm. Results show that we can reduce the feature set to a fraction of 15% through 25% of the original, while obtaining error rates comparable to the state of the art.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {201–210},
numpages = {10},
keywords = {Wikipedia, machine learning, quality assessment, genetic algorithm, feature selection},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740805,
author = {Pengcheng, Gao and Jiangqin, Wu and Yuan, Lin and Yang, Xia and Tianjiao, Mao and Baogang, Wei},
title = {Fast Image-Based Chinese Calligraphic Character Retrieval on Large Scale Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Chinese calligraphy is the art of handwriting, it draws a lot of attention for its beauty and elegance. In CADAL1, a Calligraphic Character Dictionary (CCD) which contains hundreds of thousands of character images labeled with semantic meaning has been constructed and provided online to common users. It is a great challenge to perform quick and accurate image-based calligraphic character retrieval on CCD. In this paper, a novel shape descriptor, Oriented Shape Context (OSC) is proposed basing on the tranditional Shape Context (SC) to perform similarity searching. Together with GIST, GIST-OSC descriptor is proposed to represent calligraphic character image for efficient and effective retrieval. In addition, an effective retrieval schema is proposed. The retrieval schema works in two steps. Firstly approximate nearest neighbors of the query image are found quickly using GIST and then one-to-one fine matching between approximate nearest neighbors and the query image is performed using OSC. Our experiments show that the GIST-OSC descriptor and the retrieval schema are efficient and effective for Chinese calligraphic character retrieval on large scale data.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {211–218},
numpages = {8},
keywords = {GIST-OSC, retrieval, CADAL, calligraphy},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740806,
author = {Majidi, Saeed and Crane, Gregory},
title = {Human and Machine Error Analysis on Dependency Parsing of Ancient Greek Texts},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Automatically generated metadata from large collections is an essential component of digital libraries. It is beginning to emerge as fundamental to the study of languages. Morpho-syntactic annotation captures the form of individual words and their function. Nonetheless automated syntactic analysis is still imperfect and human annotators can be significantly more accurate. On the other hand, human work is expensive and even humans find some constructions difficult to annotate correctly. Comparing the performance of human annotators with that of an automatic parser is thus important for exploring how the two methods can best be combined. In the present study, we compare the frequency of the different types of errors made by student annotators with those made by different dependency parsers when annotating ancient Greek. With a few exceptions, the frequency of the different types of errors was similar for human and machine. The significance of these results is briefly discussed.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {221–224},
numpages = {4},
keywords = {error analysis, dependency parsing, data-driven parsing, corpus annotation, ancient Greek treebanking},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740807,
author = {Chen, Hung-Hsuan and Khabsa, Madian and Giles, C. Lee},
title = {The Feasibility of Investing in Manual Correction of Metadata for a Large-Scale Digital Library},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Given a large-scale digital library that automatically crawls and parses PDF files to generate metadata for documents and authors, we estimate the number of person-hours required to correct a small portion of the metadata, in the hope that a large portion of users can benefit from these corrections. We obtain users requests by analyzing Cite-SeerX's log files from September 2009 to March 2013. We found that the distribution of users requests for search is highly imbalanced: most document search queries and author search queries concentrate on a small set of terms. As a result, even for a large-scale digital library, we estimate it is affordable to invest a few person-hours to check the correctness of a few metadata, and thus provide benefits to a good portion of document search and author search requests.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {225–228},
numpages = {4},
keywords = {user satisfaction, digital library, user experience, metadata correction, human-aided metadata generation, practicability},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740809,
author = {Jatowt, Adam and Duh, Kevin},
title = {A Framework for Analyzing Semantic Change of Words across Time},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Recently, large amounts of historical texts have been digitized and made accessible to the public. Thanks to this, for the first time, it became possible to analyze evolution of language through the use of automatic approaches. In this paper, we show the results of an exploratory analysis aiming to investigate methods for studying and visualizing changes in word meaning over time. In particular, we propose a framework for exploring semantic change at the lexical level, at the contrastive-pair level, and at the sentiment orientation level. We demonstrate several kinds of NLP approaches that altogether give users deeper understanding of word evolution. We use two diachronic corpora that are currently the largest available historical language corpora. Our results indicate that the task is feasible and satisfactory outcomes can be already achieved by using simple approaches.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {229–238},
numpages = {10},
keywords = {computational etymology, historical linguistics, language change, word meaning evolution},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740810,
author = {Aletras, Nikolaos and Baldwin, Timothy and Lau, Jey Han and Stevenson, Mark},
title = {Representing Topics Labels for Exploring Digital Libraries},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Topic models have been shown to be a useful way of representing the content of large document collections, for example via visualisation interfaces (topic browsers). These systems enable users to explore collections by way of latent topics. A standard way to represent a topic is using a set of keywords, i.e. the top-n words with highest marginal probability within the topic. However, alternative topic representations have been proposed, including textual and image labels. In this paper, we compare different topic representations, i.e. sets of topic words, textual phrases and images, in a document retrieval task. We asked participants to retrieve relevant documents based on pre-defined queries within a fixed time limit, presenting topics in one of the following modalities: (1) sets of keywords, (2) textual labels, and (3) image labels. Our results show that textual labels are easier for users to interpret than keywords and image labels. Moreover, the precision of retrieved documents for textual and image labels is comparable to the precision achieved by representing topics using sets of keywords, demonstrating that labelling methods are an effective alternative topic representation.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {239–248},
numpages = {10},
keywords = {topic model, information retrieval, evaluation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740811,
author = {Xu, Han and Martin, Eric and Mahidadia, Ashesh},
title = {Topical Establishment Leveraging Literature Evolution},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {From an evolutionary perspective, a body of research is an evolving ecosystem, consisting of research topics subjected to a form of natural selection as topics come into existence, and thrive more or less over a variable period of time. Identifying the form of establishment of a given topic in a scientific domain, in terms of its momentum at the time of inquiry, can provide useful insights into where this topic is heading, and can facilitate effective literature research. Here we propose to identify three forms of establishment of topics, emerging from a comparison between two different methodologies in ranking papers, taking advantage of the mutual relationship between recognition of papers and recognition of topics. More specifically, by analysing the correlation between the rankings obtained by applying both methodologies, we discover thee clusters of topics, each of which is associated with a particular momentum of establishment.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {249–252},
numpages = {4},
keywords = {RALEX, topical ranking, PageRank, topical establishment},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740812,
author = {Kimura, Fuminori and Maeda, Akira},
title = {Method for Supporting Analysis of Personal Relationships through Place Names Extracted from Documents},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Visualizing information extracted from text is helpful for intuitively understanding the information. Extracting and visualizing personal relationships from text is one of the promising applications of this approach. Existing methods usually estimate personal relationships from direct co-occurrences of personal names that appear in a text. In our previous work, we proposed a method for extracting personal relationships from indirect co-occurrence relationships obtained through place names. This method can estimate the relationships among persons who do not necessarily have direct relationships. These relationships are visualized in a network graph. However, it becomes difficult to grasp the relationships when the number of persons increases. In this paper, we propose a method that supports analyzing the extracted personal relationships through place names and that is based on our previous work. Our goal is to support analysis by providing the information of the clustering of closely related people and important place names for each cluster. The proposed method was applied to a Japanese historical chronicle written in the 12th century. Experimental results showed a strong correspondence to the known historical facts. The results also indicate that the proposed method might be able to uncover the characteristics of people whose histories are not clearly known yet.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {253–256},
numpages = {4},
keywords = {clustering, place name, text mining, personal relationship},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740814,
author = {Borgman, Christine L. and Darch, Peter T. and Sands, Ashley E. and Wallis, Jillian C. and Traweek, Sharon},
title = {The Ups and Downs of Knowledge Infrastructures in Science: Implications for Data Management},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The promise of technology-enabled, data-intensive scholarship is predicated upon access to knowledge infrastructures that are not yet in place. Scientific data management requires expertise in the scientific domain and in organizing and retrieving complex research objects. The Knowledge Infrastructures project compares data management activities of four large, distributed, multidisciplinary scientific endeavors as they ramp their activities up or down; two are big science and two are small science. Research questions address digital library solutions, knowledge infrastructure concerns, issues specific to individual domains, and common problems across domains. Findings are based on interviews (n=113 to date), ethnography, and other analyses of these four cases, studied since 2002. Based on initial comparisons, we conclude that the roles of digital libraries in scientific data management often depend upon the scale of data, the scientific goals, and the temporal scale of the research projects being supported. Digital libraries serve immediate data management purposes in some projects and long-term stewardship in others. In small science projects, data management tools are selected, designed, and used by the same individuals. In the multi-decade time scale of some big science research, data management technologies, policies, and practices are designed for anticipated future uses and users. The need for library, archival, and digital library expertise is apparent throughout all four of these cases. Managing research data is a knowledge infrastructure problem beyond the scope of individual researchers or projects. The real challenges lie in designing digital libraries to assist in the capture, management, interpretation, use, reuse, and stewardship of research data.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {257–266},
numpages = {10},
keywords = {knowledge infrastructures, little science, big science, astronomy, sensor networks, digital libraries, big data, small science, data management, biology},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740815,
author = {Lagoze, Carl and Vilhuber, Lars and Williams, Jeremy and Perry, Benjamin and Block, William C.},
title = {CED<sup>2</sup>AR: The Comprehensive Extensible Data Documentation and Access Repository},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We describe the design, implementation, and deployment of the Comprehensive Extensible Data Documentation and Access Repository (CED2AR). This is a metadata repository system that allows researchers to search, browse, access, and cite confidential data and metadata through either a web-based user interface or programmatically through a search API, all the while re-reusing and linking to existing archive and provider generated metadata. CED2AR is distinguished from other metadata repository-based applications due to requirements that derive from its social science context. These include the need to cloak confidential data and metadata and manage complex provenance chains.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {267–276},
numpages = {10},
keywords = {standards, metadata},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740816,
author = {St. Pierre, Carlin and Bainbridge, David and Rogers, Bill},
title = {Big Brother is Watching You: But in a Good Way},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In any modern desktop environment the glyph compositor---where raw text information is combined with font information and other attributes to render rasterized component images---is part of the software's core functionality. In this paper we present work that shows it is computationally feasible to apply full-text indexing in real-time to the live stream of glyph compositor operations generated by a user's interaction with their desktop environment. By embedding indexing functionality at such a level, we effectively get to "see" (and more importantly remember) all the text that is drawn on the user's screen. With elements reminiscent of the Memex, we illustrate the technique in use through a personal digital library we have developed that enriches (through text-searching and context) the user's desktop experience by letting them go back in time to view information that had previously been displayed. We achieved this by augmenting our dynamically updated text index with time-stamped snapshots of the desktop. By recording the (x, y) positions of the text at the time it is rendered, the snapshots have a semi-live feel, whereby text can be selected for copy-and-paste operations for further use. Moreover, windows---even if they were hidden behind others at the time the text was rendered---can be brought to the front and their text accessed.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {277–280},
numpages = {4},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740817,
author = {Dallmeier-Tiessen, S\"{u}nje and Lavasa, Artemis and Herterich, Patricia and Rueda, Laura and Kotarski, Rachael and Newbold, Elizabeth},
title = {A Comparative Analysis of Disciplinary Data Management Workflows},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Datasets are now an integral part of scholarly communication. The result is that research data has now become a reality in library and information science, and its curation requires dedicated workflows. Here, we compare two disciplinary examples from High-Energy Physics and Humanities and Social Sciences, both referenced to the OAIS conceptual model. Even though we know that the research datasets and their metadata (preparation and curation) are very different in both disciplines, it can be seen that the conceptual workflow models are very similar, including the assignment of persistent identifiers (PIDs). The latter is particularly interesting when discussing the design and implementation of transdisciplinary services in library and information science.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {281–284},
numpages = {4},
keywords = {scientific data curation, conceptual models, persistent identifiers, OAIS, author identifiers},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740818,
author = {Stathopoulou, Ioanna-Ourania and Georgiadis, Haris and Banos, Vangelis and Stathopoulos, Panagiotis and Houssos, Nikos and Sachini, Evi},
title = {An Open Cultural Digital Content Infrastructure},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We present an Open Cultural Digital Content Infrastructure, a platform providing a coherent suite of loosely-coupled services that aim to promote metadata quality in repositories and facilitate metadata data and digital content reuse. The key functions of the infrastructure are the aggregation of metadata and digital files and the automatic validation of metadata records and digital material for compliance with desired quality specifications. The system that has recently moved to production, is currently being employed to ensure the quality standards of the output of more than 70 projects that support Greek cultural heritage organisations and are funded by the European Union structural funds. These projects are expected to produce more than 1.5 million digitized and born-digital items accompanied with detailed metadata. The validation is based on a set of quality and interoperability specifications that have been developed for the purpose. The infrastructure has been developed using an open source technology stack and tools and in particular reuses a number of components of the publicly available Europeana aggregator and portal software platform.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {285–288},
numpages = {4},
keywords = {digital content aggregration, digital content aggregration validation, metadata aggregation, interoperability guidelines, metadata harvesting, metadata quality, cultural heritage infrastructures, metadata validation, OAI-PMH},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740820,
author = {Gonano, Ciro Mattia and Mambelli, Francesca and Peroni, Silvio and Tomasi, Francesca and Vitali, Fabio},
title = {Zeri e LODE: Extracting the Zeri Photo Archive to Linked Open Data: Formalizing the Conceptual Model},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper presents the first steps of a project to convert the notable Italian "Zeri photo archive" to a linked and open dataset. The full project entails the analysis of the records' description model (Scheda F) in order to define a suitable ontology by exploring existing data models, the creation of the RDF triple store, the creation of links to the cloud, and the definition of the user interface for browsing the linked open dataset. This paper presents and discusses the conceptual modeling of the data stored in the Zeri archival database.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {289–298},
numpages = {10},
keywords = {OWL 2 DL, FABIO, FRBR, CIDOC-CRM, PROV-O, FEO, RDF, Scheda F},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740821,
author = {Li, Luyuan and Wang, Yongtao and Gao, Liangcai and Tang, Zhi and Suen, Ching Y.},
title = {Comic2CEBX: A System for Automatic Comic Content Adaptation},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Comics are popular almost throughout the world. With the help of comic document digitization, it is much easier for people to archive and browse comic works. However, there are still some big challenges along with comic document digitization progress. Among these challenges, comic content adaptation is an important one to be tackled. The existing works only focus on parts of this problem and do not provide a tangible solution to display comic contents on different devices. In this paper, we solve these problems by proposing Comic2CEBX, a system which can automatically convert a set of scanned comic page images into a CEBX file that allows reflowing of the original comic pages with fixed layouts. Taking raw comic images as inputs, our system first extracts three kinds of low-level visual patterns and then uses multilayer Conditional Random Fields to detect all the panels. Meanwhile, our system automatically identifies the reading orders of the panels within each page. Finally, we encapsulate the comic page images and the obtained page structure information (i.e., the panels detection results and the corresponding reading orders) to generate a CEBX file. Experimental results show that our comic page layout analysis method achieves better performance than the existing ones, and use case presentation of the CEBX files produced by our system demonstrates that it brings better comic reading experience especially on mobile devices.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {299–308},
numpages = {10},
keywords = {conditional random fields, comic image, panel detection, CEBX document standard, page layout analysis, content reflow and adaptation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740822,
author = {Crawford, Tim and Fields, Ben and Lewis, David and Page, Kevin},
title = {Explorations in Linked Data Practice for Early Music Corpora},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Exploring connections between pieces, people and places and relating them to culture as a whole is a central activity of musicology. As libraries increase the availability of musical information in digital form, the data available for such research also expands, but to take such resources together and combine them with others that are relevant a further step of alignment and linkage is needed. We describe here the process and tools we applied to two corpora of early modern music: Early Music Online, which comprises catalogue metadata in MarcXML and facsimile images for approximately 8,500 items of early printed music; and the Electronic Corpus of Lute Music, containing over 1,000 pieces with supporting metadata. A supervised process with automated elements assists the musicologist to create a linked and extensible knowledge structure, aligning entities within and between corpora and to external Linked Data. Finally, we reflect upon how we believe these methods integrate with, and indeed form a crucial element of, the transformed process of modern digital scholarship.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {309–312},
numpages = {4},
keywords = {data modeling, data alignment, digital humanities, semantic web, linked data, musicology},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740823,
author = {Castro, Jo\~{a}o Aguiar and da Silva, Jo\~{a}o Rocha and Ribeiro, Cristina},
title = {Creating Lightweight Ontologies for Dataset Description: Practical Applications in a Cross-Domain Research Data Management Workflow},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The description of data is a central task in research data management. Describing datasets requires deep knowledge of both the data and the data creation process to ensure adequate capture of their meaning and context. Metadata schemas are usually followed in resource description to enforce comprehensiveness and interoperability, but they can be hard to understand and adopt by researchers. We propose to address data description using ontologies, which can evolve easily, express semantics at different granularity levels and be directly used in system development. Considering that existing ontologies are often hard to use in a cross-domain research data management environment, we present an approach for creating lightweight ontologies to describe research data. We illustrate our process with two ontologies, and then use them as configuration parameters for Dendro, a software platform for research data management currently being developed at the University of Porto.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {313–316},
numpages = {4},
keywords = {lightweight ontology, research data description, research data management},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740824,
author = {Fenlon, Katrina and Fallaw, Colleen and Cole, Timothy and Han, Myung-Ja},
title = {A Preliminary Evaluation of HathiTrust Metadata: Assessing the Sufficiency of Legacy Records},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Print-based libraries use metadata (specifically MARC catalog records) for both bibliographic control and to support discovery through online public access catalogs. Depending on its accuracy, completeness, and detail, metadata can afford an aerial view of a collection's topical strengths, scope of coverage, and item-to-item relationships, but the view offered is in part a function of metadata design. Most MARC records were created to support management of large print collections and optimized to meet the requirements of library online public access catalogs. How well do pre-existing MARC records serve the discovery needs of scholars using a large-scale digital library hosting collections of retrospectively digitized books and serials? This paper reports on an ongoing assessment of the utility of the MARC-based metadata underlying the HathiTrust Digital Library and explores the implications for advanced computational access to texts in the HathiTrust. We consider here the utility of metadata to scholars creating worksets for analysis, examining three user scenarios, which were gleaned from an ongoing user-requirements study done for the HathiTrust Research Center: (1) using metadata fields in combination for corpus characterization and discovery; (2) relying on metadata to identify resources of interest; and (3) using bibliographies of known items to seed research worksets. Our goal is to better understand the need for metadata remediation and augmentation and assess the scope of additional work required.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {317–320},
numpages = {4},
keywords = {digital library metadata requirements, workset creation for scholarly analysis, metadata reliability, MARC-based metadata, metadata evaluation, HathiTrust research center},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740826,
author = {Brunelle, Justin F. and Kelly, Mat and SalahEldeen, Hany and Weigle, Michele C. and Nelson, Michael L.},
title = {Not All Mementos Are Created Equal: Measuring the Impact of Missing Resources},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Web archives do not capture every resource on every page that they attempt to archive. This results in archived pages missing a portion of their embedded resources. These embedded resources have varying historic, utility, and importance values. The proportion of missing embedded resources does not provide an accurate measure of their impact on the Web page; some embedded resources are more important to the utility of a page than others. We propose a method to measure the relative value of embedded resources and assign a damage rating to archived pages as a way to evaluate archival success. In this paper, we show that Web users' perceptions of damage are not accurately estimated by the proportion of missing embedded resources. The proportion of missing embedded resources is a less accurate estimate of resource damage than a random selection. We propose a damage rating algorithm that provides closer alignment to Web user perception, providing an overall improved agreement with users on memento damage by 17% and an improvement by 51% if the mementos are not similarly damaged. We use our algorithm to measure damage in the Internet Archive, showing that it is getting better at mitigating damage over time (going from 0.16 in 1998 to 0.13 in 2013). However, we show that a greater number of important embedded resources (2.05 per memento on average) are missing over time.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {321–330},
numpages = {10},
keywords = {web archiving, HTTP, TimeMaps, digital preservation, memento, web architecture},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740827,
author = {Huurdeman, Hugo C. and Ben-David, Anat and Kamps, Jaap and Samar, Thaer and de Vries, Arjen P.},
title = {Finding Pages on the Unarchived Web},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Web archives preserve the fast changing Web, yet are highly incomplete due to crawling restrictions, crawling depth and frequency, or restrictive selection policies---most of the Web is unarchived and therefore lost to posterity. In this paper, we propose an approach to recover significant parts of the unarchived Web, by reconstructing descriptions of these pages based on links and anchors in the set of crawled pages, and experiment with this approach on the Dutch Web archive.Our main findings are threefold. First, the crawled Web contains evidence of a remarkable number of unarchived pages and websites, potentially dramatically increasing the coverage of the Web archive. Second, the link and anchor descriptions have a highly skewed distribution: popular pages such as home pages have more terms, but the richness tapers off quickly. Third, the succinct representation is generally rich enough to uniquely identify pages on the unarchived Web: in a known-item search setting we can retrieve these pages within the first ranks on average.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {331–340},
numpages = {10},
keywords = {link evidence, web crawlers, anchor text, web archives, information retrieval, web archiving},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740828,
author = {Kanhabua, Nattiya and Nguyen, Tu Ngoc and Nieder\'{e}e, Claudia},
title = {What Triggers Human Remembering of Events? A Large-Scale Analysis of Catalysts for Collective Memory in Wikipedia},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Going beyond its role as an encyclopedia, Wikipedia becomes a global memory place for high-impact events, such as, natural disasters and manmade incidents, thus influencing collective memory, i.e., the way we remember the past. Due to the importance of collective memory for framing the assessment of new situations, our actions and value systems, its open construction and negotiation in Wikipedia is an important new cultural and societal phenomenon. The analysis of this phenomenon does not only promise new insights in collective memory. It is also an important foundation for technology, which more effectively complements the processes of human forgetting and remembering and better enables us to learn from the past. In this paper, we analyse the long-term dynamics of Wikipedia as a global memory place for high-impact events. This complements existing work in analysing the collective memory negotiation and construction process in Wikipedia directly following the event. In more detail, we are interested in catalysts for reviving memories, i.e., in the fuel that keeps memories of past events alive, interrupting the general trend for fast forgetting. For this purpose, we study the trigger of revisiting behavior for a large set of event pages by exploiting page views and time series analysis, as well as identify of most important catalyst features.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {341–350},
numpages = {10},
keywords = {real-world events, social computing, Wikipedia page views, collective memory, time series analysis},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740830,
author = {Chakraborty, Tanmoy and Kumar, Suhansanu and Goyal, Pawan and Ganguly, Niloy and Mukherjee, Animesh},
title = {Towards a Stratified Learning Approach to Predict Future Citation Counts},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper, we study the problem of predicting future citation count of a scientific article after a given time interval of its publication. To this end, we gather and conduct an exhaustive analysis on a dataset of more than 1.5 million scientific papers of computer science domain. On analysis of the dataset, we notice that the citation count of the articles over the years follows a diverse set of patterns; on closer inspection we identify six broad categories of citation patterns. This important observation motivates us to adopt stratified learning approach in the prediction task, whereby, we propose a two-stage prediction model -- in the first stage, the model maps a query paper into one of the six categories, and then in the second stage a regression module is run only on the subpopulation corresponding to that category to predict the future citation count of the query paper. Experimental results show that the categorization of this huge dataset during the training phase leads to a remarkable improvement (around 50%) in comparison to the well-known baseline system.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {351–360},
numpages = {10},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740831,
author = {Liu, Xiaozhong and Yu, Yingying and Guo, Chun and Sun, Yizhou and Gao, Liangcai},
title = {Full-Text Based Context-Rich Heterogeneous Network Mining Approach for Citation Recommendation},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Citation relationship between scientific publications has been successfully used for scholarly bibliometrics, information retrieval and data mining tasks, and citation-based recommendation algorithms are well documented. While previous studies investigated citation relations from various viewpoints, most of them share the same assumption that, if paper1 cites paper2 (or author1 cites author2), they are connected, regardless of citation importance, sentiment, reason, topic, or motivation. However, this assumption is oversimplified. In this study, we employ an innovative "context-rich heterogeneous network" approach, which paves a new way for citation recommendation task. In the network, we characterize 1) the importance of citation relationships between citing and cited papers, and 2) the topical citation motivation. Unlike earlier studies, the citation information, in this paper, is characterized by citation textual contexts extracted from the full-text citing paper. We also propose algorithm to cope with the situation when large portion of full-text missing information exists in the bibliographic repository. Evaluation results show that, context-rich heterogeneous network can significantly enhance the citation recommendation performance.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {361–370},
numpages = {10},
keywords = {citation recommendation, heterogeneous information network, full-text citation analysis, meta-path},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740832,
author = {Huang, Wenyi and Wu, Zhaohui and Mitra, Prasenjit and Giles, C. Lee},
title = {RefSeer: A Citation Recommendation System},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Citations are important in academic dissemination. To help researchers check the completeness of citations while authoring a paper, we introduce a citation recommendation system called RefSeer. Researchers can use it to find related works to cited while authoring papers. It can also be used by reviewers to check the completeness of a paper's references. RefSeer presents both topic based global recommendation and also citation-context based local recommendation. By evaluating the quality of recommendation, we show that such recommendation system can recommend citations with good precision and recall. We also show that our recommendation system is very efficient and scalable.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {371–374},
numpages = {4},
keywords = {RefSeer, citation recommendation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740833,
author = {Alhoori, Hamed and Furuta, Richard},
title = {Do Altmetrics Follow the Crowd or Does the Crowd Follow Altmetrics?},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Changes are occurring in scholarly communication as scientific discourse and research activities spread across various social media platforms. In this paper, we study altmetrics on the article and journal levels, investigating whether the online attention received by research articles is related to scholarly impact or may be due to other factors. We define a new metric, Journal Social Impact (JSI), based on eleven data sources: CiteULike, Mendeley, F1000, blogs, Twitter, Facebook, mainstream news outlets, Google Plus, Pinterest, Reddit, and sites running Stack Exchange (Q&amp;A). We compare JSI against diverse citation-based metrics, and find that JSI significantly correlates with a number of them. These findings indicate that online attention of scholarly articles is related to traditional journal rankings and favors journals with a longer history of scholarly impact. We also find that journal-level altmetrics have strong significant correlations among themselves, compared with the weak correlations among article-level altmetrics. Another finding is that Mendeley and Twitter have the highest usage and coverage of scholarly activities. Among individual altmetrics, we find that the readership of academic social networks have the highest correlations with citation-based metrics. Our findings deepen the overall understanding of altmetrics and can assist in validating them.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {375–378},
numpages = {4},
keywords = {research impact, online reference managers, journal impact factor, social media, journal ranking, CiteULike, Facebook, F1000, Mendeley, Twitter, research evaluation, altmetrics},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740835,
author = {Sultan, Md Arafat and Bethard, Steven and Sumner, Tamara},
title = {Towards Automatic Identification of Core Concepts in Educational Resources},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Automatically identifying and extracting key ideas and concepts from educational resources is an important but challenging computational task. We present a supervised machine learning approach to assessing the "coreness" of concepts expressed by resource sentences. The algorithm has been developed and evaluated in the domain of science education where coreness refers to the degree to which a sentence embodies key concepts important to developing a robust understanding of the domain. Our method operates by automatically computing and leveraging the degree of semantic similarity between resource sentences and standard domain concepts designed by human experts for various STEM domains. In our experiments, the algorithm demonstrates high accuracy in identifying sentence coreness when there is agreement between human experts on the coreness rating. We also present performance comparisons with a number of baseline systems.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {379–388},
numpages = {10},
keywords = {semantic similarity, core concepts, text summarization},
location = {London, United Kingdom},
series = {JCDL '14}
}

@dataset{10.1145/review-2740769.2740835_R50997,
author = {Hazeltine, Barrett},
title = {Review ID:R50997 for DOI: 10.5555/2740769.2740835},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2740769.2740835_R50997}
}

@inproceedings{10.5555/2740769.2740836,
author = {Guo, Yan Ru and Goh, Dion Hoe-Lian and Luyt, Brendan},
title = {Using Affective Embodied Agents in Information Literacy Education},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This study aims to evaluate the impact of affective embodied agents (EAs) on students' learning performance in an online tutorial that teaches academic information seeking skills. A hundred and twenty tertiary students from two major universities participated in the between-subjects experiment. The results suggested that the use of affective EAs significantly increased students' learning motivation and enjoyment, compared to neutral-EAs or text-only conditions. However, there were no significant differences in knowledge retention between the three groups. This study paves the way for a better understanding of embedding affective EAs in online information literacy (IL) education. Furthermore, the improvement in students' learning motivation and enjoyment can serve as a basis for future research in this context.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {389–398},
numpages = {10},
keywords = {information seeking, knowledge retention, information literacy, information search process (ISP), affective agents, emotions, embodied agents, enjoyment, affect, motivation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740837,
author = {McKay, Dana},
title = {Bend Me, Shape Me: A Practical Experience of Repurposing Research Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper presents a practical experience of using a large, publically available dataset for a purpose that it was not originally collected The process is examined from discovery to analysis with reference to the vaunted but seldom seen ideal of data digital libraries.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {399–402},
numpages = {4},
keywords = {digital libraries, institutional repositories, data digital libraries, case study, data sharing, human factors},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740838,
author = {Costa, Mark R. and Qin, Jian and Wang, Jun},
title = {Research Networks in Data Repositories},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper reports our ongoing work investigating the structural features of scientific collaboration based on metadata collected from a scientific data repository (SDR). The background literature is reviewed in supporting our claim that metadata collected from SDRs offer a complimentary data source to traditional publication metadata collected from digital libraries. Methodological considerations are discussed in association with using metadata from SDRs, including author name disambiguation and data parsing. Initial findings show that the network has some unique macro-level structural features while also in agreement with existing networks theories. Challenges due to inconsistent metadata quality control procedures are also discussed in an attempt to reinforce claims that metadata should be designed to support both domain specific retrieval and evaluation and assessment needs.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {403–406},
numpages = {4},
keywords = {scientific data repositories, scientific collaboration networks, complex network analysis, scientific collaboration, metadata},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740840,
author = {Artini, Michele and Atzori, Claudio and Bardi, Alessia and La Bruzzo, Sandro and Manghi, Paolo},
title = {TagTick: A Tool for Annotation Tagging over Solr Indexes},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {"Annotation tagging" is an important curation action performed by authorized data curators willing to classify according to a common vocabulary an Information Space of potentially heterogeneous objects (e.g. not sharing common classification schemes). To carry out their activities, data curators need annotation tagging tools which allow them to bulk tag or untag large sets of objects in temporary work sessions, where they can experiment in real-time the effect of their actions before making the changes visible to end-users. Real-time temporary bulk tagging is a non trivial feature to implement, which strictly depends on the back-end used to index the Information Space. This demo presents TagTick, a tool which offers to data curators a fully functional annotation tagging environment over full-text index Apache Solr, considered a "de facto standard" in the field.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {407–408},
numpages = {2},
keywords = {annotation tagging, Apache Solr, full-text index, real-time update},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740841,
author = {Artini, Michele and Atzori, Claudio and Manghi, Paolo},
title = {Keeping Your Aggregative Infrastructure under Control},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {"Aggregative Data Infrastructures" (ADIs) are systems devised to collect metadata descriptions (and files) from several data sources to construct uniform Information Spaces, hence providing cross-data source access via standard APIs or custom portals. ADIs typically deal with data collection workflows from arbitrary numbers of data sources, with heterogeneous access protocols, data exchange formats, and data models. Besides, they handle data processing workflows for the harmonization and enrichment of aggregated metadata. Correct workflow management is crucial to ensure Information Space consistency, but is in general hard to sustain. This demo will present the solution offered in the context of the OpenAIRE infrastructure, which today collects metadata and files from around 450+ data sources (and growing) of several typologies. The D-NET Workflow Management Suite user interfaces support data curators at orchestrating overtime and in a sustainable way the configuration, execution, and monitoring of data collection and processing workflows for thousands of data sources.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {409–410},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740842,
author = {Kargakis, Yannis and Tzitzikas, Yannis},
title = {Epimenides: An Information System Offering Automated Reasoning for the Needs of Digital Preservation},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Epimenides is a system that can be used in the context of digital archives and digital libraries for helping archivists in checking whether the archived digital artifacts remain intelligible and functional, and in identifying the consequences of probable losses. A distinctive feature of Epimenides is that it can model also converters and emulators, and the adopted modelling approach enables the automatic reasoning needed for reducing the human effort required for checking whether a task can be performed over a digital object (or digital collection in general).},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {411–412},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740843,
author = {Holzmann, Helge and Risse, Thomas},
title = {Extraction of Evolution Descriptions from the Web},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The evolution of named entities affects exploration and retrieval tasks in digital libraries. An information retrieval system that is aware of name changes can actively support users in finding former occurrences of evolved entities. However, current structured knowledge bases, such as DBpedia or Freebase, do not provide enough information about evolutions, even though the data is available on their resources, like Wikipedia. Our Evolution Base prototype will demonstrate how excerpts describing name evolutions can be identified on these websites with a promising precision. The descriptions are classified by means of models that we trained based on a recent analysis of named entity evolutions on Wikipedia.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {413–414},
numpages = {2},
keywords = {named entity evolution, Wikipedia, semantics},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740844,
author = {Osborne, Francesco and Motta, Enrico},
title = {Rexplore: Unveiling the Dynamics of Scholarly Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Rexplore is a novel system that integrates semantic technologies, data mining techniques, and visual analytics to provide an innovative environment for making sense of scholarly data. Its functionalities include: i) a variety of views to make sense of important trends in research; ii) a novel semantic approach for characterising research topics; iii) a very fine-grained expert search with detailed multi-dimensional parameters; iv) an innovative graph view to relate a variety of academic entities; iv) the ability to detect and explore the main communities within a research topic; v) the ability to analyse research performance at different levels of abstraction, including individual researchers, organizations, countries, and research communities.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {415–416},
numpages = {2},
keywords = {data integration, data mining, empirical evaluation, ontology population, scholarly data, data exploration, visual analytics},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740845,
author = {Hall, Mark M.},
title = {Explore the Stacks: A System for Exploration in Large Digital Libraries},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Providing access to large digital library collections to novice users requires novel interfaces that are not built around the concept of search, as novice users frequently struggle to formulate appropriate queries. This paper presents the "Explore the Stacks" system, which provides a novel, browsing-focused interface for exploring digital library collections that is applicable to Big Data scale digital libraries. The system is demonstrated using a collection of approximately one million book illustrations provided by the British Library.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {417–418},
numpages = {2},
keywords = {digital library, exploration, user interface},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740846,
author = {Frommholz, Ingo and Graves, David and Liu, Haiming and Kumar, Ashwin and Brady, Gordon},
title = {Great War Stories Told by the People: Crowdsourced Cultural Heritage in Digital Museums},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The increasing interest in the centenary of the Great War 1914--1918 motivates the development of a digital library to capture and access valuable cultural heritage artefacts that would otherwise be lost. We will present a prototype to make available the story of the First World War in the local context of a British town, as told by the people today. The core of our prototype is crowdsourced ingest. To this end we apply latest insights from information interaction and access to foster user engagement. Open standards like CIDOC/CRM facilitate the external provision of our data and the integration of external resources. In the demo we will present our current Great War Stories prototype and how researchers from the humanities as well as digital libraries researchers will be able to benefit from and contribute to the project.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {419–420},
numpages = {2},
keywords = {CIDOC, crowdsourcing, user engagement and interaction, WW1, cultural heritage},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740847,
author = {Safey, Steffan and Bainbridge, David},
title = {When Catalogs Collide: A Mashup of the Bibliographic Records from New Zealand's National Bibliography and the HathiTrust},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this article we present work done developing an interactive comparison tool for large-scale catalogs using the general purpose open source digital library toolkit, Greenstone. The two catalogs selected to demonstrate the approach were the Bibliographic Records from New Zealand's National Bibliography and the HathiTrust. With Greenstone's triple-store extension activated, the two collections were ingested to form two Greenstone collections. Next, an interactive visualization tool was developed within the digital library's presentation layer to allow users to explore the two collections, comparing fields from the two collections and producing a variety of visualizations. The required interactivity was accomplished using AJAX calls to the Greenstone triple-store, further supported by the use of Javascript libraries for the presentation of the retrieved data in both visual and spreadsheet forms.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {421–422},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740848,
author = {Sztyler, Timo and Huber, Jakob and Noessner, Jan and Murdock, Jaimie and Allen, Colin and Niepert, Mathias},
title = {LODE: Linking Digital Humanities Content to the Web of Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Numerous digital libraries projects maintain their data collections in the form of text, images, and metadata. While data may be stored in many formats, from plain text to XML to relational databases, the use of the resource description framework (RDF) as a standardized representation has gained considerable traction during the last five years. Almost every digital humanities meeting has at least one session concerned with the topic of digital humanities, RDF, and linked data, including JCDL.While most existing work in linked data has focused on improving algorithms for entity matching, the aim of our Linked Open Data Enhancer Lode is to work "out of the box", enabling their use by humanities scholars, computer scientists, librarians, and information scientists alike.With Lode we enable non-technical users to enrich a local RDF repository with high-quality data from the Linked Open Data cloud. Lode links and enhances the local RDF repository without reducing the quality of the data. In particular, we support the user in the enhancement and linking process by providing intuitive user-interfaces and by suggesting high quality linking candidates using state of the art matching algorithms. We hope that the Lode framework will be useful to digital humanities scholars complementing other digital humanities tools.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {423–424},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740849,
author = {Duretec, Kresimir and Kulmukhametov, Artur and Kraxner, Michael and Plangg, Markus and Becker, Christoph and Faria, Luis},
title = {The SCAPE Preservation Lifecycle},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Continuous activities such as preservation monitoring, planning and operations, including the provisioning of access mechanisms or the creation of derivatives through migration, are needed to enable continuous access to content across evolving technological contexts without affecting the authenticity of digital objects. This article describes the SCAPE preservation suite, a loosely coupled set of systems and open APIs that facilitate scalable content profiling, monitoring, planning and workflow execution.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {425–426},
numpages = {2},
keywords = {digital curation, digital preservation, scalability, repositories},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740850,
author = {Larson, Ray R. and Pitti, Daniel and Turner, Adrian},
title = {SNAC: The Social Networks and Archival Context Project - towards an Archival Authority Cooperative},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Social Networks and Archival Context (SNAC) is a multi-year research and demonstration project that aims to address the longstanding research challenge of discovering, locating, and using distributed historical resources. It also seeks to redefine traditional online access points for those resources, by exposing information about the people, families, and organizations who created them in addition to their socio-historical contexts. Finally, SNAC endeavors to set the stage for a cooperative program for maintaining names of creators of archival materials, via the Encoded Archival Context - Corporate Bodies, Persons, and Families (EAC-CPF) standard.This demonstration will show the prototype access and search systems for the second phase of SNAC, incorporating over 2 million records derived from Encoded Archival Descriptions (EAD), MARC Archival Records and EAC-CPF records from over 40 repositories and consortia including the Library of Congress, ArchivesHub, Archives nationales, the Biblioth\`{e}que nationale de France (BnF), and OCLC World-Cat.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {427–428},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740851,
author = {You, Sukjin and DesArmo, Joel and Mu, Xiangming and Lee, Sukwon and Neal, Jessica C.},
title = {Visualized Related Topics (VRT) System for Health Information Retrieval},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {To help bridge the gap between consumer user's vocabulary and controlled vocabulary used to index health information, in this demo we implemented a Visualized Related Topics (VRT) browser system. The VRT was integrated into the "MeshMed" [2] system to support health information retrieval. The key technology behind the VRT browser is to select MeSH terms, which represent the related topics or subjects, from the top relevant documents. We rank these MeSH terms using the traditional Term Frequency-Inverse Document Frequency (TF-IDF) algorithm. The VRT browser displays a graphic representation of these MeSH terms by creating a visual where the selected MeSH terms stem from the centered user query. The design goal is provide users an overview of the key topics of the search results. In addition, VRT browser may also help users form better queries. Using the VRT browser we will be studying how to effectively assist in consumer users with their health information seeking.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {429–430},
numpages = {2},
keywords = {related terms, health information retrieval system, related terms browser, visualized related topics},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740853,
author = {El Raheb, Katerina and Ioannidis, Yannis},
title = {Modeling Abstractions for Dance Digital Libraries},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The description of the human body and its movement is fundamental and a critical part of the content of a Dance Digital Library. It must be captured in an organized way, both for allowing user interaction (browse, search) and computational analysis (similarity comparison) of dances, as well as for exploring meaningful ways to present content to users. In this paper, we present a comprehensive modeling abstraction for such digital libraries, which consists of a multi-layered model that covers different levels for describing dance movement. We address the semantic challenge of organizing knowledge of dance by starting from defining a dance piece or work, going to the characterization of its structural movement components and their related concepts and standard detailed movement description and notation i.e., Labanotation. In addition, we take into account the existing chorological research, as well as, related work in other domains, such as music information systems and standards i.e., IEEE 1599 and generic cultural heritage models i.e., FRBRoo. These modeling abstractions have been devised in the context of a more general on-going effort to develop a Dance Digital Library System and will be instrumental in some critical functionality, i.e., searching by movement concepts and characteristics in a meaningful way for a wide range of users, and linking different manifestations of movement recordings, descriptions, prescriptions or representations.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {431–432},
numpages = {2},
keywords = {conceptual models, dance digital libraries, intangible cultural heritage, labanotation, movement analysis},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740854,
author = {Shibata, Hirohito and Takano, Kentaro},
title = {Reading from Paper versus Reading from a Touch-Based Tablet Device in Proofreading},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper describes an experiment to evaluate the impact of the use of a touch-based digital reading device in active reading. We compared the performance of proofreading when using paper and when using a touch-based tablet device. Results showed that participants detected more errors when reading from paper than when reading from the tablet device. During reading, when using paper, participants frequently performed the interaction with text, such as pointing to words or sliding their fingers or pens along sentences. This fact suggests that interaction with text plays an important role in proofreading tasks.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {433–434},
numpages = {2},
keywords = {ergonomics, active reading, proofreading, touch-based tablet devices, digital reading devices},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740855,
author = {Barker, Michelle and Brower, Donald and Meyers, Natalie},
title = {Vector-Borne Disease Network Digital Library},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Vector-Borne Disease Network (VecNet)'s digital library provides part of a common analytical framework to assemble data on malaria transmission and make it accessible for the purposes of computational modeling. This poster-paper reports on VecNet digital library development, key decisions related to metadata standards, design, the central role of metadata and authority files in its architecture, and future directions of this Hydra/Fedora based repository solution.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {435–436},
numpages = {2},
keywords = {taxonomies, metadata, digital libraries, computational modeling geospatial analysis, vocabularies},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740856,
author = {Zhu, Yingzhen and Cao, Xinyi and Bian, Yali and Wu, Jiangqin},
title = {CKGHV: A Comprehensive Knowledge Graph for History Visualization},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {How to help users learn history efficiently is a problem. To solve it, We proposed CKGHV(Comprehensive Knowledge Graph for History Visualization). This paper focuses on analyzing character relationship of the three kingdoms, and proposed a visualization called overview map. Wordcloud and radiogram present information of battle and character relationship.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {437–438},
numpages = {2},
keywords = {knowledge learning, overview graph, text visualization},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740857,
author = {Ferreira, Filipe and Vieira, Ricardo and Borbinha, Jos\'{e}},
title = {The Value of Risk Management for Data Management in Science and Engineering},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {An established concept to address data management challenges in science and engineering is the Data Management Plans. However, we claim that in some complex scenarios the actual principles for Data Management Plans might not be enough, especially when Risk Management turns to be relevant. Therefore, we propose a method, based on the ISO 31000, for science and engineering projects to create a Risk Management Plan that can complement the Data Management Plan. The validation of this proposal is presented in the real case of an engineering laboratory.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {439–440},
numpages = {2},
keywords = {risk management, data management plan, science, risk management plan, data management, E-Science},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740858,
author = {Bergstrom, Tracy and Brower, Donald and Meyers, Natalie},
title = {Utilizing Digital Humanities Methods for Quantifying Howell's State Trials},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper we describe the undertaking of a quantitative, historically oriented analysis of the law of England between 1650-1700 as represented in Howell's State Trials. Our goal was to analyze cases over time to support investigation into whether a quantitative analysis of the content of the 1650-1700 State Trials would exhibit an upward trend of religious tolerance.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {441–442},
numpages = {2},
keywords = {legal history, visualization techniques, sentiment analysis, digital humanities, cosine-distance, latent Dirichlet allocation, concept classification, text analysis, topic modeling},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740859,
author = {Pop, Daniel and Neagul, Marian and Petcu, Dana},
title = {On Cloud Deployment of Digital Preservation Environments},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Although migrating library applications to Cloud environment is not an easy task, many libraries are interested in using Cloud infrastructure services broadly across their businesses, whether is about a Public, Private or Hybrid Cloud. One of the migration expectations is the scalability of digital preservation architectures in Cloud environments. In this paper we address the scalability and portability of storage and compute platforms, which combine storage of large datasets and their processing. Concretely, we propose a toolkit developed using Puppet configuration management system that facilitate the deployment of complex digital preservation platforms over heterogeneous Cloud environments and we present, as a use case, its integration with SCAPE platform.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {443–444},
numpages = {2},
keywords = {digital preservation, cloud computing},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740860,
author = {Takano, Kentaro and Shibata, Hirohito and Ichino, Junko and Hashiyama, Tomonori and Tano, Shun'ichi},
title = {Microscopic Analysis of Document Handling While Reading: Classification of Behavior toward Paper Document},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We conducted a microscopic analysis of work-related reading to find ways to support reading in the workplace. We obtained empirical data from video recording, concurrent verbal reporting, and retrospective reporting of 18 participants in 10 target types of reading using paper. Using these data, we categorized the ways people interact with paper while reading in detail. We will discuss what kinds of support are required for work-related reading.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {445–446},
numpages = {2},
keywords = {work-related reading, paper},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740861,
author = {Yang, Shansong and Lu, Weiming and Wei, Baogang and An, Wenjia},
title = {Amplifying Scientific Paper's Abstract by Leveraging Data-Weighted Reconstruction},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper considers the problem of amplifying scientific paper's abstract by using its citation sentences. While scientific paper's abstract is concise and subjective, its citation sentences, which can be regarded as one kind of comment, are redundant and objective. A summary combining the merits of those two resource is helpful to researchers. A data-weighted reconstruction approach is proposed to generate this summary and sentence's weight is learned through a ranking algorithm over hypergraph of bibliographic network. The experimental results show that the proposed approach can achieve significantly better than several document summarization's techniques.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {447–448},
numpages = {2},
keywords = {heterogeneous bibliographic network, document summarization, data-weighted reconstruction},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740862,
author = {Hasan, S. M. Shamimul and Gupta, Sandeep and Fox, Edward A. and Bisset, Keith and Marathe, Madhav V.},
title = {Data Mapping Framework in a Digital Library with Computational Epidemiology Datasets},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Computational epidemiology employs computer models and informatics tools to reason about the spatio-temporal spread of diseases. The diversity of models, data sources, data representations, and modalities that are collected, used, and modified motivate the development of a digital library (DL) framework to support computational epidemiology. The heterogeneous content includes metadata, text, tables, spreadsheets, experimental descriptions, and large result files. There is no accepted framework that allows unified access to such content. We propose a framework for a digital library system tailored to such datasets to support computational network epidemiology.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {449–450},
numpages = {2},
keywords = {digital library, simulation, epidemiology},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740863,
author = {Zhou, Ke and Tobin, Richard and Grover, Claire},
title = {Extraction and Analysis of Referenced Web Links in Large-Scale Scholarly Articles},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper we report on a sub-task undertaken as part of Hiberlink, a project which is examining the phenomenon of reference rot within scholarly works. In our sub-task we aim to quantify and understand the nature of occurrence of links to web resources referenced from papers in very large-scale scholarly collections. We first introduce the challenges involved in extracting links from scholarly articles and develop and evaluate the accuracy of a set of link extraction systems. Secondly, five collections containing millions of scholarly articles with different characteristics (across different disciplines, time periods and publication types) are studied and we demonstrate that web resources are widely cited in scholarly publications and should be an important concern for digital preservation.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {451–452},
numpages = {2},
keywords = {scholarly data, link extraction, digital preservation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740864,
author = {Choi, Kahyun and Lee, Jin Ha and Downie, J. Stephen},
title = {What is This Song about Anyway? Automatic Classification of Subject Using User Interpretations and Lyrics},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Metadata research for music digital libraries has traditionally focused on genre. Despite its potential for improving the ability of users to better search and browse music collections, music subject metadata is an unexplored area. The objective of this study is to expand the scope of music metadata research, in particular, by exploring music subject classification based on user interpretations of music. Furthermore, we compare this previously unexplored form of user data to lyrics at subject prediction tasks. In our experiment, we use datasets consisting of 900 songs annotated with user interpretations. To determine the significance of performance differences between the two sources, we applied Friedman's ANOVA test on the classification accuracies. The results show that user-generated interpretations are significantly more useful than lyrics as classification features (p &lt; 0.05). The findings support the possibility of exploiting various existing sources for subject metadata enrichment in music digital libraries.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {453–454},
numpages = {2},
keywords = {music, data mining, text classification, lyrics, user-generated content, music information retrieval, subject, metadata},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740865,
author = {Barrio, Pablo and Sim\~{o}es, Gon\c{c}alo and Galhardas, Helena and Gravano, Luis},
title = {REEL: A Relation Extraction Learning Framework},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We introduce the REEL (RElation Extraction Learning) framework, an open source framework that facilitates the development and evaluation of relation extraction systems over text collections. To define a relation extraction system for a new relation and text collection, users only need to specify the parsers to load the collection, the relation and its constraints, and the learning and extraction techniques to be used. This makes REEL a powerful framework to enable the deployment and evaluation of relation extraction systems for both application building and research.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {455–456},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740866,
author = {Alam, Andias Wira and Kempf, Andreas Oskar and Zapilko, Benjamin},
title = {Linking the Thesaurus for the Social Sciences to the Web of Linked Data},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper, we apply different methods for linking subject headings of the Thesaurus for the Social Sciences (TheSoz) to DBpedia, the nucleus of the Web of Linked Data which is derived from the structured information of Wikipedia. Our method utilizes the backlinks and outlinks within Wikipedia for link detection. We examine to what extent the linking process can be optimized with the help of a network-based similarity measure, in order to achieve a higher precision and recall. We test two baseline methods, string alignment and language property matching and compare them to our own method. Our method outperforms the F-scores of the baselines by 10 percentage points.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {457–458},
numpages = {2},
keywords = {Wikipedia, entity linking, experiments, term matching, social sciences, information retrieval, thesaurus},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740867,
author = {Mayer, Rudolf and Rauber, Andreas and Antunes, Gon\c{c}alo},
title = {A Context Model for Digital Preservation of Processes and Its Application to a Digital Library System},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Digital preservation is an important aspect to ensure authenticity, traceability and auditing in processes. Digital Library Systems are one example where data transformation processes are executed upon collections of data, and where such preservation of processes is an important aspect for the trustworthiness of the repository. We thus present a model for the semantic description of processes, and apply it on a Digital Library System.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {459–460},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740868,
author = {Di Iorio, Angela and Schaerf, Marco},
title = {The Organization Information Integration in the Management of a Digital Library System},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {The Sapienza Digital Library collects digital resources from the different University's Organizations representing the multidisciplinary Sapienza University's community. The poster presents the pre-ingestion process for creating and aggregating digital resources, under the Organizational Collection conceptualization. The pre-ingestion building process had allowed to automatically provide information about the resources' custody from the origination, until their creation as OAIS Submission Information Package. Whatever system able to provide archival, preservation or dissemination services, could potentially use it, maintaining provenance information.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {461–462},
numpages = {2},
keywords = {digital libraries organization, semantic web, digital libraries, workflow modeling, information integration},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740869,
author = {Agata, Teru and Miyata, Yosuke and Ishita, Emi and Ikeuchi, Atsushi and Ueda, Shuichi},
title = {Life Span of Web Pages: A Survey of 10 Million Pages Collected in 2001},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper highlights the results of a survival survey and life span study of 10 million web pages, mainly in Japanese, that were collected for NTCIR-3 (web task) in 2001. To calculate web page life span, metadata was collected from Internet Archive's Wayback Machine via Memento. The life span study showed that the average life span of a web page is 1,132.1 days.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {463–464},
numpages = {2},
keywords = {web page life span, web archiving, internet archive, digital preservation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740870,
author = {Moreno, Jose G. and Dias, Ga\"{e}l},
title = {PageRank-Based Word Sense Induction within Web Search Results Clustering},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Word Sense Induction is an open problem in Natural Language Processing. Many recent works have been addressing this problem with a wide spectrum of strategies based on content analysis. In this paper, we present a sense induction strategy exclusively based on link analysis over the Web. In particular, we explore the idea that the main different senses of a given word share similar linking properties and can be found by performing clustering with link-based similarity metrics. The evaluation results show that PageRank-based sense induction achieves interesting results when compared to state-of-the-art content-based algorithms in the context of Web Search Results Clustering.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {465–466},
numpages = {2},
keywords = {word sense induction, PageRank clustering, web links},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740871,
author = {Chen, Jiangping and Azogu, Olajumoke and Knudson, Ryan},
title = {Enabling Multilingual Information Access to Digital Collections: An Investigation of Metadata Records Translation},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We conducted a research project exploring machine translation performance on digital metadata records. This short paper reports the background, research purposes, research design, experiments, and evaluation results.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {467–468},
numpages = {2},
keywords = {multilingual information access, metadata, digital libraries},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740872,
author = {Kelly, Mat and Nelson, Michael L. and Weigle, Michele C.},
title = {Mink: Integrating the Live and Archived Web Viewing Experience Using Web Browsers and Memento},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We describe Mink, a new web browser extension that provides a different model for integration of the live and archived web. While a user browses the live web, Mink actively queries the archives and reports other instances of the page in the archives without requiring active querying by the user. Further, by querying the archives dynamically and asynchronously, a user can view the extent to which the currently viewed page on the live web has been archived and proactively submit a request to various archives using an overlay on the live web page and a simple interface.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {469–470},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740873,
author = {Hu, Xiao and Yang, Yi-Hsuan},
title = {Cross-Cultural Mood Regression for Music Digital Libraries},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Mood is a popular access point in music digital libraries and online music repositories, and is often represented as numerical values in a small number of emotion-related dimensions (e.g., valence and arousal). As music mood is recognized as culturally dependent, this study investigates whether regression models built with music data in one culture can be applied to music in another culture. Results indicate that cross-cultural predictions of both valence and arousal values are feasible.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {471–472},
numpages = {2},
keywords = {music digital libraries, cross-cultural, regression, music mood},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740874,
author = {Kern, Dagmar and Mutschke, Peter and Mayr, Philipp},
title = {Establishing an Online Access Panel for Interactive Information Retrieval Research},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {We propose an online access panel to support the evaluation process of Interactive Information Retrieval (IIR) systems - called IIRpanel. By maintaining an online access panel with users of IIR systems we assume that the recurring effort to recruit participants for web-based as well as for lab studies can be minimized. We target on using the online access panel not only for our own development processes but to open it for other interested researchers in the field of IIR. In this paper we present the concept of IIRpanel as well as first implementation details.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {473–474},
numpages = {2},
keywords = {online research, user interface development, interactive information retrieval, participant recruiting support, online access panel, retrieval evaluation},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740875,
author = {Rossi, Stephanie and Lee, Jin Ha and Clarke, Rachel Ivy},
title = {Mood Metadata for Video Games and Interactive Media},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Video games are becoming an important part of digital library collections due to increasing popularity and the acknowledgement of their significance as cultural artifacts. In order to support robust search and browse functions, it is imperative to develop a metadata schema to effectively represent this medium. The potential of mood metadata in the domain of video game classification is little explored, despite the value given to it by gamers in user studies. Here, we present a Controlled Vocabulary (CV) for moods related to video games with 17 defined mood terms, equivalent terms, and game examples. This CV will enable catalogers to organize video games by mood, allowing mood to be used for search and collocation. In order to evaluate the applicability of this CV and discover which terms are most relevant for video games, we annotated the mood of a sample collection of 617 video game titles. In this poster, we discuss the issues and challenges we encountered in the creation and evaluation of the current CV and our future research goals.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {475–476},
numpages = {2},
keywords = {mood, controlled vocabulary, taxonomy, thesaurus, video game},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740876,
author = {You, Sukjin and DesArmo, Joel and Mu, Xiangming and Dimitroff, Alexandra},
title = {Balancing Factors Affecting Virtual Reference Services: Identified from Academic Librarians' Perspective},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Many digital libraries are providing Virtual Reference Services (VRS). There could be various approaches to increase the quality of VRS. In this study, we focused on two key factors; improving helpfulness and reducing user's feeling of intrusiveness. Studies indicated that librarian-initiated attempts for help may increase user's feeling of intrusiveness [2] [3]. It is challenging to provide high helpfulness along with less intrusiveness in VRS. This study aimed to identify factors that contribute to improving helpfulness and reducing intrusiveness. Data were collected based on a survey using systemic random sample approach. Our initial results indicated that awareness, timing, and transparency were key factors affecting the helpfulness and intrusiveness.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {477–478},
numpages = {2},
keywords = {helpfulness, transparency, intrusiveness, awareness, virtual reference services, timing},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740877,
author = {Weideman, Melius},
title = {Articles, Papers, Chapters, Theses: Who Wins the Visibility Wars?},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Researchers need access to previous research to base their own work on. Some of the most commonly referenced materials are published in the form of journal articles, conference papers, books and book chapters, and research theses. The purpose of this research was to determine how these four categories of documents compare in terms of visibility to search engine crawlers. A questionnaire was used to gather data from international scholars on their completed research. Three types of queries were generated and over 3000 websites were inspected to determine the visibility of these outputs. Search engine result pages were inspected, and the rankings of the research documents were recorded and converted to a scoring system. The results have indicated that the four types of outputs enjoy varying degrees of exposure to search engines, with journal articles leading the way, and books/book chapters having the smallest degree of exposure to search engines. Some query types also produced better results than others. It was concluded that journal articles provide the best way to expose research work to Internet searchers through search engines.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {479–480},
numpages = {2},
keywords = {book, ranking, journal article, conference paper, thesis, search engine},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740878,
author = {Clarke, Rachel Ivy and Lee, Jin Ha and Jett, Jacob and Sacchi, Simone},
title = {Exploring Relationships among Video Games},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This poster explores relationships among video games in an attempt to better understand the domain of video games and interactive media as well as improve user access to games. Video games are related in complex ways that cannot be adequately represented by contemporary conceptual models like Functional Requirements for Bibliographic Records (FRBR). Relationships between game editions, series, distribution methods and additional game content all pose challenges for those seeking to describe video games in a user-centered way.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {481–482},
numpages = {2},
keywords = {metadata, conceptual models, video games, relationships},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740879,
author = {Koopman, Rob and Wang, Shenghui},
title = {Where Should I Publish? Detecting Journal Similarity Based on What Have Been Published There},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Finding similar journals within a large amount of existing ones is not a trivial task. Based on the hypothesis that similar journals publish similar articles, we propose in this paper a scalable method based on random projection to calculate the similarities between 35K journals based on 67 millions articles published with them. We evaluate our results against Dewey Decimal codes and analyse the networks of similar journals.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {483–484},
numpages = {2},
keywords = {random projection, similarity measures, network analysis},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740880,
author = {Zhang, Hong and Hu, Xiao},
title = {A Quantitative Comparison on File Folder Structures of Two Groups of Information Workers},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This study compares file folder structures on personal computers of two groups of information workers, administrative staff and PhD students. A set of quantitative measures are calculated which disclose the differences and similarities between folder structures of the two user groups. The results shows that the group conducting more administrative activities has broader and shallower folders than the PhD group who performs more research activities, and the folders of the PhD group are more populated over deeper levels of the trees than those of the administrative group. The study improves our understanding of the various quantitative measures in investigating personal computer folder structures, and furthermore contributes to our knowledge of the information organization structure in personal information systems.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {485–486},
numpages = {2},
keywords = {quantitative measures, personal information organization, information workers, file structures, user groups},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740881,
author = {Dibie, Ogheneovo and Maull, Keith and Sumner, Tamara},
title = {A Computational Approach to Understanding and Predicting the Behavior of Educators Using an Online Curriculum Planning Tool},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {This paper presents a computational approach to understanding and predicting the behavior of Earth Science educators using an online curriculum planning tool incorporating digital library resources. It expands on prior work on understanding educators' adoption and use of digital library resources [2] by introducing a methodology for characterizing user behaviors and understanding the trends and frequent patterns of use that are observable from these behaviors.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {487–488},
numpages = {2},
keywords = {frequent pattern mining, prediction, technology use, classification, educational digital libraries, use diffusion},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740882,
author = {Batjargal, Biligsaikhan and Khaltarkhuu, Garmaabazar and Kimura, Fuminori and Maeda, Akira},
title = {An Approach to Named Entity Extraction from Historical Documents in Traditional Mongolian Script},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this poster, we propose an information extraction method for digitized ancient Mongolian documents by utilizing an ancient-modern dictionary. Named entities such as historical figures and place names will be extracted by employing text mining techniques that aim to reduce the labor-intensive annotation on historical text. The Text Encoding Initiative (TEI) guidelines will be applied to digital text representations that encode the historical figures and place names along with their interpretations, and commentaries.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {489–490},
numpages = {2},
keywords = {traditional Mongolian script, historical documents, named entity extraction, digital library},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740883,
author = {Kats, Pavel and Knoth, Petr and Mamakis, Georgios and Mielnicki, Marcin and Muhr, Markus and Werla, Marcin},
title = {Design of Europeana Cloud Technical Infrastructure},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {In this paper, we present the overview of Europeana Cloud system, which is a new undertaking of Europeana Foundation and partnering institutions aimed to provide shared, cloud-based infrastructure for aggregation and exchange of cultural heritage metadata and content for European institutions.},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {491–492},
numpages = {2},
keywords = {metadata aggregation, cloud architecture, digital libraries, Europeana},
location = {London, United Kingdom},
series = {JCDL '14}
}

@inproceedings{10.5555/2740769.2740884,
author = {Llewellyn, Clare and Ruus, Laine and Burnett, Ros and Kirkwood, Steve and Smith, Mark and von-Jungenfeld, Rocio},
title = {Building a Dataset of Sensitive Information},
year = {2014},
isbn = {9781479955695},
publisher = {IEEE Press},
abstract = {Using text analysis tools to study large data sets is currently an area of popular interest. Prompted by the success of several big data research initiatives, researchers from a variety of disciplines wish to gather and analyse textual data [7]. Communication between members of diverse teams can present a problem and developing a shared language and understanding of the task is necessary [6].},
booktitle = {Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries},
pages = {493–494},
numpages = {2},
location = {London, United Kingdom},
series = {JCDL '14}
}

