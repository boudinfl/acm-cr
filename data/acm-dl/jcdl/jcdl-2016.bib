@inproceedings{10.1145/2910896.2926740,
author = {Zemankova, Maria},
title = {Future Digital Libraries: Research and Responsibilities},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926740},
doi = {10.1145/2910896.2926740},
abstract = {In October 1991 the National Science Foundation (NSF) sponsored a workshop to examine the role of the Information Retrieval research community in the emerging environment of Internet, high performance text processing capabilities and ever-increasing volumes of digitized documents. Ed Fox, Michael Lesk and Michael McGill drafted a White Paper, calling for a National Electronic Science, Engineering, and Technology Library. The term "Digital Library" was adopted and for follow-up workshops with the goal to identify research directions, leading to National Science Foundation (NSF)/Defense Advanced Research Projects Agency (DARPA)/National Aeronautics and Space Administration (NASA) Research in Digital Libraries Initiative announced in late 1993. Now, in 2016, 25 years after the first workshop, 15 years after the Joint Conference on Digital Libraries has been established, and many initiatives and developments around the world, what is the state of Digital Libraries? What items should be in digital libraries, who should their custodians, how can the items be organized to support knowledge discovery, how can the contents be safeguarded and preserved? Ebla, Syria (2500 B.C. - 2250 B.C.) constitutes the oldest organized library of tables yet discovered. What will the archaeologists discover in year 4400 about the world, politics, economies, technologies, science, climate, species, health, food, culture, art, entertainment and everyday life through the ages? The talk will examine what we can do to support innovative research and design and implementation of lasting, informative Digital Libraries that will promote global goals of knowledge discovery and international understanding and personal needs to organize and selectively share important facts, creations, and memories.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {1},
numpages = {1},
keywords = {digitized documents, preservation, digital library, knowledge discovery},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926741,
author = {Frick, Rachel},
title = {The State of Practice and Use of Digital Collections: The Digital Public Library of America as a Platform for Research},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926741},
doi = {10.1145/2910896.2926741},
abstract = {In 2016, Digital Public Library of America is celebrating the third year of its cultural heritage metadata aggregator service. Since its launch, the DPLA collection has grown to represent over 13 million objects and over 1900 institutions, from small historical societies to large research libraries. With onramps, or hubs, in over 20 states, DPLA is well on its way to complete the coverage map by the end of 2017. As it continues to build this amazing dataset, DPLA is taking the time to examine what lessons are to be learned from this unprecedented resource, as the organization's sustainability is directly tied to how the collection grows, how it measures use, and proving its value to the communities it serves. What does this collection data tell us about the state of bibliographic holdings information, and the knowledge and skills and abilities of those who create records, not just for local use, but for use in other environments and contexts? How well does the metadata perform when it leaves its original context? Working with colleagues at Europeana, DPLA has begun investigating and addressing the problematic issues regarding access and reuse of digital objects in the collective by examining current ways rights are expressed in the metadata, working towards standardization of this information. Ms. Frick will discuss DPLA's rights work, as well as other potential areas of research and DPLA's strategy for future growth.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {3},
numpages = {1},
keywords = {open data, collection aggregation, national digital libraries},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926742,
author = {Bury, Stephen},
title = {The Energy of Delusion: The New York Art Resources Consortium (NYARC) &amp; The Digital},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926742},
doi = {10.1145/2910896.2926742},
abstract = {Museum libraries came late to the digitization party - primarily because of perceived copyright issues. Since 2010 the three libraries of the New York Art Resources Consortium (NYARC) have embarked on a series of niche, boutique digitization projects, pushing the boundaries of fair use, but they have also embraced the born-digital, establishing a program to capture art-history-rich websites and to give access to them via an innovative use of a discovery layer which prioritizes web resources in the ranking of results.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {5–6},
numpages = {2},
keywords = {born-digital, discovery layer, art research, digitization, world wide web},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910907,
author = {Traub, Myriam C. and Samar, Thaer and van Ossenbruggen, Jacco and He, Jiyin and de Vries, Arjen and Hardman, Lynda},
title = {Querylog-Based Assessment of Retrievability Bias in a Large Newspaper Corpus},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910907},
doi = {10.1145/2910896.2910907},
abstract = {Bias in the retrieval of documents can directly influence the information access of a digital library. In the worst case, systematic favoritism for a certain type of document can render other parts of the collection invisible to users. This potential bias can be evaluated by measuring the retrievability for all documents in a collection. Previous evaluations have been performed on TREC collections using simulated query sets. The question remains, however, how representative this approach is of more realistic settings.To address this question, we investigate the effectiveness of the retrievability measure using a large digitized newspaper corpus, featuring two characteristics that distinguishes our experiments from previous studies: (1) compared to TREC collections, our collection contains noise originating from OCR processing, historical spelling and use of language; and (2) instead of simulated queries, the collection comes with real user query logs including click data.First, we assess the retrievability bias imposed on the newspaper collection by different IR models. We assess the retrievability measure and confirm its ability to capture the retrievability bias in our setup. Second, we show how simulated queries differ from real user queries regarding term frequency and prevalence of named entities, and how this affects the retrievability results.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {7–16},
numpages = {10},
keywords = {digital library, digital humanities, user query logs, retrievability bias},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910911,
author = {Jatowt, Adam and Kawai, Daisuke and Tanaka, Katsumi},
title = {Digital History Meets Wikipedia: Analyzing Historical Persons in Wikipedia},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910911},
doi = {10.1145/2910896.2910911},
abstract = {Wikipedia is the result of a collaborative effort aiming to represent human knowledge and to make it accessible for everyone. As such it contains lots of contemporary as well as history-related information. This research looks into historical data available in Wikipedia to explore its various time-related characteristics. In particular, we study Wikipedia articles on historical persons. Our analysis sheds new light on the characteristics of information about historical persons in Wikipedia and quantifies user interest in such data. We use signals derived from the hyperlink structure of Wikipedia as well as from article view logs and we overlay them over temporal dimension to understand relations between time, link structure and article popularity. In the latter part of the paper, we also demonstrate different ways for estimating person importance based on the temporal aspects of the link structure.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {17–26},
numpages = {10},
keywords = {digital history, temporal link analysis, social networks, wikipedia, historical analysis},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910917,
author = {Dang, Quang Vinh and Ignat, Claudia-Lavinia},
title = {Quality Assessment of Wikipedia Articles without Feature Engineering},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910917},
doi = {10.1145/2910896.2910917},
abstract = {As Wikipedia became the largest human knowledge repository, quality measurement of its articles received a lot of attention during the last decade. Most research efforts focused on classification of Wikipedia articles quality by using a different feature set. However, so far, no ``golden feature set" was proposed. In this paper, we present a novel approach for classifying Wikipedia articles by analysing their content rather than by considering a feature set. Our approach uses recent techniques in natural language processing and deep learning, and achieved a comparable result with the state-of-the-art.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {27–30},
numpages = {4},
keywords = {wikipedia, document representation, feature engineering, deep learning, quality assessment},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910915,
author = {Budig, Benedikt and van Dijk, Thomas C. and Kirchner, Felix},
title = {Glyph Miner: A System for Efficiently Extracting Glyphs from Early Prints in the Context of OCR},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910915},
doi = {10.1145/2910896.2910915},
abstract = {While off-the-shelf OCR systems work well on many modern documents, the heterogeneity of early prints provides a significant challenge. To achieve good recognition quality, existing software must be "trained" specifically to each particular corpus. This is a tedious process that involves significant user effort. In this paper we demonstrate a system that generically replaces a common part of the training pipeline with a more efficient workflow: Given a set of scanned pages of a historical document, our system uses an efficient user interaction to semi-automatically extract large numbers of occurrences of glyphs indicated by the user. In a preliminary case study, we evaluate the effectiveness of our approach by embedding our system into the workflow at the University Library W\"{u}rzburg.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {31–34},
numpages = {4},
keywords = {glyph extraction, early prints, ocr, document recognition, efficient user interaction},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910903,
author = {Jett, Jacob and Nurmikko-Fuller, Terhi and Cole, Timothy W. and Page, Kevin R. and Downie, J. Stephen},
title = {Enhancing Scholarly Use of Digital Libraries: A Comparative Survey and Review of Bibliographic Metadata Ontologies},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910903},
doi = {10.1145/2910896.2910903},
abstract = {The HathiTrust Research Center (HTRC) is engaged in the development of tools that will give scholars the ability to analyze the HathiTrust digital library's 14 million volume corpus. A cornerstone of the HTRC's digital infrastructure is the workset -- a kind of scholar-built research collection intended for use with the HTRC's analytics platform. Because more than 66% of the digital corpus is subject to copyright restrictions, scholarly users remain dependent upon the descriptive accounts provided by traditional metadata records in order to identify and gather together bibliographic resources for analysis. This paper compares the MADSRDF/MODSRDF, Bibframe, schema.org, BIBO, and FaBiO ontologies by assessing their suitability for employment by the HTRC to meet scholars' needs. These include distinguishing among multiple versions of the same work; representing the complex historical and physical relationships among those versions; and identifying and providing access to finer grained bibliographic entities, e.g., poems, chapters, sections, and even smaller segments of content.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {35–44},
numpages = {10},
keywords = {bibliographic metadata, ontologies, digital libraries},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910906,
author = {Esteva, Maria and Sweat, Sandra and McLay, Robert and Xu, Weijia and Kulasekaran, Sivakumar},
title = {Data Curation with a Focus on Reuse},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910906},
doi = {10.1145/2910896.2910906},
abstract = {A dataset from the field of High Performance Computing (HPC) was curated with the focus on facilitating its reuse and to appeal to a broader audience beyond HPC specialists. At an early stage in the research project, the curators gathered requirements from prospective users of the dataset, focusing on how and for which research projects they would reuse the data. Users needs informed which curation tasks to conduct, which included: adding more information elements to the dataset to expand its content scope; removing personal information; and, packaging the data in a size, a format, and at a frequency of delivery that are convenient for access and analysis purposes. The curation tasks are embedded in the software that produces the data, and are implemented as an automated workflow that spans various HPC resources, in which the dataset is generated, processed and stored and the Texas ScholarWorks institutional repository, through which the data is published. Within this distributed architecture, the integrated data creation and curation workflow complies with long-term preservation requirements, and is the first one implemented as a collaboration between the supercomputing center where the data is created on ongoing basis, and the University Libraries at UT Austin where it is published. The targeted curation strategy included the design of proof of concept data analyses to evaluate if the curated data met the reuse scenarios proposed by users. The results suggest that the dataset is understandable, and that researchers can use it to answer some of the research questions they posed. Results also pointed to specific elements of the curation strategy that had to be improved and disclosed the difficulties involved in breaking data to new users.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {45–54},
numpages = {10},
keywords = {data curation, distributed collections architecture, data publishing and reuse., high performance computing},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910919,
author = {Marshall, Byron and Reitsma, Ren\'{e} and Samson, Carleigh},
title = {Unraveling K-12 Standard Alignment: Report on a New Attempt},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910919},
doi = {10.1145/2910896.2910919},
abstract = {We present the results of an experiment which indicate that automated alignment of electronic learning objects to educational standards may be more feasible than previously implied. We highlight some important deficiencies in existing alignment systems and formulate suggestions for improved future ones. We consider how the changing substance of newer educational standards, a multi-faceted view of standard alignment, and a more nuanced view of the alignment concept may bring the long-sought goal of automated standard alignment closer. We explore how lexical similarity of documents, a World+Method representation of semantics, and network-based analysis can yield promising results. We furthermore investigate the nature of false positives to better understand how validity of match is evaluated so as to better focus future alignment system development.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {55–58},
numpages = {4},
keywords = {semantic analysis, natural language processing, reliability, educational standard alignment, measurement},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910921,
author = {Wu, Dan and Liang, Shaobo},
title = {Research on the Follow-up Actions of College Students' Mobile Search},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910921},
doi = {10.1145/2910896.2910921},
abstract = {This paper focuses on the follow-up actions triggered by college students' mobile searches, which involved 30 participants conducting an uncontrolled experiment in fifteen days. We collected the mobile phone usage data by an app called AWARE, and combined with structured diary and interviews to perform a quantitative and qualitative study. The results showed that, there were three categories of follow-up actions and majority of these actions occurred within one hour after the initial search session. We also found that participants often conducted follow-up actions with different apps, and certain information needs triggered more follow-up actions. We finally discussed the characteristics and the causes of these actions, and stated further studies which include comparing follow-up actions triggered by mobile search and that of Web search, and building a model for the follow-up actions.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {59–62},
numpages = {4},
keywords = {search behavior, follow-up action, user behavior., mobile search},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910899,
author = {Bornand, Nicolas J. and Balakireva, Lyudmila and Van de Sompel, Herbert},
title = {Routing Memento Requests Using Binary Classifiers},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910899},
doi = {10.1145/2910896.2910899},
abstract = {The Memento protocol provides a uniform approach to query individual web archives. Soon after its emergence, Memento Aggregator infrastructure was introduced that supports querying across multiple archives simultaneously. An Aggregator generates a response by issuing the respective Memento request against each of the distributed archives it covers. As the number of archives grows, it becomes increasingly challenging to deliver aggregate responses while keeping response times and computational costs under control. Ad-hoc heuristic approaches have been introduced to address this challenge and research has been conducted aimed at optimizing query routing based on archive profiles. In this paper, we explore the use of binary, archive-specific classifiers generated on the basis of the content cached by an Aggregator, to determine whether or not to query an archive for a given URI. Our results turn out to be readily applicable and can help to significantly decrease both the number of requests and the overall response times without compromising on recall. We find, among others, that classifiers can reduce the average number of requests by 77% compared to a brute force approach on all archives, and the overall response time by 42% while maintaining a recall of 0.847.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {63–72},
numpages = {10},
keywords = {machine learning, memento, web archiving, request routing},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910901,
author = {Holzmann, Helge and Nejdl, Wolfgang and Anand, Avishek},
title = {The Dawn of Today's Popular Domains: A Study of the Archived German Web over 18 Years},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910901},
doi = {10.1145/2910896.2910901},
abstract = {The Web has been around and maturing for 25 years. The popular websites of today have undergone vast changes during this period, with a few being there almost since the beginning and many new ones becoming popular over the years. This makes it worthwhile to take a look at how these sites have evolved and what they might tell us about the future of the Web. We therefore embarked on a longitudinal study spanning almost the whole period of the Web, based on data collected by the Internet Archive starting in 1996, to retrospectively analyze how the popular Web as of now has evolved over the past 18 years.For our study we focused on the German Web, specifically on the top 100 most popular websites in 17 categories. This paper presents a selection of the most interesting findings in terms of volume, size as well as age of the Web. While related work in the field of Web Dynamics has mainly focused on change rates and analyzed datasets spanning less than a year, we looked at the evolution of websites over 18 years. We found that around 70% of the pages we investigated are younger than a year, with an observed exponential growth in age as well as in size up to now. If this growth rate continues, the number of pages from the popular domains will almost double in the next two years. In addition, we give insights into our data set, provided by the Internet Archive, which hosts the largest and most complete Web archive as of today.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {73–82},
numpages = {10},
keywords = {retrospective, statistics, web dynamics, analysis, longitudinal},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910902,
author = {Holzmann, Helge and Goel, Vinay and Anand, Avishek},
title = {ArchiveSpark: Efficient Web Archive Access, Extraction and Derivation},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910902},
doi = {10.1145/2910896.2910902},
abstract = {Web archives are a valuable resource for researchers of various disciplines. However, to use them as a scholarly source, researchers require a tool that provides efficient access to Web archive data for extraction and derivation of smaller datasets. Besides efficient access we identify five other objectives based on practical researcher needs such as ease of use, extensibility and reusability.Towards these objectives we propose ArchiveSpark, a framework for efficient, distributed Web archive processing that builds a research corpus by working on existing and standardized data formats commonly held by Web archiving institutions. Performance optimizations in ArchiveSpark, facilitated by the use of a widely available metadata index, result in significant speed-ups of data processing. Our benchmarks show that ArchiveSpark is faster than alternative approaches without depending on any additional data stores while improving usability by seamlessly integrating queries and derivations with external tools.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {83–92},
numpages = {10},
keywords = {data extraction, web archives, big data},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910910,
author = {Hinze, Annika and Bainbridge, David and Cunningham, Sally Jo and Downie, J. Stephen},
title = {Low-Cost Semantic Enhancement to Digital Library Metadata and Indexing: Simple Yet Effective Strategies},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910910},
doi = {10.1145/2910896.2910910},
abstract = {Most existing digital libraries use traditional lexically-based retrieval techniques. For established systems, completely replacing, or even making significant changes to the document retrieval mechanism (document analysis, indexing strategy, query processing and query interface) would require major technological effort, and would most likely be disruptive. In this paper, we describe ways to use the results of semantic analysis and disambiguation, while retaining an existing keyword-based search and lexicographic index. We engineer this so the output of semantic analysis (performed off-line) is suitable for import directly into existing digital library metadata and index structures, and thus incorporated without the need for architecture modifications.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {93–102},
numpages = {10},
keywords = {semantic enrichment, indexing, semantic analysis, disambiguation},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910912,
author = {Jackson, Andrew and Lin, Jimmy and Milligan, Ian and Ruest, Nick},
title = {Desiderata for Exploratory Search Interfaces to Web Archives in Support of Scholarly Activities},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910912},
doi = {10.1145/2910896.2910912},
abstract = {Web archiving initiatives around the world capture ephemeral web content to preserve our collective digital memory. In this paper, we describe initial experiences in providing an exploratory search interface to web archives for humanities scholars and social scientists. We describe our initial implementation and discuss our findings in terms of desiderata for such a system. It is clear that the standard organization of a search engine results page (SERP), consisting of an ordered list of hits, is inadequate to support the needs of scholars. Shneiderman's mantra for visual information seeking ("overview first, zoom and filter, then details-on-demand") provides a nice organizing principle for interface design, to which we propose an addendum: "Make everything transparent". We elaborate on this by highlighting the importance of the temporal dimension of web pages as well as issues surrounding metadata and veracity.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {103–106},
numpages = {4},
keywords = {veracity, shneiderman's mantra, metadata, faceted browsing},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910913,
author = {Milligan, Ian and Ruest, Nick and Lin, Jimmy},
title = {Content Selection and Curation for Web Archiving: The Gatekeepers vs. the Masses},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910913},
doi = {10.1145/2910896.2910913},
abstract = {Any preservation effort must begin with an assessment of what content to preserve, and web archiving is no different. There have historically been two answers to the question "what should we archive?" The Internet Archive's broad entire-web crawls have been supplemented by narrower domain- or topic-specific collections gathered by numerous libraries. We can characterize this as content selection and curation by "gatekeepers". In contrast, we have witnessed the emergence of another approach driven by "the masses"---we can archive pages that are contained in social media streams such as Twitter. The interesting question, of course, is how these approaches differ. We provide an answer to this question in the context of a case study about the 2015 Canadian federal elections. Based on our analysis, we recommend a hybrid approach that combines an effort driven by social media and more traditional curatorial methods.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {107–110},
numpages = {4},
keywords = {subject-matter experts, collection development, twitter, internet archive},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910922,
author = {Khabsa, Madian and Wu, Zhaohui and Giles, C. Lee},
title = {Towards Better Understanding of Academic Search},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910922},
doi = {10.1145/2910896.2910922},
abstract = {Academics have relied heavily on search engines to identify and locate research manuscripts that are related to their research areas. Many of the early information retrieval sys- tems and technologies were developed while catering for li- brarians to help them sift through books and proceedings, followed by recent online academic search engines such as Google Scholar and Microsoft Academic Search. In spite of their popularity among academics and importance to academia, the usage, query behaviors, and retrieval models for aca- demic search engines have not been well studied. To this end, we study the distribution of queries that are received by an academic search engine. Furthermore, we delve deeper into academic search queries and classify them into navigational and informational queries. This work in- troduces a definition for navigational queries in academic search engines under which a query is considered naviga- tional if the user is searching for a specific paper or docu- ment. We describe multiple facets of navigational academic queries, and introduce a machine learning approach with a set of features to identify such queries.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {111–114},
numpages = {4},
keywords = {scholarly search, query unverstanding},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910923,
author = {Grech, Daniel and Clough, Paul},
title = {Investigating Cluster Stability When Analyzing Transaction Logs},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910923},
doi = {10.1145/2910896.2910923},
abstract = {Data-driven approaches have become increasingly popular as a means for analyzing transaction logs from web search engines and digital libraries, for example using cluster analysis to identify common patterns of search and navigation behavior. However, steps must be taken to ensure that results are reliable and repeatable. Although clustering patterns of user interaction behavior has been previously explored, one aspect that has received less attention is cluster stability that can be used to aid cluster validation. In this paper we compute stability based on the Jaccard coefficient to investigate the cluster stability when using different subsets of transaction log data from WorldCat.org. Results provide insights into different types of search behaviors and highlight that clusters of varying degrees of stability will result from the clustering process. However, we show that additional investigation beyond the results of cluster stability is required to fully validate the resulting clusters.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {115–118},
numpages = {4},
keywords = {clustering, cluster stability, transaction log analysis},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910897,
author = {Guo, Yan Ru and Goh, Dion Hoe-Lian and Muhamad, Hurizan Bin Hussain and Ong, Boon Kuang and Lei, Zichao},
title = {Experimental Evaluation of Affective Embodied Agents in an Information Literacy Game},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910897},
doi = {10.1145/2910896.2910897},
abstract = {Digital game-based learning (DGBL) has become increasingly popular. With elements such as narratives, rewards, quests, and interactivity, DGBL can actively engage learners, stimulating desired learning outcomes. In an effort to increase its appeal, affective embodied agents (EAs) have been incorporated as learning companions or instructors in DGBL. However, claims about the efficacy of using affective EAs in DGBL have scarcely been subjected to empirical analysis. Therefore, this study aims to investigate the influence of affective EAs on students' learning outcome, motivation, perceived usefulness, and behavioral intention in an information literacy (IL) game. Eighty tertiary students were recruited and randomly assigned in a pre- and post-test between-subjects experiment with two conditions: affective-EA and no-EA. Results showed that participants benefited from interacting with the affective EA in the IL game in terms of attention, confidence, satisfaction, and intention to learn IL knowledge and to recommend. However, there were no significant differences in learning outcome, relevance, or intention to play the game. Contributions and limitations of this study are also discussed at the end.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {119–128},
numpages = {10},
keywords = {game evaluation, information literacy education., digital game-based learning, educational games, affective embodied agent},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910900,
author = {Le, Long T. and Shah, Chirag and Choi, Erik},
title = {Evaluating the Quality of Educational Answers in Community Question-Answering},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910900},
doi = {10.1145/2910896.2910900},
abstract = {Community Question-Answering (CQA), where questions and answers are generated by peers, has become a popular method of information seeking in online environments. While the content repositories created through CQA sites have been used widely to support general purpose tasks, using them as online digital libraries that support educational needs is an emerging practice. Horizontal CQA services, such as Yahoo! Answers, and vertical CQA services, such as Brainly, are aiming to help students improve their learning process by answering their educational questions. In these services, receiving high quality answer(s) to a question is a critical factor not only for user satisfaction, but also for supporting learning. However, the questions are not necessarily answered by experts, and the askers may not have enough knowledge and skill to evaluate the quality of the answers they receive. This could be problematic when students build their own knowledge base by applying inaccurate information or knowledge acquired from online sources. Using moderators could alleviate this problem. However, a moderator's evaluation of answer quality may be inconsistent because it is based on their subjective assessments. Employing human assessors may also be insufficient due to the large amount of content available on a CQA site. To address these issues, we propose a framework for automatically assessing the quality of answers. This is achieved by integrating different groups of features - personal, community-based, textual, and contextual - to build a classification model and determine what constitutes answer quality. To test this evaluation framework, we collected more than 10 million educational answers posted by more than 3 million users on Brainly's United States and Poland sites. The experiments conducted on these datasets show that the model using Random Forest (RF) achieves more than 83% accuracy in identifying high quality of answers. In addition, the findings indicate that personal and community-based features have more prediction power in assessing answer quality. Our approach also achieves high values on other key metrics such as F1-score and Area under ROC curve. The work reported here can be useful in many other contexts where providing automatic quality assessment in a digital repository of textual information is paramount.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {129–138},
numpages = {10},
keywords = {community question-answering (cqa), answer quality, features},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910914,
author = {Fu, Hengyi and Fan, Yun},
title = {Music Information Seeking via Social Q&amp;A: An Analysis of Questions in Music StackExchange Community},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910914},
doi = {10.1145/2910896.2910914},
abstract = {In this paper we report preliminary findings based on a quantitative analysis of data from a music social Q&amp;A site, Music StackExchange, focusing on real-life music information needs, uses, and seeking. Eight major topic categories and a two-level taxonomy for question type/intent and the characteristics of questions in each category are presented. Our findings suggest that Q&amp;A sites are a fruitful resource for identifying users' music information needs, how these needs are expressed, and intended uses for the information. On Music StackExchange, users' questioning behaviors were motivated by the recognition of knowledge gaps, lack of resources, need for others' opinions, or interest in research issues, spanning different topics. This study is explorative in nature and the results could improve the understanding of everyday life music information seeking. The findings can inform music librarians and general-purpose music information systems designers of the needs, requirements, and approaches to enhance music related controlled vocabularies, and improve search engines and online knowledge sharing communities to categorize and provide users with more relevant music information.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {139–142},
numpages = {4},
keywords = {music information needs and uses, music information behavior, question type, social q&amp;a site., music information seeking},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910904,
author = {Clark, Christopher and Divvala, Santosh},
title = {PDFFigures 2.0: Mining Figures from Research Papers},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910904},
doi = {10.1145/2910896.2910904},
abstract = {Figures and tables are key sources of information in many scholarly documents. However, current academic search engines do not make use of figures and tables when semantically parsing documents or presenting document summaries to users. To facilitate these applications we develop an algorithm that extracts figures, tables, and captions from documents called "PDFFigures 2.0." Our proposed approach analyzes the structure of individual pages by detecting captions, graphical elements, and chunks of body text, and then locates figures and tables by reasoning about the empty regions within that text. To evaluate our work, we introduce a new dataset of computer science papers, along with ground truth labels for the locations of the figures, tables, and captions within them. Our algorithm achieves impressive results (94% precision at 90% recall) on this dataset surpassing previous state of the art. Further, we show how our framework was used to extract figures from a corpus of over one million papers, and how the resulting extractions were integrated into the user interface of a smart academic search engine, Semantic Scholar (www.semanticscholar.org). Finally, we present results of exploratory data analysis completed on the extracted figures as well as an extension of our method for the task of section title extraction. We release our dataset and code on our project webpage for enabling future research (http://pdffigures2.allenai.org).},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {143–152},
numpages = {10},
keywords = {section title extraction, scalable figure extraction, figure usage analysis, academic search engine},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910909,
author = {Klein, Martin and Broadwell, Peter and Farb, Sharon E. and Grappone, Todd},
title = {Comparing Published Scientific Journal Articles to Their Pre-Print Versions},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910909},
doi = {10.1145/2910896.2910909},
abstract = {Academic publishers claim that they add value to scholarly communications by coordinating reviews and contributing and enhancing text during publication. These contributions come at a considerable cost: U.S. academic libraries paid $1.7 billion for serial subscriptions in 2008 alone. Library budgets, in contrast, are flat and not able to keep pace with serial price inflation. We have investigated the publishers' value proposition by conducting a comparative study of pre-print papers and their final published counterparts. This comparison had two working assumptions: 1) if the publishers' argument is valid, the text of a pre-print paper should vary measurably from its corresponding final published version, and 2) by applying standard similarity measures, we should be able to detect and quantify such differences. Our analysis revealed that the text contents of the scientific papers generally changed very little from their pre-print to final published versions. These findings contribute empirical indicators to discussions of the added value of commercial publishers and therefore should influence libraries' economic decisions regarding access to scholarly publications.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {153–162},
numpages = {10},
keywords = {pre-print, open access, similarity, publishing},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910916,
author = {Dores, Wellington and Benevenuto, Fabr\'{\i}cio and Laender, Alberto H.F.},
title = {Extracting Academic Genealogy Trees from the Networked Digital Library of Theses and Dissertations},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910916},
doi = {10.1145/2910896.2910916},
abstract = {Along the history, many researchers provided remarkable contributions to science, not only advancing knowledge but also in terms of mentoring new scientists. Currently, identifying and studying the formation of researchers over the years is a challenging task as current repositories of theses and dissertations are cataloged in a decentralized way through many local digital libraries. In this paper, we give a first step towards building a large repository that records the academic genealogy of researchers across fields and countries. We crawled data from the Networked Digital Library of Theses and Dissertations (NDLTD) and develop a framework to extract academic genealogy trees from this data and provide a series of analyses that describe the main properties of the academic genealogy trees. Our effort identified interesting findings related to the structure of academic formation, which highlight the importance of cataloging academic genealogy trees. We hope our initial framework will be the basis of a much larger crowdsourcing system.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {163–166},
numpages = {4},
keywords = {academic genealogy trees, ndltd, etd},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910920,
author = {Kehoe, Adam K. and Torvik, Vetle I.},
title = {Predicting Medical Subject Headings Based on Abstract Similarity and Citations to MEDLINE Records},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910920},
doi = {10.1145/2910896.2910920},
abstract = {We describe a classifier-enhanced nearest neighbor approach to assigning Medical Subject Headings (MeSH) to unlabeled documents using a combination of abstract similarities and direct citations to labeled MEDLINE records. The approach frames the classification problem by decomposing it into sets of siblings in the MeSH hierarchy (e.g., training a classifier for predicting "Heterocyclic Compounds, 2-Ring" vs. other "Heterocyclic Compounds"). Preliminary experiments using a small but diverse set of MeSH terms shows the highest performance when using both abstracts and citations compared to each alone, and coupled with a non-naive classifier: 90+% precision and recall with 10-fold cross-validation. NLM's Medical Text Indexer (MTI) tool achieves similar overall performance but varies more across the terms tested. For example, MTI performs better on "Heterocyclic Compounds, 2-Ring", while our approach performs better on Alzheimer Disease. Our approach can be applied broadly to documents with abstracts that are similar to (or cite) MEDLINE abstracts, which would help linking and searching across bibliographic databases beyond MEDLINE.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {167–170},
numpages = {4},
keywords = {machine learning, controlled vocabularies, medical subject headings, curation of bibliographic databases},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910898,
author = {Nishioka, Chifumi and Scherp, Ansgar},
title = {Profiling vs. Time vs. Content: What Does Matter for Top-k Publication Recommendation Based on Twitter Profiles?},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910898},
doi = {10.1145/2910896.2910898},
abstract = {So far it is unclear how different factors of a scientific publication recommender system based on users' tweets have an influence on the recommendation performance. We examine three different factors, namely profiling method, temporal decay, and richness of content. Regarding profiling, we compare CF-IDF that replaces terms in TF-IDF by semantic concepts, HCF-IDF as novel hierarchical variant of CF-IDF, and topic modeling. As temporal decay functions, we apply sliding window and exponential decay. In terms of the richness of content, we compare recommendations using both full-texts and titles of publications and using only titles. Overall, the three factors make twelve recommendation strategies. We have conducted an online experiment with 123 participants and compared the strategies in a within-group design. The best recommendations are achieved by the strategy combining CF-IDF, sliding window, and with full-texts. However, the strategies using the novel HCF-IDF profiling method achieve similar results with just using the titles of the publications. Therefore, HCF-IDF can make recommendations when only short and sparse data is available.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {171–180},
numpages = {10},
keywords = {user profiling, recommender system, temporal decay, social media},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910905,
author = {Nezhadbiglari, Masoumeh and Gon\c{c}alves, Marcos Andr\'{e} and Almeida, Jussara M.},
title = {Early Prediction of Scholar Popularity},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910905},
doi = {10.1145/2910896.2910905},
abstract = {Prediction of scholar popularity has become an important research topic for a number of reasons. In this paper, we tackle the problem of predicting the popularity {it trend} of scholars by concentrating on making predictions both as earlier and accurate as possible. In order to perform the prediction task, we first extract the popularity trends of scholars from a training set. To that end, we apply a time series clustering algorithm called K-Spectral Clustering (K-SC) to identify the popularity trends as cluster centroids. We then predict trends for scholars in a test set by solving a classification problem. Specifically, we first compute a set of measures for individual scholars based on the distance between earlier points in her particular popularity curve and the identified centroids. We then combine those distance measures with a set of academic features (e.g., number of publications, number of venues, etc) collected during the same monitoring period, and use them as input to a classification method. One aspect that distinguishes our method from other approaches is that the monitoring period, during which we gather information on each scholar popularity and academic features, is determined on a per scholar basis, as part of our approach. Using total citation count as measure of scientific popularity, we evaluate our solution on the popularity time series of more than 500,000 Computer Science scholars, gathered from Microsoft Azure Marketplace (https://datamarket.azure.com/dataset/mrc/microsoftacademic). The experimental results show that the our prediction method outperforms other alternative prediction methods. We also show how to apply our method jointly with regression models to improve the prediction of scholar popularity values (e.g., number of citations) at a given future time.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {181–190},
numpages = {10},
keywords = {scholar popularity, early trends, popularity prediction, academic scholar features},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2910908,
author = {Schwarzer, Malte and Schubotz, Moritz and Meuschke, Norman and Breitinger, Corinna and Markl, Volker and Gipp, Bela},
title = {Evaluating Link-Based Recommendations for Wikipedia},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2910908},
doi = {10.1145/2910896.2910908},
abstract = {Literature recommender systems support users in filtering the vast and increasing number of documents in digital libraries and on the Web. For academic literature, research has proven the ability of citation-based document similarity measures, such as Co-Citation (CoCit), or Co-Citation Proximity Analysis (CPA) to improve recommendation quality. In this paper, we report on the first large-scale investigation of the performance of the CPA approach in generating literature recommendations for Wikipedia, which is fundamentally different from the academic literature domain. We analyze links instead of citations to generate article recommendations. We evaluate CPA, CoCit, and the Apache Lucene MoreLikeThis (MLT) function, which represents a traditional text-based similarity measure. We use two datasets of 779,716 and 2.57 million Wikipedia articles, the Big Data processing framework Apache Flink, and a ten-node computing cluster. To enable our large-scale evaluation, we derive two quasi-gold standards from the links in Wikipedia's "See also" sections and a comprehensive Wikipedia clickstream dataset.Our results show that the citation-based measures CPA and CoCit have complementary strengths compared to the text-based MLT measure. While MLT performs well in identifying narrowly similar articles that share similar words and structure, the citation- based measures are better able to identify topically related information, such as information on the city of a certain university or other technical universities in the region. The CPA approach, which consistently outperformed CoCit, is better suited for identifying a broader spectrum of related articles, as well as popular articles that typically exhibit a higher quality. Additional benefits of the CPA approach are its lower runtime requirements and its language-independence that allows for a cross-language retrieval of articles. We present a manual analysis of exemplary articles to demonstrate and discuss our findings. The raw data and source code of our study, together with a manual on how to use them, are openly available at: https://github.com/wikimedia/citolytics},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {191–200},
numpages = {10},
keywords = {link-based, big data, co-citation, digital libraries, large-scale evaluations, citation analysis, co-citation proximity analysis, document similarity measures, literature recommendations},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925431,
author = {Duma, Daniel and Sutton, Charles and Klein, Ewan},
title = {Context Matters: Towards Extracting a Citation's Context Using Linguistic Features},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925431},
doi = {10.1145/2910896.2925431},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {201–202},
numpages = {2},
keywords = {citation context, citation recommendation, context extraction, information retrieval, window of words},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925432,
author = {Fu, Hengyi and Stvilia, Besiki},
title = {Knowledge Curation Discussions and Activity Dynamics in a Short Lived Social Q&amp;A Community},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925432},
doi = {10.1145/2910896.2925432},
abstract = {Studying the dynamics and life-cycles of online knowledge curation communities is essential to identify and assemble community type specific repertoires of strategies, rules, and actions of community design, governance, content creation and curation. This paper examines the lifecycle of a short lived social Q&amp;A community on Stack Exchange by performing the content analysis of the logs of member discussions and content curation actions.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {203–204},
numpages = {2},
keywords = {knowledge curation, social q&amp;a sites, community lifecycle., online communities},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925433,
author = {Llewellyn, Clare and Cram, Laura and Favero, Adrian},
title = {Avoiding the Drunkard's Search: Investigating Collection Strategies for Building a Twitter Dataset},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925433},
doi = {10.1145/2910896.2925433},
abstract = {We investigate methods for collecting data to form an archive on the debate within Twitter surrounding the UK's inclusion in the EU. We use three strategies, gathering data using hashtags, extracting data from the random stream and collecting from users known to be discussing the debate. We explore the various bias in the resulting datasets.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {205–206},
numpages = {2},
keywords = {twitter data selection, data analytics, social media analysis},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925434,
author = {Aalberg, Trond and Mer\v{c}un, Tanja and \v{Z}umer, Maja},
title = {BIBSURF: Discover Bibliographic Entities by Searching for Units of Interest, Ranking and Filtering},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925434},
doi = {10.1145/2910896.2925434},
abstract = {BIBSURF is a system demonstrating search, ranking and filtering of bibliographic RDF data that is organized in form of entities representing intellectual endeavor at different levels of abstraction: item, manifestation, expression, work.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {207–208},
numpages = {2},
keywords = {ranking, rdf, filtering, lrm, models, keyword search},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925435,
author = {Wang, Wei and Liu, Jiaying and Yu, Shuo and Zhang, Chenxin and Xu, Zhenzhen and Xia, Feng},
title = {Mining Advisor-Advisee Relationships in Scholarly Big Data: A Deep Learning Approach},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925435},
doi = {10.1145/2910896.2925435},
abstract = {Mining advisor-advisee relationships can benefit many interesting applications such as advisor recommendation and protege performance analysis. Based on the hypothesis that, advisor-advisee relationships among researchers are hidden in scholarly big data, we propose in this work a deep learning based advisor-advisee relationship identification method which considers the personal properties and network characteristics with a stacked autoencoder model. To the best of our knowledge, this is the first time that a deep learning model is utilized to represent coauthor network features for relationships identification. Moreover, experiments demonstrate that the proposed method has better performance compared with other state-of-the-art methods.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {209–210},
numpages = {2},
keywords = {deep learning, relationship mining, stacked autoencoders},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925436,
author = {Zhang, Jun and Ning, Zhaolong and Bai, Xiaomei and Wang, Wei and Yu, Shuo and Xia, Feng},
title = {Who Are the Rising Stars in Academia?},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925436},
doi = {10.1145/2910896.2925436},
abstract = {This paper proposes a novel method named ScholarRank to evaluate the scientific impact of rising stars. Our proposed ScholarRank integrates the merits of both statistical indicators and influence calculation algorithms in heterogeneous academic networks. The ScholarRank method considers three factors, which are the citation counts of authors, the mutual influence among coauthors and the mutual reinforce process among different entities in heterogeneous academic networks. Through experiments on real datasets, we demonstrate that our ScholarRank can efficiently select more top ranking rising stars than other methods.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {211–212},
numpages = {2},
keywords = {pagerank, rising star, heterogeneous networks, hits},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925437,
author = {Di Nunzio, Giorgio Maria},
title = {Can You Learn It? Probably! Developing Learning Analytics Tools in R},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925437},
doi = {10.1145/2910896.2925437},
abstract = {Automatic text categorization is an effective way to organize large text datasets in Digital Libraries (DL). However, most of the available machine learning tools are complex and go beyond the scope of what a digital library curator need or is able to do in order to classify the objects of a DL. Drawing inspiration from the field of Learning Analytics and Interactive Machine Learning, we design and implement visual interactive classifiers that are intuitive to train and easy to use. In this poster, we present an interactive Web application in R that allows users to use text classifier in an innovative way. The source code of the application is available at the following link: https://github.com/gmdn/educational-data-mining},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {213–214},
numpages = {2},
keywords = {na\'{\i}ve bayes, r programming, learning analytics, interactive machine learning, automated text classification, r shiny},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925438,
author = {Li, Lei and Zhang, Chengzhi},
title = {Characterizing Users Tagging Behavior in Academic Blogs},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925438},
doi = {10.1145/2910896.2925438},
abstract = {Along with popular of academic social media, academic blogs are one of the user generated academic information that can be annotated using social tags for user's information retrieval and organization. In order to improve the existing social tagging system to satisfy the users' needs, users' tagging behavior need to be understood. However, there is no researches on characterizing user tagging behaviors of academic resources. In this paper, using the tag of academic blog as the research object, the author analyze user's tagging behaviors based on the characteristics of tags (tags-based features) and those related to blog contents (content-based features). These characteristics can be used to the academic tagging system to promote organization and propagation of academic knowledge.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {215–216},
numpages = {2},
keywords = {narrow folksonomy, academic blogs, academic social media, tagging behavior},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925439,
author = {Garay, Yanet and Akbar, Monika and Gates, Ann Q.},
title = {Towards Identifying Potential Research Collaborations from Scientific Research Networks Using Scholarly Data},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925439},
doi = {10.1145/2910896.2925439},
abstract = {Identifying research areas of researchers is a difficult task because of the various levels of abstraction in which information may be stored; however, such a task is essential for detecting potential research collaborations within an institution. This work describes an approach to create a scientific research network with topics identified from the researchers' scholarly data and relations between topics by analyzing data harvested from digital libraries and queries to domain ontologies. The relations are used to connect the researchers. Such networks have the potential for revealing the synergy between different topics and researchers within an institution. It will also show less explored research areas that can be targeted for further study. The poster will describe the approach and how it was applied to a biomedical domain at the university.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {217–218},
numpages = {2},
keywords = {scholarly data, scientific research network, research collaborations},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925440,
author = {Cunningham, Sally Jo and Nichols, David M. and Bowen, Judy},
title = {Personal Video Collection Management Behavior},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925440},
doi = {10.1145/2910896.2925440},
abstract = {Video content typically consumes more storage space and bandwidth than other document types although users structure their content with the same organisational tools they use for smaller and simpler items. We analyze the "native" video management behavior as expressed in 35 self-interviews and diary studies produced by New Zealand students, to create a "rich picture" of personal video collections. We see that personal collections can have diffuse boundaries and many different intended users' and that these information management needs are difficult to fulfill with their homegrown video collection management strategies.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {219–220},
numpages = {2},
keywords = {personal collection management, video information behavior, qualitative research},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925441,
author = {Erekhinskaya, Tatiana and Balakrishna, Mithun and Tatu, Marta and Werner, Steven and Moldovan, Dan},
title = {Knowledge Extraction for Literature Review},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925441},
doi = {10.1145/2910896.2925441},
abstract = {Researchers in all domains need to keep abreast with recent scientific advances. Finding relevant publications and reviewing them is a labor-intensive task that lacks efficient automatic tools to support it. Current tools are limited to standard keyword-based search systems that return potentially relevant documents and then leave the user with a monumental task of sifting through them. In this paper, we present a semantic-driven system to automatically extract the most important knowledge from a publication and reduces the effort required for the literature review. The system extracts key findings from biomedical papers in PubMed, populates a predefined template and displays it. This allows the user to get the key ideas of the content even before opening or downloading the publication.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {221–222},
numpages = {2},
keywords = {literature review, semantic relation, knowledge extraction},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925442,
author = {Ojokoh, Bolanle and Igbe, Tobore and Araoye, Ayobami and Ameh, Friday},
title = {Question Identification and Classification on an Academic Question Answering Site},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925442},
doi = {10.1145/2910896.2925442},
abstract = {Online communities such as wikis, blogs, forums, scientific communities and other social networking services have enabled new levels of interactions and interconnections among individuals, documents and data and have become places for people to seek and share expertise. In this paper, we propose a systematic approach to identification and classification of questions. The questions were first identified using semantic occurrence of Part of Speech (POS) tag in English Language, after which they were classified based on maximum probability value of Na\"{\i}ve Bayes classification. The model was validated and evaluated with experiments on some crawled web pages from ResearchGate.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {223–224},
numpages = {2},
keywords = {questions, research gate, online forums., classification},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925443,
author = {Gopavarapu, Parthasarathy and Pouchard, Line C. and Pujol, Santiago},
title = {Increasing Datasets Discoverability in an Engineering Data Platform Using Keyword Extraction},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925443},
doi = {10.1145/2910896.2925443},
abstract = {In this paper we describe the use of keyword extraction in a data management platform for the storage, publication, and sharing of scientific and engineering datasets primarily related to the stress of concrete structures under earthquake conditions. To improve discoverability of datasets and assist scientists who upload data, we designed an automated keyword extraction system that will propose keywords for uploaded datasets.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {225–226},
numpages = {2},
keywords = {data repository, keyword extraction, data discovery},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925444,
author = {Hinze, Annika and Coleman, Michael and Cunningham, Sally Jo and Bainbridge, David},
title = {Semantic Bookworm: Mining Literary Resources Revisited},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925444},
doi = {10.1145/2910896.2925444},
abstract = {In this paper, we describe Semantic Bookworm-a tool that supports scholarly text analysis. In contrast to the text-based Bookworm tool, the Semantic Bookworm identifies semantic concepts.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {227–228},
numpages = {2},
keywords = {text mining, digital humanities, semantic analysis, data mining},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925445,
author = {Sesagiri Raamkumar, Aravind and Foo, Schubert and Pang, Natalie},
title = {Making Literature Review and Manuscript Writing Tasks Easier for Novice Researchers through Rec4LRW System},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925445},
doi = {10.1145/2910896.2925445},
abstract = {We demonstrate the recently built Rec4LRW system, meant for assisting researchers in three literature review and manuscript writing tasks. The system has been designed to be useful for all researchers, albeit the evaluation results show that it is more beneficial for research students and beginners. In this demonstration, we provide a walkthrough of the system by executing the tasks with sample research topics. The unique User-Interface (UI) and the task interconnectivity features are some of the highlighted aspects.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {229–230},
numpages = {2},
keywords = {scientific paper information retrieval, scientific paper recommender systems, manuscript writing, reading list, literature review, shortlisting feature},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925446,
author = {Su, Xiaoyan and Wang, Wei and Yu, Shuo and Zhang, Chenxin and Bekele, Teshome Megersa and Xia, Feng},
title = {Can Academic Conferences Promote Research Collaboration?},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925446},
doi = {10.1145/2910896.2925446},
abstract = {This work proposes to investigate the question of whether attending conference will breed new scientific collaboration based on the focal closure theory. Through the analysis of conference closure on individual and community level, we show that attending conference can promote new scientific collaborations, and conferences with more attendees and higher field ratings bring more new scientific collaborations.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {231–232},
numpages = {2},
keywords = {research collaboration, academic social networks, focal closure},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925447,
author = {Mitsui, Matthew and Shah, Chirag},
title = {Coagmento 2.0: A System for Capturing Individual and Group Information Seeking Behavior},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925447},
doi = {10.1145/2910896.2925447},
abstract = {In this demo, we present Coagmento 2.0, a Web-based, open-source platform that provides support for one working in individual or group projects spanning multiple sessions that involve looking for, collecting, and synthesizing information. The system also provides a highly customizable platform for researchers who want to investigate individual and group information seeking behaviors in a lab or a field setting. The demo not only shows back-end components and front-end interaction elements of the system, but also how one could easily configure Coagmento for user studies involving information seeking/retrieval with digital libraries (including the Web).},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {233–234},
numpages = {2},
keywords = {interactive search, cscw, collaborative information seeking, exploratory search, information synthesis, sensemaking},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925448,
author = {Herrmannova, Drahomira and Knoth, Petr},
title = {Semantometrics: Towards Fulltext-Based Research Evaluation},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925448},
doi = {10.1145/2910896.2925448},
abstract = {Over the recent years, there has been a growing interest in developing new research evaluation methods that could go beyond the traditional citation-based metrics. This interest is motivated on one side by the wider availability or even emergence of new information evidencing research performance, such as article downloads, views and Twitter mentions, and on the other side by the continued frustrations and problems surrounding the application of purely citation-based metrics to evaluate research performance in practice.Semantometrics are a new class of research evaluation metrics which build on the premise that full-text is needed to assess the value of a publication. This paper reports on the analysis carried out with the aim to investigate the properties of the semantometric contribution measure [Knoth, 2014], which uses semantic similarity of publications to estimate research contribution, and provides a comparative study of the contribution measure with traditional bibliometric measures based on citation counting.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {235–236},
numpages = {2},
keywords = {citation analysis, research evaluation, text mining},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925449,
author = {Nwala, Alexander C. and Nelson, Michael L.},
title = {A Supervised Learning Algorithm for Binary Domain Classification of Web Queries Using SERPs},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925449},
doi = {10.1145/2910896.2925449},
abstract = {General purpose Search Engines (SEs) crawl all domains (e.g., Sports, News, Entertainment) of the Web, but sometimes the informational need of a query is restricted to a particular domain (e.g., Medical). We leverage the work of SEs as part of our effort to route domain specific queries to local Digital Libraries (DLs). SEs are often used even if they are not the "best" source for certain types of queries. Rather than tell users to "use this DL for this kind of query", we intend to automatically detect when a query could be better served by a local DL (such as a private, access-controlled DL that is not crawlable via SEs). This is not an easy task because Web queries are short, ambiguous, and there is lack of quality labeled training data (or it is expensive to create). To detect queries that should be routed to local, specialized DLs, we first send the queries to Google and then examine the features in the resulting Search Engine Result Pages. Using 400,000 AOL queries for the "non-scholar" domain and 400,000 queries from the NASA Technical Report Server for the "scholar" domain, our classifier achieved a precision of 0.809 and F-measure of 0.805.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {237–238},
numpages = {2},
keywords = {search engines, web queries, query understanding},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925450,
author = {Alhoori, Hamed},
title = {How to Identify Specialized Research Communities Related to a Researcher's Changing Interests},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925450},
doi = {10.1145/2910896.2925450},
abstract = {Scholarly events and venues are increasing rapidly in number. This poses a challenge for researchers who seek to identify events and venues related to their work in order to draw more efficiently and comprehensively from published research and to share their own findings more effectively. Such efforts are hampered also by the fact that no rating system yet exists to assist researchers in culling the venues most relevant to their current readings and interests. This study describes a methodology we developed in response to this need, one that recommends scholarly venues related to researchers' specific interests according to personalized social web indicators. Our experiments applying our proposed rating and recommendation method show that it outperforms the baseline venue recommendations in terms of accuracy and ranking quality.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {239–240},
numpages = {2},
keywords = {social media, citeulike, scholarly venues, altmetrics, personalized recommendation},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925451,
author = {Karadkar, Unmil P. and Potter, Geoffrey A. and Wang, Shengwei},
title = {Visualizing Published Metadata in Large Aggregations},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925451},
doi = {10.1145/2910896.2925451},
abstract = {Large metadata aggregations provide access to documents held by multiple cultural heritage (CH) institutions. As CH institutions encode their metadata using different schemas and follow different data standards, aggregators must process the received data before making it available through a unified portal. Staff members at the contributing CH institutions don't receive feedback regarding the quality of the provided or the processed data. We are developing mechanisms that enable staff at the CH institutions to understand the effectiveness of their metadata with a goal of improving the visibility of their items in these large portals such as the Digital Public Library of America. This poster will present a classification of the DPLA metadata application profile highlighting compliance levels as well as a visualization framework for presenting the compliance of an institution's data with the DPLA data model.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {241–242},
numpages = {2},
keywords = {metadata visualization, digital public library of america, metadata aggregation},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925452,
author = {Alam, Sawood and Nelson, Michael L.},
title = {MemGator - A Portable Concurrent Memento Aggregator: Cross-Platform CLI and Server Binaries in Go},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925452},
doi = {10.1145/2910896.2925452},
abstract = {The Memento protocol makes it easy to build a uniform lookup service to aggregate the holdings of web archives. However, there is a lack of tools to utilize this capability in archiving applications and research projects. We created MemGator, an open source, easy to use, portable, concurrent, cross-platform, and self-documented Memento aggregator CLI and server tool written in Go. MemGator implements all the basic features of a Memento aggregator (e.g., TimeMap and TimeGate) and gives the ability to customize various options including which archives are aggregated. It is being used heavily by tools and services such as Mink, WAIL, OldWeb.today, and archiving research projects and has proved to be reliable even in conditions of extreme load.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {243–244},
numpages = {2},
keywords = {web archiving, aggregator, memgator, memento},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925453,
author = {Yao, Lili and Fan, Feifan and Feng, Yansong and Zhao, Dongyan},
title = {Leveraging Tweet Ranking in an Optimization Frameworkfor Tweet Timeline Generation},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925453},
doi = {10.1145/2910896.2925453},
abstract = {When users search in Twitter, they are overloaded with a mass of microblog posts every time, which are not particularly informative and lack of meaningful organization. Therefore, it is helpful to produce a summarized tweet timeline about the topic. The tweet timeline generation is such a task aiming at selecting a small set of representative tweets to generate meaningful timeline. In this paper, we introduce an optimization framework to jointly model the relevance, novelty and coverage of the tweet timeline, including effective tweet ranking algorithm. Extensive experiments on the public TREC 2014 dataset demonstrate our method can achieve very competitive results against the state-of-art TTG systems.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {245–246},
numpages = {2},
keywords = {tweet timeline generation, optimization framework, tweet ranking},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925454,
author = {Xie, Zhiwu and Chen, Yinlin and Speer, Julie and Walters, Tyler},
title = {Evaluating Cost of Cloud Execution in a Data Repository},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925454},
doi = {10.1145/2910896.2925454},
abstract = {In this paper, we utilize a set of controlled experiments to benchmark the cost associated with the cloud execution of typical repository functions such as ingestion, fixity checking, and heavy data processing. We focus on the repository service pattern where content is explicitly stored away from where it is processed. We measured the processing speed and unit cost of each scenario using a large sensor dataset and Amazon Web Services (AWS). The initial results reveal three distinct cost patterns: 1) spend more to buy up to proportionally faster services; 2) more money does not necessarily buy better performance; and 3) spend less, but faster. Further investigations into these performance and cost patterns will help repositories to form a more effective operation strategy.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {247–248},
numpages = {2},
keywords = {institutional repository, cost analysis, cloud computing, big data},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925455,
author = {Goh, Dion Hoe-Lian and Pe-Than, Ei Pa Pa and Lee, Chei Sian},
title = {Games for Crowdsourcing Mobile Content: An Analysis of Contribution Patterns},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925455},
doi = {10.1145/2910896.2925455},
abstract = {Crowdsourcing of mobile content through games is becoming a major way of populating information-rich online environments. A current research gap is that actual usage patterns of crowdsourcing games has been inadequately investigated. We address this gap by comparing content creation patterns in a game for crowdsourcing mobile content against a non-game version. Results show distinct differences in the types and distribution of content created.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {249–250},
numpages = {2},
keywords = {mobile content, crowdsourcing games, content analysis},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925456,
author = {Xie, Haihua and Lu, Xiaoqing and Tang, Zhi and Ye, Mao},
title = {A Methodology to Evaluate Triple Confidence and Detect Incorrect Triples in Knowledge Bases},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925456},
doi = {10.1145/2910896.2925456},
abstract = {The accuracy of the contents of a knowledge base determines the effectiveness of knowledge service applications, thus, it is necessary to evaluate the confidence of triples when a knowledge base is built. This study introduces a generic computational methodology to compute the confidence values of triples in knowledge bases and detect potentially incorrect ones for further verification. The major contributions of the proposed methodology are as follows: (1) A process to compute the confidence values of triples is designed; (2) New algorithms are proposed to adjust the term frequency and inverse document frequency values of each triple; (3) A method to build a support vector machine (SVM) classifier based on the selected triples used for incorrect triple detection is presented.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {251–252},
numpages = {2},
keywords = {knowledge service, triple confidence, knowledge base},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925457,
author = {Decourselle, Joffrey and Duchateau, Fabien and Aalberg, Trond and Takhirov, Naimdjon and Lumineau, Nicolas},
title = {Open Datasets for Evaluating the Interpretation of Bibliographic Records},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925457},
doi = {10.1145/2910896.2925457},
abstract = {The transformation of legacy MARC catalogs to FRBR catalogs (FRBRization) is a complex and important challenge for libraries. Although many FRBRization tools have provided experimental validation, it is difficult to evaluate and compare these systems on a fair basis due to a lack of common datasets. This poster presents two public datasets (T42 and BIB-RCAT) intended to support the validation of the FRBRization process.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {253–254},
numpages = {2},
keywords = {migration, frbrization, record interpretation, frbr, dataset},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925458,
author = {Knyazeva, Anna and Kolobov, Oleg and Turchanovsky, Igor},
title = {An Example of Automatic Authority Control},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925458},
doi = {10.1145/2910896.2925458},
abstract = {The automatic authority control problem is considered. One possible solution is to use the record linkage approach for authority and bibliographic records. The main aim of this paper is to figure out which concepts and methods are most useful for dealing with our data. An approach based on machine learning method (classification) is considered. A comparative study of different distances and feature sets is made. A study carried out on data of several Russian libraries. The data we deal with are in RUSMARC format which is a variant of UNIMARC popular in Russia.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {255–256},
numpages = {2},
keywords = {name disambiguation, record linkage, authority records, bibliographic records, measuring distances},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925459,
author = {Suire, Cyrille and Jean-Caurant, Axel and Courboulay, Vincent and Burie, Jean-Christophe and Estraillier, Pascal},
title = {User Activity Characterization in a Cultural Heritage Digital Library System},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925459},
doi = {10.1145/2910896.2925459},
abstract = {Digital access to large amount of heterogeneous data can create methodological biases regarding the discovery and exploitation of resources, particularly when it comes to Social Sciences. In order to provide relevant adaptivity for social scientists, it is important to fully consider their research practice diversity. To do so, we consider an activity-based approach for researchers' information search behavior. We have also conducted an experiment in a Cultural Heritage use case. The main result shows us that social scientists have the same research behaviors as those observed in exact Sciences.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {257–258},
numpages = {2},
keywords = {user modeling, user behavior, humanities, task models, information seeking, cultural heritage},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925460,
author = {Yuan, Ke and Gao, Liangcai and Wang, Yuehan and Yi, Xiaohan and Tang, Zhi},
title = {A Mathematical Information Retrieval System Based on RankBoost},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925460},
doi = {10.1145/2910896.2925460},
abstract = {Mathematical Information Retrieval (MIR) systems are designed to help users to find related formulae and further understand the formulae in scientific documents. However, in existing MIR systems, nearly all the ranker models of MIR systems are based on tf-idf model, and few efforts have been made to discover the features besides the relevance between the query formula and related formulae. In this paper, we investigate a supervised ranking approach (RankBoost) in an MIR system, and we consider not only the relevance between a query formula and related formulae, but also the features of the query formula itself and plentiful features about the documents where the related formulae appear. Experimental results show that our system achieves better performance by comparing with state-of-the-art MIR systems.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {259–260},
numpages = {2},
keywords = {mathematical information retrieval, rankboost, learning to rank},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925461,
author = {Momeni, Fakhri and Mayr, Philipp},
title = {Using Co-Authorship Networks for Author Name Disambiguation},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925461},
doi = {10.1145/2910896.2925461},
abstract = {With the increasing size of digital libraries (DLs) it has become a challenge to identify author names correctly and assign publications to them. The situation becomes more critical when different persons share the same name (homonym problem) or when the names of authors are presented in several different ways (synonym problem). This paper focuses on homonym names in the computer science bibliography DBLP. The goal of this study is to implement and evaluate a method which uses co-authorship networks in order to disambiguate homonym names, especially common names. The results show that the implemented method has a good performance and can be used for author name disambiguation of sparse bibliographic records.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {261–262},
numpages = {2},
keywords = {author name homonyms, community detection, co-authorship network, gold standard, louvain method},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925462,
author = {Fei, Yue and Lv, Chao and Feng, Yansong and Zhao, Dongyan},
title = {Real-Time Filtering on Interest Profiles in Twitter Stream},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925462},
doi = {10.1145/2910896.2925462},
abstract = {The advent of Twitter has led to the ubiquitous information overload problem with a dramatic increase in the amount of tweets a user is exposed to. In this paper, we consider real-time tweet filtering with respect to users' interest profiles in public Twitter stream. While traditional filtering methods mainly focus on judging relevance of a document, we aim to retrieve relevant and novel documents to address the high redundancy of tweets. An unsupervised approach is proposed to model relevance between tweets and different profiles adaptively and a neural network language model is employed to learn semantic representation for tweets. Experiments on TREC 2015 dataset demonstrate the effectiveness of the proposed approach.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {263–264},
numpages = {2},
keywords = {adaptive thresholding, neural network language model, real-time filtering},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925463,
author = {Liu, Chang and Xu, Tao},
title = {Preliminary Exploration of the Effect of Time Constraint on Search Interactions on Webpages},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925463},
doi = {10.1145/2910896.2925463},
abstract = {This study explored the effect of time constraint on searchers' interactions during two kinds of tasks through conducting a user experiment. The results demonstrated users' did not tend to accelerate their reading or decision speed given time constraint, but to select fewer pages to read, i.e. visit fewer content pages and search result pages (SERPs); and they had more mouse clicks but fewer keystrokes per page when searching with time constraint. The results also showed the different effects of time constraint on search interactions on pages for two types of tasks. The results have implications for the design of digital library systems that take account users' time constraint or time pressure.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {265–266},
numpages = {2},
keywords = {task type, search strategy, search interaction, time constraint},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925464,
author = {Papachristopoulos, Leonidas and Sfakakis, Michalis and Kleidis, Nikos and Tsakonas, Giannis and Papatheodorou, Christos},
title = {Exploiting Network Analysis to Investigate Topic Dynamics in the Digital Library Evaluation Domain},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925464},
doi = {10.1145/2910896.2925464},
abstract = {The multidimensional nature of digital libraries evaluation domain and the amount of scientific production published on the field hinders and disorientates the interested researchers who contemplate to focus on the specific domain. These communities need guidance in order to exploit the considerable amount of data and the diversity of methods effectively as well as to identify new research goals and develop their plans for future works. This poster investigates the core topics of the digital library evaluation field and their impact by applying topic modeling and network analysis on a corpus of the JCDL, ECDL/TDPL and ICADL conferences proceedings in the period 2001-2013.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {267–268},
numpages = {2},
keywords = {digital library evaluation, topic modeling, network analysis},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925465,
author = {Kim, Kunho and Khabsa, Madian and Giles, C. Lee},
title = {Inventor Name Disambiguation for a Patent Database Using a Random Forest and DBSCAN},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925465},
doi = {10.1145/2910896.2925465},
abstract = {Inventor name disambiguation is the task that distinguishes each unique inventor from all other inventor records in a patent database. This task is essential for processing person name queries in order to get information related to a specific inventor, e.g. a list of all that inventor's patents. Using earlier work on author name disambiguation, we apply it to inventor name disambiguation. A random forest classifier is trained to classify whether each pair of inventor records is the same person. The DBSCAN algorithm is use for inventor record clustering, and its distance function is derived using the random forest classifier. For scalability, blocking functions are used to reduce the complexity of record matching and enable parallelization since each block can be run simultaneously. Tested on the USPTO patent database, 12 million inventor records were disambiguated in 6.5 hours. Evaluation on the labeled datasets from USPTO PatentsView competition shows our algorithm outperforms all algorithms submitted to the competition.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {269–270},
numpages = {2},
keywords = {name disambiguation, random forest, dbscan},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925466,
author = {Farag, Mohamed and Nakate, Pranav and Fox, Edward A.},
title = {Big Data Processing of School Shooting Archives},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925466},
doi = {10.1145/2910896.2925466},
abstract = {Web archives about school shootings consist of webpages that may or may not be relevant to the events of interest. There are 3 main goals of this work; first is to clean the webpages, which involves getting rid of the stop words and non-relevant parts of a webpage. The second goal is to select just webpages relevant to the events of interest. The third goal is to upload the cleaned and relevant webpages to Apache Solr so that they are easily accessible. We show the details of all the steps required to achieve these goals. The results show that representative Web archives are noisy, with 2% - 40% relevant content. By cleaning the archives, we aid researchers to focus on relevant content for their analysis.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {271–272},
numpages = {2},
keywords = {big data processing, classification, digital libraries, web archives},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925467,
author = {Alam, Sawood and Kelly, Mat and Nelson, Michael L.},
title = {InterPlanetary Wayback: The Permanent Web Archive},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925467},
doi = {10.1145/2910896.2925467},
abstract = {To facilitate permanence and collaboration in web archives, we built InterPlanetary Wayback to disseminate the contents of WARC files into the IPFS network. IPFS is a peer-to-peer content-addressable file system that inherently allows deduplication and facilitates opt-in replication. We split the header and payload of WARC response records before disseminating into IPFS to leverage the deduplication, build a CDXJ index, and combine them at the time of replay. From a 1.0 GB sample Archive-It collection of WARCs containing 21,994 mementos, we found that on an average, 570 files can be indexed and disseminated into IPFS per minute. We also found that in our naive prototype implementation, replay took on an average 370 milliseconds per request.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {273–274},
numpages = {2},
keywords = {web archives, ipfs, memento, p2p file system, ipwb, interplanetary wayback},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925468,
author = {Williams, Kyle and Giles, C. Lee},
title = {Improving Similar Document Retrieval Using a Recursive Pseudo Relevance Feedback Strategy},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925468},
doi = {10.1145/2910896.2925468},
abstract = {We present a recursive pseudo relevance feedback strategy for improving retrieval performance in similarity search. The strategy recursively searches on search results returned for a given query and produces a tree that is used for ranking. Experiments on the Reuters 21578 and WebKB datasets show how the strategy leads to a significant improvement in similarity search performance.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {275–276},
numpages = {2},
keywords = {relevance feedback, similarity search},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925469,
author = {Ray Choudhury, Sagnik and Wang, Shuting and Giles, C. Lee},
title = {Curve Separation for Line Graphs in Scholarly Documents},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925469},
doi = {10.1145/2910896.2925469},
abstract = {Line graphs are abundant in scholarly papers. They are usually generated from a data table and that data can not be accessed. One important step in an automated data extraction pipeline is the curve separation problem: segmenting the pixels into separate curves. Previous work in this domain has focused on raster graphics extracted from scholarly PDFs, whereas most scholarly plots are embedded as vector graphics. We report a system to extract these plots as SVG images and show how that can improve both the accuracy (90%) and the scalability (5-8 seconds) of the curve separation problem.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {277–278},
numpages = {2},
keywords = {line graph, vector graphics, data extraction},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926738,
author = {Hwang, Soo-yeon and Cragin, Melissa and Lesk, Michael and Lin, Yu-Hung and O'Connor, Daniel},
title = {Issues of Dealing with Fluid Data in Digital Libraries},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926738},
doi = {10.1145/2910896.2926738},
abstract = {This panel discusses the issues of dealing with fluid data and curating new data in digital libraries.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {279–280},
numpages = {2},
keywords = {digital libraries, fluid data, big data, curation, secondary analysis, velocity},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926739,
author = {McCain, Edward and Klein, Martin and Weber, Matthew},
title = {Panel: Preserving Born-Digital News},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926739},
doi = {10.1145/2910896.2926739},
abstract = {This panel examines the need for digital libraries to capture and preserve journalistic content in digital formats, especially online news.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {281},
numpages = {1},
keywords = {information systems, digital libraries and archives, information systems applications},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925429,
author = {Fox, Edward A.},
title = {Introduction to Digital Libraries},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925429},
doi = {10.1145/2910896.2925429},
abstract = {This tutorial is a thorough and deep introduction to the Digital Libraries (DL) field, providing a firm foundation: covering key concepts and terminology, as well as services, systems, technologies, methods, standards, projects, issues, and practices. It introduces and builds upon a firm theoretical foundation (starting with the `5S' set of intuitive aspects: Streams, Structures, Spaces, Scenarios, Societies), giving careful definitions and explanations of all the key parts of a `minimal digital library', and expanding from that basis to cover key DL issues. Illustrations come from a set of case studies. Attendees will be exposed to four Morgan and Claypool books that elaborate on 5S, published 2012-2014. Complementing the coverage of `5S' will be an overview of key aspects of the DELOS Reference Model and DL.org activities. Further, use of a Hadoop cluster supporting DLs will be described.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {283–284},
numpages = {2},
keywords = {streams, 5s, societies, structures, spaces, scenarios},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925428,
author = {Karadkar, Unmil P. and Altman, Audrey and Breedlove, Mark and Matienzo, Mark},
title = {Introduction to the Digital Public Library of America API},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925428},
doi = {10.1145/2910896.2925428},
abstract = {The Digital Public Library of America (DPLA) provides access to over 11 million objects from libraries, museums, and archives. In addition to serving as an open portal for cultural heritage, literature, art, and scientific materials, the DPLA provides access to extensive metadata related to these materials via an openly available, RESTful application programming interface (API). The open API enables third party developers to create targeted applications that enable new and transformative uses of the items indexed by the DPLA. This half day tutorial will introduce participants to the DPLA's data model, describe the API, explain how to retrieve data using the API, and how to work with the retrieved data using freely available software using both interactive and programmatic techniques.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {285–286},
numpages = {2},
keywords = {restful api, dpla api, digital public library of america},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2925430,
author = {Williams, Kyle and Wu, Jian and Wu, Zhaohui and Giles, C. Lee},
title = {Information Extraction for Scholarly Digital Libraries},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2925430},
doi = {10.1145/2910896.2925430},
abstract = {Scholarly documents contain many data entities, such as titles, authors, affiliations, figures, and tables. These entities can be used to enhance digital library services through enhanced metadata and enable the development of new services and tools for interacting with and exploring scholarly data. However, in a world of scholarly big data, extracting these entities in a scalable, efficient and accurate manner can be challenging. In this tutorial, we introduce the broad field of information extraction for scholarly digital libraries. Drawing on our experience in running the CiteSeerX digital library, which has performed information extraction on over 7 million academic documents, we argue for the need for automatic information extraction, describe different approaches for performing information extraction, present tools and datasets that are readily available, and describe best practices and areas of research interest.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {287–288},
numpages = {2},
keywords = {information extraction, digital libraries, scholarly big data},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926733,
author = {Clough, Paul D. and Goodale, Paula and Agosti, Maristella and Lawless, S\'{e}amus},
title = {ACHS'16: First International Workshop on Accessing Cultural Heritage at Scale},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926733},
doi = {10.1145/2910896.2926733},
abstract = {The workshop aims to bring together researchers and practitioners to review and discuss ways of providing effective access to large-scale collections of cultural heritage content. The scale, variety and availability of cultural heritage content, combined with the variety of user groups with respect to background knowledge, specialist experience and needs is challenging in the context of existing access methods. In particular, we consider going beyond keyword search in large-scale cultural heritage digital libraries, in support of exploration and discovery. Our purpose for the workshop is to consider the opportunities and challenges presented by new and existing technologies, as well as the needs and experiences of diverse user communities. Our goal is to assess the current state-of the-art, to identify opportunities and establish future research priorities, informed by the combined knowledge and experience of academics and practitioners.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {289–290},
numpages = {2},
keywords = {information access, cultural heritage, big data, exploration, discovery, digital libraries, information retrieval},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926736,
author = {Karadkar, Unmil P. and Lehnert, Kerstin and Lenhardt, Chris},
title = {Physical Samples and Digital Libraries},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926736},
doi = {10.1145/2910896.2926736},
abstract = {Research in disciplines such as the earth and biological sciences depends on the availability of representative physical samples that have been collected at substantial cost and effort and some are irreplaceable. The EarthCube iSamples (Internet of Samples in the Earth Sciences) Research Coordination Network (RCN), funded by the National Science Foundation, aims to connect physical samples and sample collections across the Earth Sciences with digital data infrastructures to revolutionize their utility in the support of science. The goal of this workshop is to attract a broad audience comprising of earth scientists and other scientists working with physical samples, data curators, and computer and information scientists to learn from each other about the requirements of physical and digital sample and collection management.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {291–292},
numpages = {2},
keywords = {internet of samples in the earth sciences, isamples, earthcube, cyberinfrastructure},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926735,
author = {Fox, Edward A. and Xie, Zhiwu and Klein, Martin},
title = {WADL 2016: Third International Workshop on Web Archiving and Digital Libraries},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926735},
doi = {10.1145/2910896.2926735},
abstract = {This workshop will explore integration of Web archiving and digital libraries, so the complete life cycle involved is covered: creation/authoring, uploading/publishing in the Web (2.0), (focused) crawling, indexing, exploration (searching, browsing), archiving (of events), etc. It will include particular coverage of current topics of interest, like: big data, mobile web archiving, and systems (e.g., Memento, SiteStory, Hadoop processing).},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {293–294},
numpages = {2},
keywords = {web archiving, internet archive},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926737,
author = {Knoth, Petr and Anastasiou, Lucas and Herrmannova, Drahomira and Pontika, Nancy},
title = {5th International Workshop on Mining Scientific Publications (WOSP 2016)},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926737},
doi = {10.1145/2910896.2926737},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {295–297},
numpages = {3},
keywords = {web archiving, internet archive},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

@inproceedings{10.1145/2910896.2926734,
author = {Cabanac, Guillaume and Chandrasekaran, Muthu Kumar and Frommholz, Ingo and Jaidka, Kokil and Kan, Min-Yen and Mayr, Philipp and Wolfram, Dietmar},
title = {Joint Workshop on Bibliometric-Enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2016)},
year = {2016},
isbn = {9781450342292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910896.2926734},
doi = {10.1145/2910896.2926734},
abstract = {The large scale of scholarly publications poses a challenge for scholars in information-seeking and sensemaking. Bibliometric, information retrieval~(IR), text mining and NLP techniques could help in these activities, but are not yet widely used in digital libraries. This workshop is intended to stimulate IR researchers and digital library professionals to elaborate on new approaches in natural language processing, information retrieval, scientometric and recommendation techniques which can advance the state-of-the-art in scholarly document understanding, analysis and retrieval at scale.},
booktitle = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
pages = {299–300},
numpages = {2},
keywords = {information retrieval, bibliometrics, natural language processing, text mining, digital libraries},
location = {Newark, New Jersey, USA},
series = {JCDL '16}
}

