@inproceedings{10.1145/2686612.2686613,
author = {N\'{u}\~{n}ez-Pacheco, Claudia and Loke, Lian},
title = {Aesthetic Resources for Technology-Mediated Bodily Self-Reflection: The Case of Eloquent Robes},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686613},
doi = {10.1145/2686612.2686613},
abstract = {The use of biofeedback data is becoming increasingly popular in interactive art and design, acting as a mirror of the self. It opens up interesting avenues for facilitating technology-mediated self-reflection on the body. However it also poses challenges for interaction design, given the semi-involuntary nature of control we have over our physiological data and the personal and social implications of externalising what is normally invisible. We describe the case of Eloquent Robes, an interactive installation, aiming to elicit self-reflective engagement with personal physiological data that normally remains concealed from our everyday awareness. The study explored methods for facilitating the subjective interpretation of heartbeat data represented in an artistic form, as an aesthetic revelation of the inner self during a moment outside the quotidian. Participants were asked to compare their results with other people's manifestations in the form of a reflective garment, revealing a mirroring of the self in the other. Heartbeat - as a physiological data - might not be an accurate tool for prediction of another person's feelings, however when shared as a metaphor of feelings, it can be an effective tool for the generation of narratives and self-revelation. We contribute a set of design strategies for interactive biofeedback artworks that aim to address some of the challenges of using physiological data as an aesthetic resource to enhance bodily self-awareness.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {1–10},
numpages = {10},
keywords = {heartbeat, biofeedback, wearable technology, self-reflection, self-awareness},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686616,
author = {Wang, Jinyi and Juhlin, Oskar and Johnson, Eva-Carin Banka},
title = {Previsualization with Computer Animation (Previs): Communicating Research to Interaction Design Practice},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686616},
doi = {10.1145/2686612.2686616},
abstract = {In recent years there has been growing concern about a gap between HCI research and industrial practitioners. We review methods proposed in HCI for enhancing communication between researchers and designers, and propose previsualization animation, borrowed from the movie industry, as an additional means to support this communication. The potential benefit is investigated through a process of designing and producing an animated film for a design research project at a furniture company and gathering initial user feedback. We argue that a technique that accounts for interaction dynamics and provisionality and that supports brevity and mobility can communicate design research in an inspirational manner to practitioners. However we also identified a remaining difference in the two groups' expectations about the animation, with researchers wanting it to be more research-like and practitioners wanting it to be more production-oriented.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {11–20},
numpages = {10},
keywords = {animation, research-practice gap, interaction design, previsualization, communication},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686617,
author = {Frawley, Jessica Katherine and Dyson, Laurel Evelyn},
title = {Animal Personas: Acknowledging Non-Human Stakeholders in Designing for Sustainable Food Systems},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686617},
doi = {10.1145/2686612.2686617},
abstract = {This paper describes the development and application of a non-human animal persona in designing to support co-operative and free-range animal agriculture. This work is grounded in case study research of a small free-range egg farm, through which field and interview work were undertaken. We demonstrate how existing user-centred design tools, such as the persona, can be used to better reflect co-operative farming philosophies and more meaningfully represent both farmer and animal stakeholders within the design process. This approach is theoretically orientated within sustainable HCI and Animal Computer Interaction (ACI), which is itself an extension of HCI. The species-specific persona of a chicken allows representation and ensures that the animal, which is made deliberately invisible within factory and intensive farming, is made visible through and within the design of an online system. By making explicit the implicit assumptions we hold about an animal, such personas provide a tool for thinking, design, and further discussion.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {21–30},
numpages = {10},
keywords = {sustainable HCI, personas, stakeholders, animal computer interaction, food systems},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686618,
author = {Fritsch, Jonas and Breinbjerg, Morten and Jensen, Tue S.},
title = {Designing Interactive Listening Situations},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686618},
doi = {10.1145/2686612.2686618},
abstract = {This article presents the interactive sound installation Ekkomaten, a machine originally designed to let people explore an 18th century soundscape as part of a historical festival in Aarhus, Denmark. We present the design of the installation focusing on three core concerns when designing interactive listening situations; the physical interface, the site-specific soundscape and the affectively engaging listening experience. We then provide a detailed video analysis of the richness of use of the installation, focusing on the interaction and ways of listening facilitated by the setup. Based on this, we highlight the ways in which Ekkomaten has provided an interactive listening situation engaging people affectively and intellectually both in the exploration of sonified stories about the 18th century as well as of the installation in itself as an interactive machine for listening. Further, we reflect on important insights when designing interactive listening situations, critically reflect on the data and evaluation and outline a future experiment with the Ekkomaten infrastructure.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {31–40},
numpages = {10},
keywords = {interactive environments and installations, urban computing, site-specific design, cultural heritage, audio design, interactive sound design, affective engagement},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686619,
author = {Bouzit, Sara and Ch\^{e}ne, Denis and Calvary, Gaelle},
title = {From Appearing to Disappearing Ephemeral Adaptation for Small Screens},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686619},
doi = {10.1145/2686612.2686619},
abstract = {This paper presents two forms of adaptive menus for small devices (smart phones). Contrary to the Ephemeral appearing adaptation proposed by Findlater et al. [7], we claim for disappearing adaptation. The first form is named In Context Disappearing (ICD); the second one Out of Context Disappearing (OCD). The principle of ICD is to display predictive information in a prompting window placed above the main list. The prompting window disappears gradually while maintaining the context always visible and directly accessible. In case of low level prediction, ICD enables user to reach its target without waiting for disappearing effect. OCD principle is almost the same except that the disappearing prompting window covers the full page and thus is out of context like Findlater's approach. Our study shows that for small devices "fading out" a contextual window is better than "fading in". We demonstrate the benefit of these new forms of adaptation through an experiment with 24 subjects. We conclude that (1) ICD and OCD adaptive lists support faster selection than Control condition when the level of prediction is high, slower in case of bad prediction, and that (2) ICD is faster than OCD in case of bad prediction.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {41–48},
numpages = {8},
keywords = {gradual onset, disappearing adaptation, adaptive interfaces, gradual disappearance, ephemeral adaptation, interaction techniques},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686620,
author = {Lafreniere, Benjamin and Bunt, Andrea and Terry, Michael},
title = {Task-Centric Interfaces for Feature-Rich Software},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686620},
doi = {10.1145/2686612.2686620},
abstract = {Feature-rich software can be difficult to learn and use, and current approaches to organizing functionality do little to help users with performing unfamiliar tasks. In this paper, we investigate the potential for alternative task-centric interface designs that organize functionality around specific tasks. To understand the potential of this approach, we developed and studied Workflows, a prototype task-centric interface design. Our findings suggest that task-centric interfaces scaffold and guide the user's exploration of a subset of application functionality, and thereby help them to avoid common difficulties and inefficiencies caused by self-directed exploration of the full interface. We also found evidence that task-centric interfaces enable a different kind of application learning, in which users associate tasks with relevant keywords as opposed to low-level commands and procedures. This has potential benefits for memorability, because the keywords themselves describe the task, and scalability, because a few keywords can map to an arbitrarily large procedure.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {49–58},
numpages = {10},
keywords = {learning, task-centric interfaces, search-based interaction, tutorials, feature-rich software, help},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686621,
author = {Kieffer, Suzanne and Batalas, Nikolaos and Markopoulos, Panos},
title = {Towards Task Analysis Tool Support},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686621},
doi = {10.1145/2686612.2686621},
abstract = {This paper discusses challenges in contextual task analysis and the need of tools that support analysts to collect such information in context. Specifically we argue that the analysis of collaborative and distributed tasks can be supported by ambulatory assessment tools. We illustrate how contextual task analysis can be supported by TEMPEST, a platform originally created for experience sampling and more generally, longitudinal ambulatory assessment studies. We present a case study that illustrates the extent to which this tool meets the needs of real-world task analysis, describing the gains in efficiency it can provide but also directions for the development of tool support for task analysis.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {59–68},
numpages = {10},
keywords = {tool support, ambulatory assessment methods, contextual task analysis},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686622,
author = {Ichino, Junko and Onda, Mariko and Tano, Shun'ichi and Hashiyama, Tomonori and Iwata, Mitsuru},
title = {User Interface Design Combining a Logical and Physical Structure-Based Approach},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686622},
doi = {10.1145/2686612.2686622},
abstract = {With the enormous growth in the amount of information and functionality available, it is increasingly important that the desired information and functions can be easily found and made use of through user interface. To enable users to easily find and use the desired information and functions, both user interface content (logical structure) and user interface appearance (physical structure) need to be easily comprehensible for the user. We have addressed this need by developing a system to support user interface designers following a dual approach, that is logical structure design support based on objective and quantitative analysis of languages used by users themselves, and physical structure design support that takes the stages in the design process into account. The proposed system will make it easier for designers to design user interface using the language of users, as well as user interface that reflects their own creativity.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {69–76},
numpages = {8},
keywords = {objective and quantitative analysis, pen-based interaction, user interface design, design stage, early prototyping and evaluation},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686623,
author = {Lupton, Deborah},
title = {Self-Tracking Cultures: Towards a Sociology of Personal Informatics},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686623},
doi = {10.1145/2686612.2686623},
abstract = {A body of literature on self-tracking has been established in human-computer interaction studies. Contributors to this literature tend to take a cognitive or behavioural psychology approach to theorising and explaining self-tracking. Such an approach is limited to understanding individual behaviour. Yet self-tracking is a profoundly social practice, both in terms of the enculturated meanings with which it is invested and the social encounters and social institutions that are part of the self-tracking phenomenon. In this paper I contend that sociological perspectives can contribute some intriguing possibilities for human-computer interaction research, particularly in developing an understanding of the wider social, cultural and political dimensions of what I refer to as 'self-tracking cultures'. The discussion focuses on the following topics: self-optimisation and governing the self; entanglements of bodies and technologies; the valorisation of data; data doubles; and social inequalities and self-tracking. The paper ends with outlining some directions for future research on self-tracking cultures that goes beyond the individual to the social.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {77–86},
numpages = {10},
keywords = {self-tracking, theory, culture, selfhood, personal informatics: sociology},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686624,
author = {Nansen, Bjorn and van Ryn, Luke and Vetere, Frank and Robertson, Toni and Brereton, Margot and Dourish, Paul},
title = {An Internet of Social Things},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686624},
doi = {10.1145/2686612.2686624},
abstract = {The Internet of Things is a vision for a world of interconnected smart devices. We present an alternative vision based on a review of literature that emphasizes the importance and role of objects in social relations. We situate this work in relation to a conceptual understanding of objects and sociality, and note some methodological implications of a more object-centred sociality that may suggest design opportunities alongside the emerging Internet of Things.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {87–96},
numpages = {10},
keywords = {ethnography, user, social objects, materiality, internet of things},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686625,
author = {McKay, Dana and Buchanan, George},
title = {On the Other Side from You: How Library Design Facilitates and Hinders Group Work},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686625},
doi = {10.1145/2686612.2686625},
abstract = {This paper describes a longitudinal ethnographic analysis of space usage in an academic library. We focus on group work, identifying a range of group types and activities. We address how the library space and users' technology choices impact the flow of information within groups, and finally identify some implications for both space and technology design.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {97–106},
numpages = {10},
keywords = {space, libraries, awareness, group work, ethnography},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686626,
author = {Tipping, Robert and Farrell, Graham and Farrell, Vivienne and Woodward, Clinton J.},
title = {From Collection to Courtroom: Perceptions and Realities of How the Data Flows},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686626},
doi = {10.1145/2686612.2686626},
abstract = {There is a strong movement for integrated, technology solutions to be adopted for the presentation of evidence in the Australian courtrooms. Current, commercially available solutions that are being considered create concerns for individual users, as they do not reflect data types or processes within the Australian courts. An individual's understanding of how digital data evidence is collected and prepared for courtroom presentation is derived only from their personal knowledge and activity with the data within the process chain. This user-centred study reflects on the discussions held with the various individuals involved in the process of evidence collection and transformation of digital data to its final format for courtroom evidence presentation. This research has identified the need to take a step back in the design process to substantiate the data flow, and identified the need for justification of how each data type transformation is decided within the process. This research is also of value to stakeholders to understand the stages of the process in which they are not involved.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {107–110},
numpages = {4},
keywords = {data modelling, e-courts, Australian courts, digital evidence},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686627,
author = {Ardianto, Danny},
title = {Understanding Social Media-Enabled Participation and Resilience in Urban Farming Communities},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686627},
doi = {10.1145/2686612.2686627},
abstract = {The roles of technology in urban farming have recently been a subject of examination in sustainable human-computer interaction (HCI). Few have suggested that social media can support citizen engagement due to its accumulative power for collective action. However, little has been known about how such a provision takes place and what kind of participation can lead to the resilience of a community. This paper presents a field report which seeks to reveal the nature of participation in a social media-enabled urban farming community. Through an interpretive case study, the findings demonstrate interconnectedness of the community involving people, place, and technology. Three areas of contributions are outlined: a wider application of design framework for sustainable food culture, the role of social media for social participation through urban farms, and the route to building community resilience from social media-enabled participation.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {111–114},
numpages = {4},
keywords = {urban farming, resilience, social media, participation},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686628,
author = {Kan, Alexander and Ploderer, Bernd and Gibbs, Martin},
title = {Mixed Reality Stories: How Creative Writers Integrate Virtual and Physical Realities},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686628},
doi = {10.1145/2686612.2686628},
abstract = {Mixed reality stories (MRS) unfold simultaneously in the physical and the virtual world. Advancements in digital technologies, which are now able to capture more contextual information about our physical environments, are enabling novel ways of blending the two worlds. To explore the process of creating stories from this perspective, we conducted a study with creative writers, in which we asked them to write a MRS script for outdoor running. While we saw instances of intentional connections between physical and virtual worlds in their work, we also observed the use of ambiguity or even deliberate contradiction with available contextual information. In this paper we discuss how these approaches can be beneficial for MRS and propose directions for future work.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {115–118},
numpages = {4},
keywords = {mixed reality, storytelling, workshop, running, serious games, creative writers},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686629,
author = {Pietroszek, Krzysztof and Kuzminykh, Anastasia and Wallace, James R. and Lank, Edward},
title = {Smartcasting: A Discount 3D Interaction Technique for Public Displays},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686629},
doi = {10.1145/2686612.2686629},
abstract = {We introduce and formally evaluate smartcasting: a smartphone-based Ray Casting implementation for 3D environments presented on large, public, autostereoscopic displays. By utilizing a smartphone as an input device, smartcasting enables "walk up and use" interaction with large displays, without the need for expensive tracking systems or specialized pointing devices. Through an empirical validation we show that the performance and precision of smartcasting is comparable to a Wiimote-based raycasting implementation, without requiring specialized hardware or high-precision cameras to enable user interaction.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {119–128},
numpages = {10},
keywords = {3D environnent, 3D interaction, mobile interaction, 3D displays, interaction technique, raycasting},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686630,
author = {Vent\"{a}-Olkkonen, Leena and \r{A}kerman, Panu and Puikkonen, Arto and Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {Touching the Ice: In-the-Wild Study of an Interactive Icewall},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686630},
doi = {10.1145/2686612.2686630},
abstract = {In this paper, we present an interactive installation consisting of a 3 m wide \texttimes{} 1.4 m high touch sensitive wall of ice, which was set up as an indoor installation during a music festival. During a one night in-the-wild study, the audience could draw on the back-projected icewall, either directly using it as a touch screen, or remotely via a mobile optimized webpage. We focus on reporting the lessons learnt from this in-the-wild experience, and on user experience aspects of interacting both with the physical ice and through the mobile interface. The results highlight that the material qualities of the tangible user interface are essential for creating engaging and intriguing user experiences, whereas remote interaction through a mobile app enhances the possibilities for social interaction and sharing.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {129–132},
numpages = {4},
keywords = {interactive installations, user studies, ice, tangible user interfaces, in-the-wild studies, user experience},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686631,
author = {Yang, Xiao Emila and Tomitsch, Martin},
title = {Designing Interactions with Pervasive Displays for Location-Based Storytelling},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686631},
doi = {10.1145/2686612.2686631},
abstract = {This paper investigates the use of pervasive displays for location-based storytelling. It proposes the integration of such displays with fictional location-based story experiences as a way of connecting the story with the physical environment in which the story unfolds. The study in presented in this paper investigates techniques for interacting with pervasive displays as part of a location-based story prototype. The study results suggest that pervasive displays affect the engagement with the story and locations, the flow and pace of the story, and the general comprehension of the story content. Based on the findings, we suggest a set of guidelines for integrating pervasive displays with location-based stories.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {133–136},
numpages = {4},
keywords = {contextually aware displays, mobile, interactive storytelling, pervasive displays, location-based stories, ubiquitous interactions},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686633,
author = {Poxon, David and Sitbon, Laurianne and Schroeter, Ronald and Bruza, Peter D.},
title = {Large Scale Multiuser Digital Mind Mapping Tool: A Study in Usability},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686633},
doi = {10.1145/2686612.2686633},
abstract = {Project work can involve multiple people from varying disciplines coming together to solve problems as a group. Large scale interactive displays are presenting new opportunities to support such interactions with interactive and semantically enabled cooperative work tools such as intelligent mind maps. In this paper, we present a novel digital, touch-enabled mind-mapping tool as a first step towards achieving such a vision. This first prototype allows an evaluation of the benefits of a digital environment for a task that would otherwise be performed on paper or flat interactive surfaces. Observations and surveys of 12 participants in 3 groups allowed the formulation of several recommendations for further research into: new methods for capturing text input on touch screens; inclusion of complex structures; multi-user environments and how users make the shift from single-user applications; and how best to navigate large screen real estate in a touch-enabled, co-present multi-user setting.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {137–140},
numpages = {4},
keywords = {mind mapping, large interactive displays, computer-supported cooperative work, collaborative computing},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686634,
author = {Purcell, Arrian and Gardner, Henry and Swift, Ben},
title = {Visualising a Live Coding Arts Process},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686634},
doi = {10.1145/2686612.2686634},
abstract = {This paper describes an empirical study of source code visualisation as a means to communicate the programming process in "live coding" computer music performances. Following an exploratory field study of a live-coding performance at an arts festival, two different interaction-driven visualisation techniques were incorporated into a live coding system. We then performed a more controlled laboratory study to evaluate the visualisations' contributions to the audience experience, with emphasis on the (self-reported) experiential dimensions of understanding and enjoyment. Both software visualisation techniques enhanced audience enjoyment, while the effect on audience understanding was more complex. We conclude by suggesting how these visualisation techniques may be used to enhance the audience experience of live coding.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {141–144},
numpages = {4},
keywords = {musical performance, live coding, software visualisation},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686632,
author = {Regenbrecht, H. and M\"{u}ller, L. and Hoermann, S. and Langlotz, T. and Wagner, M. and Billinghurst, M.},
title = {Eye-to-Eye Contact for Life-Sized Videoconferencing},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686632},
doi = {10.1145/2686612.2686632},
abstract = {Videoconferencing systems available for end users do not allow for eye-to-eye contact between participants. The different locations of video camera and video display make it impossible to directly look into each others eyes. This issue is known as the lack of mutual gaze. Combined with a lack of a life-sized video image of the communication partner videoconferencing becomes an artificial experience leading to decreased communication quality, empathy and trust. In this work, we present life-sized videoconferencing solution supporting mutual gaze and report on the experiences made with our system in empirical evaluations.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {145–148},
numpages = {4},
keywords = {mutual gaze, eye contact, videoconferencing, trust},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686635,
author = {Nansen, Bjorn and Davis, Hilary and Vetere, Frank and Skov, Mikael and Paay, Jeni and Kjeldskov, Jesper},
title = {Kitchen Kinesics: Situating Gestural Interaction within the Social Contexts of Family Cooking},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686635},
doi = {10.1145/2686612.2686635},
abstract = {HCI research and practice have moved into the kitchen, and alongside screen-based technologies, a number of tangible interaction designs are emerging to support home cooking. However, we note that the designs of tangible technologies for kitchens have, to date, emphasized the work of cooking rather than the social significance or context in which it occurs. Building on this growing interest in cooking and the kitchen, we report on ethnographic research with intergenerational family members cooking together in their homes. We analyze the social, material and embodied contexts of kitchen kinesics -- the non-verbal gestural communication observed in family cooking interactions. Based upon these social, embodied, and material contexts of gestural interaction in the kitchen, we identify a number of contextual concerns for approaching the design and understanding of the role of gesture in familial cooking. Ultimately we highlight the significance of collocated gestural interaction and gestured interaction over a distance to understand the opportunities and limitations afforded by the design of new technologies in the kitchen.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {149–158},
numpages = {10},
keywords = {family, tangible interaction, gesture, home, ethnography, kitchen, kinesics, cooking},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686636,
author = {Light, Ann and Petrelli, Daniela},
title = {The Rhythm of Christmas: Temporality, ICT Use and Design for the Idiosyncrasies of a Major Festival},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686636},
doi = {10.1145/2686612.2686636},
abstract = {We present a study of preparation for and celebration of an English Christmas, with particular stress on temporal aspects, including duration, anticipation and repetition. We asked nine households to document their countdown to Christmas using media and diaries, and interviewed them before and after. We detail how time appears in the accounts, from the staging of collaborative preparations to the gift of attention, and consider what the collected insights offer for supporting the design of technology, given that one of our findings on media and ICT use was how it dwindles as focus concentrates on the present, and those present, for the days of the festivities. In doing so, we challenge the dominant efficiency paradigm in HCI.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {159–167},
numpages = {9},
keywords = {temporality, attention, duration, time, phenomenology, celebration, repetition, preparation, tangible, media use},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686637,
author = {Cumbo, Bronwyn J. and Jacobs, Brent C. and Leong, Tuck W. and Kanstrup, Anne Marie},
title = {What Motivates Children to Play Outdoors? Potential Applications for Interactive Digital Tools},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686637},
doi = {10.1145/2686612.2686637},
abstract = {Children (8-12 years) living in urban, western contexts are increasingly spending their free time indoors engaging in digital recreation, rather than outdoor, child-directed play. There is potential for place-specific, digital technology to be designed to motivate children 'off the couch' and outdoors into their local natural places. This paper presents the outcomes of three workshops conducted with eleven children (8-12 years) in Aalborg, Denmark, designed to understand key motivators for outdoor play in children. Children were divided into five design groups. Fictional inquiry and a series of artifacts and triggers were used to communicate the design task to children and inspire a range of relevant designs. Here, we report on the design outcomes of workshops, the motivators for outdoor play, and potential applications for interactive digital technology to inspire more regular, outdoor play experiences in children.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {168–171},
numpages = {4},
keywords = {outdoor play, motivation, interactive digital technology, participatory design, children},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686638,
author = {Wasinger, Rainer and He, Hai and Chinthammit, Winyu and Collis, Christy and Duh, Henry and Kay, Judy},
title = {The Importance of 'neighbourhood' in Personalising Location-Based Services},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686638},
doi = {10.1145/2686612.2686638},
abstract = {Location-Based Services (LBSes) provide information and functionality based on a user's geographical location and surrounding area, yet there is currently little known about how people actually perceive their surrounding area in relation to its use by online services. With a focus on the home neighbourhood, this paper introduces an experimental platform that supports a variety of LBSes and the results of a study designed to understand how users define 'neighbourhood' as a geographical construct for use by online LBSes. To this end, the study analyses the suitability of five different representation methods (freeform, radius, suburb, postcode, and council area) and their frequency of use across four different LBSes (item borrowing, media mention, directory listing, and property).Results show (1) that user-defined neighbourhoods differ greatly to the existing geographical constructs that are typically employed by LBSes like suburb, postcode, and council area (with only 22% similarity in overlap); (2) that representation methods allowing a user to self-define an area (i.e. freeform and radius) are used significantly more often by users (64% of the time) than pre-defined constructs (i.e. suburb, postcode, and council area); and (3) that many users (61%) have a dominant preference for a particular representation method that they use across multiple services. These findings are statistically significant and indicate that LBSes need to accommodate for individualised representations of neighbourhood, or face missing the next wave of personalisation in this field.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {172–175},
numpages = {4},
keywords = {hyperlocal computing, location-based services, user studies},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686639,
author = {Pearce, Jon and Chang, Shanton},
title = {Exploration without Keywords: The Bookfish Case},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686639},
doi = {10.1145/2686612.2686639},
abstract = {As a generation of information seekers we tend to think in terms of targeted search results, yet there are some contexts in which a more exploratory behaviour might be desirable. This paper presents the design and development of a playful Web app called Bookfish that seeks to encourage exploratory behaviour amongst children wishing to discover new books. Bookfish sets out to return more open, or even unexpected, serendipitous results through using an approach designed for exploration rather than search. The paper reports on the design considerations and initial user expectations of such a system and contributes both through this discussion of design as well as the application of a novel exploration environment. Strategies for managing these design challenges are also discussed.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {176–179},
numpages = {4},
keywords = {playful interactions, serendipity, search engine, exploratory search, interface design},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686640,
author = {Wadley, Greg and Bumpus, Adam and Green, Ray},
title = {Citizen Involvement in the Design of Technology for Climate Change Adaptation Projects in the Pacific},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686640},
doi = {10.1145/2686612.2686640},
abstract = {This paper describes work in progress aimed at exploring a role for mobile technology in helping citizens adapt to climate change in the Pacific. The research involved codesign workshops and stakeholder interviews in Fiji. In this paper we describe the design and conduct of the research program, the research context, and participants' reports of the environmental problems they experience. We discuss the technology features participants would like to see, and outline a design that might meet their requirements. We discuss difficulties we experienced using participatory methods in this context, and suggest ways in which further HCI research can contribute to addressing climate change in the Pacific region.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {180–183},
numpages = {4},
keywords = {climate change, participatory design, pacific islands},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686641,
author = {Dumesny, James and Tomitsch, Martin},
title = {Reconciling Paper and Tablets: Interaction Mappings for Linking Physical Information with Digital Documents},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686641},
doi = {10.1145/2686612.2686641},
abstract = {Despite the increasing use of tablet computers, there is evidence that paper still plays an important role for recording ideas and knowledge. Research on tablet usage suggests that they are seen to have a complementary role to that of paper. However, current methods of transferring paper-based information onto a digital device are limited to transcribing, scanning and taking a picture. We present a design study that investigates better-integrated ways of linking paper-based information with digital documents, such as websites or files. Our solution leverages new transparent display technologies for providing a direct augmentation of paper-based information while at the same time being capable of displaying associated digital documents. Through a series of design iterations and user evaluations, we identified interaction mappings for this new type of augmented reality as well as considerations for future implementations of transparent mobile devices.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {184–193},
numpages = {10},
keywords = {interaction design, physical information, mobile device interaction, transparent devices, contact augmented reality},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686642,
author = {Zollmann, Stefanie and Grasset, Raphael and Reitmayr, Gerhard and Langlotz, Tobias},
title = {Image-Based X-Ray Visualization Techniques for Spatial Understanding in Outdoor Augmented Reality},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686642},
doi = {10.1145/2686612.2686642},
abstract = {This paper evaluates different state-of-the-art approaches for implementing an X-ray view in Augmented Reality (AR). Our focus is on approaches supporting a better scene understanding and in particular a better sense of depth order between physical objects and digital objects. One of the main goals of this work is to provide effective X-ray visualization techniques that work in unprepared outdoor environments. In order to achieve this goal, we focus on methods that automatically extract depth cues from video images. The extracted depth cues are combined in ghosting maps that are used to assign each video image pixel a transparency value to control the overlay in the AR view. Within our study, we analyze three different types of ghosting maps, 1) alpha-blending which uses a uniform alpha value within the ghosting map, 2) edge-based ghosting which is based on edge extraction and 3) image-based ghosting which incorporates perceptual grouping, saliency information, edges and texture details. Our study results demonstrate that the latter technique helps the user to understand the subsurface location of virtual objects better than using alpha-blending or the edge-based ghosting.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {194–203},
numpages = {10},
keywords = {X-ray, visualization, evaluation, augmented reality},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686643,
author = {Ortega-Avila, Santiago and Huber, Jochen and Janaka, Nuwan and Withana, Anusha and Fernando, Piyum and Nanayakkara, Suranga},
title = {SparKubes: Exploring the Interplay between Digital and Physical Spaces with Minimalistic Interfaces},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686643},
doi = {10.1145/2686612.2686643},
abstract = {Tangible objects have seen an ongoing integration into real-world settings, e.g. in the classroom. These objects allow for instance learners to explore digital content in the physical space and leverage the physicality of the interface for spatial interaction. In this paper, we present SparKubes, a set of stand-alone tangible objects that are corded with simple behaviors and do not require additional instrumentation or setup. This overcomes a variety of issues such as setting up network connection and instrumentation of the environment--as long as a SparKube sees another, it "works". The contribution of this paper is three-fold: we (1) present the implementation of a minimalistic tangible platform as the basis for SparKube, (2) depict the design space that covers a variety of interaction primitives and (3) show how these primitives can be combined to create and manipulate SparKube interfaces in the scope of two salient application scenarios: tangible widgets and the manipulation of information flow.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {204–207},
numpages = {4},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686644,
author = {Fernando, Piyum and Peiris, Roshan Lalintha and Nanayakkara, Suranga},
title = {I-Draw: Towards a Freehand Drawing Assistant},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686644},
doi = {10.1145/2686612.2686644},
abstract = {In this paper we present I-Draw, a drawing tool to assist free hand drawings on physical surfaces. We explore the interaction design space that combines the digital capabilities with the traditional drawing process. I-Draw device has been conceptualised in terms of its interactive philosophy, features and affordances. We developed a proof-of-concept prototype of I-Draw and discuss the future directions. We believe I-Draw would open new drawing possibilities between physical and digital spaces.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {208–211},
numpages = {4},
keywords = {computer-aided design, freehand drawing, smart tools},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686645,
author = {Brown, Mark and Chinthammit, Winyu and Nixon, Paddy},
title = {A Comparison of User Preferences for Tangible Objects vs Touch Buttons with a Map-Based Tabletop Application},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686645},
doi = {10.1145/2686612.2686645},
abstract = {Although finger touch is widely expected as the control mechanism for touch tables, tangible object interaction is another, if rarely implemented possibility. Little empirical research exists showing uptake, user engagement, or use preferences for adult users of multi-touch tangible systems (Antle &amp; Wise, 2013; Schneider et al., 2010) with the majority of past research for tangible objects focusing on children (Marshall et al., 2003; Price et al, 2008; Zuckerman et al., 2005). Yet it is adults, as decision makers, who are the true targets of increasingly available commercial multi-touch table applications. By observing the interaction behaviours of 20 participants, this research investigates the appeal of two distinctly different styles of tangible objects compared with their finger touch equivalents. The explorative style study measures user preferences, perceived engagement, fit for purpose, usability, and enjoyment. The aim is to determine how the inclusion of tangible object interaction as part of the interface influences user preferences compares with a touch only system. This provides valuable base information to predict potential uptake and preferences of local adult users for future tangible or hybrid tangible touch systems.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {212–215},
numpages = {4},
keywords = {tangible, multi-touch table, interaction design, physical vs. virtual objects},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686646,
author = {Stannus, Simon and Fu, Wai-Tat and Lucieer, Arko},
title = {Natural 7DoF Input for 3D Navigation},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686646},
doi = {10.1145/2686612.2686646},
abstract = {As newer technology allows easier collection and display of increasingly complex 3D data, the need for more user-friendly interfaces to navigate and interact with such data grows. At the same time, there has been a jump in the capabilities and availability of natural interaction hardware. Anticipating the convergence of these two trends, this paper argues from interaction axioms to derive AeroSpace - our interaction technique for 7DoF spatial navigation that elegantly ties together the principles of direct, simultaneous and bimanual interaction into a small set of implementation requirements. We then show how we implemented these requirements with a simple glove design and our current software prototype built around NASA's World Wind SDK.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {216–219},
numpages = {4},
keywords = {visualization, navigation, 7DoF, natural, spatial},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686647,
author = {Martinez-Maldonado, Roberto and Clayphan, Andrew and Ackad, Christopher and Kay, Judy},
title = {Multi-Touch Technology in a Higher-Education Classroom: Lessons in-the-Wild},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686647},
doi = {10.1145/2686612.2686647},
abstract = {Inspired by the promise of tabletops for collaborative learning, and building on the many tabletop lab studies, and a few in-the-wild tabletop classrooms, we designed the first semester-long use of a multi-tabletop classroom for two university subjects, with 105 and 40 students respectively. Surprisingly, we found that with just three applications, designed to meet emerging teaching goals, we could support diverse classroom activities. Our technology also featured key minimalist functions that proved effective in enhancing the teacher's management of the class. This points to a research agenda for the applications and functionalities needed to make tabletop classrooms a reality. This paper describes the design process we followed to deploy multi-touch technology as a classroom ecology and the lessons learnt from the semester-long use in two authentic university courses.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {220–229},
numpages = {10},
keywords = {computer supported collaborative learning, classrooms, surface computing, tabletops},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686648,
author = {Copeland, Leana and Gedeon, Tom},
title = {Effect of Presentation on Reading Behaviour},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686648},
doi = {10.1145/2686612.2686648},
abstract = {Eye tracking is a useful tool for investigating how people read and the attention that they give to certain words and phrases. Eye tracking is used to investigate how different presentation formats of the same learning material affect learning performance, eye movements, and reading behaviour. We show that different presentation formats induce different eye movements and that reading behaviour is subject to the goals placed on the reader. We also observe that the presentation format affects not only their learning performance but also how they perceive their performance. Finally, we show that different formats and question types can induce specific reading behaviour such as thorough reading. This can be used to influence how students interact with the learning environment as well as how they learn the material. The purpose of this investigation is to be able to make informative decisions about designing adaptive eLearning environments.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {230–239},
numpages = {10},
keywords = {presentation format, eye gaze, eye tracking, adaptive eLearning},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686649,
author = {Ichino, Junko and Pon, Aura and Sharlin, Ehud and Eagle, David and Carpendale, Sheelagh},
title = {Vuzik: The Effect of Large Gesture Interaction on Children's Creative Musical Expression},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686649},
doi = {10.1145/2686612.2686649},
abstract = {Bringing the body more fully into interaction has attracted attention as research now looks to combines body, mind, cognition and emotion when people interact with a digital environment. This paper describes a user study comparing Vuzik -- an application where the user manipulates, arranges, and composes music with painting interaction akin to that used when standing at an easel, to a traditional, GUI based musical interface. Vuzik aims to promote creative musical experiences in children by allowing the child's actions and movements as he/she paints on a large display resembling a canvas using a palette and brush or finger to control musical parameters interactively. In a study conducted with fourteen elementary school children, we found that when compared to a more WIMP-based traditional tool, Vuzik promoted larger scale gestures, ease of learning, and the formation of a broader overall understanding of their musical creation.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {240–249},
numpages = {10},
keywords = {musical expression, large gesture interaction, embodiment, creativity, children},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686650,
author = {Fisk, Lyndsey and Carter, Marcus and Yeganeh, Behnaz Rostami and Vetere, Frank and Ploderer, Bernd},
title = {Implicit and Explicit Interactions in Video Mediated Collaboration},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686650},
doi = {10.1145/2686612.2686650},
abstract = {In this paper we report the results of a study comparing implicit-only and explicit-only interactions in a collaborative, video-mediated task with shared content. Expanding on earlier work which has typically only evaluated how implicit interaction can augment primarily explicit systems, we report issues surrounding control, anxiousness and negotiation in the context of video mediated collaboration. We conclude that implicit interaction has the potential to improve collaborative work, but that there are a multitude of issues that must first be negotiated.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {250–259},
numpages = {10},
keywords = {video mediated collaboration, implicit, interaction, explicit},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686651,
author = {Stisen, Allan and Blunck, Henrik and Kj\ae{}rgaard, Mikkel Baun and Gr\o{}nb\ae{}k, Kaj},
title = {Handheld versus Wearable Interaction Design for Professionals: A Case Study of Hospital Service Work},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686651},
doi = {10.1145/2686612.2686651},
abstract = {With the blooming of new available wrist-worn devices there are potentials for these to support the work done in many professional domains. One such domain is hospital service work. This paper explores two wearable prototypes' challenges and opportunities to support future hospital service work. This explorative study was conducted with 4 experienced hospital orderlies who interacted with an application across two wearable concepts, and one handheld smartphone in five scenarios, not involving patients, in a hospital environment. The interactions were recorded with a chest-mounted camera afterwards semi-structured interviews with each participant were conducted. This study shows that wearable computers can effectively support the maintenance work of the orderlies and has domain-specific advantages over the handheld smartphone, e.g., the former support glancing at the task information. Furthermore, we outline aspects to aid designers of next generation wearable designs for hospital service work.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {260–269},
numpages = {10},
keywords = {wearable computing, mobile work, handheld computing},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686652,
author = {Davis, Hilary and Pedell, Sonja and Lorca, Antonio Lopez and Miller, Tim and Sterling, Leon},
title = {Researchers as Proxies for Informal Carers: Photo Sharing with Older Adults to Mediate Wellbeing},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686652},
doi = {10.1145/2686612.2686652},
abstract = {Social technologies offer potential for enhancing aged care, but research on their use has largely focused on formalized care settings, rather than supporting informal care and wellbeing in the home. We examine the use of a novel social technology 'PictureFrame' to support the provision of wellbeing check use for older adults living at home. We conducted a field study of this photo and message-sharing tool to facilitate and support interaction and wellbeing checks with older people. We outline opportunities and challenges encountered when researchers enabled and supported interactions, and acted as part or full proxies for informal carers. We explore the technical, social and emotional aspects of photo and message sharing. Our findings demonstrate that 'PictureFrame' was valuable for providing reassurance, capturing emotional aspects of caregiving, and for monitoring wellbeing in subtle, non-intrusive ways. The proxy role enabled us to include the view of older adults who could not have participated otherwise.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {270–279},
numpages = {10},
keywords = {social technologies, wellbeing, iPad, older adults, emergency alarms, emotions, photo-sharing, prototype},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686653,
author = {Jalil, Sakib and Hardy, Dianna and Myers, Trina and Atkinson, Ian},
title = {But It Doesn't Go with the D\'{e}Cor: Domesticating a Telemedicine Diabetes Intervention in the Home},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686653},
doi = {10.1145/2686612.2686653},
abstract = {Type 2 Diabetes (T2D) is a chronic disease that requires day-to-day management. Telemedicine is one way of providing support to patients, to manage and receive care from home. Medical researchers use clinical trials to evaluate telemedicine technologies by comparing medical improvements of the patients. However, the patients' interactions and experiences with the technology are important because unpleasant experiences may result in non-adherence to a medical program. HCI experts have contributed in user-centred evaluations for decades. This research complements a telemedicine clinical trial with human-centred evaluation to understand patients during the post- rollout phase. Findings present patients' placement of telemedicine device in their homes, patients' feelings of using the device and their family involvement, and our experiences of conducting a HCI research with medical researchers in a clinical trial. We conclude that though the telemedicine device is seen as life-saving, patients treat it just as a regular device. We conclude that telemedicine evaluations such as clinical trials can benefit from evaluation methods in HCI.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {280–289},
numpages = {10},
keywords = {domestic life, telemedicine intervention, type 2 diabetes, clinical trial, contextual inquiry, experience},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686654,
author = {Torkilsheyggi, Arnv\o{}r \'{a} and Hertzum, Morten},
title = {User Participation in Pilot Implementation: Porters and Nurses Coordinating Patient Transports},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686654},
doi = {10.1145/2686612.2686654},
abstract = {Pilot implementations provide users with real-work experiences of how a system will affect their daily work before the design of the system is finalized. On the basis of a pilot implementation of a system for coordinating the transport of patients by hospital porters, we investigate pilot implementation as a method for participatory design. We find that to foster participation and learning about user needs a pilot implementation must create a space for reflecting on use, in addition to the space for using the pilot system. The space for reflection must also exist during the activities preparing the use of the pilot system because the porters and nurses learned about their needs throughout the pilot implementation, not just during use. Finally, we discuss how the scope and duration of a pilot implementation influence the conditions for participation.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {290–299},
numpages = {10},
keywords = {learning, real-use experience, pilot implementation},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686655,
author = {Lissermann, Roman and Huber, Jochen and Hadjakos, Aristotelis and Nanayakkara, Suranga and M\"{u}hlh\"{a}user, Max},
title = {EarPut: Augmenting Ear-Worn Devices for Ear-Based Interaction},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686655},
doi = {10.1145/2686612.2686655},
abstract = {One of the pervasive challenges in mobile interaction is decreasing the visual demand of interfaces towards eyes-free interaction. In this paper, we focus on the unique affordances of the human ear to support one-handed and eyes-free mobile interaction. We present EarPut, a novel interface concept and hardware prototype, which unobtrusively augments a variety of accessories that are worn behind the ear (e.g. headsets or glasses) to instrument the human ear as an interactive surface. The contribution of this paper is three-fold. We contribute (i) results from a controlled experiment with 27 participants, providing empirical evidence that people are able to target salient regions on their ear effectively and precisely, (ii) a first, systematically derived design space for ear-based interaction and (iii) a set of proof of concept EarPut applications that leverage on the design space and embrace mobile media navigation, mobile gaming and smart home interaction.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {300–307},
numpages = {8},
keywords = {ear-based interaction, device augmentation, ear-worn, multi-touch, mobile interaction, touch, eyes-free},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686656,
author = {M\"{u}ller, Hendrik and Sedley, Aaron},
title = {HaTS: Large-Scale in-Product Measurement of User Attitudes &amp; Experiences with <u>Ha</u>Ppiness <u>T</u>Racking <u>S</u>Urveys},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686656},
doi = {10.1145/2686612.2686656},
abstract = {With the rise of Web-based applications, it is both important and feasible for human-computer interaction practitioners to measure a product's user experience. While quantifying user attitudes at a small scale has been heavily studied, in this industry case study, we detail best Happiness Tracking Surveys (HaTS) for collecting attitudinal data at a large scale directly in the product and over time. This method was developed at Google to track attitudes and open-ended feedback over time, and to characterize products' user bases. This case study of HaTS goes beyond the design of the questionnaire to also suggest best practices for appropriate sampling, invitation techniques, and its data analysis. HaTS has been deployed successfully across dozens of Google's products to measure progress towards product goals and to inform product decisions; its sensitivity to product changes has been demonstrated widely. We are confident that teams in other organizations will be able to embrace HaTS as well, and, if necessary, adapt it for their unique needs.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {308–315},
numpages = {8},
keywords = {large scale, HaTS, tracking, metrics, surveys, attitudes},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686660,
author = {Stojmenovic, Milica and Pilgrim, Christopher and Lindgaard, Gitte},
title = {Perceived and Objective Usability and Visual Appeal in a Website Domain with a Less Developed Mental Model},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686660},
doi = {10.1145/2686612.2686660},
abstract = {In Human-Computer Interaction (HCI), the usability and aesthetics of webpages have been studied extensively. However, research into participant experience and expertise with the website domain being studied is often overlooked. This paper strived to acquire an understanding of the relationship between usability and visual appeal by examining it in a domain that had less developed mental models, to exclude the influence of past experiences. Two studies were conducted to (1) find a domain with a less developed mental model and (2) examine correlations between usability and aesthetics in the less familiar domain. Results of Study 1 showed that mental models were weaker for city council websites. Results of Study 2 showed that, for city council websites, pre- and post-use perceived usability and visual appeal, perceived usability and the number of passed tasks, and average number of hovers (objective usability) and visual appeal were all significantly and positively correlated.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {316–323},
numpages = {8},
keywords = {aesthetics, visual appeal, mental models, websites, usability},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686661,
author = {Khawaji, Ahmad and Chen, Fang and Zhou, Jianlong and Marcus, Nadine},
title = {Trust and Cognitive Load in the Text-Chat Environment: The Role of Mouse Movement},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686661},
doi = {10.1145/2686612.2686661},
abstract = {This paper examines how different levels of cognitive load can affect trust in the text-chat environment. It also examines how the mouse movements of participants can indicate the level of cognitive load when they chat with each other. We designed two chat systems: one in which subjects chat under low mental load and the other in which subjects chat under high mental load. Twenty subjects participated in the study and the results showed significant differences in the level of trust between subjects under different cognitive loads; that is, subjects who chatted under low mental load showed more trust in their partners. Moreover, the mouse data obtained proved to be effective in indicating the level of cognitive load existing between the subjects. However, this work suggests that to establish trust in the chat environment, it is better to communicate under a low cognitive load. Our findings also show the ability of designed systems to measure cognitive load via tracking mouse events for the purpose of providing assistance to communicators.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {324–327},
numpages = {4},
keywords = {trust, text-chat environment, cognitive load, social dilemma, mouse movement},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686662,
author = {Ganh\"{o}r, Roman and G\"{u}ldenpfennig, Florian and Subasi, \"{O}zge and Fitzpatrick, Geraldine},
title = {Towards Fast and Interactive Prototypes of Mobile Apps},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686662},
doi = {10.1145/2686612.2686662},
abstract = {With the advent of modern mobile phones and tablet devices unprecedented opportunities arise to create rich user experiences that incorporate the context in which the interaction is situated. Sensors and other built-in technologies provide designers with a variety of possibilities for new and exciting applications. Since building such applications requires specialists there is an increasing demand for tools supporting people without programming skills to access, explore and design for the opportunities of mobile devices. In this paper we present a novel prototyping system named FamOz that combines the ease of paper prototyping with the efficiency of Wizard of Oz while exploiting the interactivity offered by new mobile devices. FamOz allows designers and researchers to evaluate mobile prototypes in situated real-world settings in an early stage of development.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {328–331},
numpages = {4},
keywords = {prototyping, mobile, wizard of Oz, method, design process, design},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686663,
author = {Paay, Jeni and Kjeldskov, Jesper and Skov, Mikael B. and Lund, Dennis and Madsen, Tue and Nielsen, Michael},
title = {Design of an Appliance Level Eco-Feedback Display for Domestic Electricity Consumption},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686663},
doi = {10.1145/2686612.2686663},
abstract = {Over the past decade there has been an increased focus on eco-feedback systems for electricity consumption due to emerging technologies that allow detailed and real-time usage data to be collected and presented to users. In this paper, we present the design of an always-on eco-feedback display, PowerViz, that provides information about people's power usage in their homes at an appliance level. In our study, we found that PowerViz increased awareness towards energy consumption, gave householders a better understanding of high consumption devices and made it easy for them to isolate and respond to unnecessary or "greedy" appliances by turning them off or changing their use patterns. We also found that an ambient display of the household's total current electricity use both informed and attracted people to use the system when power usage became unusually high.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {332–341},
numpages = {10},
keywords = {situated display, design, technology probe, electricity, always-on display, sustainability, eco-feedback},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686664,
author = {Snow, Stephen and Radke, Kenneth and Vyas, Dhaval and Brereton, Margot},
title = {Privacy in the New Era of Visible and Sharable Energy-Use Information},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686664},
doi = {10.1145/2686612.2686664},
abstract = {A new era of visible and sharable electricity information is emerging. Where eco-feedback is installed, households can now visualise many aspects of their energy consumption and share this information with others through Internet platforms such as social media. Despite providing users with many affordances, eco-feedback information can make public previously private actions from within the intimate setting of the family home. This paper represents a study focussing specifically on the privacy aspects of nascent ways for viewing and sharing this new stream of personal information. It explores the nuances of privacy related to eco-feedback both within and beyond the family home. While electricity consumption information may not be considered private itself, the household practices which eco-feedback systems makes visible may be private. We show that breaches of privacy can occur in unexpected ways and have the potential to cause distress. The paper concludes with some suggestions for how to realise the benefits of sharing energy consumption information whist effectively maintaining individuals' conceptions of adequate privacy.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {342–351},
numpages = {10},
keywords = {social networking, collective information practices, eco-feedback, privacy, security, smart meters},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686665,
author = {Farr-Wharton, Geremy and Choi, Jaz Hee-Jeong and Foth, Marcus},
title = {Food Talks Back: Exploring the Role of Mobile Applications in Reducing Domestic Food Wastage},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686665},
doi = {10.1145/2686612.2686665},
abstract = {Mitigating domestic food waste reduces its environmental and economic impacts. In our study, we have identified the use of mobile technology to support behaviour change as a key tool to assist the process of reducing food waste. This paper reports on three mobile applications designed to reduce domestic food waste: Fridge Pal, LeftoverSwap and EatChaFood. The paper examines how each app can influence consumer knowledge of domestic food supply, location, and literacy. We discuss our findings with respect to three considerations: (i) assisting with the user's food supply and location knowledge; (ii) improving the user's food literacy; (iii) facilitating social food sharing of excess food. We present new insights for mobile interventions that encourage changes towards more sustainable behaviours to reduce food waste.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {352–361},
numpages = {10},
keywords = {food sharing, eatchafood, food location, social engagement, food supply, user behaviour, mobile, HCI, urban informatics, fridge pal, leftoverswap, behaviour change, food literacy, australia},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686666,
author = {Lyle, Peter and Choi, Jaz Hee-jeong and Foth, Marcus},
title = {Designing for Grassroots Food Production: An Event-Based Urban Agriculture Community},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686666},
doi = {10.1145/2686612.2686666},
abstract = {As urbanisation of the global population has increased above 50%, growing food in urban spaces increases in importance, as it can contribute to food security, reduce food miles, and improve people's physical and mental health. Approaching the task of growing food in urban environments is a mixture of residential growers and groups. Permablitz Brisbane is an event-centric grassroots community that organises daylong 'working bee' events, drawing on permaculture design principles in the planning and design process. Permablitz Brisbane provides a useful contrast from other location-centric forms of urban agriculture communities (such as city farms or community gardens), as their aim is to help encourage urban residents to grow their own food. We present findings and design implications from a qualitative study with members of this group, using ethnographic methods to engage with and understand how this group operates. Our findings describe four themes that include opportunities, difficulties, and considerations for the creation of interventions by Human-Computer Interaction (HCI) designers.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {362–365},
numpages = {4},
keywords = {urban agriculture, urban informatics, food, gardening, grass roots community},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686667,
author = {Frawley, Jessica K. and Dyson, Laurel E. and Underwood, Jim},
title = {Rewriting, Redesigning and Reimagining the Recipe for More Sustainable Food Systems},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686667},
doi = {10.1145/2686612.2686667},
abstract = {This paper describes Red Hen Recipes, a user generated recipe site that seeks to connect buying, cooking and eating practices with the modes of food production through the redesign of the recipe format. User research found recipes to be a reflective and creative space for imagining "what we should eat". Through simple website technologies we redesign the recipe to afford users the opportunity of exploring "what we should eat" within the context of the wider agro-food system. The site provides a digital space for dialogic interactions between farmers, backyard growers, shoppers and foragers to "rewrite" the recipe to include information about the origins of a single ingredient. In connecting the labour of the field with the labour of the home and kitchen, this tool deliberately breaks down the false dichotomy of producer and consumer, and identifies all users as active producers within the food system, albeit within different contexts.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {366–369},
numpages = {4},
keywords = {sustainable HCI, learning interactions, food systems},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686668,
author = {Collins, Emily I. M. and Cox, Anna L. and Bird, Jon and Cornish-Tresstail, Cassie},
title = {Barriers to Engagement with a Personal Informatics Productivity Tool},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686668},
doi = {10.1145/2686612.2686668},
abstract = {Technology helps us get work done but also provides many distractions. As a result, seemingly unproductive activities such as social networking sites (SNS) cause considerable stress. This paper reports a series of studies into whether personal informatics (PI) tools for productivity can make people more aware of their SNS usage and encourage behaviour change. The first two studies took an in-the-wild approach, encouraging students to use a PI tool, RescueTime, to improve their estimations of how much time they spent using SNS, in line with research that had used this technique to reduce participants' stress. However, participants simply did not engage with RescueTime in the studies. A further interview study found that there are four barriers that inhibit engagement with this PI tool and reduce its potential to facilitate behaviour change. In particular, the way it presents data lacks: salience; contextual information; credibility; and action advice.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {370–379},
numpages = {10},
keywords = {barriers, productivity, personal informatics tools, stress, engagement, social networking},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686669,
author = {Peiris, Roshan Lalintha and Janaka, Nuwan and De Silva, Deepthika and Nanayakkara, Suranga},
title = {SHRUG: Stroke Haptic Rehabilitation Using Gaming},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686669},
doi = {10.1145/2686612.2686669},
abstract = {In this paper we present SHRUG, an interactive shoulder rehabilitation exerciser. With this work-in-progress system, we intend to (1) explore the effectiveness of providing interactive and just-in-time feedback to the patients and therapists; (2) explore the effect of adding a gaming element on the motivation of the patients. The SHRUG prototype was developed in collaboration with the rehabilitation therapists by augmenting their existing exercising system. We present the implementation details of the system and some of the initial reactions from the therapists on various aspects of the SHRUG prototypes.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {380–383},
numpages = {4},
keywords = {serious games, responsive objects, stroke rehabilitation},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686670,
author = {Regenbrecht, Holger and Langlotz, Tobias and Ho, Christine and George, Mark and Gray, Andrew and Walmsley, Russell and Schultz, Michael},
title = {Field Test of a Questionnaire-Based Mobile Health Reporting System},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686670},
doi = {10.1145/2686612.2686670},
abstract = {There is increasing demand to improve the quality and efficiency of healthcare delivery. Mobile health self-reporting can play a vital role here, provided that user acceptance can be achieved. We developed a mobile health reporting app for patients suffering from inflammatory bowel diseases and tested its acceptance, perceived usefulness and usability in a field trial with 35 patients over a period of eight weeks. Participants selected were already accustomed to filling in questionnaires about their health and well-being (albeit less frequently and post-hoc). Therefore we designed and implemented an interface emulating this form of interaction as closely as possible. This approach proved to be successful: our participants in the field study attested to the feasibility of this approach as indicated by the data presented here. With our example, we can show that for an effective transition to electronic/mobile systems, it should be possible to minimize the gulfs of execution and evaluation.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {384–387},
numpages = {4},
keywords = {mobile health care, field research, usability and utility, mobile user interfaces},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686671,
author = {Wadley, Greg and Smith, Wally and Ploderer, Bernd and Pearce, Jon and Webber, Sarah and Whooley, Mark and Borland, Ron},
title = {What People Talk about When They Talk about Quitting},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686671},
doi = {10.1145/2686612.2686671},
abstract = {As part of an ongoing project to explore the design of behaviour-change technology for smoking cessation, we analysed a successful community who come together on the popular Reddit website to discuss quitting and to encourage each other's quit attempts. We found that users remain anonymous but identify according to their quit stage. We examined the form and content of posts, finding that narratives about people and events are more common than other rhetorical forms. Many speak of ongoing struggles with quit attempts. Our analysis reveals forms of sociality spontaneously enacted in a self-managed community of quitters. We compare our results with earlier work on social media and behaviour change.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {388–391},
numpages = {4},
keywords = {online health community, Reddit, smoking cessation},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686672,
author = {Smith, Wally and Wadley, Greg and Webber, Sarah and Ploderer, Bernd and Lederman, Reeva},
title = {Unbounding the Interaction Design Problem: The Contribution of HCI in Three Interventions for Well-Being},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686672},
doi = {10.1145/2686612.2686672},
abstract = {In this paper we consider HCI's role in technology interventions for health and well-being. Three projects carried out by the authors are analysed by appropriating the idea of a value chain to chart a causal history from proximal effects generated in early episodes of design through to distal health and well-being outcomes. Responding to recent arguments that favour bounding HCI's contribution to local patterns of use, we propose an unbounded view of HCI that addresses an extended value chain of influence. We discuss a view of HCI methods as mobilising this value chain perspective in multi-disciplinary collaborations through its emphasis on early prototyping and naturalistic studies of use.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {392–395},
numpages = {4},
keywords = {behaviour change, value chain, contribution of HCI, medical informatics},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686673,
author = {Lu, Zeqing and Matthews, Ben and Viller, Stephen},
title = {Designing for Reducing Procrastination on Side Projects},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686673},
doi = {10.1145/2686612.2686673},
abstract = {People have the tendency to procrastinate on their side projects, despite how much they would like to finish them. A persuasive web application was built and evaluated as a platform to help motivate people to reduce procrastination and make regular progress on their side projects. Tuition is an online community where users document, review and share their progress on their side projects. The application was evaluated with 17 students and professionals working in the IT and multimedia design industry. We found that clearly communicating the central purpose of the app, but allowing for users to use the platform in their own ways was effective in persuading the target behaviour (i.e. not procrastinating).From our experiences of designing and deploying Tuition, we take some initial steps towards a critical review of persuasive design guidelines such as Fogg's (2009) Eight Step Design Process as they apply to heterogeneous behaviour patterns like procrastination. We suggest these existing design guidelines tend to be too generalised to provide the intended help to design when applied to support or allay complex behaviours.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {396–399},
numpages = {4},
keywords = {productivity, interaction design, persuasive technology},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686675,
author = {Smith, Wally and Lewi, Hannah and Constantinidis, Dora and Stitt, Helen},
title = {Directed Looking and Proximal Content: Two Concepts for Designing Mobile Guides to Historic Urban Places},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686675},
doi = {10.1145/2686612.2686675},
abstract = {Over the past decade, a body of HCI research has investigated technologies intended to enrich visitors' experience of historic places in situ. While much of this research has examined novel technologies and forms of interaction, in this paper we explore a complementary question: How do different kinds of content presented on a mobile device affect visitors' interaction with place? We present some findings from the design and evaluation of a mobile guide to the architectural history of a major city street in Melbourne. Through direct observation of students taking the tour and a later survey questionnaire, we found that some kinds of content were more effective in supporting peoples' interrogation of place. To explain this we propose two related concepts relevant to the design of mobile content in this context: directed looking and proximal content.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {400–403},
numpages = {4},
keywords = {mobile guide, directed looking, proximal content, architectural history},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686674,
author = {Ishac, Karlos and Rozado, David},
title = {Low Cost Human-Robot Gaze Estimation System},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686674},
doi = {10.1145/2686612.2686674},
abstract = {This work presents the development of a low cost Human-Robot gaze estimation system for the purpose of promoting joint Human-Robot workspaces in daily scenarios. We have developed this system using only monocular eye tracking and the 2D gaze point. Prior to this work there have been many efforts to bridge the gap between human and robots by developing robotic assistants capable of serving humans through command based interaction or manual input. Such systems lack freedom and require constant input whenever interaction is required. The system we have developed allows for both seated and free roaming interaction between a human and the robot. The end software allows the robot to track the gaze point of the human in real-time and fixate on the same point in space. Once the robot is stabilized on this gaze point it may perform a number of different tasks which may assist the human. We have constructed our own pair of gaze tracking glasses using only low cost components to demonstrate effective performance under budget costs. These glasses are coupled with a pan/tilt laser robot which tracks the gaze point of the human on the environment by projecting a red laser. We have designed 2 separate subsystems which track the pose o the user's head in real time and then combine to give an accurate estimate relative to the robot. As well as this we have developed a gaze tracking module which calibrates the gaze point of the human to a relative gaze window on the robot. Data from all 3 subsystems are then combined through a data fusion model and then sent to the robot to adjust its pan/tilt angles to focus on the same point in space as the human. These subsystems combine to provide an accuracy of 94% to the centre of a target object. The system was tested through a user study which involved 12 subjects undergoing 5 different testing scenarios.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {404–413},
numpages = {10},
keywords = {mobile interaction, eye tracking, joint workspace, head mounted tracker, assistant robot, HRI, gaze tracking, gaze point, HCI, eye tracking glasses},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686676,
author = {Rozado, David and Stephen, Louis and Kottege, Navinda},
title = {Interacting with Objects in the Environment Using Gaze Tracking Glasses and Speech},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686676},
doi = {10.1145/2686612.2686676},
abstract = {This work explores the combination of gaze and speech to interact with objects in the environment. A head-mounted wireless gaze tracker in the form of gaze tracking glasses is used for mobile monitoring of a subject's point of regard on the surrounding environment. In our proposed system, a mobile subject gazes at an object of interest in the environment which opens an interaction window with the object being gazed upon, and a specific interaction command is then given to the object using speech commands. The gaze tracking glasses were made from low-cost hardware consisting of a safety glasses' frame and wireless eye tracking and scene cameras. An open source gaze estimation algorithm is used for eye tracking and user's gaze estimation. The Windows Speech Recognition engine is used for recognition of voice commands. A visual markers recognition library is used to identify objects in the environment through the scene camera. When combining all these elements, the emerging system permits a subject to move freely in an environment, select the object he wants to interact with using gaze (identification) and transmit a control command to it by uttering a speech command (control).},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {414–417},
numpages = {4},
keywords = {gaze interaction, gaze tracking glasses, speech interaction, HCI, mobile interaction, gaze tracking},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686677,
author = {Majrashi, Khalid and Hamilton, Margaret and Uitdenbogerd, Alexandra L.},
title = {Cross-Platform Usability and Eye-Tracking Measurement and Analysis Model},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686677},
doi = {10.1145/2686612.2686677},
abstract = {Evaluating the usability of cross-platform interactive systems has become increasingly important. In this paper, we review the interpretations of current eye-movement metrics across several usability and HCI studies. We found that the existing eye-tracking metrics and their associated interpretations do not consider cross-platform usability (CPU) aspects. Therefore, taking into consideration the characteristics of user interaction with Multiple User Interfaces (MUIs), a usability-engineering model, which is called Eye Tracking Measurement and Analysis model for Cross-Platform Usability (CPU-EMA), has been developed. This model decomposed eye-tracking metrics for cross-platform usability into four high-level metrics, namely, cross-platform fixation, saccade, scanpath and gaze. The high-level metrics were further decomposed into low-level metrics with possible interpretations for cross-platform usability. The model also provided procedures for measuring and analysing cross-platform usability using eye-movement data.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {418–421},
numpages = {4},
keywords = {cross-platform usability, user experience, eye-tracking metrics, multiple user interfaces},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686678,
author = {Hettiarachchi, Anuruddha and Premalal, Anuruddha and Dias, Dileeka and Nanayakkara, Suranga},
title = {Toward Context-Aware Just-in-Time Information: Micro-Activity Recognition of Everyday Objects},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686678},
doi = {10.1145/2686612.2686678},
abstract = {Transferring computational tasks from user-worn devices to everyday objects allows users to freely focus on their regular non-computing tasks. Identifying micro-activities (short-repetitive-activities that compose the macro-level behavior) enables the understanding of subtle behavioral changes and providing just-in-time information without explicit user input. In this paper, we propose the concept of micro-activity recognition of augmented-everyday-objects and evaluate the applicability of machine learning algorithms that are previously used for macro-level activity recognition. We outline a few proof-of-concept application scenarios that provide micro-activity-aware just-in-time information.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {422–425},
numpages = {4},
keywords = {classification, micro-activity recognition, augmented-everyday-objects},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686679,
author = {Portela, Matheus Vieira and Rozado, David},
title = {Gaze Enhanced Speech Recognition for Truly Hands-Free and Efficient Text Input during HCI},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686679},
doi = {10.1145/2686612.2686679},
abstract = {The performance of current speech recognition algorithms is well below that of human speech recognition, with high number of misrecognized words in quiet environments and degrading even further in noisy ones. Therefore, hands-free interaction remains a deeply frustrating experience. In this work, we present an innovative form of correcting misrecognized words during a speech recognition task by using gaze tracking technology in a multimodal approach. We propose to employ the user's gaze to point at misrecognized words and select appropriate alternatives. We compare the performance of this multimodal approach with traditional modalities of correcting words: usage of mouse and keyboard and usage of voice alone. The results of the user study show that whereas the proposed system is not as fast as using mouse and keyboard for correction, gaze enhanced correction significantly outperforms voice alone correction and is preferred by the users, offering a truly hands-free means of interaction.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {426–429},
numpages = {4},
keywords = {gaze responsive systems, multimodal interaction, gaze tracking, speech recognition},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686680,
author = {Pakanen, Minna and Arhippainen, Leena},
title = {User Experiences with Web-Based 3D Virtual Travel Destination Marketing Portals: The Need for Visual Indication of Interactive 3D Elements},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686680},
doi = {10.1145/2686612.2686680},
abstract = {The tourism sector has found virtual reality technology to be a good way to market travel destinations for consumers. In this paper, we describe two user studies with three web-based 3D virtual travel destination marketing portals. These three portals were developed to support and attract wintertime tourism into the region by offering a possibility to experience in advance, a virtual snowy scenery with different activities, for example downhill skiing. In both user studies with 21 subjects the focus was on user experience with the 3D virtual travel destination marketing portals. In the second study also the visual design aspects within these portals were studied. Our studies indicate that 3D virtual travel destination marketing portals can enhance 2D web pages, if they offer the possibility to explore the location freely and through different kinds of virtual activities. Also our studies support prior findings of the efficiency of glow effect for indicating interactive 3D elements within a 3D virtual environment.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {430–439},
numpages = {10},
keywords = {3D, virtual environments, HCI, visual indication, travel destination marketing, user experience, design},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686681,
author = {Dekker, Andrew and Worthy, Peter and Viller, Stephen and Zimbardi, Kirsten and Robinson, Ricky},
title = {Designer-Client Communication in Web Design: A Case Study on the Use of Communication in Practice},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686681},
doi = {10.1145/2686612.2686681},
abstract = {This paper reflects on a participant observational study that was conducted during a long-term iterative design project in which there was a high level of digital communication between the designers and clients. We describe a number of communication technologies that were employed to support the designer-client communication, and examine how successful they were in supporting this work. In our reflection we find that although the nature of digital communication between participants appears straightforward, there are a number of complexities in the roles and messiness that occurs throughout the design process. We examine how these channels were used in tandem to effectively communicate between the stakeholders, and explore why some technologies (primarily email) were more successful than others. Finally, we describe a number of patterns that emerged within the overall narrative, and reflect on ways in which these tools could be considered and designed in the future to better support this kind of project work.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {440–443},
numpages = {4},
keywords = {communication design, CMC, web design, interaction design, CSCW, application design},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686682,
author = {Simonsen, Jesper and Hertzum, Morten and Nielsen, J\o{}rgen Lerche and Riis, S\o{}ren},
title = {Toward a Theory for the Design of Human Technologies},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686682},
doi = {10.1145/2686612.2686682},
abstract = {Design is increasingly becoming a part of the university curriculum and research agenda. A theory about the process and practice of design might be important to establish design as a main subject at universities. We believe it is in the interest of many design communities -- not least the Participatory Design (PD) community -- to engage in theorizing design, on the basis of our understanding of design and design practices. This theory could be positioned as an alternative to other attempts to theorize design, for example the influential efforts of the Information Systems (IS) community. We urge the PD community to engage in collective theory building, and we present a framework intended to support our shared reflections on the design of human technologies.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {444–447},
numpages = {4},
keywords = {epistemology, framework, theory, design},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686683,
author = {Sutherland, Claire and Coventry, Lynne and Sillence, Elizabeth},
title = {Using Animated Scenarios to Explore Severity of Cyberbullying and Reporting Readiness},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686683},
doi = {10.1145/2686612.2686683},
abstract = {Cyberbullying is a growing social problem especially amongst school aged children facilitated by the prevalent use of communication technology. This paper examines (a) the extent to which cyberbullying incidents are distinguishable by perceived severity and (b) the role of perpetrator anonymity on such perceptions of severity. Sixty six female school students (age 10--12 years) were shown animated scenarios depicting mobile phone based cyberbullying scenarios. Measures of severity and likelihood to report the incident were taken. The findings show that children were able to distinguish between different levels of severity of cyberbullying and were influenced by the anonymity of the perpetrator, with anonymous perpetrator scenarios being rated as more severe than known perpetrators. Bystanders rated scenarios with the same severity as victims but were less likely to report.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {448–451},
numpages = {4},
keywords = {cyberbullying, reporting, scenarios, bystander, perceived severity, resilience},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686684,
author = {Mannonen, Petri and Aikala, Maiju and Koskinen, Hanna and Savioja, Paula},
title = {Uncovering the User Experience with Critical Experience Interviews},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686684},
doi = {10.1145/2686612.2686684},
abstract = {User experience (UX) design relies on comprehensive understanding about the experiential aspects of users and their tasks. Gathering the understanding is difficult and there is a need for cost-efficient ways to build the UX knowledge. This paper describes a study where the critical decision-making method (CDM) was adapted to user experience research and tried-out in process industry context. CDM is a retrospective interview strategy, which aims to elicit the insights of decision-making of professionals through a walkthrough of non-routine decision-making events. Our adapted version of the CDM, critical experience interview, utilizes the structure and core logic of CDM but focuses on experiential and emotional factors instead of reasoning and decision making ones. The strengths of the critical experience interview lie in the multiple viewpoints and iterative interview strategy. In the study, the critical experience interview was able to produce useful and rich descriptions of work related experiences of the interviewees.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {452–455},
numpages = {4},
keywords = {user research method, interview, user experience, critical incident},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686685,
author = {Nonose, Kohei and Corver, Sifra and Majumdar, Arnab and Gudela, Grote and Kanno, Taro and Furuta, Kazuo},
title = {A Behavioural Observation Method to Assess Team Situation Awareness of Air Traffic Control Teams},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686685},
doi = {10.1145/2686612.2686685},
abstract = {High reliability teams in complex and dynamics settings. such as air traffic control (ATC) teams, require high levels of shared awareness and understanding between team members concerning the task for safe and efficient operations. Although much research has been devoted to the measurement of situation awareness of individuals in high risk environments, the operationalization of team situational awareness (TSA) has remained fuzzy and the development of techniques to measure TSA has received little attention. This study describes the first results of a TSA measurement based on mutual belief. The new TSA method is a qualitative as well as a quantitative method, which relies on qualitative data obtained through behavioral observation by Subject Matter Experts and allows quantitative TSA ratings based on the collected data. This paper describes the method and initial efforts to establish reliability and validity in an ATC environment and discusses the next steps for further development.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {456–459},
numpages = {4},
keywords = {en-route air traffic control, behavioural observation, team situation awareness, evaluation of human-machine systems},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686686,
author = {Rodil, Kasper and Winschiers-Theophilus, Heike and Stanley, Colin and Kapuire, Gereon Koch and Rehm, Matthias},
title = {An Approach to User Interface Design with Two Indigenous Groups in Namibia},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686686},
doi = {10.1145/2686612.2686686},
abstract = {It has been widely reported that interactions with and expectations of technology differ across cultural contexts. Concepts such as 'usability' have shown to be context-dependent, thus user interfaces intuitive to one group of users appears counter-intuitive to the others. In an attempt to localise a user interface of a tablet based system aimed at preserving Indigenous Knowledge for rural Herero communities, we present findings from two sites in Namibia, complementing prior research. Participants who had little or no previous experience with technologies informed our endeavour of aligning local indigenous knowledge practices with digital object taxonomies. We present a method (picture card sorting) of discovering taxonomies that influence the users' interaction with a prototype system to preserve indigenous knowledge. Finally we describe the design implications, a new design approach based on findings and present preliminary evaluations in a collaboration village as well as design export results with another indigenous group.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {460–469},
numpages = {10},
keywords = {user-interface, indigenous knowledge, taxonomy, user model, participatory design, cultural, categorization},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686687,
author = {Walsh, Tanja and Petrie, Helen and Odutola, Olufunmilayo},
title = {Developing Interactive Systems for Different Cultures: Issues of Assessing User Experience with Visual Materials},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686687},
doi = {10.1145/2686612.2686687},
abstract = {Evaluation of user experience (UX) in cross-cultural settings is vital for the development of interactive systems due to the globalization of markets and the search for good user experience in interactive systems. Although interactive systems are distributed globally, users are always local and this should be taken into consideration in methods and materials used in the cross-cultural UX research. A localized web-survey was designed and data collected from 92 respondents in two cultures, Nigeria and Anglo-Celtic (AC) countries (Australia, Canada, Ireland, and the UK). We found that Nigerian respondents are more positive in their ratings than AC respondents, irrespective of content, and are less likely to criticize in their feedback. The culture of the respondents and culture of the visual materials of the scenarios does matter in respondents' reactions, but the way it matters is not straightforward, and there are complex interactions. We expected that our results would show a strong identification with one's own cultural group, but this turns out to be only one aspect of a scenario that may affect respondents' reactions. Therefore care needs to be taken in localizing visual materials and in interpreting the results from different cultural groups.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {470–479},
numpages = {10},
keywords = {UX, cross-cultural user research methods, localization, visual materials, online surveys},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686688,
author = {Shaw, Grace and Brereton, Margot and Roe, Paul},
title = {Mobile Phone Use in Australian Indigenous Communities: Future Pathways for HCI4D},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686688},
doi = {10.1145/2686612.2686688},
abstract = {This paper collates recent research on mobile phone use in Indigenous communities in Australia. Its key finding is that mobile phones are heavily used in these communities, albeit in unique and unusual ways that may be difficult to comprehend beneath 'top-down' measurements. Rather than framing these uses as being compromises made in lieu of appropriate infrastructures or literacies, it is argued that HCI4D (Human-Computer Interaction for Development) would be better served by seriously plumbing into the information they reveal about how mobile phones are constructed and placed in these communities, and what these factors might reveal about local understandings of development and well-being. A consideration of these specific patterns of appropriation is necessary to push the field beyond top-down, rationalist approaches to development towards more flexible, creative solutions that build from local knowledge and competencies.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {480–483},
numpages = {4},
keywords = {HCI4D, indigenous, mobile phones, indigenous design, critical HCI4D},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686689,
author = {Byamugisha, Joan and Sitbon, Laurianne and Brereton, Margot},
title = {Cultural and Linguistic Localization of Games to Bridge the Digital and Cultural Divide in Indigenous Populations},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686689},
doi = {10.1145/2686612.2686689},
abstract = {Localization of technology is now widely applied to the preservation and revival of the culture of indigenous peoples around the world, most commonly through the translation into indigenous languages, which has been proven to increase the adoption of technology. However, this current form of localization excludes two demographic groups, which are key to the effectiveness of localization efforts in the African context: the younger generation (under the age of thirty) with an Anglo-American cultural view who have no need or interest in their indigenous culture; and the older generation (over the age of fifty) who are very knowledgeable about their indigenous culture, but have little or no knowledge on the use of a computer. This paper presents the design of a computer game engine that can be used to provide an interface for both technology and indigenous culture learning for both generations. Four indigenous Ugandan games are analyzed and identified for their attractiveness to both generations, to both rural and urban populations, and for their propensity to develop IT skills in older generations.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {484–487},
numpages = {4},
keywords = {Omweso, indigenous culture, Matatu, localization, game engine technology},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686690,
author = {Jumisko-Pyykk\"{o}, Satu and V\"{a}\"{a}t\"{a}j\"{a}, Heli and Jaakola, Markus},
title = {Quality Management of User-Generated Content in Participatory Journalism},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686690},
doi = {10.1145/2686612.2686690},
abstract = {Newsrooms utilize increasing amounts of user-generated content (UGC) in news making. However, managing the quality of UGC is challenging. Our three-phase study identifies qualities of newsworthy UGC, and ways to enhance the quality of contributions by online feedback. Review of 31 UGC-driven websites revealed as the most used methods of improving the quality of contributions flagging of inappropriate content, counts of sharing to social media services, ratings, user's activity statistics, and badges. Interviews of news editors and reader reporters showed a conceptual difference in the qualities of good news content. Interviewed reader reporters expressed the feedback from the newsroom as the most important for their development in addition to seeing the examples by other reader reporters. Content was perceived as more important than competition in case of readers' UGC. Communal quality management conventions, online community elements, and guidelines for developing quality management are presented.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {488–497},
numpages = {10},
keywords = {online feedback, user-generated content, hyperlocal, media, news, participatory journalism, quality management},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686691,
author = {Peiris, Roshan Lalintha and Nanayakkara, Suranga},
title = {PaperPixels: A Toolkit to Create Paper-Based Displays},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686691},
doi = {10.1145/2686612.2686691},
abstract = {In this paper we present PaperPixels, a toolkit for creating subtle and ambient animations on regular paper. This toolkit consists of two main components: (1) a modularised plug and play type elements (PaperPixels elements) that can be attached on the back of regular paper; (2) a GUI (graphical user interface) that allows users to stage the animation in a time line format. A user would simply draw on regular paper, attach PaperPixels elements behind the regions that needs to be animated, and specify the sequence of appearing and disappearing by arranging icons on a simple GUI. Observations made during a workshop at a local maker faire showed the potential of PaperPixels being integrated in many different applications such as animated wallpapers, animated story books.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {498–504},
numpages = {7},
keywords = {paper display, peltier, toolkit, DIY, thermochromic},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686692,
author = {Nurkka, Piia and Jumisko-Pyykk\"{o}, Satu},
title = {Exploring Online Customization of a High Involvement Experience Product},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686692},
doi = {10.1145/2686612.2686692},
abstract = {The success of online customization depends on the readiness and willingness of users' to adopt it. The purpose of this study was to explore the potential for applying online customization in surfboard manufacturing. Surfers' needs and preferences related to surfboard purchase were investigated and the associated benefits and costs were identified in an interview study of 22 surfers in two countries, New Zealand and Finland. In addition, their perception of online customization, including interest to use and potential barriers of use, was explored with a stimulus. The findings were combined to create initial requirements for an online surfboard customization tool.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {505–514},
numpages = {10},
keywords = {online customization, surfboard, configuration tool, requirements},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686693,
author = {Sitbon, Laurianne and Wong, Oscar and Brereton, Margot},
title = {Efficient Web Browsing with a Single-Switch},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686693},
doi = {10.1145/2686612.2686693},
abstract = {This paper presents a new approach to web browsing in situations where the user can only provide the device with a single input command device (switch). Switches have been developed for example for people with locked-in syndrome and are used in combination with scanning to navigate virtual keyboards and desktop interfaces. Our proposed approach leverages the hierarchical structure of webpages to operate a multi-level scan of actionable elements of webpages (links or form elements). As there are a few methods already existing to facilitate browsing under these conditions, we present a theoretical usability evaluation of our approach in comparison to the existing ones, which takes into account the average time taken to reach any part of a web page (such as a link or a form) but also the number of clicks necessary to reach the goal. We argue that these factors contribute together to usability. In addition, we propose that our approach presents additional usability benefits.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {515–518},
numpages = {4},
keywords = {single switch, scanning, web browsing, disability},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686694,
author = {Rajapakse, Ravihansa and Brereton, Margot and Roe, Paul and Sitbon, Laurianne},
title = {Designing with People with Disabilities: Adapting Best Practices of DIY and Organizational Approaches},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686694},
doi = {10.1145/2686612.2686694},
abstract = {Individualization of design is often necessary particularly when designing with people with disabilities. Maker communities, with their flexible Do-It-Yourself (DIY) practices, offer potential to support individualized and cost-effective product design. However, efforts to adapt DIY practices in designing with people with disabilities tend to face difficulties with regard to continuous commitment, infrastructure provision and proper guidance. We carried out interviews with diverse stakeholders in the disability services sector and carried out observations of local makerspaces to understand their current practices and potential for future collaborations. We found that makerspace participants face difficulties in terms of infrastructure provision and proper guidance whereas Disability Service Organizations face difficulties in continuous expertise. We suggest that artful infrastructuring to blend the best of both approaches offers potential to create a sustainable community that can design individualized technologies to support people with disabilities.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {519–522},
numpages = {4},
keywords = {disability services, individualized design, DIY design, maker communities},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686695,
author = {Araullo, Jake and Potter, Leigh Ellen},
title = {Experiences Using Emerging Technology},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686695},
doi = {10.1145/2686612.2686695},
abstract = {Emerging technologies are being developed at a rapid pace, driven by strong innovation in the hardware sector, resulting in an increase in the range of input devices that people can use to interact with computers and applications. Unfortunately, there are no established interaction standards or best practices when developing software for emerging technologies, and user experience suffers as a result. This paper presents the findings from an early case study exploring the experiences of a group of individuals when playing games using emerging technology: namely the Oculus Rift and the Leap Motion controller. This case study provides insight into the usability of the interaction between game and device.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {523–526},
numpages = {4},
keywords = {emerging technology, natural user interface},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686696,
author = {Jensen, Mads M\o{}ller and Mueller, Florian 'Floyd'},
title = {Running with Technology: Where Are We Heading?},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686696},
doi = {10.1145/2686612.2686696},
abstract = {Running has become popular in recent years, and numerous runners utilize wearable technologies in order to improve their run training. This paper investigates the development and trends in technologies used for run training, and describes how these are changing from solely focusing on the performance (e.g. pace) to having an additional focus on the technique (e.g. foot strike type). Based on this investigation, we present a design space for run-training technologies. By plotting existing technologies onto the design space, we argue that there has been limited attention on how to utilize technique-related information in run-training interfaces. From that finding, this paper presents three questions to be addressed by designers of future run-training interfaces. We believe that addressing these questions will support creation of expedient interfaces that improve runners' technique and training.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {527–530},
numpages = {4},
keywords = {exertion interfaces, interactive sports-training systems, running, running technologies, sports},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686697,
author = {Xu, Yuanying and Zhang, Jinglan and Yagovkin, Roman and Maniero, Simone and Wangchunk, Phurpa and Koplick, Stewart},
title = {Rove n Rave™ Development: A Partnership between the University and the Disability Service Provider to Build a Social Website for People with an Intellectual Disability},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686697},
doi = {10.1145/2686612.2686697},
abstract = {Rove n Rave ™ is a website designed and created for, and with, people with an intellectual disability. Its aim is to provide them with a user-friendly online platform where they can share opinions and experiences, and where they can find reviews which will help them to choose a place to visit themselves.During the development process, input on design requirements was gathered from a group of people with an intellectual disability and the disability service provider. This group then tested the product and provided further feedback on improving the website. It was found that the choice of wording, icons, pictures, colours and some functions significantly affected the users' ability to understand the content of the website. This demonstrated that a partnership between the developer and the user is essential when designing and delivering products or services for people with an intellectual disability.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {531–534},
numpages = {4},
keywords = {co-design, intellectual disability, user-oriented, inclusive design, universal design, web development},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686698,
author = {Al Mahmud, Abdullah},
title = {Considerations for Designing Technology with and for Persons with Aphasia},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686698},
doi = {10.1145/2686612.2686698},
abstract = {This paper provides the lessons learned from two design research projects, which deal with designing technology with and for persons with aphasia. We faced several challenges while conducting usability studies, recruiting aphasic individuals and conducting field studies. Based on our experience from the two projects we provide recommendations to design and test interactive systems for people with aphasia.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {535–538},
numpages = {4},
keywords = {design guidelines, aphasia, assistive technology},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686699,
author = {Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {Exploring Finger Specific Touch Screen Interaction for Mobile Phone User Interfaces},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686699},
doi = {10.1145/2686612.2686699},
abstract = {Today, mobile phones with touch screens are widespread but as de facto, the interaction space is limited to single finger taps or multitouch gestures. In this paper, we present an investigation of a novel interaction concept for mobile phone touch screen input by distinguishing between different fingers. To explore the concept, we organized three user studies (number of participants 37, 13 and 25), where we charted the finger specific input performance, and evaluated the concept with both a Wizard-of-Oz prototype and a functional implementation. The salient results show, e.g. statistical differences in comfort and perceived speed for interacting with different fingers, and that users see value in finger specific functionality, especially in providing fast shortcuts to different functions and as a means to personalize the interaction with the device.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {539–548},
numpages = {10},
keywords = {touch screens, user interfaces, mobile interaction, user studies, mobile phones},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686700,
author = {Shibata, Hirohito and Takano, Kentaro and Omura, Kengo},
title = {Comparison of Paper and Computer Displays in Reading Including Frequent Movement between Pages},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686700},
doi = {10.1145/2686612.2686700},
abstract = {This paper describes experiments to compare reading with paper versus electronic media when reading with frequently moving back and forth between pages. In the first experiment, eighteen participants read aloud multi-page documents with endnotes in three conditions: paper, a large display, and a small display. Results revealed that reading from paper was 6.8% faster than reading from a large computer display and 11.4% faster than reading from a small computer display. Detailed analyses of the reading process showed that participants performed both reading and page-turning simultaneously in the paper condition. However, when using computer displays, reading and turning pages were performed separately. In the second experiment, 12 participants read documents using electronic system with more effective features for page-turning such as an overview of pages and links from reference symbols to notes. However, paper remained the most efficient medium to support reading with endnotes. This indicates that electronic media should be improved to support between-page navigation.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {549–558},
numpages = {10},
keywords = {page turning, paper, electronic media, ergonomics, reading},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686701,
author = {Takano, Kentaro and Shibata, Hirohito and Ichino, Junko and Tomonori, Hashiyama and Tano, Shun'ichi},
title = {Microscopic Analysis of Document Handling While Reading Paper Documents to Improve Digital Reading Device},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686701},
doi = {10.1145/2686612.2686701},
abstract = {We conducted microscopic analysis on several frequently observed types of work-related reading to find ways to support each type of reading. We obtained empirical data from video recording, concurrent verbal reporting, and retrospective reporting by 18 participants in 10 target types of reading that use paper. Using these data, first, we categorized the ways people interact with paper documents when reading in detail. We analyzed which types of behaviors were frequently observed in each type of reading based on these categories. We will discuss what kind of support is required for each type of reading by specifying what types of behaviors were frequently observed for certain types of reading.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {559–567},
numpages = {9},
keywords = {work-related reading, paper},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

@inproceedings{10.1145/2686612.2686702,
author = {Lee, Seunghwan and Lee, Geehyuk},
title = {Design of Interaction Techniques for Clickable Touch Screens},
year = {2014},
isbn = {9781450306539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2686612.2686702},
doi = {10.1145/2686612.2686702},
abstract = {A clickable touch screen (CTS) offers an additional finger pressing state that allows users to feel a distinct click when they press the screen. CTS phones that exist in the market use this additional state only for a few safety features such as adding a preview step before committing to an action. A more systematic investigation of the possible interaction techniques using a CTS is needed to achieve a fuller utilization of this additional state. Accordingly, we conducted a brainstorming session to investigate the unexplored design space of CTS operations, and identified a set of CTS operations that make good use of this additional state. We then characterized the CTS operations using two kinds of notations that we developed to visualize both their temporal and spatial aspects, and named them based on their characteristics. Finally, we examined the feasibility of the CTS operations by implementing usage scenarios on a CTS phone and conducting user experiments.},
booktitle = {Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design},
pages = {568–577},
numpages = {10},
keywords = {clickable touch screen, design space, touch interface, interaction techniques},
location = {Sydney, New South Wales, Australia},
series = {OzCHI '14}
}

