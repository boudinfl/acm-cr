@inproceedings{10.1145/2988450.2991128,
author = {Dieleman, Sander},
title = {Keynote: Deep Learning for Audio-Based Music Recommendation},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2991128},
doi = {10.1145/2988450.2991128},
abstract = {The advent of deep learning has made it possible to extract high-level information from perceptual signals without having to specify manually and explicitly how to obtain it; instead, this can be learned from examples. This creates opportunities for automated content analysis of musical audio signals. In this talk, I will discuss how deep learning techniques can be used for audio-based music recommendation, with which we can tackle the item cold-start problem that burdens the prevailing collaborative filtering approaches.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {1},
numpages = {1},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988453,
author = {Zheng, Yin and Liu, Cailiang and Tang, Bangsheng and Zhou, Hanning},
title = {Neural Autoregressive Collaborative Filtering for Implicit Feedback},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988453},
doi = {10.1145/2988450.2988453},
abstract = {This paper proposes implicit CF-NADE, a neural autoregressive model for collaborative filtering tasks using implicit feedback( e.g. click/watch/browse behaviors). We first convert a user's implicit feedback into a "like" vector and a confidence vector, and then model the probability of the "like" vector, weighted by the confidence vector. The training objective of implicit CF-NADE is to maximize a weighted negative log-likelihood. We test the performance of implicit CF-NADE on a dataset collected from a popular digital TV streaming service. More specifically, in the experiments, we describe how to convert watch counts into implicit "relative rating", and feed into implicit CF-NADE. Then we compare the performance of implicit CF-NADE model with the popular implicit matrix factorization approach. Experimental results show that implicit CF-NADE significantly outperforms the baseline.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {2–6},
numpages = {5},
keywords = {implicit feedback, neural network, collaborative filtering, deep learning},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988454,
author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
title = {Wide &amp; Deep Learning for Recommender Systems},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988454},
doi = {10.1145/2988450.2988454},
abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide &amp; Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide &amp; Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {7–10},
numpages = {4},
keywords = {Recommender Systems, Wide &amp; Deep Learning},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988456,
author = {Strub, Florian and Gaudel, Romaric and Mary, J\'{e}r\'{e}mie},
title = {Hybrid Recommender System Based on Autoencoders},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988456},
doi = {10.1145/2988450.2988456},
abstract = {A standard model for Recommender Systems is the Matrix Completion setting: given partially known matrix of ratings given by users (rows) to items (columns), infer the unknown ratings. In the last decades, few attempts where done to handle that objective with Neural Networks, but recently an architecture based on Autoencoders proved to be a promising approach. In current paper, we enhanced that architecture (i) by using a loss function adapted to input data with missing values, and (ii) by incorporating side information. The experiments demonstrate that while side information only slightly improve the test error averaged on all users/items, it has more impact on cold users/items.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {11–16},
numpages = {6},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988452,
author = {Tan, Yong Kiam and Xu, Xinxing and Liu, Yong},
title = {Improved Recurrent Neural Networks for Session-Based Recommendations},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988452},
doi = {10.1145/2988450.2988452},
abstract = {Recurrent neural networks (RNNs) were recently proposed for the session-based recommendation task. The models showed promising improvements over traditional recommendation approaches. In this work, we further study RNN-based models for session-based recommendations. We propose the application of two techniques to improve model performance, namely, data augmentation, and a method to account for shifts in the input data distribution. We also empirically study the use of generalised distillation, and a novel alternative model that directly predicts item embeddings. Experiments on the RecSys Challenge 2015 dataset demonstrate relative improvements of 12.8% and 14.8% over previously reported results on the Recall@20 and Mean Reciprocal Rank@20 metrics respectively.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {17–22},
numpages = {6},
keywords = {Recommender systems, Session-based recommendations, Recurrent neural networks},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988457,
author = {Vuurens, Jeroen B. P. and Larson, Martha and de Vries, Arjen P.},
title = {Exploring Deep Space: Learning Personalized Ranking in a Semantic Space},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988457},
doi = {10.1145/2988450.2988457},
abstract = {Recommender systems leverage both content and user interactions to generate recommendations that fit users' preferences. The recent surge of interest in deep learning presents new opportunities for exploiting these two sources of information. To recommend items we propose to first learn a user-independent high-dimensional semantic space in which items are positioned according to their substitutability, and then learn a user-specific transformation function to transform this space into a ranking according to the user's past preferences. An advantage of the proposed architecture is that it can be used to effectively recommend items using either content that describes the items or user-item ratings. We show that this approach significantly outperforms state-of-the-art recommender systems on the MovieLens 1M dataset.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {23–28},
numpages = {6},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988451,
author = {Dai, Hanjun and Wang, Yichen and Trivedi, Rakshit and Song, Le},
title = {Recurrent Coevolutionary Latent Feature Processes for Continuous-Time Recommendation},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988451},
doi = {10.1145/2988450.2988451},
abstract = {Matching users to the right items at the right time is a fundamental task in recommender systems. As users interact with different items over time, users' and items' feature may drift, evolve and co-evolve over time. Traditional models based on static latent features or discretizing time into epochs can become ineffective for capturing the fine-grained temporal dynamics in the user-item interactions. We propose a coevolutionary latent feature process model that accurately captures the coevolving nature of users' and items' feature. We use a recurrent neural network to automatically learn a representation of influences from drift, evolution and co-evolution of user and item features. We develop an efficient stochastic gradient algorithm for learning the model parameters which can readily scale up to millions of events. Experiments on diverse real-world datasets demonstrate significant improvements in user behavior prediction compared to state-of-the-arts.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {29–34},
numpages = {6},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

@inproceedings{10.1145/2988450.2988455,
author = {Zanotti, Greg and Horvath, Miller and Barbosa, Lucas Nunes and Immedisetty, Venkata Trinadh Kumar Gupta and Gemmell, Jonathan},
title = {Infusing Collaborative Recommenders with Distributed Representations},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988455},
doi = {10.1145/2988450.2988455},
abstract = {Recommender systems assist users in navigating complex information spaces and focus their attention on the content most relevant to their needs. Often these systems rely on user activity or descriptions of the content. Social annotation systems, in which users collaboratively assign tags to items, provide another means to capture information about users and items. Each of these data sources provides unique benefits, capturing different relationships.In this paper, we propose leveraging multiple sources of data: ratings data as users report their affinity toward an item, tagging data as users assign annotations to items, and item data collected from an online database. Taken together, these datasets provide the opportunity to learn rich distributed representations by exploiting recent advances in neural network architectures. We first produce representations that subjectively capture interesting relationships among the data. We then empirically evaluate the utility of the representations to predict a user's rating on an item and show that it outperforms more traditional representations. Finally, we demonstrate that traditional representations can be combined with representations trained through a neural network to achieve even better results.},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {35–42},
numpages = {8},
keywords = {Collaborative filtering, neural networks, distributed representations, recommender systems},
location = {Boston, MA, USA},
series = {DLRS 2016}
}

