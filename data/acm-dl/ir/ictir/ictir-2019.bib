@inproceedings{10.1145/3341981.3344254,
author = {Gao, Jianfeng},
title = {Towards an Open-Doman Dialog System},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344254},
doi = {10.1145/3341981.3344254},
abstract = {Developing an intelligent dialogue system that not only emulates human conversation, but also can answer questions of topics ranging from latest news of a movie star to Einstein's theory of relativity, and fulfill complex tasks such as travel planning, has been one of the longest running goals in AI. In this talk, we use Microsoft XiaoIce [1] as a case study to discuss the state-of-the-art conversational AI [2], focusing on three types of dialogues: (1) question answering bots that can provide concise direct answers to user queries; (2) task-oriented bots that can help users accomplish tasks ranging from meeting scheduling to vacation planning; and (3) social bots which can converse seamlessly and appropriately with humans, and often plays roles of a chat companion and a recommender.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {1–2},
numpages = {2},
keywords = {task-oriented dialogue, social chatbot, question answering, dialogue, conversation},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344217,
author = {Purpura, Alberto and Maggipinto, Marco and Silvello, Gianmaria and Susto, Gian Antonio},
title = {Probabilistic Word Embeddings in Neural IR: A Promising Model That Does Not Work as Expected (For Now)},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344217},
doi = {10.1145/3341981.3344217},
abstract = {In this paper, we discuss how a promising word vector representation based on Probabilistic Word Embeddings (PWE) can be applied to Neural Information Retrieval (NeuIR). We illustrate PWE pros for text retrieval, and identify the core issues which prevent a full exploitation of their potential. In particular, we focus on the application of elliptical probabilistic embeddings, a type of PWE, to a NeuIR system (i.e., MatchPyramid). The main contributions of this paper are: (i) an analysis of the pros and cons of PWE in NeuIR; (ii) an in-depth comparison of PWE against pre-trained Word2Vec, FastText and WordNet word embeddings; (iii) an extension of the MatchPyramid model to take advantage of broader word relations information from WordNet; (iv) a topic-level evaluation of the MatchPyramid ranking models employing the considered word embeddings. Finally, we discuss some lessons learned and outline some open research problems to employ PWE in NeuIR systems more effectively.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {3–10},
numpages = {8},
keywords = {neural information retrieval, probabilistic word embedding, natural language processing},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344235,
author = {Mansouri, Behrooz and Rohatgi, Shaurya and Oard, Douglas W. and Wu, Jian and Giles, C. Lee and Zanibbi, Richard},
title = {Tangent-CFT: An Embedding Model for Mathematical Formulas},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344235},
doi = {10.1145/3341981.3344235},
abstract = {When searching for mathematical content, accurate measures of formula similarity can help with tasks such as document ranking, query recommendation, and result set clustering. While there have been many attempts at embedding words and graphs, formula embedding is in its early stages. We introduce a new formula embedding model that we use with two hierarchical representations, (1) Symbol Layout Trees (SLTs) for appearance, and (2) Operator Trees (OPTs) for mathematical content. Following the approach of graph embeddings such as DeepWalk, we generate tuples representing paths between pairs of symbols depth-first, embed tuples using the fastText n-gram embedding model, and then represent an SLT or OPT by its average tuple embedding vector. We then combine SLT and OPT embeddings, leading to state-of-the-art results for the NTCIR-12 formula retrieval task. Our fine-grained holistic vector representations allow us to retrieve many more partially similar formulas than methods using structural matching in trees. Combining our embedding model with structural matching in the Approach0 formula search engine produces state-of-the-art results for both fully and partially relevant results on the NTCIR-12 benchmark. Source code for our system is publicly available.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {11–18},
numpages = {8},
keywords = {tree embeddings, math formula retrieval, formula embeddings},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344220,
author = {Cohen, Daniel and Jordan, Scott M. and Croft, W. Bruce},
title = {Learning a Better Negative Sampling Policy with Deep Neural Networks for Search},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344220},
doi = {10.1145/3341981.3344220},
abstract = {In information retrieval, sampling methods used to select documents for neural models must often deal with large class imbalances during training. This issue necessitates careful selection of negative instances when training neural models to avoid the risk of overfitting. For most work, heuristic sampling approaches, or policies, are created based off of domain experts, such as choosing samples with high BM25 scores or a random process over candidate documents. However, these sampling approaches are done with the test distribution in mind. In this paper, we demonstrate that the method chosen to sample negative documents during training plays a critical role in both the stability of training, as well as overall performance. Furthermore, we establish that using reinforcement learning to optimize a policy over a set of sampling functions can significantly improve performance over standard training practices with respect to IR metrics and is robust to hyperparameters and random seeds.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {19–26},
numpages = {8},
keywords = {reinforcement learning, information retrieval, meta-learning, negative sampling},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344224,
author = {Lu, Xiaolu and Kurland, Oren and Culpepper, J. Shane and Craswell, Nick and Rom, Ofri},
title = {Relevance Modeling with Multiple Query Variations},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344224},
doi = {10.1145/3341981.3344224},
abstract = {The generative theory for relevance and its operational manifestation --- the relevance model --- are based on the premise that a single query is used to represent an information need for retrieval. In this work, we extend the theory and devise novel techniques for relevance modeling using as set of query variations representing the same information need. Our new approach is based on fusion at the term level, the model level, or the document-list level. We theoretically analyze the connections between these methods and provide empirical support of their equivalence using TREC datasets. Specifically, our new approach of inducing relevance models from multiple query variations substantially outperforms relevance model induction from a single query which is the standard practice. Our approach also outperforms fusion over multiple query variations, which is currently one of the best known baselines for several commonly used test collections.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {27–34},
numpages = {8},
keywords = {fusion, relevance modelling, query formulation},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344233,
author = {Uprety, Sagar and Dehdashti, Shahram and Fell, Lauren and Bruza, Peter and Song, Dawei},
title = {Modelling Dynamic Interactions Between Relevance Dimensions},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344233},
doi = {10.1145/3341981.3344233},
abstract = {Relevance is an underlying concept in the field of Information Science and Retrieval. It is a cognitive notion consisting of several different criteria or dimensions. Theoretical models of relevance allude to interdependence between these dimensions, where their interaction and fusion leads to the final inference of relevance. We study the interaction between the relevance dimensions using the mathematical framework of Quantum Theory. It is considered a generalised framework to model decision making under uncertainty, involving multiple perspectives and influenced by context. Specifically, we conduct a user study by constructing the cognitive analogue of a famous experiment in Quantum Physics. The data is used to construct a complex-valued vector space model of the user's cognitive state, which is used to explain incompatibility and interference between relevance dimensions. The implications of our findings to inform the design of Information Retrieval systems are also discussed.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {35–42},
numpages = {8},
keywords = {quantum cognition, multidimensional relevance, user behaviour modelling},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344219,
author = {Roitman, Haggai and Erera, Shai and Feigenblat, Guy},
title = {A Study of Query Performance Prediction for Answer Quality Determination},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344219},
doi = {10.1145/3341981.3344219},
abstract = {We study a constrained retrieval setting in which either a single qualitative answer is provided as a response to a user-query or none. Given a user-query and the "best" answer that was retrieved from the underlying search engine, we wish to determine whether or not to accept it. To address this challenge, we propose an answer quality determination approach which leverages a novel set of answer-level query performance prediction (QPP) features, derived from a couple of recent discriminative QPP frameworks. Using various search benchmarks with both ad-hoc retrieval and non-factoid question answering (QA) tasks, we demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {43–46},
numpages = {4},
keywords = {classification, query performance prediction, answer quality determination},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344223,
author = {Liu, Binsheng and Craswell, Nick and Lu, Xiaolu and Kurland, Oren and Culpepper, J. Shane},
title = {A Comparative Analysis of Human and Automatic Query Variants},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344223},
doi = {10.1145/3341981.3344223},
abstract = {We present an in-depth comparative analysis of the effectiveness distributions of sets of human-created and automatically-created query variations used to represent the same information need. The automatic variations are generated using Bing's click graph. Experiments performed with TREC datasets show that using automatic variations for retrieval can result in similar effectiveness to that of using human variations, although the two types of variations can be appreciably different in several important respects --- e.g., their similarities and corresponding retrieved lists.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {47–50},
numpages = {4},
keywords = {web search, user query formulation},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344251,
author = {Bonab, Hamed and Aliannejadi, Mohammad and Foley, John and Allan, James},
title = {Incorporating Hierarchical Domain Information to Disambiguate Very Short Queries},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344251},
doi = {10.1145/3341981.3344251},
abstract = {Users often express their information needs using incomplete or ambiguous queries of only one or two terms in length, particularly in the Web environments. The ambiguity of short queries is a recognized problem for information retrieval (IR) systems. In this study, we investigate various approaches for incorporating hierarchical domain information into IR models such that the domain specification resolves the ambiguity. To this end, we develop practical models for constructing evaluation datasets from existing corpora. In terms of effectiveness, we further study the trade-off between a short query and its domain specification information. In doing so, we find that domains with the highest number of relevant documents are not always the best ones to select. We also evaluate the utility of a domain hierarchy and find that incorporating the hierarchical structure of a collection into the retrieval model could have a high impact on short query disambiguation.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {51–54},
numpages = {4},
keywords = {query disambiguation, hierarchical retrieval, hierarchical domain, very short query},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344249,
author = {Hashemi, Helia and Zamani, Hamed and Croft, W. Bruce},
title = {Performance Prediction for Non-Factoid Question Answering},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344249},
doi = {10.1145/3341981.3344249},
abstract = {Estimating the quality of a result list, often referred to as query performance prediction (QPP), is a challenging and important task in information retrieval. It can be used as feedback to users, search engines, and system administrators. Although predicting the performance of retrieval models has been extensively studied for the ad-hoc retrieval task, the effectiveness of performance prediction methods for question answering (QA) systems is relatively unstudied. The short length of answers, the dominance of neural models in QA, and the re-ranking nature of most QA systems make performance prediction for QA a unique, important, and technically interesting task. In this paper, we introduce and motivate the task of performance prediction for non-factoid question answering and propose a neural performance predictor for this task. Our experiments on two recent datasets demonstrate that the proposed model outperforms competitive baselines in all settings.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {55–58},
numpages = {4},
keywords = {query performance prediction, non-factoid questions, neural qpp, question answering},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344212,
author = {Roitman, Haggai and Mass, Yosi},
title = {Utilizing Passages in Fusion-Based Document Retrieval},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344212},
doi = {10.1145/3341981.3344212},
abstract = {The usage of passage-level information has been successfully demonstrated in many core IR tasks, and among such tasks, the task of passage-based document retrieval. In this work, we study the merits of utilizing similar information for the fusion-based document retrieval task. Overall, we show that such information can be highly useful for this task as well. To this end, we propose three passage-based fusion methods and show that their performance can transcend that of strong document-level fusion methods.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {59–66},
numpages = {8},
keywords = {framework, fusion-based document retrieval, passage-based document retrieval},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344232,
author = {Nie, Yifan and Zhang, Jiyang and Nie, Jian-Yun},
title = {Integrated Learning of Features and Ranking Function in Information Retrieval},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344232},
doi = {10.1145/3341981.3344232},
abstract = {Recent deep learning models for information retrieval typically aim to learn features either about the contents of the document and the query, or about the interactions between them. However, the existing literature shows that document ranking depends simultaneously on many factors, including both content and interaction features. The integration of both types of neural features has not been extensively studied. In addition, many studies have also shown that the deep neural features cannot replace completely the traditional features, but are complementary. It is thus reasonable to combine deep neural features with traditional features. In this paper, we propose an integrated end-to-end learning framework based on learning-to-rank (L2R) to learn both neural features and the L2R ranking function simultaneously. The framework also has the flexibility to integrate arbitrary traditional features. Our experiments on public datasets confirm that such an integrated learning strategy is better than separate learning of features and ranking function, and integrating traditional features can further improve the results.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {67–74},
numpages = {8},
keywords = {information retrieval, neural network, ranking},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344221,
author = {Bruch, Sebastian and Wang, Xuanhui and Bendersky, Michael and Najork, Marc},
title = {An Analysis of the Softmax Cross Entropy Loss for Learning-to-Rank with Binary Relevance},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344221},
doi = {10.1145/3341981.3344221},
abstract = {One of the challenges of learning-to-rank for information retrieval is that ranking metrics are not smooth and as such cannot be optimized directly with gradient descent optimization methods. This gap has given rise to a large body of research that reformulates the problem to fit into existing machine learning frameworks or defines a surrogate, ranking-appropriate loss function. One such loss is ListNet's which measures the cross entropy between a distribution over documents obtained from scores and another from ground-truth labels. This loss was designed to capture permutation probabilities and as such is considered to be only loosely related to ranking metrics. In this work, however, we show that the above statement is not entirely accurate. In fact, we establish an analytical connection between ListNet's loss and two popular ranking metrics in a learning-to-rank setup with binary relevance labels. In particular, we show that the loss bounds Mean Reciprocal Rank and Normalized Discounted Cumulative Gain. Our analysis sheds light on ListNet's behavior and explains its superior performance on binary labeled data over data with graded relevance.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {75–78},
numpages = {4},
keywords = {learning to rank with binary relevance, learning to rank loss functions, softmax cross entropy ranking loss},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344234,
author = {Lien, Yen-Chieh and Cohen, Daniel and Croft, W. Bruce},
title = {An Assumption-Free Approach to the Dynamic Truncation of Ranked Lists},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344234},
doi = {10.1145/3341981.3344234},
abstract = {In traditional retrieval environments, a ranked list of candidate documents is produced without regard to the number of documents. With the rise in interactive IR as well as professional searches such as legal retrieval, this results in a substantial ranked list which is scanned by a user until their information need is satisfied. Determining the point at which the ranking model has low confidence in the relevance score is a challenging, but potentially very useful, task. Truncation of the ranked list must balance the needs of the user with the confidence of the retrieval model. Unlike query performance prediction where the task is to estimate the performance of a model based on an initial query and a given set documents, dynamic truncation minimizes the risk of viewing a non-relevant document given an external metric by estimating the confidence of the retrieval model using a distribution over its already calculated output scores, and subsequently truncating the ranking at that position. In this paper, we propose an assumption-free approach to learning a non-parametric score distribution over any retrieval model and demonstrate the efficacy of our method on Robust04, significantly improving user defined metrics compared to previous approaches.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {79–82},
numpages = {4},
keywords = {ranked list truncation, assumption-free method, custom loss function},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3343870,
author = {Kelly, Diane},
title = {What Do We Mean by Theory in Information Retrieval?},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3343870},
doi = {10.1145/3341981.3343870},
abstract = {Theory comes in many forms. In some fields, mathematical statements are used to communicate theory, while in others, verbal statements are used. Some fields rely heavily on models, such as physical, mechanical or stochastic, while other fields rely on simulation. As an area of study, information retrieval (IR) addresses topics and problems that can be informed by a wide-variety of theories and models, including those used to describe the actions of machines, as well as those used to explain the behaviors of humans and systems. While theoretical research is often presented as being at odds with empirical research, in reality, they cannot be separated. In this talk, I will review several theories and models that have guided select IR research, and discuss the ways researchers have exercised, explored and tested theories. I will also discuss the role of theories in IR research, and present criteria that can be used to reason about whether an IR theory is useful. I will argue that we should demand more theory from IR research. In particular, while the absence of theory does not prevent us from doing research, it does restrict our findings to a narrow slice of time.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {83},
numpages = {1},
keywords = {research practice, theory, information retrieval, empiricism},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344218,
author = {Ai, Qingyao and Wang, Xuanhui and Bruch, Sebastian and Golbandi, Nadav and Bendersky, Michael and Najork, Marc},
title = {Learning Groupwise Multivariate Scoring Functions Using Deep Neural Networks},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344218},
doi = {10.1145/3341981.3344218},
abstract = {While in a classification or a regression setting a label or a value is assigned to each individual document, in a ranking setting we determine the relevance ordering of the entire input document list. This difference leads to the notion of relative relevance between documents in ranking. The majority of the existing learning-to-rank algorithms model such relativity at the loss level using pairwise or listwise loss functions. However, they are restricted to univariate scoring functions, i.e., the relevance score of a document is computed based on the document itself, regardless of other documents in the list. To overcome this limitation, we propose a new framework for multivariate scoring functions, in which the relevance score of a document is determined jointly by multiple documents in the list. We refer to this framework as GSFs---groupwise scoring functions. We learn GSFs with a deep neural network architecture, and demonstrate that several representative learning-to-rank algorithms can be modeled as special cases in our framework. We conduct evaluation using click logs from one of the largest commercial email search engines, as well as a public benchmark dataset. In both cases, GSFs lead to significant performance improvements, especially in the presence of sparse textual features.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {85–92},
numpages = {8},
keywords = {groupwise scoring functions, deep neural architectures for ir, multivariate scoring},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344227,
author = {Wang, Bingning and Yao, Ting and Zhang, Qi and Xu, Jingfang and Liu, Kang and Tian, Zhixing and Zhao, Jun},
title = {Unsupervised Story Comprehension with Hierarchical Encoder-Decoder},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344227},
doi = {10.1145/3341981.3344227},
abstract = {Commonsense understanding is a long-term goal of natural language processing yet to be resolved. One standard testbed for commonsense understanding isStory Cloze Test (SCT) citemostafazadeh2016corpus, In SCT, given a 4-sentences story, we are expected to select the proper ending out of two proposed candidates. The training set in SCT only contains unlabeled stories, previous works usually adopt the small labeled development data for training, which ignored the sufficient training data and, essentially, not reveal the commonsense reasoning procedure. In this paper, we propose an unsupervised sequence-to-sequence method for story reading comprehension, we only adopt the unlabeled story and directly model the context-target inference probability. We propose a loss-reweight training strategy for the seq-to-seq model to dynamically tuning the training process. Experimental results demonstrate the advantage of the proposed model and it achieves the comparable results with supervised methods on SCT.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {93–100},
numpages = {8},
keywords = {unsupervised learning, machine comprehension},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344245,
author = {Rahimi, Razieh and Montazeralghaem, Ali and Allan, James},
title = {Listwise Neural Ranking Models},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344245},
doi = {10.1145/3341981.3344245},
abstract = {Several neural networks have been developed for end-to-end training of information retrieval models. These networks differ in many aspects including architecture, training data, data representations, and loss functions. However, only pointwise and pairwise loss functions are employed in training of end-to-end neural ranking models without human-engineered features. These loss functions do not consider the ranks of documents in the estimation of loss over training data. Because of this limitation, conventional learning-to-rank models using pointwise or pairwise loss functions have generally shown lower performance compared to those using listwise loss functions. Following this observation, we propose to employ listwise loss functions for the training of neural ranking models. We empirically demonstrate that a listwise neural ranker outperforms a pairwise neural ranking model. In addition, we achieve further improvements in the performance of the listwise neural ranking models by query-based sampling of training data.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {101–104},
numpages = {4},
keywords = {document ranking, neural network, query-based sampling, listwise loss},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344213,
author = {Yin, Yue and Xiong, Chenyan and Luo, Cheng and Liu, Zhiyuan},
title = {Neural Document Expansion with User Feedback},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344213},
doi = {10.1145/3341981.3344213},
abstract = {This paper presents a neural document expansion approach (NeuDEF) that enriches document representations for neural ranking models. NeuDEF harvests expansion terms from queries which lead to clicks on the document and weights these expansion terms with learned attention. It is plugged into a standard neural ranker and learned end-to-end. Experiments on a commercial search log demonstrate that NeuDEF significantly improves the accuracy of state-of-the-art neural rankers and expansion methods on queries with different frequencies. Further studies show the contribution of click queries and learned expansion weights, as well as the influence of document popularity of NeuDEF's effectiveness.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {105–108},
numpages = {4},
keywords = {neural information retrieval, document expansion, user feedback},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344216,
author = {Lipani, Aldo and Carterette, Ben and Yilmaz, Emine},
title = {From a User Model for Query Sessions to Session Rank Biased Precision (SRBP)},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344216},
doi = {10.1145/3341981.3344216},
abstract = {To satisfy their information needs, users usually carry out searches on retrieval systems by continuously trading off between the examination of search results retrieved by under-specified queries and the refinement of these queries through reformulation. In Information Retrieval (IR), a series of query reformulations is known as a query-session. Research in IR evaluation has traditionally been focused on the development of measures for the ad hoc task, for which a retrieval system aims to retrieve the best documents for a single query. Thus, most IR evaluation measures, with a few exceptions, are not suitable to evaluate retrieval scenarios that call for multiple refinements over a query-session. In this paper, by formally modeling a user's expected behaviour over query-sessions, we derive a session-based evaluation measure, which results in a generalization of the evaluation measure Rank Biased Precision (RBP). We demonstrate the quality of this new session-based evaluation measure, named Session RBP (sRBP), by evaluating its user model against the observed user behaviour over the query-sessions of the 2014 TREC Session track.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {109–116},
numpages = {8},
keywords = {session search, retrieval evaluation, user model, srbp},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344226,
author = {Urgo, Kelsey and Arguello, Jaime and Capra, Robert},
title = {Anderson and Krathwohl's Two-Dimensional Taxonomy Applied to Task Creation and Learning Assessment},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344226},
doi = {10.1145/3341981.3344226},
abstract = {Search tasks play an important role in the study and development of interactive information retrieval (IIR) systems. Prior work has examined how search tasks vary along dimensions such as the task's main activity, end goal, structure, and complexity. Recently, researchers have been exploring task complexity from the perspective of cognitive complexity---related to the types (and variety) of mental activities required by the task. Anderson &amp; Krathwohl's two-dimensional taxonomy of learning has been a commonly used framework for investigating tasks from the perspective of cognitive complexity. A&amp;K's 2D taxonomy involves a cognitive process dimension and an orthogonal knowledge dimension. Prior IIR research has successfully leveraged the cognitive process dimension of this 2D taxonomy to develop search tasks and investigate their effects on searchers' needs, perceptions, and behaviors. However, the knowledge dimension of the taxonomy has been largely ignored. In this conceptual paper, we argue that future IIR research should consider both dimensions of A&amp;K's taxonomy. Specifically, we discuss related work, present details on both dimensions of A&amp;K's taxonomy, and explain how to use the taxonomy to develop search tasks and learning assessment materials. Additionally, we discuss how considering both dimensions of A&amp;K's taxonomy has important implications for future IIR research.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {117–124},
numpages = {8},
keywords = {search learning scenarios, search as learning, search tasks, task complexity, learning assessment},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344242,
author = {Mao, Jiaxin and Chu, Zhumin and Liu, Yiqun and Zhang, Min and Ma, Shaoping},
title = {Investigating the Reliability of Click Models},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344242},
doi = {10.1145/3341981.3344242},
abstract = {Click models aim to extract accurate relevance feedback from the noisy and biased user clicks. Previous work focuses on reducing the systematic bias between click and relevance but few studies have examined the reliability and precision of click models' relevance estimation. So in this study, we propose to investigate the reliability of relevance estimation derived by click models. Instead of getting a point estimate of relevance, a variational Bayesian method is used to infer the posterior distribution of relevance parameters. Based on the posterior distribution, we define measures for the reliability of pointwise and pairwise relevance estimation. With experiments on both real and synthetic query logs, we show that: 1) the proposed method effectively captures the uncertainty in relevance estimation; 2) the reliability of click models' relevance estimation is affected by the size of training data, the average ranking position of documents, and the ranking strategy of search engines.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {125–128},
numpages = {4},
keywords = {web search, bayesian analysis, click model},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344236,
author = {Bonab, Hamed and Allan, James and Sitaraman, Ramesh},
title = {Simulating CLIR Translation Resource Scarcity Using High-Resource Languages},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344236},
doi = {10.1145/3341981.3344236},
abstract = {We study the impact of translation resource scarcity on the performance of cross-language information retrieval (CLIR) systems. To do that, we develop a contrastive analysis framework that uses high-resource languages to simulate low-resource languages. In the framework, we focus on parallel translation corpora and aim to better understand the factors that impact CLIR performance. We argue that both low- and high-resource corpora are needed to develop that understanding. Hence, we take the approach of starting with a true low-resource language and systematically down-sampling a high-resource language to become an artificial low-resource language-the reverse perspective of existing research. We formalize the problem as the Resource Scarcity Simulation (RSS) problem. We model the problem with a family of set covering problems, formulate with integer linear programming, and prove that the problem is actually NP-hard. To this end, we provide two greedy algorithms with polynomial complexities. We compare and analyze our approach with alternate techniques using four high-resource languages (French, Italian, German, and Finnish) down-sampled to simulate two low-resource languages (Somali and Swahili). Our experimental results suggest that language families are important for the RSS problem. We simulate Somali with German, and Swahili with Finnish, achieving 98% and 97% on the similarity percentage in terms of CLIR performance, respectively.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {129–136},
numpages = {8},
keywords = {translation resources, cross-lingual information retrieval, low-resource languages, language simulation},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344252,
author = {Montazeralghaem, Ali and Rahimi, Razieh and Allan, James},
title = {Term Discrimination Value for Cross-Language Information Retrieval},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344252},
doi = {10.1145/3341981.3344252},
abstract = {Term discrimination value is among the three basic heuristics exploited, directly or indirectly, in almost all ranking models for ad-hoc Information Retrieval (IR). Query term discrimination in monolingual IR is usually estimated based on document or collection frequency of terms. In the query translation approach for CLIR, the discrimination value of a query term needs to be estimated based on document or collection frequencies of its translations, which is more challenging. We show that the existing estimation models do not correctly estimate and adequately reflect the difference between the discrimination power of query terms, which hurts retrieval performance. We then propose a new model to estimate discrimination values of query terms for CLIR and empirically demonstrate its impact in improving the CLIR performance.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {137–140},
numpages = {4},
keywords = {cross-language information retrieval, term discrimination value, probabilistic structured query},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344239,
author = {Eickhoff, Carsten and Gmehlin, Floran and Patel, Anu V. and Boullier, Jocelyn and Fraser, Hamish},
title = {DC3 -- A Diagnostic Case Challenge Collection for Clinical Decision Support},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344239},
doi = {10.1145/3341981.3344239},
abstract = {In clinical care, obtaining a correct diagnosis is the first step towards successful treatment and, ultimately, recovery. Depending on the complexity of the case, the diagnostic phase can be lengthy and ridden with errors and delays. Such errors have a high likelihood to cause patients severe harm or even lead to their death and are estimated to cost the U.S. healthcare system several hundred billion dollars each year.To avoid diagnostic errors, physicians increasingly rely on diagnostic decision support systems drawing from heuristics, historic cases, textbooks, clinical guidelines and scholarly biomedical literature. The evaluation of such systems, however, is often conducted in an ad-hoc fashion, using non-transparent methodology, and proprietary data.This paper presents DC3, a collection of 31 extremely difficult diagnostic case challenges, manually compiled and solved by clinical experts. For each case, we present a number of temporally ordered physician-generated observations alongside the eventually confirmed true diagnosis. We additionally provide inferred dense relevance judgments for these cases among the PubMed collection of 27 million scholarly biomedical articles.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {141–144},
numpages = {4},
keywords = {diagnostics, dataset, corpus, rare diseases},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344238,
author = {von Werra, Leandro and Sch\"{o}ngens, Marcel and Gamsiz Uzun, Ece D. and Eickhoff, Carsten},
title = {Generative Adversarial Networks in Precision Oncology},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344238},
doi = {10.1145/3341981.3344238},
abstract = {Precision medicine strives to deliver improved care based on genetic patient information. Towards this end, it is crucial to find effective data representations on which to perform matching and inference operations. We develop and evaluate a generative adversarial neural network (GAN) approach to representation learning with the goal of patient-centric literature retrieval and treatment recommendation in precision oncology. Several large-scale corpora including the COSMIC Cancer Gene Census, COSMIC Mutation Data, Genomic Data Commons (GDC) and 26M MEDLINE abstracts are used to train GANs for synthesizing genetic mutation patterns that likely correspond to patient properties such as their demographics or cancer type. The introduction of GANs into the literature retrieval and treatment recommendation process results in significant improvements in performance by increasing the recall of a range of methods at stable precision. Finally, we propose a method to discover novel gene-gene interaction hypotheses to guide future research.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {145–148},
numpages = {4},
keywords = {deep learning, gan, oncology, precision medicine},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344225,
author = {Jadidinejad, Amir H. and Macdonald, Craig and Ounis, Iadh},
title = {Unifying Explicit and Implicit Feedback for Rating Prediction and Ranking Recommendation Tasks},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344225},
doi = {10.1145/3341981.3344225},
abstract = {The two main tasks addressed by collaborative filtering approaches are rating prediction and ranking. Rating prediction models leverage explicit feedback (e.g. ratings), and aim to estimate the rating a user would assign to an unseen item. In contrast, ranking models leverage implicit feedback (e.g. clicks) in order to provide the user with a personalized ranked list of recommended items. Several previous approaches have been proposed that learn from both explicit and implicit feedback to optimize the task of ranking or rating prediction at the level of recommendation algorithm. Yet we argue that these two tasks are not completely separate, but are part of a unified process: a user first interacts with a set of items and then might decide to provide explicit feedback on a subset of items. We propose to bridge the gap between the tasks of rating prediction and ranking through the use of a novel weak supervision approach that unifies both explicit and implicit feedback datasets. The key aspects of the proposed model is that (1) it is applied at the level of data pre-processing and (2) it increases the representation of less popular items in recommendations while maintaining reasonable recommendation performance. Our experimental results - on six datasets covering different types of heterogeneous user's interactions and using a wide range of evaluation metrics - show that, our proposed approach can effectively combine explicit and implicit feedback and improve the effectiveness of the baseline explicit model on the ranking task by covering a broader range of long-tail items.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {149–156},
numpages = {8},
keywords = {weak supervision, rating prediction, ranking, collaborative filtering, matrix factorization, recommendation systems, popularity bias},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344230,
author = {Chakraborty, Anirban and Ganguly, Debasis and Caputo, Annalina and Lawless, S\'{e}amus},
title = {A Factored Relevance Model for Contextual Point-of-Interest Recommendation},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344230},
doi = {10.1145/3341981.3344230},
abstract = {The challenge of providing personalized and contextually appropriate recommendations to a user is faced in a range of use-cases, e.g., recommendations for movies, places to visit, articles to read etc. In this paper, we focus on one such application, namely that of suggesting 'points of interest' (POIs) to a user given her current location, by leveraging relevant information from her past preferences. An automated contextual recommendation algorithm is likely to work well if it can extract information from the preference history of a user (exploitation) and effectively combine it with information from the user's current context (exploration) to predict an item's 'usefulness' in the new context. To balance this trade-off between exploration and exploitation, we propose a generic unsupervised framework involving a factored relevance model (FRLM), comprising two distinct components, one corresponding to the historical information from past contexts, and the other pertaining to the information from the local context. Our experiments are conducted on the TREC contextual suggestion (TREC-CS) 2016 dataset. The results of our experiments demonstrate the effectiveness of our proposed approach in comparison to a number of standard IR and recommender-based baselines.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {157–164},
numpages = {8},
keywords = {relevance model, contextual recommendation, user model},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344214,
author = {Rafailidis, Dimitrios and Crestani, Fabio},
title = {Neural Attentive Cross-Domain Recommendation},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344214},
doi = {10.1145/3341981.3344214},
abstract = {Nowadays, users open multiple accounts on social media platforms and e-commerce sites, expressing their personal preferences on different domains. However, users' behaviors change across domains, depending on the content that users interact with, such as movies, music, clothing and retail products. The main challenge is how to capture users' complex preferences when generating cross-domain recommendations, that is exploiting users' preferences from source domains to generate recommendations in a target domain. In this study, we propose a Neural Attentive Cross-domain model, namely NAC. We design a neural architecture, to carefully transfer the knowledge of user preferences across domains by taking into account the cross-domain latent effects of multiple source domains on users' selections in a target domain. In addition, we introduce a cross-domain behavioral attention mechanism to adaptively perform the weighting of users' preferences from the source domains, and consequently generate accurate cross-domain recommendations. Our experiments on ten cross-domain recommendation tasks show that the proposed NAC model achieves higher recommendation accuracy than other state-of-the-art methods for both ordinary and cold-start users. Furthermore, we study the effect of the proposed cross-domain behavioral attention mechanism and show that it is a key factor to our model's performance.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {165–172},
numpages = {8},
keywords = {cross-domain recommendation, recommendation systems, neural attentive models},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344240,
author = {Rahmani, Hossein A. and Aliannejadi, Mohammad and Mirzaei Zadeh, Rasoul and Baratchi, Mitra and Afsharchi, Mohsen and Crestani, Fabio},
title = {Category-Aware Location Embedding for Point-of-Interest Recommendation},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344240},
doi = {10.1145/3341981.3344240},
abstract = {Recently, Point of interest (POI) recommendation has gained ever-increasing importance in various Location-Based Social Networks (LBSNs). With the recent advances of neural models, much work has sought to leverage neural networks to learn neural embeddings in a pre-training phase that achieve an improved representation of POIs and consequently a better recommendation. However, previous studies fail to capture crucial information about POIs such as categorical information.In this paper, we propose a novel neural model that generates a POI embedding incorporating sequential and categorical information from POIs. Our model consists of a check-in module and a category module. The check-in module captures the geographical influence of POIs derived from the sequence of users' check-ins, while the category module captures the characteristics of POIs derived from the category information. To validate the efficacy of the model, we experimented with two large-scale LBSN datasets. Our experimental results demonstrate that our approach significantly outperforms state-of-the-art POI recommendation methods.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {173–176},
numpages = {4},
keywords = {location-based social networks, poi embedding, point-of-interest, recommender systems},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344222,
author = {Arguello, Jaime and Crescenzi, Anita},
title = {Using Principal Component Analysis to Better Understand Behavioral Measures and Their Effects},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344222},
doi = {10.1145/3341981.3344222},
abstract = {An important question in interactive IR research is: What do search behaviors tell us about specific task characteristics, post-task perceptions, and post-task outcomes such as knowledge gains? Much research has explored this question from different perspectives. A common approach is to consider a wide range of behavioral measures and examine their differences based on dependent variables of interest (e.g., post-task perceptions). In this paper, we use principal component analysis (PCA), a dimensionality reduction technique, to analyze behavioral measures captured during three previously published studies. Using PCA, we examine the underlying phenomena being captured by different behavioral measures, and we examine the influence of these phenomena on different outcomes related to participants' post-task perceptions (e.g., workload, difficulty, engagement, etc.). We argue (and show) that PCA can provide several benefits. First, it can help us understand the behavioral phenomena captured by different measures. Second, it can help us determine which measures are ambiguous or unambiguous with respect to the underlying phenomena being captured. Third, it can help us understand how behavioral phenomena (vs. individual measures) relate to searchers' perceptions of their search experience.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {177–184},
numpages = {8},
keywords = {search behavior, search experience, user study, principal component analysis},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344231,
author = {Niu, Xi and Fan, Xiangyu},
title = {Deep Learning of Human Information Foraging Behavior with a Search Engine},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344231},
doi = {10.1145/3341981.3344231},
abstract = {In this paper, a two-level deep learning framework is presented to model human information foraging behavior with search engines. A recurrent neural network architecture is designed using LSTM as the base unit to explicitly consider the temporal and spatial dependencies of information scents, the key concept in Information Foraging Theory. The target is to predict several major search behaviors, such as query abandonment, query reformulation, number of clicks, and information gain. The memory capability and the sequence structure of LSTM allow to naturally mimic not only what users are perceiving and performing at the moment but also what they have seen and learned from the past during the search dynamics. The promising results indicate that our information scent models with different input variations were better, compared to the state-of-the art neural click models, at predicting some search behaviors. When incorporating the knowledge from a previous query in the same search session, the prediction of current query abandonment, pagination, and information gain has been improved. Compared to the well known neural click models that model search behaviors under a single search query thread, this study takes a broader view to consider an entire search session which may contain multiple queries. More importantly, our model takes the search result relevance pattern on the Search Engine Results Pages (SERP) as a whole as the information scent input to the deep learning model, instead of considering one search result at each step. The results have insights on the impact of information scents on how people forage for information, which has implications for designing or refining a set of design guidelines for search engines.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {185–192},
numpages = {8},
keywords = {information scent, deep learning, online search behavior, information foraging theory},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344246,
author = {Togashi, Riku and Sakai, Tetsuya},
title = {Generalising Kendall's Tau for Noisy and Incomplete Preference Judgements},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344246},
doi = {10.1145/3341981.3344246},
abstract = {We propose a new ranking evaluation measure for situations where multiple preference judgements are given for each item pair but they may be noisy (i.e., some judgements are unreliable) and/or incomplete (i.e., some judgements are missing). While it is generally easier for assessors to conduct preference judgements than absolute judgements, it is often not practical to obtain preference judgements for all combinations of documents. However, this problem can be overcome if we can effectively utilise noisy and incomplete preference judgements such as those that can be obtained from crowdsourcing. Our measure, η, is based on a simple probabilistic user model of the labellers which assumes that each document is associated with a graded relevance score for a given query. We also consider situations where multiple preference probabilities, rather than preference labels, are given for each document pair. For example, in the absence of manual preference judgements, one might want to employ an ensemble of machine learning techniques to obtain such estimated probabilities. For this scenario, we propose another ranking evaluation measure called η_p $. Through simulated experiments, we demonstrate that our proposed measures η and η_p$ can evaluate rankings more reliably than τmbox- b$, a popular rank correlation measure.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {193–196},
numpages = {4},
keywords = {graded relevance, evaluation measures, crowdsourcing, preference judgements},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344229,
author = {Mishra, Rahul and Setty, Vinay},
title = {SADHAN: Hierarchical Attention Networks to Learn Latent Aspect Embeddings for Fake News Detection},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344229},
doi = {10.1145/3341981.3344229},
abstract = {Recently false claims and misinformation have become rampant in the web, affecting election outcomes, societies and economies. Consequently, fact checking websites such as snopes.com and politifact.com are becoming popular. However, these websites require expert analysis which is slow and not scalable. Many recent works try to solve these challenges using machine learning models trained on a variety of features and a rich lexicon or more recently, deep neural networks to avoid feature engineering. In this paper, we propose hierarchical deep attention networks to learn embeddings for various latent aspects of news. Contrary to existing solutions which only apply word-level self-attention, our model jointly learns the latent aspect embeddings for classifying false claims by applying hierarchical attention. Using several manually annotated high quality datasets such as Politifact, Snopes and Fever we show that these learned aspect embeddings are strong predictors of false claims. We show that latent aspect embeddings learned from attention mechanisms improve the accuracy of false claim detection by up to 13.5% in terms of Macro F1 compared to a state-of-the-art attention mechanism guided by claim-text DeClarE. We also extract and visualize the evidence from the external articles which supports or disproves the claims},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {197–204},
numpages = {8},
keywords = {latent aspect embeddings, fake news detection, hierarchical attention},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344253,
author = {Mele, Ida and Crestani, Fabio},
title = {A Multi-Source Collection of Event-Labeled News Documents},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344253},
doi = {10.1145/3341981.3344253},
abstract = {In this paper, we present a collection of news documents labeled at the level of crisp events. Compared to other publicly-available collections, our dataset is made of heterogeneous documents published by popular news channels on different platforms in the same temporal window and, therefore, dealing with roughly the same events and topics.The collection spans 4 months and comprises 147K news documents from 27 news streams, i.e., 9 different channels and 3 platforms: Twitter, RSS portals, and news websites. We also provide relevance labels of news documents for some selected events. These relevance judgments were collected using crowdsourcing. The collection can be useful to researchers investigating challenging news-mining tasks, such as event detection and tracking, multi-stream analysis, and temporal analysis of news publishing patterns.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {205–208},
numpages = {4},
keywords = {event detection and analysis, news streams, test collections},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344250,
author = {Sarwar, Sheikh Muhammad and Foley, John and Yang, Liu and Allan, James},
title = {Sentence Retrieval for Entity List Extraction with a Seed, Context, and Topic},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344250},
doi = {10.1145/3341981.3344250},
abstract = {We present a variation of the corpus-based entity set expansion and entity list completion task. A user-specified query and a sentence containing one seed entity are the input to the task. The output is a list of sentences that contain other instances of the entity class indicated by the input. We construct a semantic query expansion model that leverages topical context around the seed entity and scores sentences. The proposed model finds 46% of the target entity class by retrieving 20 sentences on average. It achieves 16% improvement over BM25 in terms of recall@20.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {209–212},
numpages = {4},
keywords = {sentence retrieval, entity list extraction},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344237,
author = {Lin, Yiu-Chang and Das, Pradipto and Trotman, Andrew and Kallumadi, Surya},
title = {A Dataset and Baselines for E-Commerce Product Categorization},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344237},
doi = {10.1145/3341981.3344237},
abstract = {We make available a document collection of a million product titles from 3,008 anonymized categories of the rakuten.com product catalog. The anonymization has been done due to intellectual property rights on the underlying data organization taxonomy. Our analysis of the characteristics of the 800,000 training and 20,000 validation titles show that they match the test set of 180,000 titles. Twenty six independent teams participated in an automatic product categorization challenge on this dataset. We present results and analysis and suggest strong baselines for this collection and task.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {213–216},
numpages = {4},
keywords = {e-commerce, document collection, taxonomy categorization},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344241,
author = {Balog, Krisztian and Kenter, Tom},
title = {Personal Knowledge Graphs: A Research Agenda},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344241},
doi = {10.1145/3341981.3344241},
abstract = {Knowledge graphs, organizing structured information about entities, and their attributes and relationships, are ubiquitous today. Entities, in this context, are usually taken to be anyone or anything considered to be globally important. This, however, rules out many entities people interact with on a daily basis. In this position paper, we present the concept of personal knowledge graphs: resources of structured information about entities personally related to its user, including the ones that might not be globally important. We discuss key aspects that separate them for general knowledge graphs, identify the main challenges involved in constructing and using them, and define a research agenda.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {217–220},
numpages = {4},
keywords = {personal information management, knowledge representation, personal knowledge graphs},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344243,
author = {Chatterjee, Shubham and Dietz, Laura},
title = {Why Does This Entity Matter? Support Passage Retrieval for Entity Retrieval},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344243},
doi = {10.1145/3341981.3344243},
abstract = {Our goal is to complement an entity ranking with human-readable explanations of how those retrieved entities are connected to the information need. While related to the problem of support passage retrieval, in this paper, we explore two underutilized indicators of relevance: contextual entities and entity salience. The effectiveness of the indicators are studied within a supervised learning-to-rank framework on a dataset from TREC Complex Answer Retrieval. We find that salience is a useful indicator, but it is often not applicable. In contrast, although performance improvements are obtained by using contextual entities, using contextual words still outperforms contextual entities.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {221–224},
numpages = {4},
keywords = {entity context neighbors, entity salience, joint query-entity-passage features, entity context document},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344244,
author = {Garigliotti, Dar\'{\i}o and Albakour, Dyaa and Martinez, Miguel and Balog, Krisztian},
title = {Unsupervised Context Retrieval for Long-Tail Entities},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344244},
doi = {10.1145/3341981.3344244},
abstract = {Monitoring entities in media streams often relies on rich entity representations, like structured information available in a knowledge base (KB). For long-tail entities, such monitoring is highly challenging, due to their limited, if not entirely missing, representation in the reference KB. In this paper, we address the problem of retrieving textual contexts for monitoring long-tail entities. We propose an unsupervised method to overcome the limited representation of long-tail entities by leveraging established entities and their contexts as support information. Evaluation on a purpose-built test collection shows the suitability of our approach and its robustness for out-of-KB entities.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {225–228},
numpages = {4},
keywords = {online reputation management, context retrieval, long-tail entities},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344215,
author = {Gao, Ruoyuan and Shah, Chirag},
title = {How Fair Can We Go: Detecting the Boundaries of Fairness Optimization in Information Retrieval},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344215},
doi = {10.1145/3341981.3344215},
abstract = {The presence of bias in today's IR systems has raised concerns on the social responsibilities of IR. Fairness has become an increasingly important factor when building systems for information searching and content recommendations. Fairness in IR is often considered as an optimization problem where the system aims to optimize the utility, subject to a set of fairness constraints, or optimize fairness while guaranteeing a lower bound on the utility, or jointly optimize for both utility and fairness to achieve an overall satisfaction. While various optimization algorithms have been proposed along with theoretical analysis, in real world applications, the performance of different optimization algorithms often heavily depend on the data. Therefore, it is consequential to ask what is the solution space characterized by the data, what effect does introducing fairness bring to the system, and can we identify this solution space to help us trade-off different optimization policies and guide us to pick suitable algorithms and/or make adjustments on data? In this work, we propose a framework that offers a novel perspective into the optimization with fairness constraints problems. Our framework can effectively and efficiently estimate the solution space and answer such questions. It also has the advantage of simplicity, explainability, and reliability. Specifically, we derive theoretical expressions to identify the fairness and relevance bounds for data of different distributions, and apply them to both synthetic and real world datasets. We present a series of use cases to demonstrate how our framework is applied to facilitate various analyses and decision making.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {229–236},
numpages = {8},
keywords = {optimization policy, theoretical framework, bias in ir, fairness and relevance},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344228,
author = {Gupta, Dhruv and Berberich, Klaus},
title = {JIGSAW: Structuring Text into Tables},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344228},
doi = {10.1145/3341981.3344228},
abstract = {We present JIGSAW, an end-to-end query driven system that efficiently generates structured tables from unstructured documents. To do so, first we describe how we can quickly retrieve sentences in support of structured queries that describe the table schema. Second, we describe how we can estimate table cell values using document context where such values can not be retrieved. Third, we describe how we can link together similar rows, rank, and diversify them to generate high-quality tables. We show that JIGSAW can generate tables from 25 million documents within seconds.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {237–244},
numpages = {8},
keywords = {information extraction, linking unstructured and structured data, duplicate detection, structured summarization, table generation, semantic annotations, unstructured text, natural language processing},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344247,
author = {Gollub, Tim and Hutans, Leon and Al Jami, Tanveer and Stein, Benno},
title = {Exploratory Search Pipes with Scoped Facets},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344247},
doi = {10.1145/3341981.3344247},
abstract = {This paper presents faceted search technology tailored to the peculiarities of exploratory search tasks. In contrast to traditional faceted search systems, facets in our system are arranged as a pipe, i.e., are applied sequentially one after the other. Moreover, the facets in a pipe are not applied throughout the whole sequence, but are limited to a user-definable scope, such that the search query can be broadened by adding a facet to the pipe. By this modification, the user interaction with our exploratory search engine resembles rather an open walk through the facet space spanned by the connections between documents and facets, than a progressive filtering of the document collection. We argue that this shift in the interaction paradigm is a much better fit to exploratory search scenarios. A user study with a prototype implementation attests an improved usability of our system compared to traditional faceted search systems for complex exploratory search tasks.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {245–248},
numpages = {4},
keywords = {faceted search, scoped facets, exploratory search},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3344248,
author = {Sarwar, Sheikh Muhammad and Allan, James},
title = {SearchIE: A Retrieval Approach for Information Extraction},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344248},
doi = {10.1145/3341981.3344248},
abstract = {We address the problem of entity extraction with a very few examples and address it with an information retrieval approach. Existing extraction approaches consider millions of features extracted from a large number of training data cases. Typically, these data cases are generated by a distant supervision approach with entities in a knowledge base. After that a model is learned and entities are extracted. However, with extremely limited data a ranked list of relevant entities can be helpful to obtain user feedback to get more training data. As Information Retrieval (IR) is a natural choice for ranked list generation, we explore its effectiveness in such a limited data case. To this end, we propose SearchIE, a hybrid of IR and NLP approach that indexes documents represented using handcrafted NLP features. At query time SearchIE samples terms from a Logistic Regression model trained with extremely limited data. We explore SearchIE's potential by showing that it supersedes state-of-the-art NLP models to find civilians killed by US police officers with only a single civilian name as example.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {249–252},
numpages = {4},
keywords = {information retrieval, search index, information extraction},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3350530,
author = {Pasumarthi, Rama Kumar and Bruch, Sebastian and Bendersky, Michael and Wang, Xuanhui},
title = {Neural Learning to Rank Using TensorFlow Ranking: A Hands-on Tutorial},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3350530},
doi = {10.1145/3341981.3350530},
abstract = {A number of open source packages harnessing the power of deep learning have emerged in recent years and are under active development, including TensorFlow, PyTorch and others. Supervised learning is one of the main use cases of deep learning packages. However, compared with the comprehensive support for classification or regression in open-source deep learning packages, there is a paucity of support for ranking problems. To address this gap, we developed TensorFlow Ranking: an open-source library for training large scale learning-to-rank models using deep learning in TensorFlow. The library is flexible and highly configurable: it provides an easy-to-use API to support different scoring mechanisms, loss functions, example weights, and evaluation metrics.In this tutorial, we will combine the theoretical and the practical aspects of TF-Ranking, and will cover how TF-Ranking can be effectively employed in a variety of learning-to-rank scenarios, and demonstrate how it can handle advanced losses, scoring functions and sparse textual features. Finally, we will provide a hands-on codelab using a learning-to-rank dataset which shows how to effective incorporate sparse features for ranking.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {253–254},
numpages = {2},
keywords = {question answering, neural networks, learning to rank, deep learning},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3353768,
author = {Zhang, Yongfeng},
title = {Tutorial on Explainable Recommendation and Search},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3353768},
doi = {10.1145/3341981.3353768},
abstract = {Explainable recommendation and search attempt to develop models or methods that not only generate high-quality recommendation or search results, but also intuitive explanations of the results for users or system designers, which can help to improve the system transparency, persuasiveness, trustworthiness, and effectiveness, etc. This is even more important in personalized search and recommendation scenarios, where users would like to know why a particular product, web page, news report, or friend suggestion exists in his or her own search and recommendation lists. The tutorial focuses on the research and application of explainable recommendation and search algorithms, as well as their application in real-world systems such as search engine, e-commerce and social networks. The tutorial aims at introducing and communicating explainable recommendation and search methods to the community, as well as gathering researchers and practitioners interested in this research direction for discussions, idea communications, and research promotions.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {255–256},
numpages = {2},
keywords = {explainable recommendation, explainable machine learning, explainable search},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3358959,
author = {Carterette, Ben},
title = {Statistical Significance Testing in Theory and in Practice},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3358959},
doi = {10.1145/3341981.3358959},
abstract = {The past 25 years have seen a great improvement in the rigor of experimentation on information access problems. This is due primarily to three factors: high-quality, public, portable test collections such as those produced by TREC (the Text REtreval Conference~citetrecbook ), the increased ease of online A/B testing on large user populations, and the increased practice of statistical hypothesis testing to determine whether observed improvements can be ascribed to something other than random chance. Together these create a very useful standard for reviewers, program committees, and journal editors; work on information access (IA) problems such as search and recommendation increasingly cannot be published unless it has been evaluated offline using a well-constructed test collection or online on a large user base and shown to produce a statistically significant improvement over a good baseline. But, as the saying goes, any tool sharp enough to be useful is also sharp enough to be dangerous. Statistical tests of significance are widely misunderstood. Most researchers and developers treat them as a "black box'': evaluation results go in and a p-value comes out. But because significance is such an important factor in determining what directions to explore and what is published or deployed, using p-values obtained without thought can have consequences for everyone working in IA. Ioannidis has argued that the main consequence in the biomedical sciences is that most published research findings are false; could that be the case for IA as well?},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {257–259},
numpages = {3},
keywords = {hypothesis testing, information retrieval, recommender systems, statistical significance, statistical testing},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1145/3341981.3350529,
author = {Armentano, Marcelo G. and Bagheri, Ebrahim and Kiseleva, Julia and Takes, Frank W.},
title = {MAISoN 2019: The 3rd International Workshop on Mining Actionable Insights from Social Networks},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3350529},
doi = {10.1145/3341981.3350529},
abstract = {A lot of research in social network mining is concerned with theories and methodologies for community discovery, pattern detection and network evolution, as well as behavioural analysis and anomaly (misbehaviour) detection. The MAISoN workshop focuses on the use of social network data and methods for building predictive models that can be used to uncover hidden and unexpected aspects of user-generated content in order to extract actionable insights. The objective is to explore ways in which insights can be transformed into effective actions that can help organizations improve and refine their activities. Thus, the focus is on social network analysis and mining techniques for gaining actionable real-world insights. The 3rd International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2019) was a half day workshop co-located with ICTIR 2019, the 5th ACM SIGIR International Conference on the Theory of Information Retrieval which took place from October 2 to 5, 2019 in Santa Clara, California, United States.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {260–261},
numpages = {2},
keywords = {online social networks, data mining, social influence},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

