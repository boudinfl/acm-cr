@inproceedings{10.5555/3041021.3252688,
author = {Lytras, Miltiadis D. and Aljohani, Naif Radi and Zhang, Xi},
title = {Session Details: Cognitive Computing Alternate Research Track},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Cognitive Computing Alternate Research Track Chairs' Welcome &amp; Organization},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {3},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054149,
author = {Chen, Huijun and Li, Xin and Rao, Yanghui and Xie, Haoran and Wang, Fu Lee and Wong, Tak-Lam},
title = {Sentiment Strength Prediction Using Auxiliary Features},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054149},
doi = {10.1145/3041021.3054149},
abstract = {With an increasingly large amount of sentimental information embedded in online documents, sentiment analysis is quite valuable to product recommendation, opinion summarization, and so forth. Different from most works on identifying documents' qualitative affective information, this research focuses on the measurement of users' intensity over each sentimental category. Affect indicates positive or negative sentiment, while cognition includes certainty and tentative. Thus, our research can help bridge the cognitive and affective gaps between users and documents. The contributions of this study are twofold: (i) we proposed a neural network-based framework to sentiment strength prediction by convolving hybrid vectors, and (ii) we considered words jointly with a set of linguistic features for enhancing model robustness and adaptiveness. By exploiting the auxiliary features of sentiments from the corpus, the proposed model did not rely on well-established lexicons, and showed its robustness over sparse words. Experiments on six corpora validated the effectiveness of our sentiment strength prediction method.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {5–14},
numpages = {10},
keywords = {convolutional neural network, hybrid features, sentiment strength},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054141,
author = {Chen, Kuan-Ting and Luo, Jiebo},
title = {When Fashion Meets Big Data: Discriminative Mining of Best Selling Clothing Features},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054141},
doi = {10.1145/3041021.3054141},
abstract = {With the prevalence of e-commence websites and the ease of online shopping, consumers are embracing huge amounts of various options in products. Undeniably, shopping is one of the most essential activities in our society and studying consumer's shopping behavior is important for the industry as well as sociology and psychology. Indisputable, one of the most popular e-commerce categories is clothing business. There arises the needs for analysis of popular and attractive clothing features which could further boost many emerging applications, such as clothing recommendation and advertising. In this work, we design a novel system that consists of three major components: 1) exploring and organizing a large-scale clothing dataset from a online shopping website, 2) pruning and extracting images of best-selling products in clothing item data and user transaction history, and 3) utilizing a machine learning based approach to discovering fine-grained clothing attributes as the representative and discriminative characteristics of popular clothing style elements. Through the experiments over a large-scale online clothing shopping dataset, we demonstrate the effectiveness of our proposed system, and obtain useful insights on clothing consumption trends and profitable clothing features.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {15–22},
numpages = {8},
keywords = {big data, clothing features, data mining, image analysis, online shopping},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054142,
author = {Chen, Tianlang and Chen, Yuxiao and Luo, Jiebo},
title = {A Selfie is Worth a Thousand Words: Mining Personal Patterns behind User Selfie-Posting Behaviours},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054142},
doi = {10.1145/3041021.3054142},
abstract = {Selfies have become increasingly fashionable in the social media era. People are willing to share their selfies in various social media platforms such as Facebook, Instagram and Flicker. The popularity of selfie have caught researchers' attention, especially psychologists. In computer vision and machine learning areas, little attention has been paid to this phenomenon as a valuable data source. In this paper, we focus on exploring the deeper personal patterns behind people's different kinds of selfie-posting behaviours. We develop this work based on a dataset of WeChat, one of the most extensively used instant messaging platform in China. In particular, we first propose an unsupervised approach to classify the images posted by users. Based on the classification result, we construct three types of user-level features that reflect user preference, activity and posting habit. Based on these features, for a series of selfie related tasks, we build classifiers that can accurately predict two sets of users with opposite selfie-posting behaviours. We have found that people's interest, activity and posting habit have a great influence on their selfie-posting behaviours. Taking selfie frequency as an example, the classification accuracy between selfie-posting addict and nonaddict can reach 89.36%. We also prove that using user's image information to predict these behaviours achieve better performance than using text information. More importantly, for each set of users with a specific selfie-posting behaviour, we extract and visualize significant personal patterns about them. In addition, to concisely construct the relation between personal pattern and selfie-posting behaviour, we cluster users and extract their high-level attributes, revealing the correlation between these attributes and users' selfie-posting behaviours. In the end, we demonstrate that users' selfie-posting behaviour, as a good predictor, could predict their different preferences toward these high-level attributes accurately.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {23–31},
numpages = {9},
keywords = {selfie behavior analysis, deep residual networks, user modeling, social media mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054137,
author = {Daud, Ali and Aljohani, Naif Radi and Abbasi, Rabeeh Ayaz and Rafique, Zahid and Amjad, Tehmina and Dawood, Hussain and Alyoubi, Khaled H.},
title = {Finding Rising Stars in Co-Author Networks via Weighted Mutual Influence},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054137},
doi = {10.1145/3041021.3054137},
abstract = {Finding rising stars is a challenging and interesting task which is being investigated recently in co-author networks. Rising stars are authors who have a low research profile in the start of their career but may become experts in the future. This paper introduces a new method Weighted Mutual Influence Rank (WMIRank) for finding rising stars. WMIRank exploits influence of co-authors' citations, order of appearance and publication venues. Comprehensive experiments are performed to analyze the performance of WMIRank in comparison to baseline methods, which have ignored weighted mutual influence. AMiner data for years 1995-2000 is used for experiments. List of top 30 authors as per proposed and baseline methods are compared for their average number of papers, average number of citations and achievements. Experimental results provide convincing evidence of the effectiveness of the investigated weighted mutual influence.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {33–41},
numpages = {9},
keywords = {citations, bibliographic databases, co-author networks, rising stars, author order, mutual influence},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054144,
author = {de Melo, Gerard},
title = {Inducing Conceptual Embedding Spaces from Wikipedia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054144},
doi = {10.1145/3041021.3054144},
abstract = {The word2vec word vector representations are one of the most well-known new semantic resources to appear in recent years. While large sets of pre-trained vectors are available, these focus on frequent words and multi-word expressions but lack sufficient coverage of named entities. Moreover, Google only released pre-trained vectors for English. In this paper, we explore an automatic expansion of Google's pre-trained vectors using Wikipedia, adding millions of concepts and named entities in over 270 languages. Our method enables all of these to reside in the same vector space, thus flexibly facilitating cross-lingual semantic applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {43–50},
numpages = {8},
keywords = {wikipedia, semantic representations, conceptual knowledge},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054150,
author = {Ghosh, Shreya and Ghosh, Soumya K.},
title = {Modeling of Human Movement Behavioral Knowledge from GPS Traces for Categorizing Mobile Users},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054150},
doi = {10.1145/3041021.3054150},
abstract = {Human movement analysis and categorization of mobile users based on their movement semantics are challenging tasks. Further, due to security and privacy issues, insufficient labeled or user-annotated data (or, ground-truth data) makes the user-classification from GPS traces more complex. In this work, we present a framework which models user movement patterns containing both spatio-temporal and semantic information, generates semantic stay-point taxonomy by analysing GPS traces of all users, summarizes individuals' GPS traces and clusters users based on the semantics of their movement patterns. To alleviate labelled data scarcity problem while user categorization in a particular region of interest (ROI), we propose a method to transfer knowledge derived from a set of GPS traces of a geographically distanced but similar type of ROI. An extensive set of experiments using real GPS trace dataset of Kharagpur, India and Dartmouth, Hanover, USA have been carried out to demonstrate the effectiveness of our proposed framework.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {51–58},
numpages = {8},
keywords = {geo-tagging, clustering, categorization, spatial transfer learning, trajectory;gps data, geocoding},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054146,
author = {Gillani, Mehreen and Ilyas, Muhammad U. and Saleh, Saad and Alowibdi, Jalal S. and Aljohani, Naif and Alotaibi, Fahad S.},
title = {Post Summarization of Microblogs of Sporting Events},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054146},
doi = {10.1145/3041021.3054146},
abstract = {Every day 645 million Twitter users generate approximately 58 million tweets. This motivates the question if it is possible to generate a summary of events from this rich set of tweets only. Key challenges in post summarization from microblog posts include circumnavigating spam and conversational posts. In this study, we present a novel technique called lexi-temporal clustering (LTC), which identifies key events. LTC uses k-means clustering and we explore the use of various distance measures for clustering using Euclidean, cosine similarity and Manhattan distance. We collected three original data sets consisting of Twitter microblog posts covering sporting events, consisting of a cricket and two football matches. The match summaries generated by LTC were compared against standard summaries taken from sports sections of various news outlets, which yielded up to 81% precision, 58% recall and 62% F-measure on different data sets. In addition, we also report results of all three variants of the recall-oriented understudy for gisting evaluation (ROUGE) software, a tool which compares and scores automatically generated summaries against standard summaries.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {59–68},
numpages = {10},
keywords = {summarization, twitter},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054151,
author = {Jin, Peiquan and Mu, Lin and Zheng, Lizhou and Zhao, Jie and Yue, Lihua},
title = {News Feature Extraction for Events on Social Network Platforms},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054151},
doi = {10.1145/3041021.3054151},
abstract = {Microblog-based social network platforms like Twitter and Sina Weibo have been important sources for news event extraction. However, existing works on microblog event extraction, which usually use keywords, entities, or selected microblogs to represent events, are not able to extract details of an event. Based on the view of news report, an event should present detailed news features, i.e., when, where, who, whom, and what. Such news features are helpful for conducting deeply data analysis on microblogs, e.g., competitor monitoring and public crisis discovery. However, the challenge is that the news features of an event on microblogs are usually distributed among different posts because of the short-text property of microblogs. This is much different from extracting news events from Web news pages that usually contain most details of an event. In this paper, we propose a new framework to extract events together with their news features from microblogs. We first extract a set of events from microblogs. Each event is represented as a distribution over four kinds of named entities including location, person name, organization, and time. In addition, the type of each event, i.e., location-related, person-related, or organization-related, is determined by a machine-learning method. In order to obtain the news features of an event, we propose an event-clustering approach that puts together all the relevant events into a cluster. For each cluster, we propose different algorithms to extract the news features of the event reported in the cluster. We conduct experiments on two microblog datasets crawled from a commercial microblogging platform to evaluate the performance of the proposed framework. The results suggest the effectiveness of our proposal.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {69–78},
numpages = {10},
keywords = {microblog, news features, event extraction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054135,
author = {Li, Huadong and Wang, Yafang and de Melo, Gerard and Tu, Changhe and Chen, Baoquan},
title = {Multimodal Question Answering over Structured Data with Ambiguous Entities},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054135},
doi = {10.1145/3041021.3054135},
abstract = {In recent years, we have witnessed profound changes in the way people satisfy their information needs. For instance, with the ubiquitous 24/7 availability of mobile devices, the number of search engine queries on mobile devices has reportedly overtaken that of queries on regular personal computers. In this paper, we consider the task of multimodal question answering over structured data, in which a user supplies not just a natural language query but also an image. Our system addresses this by optimizing a non-convex objective function capturing multimodal constraints. Our experiments show that this enables it to answer even very challenging ambiguous entity queries with high accuracy.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {79–88},
numpages = {10},
keywords = {multimodal, question answering, multimodal knowledge bases},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054147,
author = {Nezhad, Hamid R. Motahari and Gunaratna, Kalpa and Cappi, Juan},
title = {EAssistant: Cognitive Assistance for Identification and Auto-Triage of Actionable Conversations},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054147},
doi = {10.1145/3041021.3054147},
abstract = {The browser and screen have been the main user interfaces of the Web and mobile apps. The notification mechanism is an evolution in the user interaction paradigm by keeping users updated without checking applications. Conversational agents are posed to be the next revolution in user interaction paradigms. However, without intelligence on the triage of content served by the interaction and content differentiation in applications, interaction paradigms may still place the burden of information overload on users. In this paper, we focus on the problem of intelligent identification of actionable information in the content served by applications, and in particular in productivity applications (such as email, chat, messaging, social collaboration tools, etc.). We present eAssistant, which offers a novel fine-grained action identification method in an adaptive, personalizable, and online-trainable manner, and a cognitive agent/API that uses action information and user-centric conversation characteristics to auto-triage user conversations. The introduced method identifies individual actions and associated metadata; it is extensible in terms of the number of action classes; it learns in an online and continuous manner via user interactions and feedback, and it is personalizable to different users. We have evaluated the proposed method using real-world datasets. The results show that the method achieves higher accuracy compared to traditional ways of formulating the problem, while exhibiting additional desired properties of online, personalized, and adaptive learning. In eAssistant, we introduce a multi-dimensional learning model of conversations auto-triage, defined based on a user study and NLP-based information extraction techniques, to auto-triage user conversations on social collaboration and productivity tools.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {89–98},
numpages = {10},
keywords = {cognitive assistance, natural language understanding, natural language interface, personalization, activity management, online learning, information extraction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054136,
author = {Nguyen, Thin and Nguyen, Duc Thanh and Larsen, Mark E. and O'Dea, Bridianne and Yearwood, John and Phung, Dinh and Venkatesh, Svetha and Christensen, Helen},
title = {Prediction of Population Health Indices from Social Media Using Kernel-Based Textual and Temporal Features},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054136},
doi = {10.1145/3041021.3054136},
abstract = {From 1984, the US has annually conducted the Behavioral Risk Factor Surveillance System (BRFSS) surveys to capture either health behaviors, such as drinking or smoking, or health outcomes, including mental, physical, and generic health, of the population. Although this kind of information at a population level, such as US counties, is important for local governments to identify local needs, traditional datasets may take years to collate and to become publicly available. Geocoded social media data can provide an alternative reflection of local health trends. In this work, to predict the percentage of adults in a county reporting "insufficient sleep", a health behavior, and, at the same time, their health outcomes, novel textual and temporal features are proposed. The proposed textual features are defined at mid-level and can be applied on top of various low-level textual features. They are computed via kernel functions on underlying features and encode the relationships between individual underlying features over a population. To further enrich the predictive ability of the health indices, the textual features are augmented with temporal information. We evaluated the proposed features and compared them with existing features using a dataset collected from the BRFSS. Experimental results show that the combination of kernel-based textual features and temporal information predict well both the health behavior (with best performance at rho=0.82) and health outcomes (with best performance at rho=0.78), demonstrating the capability of social media data in prediction of population health indices. The results also show that our proposed features gained higher correlation coefficients than did the existing ones, increasing the correlation coefficient by up to 0.16, suggesting the potential of the approach in a wide spectrum of applications on data analytics at population levels.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {99–107},
numpages = {9},
keywords = {population health indices, prediction, kernel-based features, online texts, feature engineering, geo-referenced tweets, textual features, temporal information, cognitive computing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054139,
author = {Rodrigues, Phillipe and Silva, Ismael Santana and Barbosa, Gl\'{\i}via Ang\'{e}lica Rodigues and Coutinho, Fl\'{a}vio Roberto dos Santos and Mour\~{a}o, Fernando},
title = {Beyond the Stars: Towards a Novel Sentiment Rating to Evaluate Applications in Web Stores of Mobile Apps},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054139},
doi = {10.1145/3041021.3054139},
abstract = {This paper proposes an approach to evaluate mobile applications which complements the information provided by the number of stars and downloads in app stores. The goal is to provide novel information to assist users in the decision-making process regarding the choice of applications. In this sense, we conducted experiments to verify the relationship between the number of stars and the content of review comments. Results indicated that there is information in reviews not properly represented by stars. Thus, we present a sentiment rating generated automatically by aggregating opinions reported in the reviews related to each application. We evaluated this new rating using 26,996 reviews related to six applications present on the Google Play Store. The obtained results allow us to demonstrate that: (1) it is possible and feasible to generate a sentiment rating automatically and (2) the rating is useful for web stores of mobile applications to improve their mechanisms of ranking and recommendation as well as to assist users and developers to evaluate the quality and/or acceptance of the offered mobile applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {109–117},
numpages = {9},
keywords = {machine learning, mobile apps, user review, decision-making, web stores, sentiment analysis},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054148,
author = {Ruan, Shanshan and Mehmood, Rashid and Daud, Ali and Dawood, Hussain and Alowibdi, Jalal S.},
title = {An Adaptive Method for Clustering by Fast Search-and-Find of Density Peaks: Adaptive-DP},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054148},
doi = {10.1145/3041021.3054148},
abstract = {Clustering by fast search and find of density peaks (DP) is a method in which density peaks are used to select the number of cluster centers. The DP has two input parameters: 1) the cutoff distance and 2) cluster centers. Also in DP, different methods are used to measure the density of underlying datasets. To overcome the limitations of DP, an Adaptive-DP method is proposed. In Adaptive-DP method, heat-diffusion is used to estimate density, cutoff distance is simplified, and novel method is used to discover exact number of cluster centers, adaptively. To validate the proposed method, we tested it on synthetic and real datasets, and comparison are done with the state of the art clustering methods. The experimental results validate the robustness and effectiveness of proposed method.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {119–127},
numpages = {9},
keywords = {decision graph, heat equation, kernel density estimation, clustering},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054152,
author = {Shen, Chien-wen and Ho, Jung-tsung and Kuo, Ting-Chang and Luong, Thai Ha},
title = {Behavioral Intention of Using Virtual Reality in Learning},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054152},
doi = {10.1145/3041021.3054152},
abstract = {This study integrated the unified theory of acceptance and use of technology (UTAUT) and the four stages of Kolb's learning style-concrete experience, reflective observation, abstract conception, and active experimentation to investigate the factors affecting students' behavioral intention to use a virtual reality headset (VRH) in learning. The research model, constructed using structural equation modeling, included the four constructs of the UTAUT, namely performance expectancy, effort expectancy, social influence, and facilitating condition. Hypotheses on whether the four stages of Kolb's learning style and the four constructs of the UTAUT significantly affect behavioral intention to use VRHs in learning were proposed and tested through inference analysis. The results show that only the concrete experience stage of Kolb's learning style has a positive and significant effect on users' behavioral intention to use VRHs in learning, whereas all four constructs of the UTAUT do. These findings should be applied by educational institutions to increase VRH use in learning.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {129–137},
numpages = {9},
keywords = {behavioral intention, virtual reality, technology acceptance, learning style},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054140,
author = {Wang, Pinghui and Sun, Feiyang and Wang, Di and Tao, Jing and Guan, Xiaohong and Bifet, Albert},
title = {Inferring Demographics and Social Networks of Mobile Device Users on Campus From AP-Trajectories},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054140},
doi = {10.1145/3041021.3054140},
abstract = {Exploring demographics and social networks of Internet users are widely used for many applications such as recommendation systems. The popularity of mobile devices (e.g., smartphones) and location-based Internet services (e.g., Google Maps) facilitates the collection of users' locations over time. Despite recent efforts to predict users' attributes (e.g., age and gender) and social networks based on utilizing the rich location context knowledge (e.g., name, type, and description) of places of interest (e.g., restaurants and hotels) they checked-in on location-based online social networks such as Foursqure and Gowalla, little attention has been given to inferring attributes and social networks of mobile device users based on their spatiotemporal trajectories with less/no location context knowledge. In this paper we collect logs of thousands of mobile devices' network connections to wireless access points (APs) of two campuses, and investigate whether one can infer mobile device users' demographic attributes and social networks solely from their spatiotemporal AP-trajectories. We develop a tensor factorization based method Dinfer to infer mobile device users' demographic attributes from their AP-trajectories by leveraging prior knowledge, such as users' social networks. We also propose a novel method Sinfer to learn social networks between mobile device users by exploring patterns of their AP-trajectories, such as fine-grained co-occurrence events (e.g., co-coming, co-leaving, and co-presenting duration). Experimental results on real-word datasets demonstrate the effectiveness of our methods.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {139–147},
numpages = {9},
keywords = {user profiling, spatiotemporal trajectories, social network},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054145,
author = {Zhang, Xi and Jiang, Shan and Cheng, Yihang},
title = {Inferring the Student Social Loafing State in Collaborative Learning with a Hidden Markov Model: A Case on Slack},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054145},
doi = {10.1145/3041021.3054145},
abstract = {With the increasingly prevailing usage of Information and Communication technologies (ICT) in collaborative learning, students can cooperate with others online easily, in spite of the restriction of time and location. Social loafing, a common phenomenon in collaborative work, has negative effect on team performance, especially on the individual's knowledge sharing behavior. In recent years, there are also some researches pointing out that social loafing is a kind of hidden and unobservable behavior. In this study, we propose a research model based on the stimulus-organism-response (S-O-R) framework and build a hidden Markov model (HMM) to infer the student's unobservable social loafing state. We collect real world behavior data from an online collaborative course from Nov 11th 2016 to Dec 21th 2016.The dataset includes more than 1200 knowledge sharing records from 150 students on Slack. Our research is expected to contribute in both academic study and managerial implications on how to set up a collaborative team.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {149–152},
numpages = {4},
keywords = {collaboration work, centrality, social loafing, hidden markov models, knowledge sharing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054138,
author = {Zhao, Shenglin and Zhao, Tong and King, Irwin and Lyu, Michael R.},
title = {Geo-Teaser: Geo-Temporal Sequential Embedding Rank for Point-of-Interest Recommendation},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054138},
doi = {10.1145/3041021.3054138},
abstract = {Point-of-interest (POI) recommendation is an important application for location-based social networks (LBSNs), which learns the user preference and mobility pattern from check-in sequences to recommend POIs. Previous studies show that modeling the sequential pattern of user check-ins is necessary for POI recommendation. Markov chain model, recurrent neural network, and the word2vec framework are used to model check-in sequences in previous work. However, all previous sequential models ignore the fact that check-in sequences on different days naturally exhibit the various temporal characteristics, for instance, "work" on weekday and "entertainment" on weekend. In this paper, we take this challenge and propose a Geo-Temporal sequential embedding rank (Geo-Teaser) model for POI recommendation. Inspired by the success of the word2vec framework to model the sequential contexts, we propose a temporal POI embedding model to learn POI representations under some particular temporal state. The temporal POI embedding model captures the contextual check-in information in sequences and the various temporal characteristics on different days as well. Furthermore, We propose a new way to incorporate the geographical influence into the pairwise preference ranking method through discriminating the unvisited POIs according to geographical information. Then we develop a geographically hierarchical pairwise preference ranking model. Finally, we propose a unified framework to recommend POIs combining these two models. To verify the effectiveness of our proposed method, we conduct experiments on two real-life datasets. Experimental results show that the Geo-Teaser model outperforms state-of-the-art models. Compared with the best baseline competitor, the Geo-Teaser model improves at least 20% on both datasets for all metrics.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {153–162},
numpages = {10},
keywords = {location-based services, spatial-temporal data, embedding learning, poi recommendation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252689,
author = {Lugmayr, Artur and Datta, Amitava},
title = {Session Details: DEMONSTRATION SESSION},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Demo Chairs' Welcome and Organization},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054726,
author = {Beheshti, Seyed-Mehdi-Reza and Tabebordbar, Alireza and Benatallah, Boualem and Nouri, Reza},
title = {On Automating Basic Data Curation Tasks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054726},
doi = {10.1145/3041021.3054726},
abstract = {Big data analytics is firmly recognized as a strategic priority for modern enterprises. At the heart of big data analytics lies the data curation process, consists of tasks that transform raw data (unstructured, semi-structured and structured data sources) into curated data, i.e. contextualized data and knowledge that is maintained and made available for use by end-users and applications. To achieve this, the data curation process may involve techniques and algorithms for extracting, classifying, linking, merging, enriching, sampling, and the summarization of data and knowledge. To facilitate the data curation process and enhance the productivity of researchers and developers, we identify and implement a set of basic data curation APIs and make them available as services to researchers and developers to assist them in transforming their raw data into curated data. The curation APIs enable developers to easily add features - such as extracting keyword, part of speech, and named entities such as Persons, Locations, Organizations, Companies, Products, Diseases, Drugs, etc.; providing synonyms and stems for extracted information items leveraging lexical knowledge bases for the English language such as WordNet; linking extracted entities to external knowledge bases such as Google Knowledge Graph and Wikidata; discovering similarity among the extracted information items, such as calculating similarity between string and numbers; classifying, sorting and categorizing data into various types, forms or any other distinct class; and indexing structured and unstructured data - into their data applications. These services can be accessed via a REST API, and the data is returned as a JSON file that can be integrated into data applications. The curation APIs are available as an open source project on GitHub.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {165–169},
numpages = {5},
keywords = {data curation, curation api, big data analytics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054734,
author = {Bernaschina, Carlo and Brambilla, Marco and Koka, Thanas and Mauri, Andrea and Umuhoza, Eric},
title = {Integrating Modeling Languages and Web Logs for Enhanced User Behavior Analytics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054734},
doi = {10.1145/3041021.3054734},
abstract = {While basic Web analytics tools are widespread and provide statistics about Web site navigation, no approaches exist for merging such statistics with information about the Web application structure, content and semantics. We demonstrate the advantages of combining Web application models with runtime navigation logs, at the purpose of deepening the understanding of users behaviour. We propose a model-driven approach that combines user interaction modeling (based on the IFML standard), full code generation of the designed application, user tracking at runtime through logging of runtime component execution and user activities, integration with page content details, generation of integrated schema-less data streams, and application of large-scale analytics and visualization tools for big data, by applying both traditional dataviz techniques and direct representation of statistics on visual models of the Web application.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {171–175},
numpages = {5},
keywords = {user behavior analysis, user interactions modeling, ifml, model-driven development, web analytics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054732,
author = {Boldyrev, Natalia and Spaniol, Marc and Str\"{o}tgen, Jannik and Weikum, Gerhard},
title = {SESAME: European Statistics Explored via Semantic Alignment onto Wikipedia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054732},
doi = {10.1145/3041021.3054732},
abstract = {Authorities such as the European Commission have recognized the need to offer a unified access to the data gathered by a wide variety of providers, such as the European Statistical Organization (Eurostat) or the European Environment Agency. Its EU Open Data Portal serves as a gateway to numerical data, statistical reports, and visualization tools. While making the data available to the users from all member states and concentrating efforts on bridging the language gap, the portal still focuses on a primarily statistical perspective. That is, numerical data are explained with general terms, only. However, the related events, people, or organizations ``causing'' or being ``affected'' by the statistical observation remain concealed to the user.In order to make statistical data better understandable, we present the SESAME system (Statistics Explored via Semantic AlignMEnt). It relies on a novel method for identifying background information and relating it with event descriptions in Wikipedia. Using SESAME, users can jointly browse numerical statistics, their explanation in general terms and - now - also directly relate it to associated Wikipedia articles.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {177–181},
numpages = {5},
keywords = {semantic alignment, linking numerical observations},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054733,
author = {Chavoshi, Nikan and Hamooni, Hossein and Mueen, Abdullah},
title = {On-Demand Bot Detection and Archival System},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054733},
doi = {10.1145/3041021.3054733},
abstract = {Unusually high correlation in activities among users in social media is an indicator of bot behavior. We have developed a system, called DeBot, that identifies such bots in Twitter network. Our system reports and archives thousands of bot accounts every day. DeBot is an unsupervised method capable of detecting bots in a parameter-free fashion. In February 2017, DeBot has collected over 710K unique bots since August 2015. Since we are detecting and archiving Twitter bots on a daily basis, we have the ability to offer two different services based on our bot detection system. The first one is a bot archive API that makes it easy for researchers to query the DeBot's archive. This API can be used to answer various queries: Is a given Twitter account a bot? When was this bot active in the past? Which twitter accounts were detected as bots on a specific date? The second service that we offer is an on-demand bot detection platform which can detect bots that are related to a given topic or geographical location, and report them to the user in few hours. This paper explains all the details of the services we offer on top of the DeBot's bot detection engine.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {183–187},
numpages = {5},
keywords = {social media, programming api, bot detection, twitter},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054729,
author = {Chen, Peng-Yu and Lee, Yi-Hui and Wu, Yueh-Han and Ma, Wei-Yun},
title = {IExM: Information Extraction System for Movies},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054729},
doi = {10.1145/3041021.3054729},
abstract = {In this demonstration, we present Information Extraction System for Movies(IExM), which helps extract relation instances from un- labeled movie articles. We have designed a new distant-supervised learning algorithm: Improved Pattern Ranking Algorithm(IPRA) to extract relation instances from unlabeled articles, which iteratively generates new patterns starting from a limited set of seed instances, and extracts new instances using high-ranking pattern in a precise and effective way. IPRA also has a special estimation for the newly generated patterns based on the quality estimation of the instances that generate the patterns and ranks patterns' quality based on var- ious factors.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {189–193},
numpages = {5},
keywords = {pattern ranking, bootstrapping, wikipedia, e-hownet, infobox, semi-supervised learn- ing, information extraction, pattern generation, relation extraction, distant supervision},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054725,
author = {Ding, Cheng and Xia, Fan and Gopalakrishnan, Gopakumar and Qian, Weining and Zhou, Aoying},
title = {TeamGen: An Interactive Team Formation System Based on Professional Social Network},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054725},
doi = {10.1145/3041021.3054725},
abstract = {We introduce TeamGen, an interactive team formation system, to form project teams interactively by leveraging professional social network information of potential members. Unlike earlier approaches that focused on creating flat teams, i.e., teams without communities and central authorities, we model teams as hierarchical structures to reflect the ubiquitous nature of teams in real commercial and open source projects. Correspondingly, our team formation algorithms emphasize local density of sub teams to assess communication costs of newly formed teams. During the demonstration, audience can (a) explore professional social network of potential members, (b) learn the effectiveness and efficiency of our proposed team formation algorithms by comparing them with existing ones, (c) inspect and understand the process of team formation, and (d) interactively refine a project team by revoking computed position assignments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {195–199},
numpages = {5},
keywords = {social network, team formation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054737,
author = {Garimella, Kiran and De Francisc iMorales, Gianmarco and Gionis, Aristides and Mathioudakis, Michael},
title = {Mary, Mary, Quite Contrary: Exposing Twitter Users to Contrarian News},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054737},
doi = {10.1145/3041021.3054737},
abstract = {Polarized topics often spark discussion and debate on social media. Recent studies have shown that polarized debates have a specific clustered structure in the endorsement net- work, which indicates that users direct their endorsements mostly to ideas they already agree with. Understanding these polarized discussions and exposing social media users to con- tent that broadens their views is of paramount importance. The contribution of this demonstration is two-fold. (i) A tool to visualize retweet networks about controversial issues on Twitter. By using our visualization, users can understand how polarized discussions are shaped on Twitter, and explore the positions of the various actors. (ii) A solution to reduce polarization of such discussions. We do so by exposing users to information which presents a contrarian point of view. Users can visually inspect our recommendations and understand why and how these would play out in terms of the retweet network.Our demo (https://users.ics.aalto.fi/kiran/reducingControversy/ homepage) provides one of the first steps in developing automated tools that help users explore, and possibly escape, their echo chambers. The ideas in the demo can also help content providers design tools to broaden their reach to people with different political and ideological backgrounds.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {201–205},
numpages = {5},
keywords = {filter bubble, twitter, echo chambers, polarization, controversy},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054735,
author = {Gubanov, Michael and Priya, Manju and Podkorytov, Maksim},
title = {CognitiveDB: An Intelligent Navigator for Large-Scale Dark Structured Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054735},
doi = {10.1145/3041021.3054735},
abstract = {Volume and Variety of Big data [Stonebraker, 2012] are significant impediments for anyone who wants to quickly understand what information is inside a large-scale dataset. Such data is often informally referred to as 'dark' due to the difficulties of understanding its contents. For example, there are millions of structured tables available on the Web, but finding a specific table or summarizing all Web tables to understand what information is available is infeasible or very difficult because of the scale involved.Here we present and demonstrate CognitiveDB, an intelligent cognitive data management system that can quickly summarize the contents of an unexplored large-scale structured dataset, visualize it for interactive navigation, understanding, and support intelligent query processing.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {207–211},
numpages = {5},
keywords = {cloud computing, summarization, visualization., data fusion and cleaning, large-scale data management, web-search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054731,
author = {G\"{u}r, Nurefsan and Nielsen, Jacob and Hose, Katja and Pedersen, Torben Bach},
title = {GeoSemOLAP: Geospatial OLAP on the Semantic Web Made Easy},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054731},
doi = {10.1145/3041021.3054731},
abstract = {The proliferation of spatial data and the publication of multidimensional (MD) data on the Semantic Web (SW) has led to new opportunities for On-Line Analytical Processing (SOLAP) over spatial data using SPARQL. However, formulating such queries results in verbose statements and can easily become very difficult for inexperienced users. Hence, we have developed GeoSemOLAP to enable users without detailed knowledge of RDF and SPARQL to query the SW with SOLAP. GeoSemOLAP generates SPARQL queries based on high-level SOLAP operators and allows the user to interactively formulate queries using a graphical interface with interactive maps.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {213–217},
numpages = {5},
keywords = {multidimensional rdf data, spatial olap, sparql},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054730,
author = {Kumar, Chandan and Menges, Raphael and M\"{u}ller, Daniel and Staab, Steffen},
title = {Chromium Based Framework to Include Gaze Interaction in Web Browser},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054730},
doi = {10.1145/3041021.3054730},
abstract = {Enabling Web interaction by non-conventional input sources like eyes has great potential to enhance Web accessibility. In this paper, we present a Chromium based inclusive framework to adapt eye gaze events in Web interfaces. The framework provides more utility and control to develop a full-featured interactive browser, compared to the related approaches of gaze-based mouse and keyboard emulation or browser extensions. We demonstrate the framework through a sophisticated gaze driven Web browser, which effectively supports all browsing operations like search, navigation, bookmarks, and tab management.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {219–223},
numpages = {5},
keywords = {eye-controlled interfaces, web browser, chromium embedded framework, interactive elements, gaze input, webpage rendering, dom node extraction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3058587,
author = {Kuznetsova, Irina and Filipovska, Aleksandra and Rackham, Oliver and Lugmayr, Artur and Holzinger, Andreas},
title = {Circularized Visualisation of Genetic Interactions},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3058587},
doi = {10.1145/3041021.3058587},
abstract = {Next Generation Sequencing (NGS) has been a powerful tool to investigate gene networks in biological sciences [1]. Visualisation of data produced by NGS is essential for the interpretation of the findings by biological scientists. Here we describe a workflow to image findings from a NGS sequencing methodology to investigate gene expression that can be visualised with Circus software [2]. Visualisation of these processes has provided biological scientists with valuable interpretation of high throughput data and identification of new transcripts.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {225–226},
numpages = {2},
keywords = {big data, circular rna},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054724,
author = {Lal, Anurag and Tomer, Apoorve and Chowdary, C. Ravindranath},
title = {SANE: System for Fine Grained Named Entity Typing on Textual Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054724},
doi = {10.1145/3041021.3054724},
abstract = {Assignment of fine-grained types to named entities is gaining popularity as one of the major Information Extraction tasks due to its applications in several areas of Natural Language Processing. Existing systems use huge knowledge bases to improve the accuracy of the fine-grained types. We designed and developed SANE, a system that uses Wikipedia categories to fine grain the type of the named entities recognized in the textual data.The main contribution of this work is building a named entity typing system without the use of knowledge bases. Through our experiments, 1) we establish the usefulness of Wikipedia categories to Named Entity Typing and 2) we show that SANE's performance is on par with the state-of-the-art.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {227–230},
numpages = {4},
keywords = {wikipedia, fined-grained, named entity typing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054719,
author = {Li, Jianxin and Liu, Chengfei and Chen, Lu and He, Zhenying and Datta, Amitava and Xia, Feng},
title = {ITopic: Influential Topic Discovery from Information Networks via Keyword Query},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054719},
doi = {10.1145/3041021.3054719},
abstract = {The rapid growth of information networks provides a significant opportunity for people to learn the world and find useful information for decision making. To find influential topics in a given context, instead of searching widely over the whole information network, normally it is wise to find the related communities first and then identify the influential topics in those communities. In this demonstration, we present a novel framework to compute the correlated sub-networks from a large information network such as CiteSeerX based on a user's keyword query, and to extract the influential topics from each correlated network. To help users understand the influential topics as a whole, we utilize a word cloud to represent the discovered topics for each correlated network. As such, multiple word clouds can be generated for different correlated networks, by which users can easily pick up their interested ones by reading the visualized topic descriptions over word clouds. To determine the sizes of different terms in a word cloud, we introduce a scoring scheme for assessing the influence of these terms in the corresponding networks. We demonstrate the functionality of our influential topic system, called iTopic, using the CiteSeerX information network data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {231–235},
numpages = {5},
keywords = {information network, topic discovery, keyword query},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054727,
author = {Lin, Chunbin and Wang, Jianguo},
title = {SpiderX: Fast XML Exploration System},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054727},
doi = {10.1145/3041021.3054727},
abstract = {Keyword search in XML has gained popularity as it enables users to easily access XML data without the need of learning query languages and studying complex data schemas. In XML keyword search, query semantics is based on the concept of Lowest Common Ancestor (LCA), e.g., SLCA and ELCA. However, LCA-based search methods depend heavily on hierarchical structures of XML data, which may result in meaningless answers. To obtain desired answers, a successful system should be able to (i) match a semantic entity for each keyword, (ii) discover the relationships of the matched entities, (iii) support efficient query processing, (iv) release users from having the knowledge of the XML content, and (v) visualize the search results. None of the existing XML keyword search systems completely meet the above requirements.In this paper, we design a system called SpiderXto completely solves the above challenges. We propose a query semantics Entity-Relationship Graph (ERG), which adopts the RDF subject-predicate-object semantics to capture the information of search entities along with associated attributes and the relationships between entities. SpiderX proposes a novel index structure, which has small space cost by combining the optimizations of column databases and the data compression schemes. In addition, SpiderX processes queries in a bottom-up way to achieve high performance, which is about 100X faster than the state-of-the-art algorithms. To demonstrate the high performance of SpiderX, we implement an online demo for SpiderX, which operating on three real-life datasets. The demo also provides (1) query auto-completion to guide users to formulate queries; and (2) visualization panel to display the query answers, which interacts with users by providing zoom-in and zoom-out exploration features. Demo link: http://chunbinlin.com/spiderx.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {237–241},
numpages = {5},
keywords = {semantic search, xml keyword search, entity-relationship},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054722,
author = {Liu, Wenqiang and Liu, Jun and Duan, Haimeng and Zhang, Jian and Hu, Wei and Wei, Bifan},
title = {TruthDiscover: Resolving Object Conflicts on Massive Linked Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054722},
doi = {10.1145/3041021.3054722},
abstract = {Considerable effort has been made to increase the scale of Linked Data. However, because of the openness of the Semantic Web and the ease of extracting Linked Data from semi-structured sources (e.g., Wikipedia) and unstructured sources, many Linked Data sources often provide conflicting objects for a certain predicate of a real-world entity. Existing methods cannot be trivially extended to resolve conflicts in Linked Data because Linked Data has a scale-free property. In this demonstration, we present a novel system called TruthDiscover, to identify the truth in Linked Data with a scale-free property. First, TruthDiscover leverages the topological properties of the Source Belief Graph to estimate the priori beliefs of sources, which are utilized to smooth the trustworthiness of sources. Second, the Hidden Markov Random Field is utilized to model interdependencies among objects for estimating the trust values of objects accurately. TruthDiscover can visualize the process of resolving conflicts in Linked Data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {243–246},
numpages = {4},
keywords = {linked data quality, linked data, object conflicts},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3059213,
author = {Lugmayr, Artur and Grenfeld, Adam and Zhang, Danjing Joy},
title = {Selected Advanced Data Visualizations: "The UX-Machine", Cultural Visualisation, Cognitive Big Data, and Communication of Health and Wellness Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3059213},
doi = {10.1145/3041021.3059213},
abstract = {The goal of this set of this demonstration presentation is to describe a set of visualizations that underline the importance of appropriate data visualizations in particular contexts. The goal is to showcase different types of visualizations, and illustrate how emerging media technology can be utilized for this purpose. First, we showcase "The UX-Machine", which is a tool for visualizing bio-feedback data; second, we illustrate a visualization of a cultural photographic collection; third, we present Cognitive Big Data as emerging new technology in the domain of Big Data, and fourth present visualization as a matter of communication and culture. The goal of this paper is to introduce and describe the key aspects of visualization on some concrete examples. The demonstrators should also illustrate the use of emerging media technology as part of advanced concepts for data visualization.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {247–251},
numpages = {5},
keywords = {visualization, big data, cognitive big data, affective computation, bio-feedback, user-experience, emotional computation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054720,
author = {Ma, Denghao and Chen, Yueguo and Chen, Jun and Du, Xiaoyong and Zhang, Xiangliang},
title = {ESearch: Incorporating Text Corpus and Structured Knowledge for Open Domain Entity Search},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054720},
doi = {10.1145/3041021.3054720},
abstract = {The paper introduces an open domain entity search system called ESearch, which aims at finding a list of relevant entities to an open domain entity search query (a natural language question). The system is built on top of a Wikipedia text corpus, as well as the structured DBPedia knowledge base. Entities are initially ranked by a model which effectively associates context matching (based on the contexts of entities in the unstructured text corpus) and category matching (based on the types of entities in the structured knowledge base). They are ranked further by a re-ranking component supported by blind feedback or user feedback on entities. We show that category matching is critical for the search performance and the re-ranking component can boost the performance largely. Category matching therefore needs some query entity types (especially specific entity types) as input. However, it is often hard for systems to detect specific entity types because users may not be familiar with how the types of desired entities are defined in the structured knowledge base. In ESearch, we design an effective ranking model of entity types to facilitate blind feedback and user feedback on desired entity types for category matching, so that users can effectively perform entity search without the need of explicitly providing any query entity types as inputs.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {253–256},
numpages = {4},
keywords = {information retrieval, type ranking, entity search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054728,
author = {Malmi, Eric and Rasa, Marko and Gionis, Aristides},
title = {AncestryAI: A Tool for Exploring Computationally Inferred Family Trees},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054728},
doi = {10.1145/3041021.3054728},
abstract = {Many people are excited to discover their ancestors and thus decide to take up genealogy. However, the process of finding the ancestors is often very laborious since it involves comparing a large number of historical birth records and trying to manually match the people mentioned in them. We have developed AncestryAI, an open-source tool for automatically linking historical records and exploring the resulting family trees. We introduce a record-linkage method for computing the probabilities of the candidate matches, which allows the users to either directly identify the next ancestor or narrow down the search. We also propose an efficient layout algorithm for drawing and navigating genealogical graphs. The tool is additionally used to crowdsource training and evaluation data so as to improve the matching algorithm. Our objective is to build a large genealogical graph, which could be used to resolve various interesting questions in the areas of computational social science, genetics, and evolutionary studies. The tool is openly available at: http://emalmi.kapsi.fi/ancestryai/.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {257–261},
numpages = {5},
keywords = {genealogy, family trees, record linkage, probabilistic modeling, graph drawing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054736,
author = {Patel, Pankesh and Gyrard, Amelie and Datta, Soumya Kanti and Ali, Muhammad Intizar},
title = {SWoTSuite: A Toolkit for Prototyping End-to-End Semantic Web of Things Applications},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054736},
doi = {10.1145/3041021.3054736},
abstract = {In this demonstration, we present our Semantic Web of Things~(SWoT) prototyping toolkit called SWoTSuite. It is a set of tools supporting an easy and fast prototyping of end-to-end SWoT applications. SWoTSuite facilitates - (i) automation of application development life-cycle, (ii) reducing the amount of time and effort required for developing WoT applications and (iii) an easy integration of semantic web technologies within WoT applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {263–267},
numpages = {5},
keywords = {semantic web, toolkit, semantic web of things, cyber-physical systems, internet of things, software engineering, web of things},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054723,
author = {Ryu, Woo-Jong and Lee, Jung-Hyun and Kim, Kang-Min and Lee, SangKeun},
title = {MeCurate: Personalized Curation Service Using a Tiny Text Intelligence},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054723},
doi = {10.1145/3041021.3054723},
abstract = {The necessity and importance of intelligent content curation have been demanding, as exemplified by Google Photos and Inbox. In this demo, we demonstrate a personalized curation service on a smartphone, called meCurate. By understanding implicit user interests from user smartphone usage data, meCurate intelligently organizes both in-device user content (e.g., SMSs and bookmarks) and external content (e.g., news articles crawled from The New York Times website), which are likely to match the inferred user's interests. In addition, meCurate retrieves semantically relevant in-device user content and external content to an explicit text or voice query. To this end, we utilize a tiny text intelligence which is suitable for smartphones with limited resources. Notably, meCurate works in a stand-alone, privacy-protecting manner without sending out any in-device personal data or content, resulting in a unique user experience.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {269–272},
numpages = {4},
keywords = {personalized curation, user understanding, tiny text intelligence, semantic search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054721,
author = {Spitz, Andreas and Almasian, Satya and Gertz, Michael},
title = {EVELIN: Exploration of Event and Entity Links in Implicit Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054721},
doi = {10.1145/3041021.3054721},
abstract = {Implicit networks that describe latent entity relations have been demonstrated to be valuable tools in information retrieval, knowledge extraction, and search in document collections. While such implicit relations offer less insight into the types of connection between entities than traditional knowledge bases, they are much easier to extract from unstructured textual sources. Furthermore, they allow the derivation of relationship strength between entities that can be used to identify and leverage important co-mentions, based on which complex constructs of semantically related entities can be assembled with ease. One example of such implicit networks are LOAD graphs, which encode the textual proximity of location-, organization-, actor-, and date-mentions in document collections for the exploration, identification and summarization of events and entity relations. Here, we present EVELIN as a graphical, web-based interface for the exploration of such implicit networks of entities on the example of a large-scale network constructed from the English Wikipedia. The interface is available for online use at http://evelin.ifi.uni-heidelberg.de/.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {273–277},
numpages = {5},
keywords = {entity ranking, latent network, summarization, entity network, knowledge graph, event extraction, search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252690,
author = {Sampson, Demetrios and White, Bebo and Bourdeau, Jacqueline and King, Irwin and Sari, Eunice},
title = {Session Details: Digital Learning Track},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Digital Learning Alternative Research Track Track Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054160,
author = {Dietze, Stefan and Taibi, Davide and Yu, Ran and Barker, Phil and d'Aquin, Mathieu},
title = {Analysing and Improving Embedded Markup of Learning Resources on the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054160},
doi = {10.1145/3041021.3054160},
abstract = {Web-scale reuse and interoperability of learning resources have been major concerns for the technology-enhanced learning community. While work in this area traditionally focused on learning resource metadata, provided through learning resource repositories, the recent emergence of structured entity markup on the Web through standards such as RDFa and Microdata and initiatives such as schema.org, has provided new forms of entity-centric knowledge, which is so far under-investigated and hardly exploited. The Learning Resource Metadata Initiative (LRMI) provides a vocabulary for annotating learning resources through schema.org terms. Although recent studies have shown markup adoption by approximately 30% of all Web pages, understanding of the scope, distribution and quality of learning resources markup is limited. We provide the first public corpus of LRMI extracted from a representative Web crawl together with an analysis of LRMI adoption on the Web, with the goal to inform data consumers as well as future vocabulary refinements through a thorough understanding of the use as well as misuse of LRMI vocabulary terms. While errors and schema misuse are frequent, we also discuss a set of simple heuristics which significantly improve the accuracy of markup, a prerequisite for reusing learning resource metadata sourced from markup.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {283–292},
numpages = {10},
keywords = {web markup, schema.org, lrmi, learning resources},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054163,
author = {Huang, Chieh-Yang and Chen, Mei-Hua and Ku, Lun-Wei},
title = {Towards a Better Learning of Near-Synonyms: Automatically Suggesting Example Sentences via Fill in the Blank},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054163},
doi = {10.1145/3041021.3054163},
abstract = {Language learners are confused by near-synonyms and often look for answers from the Web. However, there is little to aid them in sorting through the overwhelming load of information that is offered. In this paper, we propose a new research problem: suggesting example sentences for learning word distinctions. We focus on near-synonyms as the first step. Two kinds of one-class classifiers, the GMM and BiLSTM models, are used to solve fill-in-the-blank (FITB) questions and further to select example sentences which best differentiate groups of near-synonyms. Experiments are conducted on both an open benchmark and a private dataset for the FITB task. Experiments show that the proposed approach yields an accuracy of 73.05% and 83.59% respectively, comparable to state-of-the-art multi-class classifiers. Learner study further shows the results of the example sentence suggestion by the learning effectiveness and demonstrates the proposed model indeed is more effective in learning near-synonyms compared to the resource-based models.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {293–302},
numpages = {10},
keywords = {computer-assisted language learning, natural language processing, gmm, bilstm, data-driven language learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054159,
author = {Wang, Wei and Liu, Jiaying and Xia, Feng and King, Irwin and Tong, Hanghang},
title = {Shifu: Deep Learning Based Advisor-Advisee Relationship Mining in Scholarly Big Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054159},
doi = {10.1145/3041021.3054159},
abstract = {Scholars in academia are involved in various social relationships such as advisor-advisee relationships. The analysis of such relationship can provide invaluable information for understanding the interactions among scholars as well as providing many researcher-specific applications such as advisor recommendation and academic rising star identification. However, in most cases, high quality advisor-advisee relationship dataset is unavailable. To address this problem, we propose Shifu, a deep-learning-based advisor-advisee relationship identification method which takes into account both the local properties and network characteristics. In particular, we explore how to crawl advisor-advisee pairs from PhDtree project and extract their publication information by matching them with DBLP dataset as the experimental dataset. To the best of our knowledge, no prior effort has been made to address the scientific collaboration network features for relationship identification by exploiting deep learning. Our experiments demonstrate that the proposed method outperforms other state-of-the-art machine learning methods in precision (94%). Furthermore, we apply Shifu to the entire DBLP dataset and obtain a large-scale advisor-advisee relationship dataset.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {303–310},
numpages = {8},
keywords = {relation mining, coauthor network, scholarly big data, deep learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054168,
author = {Yang, Qian and de Melo, Gerard and Cheng, Yong and Wang, Sen},
title = {HiText: Text Reading with Dynamic Salience Marking},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054168},
doi = {10.1145/3041021.3054168},
abstract = {The staggering amounts of content readily available to us via digital channels can often appear overwhelming. While much research has focused on aiding people at selecting relevant articles to read, only few approaches have been developed to assist readers in more efficiently reading an individual text. In this paper, we present HiText, a simple yet effective way of dynamically marking parts of a document in accordance with their salience. Rather than skimming a text by focusing on randomly chosen sentences, students and other readers can direct their attention to sentences determined to be important by our system. For this, we rely on a deep learning-based sentence ranking method. Our experiments show that this results in marked increases in user satisfaction and reading efficiency, as assessed using TOEFL-style reading comprehension tests.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {311–319},
numpages = {9},
keywords = {text visualization, natural language semantics, text skimming},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054156,
author = {Wu, Runze and Xu, Guandong and Chen, Enhong and Liu, Qi and Ng, Wan},
title = {Knowledge or Gaming? Cognitive Modelling Based on Multiple-Attempt Response},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054156},
doi = {10.1145/3041021.3054156},
abstract = {Recent decades have witnessed the rapid growth of intelligent tutoring systems (ITS), in which personalized adaptive techniques are successfully employed to improve the learning of each individual student. However, the problem of using cognitive analysis to distill the knowledge and gaming factor from students learning history is still underexplored. To this end, we propose a Knowledge Plus Gaming Response Model (KPGRM) based on multiple-attempt responses. Specifically, we first measure the explicit gaming factor in each multiple-attempt response. Next, we utilise collaborative filtering methods to infer the implicit gaming factor of one-attempt responses. Then we model student learning cognitively by considering both gaming and knowledge factors simultaneously based on a signal detection model. Extensive experiments on two real-world datasets prove that KPGRM can model student learning more effectively as well as obtain a more reasonable analysis.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {321–329},
numpages = {9},
keywords = {context-aware web-based learning, gaming the system, intelligent tutoring systems, cognitive analysis, educational data analytics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252691,
author = {King, Irwin},
title = {Session Details: Session 2L - Digital Learning II},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054166,
author = {Zhang, Han and Sun, Maosong and Wang, Xiaochen and Song, Zhengyang and Tang, Jie and Sun, Jimeng},
title = {Smart Jump: Automated Navigation Suggestion for Videos in MOOCs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054166},
doi = {10.1145/3041021.3054166},
abstract = {Statistics show that, on average, each user of Massive Open Online Courses (MOOCs) uses 'jump-back' to navigate a course video for 2.6 times. By taking a closer look at the navigation data, we found that more than half of the jump-backs are due to the 'bad' positions of the previous jump-backs. In this work, employing one of the largest Chinese MOOCs, XuetangX.com, as the source for our research, we study the extent to which we can develop a methodology to understand the user intention and help the user alleviate this problem by suggesting the best position for a jumpback. We demonstrate that it is possible to accurately predict 90% of users' jump-back intentions in the real online system. Moreover, our study reveals several interesting patterns, e.g., students in nonscience courses tend to jump back from the first half of the course video, and students in science courses tend to replay for longer time.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {331–339},
numpages = {9},
keywords = {moocs, user intention, video navigation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054165,
author = {Chan, Hou Pong and King, Irwin},
title = {Leveraging Social Connections to Improve Peer Assessment in MOOCs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054165},
doi = {10.1145/3041021.3054165},
abstract = {With the advent of Massive Open Online Courses (MOOCs), students from all over the world can access to quality courses via a web browser. Due to their great convenience, a popular MOOC can easily attract tens of thousands of students to enroll. Hence, a challenging problem in MOOCs is to find an efficient way to grade a large scale of assignments. To address this problem, peer assessment was proposed to grade the assignments in a scalable way. In peer assessment, each student is asked to access a subset of his/her peers' assignments via a web interface, then all these peer grades are aggregated to predict a final grade for each submitted assignment. These peer grades are very noisy due to the fact that different students have different bias and reliability. Several probabilistic models were proposed to improve the accuracy of the predicted grades by explicitly modeling the bias and reliability of each student. However, existing methods assumed that all students are independent of each other while ignoring the social interactions among the students. In real life, students' grading bias are easily affected by their friends. For example, a student tends to have a tough grading standard if his/her friends are harsh graders. Following this intuition, we propose three probabilistic models for peer assessment by incorporating social connections to model the dependencies of bias among the students. Moreover, we evaluate our models in a new peer grading dataset, which is enhanced with the social information of users in the discussion forums of the MOOC platform. Experimental results show that our models improve the accuracy of the predicted grades by leveraging social connections of students.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {341–349},
numpages = {9},
keywords = {peer assessment, massive open online courses (moocs), social network},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054162,
author = {Nagrecha, Saurabh and Dillon, John Z. and Chawla, Nitesh V.},
title = {MOOC Dropout Prediction: Lessons Learned from Making Pipelines Interpretable},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054162},
doi = {10.1145/3041021.3054162},
abstract = {Dropout prediction in MOOCs is a well-researched problem where we classify which students are likely to persist or drop out of a course. Most research into creating models which can predict outcomes is based on student engagement data. Why these students might be dropping out has only been studied through retroactive exit surveys. This helps identify an important extension area to dropout prediction- how can we interpret dropout predictions at the student and model level? We demonstrate how existing MOOC dropout prediction pipelines can be made interpretable, all while having predictive performance close to existing techniques. We explore each stage of the pipeline as design components in the context of interpretability. Our end result is a layer which longitudinally interprets both predictions and entire classification models of MOOC dropout to provide researchers with in-depth insights of why a student is likely to dropout.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {351–359},
numpages = {9},
keywords = {machine learning, visualization, dropout, mooc},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054161,
author = {Ruip\'{e}rez-Valiente, Jos\'{e} A. and Joksimovi\'{c}, Srecko and Kovanovi\'{c}, Vitomir and Ga\v{s}evi\'{c}, Dragan and Mu\~{n}oz-Merino, Pedro J. and Delgado Kloos, Carlos},
title = {A Data-Driven Method for the Detection of Close Submitters in Online Learning Environments},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054161},
doi = {10.1145/3041021.3054161},
abstract = {Online learning has become very popular over the last decade. However, there are still many details that remain unknown about the strategies that students follow while studying online. In this study, we focus on the direction of detecting 'invisible' collaboration ties between students in online learning environments. Specifically, the paper presents a method developed to detect student ties based on temporal proximity of their assignment submissions. The paper reports on findings of a study that made use of the proposed method to investigate the presence of close submitters in two different massive open online courses. The results show that most of the students (i.e., student user accounts) were grouped as couples, though some bigger communities were also detected. The study also compared the population detected by the algorithm with the rest of user accounts and found that close submitters needed a statistically significant lower amount of activity with the platform to achieve a certificate of completion in a MOOC. These results confirm that the detected close submitters were performing some collaboration or even engaged in unethical behaviors, which facilitates their way into a certificate. However, more work is required in the future to specify various strategies adopted by close submitters and possible associations between the user accounts.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {361–368},
numpages = {8},
keywords = {online learning, algorithm, collaborative learning, educational data mining, academic dishonesty},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054157,
author = {Grawemeyer, Beate and Karoudis, Konstantinos and Magoulas, George and Pinto, Marta and Poulovassilis, Alexandra},
title = {Design and Evaluation of Adaptive Feedback to Foster ICT Information Processing Skills in Young Adults},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054157},
doi = {10.1145/3041021.3054157},
abstract = {This paper explores the provision of adaptive hints based on attainment levels in the context of supporting the development of young adults' ICT information processing skills. We describe the design of the LIBE VLE, particularly its personalisation and adaptation features, and a User Study undertaken with young adults at a vocational education centre. Using data collected through the LIBE VLE, we analyse the relationships between learners' accessing of hints, motivation, and performance. Results point to a positive effect of accessing of hints on students' perception of the LIBE VLE and their likelihood of using it again for further learning; and also a positive effect of students' interest in the course subject on their engagement and performance in course activities. These findings have important implications for supporting young adults in developing key competences necessary for integration into the workforce and for fostering self-regulated lifelong learning.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {369–377},
numpages = {9},
keywords = {adaptation, feedback, ict information processing skills},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252692,
author = {Saru, Eunice},
title = {Session Details: Session 3L - Digital Learning III},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054158,
author = {Peng, Jun and Sergis, Stylianos and Wang, Minhong and Sampson, Demetrios},
title = {Combining Smart Web-Based Learning Environments with Teaching and Learning Analytics to Support Reflection on Project-Based Programming Education},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054158},
doi = {10.1145/3041021.3054158},
abstract = {Project-based learning (PjBL) is a promising approach for supporting learning of computer programming by addressing the gap between the attainment of abstract knowledge and the application of this knowledge to authentic programming tasks. The World Wide Web has considerable potential to expand and improve PjBL environments. However, making implicit aspects of a programming task accessible to learners and instructors to support reflection and improvement can be challenging. This paper discusses the challenge of PjBL in programming education and outlines a set of key aspects and an analysis framework to inform design and analysis of PjBL programming in web-based environments, by exploiting the emerging field of Teaching and Learning Analytics. Based on the proposed analysis framework, the design of an empirical study is outlined, capitalizing on a novel web-based PjBL environment that makes complex cognitive processes accessible and affords the analysis of its effects on learning programming in multiple aspects.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {379–385},
numpages = {7},
keywords = {technology-enabled learning, teaching and learning analytics, computer programming, web-based learning, project-based learning, learning analytics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054155,
author = {Thongmak, Mathupayas},
title = {Flipping MIS Classroom by Peers: Gateway to Student's Engagement Intention},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054155},
doi = {10.1145/3041021.3054155},
abstract = {Flipped classroom is one approach of active learning leading to better students' learning, abilities, and academic performance. The aim of this study is to evaluate the effect of applying the flipped classroom approach to MIS course, to examine the antecedents of engagement intention after participating the flipped classroom by peers, and to guide key factors of success student presentations. The quasi-experimental retrospective pre-post design is adopted during the whole semester. Eight rounds of student presentations were conducted. Data were collected after each round. Descriptive statistics, t-test, simple linear regression, and multiple linear regression were used. The findings confirm the relationships among perceived usefulness, satisfaction, and engagement intention. There were significant differences among students' perceived usefulness and intention before and after applying the flipped activities. Audience students also suggest the proper settings for the flipped classroom by peers.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {387–396},
numpages = {10},
keywords = {perceived usefulness, education, flipped classroom, satisfaction, engagement intention, adoption},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054167,
author = {Atif, Yacine and Sergis, Stylianos and Sampson, Demetrios and Mathiason, Gunnar},
title = {A Cyberphysical Learning Approach for Digital Smart Citizenship Competence Development},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054167},
doi = {10.1145/3041021.3054167},
abstract = {Smart Cities have emerged as a global concept that argues for the effective exploitation of digital technologies to drive sustainable innovation and well-being for citizens. Despite the large investments being placed on Smart City infrastructure, however, there is still very scarce attention on the new learning approaches that will be needed for cultivating Digital Smart Citizenship competences, namely the competences which will be needed by the citizens and workforce of such cities for exploiting the digital technologies in creative and innovative ways for driving financial and societal sustainability. In this context, this paper introduces cyberphysical learning as an overarching model of cultivating Digital Smart Citizenship competences by exploiting the potential of Internet of Things technologies and social media, in order to create authentic blended and augmented learning experiences.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {397–405},
numpages = {9},
keywords = {learning design, cyberphysical systems, social net- works, internet of things., collaborative learn- ing, smart grid, smart city, digital smart citizenship, smart citizenship com- petences, learning technology},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054154,
author = {Newhouse, C. Paul and Tarricone, Pina},
title = {Using Pairwise Comparisons in the Online Social Moderation of Performance Assessment},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054154},
doi = {10.1145/3041021.3054154},
abstract = {Assessing the performance of a student involves some form of judgement, and where more than one assessor is involved this usually requires some form of moderation to ensure consistent and fair results. Often this involves meetings or communication between assessors, which is referred to as social moderation. This paper reports on a study that investigated the use of online technologies to support a form of social moderation of artworks submitted for assessment in a senior secondary school course in Western Australia. Online systems were used to facilitate communications and provide access to digital representations of the submissions along with assessment tools. In particular a pairwise comparison judging online tool was used. This approach to social moderation was tested in a realistic context involving a sample of 12 teachers from rural schools for whom face-to-face meetings would be difficult. The aim was to investigate whether the use of these online systems would support good moderation outcomes and valuable professional learning for those involved. The study found that this approach to online social moderation was feasible, and participants perceived that it had improved the consistency of their judgements because they had developed an improved understanding of the assessment criteria and standard of work. However, analysis of scores and reliability data suggested some were not adequately consistent, and it was likely that this was due to their inexperience in assessing such work. Therefore some changes to the processes of this form of online social moderation were recommended.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {407–414},
numpages = {8},
keywords = {online communications, online moderation, computer-supported assessment},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054164,
author = {Daud, Ali and Aljohani, Naif Radi and Abbasi, Rabeeh Ayaz and Lytras, Miltiadis D. and Abbas, Farhat and Alowibdi, Jalal S.},
title = {Predicting Student Performance Using Advanced Learning Analytics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054164},
doi = {10.1145/3041021.3054164},
abstract = {Educational Data Mining (EDM) and Learning Analytics (LA) research have emerged as interesting areas of research, which are unfolding useful knowledge from educational databases for many purposes such as predicting students' success. The ability to predict a student's performance can be beneficial for actions in modern educational systems. Existing methods have used features which are mostly related to academic performance, family income and family assets; while features belonging to family expenditures and students' personal information are usually ignored. In this paper, an effort is made to investigate aforementioned feature sets by collecting the scholarship holding students' data from different universities of Pakistan. Learning analytics, discriminative and generative classification models are applied to predict whether a student will be able to complete his degree or not. Experimental results show that proposed method significantly outperforms existing methods due to exploitation of family expenditures and students' personal information feature sets. Outcomes of this EDM/LA research can serve as policy improvement method in higher education.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {415–421},
numpages = {7},
keywords = {student performance prediction, educational data mining (edm), learning analytics (la), family expenditures, students personal information},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252693,
author = {de Freitas, Sara and Gibson, David and Masek, Martin and Boo, Ivan},
title = {Session Details: GSIE Track},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Games, Simulations and Immersive Environments Track Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054171,
author = {Beattie, Scott and Colbran, Stephen},
title = {From Phoenix Wright to Atticus Finch: Legal Simulation Games as an Aid to Self-Represented Litigants},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054171},
doi = {10.1145/3041021.3054171},
abstract = {This paper examines the feasibility of a courtroom simulation being used to assist self-represented litigants in learning basic advocacy skills. A review of legal and forensic mechanics in games, particularly the Phoenix Wright games, provides design roadmap for a courtroom learning simulation.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {425–428},
numpages = {4},
keywords = {simulation, self-represented litigants, advocacy, law},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054175,
author = {de Freitas, Sara and Gibson, David and Alvarez, Victor and Irving, Leah and Star, Kam and Charleer, Sven and Verbert, Katrien},
title = {How to Use Gamified Dashboards and Learning Analytics for Providing Immediate Student Feedback and Performance Tracking in Higher Education},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054175},
doi = {10.1145/3041021.3054175},
abstract = {With the wide use of the Internet and digital data sources, there has been a recent emergence of easy access to student data within learning management systems (LMS), grade data through student information systems (SIS) and broader sector data through benchmarking metrics and standards. Learning analytics on top of this data has introduced greater capabilities for improving student performance through immediate feedback. Current literature considers the role of dashboards for student performance and feedback, but few papers consider the efficacy of fast feedback to students or other ways that information can be fed back to learners. In this paper, we consider the work done by three leading groups addressing the impact of gamification in university education, with a specific focus on how data is presented to the learner, that is using elements such as points, levelling up, narrative and progression to scaffold learning. Results indicate increases in student motivation, engagement, satisfaction, retention and performance enhancements.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {429–434},
numpages = {6},
keywords = {serious games, game-based learning, learning analytics, dashboards, higher education},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054174,
author = {Kang, Ah Reum and Blackburn, Jeremy and Kwak, Haewoon and Kim, Huy Kang},
title = {I Would Not Plant Apple Trees If the World Will Be Wiped: Analyzing Hundreds of Millions of Behavioral Records of Players During an MMORPG Beta Test},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054174},
doi = {10.1145/3041021.3054174},
abstract = {In this work, we use player behavior during the closed beta test of the MMORPG ArcheAge as a proxy for an extreme situation: at the end of the closed beta test, all user data is deleted, and thus, the outcome (or penalty) of players' in-game behaviors in the last few days loses its meaning. We analyzed 270 million records of player behavior in the 4th closed beta test of ArcheAge. Our findings show that there are no apparent pandemic behavior changes, but some outlierswere more likely to exhibit anti-social behavior (e.g., player killing). We also found that contrary to the reassuring adage that ``Even if I knew the world would go to pieces tomorrow, I would still plant my apple tree,'' players abandoned character progression, showing a drastic decrease in quest completion, leveling, and ability changes at the end of the beta test.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {435–444},
numpages = {10},
keywords = {massively multiplayer online role playing game (mmorpg), closed beta test (cbt), online games, archeage},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054176,
author = {Park, Kunwoo and Cha, Meeyoung and Kwak, Haewoon and Chen, Kuan-Ta},
title = {Achievement and Friends: Key Factors of Player Retention Vary Across Player Levels in Online Multiplayer Games},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054176},
doi = {10.1145/3041021.3054176},
abstract = {Retaining players over an extended period of time is a long-standing challenge in game industry. Significant effort has been paid to understanding what motivates players enjoy games. While individuals may have varying reasons to play or abandon a game at different stages within the game, previous studies have looked at the retention problem from a snapshot view. This study, by analyzing in-game logs of 51,104 distinct individuals in an online multiplayer game, uniquely offers a multifaceted view of the retention problem over the players' virtual life phases. We find that key indicators of longevity change with the game level. Achievement features are important for players at the initial to the advanced phases, yet social features become the most predictive of longevity once players reach the highest level offered by the game. These findings have theoretical and practical implications for designing online games that are adaptive to meeting the players' needs.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {445–453},
numpages = {9},
keywords = {player level, online multiplayer games, longevity, virtual life trajectory, player retention},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054172,
author = {Shameli, Ali and Althoff, Tim and Saberi, Amin and Leskovec, Jure},
title = {How Gamification Affects Physical Activity: Large-Scale Analysis of Walking Challenges in a Mobile Application},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054172},
doi = {10.1145/3041021.3054172},
abstract = {Gamification represents an effective way to incentivize user behavior across a number of computing applications. However, despite the fact that physical activity is essential for a healthy lifestyle, surprisingly little is known about how gamification and in particular competitions shape human physical activity.Here we study how competitions affect physical activity. We focus on walking challenges in a mobile activity tracking application where multiple users compete over who takes the most steps over a predefined number of days. We synthesize our findings in a series of game and app design implications. In particular, we analyze nearly 2,500 physical activity competitions over a period of one year capturing more than 800,000 person days of activity tracking. We observe that during walking competitions, the average user increases physical activity by 23%. Furthermore, there are large increases in activity for both men and women across all ages, and weight status, and even for users that were previously fairly inactive. We also find that the composition of participants greatly affects the dynamics of the game. In particular, if highly unequal participants get matched to each other, then competition suffers and the overall effect on the physical activity drops significantly. Furthermore, competitions with an equal mix of both men and women are more effective in increasing the level of activities. We leverage these insights to develop a statistical model to predict whether or not a competition will be particularly engaging with significant accuracy. Our models can serve as a guideline to help design more engaging competitions that lead to most beneficial behavioral changes.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {455–463},
numpages = {9},
keywords = {gamification, physical activity, exercise, mobile application, walking, competition},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054170,
author = {Xue, Su and Wu, Meng and Kolen, John and Aghdaie, Navid and Zaman, Kazi A.},
title = {Dynamic Difficulty Adjustment for Maximized Engagement in Digital Games},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054170},
doi = {10.1145/3041021.3054170},
abstract = {Dynamic difficulty adjustment (DDA) is a technique for adaptively changing a game to make it easier or harder. A common paradigm to achieve DDA is through heuristic prediction and intervention, adjusting game difficulty once undesirable player states (e.g., boredom or frustration) are observed. Without quantitative objectives, it is impossible to optimize the strength of intervention and achieve the best effectiveness. In this paper, we propose a DDA framework with a global optimization objective of maximizing a player's engagement throughout the entire game. Using level-based games as our example, we model a player's progression as a probabilistic graph. Dynamic difficulty reduces to optimizing transition probabilities to maximize a player's stay time in the progression graph. We have successfully developed a system that applies this technique in multiple games by Electronic Arts, Inc., and have observed up to 9% improvement in player engagement with a neutral impact on monetization.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {465–471},
numpages = {7},
keywords = {progression model, player engagement optimization, dynamic difficulty adjustment},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054173,
author = {Sun, Xiaowen and Wang, Yafang and de Melo, Gerard and Gai, Wei and Shi, Yuliang and Zhao, Lu and Bian, Yulong and Liu, Juan and Yang, Chenglei and Meng, Xiangxu},
title = {Enabling Participatory Design of 3D Virtual Scenes on Mobile Devices},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054173},
doi = {10.1145/3041021.3054173},
abstract = {Designing 3D virtual scenes is essential for computer animation, computer game design, and virtual reality (VR) applications such as virtual museums. In this paper, we present a novel paradigm for participatory design of 3D virtual scenes on mobile devices. Designers and users are actively engaged in the design process so as to ensure that the results meet their needs with high standards of usability. Our new system allows the designers to construct an initial virtual scene via two tablet devices, one of which supports the scene assembly in a 2D window, while the other displays the corresponding 3D scene synchronously. Subsequently, the designers adapt the 3D scene based on real-time feedback of users exploring the virtual scene via a VR device, consisting of a smartphone with cardboard 3D glasses. The participants can then discuss how to further fine-tune the virtual scene by replaying the recorded footage of the user's experience process, interacting on their own respective tablets or smartphones. The system has been applied to the design of VR environments for virtual museums, residential decoration, firefighter training, and 3D games. Our user study suggests that this system not only increases the efficiency of the design process, but also gives rise to better designs.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {473–482},
numpages = {10},
keywords = {virtual scene modeling, multi-touch interfaces, user experience, participatory design},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252694,
author = {Serdyukov, Pavel and Walker, Andrew},
title = {Session Details: Industry &amp; Developers Track},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Industry Track Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054183,
author = {Yang, Longqi and Fang, Chen and Jin, Hailin and Hoffman, Matthew D. and Estrin, Deborah},
title = {Personalizing Software and Web Services by Integrating Unstructured Application Usage Traces},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054183},
doi = {10.1145/3041021.3054183},
abstract = {Users of software applications generate vast amounts of unstructured log-trace data. These traces contain clues to the intentions and interests of those users, but service providers may find it difficult to uncover and exploit those clues. In this paper, we propose a framework for personalizing software and web services by leveraging such unstructured traces. We use 6 months of Photoshop usage history and 7 years of interaction records from 67K Behance users to design, develop, and validate a user-modeling technique that discovers highly discriminative representations of Photoshop users; we refer to the model as cutilization-to-vector, util2vec. We demonstrate the promise of this approach for three sample applications: (1) a practical user-tagging system that automatically predicts areas of focus for millions of Photoshop users; (2) a two-phase recommendation model that enables cold-start personalized recommendations for many new Behance users who have Photoshop usage data, improving recommendation quality (Recall@100) by 21.2% over a popularity-based recommender; and (3) a novel inspiration engine that provides real-time personalized inspirations to artists. We believe that this work demonstrates the potential impact of unstructured usage-log data for personalization.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {485–493},
numpages = {9},
keywords = {user modeling, application usage, recommendation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055166,
author = {Zhang, Aston and Garcia-Pueyo, Lluis and Wendt, James B. and Najork, Marc and Broder, Andrei},
title = {Email Category Prediction},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055166},
doi = {10.1145/3041021.3055166},
abstract = {According to recent estimates, about 90% of consumer received emails are machine-generated. Such messages include shopping receipts, promotional campaigns, newsletters, booking confirmations, etc. Most such messages are created by populating a fixed template with a small amount of personalized information, such as name, salutation, reservation numbers, dates, etc. Web mail providers (Gmail, Hotmail, Yahoo) are leveraging the structured nature of such emails to extract salient information and use it to improve the user experience: e.g. by automatically entering reservation data into a user calendar, or by sending alerts about upcoming shipments. To facilitate these extraction tasks it is helpful to classify templates according to their category, e.g. restaurant reservations or bill reminders, since each category triggers a particular user experience.Recent research has focused on discovering the causal thread of templates, e.g. inferring that a shopping order is usually followed by a shipping confirmation, an airline booking is followed by a confirmation and then by a "ready to check in" message, etc. Gamzu et al. took this idea one step further by implementing a method to predict the template category of future emails for a given user based on previously received templates. The motivation is that predicting future emails has a wide range of potential applications, including better user experiences (e.g. warning users of items ordered but not shipped), targeted advertising (e.g. users that recently made a flight reservation may be interested in hotel reservations), and spam classification (a message that is part of a legitimate causal thread is unlikely to be spam).The gist of the Gamzu et al. approach is modeling the problem as a Markov chain, where the nodes are templates or temporal events (e.g. the first day of the month). This paper expands on their work by investigating the use of neural networks for predicting the category of emails that will arrive during a fixed-sized time window in the future. We consider two types of neural networks: multi-layer perceptrons (MLP), a type of feedforward neural network; and long short-term memory (LSTM), a type of recurrent neural network. For each type of neural network, we explore the effects of varying their configuration (e.g. number of layers or number of neurons) and hyper-parameters (e.g. drop-out ratio). We find that the prediction accuracy of neural networks vastly outperforms the Markov chain approach, and that LSTMs perform slightly better than MLPs. We offer some qualitative interpretation of our findings and identify some promising future directions.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {495–503},
numpages = {9},
keywords = {email, time series analysis, prediction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054200,
author = {Li, Liangyue and Jing, How and Tong, Hanghang and Yang, Jaewon and He, Qi and Chen, Bee-Chung},
title = {NEMO: Next Career Move Prediction with Contextual Embedding},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054200},
doi = {10.1145/3041021.3054200},
abstract = {With increased globalization and labor mobility, human resource reallocation across firms, industries and regions has become the new norm in labor markets. The emergence of massive digital traces of such mobility offers a unique opportunity to understand labor mobility at an unprecedented scale and granularity. While most studies on labor mobility have largely focused on characterizing macro-level (e.g., region or company) or micro-level (e.g., employee) patterns, the problem of how to accurately predict an employee's next career move (which company with what job title) receives little attention. This paper presents the first study of large-scale experiments for predicting next career moves. We focus on two sources of predictive signals: profile context matching and career path mining and propose a contextual LSTM model, NEMO, to simultaneously capture signals from both sources by jointly learning latent representations for different types of entities (e.g., employees, skills, companies) that appear in different sources. In particular, NEMO generates the contextual representation by aggregating all the profile information and explores the dependencies in the career paths through the Long Short-Term Memory (LSTM) networks. Extensive experiments on a large, real-world LinkedIn dataset show that NEMO significantly outperforms strong baselines and also reveal interesting insights in micro-level labor mobility.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {505–513},
numpages = {9},
keywords = {contextual lstm, embedding, career move},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054201,
author = {Zhai, Andrew and Kislyuk, Dmitry and Jing, Yushi and Feng, Michael and Tzeng, Eric and Donahue, Jeff and Du, Yue Li and Darrell, Trevor},
title = {Visual Discovery at Pinterest},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054201},
doi = {10.1145/3041021.3054201},
abstract = {Over the past three years Pinterest has experimented with several visual search and recommendation systems, from enhancing existing products such as Related Pins (2014), to powering new products such as Similar Looks (2015), Flashlight (2016), and Lens (2017). This paper presents an overview of our visual discovery engine powering these services, and shares the rationales behind our technical and product decisions such as the use of object detection and interactive user interfaces. We conclude that this visual discovery engine significantly improves engagement in both search and recommendation tasks.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {515–524},
numpages = {10},
keywords = {object detection, recommendation systems, convnets, visual search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054182,
author = {Li, Yixuan and Xu, Pingmei and Lagun, Dmitry and Navalpakkam, Vidhya},
title = {Towards Measuring and Inferring User Interest from Gaze},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054182},
doi = {10.1145/3041021.3054182},
abstract = {How can we reliably infer web users' interest and evaluate the content relevance when lacking active user interaction such as click behavior? In this paper, we investigate the relationship between mobile users' implicit interest inferred from attention metrics, such as eye gaze or viewport time, and explicit interest expressed by users. We present the first quantitative gaze tracking study using front-facing camera of mobile devices instead of specialized, expensive eye-tracking devices. We focus on multi-column digital media pages in Google Play Store that display 30+ items per page belonging to diverse categories. In such pages, we find significantly different distribution of gaze metrics on items that users rate as interesting vs. not. We leverage this insight by building a prediction model that is able to infer a user's interest ratings from the the non-click actions of the user. Our model is able to attain AUC of 90.32% in predicting user interest at an individual item level. In addition, our experiments on collection item re-ranking show how user gaze and viewport signals can be used to personalize item ranking on the collection page. Beyond understanding users' attention behavior in novel contexts such as multi-column digital media pages in Google Play Store, the findings in this study have implications for the design of a novel personalization and recommendation mechanism by (1) prioritizing items that are most likely of interest to users based on historical attention signals, and (2) prioritizing positions receiving significant portion of gaze attention.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {525–533},
numpages = {9},
keywords = {user attention, mobile phones, inference, user interest, personalization, eye-tracking},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054188,
author = {Karmaker Santu, Shubhra Kanti and Li, Liangda and Park, Dae Hoon and Chang, Yi and Zhai, Chengxiang},
title = {Modeling the Influence of Popular Trending Events on User Search Behavior},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054188},
doi = {10.1145/3041021.3054188},
abstract = {Understanding how users' search behavior is influenced by real world events is important both for social science research and for designing better search engines for users. In this paper, we study how to model the influence of events on user queries by framing it as a novel data mining problem. Specifically, given a text description of an event, we mine the search log data to identify queries that are triggered by it and further characterize the temporal trend of influence created by the same event on user queries. We solve this data mining problem by proposing computational measures that quantify the influence of an event on a query to identify triggered queries and then, proposing a novel extension of Hawkes process to model the evolutionary trend of the influence of an event on search queries. Evaluation results using news articles and search log data show that the proposed approach is effective for identification of queries triggered by events reported in news articles and characterization of the influence trend over time, opening up many interesting opportunities of applications such as comparative analysis of influential events and prediction of event-triggered queries by users.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {535–544},
numpages = {10},
keywords = {query log mining, trending events, search behavior, influence modeling},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054189,
author = {Lo, Caroline and Cheng, Justin and Leskovec, Jure},
title = {Understanding Online Collection Growth Over Time: A Case Study of Pinterest},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054189},
doi = {10.1145/3041021.3054189},
abstract = {A common feature of content discovery applications is the ability of users to save and organize digital items into collections, e.g., images into photo albums or songs into playlists. Understanding how these collections grow over time is important for user retention and collection as well as item recommendation. Here we study factors that affect collection growth over a long period of time. We conduct a large-scale longitudinal analysis of over 2.6 million collections, known as boards, on Pinterest, over a period of three years. We study the inter-event time distribution of pins saved to boards and find that it can be accurately described by a two-component lognormal mixture model. The mixture components reveal that board growth can be characterized by short-term fast-paced sprees of activity, and longer breaks between these sprees. Commonalities emerge in spree behavior; for example, sprees have consistent temporal dynamics and the content saved within the same spree is more focused compared to between sprees. Surprisingly, we observe that boards with longer initial sprees are less likely to have long-term growth. On the other hand, boards with more frequently occurring sprees continue growing for a longer time, and tend to have a larger size. Finally, we synthesize our findings into a series of predictive models which show that initial board evolution is a strong signal for long-term board growth in terms of size and lifespan. Overall, our research has important implications for the design of online content discovery applications and has immediate applications in user modeling and recommendation systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {545–554},
numpages = {10},
keywords = {content discovery application, pins, collections, content discovery, board growth, collection growth, pinterest},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054203,
author = {Kooti, Farshad and Subbian, Karthik and Mason, Winter and Adamic, Lada and Lerman, Kristina},
title = {Understanding Short-Term Changes in Online Activity Sessions},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054203},
doi = {10.1145/3041021.3054203},
abstract = {Online activity is characterized by regularities such as diurnal and weekly patterns, reflecting human circadian rhythms and work and leisure schedules. Using data from the online social networking site Facebook, we uncover temporal patterns at a much smaller time scale: within individual sessions. Longer sessions have different characteristics than shorter ones, and this distinction is already visible in the first minute of a person's session activity. This allows us to predict the ultimate length of his or her session and how much content the person will see. The length of the session and other factors are in turn predictive of when the individual will return. Within a session, the amount of time a person spends on different kinds of content depends on both the person's demographic attributes, such as age and the number of Facebook friends, and the length of the time elapsed since the start of the session. We also find that liking and commenting is very non-uniformly distributed between sessions. Predictions of session duration and activity can potentially be leveraged to more efficiently cache content, especially to mobile devices in places with poor communications infrastructure, in order to improve user online experience.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {555–563},
numpages = {9},
keywords = {prediction, information consumption, facebook, activity session},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054181,
author = {Yang, Carl and Zhong, Lin and Li, Li-Jia and Jie, Luo},
title = {Bi-Directional Joint Inference for User Links and Attributes on Large Social Graphs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054181},
doi = {10.1145/3041021.3054181},
abstract = {Users on social networks primarily do two things, connect to existing or new friends and exchange information. Recently, social media apps have become the primary information source for users to consume news stories. Users are inundated with a flood of information from social media networks shared by their friends and other content providers. For social media networks, it is important for us to study users' friendships and interests in order to best serve their need. However, given the nature of online applications, information on both sides is highly incomplete and noisy. Inspired by the well-known homophily phenomenon which found the two properties strongly interleaving, we propose to jointly learn them by leveraging their data redundancy and mutual reinforcement. Specifically, we exploit homophily by iteratively addressing smoothness on the graph in two directions, ie, from closeness to similarity (stronger links lead to more similar attributes), and vice versa. The two processes are done in a unified probabilistic framework through label propagation and graph construction. The refined user links and attributes are immediately useful for various tasks including link recommendation and content targeting on social networks.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {564–573},
numpages = {10},
keywords = {social network analysis, link prediction, attribute profiling},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054194,
author = {Kooti, Farshad and Grbovic, Mihajlo and Aiello, Luca Maria and Djuric, Nemanja and Radosavljevic, Vladan and Lerman, Kristina},
title = {Analyzing Uber's Ride-Sharing Economy},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054194},
doi = {10.1145/3041021.3054194},
abstract = {Uber is a popular ride-sharing application that matches people who need a ride (or riders) with drivers who are willing to provide it using their personal vehicles. Despite its growing popularity, there exist few studies that examine large-scale Uber data, or in general the factors affecting user participation in the sharing economy. We address this gap through a study of the Uber market that analyzes large-scale data covering 59 million rides which spans a period of 7 months. The data were extracted from email receipts sent by Uber collected on Yahoo servers, allowing us to examine the role of demographics (e.g., age and gender) on participation in the ride-sharing economy. In addition, we evaluate the impact of dynamic pricing (i.e., surge pricing) and income on both rider and driver behavior. We find that the surge pricing does not bias Uber use towards higher income riders. Moreover, we show that more homophilous matches (e.g., riders to drivers of a similar age) can result in higher driver ratings. Finally, we focus on factors that affect retention and use information from earlier rides to accurately predict which riders or drivers will become active Uber users.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {574–582},
numpages = {9},
keywords = {uber, sharing economy, user characterization, prediction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054202,
author = {Liu, David C. and Rogers, Stephanie and Shiau, Raymond and Kislyuk, Dmitry and Ma, Kevin C. and Zhong, Zhigang and Liu, Jenny and Jing, Yushi},
title = {Related Pins at Pinterest: The Evolution of a Real-World Recommender System},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054202},
doi = {10.1145/3041021.3054202},
abstract = {Related Pins is the Web-scale recommender system that powers over 40% of user engagement on Pinterest. This paper is a longitudinal study of three years of its development, exploring the evolution of the system and its components from prototypes to present state. Each component was originally built with many constraints on engineering effort and computational resources, so we prioritized the simplest and highest-leverage solutions. We show how organic growth led to a complex system and how we managed this complexity. Many challenges arose while building this system, such as avoiding feedback loops, evaluating performance, activating content, and eliminating legacy heuristics. Finally, we offer suggestions for tackling these challenges when engineering Web-scale recommender systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {583–592},
numpages = {10},
keywords = {learning to rank, engineering challenges, recommendation systems},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054198,
author = {Cheng, Justin and Lo, Caroline and Leskovec, Jure},
title = {Predicting Intent Using Activity Logs: How Goal Specificity and Temporal Range Affect User Behavior},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054198},
doi = {10.1145/3041021.3054198},
abstract = {People have different intents in using online platforms. They may be trying to accomplish specific, short-term goals, or less well-defined, longer-term goals. While understanding user intent is fundamental to the design and personalization of online platforms, little is known about how intent varies across individuals, or how it relates to their behavior. Here, we develop a framework for understanding intent in terms of goal specificity and temporal range. Our methodology combines survey-based methodology with an observational analysis of user activity. Applying this framework to Pinterest, we surveyed nearly 6000 users to quantify their intent, and then studied their subsequent behavior on the web site. We find that goal specificity is bimodal - users tend to be either strongly goal-specific or goal-nonspecific. Goal-specific users search more and consume less content in greater detail than goal-nonspecific users: they spend more time using Pinterest, but are less likely to return in the near future. Users with short-term goals are also more focused and more likely to refer to past saved content than users with long-term goals, but less likely to save content for the future. Further, intent can vary by demographic, and with the topic of interest. Last, we show that user's intent and activity are intimately related by building a model that can predict a user's intent for using Pinterest after observing their activity for only two minutes. Altogether, this work shows how intent can be predicted from user behavior.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {593–601},
numpages = {9},
keywords = {pinterest, goal setting, goal-directed behavior, user motivations},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054190,
author = {Rosenfeld, Nir and Mansour, Yishay and Yom-Tov, Elad},
title = {Predicting Counterfactuals from Large Historical Data and Small Randomized Trials},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054190},
doi = {10.1145/3041021.3054190},
abstract = {When a new treatment is considered for use, whether a pharmaceutical drug or a search engine ranking algorithm, a typical question that arises is, will its performance exceed that of the current treatment? The conventional way to answer this counterfactual question is to estimate the effect of the new treatment in comparison to that of the conventional treatment by running a controlled, randomized experiment. While this approach theoretically ensures an unbiased estimator, it suffers from several drawbacks, including the difficulty in finding representative experimental populations as well as the cost of running randomized trials. Moreover, such trials neglect the huge quantities of available control-condition data, which in principle can be utilized for the harder task of predicting individualized effects.In this paper, we propose a discriminative framework for predicting the outcomes of a new treatment from a large dataset of the control condition and data from a small (and possibly unrepresentative) randomized trial comparing new and old treatments. Our learning objective, which requires minimal assumptions on the treatments, models the relation between the outcomes of the different conditions. This allows us to not only estimate mean effects but also to generate individual predictions for examples outside the small randomized sample.We demonstrate the utility of our approach through experiments in three areas: search engine operation, treatments to diabetes patients, and market value estimation of houses. Our results demonstrate that our approach can reduce the number and size of the currently performed randomized controlled experiments, thus saving significant time, money and effort on the part of practitioners.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {602–609},
numpages = {8},
keywords = {supervised learning, randomized controlled trials, regression, classification, machine learning, rcts, counterfactual prediction, kernel methods, web search ranking},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054196,
author = {Abhishek, Vineet and Mannor, Shie},
title = {A Nonparametric Sequential Test for Online Randomized Experiments},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054196},
doi = {10.1145/3041021.3054196},
abstract = {We propose a nonparametric sequential test that aims to address two practical problems pertinent to online randomized experiments: (i) how to do a hypothesis test for complex metrics; (ii) how to prevent type 1 error inflation under continuous monitoring. The proposed test does not require knowledge of the underlying probability distribution generating the data. We use the bootstrap to estimate the likelihood for blocks of data followed by mixture sequential probability ratio test. We validate this procedure on data from a major online e-commerce website. We show that the proposed test controls type 1 error at any time, has good power, is robust to misspecification in the distribution generating the data, and allows quick inference in online randomized experiments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {610–616},
numpages = {7},
keywords = {a/b tests, sequential tests, the bootstrap},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054199,
author = {Chen, Albert C. and Fu, Xin},
title = {Data + Intuition: A Hybrid Approach to Developing Product North Star Metrics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054199},
doi = {10.1145/3041021.3054199},
abstract = {"You make what you measure" is a familiar mantra at data-driven companies. Accordingly, companies must be careful to choose North Star metrics that create a better product. Metrics fall into two general categories: direct count metrics such as total revenue and monthly active users, and nuanced quality metrics regarding value or other aspects of the user experience. Count metrics, when used exclusively as the North Star, might inform product decisions that harm user experience. Therefore, quality metrics play an important role in product development. We present a five-step framework for developing quality metrics using a combination of machine learning and product intuition. Machine learning ensures that the metric accurately captures user experience. Product intuition makes the metric interpretable and actionable. Through a case study of the Endorsements product at LinkedIn, we illustrate the danger of optimizing exclusively for count metrics, and showcase the successful application of our framework toward developing a quality metric. We show how the new quality metric has driven significant improvements toward creating a valuable, user-first product.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {617–625},
numpages = {9},
keywords = {endorsement, survey, reputation system, metric},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054197,
author = {Mehrotra, Rishabh and Anderson, Ashton and Diaz, Fernando and Sharma, Amit and Wallach, Hanna and Yilmaz, Emine},
title = {Auditing Search Engines for Differential Satisfaction Across Demographics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054197},
doi = {10.1145/3041021.3054197},
abstract = {Many online services, such as search engines, social media platforms, and digital marketplaces, are advertised as being available to any user, regardless of their age, gender, or other demographic factors. However, there are growing concerns that these services may systematically underserve some groups of users. In this paper, we present a framework for internally auditing such services for differences in user satisfaction across demographic groups, using search engines as a case study. We first explain the pitfalls of naively comparing the behavioral metrics that are commonly used to evaluate search engines. We then propose three methods for measuring latent differences in user satisfaction from observed differences in evaluation metrics. To develop these methods, we drew on ideas from the causal inference literature and the multilevel modeling literature. Our framework is broadly applicable to other online services, and provides general insight into interpreting their evaluation metrics.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {626–633},
numpages = {8},
keywords = {user satisfaction, internal auditing methods, search engine evaluation, user demographics, fairness},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054186,
author = {Babaioff, Moshe and Mansour, Yishay and Nisan, Noam and Noti, Gali and Curino, Carlo and Ganapathy, Nar and Menache, Ishai and Reingold, Omer and Tennenholtz, Moshe and Timnat, Erez},
title = {ERA: A Framework for Economic Resource Allocation for the Cloud},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054186},
doi = {10.1145/3041021.3054186},
abstract = {Cloud computing has reached significant maturity from a systems perspective, but currently deployed solutions rely on rather basic economics mechanisms that yield suboptimal allocation of the costly hardware resources. In this paper we present Economic Resource Allocation (ERA), a complete framework for scheduling and pricing cloud resources, aimed at increasing the efficiency of cloud resources usage by allocating resources according to economic principles. The ERA architecture carefully abstracts the underlying cloud infrastructure, enabling the development of scheduling and pricing algorithms independently of the concrete lower-level cloud infrastructure and independently of its concerns. Specifically, ERA is designed as a flexible layer that can sit on top of any cloud system and interfaces with both the cloud resource manager and with the users who reserve resources to run their jobs. The jobs are scheduled based on prices that are dynamically calculated according to the predicted demand. Additionally, ERA provides a key internal API to pluggable algorithmic modules that include scheduling, pricing and demand prediction. We provide a proof-of-concept software and demonstrate the effectiveness of the architecture by testing ERA over both public and private cloud systems -- Azure Batch of Microsoft and Hadoop/YARN. A broader intent of our work is to foster collaborations between economics and system communities. To that end, we have developed a simulation platform via which economics and system experts can test their algorithmic implementations.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {635–642},
numpages = {8},
keywords = {economics, cloud computing, reservations, dynamic pricing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054187,
author = {Dasgupta, Anirban and Kumar, Ravi and Sarl\'{o}s, Tam\'{a}s},
title = {Caching with Dual Costs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054187},
doi = {10.1145/3041021.3054187},
abstract = {Caching mechanisms in distributed and social settings face the issue that the items can frequently change, requiring the cached versions to be updated to maintain coherence. There is thus a trade-off between incurring cache misses on read requests and cache hits on update requests. Motivated by this we consider the following dual cost variant of the classical caching problem: each request for an item can be either a read or a write. If the request is read and the item is not in the cache, then a read-miss cost is incurred and if the request is write and the item is in the cache, then a write-hit cost is incurred. The goal is to design a caching algorithm that minimizes the sum of read-miss and write-hit costs. We study online and offline algorithms for this problem.For the online version of the problem, we obtain an efficient algorithm whose cost is provably close to near-optimal cost. This algorithm builds on online algorithms for classical caching and metrical task systems, using them as black boxes. For the offline version, we obtain an optimal deterministic algorithm that is based on a minimum cost flow. Experiments on real and synthetic data show that our online algorithm incurs much less cost compared to natural baselines, while utilizing cache even better; furthermore, they also show that the online algorithm is close to the offline optimum.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {643–652},
numpages = {10},
keywords = {caching, competitive analysis, distributed caching, hit-ratio, online algorithms},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054191,
author = {Bortnikov, Edward and Carmel, David and Golan-Gueta, Guy},
title = {Top-k Query Processing with Conditional Skips},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054191},
doi = {10.1145/3041021.3054191},
abstract = {This work improves the efficiency of dynamic pruning algorithms by introducing a new posting iterator that can skip large parts of the matching documents during top-k query processing. Namely, the conditional-skip iterator jumps to a target document while skipping all matching documents preceding the target that cannot belong to the final result list. We experiment with two implementations of the new iterator, and show that integrating it into representative dynamic pruning algorithms such as MaxScore, WAND, and Block Max WAND (BMW), reduces the document scoring overhead, and eventually the query latency.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {653–661},
numpages = {9},
keywords = {dynamic pruning, conditional-skip iterator, top-k query processing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054195,
author = {Liu, Xueqing and Zhai, Chengxiang and Han, Wei and Gungor, Onur},
title = {Numerical Facet Range Partition: Evaluation Metric and Methods},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054195},
doi = {10.1145/3041021.3054195},
abstract = {Faceted navigation is a very useful component in today's search engines. It is especially useful when user has an exploratory information need or prefer certain attribute values than others. Existing work has tried to optimize faceted systems in many aspects, but little work has been done on optimizing numerical facet ranges (e.g., price ranges of product). In this paper, we introduce for the first time the research problem on numerical facet range partition and formally frame it as an optimization problem. To enable quantitative evaluation of a partition algorithm, we propose an evaluation metric to be applied to search engine logs. We further propose two range partition algorithms that computationally optimize the defined metric. Experimental results on a two-month search log from a major e-Commerce engine show that our proposed method can significantly outperform baseline.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {662–671},
numpages = {10},
keywords = {faceted search, user search log, non-smooth optimization, information retrieval models},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054184,
author = {Aharon, Michal and Kagian, Amit and Somekh, Oren},
title = {Adaptive Online Hyper-Parameters Tuning for Ad Event-Prediction Models},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054184},
doi = {10.1145/3041021.3054184},
abstract = {Yahoo's native advertising (also known as Gemini native) is one of its fastest growing businesses, reaching a run-rate of several hundred Millions USD in the past year. Driving the Gemini native models that are used to predict both, click probability (pCTR) and conversion probability (pCONV), is OFFSET - a feature enhanced collaborative-filtering (CF) based event prediction algorithm. OFFSET is a one-pass algorithm that updates its model for every new batch of logged data using a stochastic gradient descent (SGD) based approach. As most learning algorithms, OFFSET includes several hyper-parameters that can be tuned to provide best performance for a given system conditions. Since the marketplace environment is very dynamic and influenced by seasonality and other temporal factors, having a fixed single set of hyper-parameters (or configuration) for the learning algorithm is sub-optimal.In this work we present an online hyper-parameters tuning algorithm, which takes advantage of the system parallel map-reduce based architecture, and strives to adapt the hyper-parameters set to provide the best performance at a specific time interval. Online evaluation via bucket testing of the tuning algorithm showed a significant 4.3% revenue lift overall traffic, and a staggering 8.3% lift over Yahoo Home-Page section traffic. Since then, the tuning algorithm was pushed into production, tuning both click- and conversion-prediction models, and is generating a hefty estimated revenue lift of 5% yearly for Yahoo Gemini native.The proposed tuning mechanism can be easily generalized to fit any learning algorithm that continuously learns on incoming streaming data, in order to adapt its hyper-parameters to temporal changes.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {672–679},
numpages = {8},
keywords = {map-reduce, ad ranking, native ads, hyper-parameters tuning, ad click-prediction, learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054185,
author = {Juan, Yuchin and Lefortier, Damien and Chapelle, Olivier},
title = {Field-Aware Factorization Machines in a Real-World Online Advertising System},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054185},
doi = {10.1145/3041021.3054185},
abstract = {Predicting user response is one of the core machine learning tasks in computational advertising. Field-aware Factorization Machines (FFM) have recently been established as a state-of-the-art method for that problem and in particular won two Kaggle challenges. This paper presents some results from implementing this method in a production system that predicts click-through and conversion rates for display advertising and shows that this method it is not only effective to win challenges but is also valuable in a real-world prediction system. We also discuss some specific challenges and solutions to reduce the training time, namely the use of an innovative seeding algorithm and a distributed learning mechanism.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {680–688},
numpages = {9},
keywords = {field-aware factorization machines, machine learning, performance advertising},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054192,
author = {Ling, Xiaoliang and Deng, Weiwei and Gu, Chen and Zhou, Hucheng and Li, Cui and Sun, Feng},
title = {Model Ensemble for Click Prediction in Bing Search Ads},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054192},
doi = {10.1145/3041021.3054192},
abstract = {Accurate estimation of the click-through rate (CTR) in sponsored ads significantly impacts the user search experience and businesses' revenue, even 0.1% of accuracy improvement would yield greater earnings in the hundreds of millions of dollars. CTR prediction is generally formulated as a supervised classification problem. In this paper, we share our experience and learning on model ensemble design and our innovation. Specifically, we present 8 ensemble methods and evaluate them on our production data. Boosting neural networks with gradient boosting decision trees turns out to be the best. With larger training data, there is a nearly 0.9% AUC improvement in offline testing and significant click yield gains in online traffic. In addition, we share our experience and learning on improving the quality of training.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {689–698},
numpages = {10},
keywords = {gbdt, dnn, model ensemble, click prediction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054193,
author = {Bron, Marc and Redi, Miriam and Lalmas, Mounia and Silvestri, Fabrizio and Evans, Huw and Chute, Mahlon},
title = {Friendly, Appealing or Both? Characterising User Experience in Sponsored Search Landing Pages},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054193},
doi = {10.1145/3041021.3054193},
abstract = {Many of today's websites have recognised the importance of mobile friendly pages to keep users engaged and to provide a satisfying user experience. However, next to the experience provided by the sites themselves, advertisements, when clicked, present users with landing pages that are not necessarily mobile friendly. We explore what type of features are able to characterise the mobile friendliness of sponsored search ad landing pages. To have a complete understanding of the mobile ad experience in terms of layout and visual appearance, we also explore the notion of the ad page aesthetic appeal. We design and collect annotations for both dimensions on a large set of ads, and find that mobile friendliness and aesthetics represent different notions. We perform a comprehensive study of the effectiveness of over 120 features on the tasks of friendliness and aesthetics prediction. We find that next to general page size, HTML, and resource usage based features, several features based on the visual composition of landing pages are important to determine mobile friendliness and aesthetics. We demonstrate the additional benefit of these various types of features by comparing against the mobile friendliness guidelines provided by W3C. Finally, we use our models to determine the state of landing page mobile friendliness and aesthetics on a large sample of advertisements of a major internet company.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {699–707},
numpages = {9},
keywords = {html, mobile friendliness, visual, w3c, aesthetic appeal, landing page, sponsored search, ad quality},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252695,
author = {Hamdi, Mohamed and Kim, Myunghwan and Lange, Rebecca and Alvarez, Victor},
title = {Session Details: PhD Symposium},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {PhD Symposium Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053374,
author = {Fang, Xiu Susie},
title = {Truth Discovery from Conflicting Multi-Valued Objects},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053374},
doi = {10.1145/3041021.3053374},
abstract = {Truth discovery is a fundamental research topic, which aims at identifying the true value(s) of objects of interest given the conflicting multi-sourced data. Although considerable research efforts have been conducted on this topic, we can still point out two significant issues unsolved: i) single-valued assumption, i.e., current methods assume only one true value for each object, while in reality objects with multiple true values widely exist; ii) sparse ground truth, i.e., current works evaluate and compare existing truth discovery methods based on datasets with limited ground truth. Therefore, the empirical studies might be biased and cannot legitimately validate the existing methods. In this PhD project, we propose a full-fledged graph-based model, SmartMTD (Smart Multi-valued Truth Discovery), which incorporates four important implications to conduct truth discovery for multi-valued objects. Two graphs are constructed and further used to derive two aspects of source reliability via random walk computations. We also present a general approach, which utilizes Markov chain models with Bayesian inference, for comparing the existing truth discovery methods and validate our approach without ground truth. Initial empirical studies on two real-world datasets show the effectiveness of SmartMTD.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {711–715},
numpages = {5},
keywords = {ground truth, performance evaluation, multi-valued objects, source relations, object popularity, truth discovery},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053375,
author = {Hube, Christoph},
title = {Bias in Wikipedia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053375},
doi = {10.1145/3041021.3053375},
abstract = {While studies have shown that Wikipedia articles exhibit quality that is comparable to conventional encyclopedias, research still proves that Wikipedia, overall, is prone to many different types of Neutral Point of View (NPOV) violations that are explicitly or implicitly caused by bias from its editors. Related work focuses on political, cultural and gender bias. We are developing an approach for detecting both explicit and implicit bias in Wikipedia articles and observing its evolution over time. Our approach is based on different factors of bias, with the most important ones being language style, editors, and citations. In this paper we present the approach, methodology and a first analysis.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {717–721},
numpages = {5},
keywords = {wikipedia; bias},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053376,
author = {Huang, Qiangjuan},
title = {Source Locating of Spreading Dynamics in Temporal Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053376},
doi = {10.1145/3041021.3053376},
abstract = {The topological structure of many real networks changes with time. Thus, locating the sources of a temporal network is a creative and challenging problem, as the enormous size of many real networks makes it unfeasible to observe the state of all nodes. In this paper, we propose an algorithm to solve this problem, named the backward temporal diffusion process. The proposed algorithm calculates the shortest temporal distance to locate the transmission source. We assume that the spreading process can be modeled as a simple diffusion process and by consensus dynamics. To improve the location accuracy, we also adopt four strategies to select which nodes should be observed by ranking their importance in the temporal network. Our paper proposes a highly accurate method for locating the source in temporal networks and is, to the best of our knowledge, a frontier work in this field. Moreover, our framework has important significance for controlling the transmission of diseases or rumors and formulating immediate immunization strategies.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {723–727},
numpages = {5},
keywords = {shortest paths, centrality, spreading dynamics, source locating, temporal network},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053377,
author = {Yadav, Deepika},
title = {Low-Cost Mobile Learning Solutions for Community Health Workers},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053377},
doi = {10.1145/3041021.3053377},
abstract = {Accredited Social Health Activists in India play a critical role in improving the access to healthcare services of rural populations. Despite their key contribution in Millennium Development Goals, they receive inadequate training and supervision. Traditional face to face training face challenges of infrastructure, management and cost. Existing research studies have highlighted the potential of alternative approaches e.g. mHealth for capacity building, however so far they mainly focus on providing job aids only.In this thesis, we are exploring mobile technologies for building a distance learning platform for ASHAs; which is low cost, feasible and relevant to the local context. We propose our system that combines Internet and IVR technology in a novel way such that it allows the trainers to connect to ASHAs through a conference call and host structured real time interactions via a smartphone application. To evaluate the system we have conducted a field deployment of four weeks in the Haryana state, India. In collaboration with an NGO we provided a training intervention to 20 ASHAs on Home Based Newborn Care and found positive outcomes in terms of learning gains and acceptability by the stakeholders. We aim to build a comprehensive mobile learning solution that utilizes the available resources efficiently in order to produce larger impact.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {729–734},
numpages = {6},
keywords = {training, chw, mhealth, ivr, mlearning, asha, peer learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053379,
author = {Popat, Kashyap},
title = {Assessing the Credibility of Claims on the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053379},
doi = {10.1145/3041021.3053379},
abstract = {In my doctoral research, I plan to address the problem of assessing the credibility of arbitrary claims made in natural-language text - in an open-domain setting. Automatic credibility assessment is a complex task depending upon many factors. To start with, we propose three factors which can help in assessing the credibility of textual claims: (i) the reliability of the web sources talking about the claim, (ii) the language style of the articles reporting the claim and, (iii) their stance (i.e., support or refute) towards the claim. In addition, we also focus on extracting user-interpretable explanations as evidence supporting the verdict of the assessment.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {735–739},
numpages = {5},
keywords = {text analytics, credibility analysis, rumor detection},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055365,
author = {Jin, Hongshan},
title = {Detection and Characterization of Influential Cross-Lingual Information Diffusion on Social Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055365},
doi = {10.1145/3041021.3055365},
abstract = {Social network services (SNSs) have become new global and multilingual information platforms due to their popularity. In SNSs with content-sharing functionality, such as "retweet" in Twitter and "share" in Facebook, posts are easily and quickly shared among users, and some of which can spread over different regions and languages. In this work, we first define the concept of cross-lingual information cascade on the basis of the main language of users and then try to characterize and detect those information cascades which can widely spread over different regions and languages on social networks. Understanding the cross-lingual characteristics of information cascades is not only valuable for sociological research, but also beneficial in the practical sense for those who want to know globally-influential events (e.g. ALS Ice Bucket Challenge and Terrorism in Europe) and estimate the impact of global advertisements on products (e.g. Samsung galaxy phone and a movie, Your Name). On the first attempt, we conducted statistical analysis of cascade growth and language distribution of information cascades with a large Twitter dataset. Based on the results, we propose a feature-based model, by which we successfully detected influential cross-lingual information cascades.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {741–745},
numpages = {5},
keywords = {cross-lingual cascades, multilingualism, information diffusion, cascade growth, information cascades},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053380,
author = {Zhang, Wen},
title = {Knowledge Graph Embedding with Diversity of Structures},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053380},
doi = {10.1145/3041021.3053380},
abstract = {In recent years, different web knowledge graphs, both free and commercial, have been created. Knowledge graphs use relations between entities to describe facts in the world. We engage in embedding a large scale knowledge graph into a continuous vector space. TransE, TransH, TransR and TransD are promising methods proposed in recent years and achieved state-of-the-art predictive performance. In this paper, we discuss that graph structures should be considered in embedding and propose to embed substructures called "one-relation-circle" (ORC) to further improve the performance of the above methods as they are unable to encode ORC substructures. Some complex models are capable of handling ORC structures but sacrifice efficiency in the process. To make a good trade-off between the model capacity and efficiency, we propose a method to decompose ORC substructures by using two vectors to represent the entity as a head or tail entity with the same relation. In this way, we can encode the ORC structure properly when apply it to TransH, TransR and TransD with almost the same model complexity of themselves. We conduct experiments on link prediction with benchmark dataset WordNet. Our experiments show that applying our method improves the results compared with the corresponding original results of TransH, TransR and TransD.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {747–753},
numpages = {7},
keywords = {substructure diversity, link prediction, knowledge graph embedding, knowledge graph completion},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252696,
author = {Chakrabarti, Soumen and Chen, Wei and Lalmas, Mounia},
title = {Session Details: Posters},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {WWW 2017 Posters Organization},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054249,
author = {Andrade, Rosita and Str\"{o}tgen, Jannik},
title = {All Dates Lead to Rome: Extracting and Explaining Temporal References in Street Names},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054249},
doi = {10.1145/3041021.3054249},
abstract = {Street names say a lot about a country's or region's identity. So far, they have mostly been analyzed manually and for very limited regions (e.g., a city), and hardly any large-scale studies have been performed automatically. A phenomenon not yet studied are street names with date references. These are of special interest as they can be used to commemorate important events in a region's history. In this paper, we present our approach to automatically extract such street names across the world. We analyze the dates' temporal and geographic distribution, and automatically gather potential explanations why specific dates occur in particular regions. We further describe date-Rome, a tool to interactively explore the streets, their distribution, and possible explanations.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {757–758},
numpages = {2},
keywords = {temporal tagging, map-based exploration, street names},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054223,
author = {Badjatiya, Pinkesh and Gupta, Shashank and Gupta, Manish and Varma, Vasudeva},
title = {Deep Learning for Hate Speech Detection in Tweets},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054223},
doi = {10.1145/3041021.3054223},
abstract = {Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {759–760},
numpages = {2},
keywords = {deep learning applications, hate speech detection, cnn, lstm, twitter},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054213,
author = {Bhattacharyya, Prantik and Spasojevic, Nemanja},
title = {Global Entity Ranking Across Multiple Languages},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054213},
doi = {10.1145/3041021.3054213},
abstract = {We present work on building a global long-tailed ranking of entities across multiple languages using Wikipedia and Freebase knowledge bases. We identify multiple features and build a model to rank entities using a ground-truth dataset of more than 10 thousand labels. The final system ranks 27 million entities with 75% precision and 48% F1 score. We provide performance evaluation and empirical evidence of the quality of ranking across languages, and open the final ranked lists for future research.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {761–762},
numpages = {2},
keywords = {entity extraction, knowledge base, entity ranking},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054235,
author = {Cai, Pengshan and Feng, Yansong and Jia, Yantao and Wang, Yuanzhuo and Jin, Xiaolong and Cheng, Xueqi},
title = {Coarse to Fine: Diffusing Categories in Wikipedia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054235},
doi = {10.1145/3041021.3054235},
abstract = {Automatic taxonomy construction aims to build a categorization system without human efforts. Traditional textual pattern based methods extract hyponymy relation in raw texts. However, these methods usually yield low precision and recall. In this paper, we propose a method to automatically find diffusing attributes to a category from Wikipedia infoboxes. We use the diffusing attribute to diffuse a coarse-grained category into several fine-grained subcategories and generate a finer-grained taxonomy. Experiments show our method can find proper diffusing attributes to categories across various domains.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {763–764},
numpages = {2},
keywords = {wikipedia, diffusing attribute, taxonomy, category},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054242,
author = {Cao, Qi and Shen, Huawei and Gao, Hao and Gao, Jinhua and Cheng, Xueqi},
title = {Predicting the Popularity of Online Content with Group-Specific Models},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054242},
doi = {10.1145/3041021.3054242},
abstract = {Predicting the popularity of online content is highly valuable in many applications and has been studied for several years. However, existing models either work in population level---all messages are assumed to follow similar popularity dynamics, lacking flexibility to capture the intrinsic complexity of popularity dynamics, or work in individual level---the popularity dynamics of messages are independent of each other, failing to leverage other messages to improve prediction accuracy. In this paper, we propose a divide and conquer framework for popularity prediction. We first divide messages into groups, anticipating each group of messages follow similar popularity dynamics, and then, we train a group-specific model for the messages of each group. Experiments demonstrate that group-specific models improve the population-level models by about 30% and outperform state-of-the-art individual-level model.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {765–766},
numpages = {2},
keywords = {information cascades, social media, popularity prediction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054211,
author = {Chatzakou, Despoina and Kourtellis, Nicolas and Blackburn, Jeremy and De Cristofaro, Emiliano and Stringhini, Gianluca and Vakali, Athena},
title = {Detecting Aggressors and Bullies on Twitter},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054211},
doi = {10.1145/3041021.3054211},
abstract = {Online social networks constitute an integral part of people's every day social activity and the existence of aggressive and bullying phenomena in such spaces is inevitable. In this work, we analyze user behavior on Twitter in an effort to detect cyberbullies and cuber-aggressors by considering specific attributes of their online activity using machine learning classifiers.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {767–768},
numpages = {2},
keywords = {twitter, crowdsourcing, cyber-aggression, cyberbullying},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054227,
author = {Chen, Cen and Zhao, Peilin and Li, Longfei and Zhou, Jun and Li, Xiaolong and Qiu, Minghui},
title = {Locally Connected Deep Learning Framework for Industrial-Scale Recommender Systems},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054227},
doi = {10.1145/3041021.3054227},
abstract = {In this work, we propose a locally connected deep learning framework for recommender systems, which reduces the complexity of deep neural network (DNN) by two to three orders of magnitude. We further extend the framework using the idea of the recently proposed Wide&amp;Deep model. Experiments on industrial-scale datasets show that our methods could achieve good results with much shorter runtime.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {769–770},
numpages = {2},
keywords = {locally-connected dnn, dnn, wide&amp;deep},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054250,
author = {Chen, Jiaoyan and Zipf, Alexander},
title = {DeepVGI: Deep Learning with Volunteered Geographic Information},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054250},
doi = {10.1145/3041021.3054250},
abstract = {Recently, deep learning has been widely studied to recognize ground objects with satellite imageries. However, finding ground truths especially for developing and rural areas is quite hard and manually labeling a large set of training data is costly. In this work, we propose an ongoing research named DeepVGI which aims at deeply learning from satellite imageries with the supervision of Volunteered Geographic Information (VGI). VGI data from OpenStreetMap (OSM) and a crowdsourcing mobile application named MapSwipe which allows volunteers to label images with buildings or roads for humanitarian aids are utilized. Meanwhile, an active learning framework with deep neural networks is developed by incorporating both VGI data with more complete supervision knowledge. Our experiments show that DeepVGI can achieve high building detection performance for humanitarian mapping in rural African areas.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {771–772},
numpages = {2},
keywords = {deep learning, openstreetmap, volunteered geographic information},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054251,
author = {Dalum Hansen, Niels and M\o{}lbak, K\r{a}re and Cox, Ingemar J. and Lioma, Christina},
title = {Time-Series Adaptive Estimation of Vaccination Uptake Using Web Search Queries},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054251},
doi = {10.1145/3041021.3054251},
abstract = {Estimating vaccination uptake is an integral part of ensuring public health. It was recently shown that vaccination uptake can be estimated automatically from web data, instead of slowly collected clinical records or population surveys. All prior work in this area assumes that features of vaccination uptake collected from the web are temporally regular. We present the first ever method to remove this assumption from vaccination uptake estimation: our method dynamically adapts to temporal fluctuations in time series web data used to estimate vaccination uptake. We show our method to outperform the state of the art compared to competitive baselines that use not only web data but also curated clinical data. This performance improvement is more pronounced for vaccines whose uptake has been irregular due to negative media attention (HPV-1 and HPV-2), problems in vaccine supply (DiTeKiPol), and targeted at children of 12 years old (whose vaccination is more irregular compared to younger children).},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {773–774},
numpages = {2},
keywords = {estimation of health event, online learning, regression trees, vaccination uptake, web data},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054234,
author = {Fang, Dezhi and Keezer, Matthew and Williams, Jacob and Kulkarni, Kshitij and Pienta, Robert and Chau, Duen Horng},
title = {Carina: Interactive Million-Node Graph Visualization Using Web Browser Technologies},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054234},
doi = {10.1145/3041021.3054234},
abstract = {We are working on a scalable, interactive visualization system, called Carina, for people to explore million-node graphs. By using latest web browser technologies, Carina offers fast graph rendering via WebGL, and works across desktop (via Electron) and mobile platforms. Different from most existing graph visualization tools, Carina does not store the full graph in RAM, enabling it to work with graphs with up to 69M edges. We are working to improve and open-source Carina, to offer researchers and practitioners a new, scalable way to explore and visualize large graph datasets.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {775–776},
numpages = {2},
keywords = {interactive graph visualization, webgl, web standards},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054212,
author = {Fang, Xiu Susie and Sheng, Quan Z. and Wang, Xianzhi and Ngu, Anne H.H.},
title = {Value Veracity Estimation for Multi-Truth Objects via a Graph-Based Approach},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054212},
doi = {10.1145/3041021.3054212},
abstract = {A fundamental issue with current truth discovery methods is that they generally assume only one true value for each object, while in reality objects may have multiple true values. In this work, we propose a graph-based approach, called SmartMTD, to relax this assumption in truth discovery. SmartMTD models two types of source relations with additional quantification to precisely estimate source reliability and to detect malicious agreement among sources for multi-truth discovery. In particular, two graphs are constructed based on the modeled source relations, which are further used to derive two aspects of source reliability via random walk computation.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {777–778},
numpages = {2},
keywords = {object popularity, multi-truth discovery, copy detection},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054215,
author = {Garimella, Kiran and Xiao, Han},
title = {Media Attention to Science},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054215},
doi = {10.1145/3041021.3054215},
abstract = {How has media attention to science changed over the past decade? Does media attention bring scientific attention too? To answer these questions, we collected media attention statistics from Altmetric.com for over 40,000 papers published in PNAS journal in the last 13 years. Our analysis reveals that (i) Media attention to science has slowly, but steadily increased over time, (ii) Media attention doesn't necessarily translate into scientific attention (citations) and, (iii) It is non-trivial to predict the amount of media attention a paper gets from attributes such as authors, author affiliations, abstract, and title.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {779–780},
numpages = {2},
keywords = {media attention, scientometrics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054255,
author = {Gilani, Zafar and Farahbakhsh, Reza and Crowcroft, Jon},
title = {Do Bots Impact Twitter Activity?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054255},
doi = {10.1145/3041021.3054255},
abstract = {The WWW has seen massive growth in population of automated programs (bots) for a variety of exploits on online social networks (OSNs). In this paper we extend on our previous work to study the affects of bots on Twitter. By setting up a bot account on Twitter and conducting analysis on a click logs dataset from our web server, we show that despite bots being in smaller numbers, they exercise a profound impact on content popularity and activity on Twitter.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {781–782},
numpages = {2},
keywords = {bot activity analysis, bot characterisation, information propagation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054231,
author = {Gruetze, Toni and Krestel, Ralf and Lazaridou, Konstantina and Naumann, Felix},
title = {What Was Hillary Clinton Doing in Katy, Texas?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054231},
doi = {10.1145/3041021.3054231},
abstract = {During the last presidential election in the United States, Twitter drew a lot of attention. This is because many leading persons and organizations, such as U.S. president Donald J. Trump, showed a strong affection to this medium. In this work we neglect the political contents and opinions shared on Twitter and focus on the question: Can we determine and track the physical location of presidential candidates based on posts in the Twittersphere?},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {783–784},
numpages = {2},
keywords = {tracking, twitter, location, politician, us election},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054206,
author = {Gudla, Suresh Kumar and Sahoo, Jitendra Kumar and Singh, Abhishek and Bose, Joy and Ahamed, Nazeer},
title = {A Systematic Framework to Optimize Launch Times of Web Apps},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054206},
doi = {10.1145/3041021.3054206},
abstract = {Web Applications typically have longer launch times compared to native applications, especially upon device boot up or if the browser is not already running in the background. In this paper, we propose an approach to speed up the launch time for web applications, by considering the user's usage of web applications and pre-launching the predicted web applications. We provide implementation details of our model and perform experiments on various web applications to measure the effectiveness of the framework for fast launch of the applications after the device boots.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {785–786},
numpages = {2},
keywords = {web apps, native apps, progressive web apps, launch time},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054208,
author = {Guo, Huifeng and Tang, Ruiming and Ye, Yunming and He, Xiuqiang},
title = {Holistic Neural Network for CTR Prediction},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054208},
doi = {10.1145/3041021.3054208},
abstract = {This paper proposes HNN, a holistic neural network structure for click-through rate (CTR) prediction in recommender systems. Empirically, equipped with HNN, the performance of deep neural networks for CTR prediction are improved on Criteo and Huawei App Store datasets.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {787–788},
numpages = {2},
keywords = {ctr prediction, deep learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054216,
author = {Guo, Jiahui and Yue, Bin and Xu, Guandong and Yang, Zhenglu and Wei, Jin-Mao},
title = {An Enhanced Convolutional Neural Network Model for Answer Selection},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054216},
doi = {10.1145/3041021.3054216},
abstract = {Answer selection is an important task in question answering (QA) from the Web. To address the intrinsic difficulty in encoding sentences with semantic meanings, we introduce a general framework, i.e., Lexical Semantic Feature based Skip Convolution Neural Network (LSF-SCNN), with several optimization strategies. The intuitive idea is that the granular representations with more semantic features of sentences are deliberately designed and estimated to capture the similarity between question-answer pairwise sentences. The experimental results demonstrate the effectiveness of the proposed strategies and our model outperforms the state-of-the-art ones by up to 3.5% on the metrics of MAP and MRR.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {789–790},
numpages = {2},
keywords = {convolutional neural network, question answering, answer selection},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054264,
author = {Han, Bo and Radford, Will and Cadilhac, Ana\"{\i}s and Harol, Art and Chisholm, Andrew and Hachey, Ben},
title = {Post-Edit Analysis of Collective Biography Generation},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054264},
doi = {10.1145/3041021.3054264},
abstract = {Text generation is increasingly common but often requires manual post-editing where high precision is critical to end users. However, manual editing is expensive so we want to ensure this effort is focused on high-value tasks. And we want to maintain stylistic consistency, a particular challenge in crowd settings. We present a case study, analysing human post-editing in the context of a template-based biography generation system. An edit flow visualisation combined with manual characterisation of edits helps identify and prioritise work for improving end-to-end efficiency and accuracy.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {791–792},
numpages = {2},
keywords = {collective intelligence, evaluation, text generation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054259,
author = {Hu, Xiping and Bai, Kun and Cheng, Jun and Deng, Jun-qi and Guo, Yanxiang and Hu, Bin and Krishnan, Arun Sai and Wang, Fei},
title = {MeDJ: Multidimensional Emotion-Aware Music Delivery for Adolescent},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054259},
doi = {10.1145/3041021.3054259},
abstract = {Music listening is an integral part of many adolescents? everyday lives, but it is also a time when adolescents are uniquely vulnerable. Emotional-oriented and avoidance through listening to unsuitable music may bring negative emotion to adolescents and increase the level of their depression. We propose MeDJ, a multidimensional emotion-aware music delivery application, which turns adolescents' music listening into a health and pleasure way. MeDJ aims at helping adolescents to improve emotional management and prevent depression. It is built on a cloud-based platform that enables adolescents and their peers collaboratively recommend suitable music to each other through smartphones. Prototype implementation and initial results of MeDJ have demonstrated its practicability for real-world deployment.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {793–794},
numpages = {2},
keywords = {cloud, mobile health application, emotion-aware},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054233,
author = {Huang, Hen-Hsen and Wen, Yu-Wei and Chen, Hsin-Hsi},
title = {Detection of False Online Advertisements with DCNN},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054233},
doi = {10.1145/3041021.3054233},
abstract = {In addition to opinion spam, the overstated or unproven information in false advertisements could also mislead customers while making purchasing decisions. A false-advertisement judgement system aims at recognizing and explaining the illegal false advertisements. In this paper, we incorporate the convolutional neural network (CNN) with word embeddings and syntactic features in the system. The recognition experiments show that Dependency-based CNN (DCNN) achieves F-scores of 86.77%, 93.18%, and 87.46% in the cosmetics, food, and drug datasets, respectively. Moreover, the explanation of illegality experiments shows the F-scores of 56.19%, 50.36%, and 62.06% in the three datasets. Our judgement system can contribute to different roles in the online advertising.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {795–796},
numpages = {2},
keywords = {convolutional neural network, opinion spam detection, overstated advertisement identification},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054257,
author = {Huang, Yu-Hsiang and Huang, Hen-Hsen and Chen, Hsin-Hsi},
title = {Identification of Homographic Pun Location for Pun Understanding},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054257},
doi = {10.1145/3041021.3054257},
abstract = {This paper introduces a novel framework for homographic pun location identification. Two observations, the existence of the support term and the preferred positions of the pun in context, are considered as crucial hints for pun identification. We first nominate the pun candidates, and then select the most probable one based on various strategies. Experimental results show the effectiveness of our method.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {797–798},
numpages = {2},
keywords = {pun understanding, computational humor, homographic},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054258,
author = {Hui, Kai and Yates, Andrew and Berberich, Klaus and de Melo, Gerard},
title = {Position-Aware Representations for Relevance Matching in Neural Information Retrieval},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054258},
doi = {10.1145/3041021.3054258},
abstract = {To deploy deep learning models for ad-hoc information retrieval, suitable representations of query-document pairs are needed. Such representations ought to capture all relevant information required to assess the relevance of a document for a given query, including uni-gram term overlap as well as positional information such as proximity and term dependencies. In this work, we investigate the use of similarity matrices that are able to encode such position-specific information. Extensive experiments on TREC Web Track data confirm that such representations can yield good results.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {799–800},
numpages = {2},
keywords = {neural information retrieval, similarity matrix, position-aware, representation, relevance matching},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054238,
author = {Kanojia, Vibhor and Maeda, Hideyuki and Togashi, Riku and Fujita, Sumio},
title = {Enhancing Knowledge Graph Embedding with Probabilistic Negative Sampling},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054238},
doi = {10.1145/3041021.3054238},
abstract = {Link Prediction using Knowledge graph embedding projects symbolic entities and relations into low dimensional vector space, thereby learning the semantic relations between entities.Among various embedding models, there is a series of translation-based models such as TransE[1], TransH[2], and TransR[3]. This paper proposes modifications in the TransR model to address the issue of skewed data which is common in real-world knowledge graphs. The enhancements enable the model to smartly generate corrupted triplets during negative sampling, which significantly improves the training time and performance of TransR.The proposed approach can be applied to other translation-based models.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {801–802},
numpages = {2},
keywords = {probabilistic negative sampling, transr, knowledge graph embedding},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054256,
author = {Kim, Sungchul and Malik, Sana and Lipka, Nedim and Koh, Eunyee},
title = {WimNet: Vision Search for Web Logs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054256},
doi = {10.1145/3041021.3054256},
abstract = {With the growing popularity of mobile devices, user web logs are more heterogeneous than ever, across an increased number of devices and websites. As a result, identifying users with similar usage patterns within these large sets of web logs is increasingly challenging and critical for personalization and user experience in many areas, from recommender systems to digital marketing.In this work, we explore the use of visual search for top-k user retrieval based on similar user behavior. We introduce a convolution neural network (WimNet) that learns latent representation from a set of web logs represented as images. Specifically, it contains two convolution layers take row- and column-wise convolutions to capture user behavior across multiple devices and websites and learns latent representation and reconstructs a transition matrix between user activities of given web logs. To evaluate our method, we conduct conventional top-k retrieval task on the simulated dataset, and the preliminary analysis results suggest that our method produces more accurate and robust results regardless of the complexity of query log.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {803–804},
numpages = {2},
keywords = {user behavior, cnn, top-k retrieval},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054217,
author = {Kim, Sunghwan Mac and Paris, Cecile and Power, Robert and Wan, Stephen},
title = {Distinguishing Individuals from Organisations on Twitter},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054217},
doi = {10.1145/3041021.3054217},
abstract = {Twitter is a popular public platform for individuals to share information and express opinions. It is also widely used as an active communication channel by many organisations. Analysis results about public opinion could thus be misrepresented and distorted if the posts generated by non-individuals are appropriately handled motivating the need to identify the type of user accounts for social media analytics. In this paper, we demonstrate the utility of a joint text and network representation for classifying if a profile belongs to an individual or organisation. Crucially, combining the two feature types has not been shown before for this task. Our experimental results show that performance gains are possible but only when using our novel adaptation of the Text-Associated DeepWalk(TADW) method.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {805–806},
numpages = {2},
keywords = {user classification, twitter, social network embeddings},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054237,
author = {Kim, Sunghwan Mac and Kageura, Kyo and McHugh, James and Nepal, Surya and Paris, C\'{e}cile and Robinson, Bella and Sparks, Ross and Wan, Stephen},
title = {Twitter Content Eliciting User Engagement: A Case Study on Australian Organisations},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054237},
doi = {10.1145/3041021.3054237},
abstract = {Social media has become an important communication platform for all kinds of organisations, ranging from government departments to companies. When using social media, organisations are often keen to maximise engagements from their target audiences, that is, create posts to which their audience will react by, for example, replying, retweeting or liking. In this paper, we investigate the factors that characterise the posts with which an audience engages. While other work has looked at such factors for Twitter posts at large, we account for the effect of the organisation type. We find that the type of organisation (e.g., financial vs. telecommunications) has an impact on the characteristics of the posts associated with audience engagement. This is important as it can provide guidance to organisations on content creation strategies to maximise engagement.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {807–808},
numpages = {2},
keywords = {social media engagement, australian organisations},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054220,
author = {Lee, Sang-Chul and Kim, Sang-Wook and Park, Sunju and Chae, Dong-Kyu},
title = {A Single-Step Approach to Recommendation Diversification},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054220},
doi = {10.1145/3041021.3054220},
abstract = {This paper addresses recommendation diversification. Existing diversification methods have a difficulty in dealing with the accuracy-diversity tradeoff. We propose a novel method to simultaneously optimize the user preference and diversity of k-items to be recommended.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {809–810},
numpages = {2},
keywords = {e-commerce, recommender system, diversification},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054219,
author = {Lee, Sang-Chul and Faloutsos, Christos and Chae, Dong-Kyu and Kim, Sang-Wook},
title = {On Detecting Frauds in Comparison-Shopping Services},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054219},
doi = {10.1145/3041021.3054219},
abstract = {In comparison-shopping services (CSS), there exist frauds who perform excessive clicks on a target item in order to boost the popularity of it. In this paper, we introduce the problem of detecting frauds in CSS and propose three anomaly scores designed based on click behaviors of users in CSS.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {811–812},
numpages = {2},
keywords = {fraud detection, user behavior analysis},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054241,
author = {Li, Hang and Wang, Haozheng and Yang, Zhenglu and Wei, Jin-Mao and Odagaki, Masato},
title = {Effective Strategies on Representing Information Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054241},
doi = {10.1145/3041021.3054241},
abstract = {Network representation is the basis of many applications and of extensive interest in various fields such as information retrieval, social network analysis, and recommendation systems. Majority of previous methods on network representation only considered incomplete aspects of the problem, such as link structure, node information, or partial integration. The present paper proposes a comprehensive network representation model, which seamlessly integrates the text information, node label, and first-order and second-order proximity of a network. The effectiveness of the introduced strategies is experimentally evaluated. Results demonstrate that our method is better than state-of-the-art techniques.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {813–814},
numpages = {2},
keywords = {representation learning, information network, classification},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054243,
author = {Li, Qiong and Zhang, Xiaowang and Feng, Zhiyong},
title = {PRSP: A Plugin-Based Framework for RDF Stream Processing},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054243},
doi = {10.1145/3041021.3054243},
abstract = {In this paper, we propose a plugin-based framework for RDF stream processing (PRSP). With this framework, we can apply SPARQL engines to process C-SPARQL queries with maintaining the high performance of those engines in a simple way. Taking advantage of PRSP, we can process large RDF streams in a distributed context via distributed SPARQL engines. Moreover, we can evaluate the performance and correctness of existing SPARQL engines in handling RDF streams in a united way, which amends the evaluation of them ranging from static RDF to dynamic RDF. Finally, we experimentally evaluate the performance and correctness of PRSP on YABench. The experiments show that PRSP can still maintain the high performance with SPARQL engines in RDF stream processing although there are some slight differences among them.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {815–816},
numpages = {2},
keywords = {sparql, c-sparql, rdf stream, rsp},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054207,
author = {Lian, Jianxun and Zhang, Fuzheng and Xie, Xing and Sun, Guangzhong},
title = {CCCFNet: A Content-Boosted Collaborative Filtering Neural Network for Cross Domain Recommender Systems},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054207},
doi = {10.1145/3041021.3054207},
abstract = {To overcome data sparsity problem, we propose a cross domain recommendation system named CCCFNet which can combine collaborative filtering and content-based filtering in a unified framework. We first introduce a factorization framework to tie CF and content-based filtering together. Then we find that the MAP estimation of this framework can be embedded into a multi-view neural network. Through this neural network embedding the framework can be further extended by advanced deep learning techniques.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {817–818},
numpages = {2},
keywords = {cross domain, recommendation system, neural network},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054205,
author = {Lin, Chunbin and Wang, Jianguo and Lu, Jiaheng},
title = {Location-Sensitive Query Auto-Completion},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054205},
doi = {10.1145/3041021.3054205},
abstract = {This paper studies the location-sensitive auto-completion problem. We propose an efficient algorithm SQA running on a native index combining both IR-tree and Trie index. The experiments on real-life datasets demonstrate that SQA outperforms baseline methods by one order of magnitude.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {819–820},
numpages = {2},
keywords = {spatial keyword search, auto-completion, location sensitive search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054254,
author = {Mehrotra, Rishabh and Kholy, Ahmed El and Zitouni, Imez and Shokouhi, Milad and Hassan, Ahmed},
title = {Identifying User Sessions in Interactions with Intelligent Digital Assistants},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054254},
doi = {10.1145/3041021.3054254},
abstract = {Search sessions have traditionally been considered as the focal unit of analysis for seeking behavioral insights from user interactions. While most session identification techniques have focused on the traditional web search setting; in this work, we instead consider user interactions with digital assistants (e.g. Cortana, Siri) and aim at identifying session boundary cut-offs. To our knowledge, this is one of the first studies investigating user interactions with a desktop based digital assistant. Historically, most user session identification strategies based on inactivity thresholds are either inherently arbitrary, or set at about 30 minutes. We postulate that such 30 minute thresholds may not be optimal for segregating user interactions with intelligent assistants into sessions. Instead, we model user-activity times as a Gaussian mixture model and look for evidence of a valley to identify optimal inter-activity thresholds for identifying sessions. Our results suggest a smaller threshold($sim$2 minutes) for session boundary cut-off in digital assistants than the traditionally used 30 minute threshold for web search engines.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {821–822},
numpages = {2},
keywords = {user sessions, digital assistants, mixture models},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054265,
author = {Mitra, Anasua and Awekar, Amit},
title = {On Low Overlap among Search Results of Academic Search Engines},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054265},
doi = {10.1145/3041021.3054265},
abstract = {Number of published scholarly articles is growing exponentially. To tackle this information overload, researchers are increasingly depending on niche academic search engines. Recent works have shown that two major general web search engines: Google and Bing, have high level of agreement in their top search results. In contrast, we show that various academic search engines have low degree of agreement among themselves. We performed experiments using 2500 queries over four academic search engines. We observe that overlap in search result sets of any combination of academic search engines is significantly low and in most of the cases the search result sets are mutually exclusive. We also discuss implications of this low overlap.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {823–824},
numpages = {2},
keywords = {search engine comparison, web mining, scholarly data},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054261,
author = {Mohd Pozi, Muhammad Syafiq and Kawai, Yukiko and Jatowt, Adam and Akiyama, Toyokazu},
title = {Sketching Linguistic Borders: Mobility Analysis on Multilingual Microbloggers},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054261},
doi = {10.1145/3041021.3054261},
abstract = {Twitter has been used for various kinds of sociological studies including also multi-lingual analysis. In this paper we study the phenomenon of multilingualism in Twitter from a novel viewpoint. We advance the existing studies by correlating user mobility and multilingualism. The results we show can be used for explaining the usage of languages based on user location and mobility.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {825–826},
numpages = {2},
keywords = {multilingual, microblogging, tourism, twitter},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054270,
author = {Mullick, Ankan and Maheshwari, Shivam and C., Soumya and Goyal, Pawan and Ganguly, Niloy},
title = {A Generic Opinion-Fact Classifier with Application in Understanding Opinionatedness in Various News Section},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054270},
doi = {10.1145/3041021.3054270},
abstract = {In this paper, we build a generic opinion-fact classifier to detect opinions and facts from online news articles and social media datasets such as Youtube comments and idiom hashtags. We further use this classification model to compare opinionatedness of various news article sections. The proposed classifier produces better results than the existing methods over four different datasets, and the opinion fraction of various sections of news articles provides very interesting patterns.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {827–828},
numpages = {2},
keywords = {text classification, opinion detection, fact detection},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054222,
author = {Nguyen, Hieu and Garimella, Kiran},
title = {Understanding International Migration Using Tensor Factorization},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054222},
doi = {10.1145/3041021.3054222},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {829–830},
numpages = {2},
keywords = {global migration twitter, migration social media},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054232,
author = {Prakash, Abhay and Agrawal, Parag and Narahari, Kedhar Nath and Agrawal, Puneet},
title = {Mining Unusual Search Behavior Related to Physical Events},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054232},
doi = {10.1145/3041021.3054232},
abstract = {Search logs of commercial search engines like Bing or Google reflect the topics of interest in humans at any given point of time. While many of these topics are predictable information needs, some are unusual and point to a curious human mind. In this paper, we propose a novel solution for mining unusual search behaviors triggered by some recent physical events using Bing search logs. Our algorithm successfully identified unusual search behaviors related to physical events during 2016. We define unusual-relatedness and use crowdsource judgment to evaluate quality of our results along with a qualitative analysis. Our results show a 9.5 times improvement over baseline.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {831–832},
numpages = {2},
keywords = {search logs, mapping unusual search behavior to event},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054266,
author = {Ru, Chengsen and Tang, Jintao and Li, Shasha and Wang, Ting},
title = {Syntactic Representation Learning for Open Information Extraction on Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054266},
doi = {10.1145/3041021.3054266},
abstract = {This paper proposes a representation learning based method to discover new relations between entities from web, which is more general than existing Open Information Extraction(OIE) methods. Given dependency sequences on the expandPath as input, a convolutional neural network(CNN) is adopted to learn the representation layer features of the syntactic dependency patterns which indicate the relations. Experimental results show that compared with the state-of-art OIE methods, the proposed method obviously improves recall without much expense of precision.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {833–834},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054252,
author = {Savov, Pavel and Jatowt, Adam and Nielek, Radoslaw},
title = {Towards Understanding the Evolution of the WWW Conference},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054252},
doi = {10.1145/3041021.3054252},
abstract = {The World Wide Web conference is a well-established and mature venue with an already long history. Over the years it has been attracting papers reporting many important research achievements centered around the Web. In this work we aim at understanding the evolution of WWW conference series by detecting crucial years and important topics. We propose a simple yet novel approach based on tracking the classification errors of the conference papers according to their predicted publication years.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {835–836},
numpages = {2},
keywords = {www, www research, evolution},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054263,
author = {Sawant, Uma and Gabale, Vijay and Subramanian, Anand},
title = {E-Fashion Product Discovery via Deep Text Parsing},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054263},
doi = {10.1145/3041021.3054263},
abstract = {Transforming unstructured text into structured form is important for fashion e-commerce platforms that ingest tens of thousands of fashion products every day. While most of the e-commerce product extraction research focuses on extracting a single product from the product title using known keywords, little attention has been paid to discovering potentially multiple products present in the listing along with their respective relevant attributes, and leveraging the entire title and description text for this purpose. We fill this gap and propose a novel composition of sequence labeling and multi-task learning as an end-to-end trainable deep neural architecture. We systematically evaluate our approach on one of the largest tagged datasets in fashion e-commerce consisting of 25K listings labeled at word-level. Given 23 labels, we discover label-values with F1 score of 92.2%. When applied to 2M listings, we discovered 2.6M fashion items and 9.5M attribute values.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {837–838},
numpages = {2},
keywords = {multi-task learning, product discovery, sequence labeling},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054253,
author = {Song, Yan and Lee, Chia-Jung},
title = {Embedding Projection for Query Understanding},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054253},
doi = {10.1145/3041021.3054253},
abstract = {Learning reliable embeddings requires large data and is not trivial to be adapted to specific tasks due to certain constraints. For queries, the lack of sufficient context can prohibit learning quality representations and thus effective query understanding. We propose to project embeddings from a source space learned with natural language into a target space on queries. The projection function is learned via an overlap vocabulary set shared by both source and target spaces. Experimental results show that both linear and nonlinear embedding projections can help query intent classification and query slot tagging, even when the amount of data used for learning the projection is limited.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {839–840},
numpages = {2},
keywords = {projection, word embeddings, query understanding},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054224,
author = {Subramanian, S. and Baldwin, Timothy and Brooke, Julian and Cohn, Trevor},
title = {Pairwise Webpage Coreference Classification Using Distant Supervision},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054224},
doi = {10.1145/3041021.3054224},
abstract = {A person or other entity is often associated with multiple URL endpoints on the web, motivating the task of determining whether a given pair of webpages is coreferent to a given entity. To strike a balance between unsupervised and supervised methods that require annotated data, we build a positive and unlabelled (PU) learning model, where we obtain positive examples using web search-based distant supervision. We evaluate our proposed approach using the SemEval-2007 WePS and ALTA-2016 shared task datasets.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {841–842},
numpages = {2},
keywords = {end-point disambiguation, webpage coreference, semi-supervised learning, distant supervision, pu learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054210,
author = {Taelman, Ruben and Verborgh, Ruben and De Nies, Tom and Mannens, Erik},
title = {PoDiGG: A Public Transport RDF Dataset Generator},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054210},
doi = {10.1145/3041021.3054210},
abstract = {A large amount of public transport data is made available by many different providers, which makes RDF a great method for integrating these datasets. Furthermore, this type of data provides a great source of information that combines both geospatial and temporal data. These aspects are currently undertested in RDF data management systems, because of the limited availability of realistic input datasets. In order to bring public transport data to the world of benchmarking, we need to be able to create synthetic variants of this data. In this paper, we introduce a dataset generator with the capability to create realistic public transport data. This dataset generator, and the ability to configure it on different levels, makes it easier to use public transport data for benchmarking with great flexibility.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {843–844},
numpages = {2},
keywords = {linked data, public transport, benchmark, dataset generator, rdf},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054204,
author = {Tagami, Yukihiro},
title = {Learning Extreme Multi-Label Tree-Classifier via Nearest Neighbor Graph Partitioning},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054204},
doi = {10.1145/3041021.3054204},
abstract = {Web scale classification problems, such as Web page tagging and E-commerce product recommendation, are typically regarded as multi-label classification with an extremely large number of labels. In this paper, we propose GPT, which is a novel tree-based approach for extreme multi-label learning. GPT recursively splits a feature space with a hyperplane at each internal node, considering approximate k-nearest neighbor graph on the label space. We learn the linear binary classifiers using a simple optimization procedure. We conducted evaluations on several large-scale real-world data sets and compared our proposed method with recent state-of-the-art methods. Experimental results demonstrate the effectiveness of our proposed method.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {845–846},
numpages = {2},
keywords = {extreme multi-label classification, approximate k-nearest neighbor graph},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054262,
author = {Togashi, Riku and Maeda, Hideyuki and Kanojia, Vibhor and Morimoto, Kousuke and Fujita, Sumio},
title = {Euclidean Image Embedding in View of Similarity Ranking in Auction Search by Image},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054262},
doi = {10.1145/3041021.3054262},
abstract = {We propose an Euclidean embedding image representation, which serves to rank auction item images through wide range of semantic similarity spectrum, in the order of the relevance to the given query image much more effective than the baseline method in terms of a graded relevance measure. Our method uses three stream deep convolutional siamese networks to learn a distance metric and we leverage search query logs of an auction item search of the largest auction service in Japan. Unlike previous approaches, we define the inter-image relevance on the basis of user queries in the logs used to search each auction item, which enables us to acquire the image representation preserving the features concerning user intents in real e-commerce world.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {847–848},
numpages = {2},
keywords = {euclidean embedding, auction search, search by image, search query logs},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054267,
author = {Wang, Bo and Sun, Yingjun and Han, Bo and Hou, Yuexian and Song, Dawei},
title = {Extending the Balance Theory by Measuring Bidirectional Opinions with Interactive Language},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054267},
doi = {10.1145/3041021.3054267},
abstract = {The signs of social relationship in balance theory is objective and undirected which cannot characterize participants' bidirectional subjective opinions on social relationships. By redefining the signs with the bidirectional opinions according to homogeneity principle, we extend the balance theory by measuring the opinions with interactive language. Initial experimental results on Enron emails shows that the extended model supports the homogeneity principle of balance theory and make it possible to use balance theory to predict the directed opinions besides undirected signs.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {849–850},
numpages = {2},
keywords = {opinions, balance theory, homogeneity, interactive language},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054244,
author = {Wang, Pengwei and Wang, Zhongyuan and Ji, Lei and Yan, Jun and Jin, Lianwen},
title = {Can Machines Intelligently Propose Novel and Reasonable Scientific Hypotheses?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054244},
doi = {10.1145/3041021.3054244},
abstract = {Machine intelligence is attracting increasing attention from both industry and academia. However, the problem of how to make machines innovate novel hypothesis is underexplored. Automatic hypothesis generation can effectively shorten research process. In this work, we try to build an embedding based genetic algorithm to learn "experience" from past data, mine latent semantic information, and then propose the new scientific hypotheses. To our best knowledge, we are the first who propose to use an embedding based genetic algorithm for scientific hypothesis generation. Experiments show that our method outperforms the state of the art.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {851–852},
numpages = {2},
keywords = {genetic algorithm, hypothesis generation, machine intelligence},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054230,
author = {Wang, Wei and Cui, Zixin and Gao, Tong and Yu, Shuo and Kong, Xiangjie and Xia, Feng},
title = {Is Scientific Collaboration Sustainability Predictable?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054230},
doi = {10.1145/3041021.3054230},
abstract = {This work aims to explore whether the sustainability of scientific collaboration including collaboration duration and collaboration times can be predicted. For this purpose, we propose a series of features including structural similarity indices, authorship properties, and research interests. Experimental results on a real-world dataset show that our proposed model outperforms baseline model by 10% in MAE. Our study may shed light on investigating scientific collaboration from the perspective of sustainability.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {853–854},
numpages = {2},
keywords = {sustainable collaboration, early stage prediction, scientific collaboration},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054226,
author = {Wu, Yingying and Liu, Yiqun and Su, Ning and Ma, Shaoping and Ou, Wenwu},
title = {Predicting Online Shopping Search Satisfaction and User Behaviors with Electrodermal Activity},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054226},
doi = {10.1145/3041021.3054226},
abstract = {Electrodermal activity (EDA) delineates positive and negative emotions, especially in the lower arousal range, which reflects small variations. This study derived formulas to extract features from the EDA graph and found they are effective to predict search satisfaction and explain mobile shopping behaviors including add to cart, purchase, and abandonment (added to cart without purchase). The best features found in the generalized linear mixed model with the binomial family agree with known physiological results. To the best of our knowledge, this study is the first to use physiological methods to study satisfaction and user behavior.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {855–856},
numpages = {2},
keywords = {physiological signals, satisfaction, mobile product search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054239,
author = {Xu, Chang and Chang, Kuiyu and Chua, Khee-Chin and Hu, Meishan and Gao, Zhenxiang},
title = {Large-Scale Wi-Fi Hotspot Classification via Deep Learning},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054239},
doi = {10.1145/3041021.3054239},
abstract = {We describe the problem of classifying hundreds of millions of Wi-Fi hotspots using only connection and user count characteristics. We use a combination of deep learning and frequency analysis. Specifically, Convolution Neural Networks (CNN) capture the spatio-temporal relationship between adjacent connection/user counts across a 24 hour\texttimes{}7 day matrix, while FFT (Fast Fourier Transforms) extract user and connection frequencies. Our production system has been deployed to classify 239 million hotspots in 12 hours on a SPARK 2.0 cluster, achieving close to 80% F1-score for binary classification.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {857–858},
numpages = {2},
keywords = {large-scale production, wi-fi hotspot classification, deep learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054268,
author = {Xu, Linchuan and Wei, Xiaokai and Cao, Jiannong and Yu, Philip S.},
title = {Embedding Identity and Interest for Social Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054268},
doi = {10.1145/3041021.3054268},
abstract = {Network embedding fills the gap of applying tuple-based data mining models to networked datasets through learning latent representations or embeddings. However, it may not be likely to associate latent embeddings with physical meanings just as the name, latent embedding, literally suggests. Hence, models built on embeddings may not be interpretable. In this paper, we thus propose to learn identity embeddings and interest embeddings, where user identity includes demographic and affiliation information, and interest is demonstrated by activities or topics users are interested in. With identity and interest information, we can make data mining models not only more interpretable, but also more accurate, which is demonstrated on three real-world social networks in link prediction and multi-task classification.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {859–860},
numpages = {2},
keywords = {data mining, social networks, network embeddings},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054269,
author = {Xu, Linchuan and Wei, Xiaokai and Cao, Jiannong and Yu, Philip S.},
title = {On Learning Mixed Community-Specific Similarity Metrics for Cold-Start Link Prediction},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054269},
doi = {10.1145/3041021.3054269},
abstract = {We study the cold-start link prediction problem where edges between vertices is unavailable by learning vertex-based similarity metrics. Existing metric learning methods for link prediction fail to consider communities which can be observed in many real-world social networks. Because different communities usually exhibit different intra-community homogeneities, learning a global similarity metric is not appropriate. In this paper, we thus propose to learn community-specific similarity metrics via joint community detection. Experiments on three real-world networks show that the intra-community homogeneities can be well preserved, and the mixed community-specific metrics perform better than a global similarity metric in terms of prediction accuracy.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {861–862},
numpages = {2},
keywords = {link prediction, data mining, metric learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054248,
author = {Yang, Xiao and Deng, Tao and Guo, Zhi and Ding, Zongyao},
title = {Advertising Keyword Recommendation Based on Supervised Link Prediction in Multi-Relational Network},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054248},
doi = {10.1145/3041021.3054248},
abstract = {In the sponsored search system, advertisers bid on keywords that are related to their products or services to participate in repeated auctions and display their ads on the search result pages. Since there is a huge inventory of possible terms, instructive keyword recommendation is an important component to help advertisers optimize their campaigns and improve ad monetization. In this paper, by constructing a heterogeneous network which contains four types of links between advertisers and keywords based on different data resources and mining complex representations of network structure and task-guided attributes of nodes, we propose an approach to keyword recommendation based on supervised link prediction in multi-relational network. This method can retrieve ample candidates and provide informative ranking scores for recommended list of keywords, experimental results with real sponsored search data validate the effectiveness of the proposed algorithm in producing valuable keywords for advertisers.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {863–864},
numpages = {2},
keywords = {link prediction, keyword recommendation, network mining, sponsored search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054240,
author = {Yue, Bin and Gui, Min and Guo, Jiahui and Yang, Zhenglu and Wei, Jin-Mao and You, Shaodi},
title = {An Effective Framework for Question Answering over Freebase via Reconstructing Natural Sequences},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054240},
doi = {10.1145/3041021.3054240},
abstract = {Question answering over knowledge bases has rapidly developed with the continuous expansion of resources. However, how to match the natural language question to the structured answer entities in the knowledge bases remains a major challenge. In this paper, we propose an effective framework that bridges the gap between the given question and the answer entities, by reconstructing the intermediate natural sequences on the basis of the entities and relations in knowledge bases. The intuitive idea is that these intermediate sequences may encode rich semantic information that can identify the candidate answer entities. Experimental evaluation is conducted on a benchmark dataset WebQuestions. Results demonstrate the effectiveness of our proposed framework, i.e., it outperforms state-of-the-art models by up to 6.8% in terms of F1 score.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {865–866},
numpages = {2},
keywords = {cnn, question answering, knowledge base},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054214,
author = {Zang, Chengxi and Cui, Peng and Song, Chaoming and Faloutsos, Christos and Zhu, Wenwu},
title = {Quantifying Structural Patterns of Information Cascades},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054214},
doi = {10.1145/3041021.3054214},
abstract = {Information cascades are ubiquitous in both physical society and online social media, taking on large variations in structures, dynamics and semantics. Although there has been much progress on understanding the dynamics and semantics of information cascades, little is known about their structural patterns. In this paper, we explore a large-scale dataset including 432 million information cascades with explicit records of spreading traces. We find that the structural complexity of information cascades is far beyond the previous conjectures. We first propose seven-dimensional metrics, which reflect size and spreading orientation aspects, to quantify the structural characteristics of millions of information cascades. Further, we analyze the correlations of these metrics, finding some brand new structure patterns of information cascades, potentially providing insights into intrinsic mechanisms governing information spreading in nature and new models to forecast as well as to impose good control over information cascades in real applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {867–868},
numpages = {2},
keywords = {information cascades, social networks, structures},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054247,
author = {Zhang, Fan and Shuai, Yingbin and Lin, Siyuan and Li, Xuan and Jiang, Hao and Yao, Cheng and Ying, Fangtian and Lin, Minneng},
title = {A Study of How List Format Influences the Visual Search Performance},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054247},
doi = {10.1145/3041021.3054247},
abstract = {Previous research has shown that format design has an impact on the usability of listing pages. This study investigated the effects of specific list presentation format on visual search performance and subjective satisfaction in e-commerce listing pages. At first, we found seven important commodity features for consumers through pre-study. Then, an eye tracking study was conducted to record the visual search for target items and cognitive workload based on three different list formats (Vertical Format/T Format/Block format) in e-commerce websites. The results suggested that list format could significantly influence the visual search performance and satisfaction. The efficiency of Vertical format and T format is higher than block format. Designers could get some valid references from this result when they are designing listing pages.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {869–870},
numpages = {2},
keywords = {list format, listing pages, cognitive load, visual search, user satisfaction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054236,
author = {Zhang, Fan and Lin, Siyuan and Li, Xuan and Shuai, Yingbin and Jiang, Hao and Yao, Cheng and Ying, Fangtian and Gao, Feng},
title = {Navigation Configuration and Placement Influences the Visual Search Efficiency and Preference},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054236},
doi = {10.1145/3041021.3054236},
abstract = {As the basic and ubiquitous elements of interfaces, navigation is used to search target information items. Many prior research has shown that how does the navigation placement influence users' visual search efficiency and preference, and owing to the format of navigation is hierarchical navigation in most of e-commerce websites today. So designers need to consider about the navigation configuration. To investigate the effects of navigation design on usersv experience in e-commerce websites, we performed an experimental study to better understand what kind of two-level hierarchical menu layout users preferred, and two factors we controlled were configuration and placement. These data indicate that the manual placement could significantly influence users' preference. And the influence of configuration is significant with navigation placed on the top or left.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {871–872},
numpages = {2},
keywords = {subjective preference, cognitive load, navigation placement and configuration, visual search},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054246,
author = {Zhang, Mingyue and Chen, Renhai and Zhang, Xiaowang and Feng, Zhiyong and Rao, Guozheng and Wang, Xin},
title = {Intelligent RDD Management for High Performance In-Memory Computing in Spark},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054246},
doi = {10.1145/3041021.3054246},
abstract = {Spark is a pervasively used in-memory computing framework in the era of big data, and can greatly accelerate the computation speed by wrapping the accessed data as resilient distribution datasets (RDDs) and storing these datasets in the fast accessed main memory. However, the space of main memory is limited, and Spark does not provide an intelligent mechanism to store reasonable RDDs in the limited memory. In this paper, we propose a fine-grained RDD checkpointing and kick-out selection strategy, by which Spark can intelligently select the reasonable RDDs to maximize the memory usage. The experiment is conducted on a server with four nodes. Experimental results demonstrate that the proposed techniques can effectively accelerate the execution speed.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {873–874},
numpages = {2},
keywords = {rdd, checkpointing, spark, intelligent},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054260,
author = {Zhang, Xiaowang},
title = {On the Primitivity of SPARQL 1.1 Operators},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054260},
doi = {10.1145/3041021.3054260},
abstract = {The paper studies the primitivity of the eleven basic operators used in the SPARQL 1.1 query language. This paper shows that the six operators BIND, FILTER, GRAPH, property path, SELECT, and VALUES are primitive while the left five operators AND, EXISTS, MINUS, OPT, and UNION, are not primitive. It is surprised that OPT and UNION which are primitive in SPARQL 1.0 become no longer primitive in SPARQL 1.1.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {875–876},
numpages = {2},
keywords = {rdf databases, expressive power, primitive operator, sparql 1.1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054228,
author = {Zhang, Xinbo and Zou, Lei},
title = {Improving the Precision of RDF Question/Answering Systems: A Why Not Approach},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054228},
doi = {10.1145/3041021.3054228},
abstract = {Given a natural language question qNL over an RDF dataset D, an RDF Question/Answering (Q/A) system first translatesqNL into a SPARQL query graph Q and then evaluates Q over the underlying knowledge graph to figure out the answers Q(D). However, due to the challenge of understanding natural language questions and the complexity of linking phrases with specific RDF items (e.g., entities and predicates), the translated query graph Q may be incorrect, leading to some wrong or missing answers. In order to improve the system's precision, we propose a self-learning solution based on the users' feedback over Q(D. Specifically, our method automatically refines the SPARQL query Q into a new query graph Q′ with minimum modifications (over the original query Q). The new query will fix the errors and omissions of the query results. Furthermore, each amendment will also be used to improve the precision in answering subsequent natural language questions.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {877–878},
numpages = {2},
keywords = {entity resolution, interaction, rdf, graph database, paraphrase, question answering},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054225,
author = {Zhou, Jun and Cui, Qing and Li, Xiaolong and Zhao, Peilin and Qu, Shenquan and Huang, Jun},
title = {PSMART: Parameter Server Based Multiple Additive Regression Trees System},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054225},
doi = {10.1145/3041021.3054225},
abstract = {In this paper, we describe a Parameter Server based Multiple Additive Regression Trees system, or PSMART for short. Empirically, PSMART scales MART to hundreds of billions of samples and thousands of features in production.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {879–880},
numpages = {2},
keywords = {xgboost, mart, lambdamart, parameter server},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054229,
author = {Zhuang, Fuzhen and Zhou, Yingmin and Zhang, Fuzheng and Ao, Xiang and Xie, Xing and He, Qing},
title = {Sequential Transfer Learning: Cross-Domain Novelty Seeking Trait Mining for Recommendation},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054229},
doi = {10.1145/3041021.3054229},
abstract = {Recent studies in psychology suggest that novelty-seeking trait is highly related to consumer behavior, which has a profound business impact on online recommendation. This paper studies the problem of mining novelty seeking trait across domains to improve the recommendation performance in target domain. We propose an efficient model, CDNST, which significantly improves the recommendation performance by transferring the knowledge from auxiliary source domain. We conduct extensive experiments on three domain datasets crawled from Douban (www.douban.com) to demonstrate the effectiveness of the proposed model. Moreover, we find that the property of sequential data affects the performance of CDNST.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {881–882},
numpages = {2},
keywords = {recommendation novelty-seeking trait transfer learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054221,
author = {Zong, Shi and Kveton, Branislav and Berkovsky, Shlomo and Ashkan, Azin and Vlassis, Nikos and Wen, Zheng},
title = {Does Weather Matter? Causal Analysis of TV Logs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054221},
doi = {10.1145/3041021.3054221},
abstract = {Weather affects our mood and behaviors, and many aspects of our life. When it is sunny, most people become happier; but when it rains, some people get depressed. Despite this evidence and the abundance of data, weather has mostly been overlooked in the machine learning and data science research. This work presents a causal analysis of how weather affects TV watching patterns. We show that some weather attributes, such as pressure and precipitation, cause major changes in TV watching patterns. To the best of our knowledge, this is the first large-scale causal study of the impact of weather on TV watching patterns.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {883–884},
numpages = {2},
keywords = {weather, causality},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054209,
author = {Zou, Bin and Lampos, Vasileios and Liang, Shangsong and Ren, Zhaochun and Yilmaz, Emine and Cox, Ingemar},
title = {A Concept Language Model for Ad-Hoc Retrieval},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054209},
doi = {10.1145/3041021.3054209},
abstract = {We propose an extension to language models for information retrieval. Typically, language models estimate the probability of a document generating the query, where the query is considered as a set of independent search terms. We extend this approach by considering the concepts implied by both the query and words in the document. The model combines the probability of the document generating the concept embodied by the query, and the traditional language model probability of the document generating the query terms. We use a word embedding space to express concepts. The similarity between two vectors in this space is estimated using a weighted cosine distance. The weighting significantly enhances the discrimination between vectors. We evaluate our model on benchmark datasets (TREC 6--8) and empirically demonstrate it outperforms state-of-the-art baselines.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {885–886},
numpages = {2},
keywords = {word embeddings, ad-hoc retrieval, language model},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252697,
author = {Al-Masri, Eyhab and Li, Jianxin and Osseiran, Adam},
title = {Session Details: Tutorial Track},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Tutorial Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051096,
author = {Hartig, Olaf and Cur\'{e}, Olivier},
title = {Semantic Data Management in Practice},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051096},
doi = {10.1145/3041021.3051096},
abstract = {After years of research and development, standards and technologies for semantic data are sufficiently mature to be used as the foundation of novel data science projects that employ semantic technologies in various application domains such as bio-informatics, materials science, criminal intelligence, and social science. Typically, such projects are carried out by domain experts who have a conceptual understanding of semantic technologies but lack the expertise to choose and to employ existing data management solutions for the semantic data in their project. For such experts, including domain-focused data scientists, project coordinators, and project engineers, our tutorial delivers a practitioner's guide to semantic data management. We discuss the following important aspects of semantic data management and demonstrate how to address these aspects in practice by using mature, production-ready tools: i) storing and querying semantic data; ii) understanding, iii) searching, and iv) visualizing the data; v) automated reasoning; vi) integrating external data and knowledge; and vii) cleaning the data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {901–904},
numpages = {4},
keywords = {semantic technologies, search, rdf, reasoning, visualization, querying, cleaning, storage},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051098,
author = {Zakhary, Victor and Agrawal, Divyakant and El Abbadi, Amr},
title = {Caching at the Web Scale: [Tutorial]},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051098},
doi = {10.1145/3041021.3051098},
abstract = {Today's web applications and social networks are serving billions of users around the globe. These users generate billions of key lookups and millions of data object updates per second. A single user's social network page load requires hundreds of key lookups. This scale creates many design challenges for the underlying storage systems. First, these systems have to serve user requests with low latency. Any increase in the request latency leads to a decrease in user interest. Second, storage systems have to be highly available. Failures should be handled seamlessly without affecting user requests. Third, users consume an order of magnitude more data than they produce. Therefore, storage systems have to be optimized for read-intensive workloads. To address these challenges, distributed in-memory caching services have been widely deployed on top of persistent storage. In this tutorial, we survey the recent developments in distributed caching services. We present the algorithmic and architectural efforts behind these systems focusing on the challenges in addition to open research questions.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {909–912},
numpages = {4},
keywords = {cache replacement policy, contention, distributed caching, memcached},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051099,
author = {Liu, Tie-Yan and Chen, Wei and Wang, Taifeng},
title = {Distributed Machine Learning: Foundations, Trends, and Practices},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051099},
doi = {10.1145/3041021.3051099},
abstract = {In recent years, artificial intelligence has achieved great success in many important applications. Both novel machine learning algorithms (e.g., deep neural networks), and their distributed implementations play very critical roles in the success. In this tutorial, we will first review popular machine learning algorithms and the optimization techniques they use. Second, we will introduce widely used ways of parallelizing machine learning algorithms (including both data parallelism and model parallelism, both synchronous and asynchronous parallelization), and discuss their theoretical properties, strengths, and weakness. Third, we will present some recent works that try to improve standard parallelization mechanisms. Last, we will provide some practical examples of parallelizing given machine learning algorithms in online application (e.g. Recommendation and Ranking) by using popular distributed platforms, such as Spark MlLib, DMTK, and Tensorflow. By listening to this tutorial, the audience can form a clear knowledge framework about distributed machine learning, and gain some hands-on experiences on parallelizing a given machine learning algorithm using popular distributed systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {913–915},
numpages = {3},
keywords = {machine learning, distributed machine learning, parallelization, distributed system, optimization methods},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051100,
author = {Gyrard, Amelie and Patel, Pankesh and Datta, Soumya Kanti and Ali, Muhammad Intizar},
title = {Semantic Web Meets Internet of Things and Web of Things: [2nd Edition]},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051100},
doi = {10.1145/3041021.3051100},
abstract = {An ever growing interest and wide adoption of Internet of Things (IoT) and Web technologies are unleashing a true potential of designing a broad range of high-quality consumer applications. Smart cities, smart buildings, and e-health are among various application domains which are currently benefiting and will continue to benefit from IoT and Web technologies in a foreseeable future. Similarly, semantic technologies have proven their effectiveness in various domains and a few among multiple challenges which semantic Web technologies are addressing are to (i) mitigate heterogeneity by providing semantic inter-operability, (ii) facilitate easy integration of data application, (iii) deduce and extract new knowledge to build applications providing smart solutions, and (iv) facilitate inter-operability among various data processes including representation, management and storage of data.In this tutorial, our focus will be on the combination of Web technologies, Semantic Web, and IoT technologies and we will present to our audience that how a merger of these technologies is leading towards an evolution from IoT to Web of Things (WoT) to Semantic Web of Things. This tutorial will introduce the basics of Internet of Things, Web of Things and Semantic Web and will demonstrate tools and techniques designed to enable the rapid development of semantics-based Web of Things applications. One key aspect of this tutorial is to familiarize its audience with the open source tools designed by different semantic Web, IoT and WoT based projects and provide the audience a rich hands-on experience to use these tools and build smart applications with minimal efforts. Thus, reducing the learning curve to its maximum. We will showcase real-world use case scenarios which are designed using semantically-enabled WoT frameworks (e.g. CityPulse, FIESTA-IoT and M3).},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {917–920},
numpages = {4},
keywords = {semantic web of things (swot), data interoperability, ontologies, web of things (wot), internet of things (iot)},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051101,
author = {Tang, Jie},
title = {Computational Models for Social Network Analysis: A Brief Survey},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051101},
doi = {10.1145/3041021.3051101},
abstract = {With the exponential growth of online social network services such as Facebook and Twitter, social networks and social medias become more and more important, directly influencing politics, economics, and our daily life. Mining big social networks aims to collect and analyze web-scale social data to reveal patterns of individual and group behaviors. It is an inherently interdisciplinary academic field which emerged from sociology, psychology, statistics, and graph theory. In this article, I briefly survey recent progress on social network mining with an emphasis on understanding the interactions among users in the large dynamic social networks. I will start with some basic knowledge for social network analysis, including methodologies and tools for macro-level, meso-level and microlevel social network analysis. Then I will give an overall roadmap of social network mining. After that, I will describe methodologies for modeling user behavior including state-of-the-art methods for learning user profiles, and introduce recent progress on modeling dynamics of user behaviors using deep learning. Then I will present models and algorithms for quantitative analysis on social interac- tions including homophily and social influence.Finally, I will introduce network structure model including social group formation, and network topology generation. We will introduce recent developed network embedding algorithms for modeling social networks with the embedding techniques. Finally, I will use several concrete examples from Alibaba, the largest online shopping website in the world, and WeChat, the largest social messaging service in China, to explain how online social networks influence our offline world.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {921–925},
numpages = {5},
keywords = {user behavior, big data, social influence, social networks},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051102,
author = {Schifanella, Rossano and Thomee, Bart and Shamma, David A.},
title = {The Lifecycle of Geotagged Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051102},
doi = {10.1145/3041021.3051102},
abstract = {The world is a big place. At any given instant something is happening somewhere, but even when nothing in particular is going on people still find ways to generate data, such as posting on social media, taking photos, and issuing search queries. A substantial number of these actions is associated with a location, and in an increasingly mobile and connected world (both in terms of people and devices), this number is only bound to get larger. Yet, in the literature we observe that many researchers often unwittingly treat the geospatial dimension as if it were a regular feature dimension, despite it requiring special attention. In order to avoid pitfalls and to steer clear of erroneous conclusions, our tutorial aims to teach researchers and students how geotagged data differs from regular data, and to educate them on best practices when dealing with such data. We will cover the lifecycle of how geotagged data is used in research, where the topics range from how it is created, represented, processed, modeled, analyzed, visualized, and perceived. The tutorial requires both passive and active involvement - we not only present the material, but the attendees also get the opportunity to interact with it using a variety of open source data and tools that we have prepared using a virtual machine. Attendees should expect to leave the course with a high-level understanding of methods for properly using geospatial data and reporting results, the necessary context to better understand the geography literature, and resources for further engaging with georeferenced data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {927–929},
numpages = {3},
keywords = {geospatial data, tutorial, spatiotemporality, geotagged data},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051103,
author = {Pathak, Sayan and He, Pengcheng and Darling, William},
title = {Scalable Deep Document / Sequence Reasoning with Cognitive Toolkit},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051103},
doi = {10.1145/3041021.3051103},
abstract = {Deep Neural Networks (DNNs) have revolutionized the way that machines understand language and have allowed us to create models that answer textual questions, translate pairs of languages, and intelligently compare document corpora. At the heart of these successes lie core techniques that fall into the area of sequence understanding. While powerful, dealing with variable-size sequences in DNNs requires deep understanding and experience in creating such networks, which can be daunting to many scientists and engineers. This tutorial will focus on introducing core concepts, end-to-end recipes, and key innovations facilitated by the cross-platform fully open-source Cognitive Toolkit (formerly called CNTK) with superior scalability (up to 1000 GPUs) for very large data corpora. Specifically, we will present tutorials on basic sequence understanding, intermediate sequence-to-sequence translation (both with and without attention), and the advanced Reasoning Network (ReasoNet) which has achieved industry-leading results in reading comprehension.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {931–934},
numpages = {4},
keywords = {cognitive toolkit, deep neural networks, sequence to sequence, reasonet, cntk},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051104,
author = {Weber, Ingmar and State, Bogdan},
title = {Digital Demography},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051104},
doi = {10.1145/3041021.3051104},
abstract = {Demography is the science of human populations and, at its most basic, focuses on the processes of (i) fertility, (ii) mortality and (iii) mobility. Whereas modern states are typically in a reasonable position to keep records on both fertility and mortality, through birth and death registrations, as well as through censuses, measuring the mobility of populations represents a particular challenge due to reasons ranging from inconsistencies in official definitions across countries, to the difficulty of quantifying illegal migration. At the same time, mere numbers, whether on births, deaths or migration events, shed little light on the underlying causes, hence providing insufficient information to policy makers.The use of digital methods and data sources, ranging from social media data to web search logs, offers possibilities to address some of the challenges of traditional demography by (i) improving existing statistics or helping to create new ones, and (ii) enriching statistics by providing context related to the drivers of demographic changes. This tutorial will help to familiarize participants with research in this area.First, we will give an overview of fundamental concepts in demographic research including the population equation. We also showcase traditional data collection and analysis methods such as census microdata, the construction of a basic life table, panel datasets and survival analysis.In the second part, we present a number of studies that have tried to overcome limitations of traditional approaches by using innovative methods and data sources ranging from geo-tagged tweets to online genealogy. We will put particular emphasis on (i) methodological challenges such as issues related to bias, as well as on (ii) how to collect open data from the World Wide Web.The slides and other material for this tutorial are available at https://sites.google.com/site/digitaldemography/.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {935–939},
numpages = {5},
keywords = {demography, digital methods, social media},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051105,
author = {Sun, Yizhou and Yin, Hongzhi and Ren, Xiang},
title = {Recommendation in Context-Rich Environment: An Information Network Analysis Approach},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051105},
doi = {10.1145/3041021.3051105},
abstract = {Recommendation has received tremendous attention recently due to its wide and successful applications across different domains. Different from traditional setting of recommendation tasks, modern recommendation tasks are usually exposed in a context-rich environment. For example, in addition to a user-item rating matrix, users and items are connected to other objects via different relationships and they are usually associated with rich attributes, such as text and spatio-temporal information. It turns out that heterogeneous information network serves a natural data model to capture the rich context of these recommendation tasks. In this tutorial, we will systematically introduce the methodologies of using heterogeneous information network mining approach to solve recommendation tasks, and demonstrate the effectiveness of such methods using different applications, ranging from collaboration recommendation in scientific research network to job recommendation in professional social network, and to drug discovery in biomedical networks. The topics to be covered in the tutorial include: (1) overall introduction; (2) recommendation in heterogeneous information networks, which introduces the general methodology of how to model the recommendation problem as a heterogeneous information network mining problem; (3) recommendation in a text-rich setting, where the information network is further enriched by refined analysis of text information; (4) recommendation with spatio-temporal information, where entities and relationships in the network are associated with spatio-temporal attributes; and (5) research frontiers for context-rich recommendation.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {941–945},
numpages = {5},
keywords = {information network mining, spatio-temporal recommendation, contex-rich recommendation, recommender systems},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051106,
author = {Kumar, Srijan and Cheng, Justin and Leskovec, Jure},
title = {Antisocial Behavior on the Web: Characterization and Detection},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051106},
doi = {10.1145/3041021.3051106},
abstract = {Web platforms enable unprecedented speed and ease in transmission of knowledge, and allow users to communicate and shape opinions. However, the safety, usability and reliability of these platforms are compromised by the prevalence of online antisocial behavior, for e.g. 40% of users have experienced online harassment. This is present in the form of antisocial users, such as trolls, sockpuppets and vandals, and misinformation, such as hoaxes, rumors and fraudulent reviews. This tutorial presents the state-of-the-art research spanning two aspects of antisocial behavior: characterization of their behavioral properties, and development of algorithms for identifying and predicting them. The tutorial first discusses antisocial users --- trolls, sockpuppets and vandals. We present the causes, community effects, and linguistic, social and temporal characteristics of trolls. Then we discuss the types of sockpuppets, i.e. multiple accounts of the same user, and their behavioral characteristics in Wikipedia and online discussion forums. Vandals make destructive edits on Wikipedia and we discuss the properties of vandals and vandalism edits. In each case, detection and prediction algorithms of the antisocial user are also discussed.The second part of the tutorial discusses about misinformation --- hoaxes, rumors and fraudulent reviews. We present the characteristics and impact of hoaxes on Wikipedia, followed by the spread and evolution of rumors on social media. Then, we discuss the algorithms to identify fake reviews and reviewers from their characteristics, and the camouflage and coordination among sophisticated fraudsters. Again, in each case, we present the detection algorithms, using textual, temporal, sentiment, network structure and rating patterns. Finally, the tutorial concludes with future research avenues.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {947–950},
numpages = {4},
keywords = {trolls, bots, hoax, fake review, rumor, antisocial behavior, fraud, spam, vandals, sockpuppets, cyberbully, malicious users, false information, shills},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051107,
author = {Ren, Xiang and Jiang, Meng and Shang, Jingbo and Han, Jiawei},
title = {Constructing Structured Information Networks from Massive Text Corpora},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051107},
doi = {10.1145/3041021.3051107},
abstract = {In today's computerized and information-based society, text data is rich but messy. People are soaked with vast amounts of natural-language text data, ranging from news articles, social media post, advertisements, to a wide range of textual information from various domains (medical records, corporate reports). To turn such massive unstructured text data into actionable knowledge, one of the grand challenges is to gain an understanding of the factual information (e.g., entities, attributes, relations, events) in the text. In this tutorial, we introduce data-driven methods to construct structured information networks (where nodes are different types of entities attached with attributes, and edges are different relations between entities) for text corpora of different kinds (especially for massive, domain-specific text corpora) to rep- resent their factual information. We focus on methods that are minimally-supervised, domain-independent, and language-independent for fast network construction across various application domains (news, web, biomedical, reviews). We demonstrate on real datasets including news articles, scientific publications, tweets and reviews how these constructed networks aid in text analytics and knowledge discovery at a large scale.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {951–954},
numpages = {4},
keywords = {attribute discovery, entity recognition and typing, relation extraction, quality phrase mining, massive text corpora},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051108,
author = {Shanahan, James and Dai, Liang},
title = {Large Scale Distributed Data Science from Scratch Using Apache Spark 2.0},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051108},
doi = {10.1145/3041021.3051108},
abstract = {Apache Spark is an open-source cluster computing framework. It has emerged as the next generation big data processing engine, overtaking Hadoop MapReduce which helped ignite the big data revolution. Spark maintains MapReduce's linear scalability and fault tolerance, but extends it in a few important ways: it is much faster (100 times faster for certain applications), much easier to program in due to its rich APIs in Python, Java, Scala, SQL and R (MapReduce has 2 core calls) , and its core data abstraction, the distributed data frame. In addition, it goes far beyond batch applications to support a variety of compute-intensive tasks, including interactive queries, streaming, machine learning, and graph processing. With massive amounts of computational power, deep learning has been shown to produce state-of-the-art results on various tasks in different fields like computer vision, automatic speech recognition, natural language processing and online advertising targeting. Thanks to the open-source frameworks, e.g. Torch, Theano, Caffe, MxNet, Keras and TensorFlow, we can build deep learning model in a much easier way. Among all these framework, TensorFlow is probably the most popular open source deep learning library. TensorFlow 1.0 was released recently, which provide a more stable, flexible and powerful computation tool for numerical computation using data flow graphs. Keras is a high-level neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. This tutorial will provide an accessible introduction to large-scale distributed machine learning and data mining, and to Spark and its potential to revolutionize academic and commercial data science practices. It is divided into three parts: the first part will cover fundamental Spark concepts, including Spark Core, functional programming ala map-reduce, data frames, the Spark Shell, Spark Streaming, Spark SQL, MLlib, and more; the second part will focus on hands-on algorithmic design and development with Spark (developing algorithms from scratch such as decision tree learning, association rule mining (aPriori), graph processing algorithms such as pagerank/shortest path, gradient descent algorithms such as support vectors machines and matrix factorization. Industrial applications and deployments of Spark will also be presented.; the third part will introduce deep learning concepts, how to implement a deep learning model through TensorFlow, Keras and run the model on Spark. Example code will be made available in python (pySpark) notebooks.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {955–957},
numpages = {3},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252698,
author = {Hooper, Clare and Hendler, Jim},
title = {Session Details: WebScience Track},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252699,
author = {Tinati, Ramine},
title = {Session Details: WebScience Track Session 1: Social Networks and User Modelling},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055203,
author = {Hall, Wendy},
title = {Web Science @ 10},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055203},
doi = {10.1145/3041021.3055203},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {961},
numpages = {1},
keywords = {web science},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055135,
author = {Cresci, Stefano and Di Pietro, Roberto and Petrocchi, Marinella and Spognardi, Angelo and Tesconi, Maurizio},
title = {The Paradigm-Shift of Social Spambots: Evidence, Theories, and Tools for the Arms Race},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055135},
doi = {10.1145/3041021.3055135},
abstract = {Recent studies in social media spam and automation provide anecdotal argumentation of the rise of a new generation of spambots, so-called social spambots. Here, for the first time, we extensively study this novel phenomenon on Twitter and we provide quantitative evidence that a paradigm-shift exists in spambot design. First, we measure current Twitter's capabilities of detecting the new social spambots. Later, we assess the human performance in discriminating between genuine accounts, social spambots, and traditional spambots. Then, we benchmark several state-of-the-art techniques proposed by the academic literature. Results show that neither Twitter, nor humans, nor cutting-edge applications are currently capable of accurately detecting the new social spambots. Our results call for new approaches capable of turning the tide in the fight against this raising phenomenon. We conclude by reviewing the latest literature on spambots detection and we highlight an emerging common research trend based on the analysis of collective behaviors. Insights derived from both our extensive experimental campaign and survey shed light on the most promising directions of research and lay the foundations for the arms race against the novel social spambots. Finally, to foster research on this novel phenomenon, we make publicly available to the scientific community all the datasets used in this study.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {963–972},
numpages = {10},
keywords = {twitter, social networks security, automation, spam, social spambots},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055138,
author = {Rezaei, Aria and Perozzi, Bryan and Akoglu, Leman},
title = {Ties That Bind: Characterizing Classes by Attributes and Social Ties},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055138},
doi = {10.1145/3041021.3055138},
abstract = {Given a set of attributed subgraphs known to be from different classes, how can we discover their differences? There are many cases where collections of subgraphs may be contrasted against each other. For example, they may be as- signed ground truth labels (spam/not-spam), or it may be desired to directly compare the biological networks of different species or compound networks of different chemicals.In this work we introduce the problem of characterizing the differences between attributed subgraphs that belong to different classes. We define this characterization problem as one of partitioning the attributes into as many groups as the number of classes, while maximizing the total attributed quality score of all the given subgraphs.We show that our attribute-to-class assignment problem is NP-hard and an optimal (1 -- 1/e)-approximation algorithm exists. We also propose two different faster heuristics that are linear-time in the number of attributes and subgraphs. Unlike previous work where only attributes were taken into account for characterization, here we exploit both attributes and social ties (i.e. graph structure).Through extensive experiments, we compare our proposed algorithms, show findings that agree with human intuition on datasets from Amazon co-purchases, Congressional bill sponsorships and DBLP co-authorships. We also show that our approach of characterizing subgraphs is better suited for sense-making than discriminating classification approaches.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {973–981},
numpages = {9},
keywords = {attributed graphs, community understanding, subspace discovery, social networks, homophily},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055139,
author = {Rotabi, Rahmtin and Kamath, Krishna and Kleinberg, Jon and Sharma, Aneesh},
title = {Detecting Strong Ties Using Network Motifs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055139},
doi = {10.1145/3041021.3055139},
abstract = {Detecting strong ties among users in social and information networks is a fundamental operation that can improve performance on a multitude of personalization and ranking tasks. There are a variety of ways a tie can be deemed ``strong'', and in this work we use a data-driven (or supervised) approach by assuming that we are provided a sample set of edges labeled as strong ties in the network. Such labeled edges are often readily obtained from the social network as users often participate in multiple overlapping networks via features such as following and messaging. These networks may vary greatly in size, density and the information they carry --- for instance, a heavily-used dense network (such as the network of followers) commonly overlaps with a secondary sparser network composed of strong ties (such as a network of email or phone contacts). This setting leads to a natural strong tie detection task: given a small set of labeled strong tie edges, how well can one detect unlabeled strong ties in the remainder of the network?This task becomes particularly daunting for the Twitter network due to scant availability of pairwise relationship attribute data, and sparsity of strong tie networks such as phone contacts. Given these challenges, a natural approach is to instead use structural network features for the task, produced by combining the strong and ``weak'' edges. In this work, we demonstrate via experiments on Twitter data that using only such structural network features is sufficient for detecting strong ties with high precision. These structural network features are obtained from the presence and frequency of small network motifs on combined strong and weak ties. We observe that using motifs larger than triads alleviate sparsity problems that arise for smaller motifs, both due to increased combinatorial possibilities as well as benefiting strongly from searching beyond the ego network. Empirically, we observe that not all motifs are equally useful, and need to be carefully constructed from the combined edges in order to be effective for strong tie detection. Finally, we reinforce our experimental findings with providing theoretical justification that suggests why incorporating these larger sized motifs as features could lead to increased performance in planted graph models.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {983–992},
numpages = {10},
keywords = {information transfer, network motifs, strong-tie detection},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252700,
author = {Goncalves, Jorge},
title = {Session Details: WebScience Track Session 2: Web Mining},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055130,
author = {Lian, Jianxun and Zhang, Fuzheng and Xie, Xing and Sun, Guangzhong},
title = {Restaurant Survival Analysis with Heterogeneous Information},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055130},
doi = {10.1145/3041021.3055130},
abstract = {For shopkeepers, one of their biggest common concerns is whether their business will thrive or fail in the future. With the development of new ways to collect business data, it is possible to leverage multiple domains' knowledge to build an intelligent model for business assessment. In this paper, we discuss what the potential indicators are for the long-term survival of a physical store. To this end, we study factors from four pillars: geography, user mobility, user rating, and review text. We start by exploring the impact of geographic features, which describe the location environment of the retailer store. The location and nearby places play an important role in the popularity of the shop, and usually less competitiveness and more heterogeneity is better. Then we study user mobility. It can be viewed as supplementary to the geographical placement, showing how the location can attract users from anywhere. Another important factor is how the shop can serve and satisfy users. We find that restaurant survival prediction is a hard task that can not be solved simply using consumers' ratings or sentiment metrics. Compared with conclusive and well-formatted ratings, the various review words provide more insight of the shop and deserve in-depth mining. We adopt several language models to fully explore the textual message. Comprehensive experiments demonstrate that review text indeed have the strongest predictive power. We further compare different cities' models and find the conclusions are highly consistent. Although we focus on the class of restaurant in this paper, the method can be easily extended to other shop categories.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {993–1002},
numpages = {10},
keywords = {restaurant survival analysis, location-based services, data mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055133,
author = {Popat, Kashyap and Mukherjee, Subhabrata and Str\"{o}tgen, Jannik and Weikum, Gerhard},
title = {Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055133},
doi = {10.1145/3041021.3055133},
abstract = {The web is a huge source of valuable information. However, in recent times, there is an increasing trend towards false claims in social media, other web-sources, and even in news. Thus, factchecking websites have become increasingly popular to identify such misinformation based on manual analysis. Recent research proposed methods to assess the credibility of claims automatically. However, there are major limitations: most works assume claims to be in a structured form, and a few deal with textual claims but require that sources of evidence or counter-evidence are easily retrieved from the web. None of these works can cope with newly emerging claims, and no prior method can give user-interpretable explanations for its verdict on the claim's credibility.This paper overcomes these limitations by automatically assessing the credibility of emerging claims, with sparse presence in web-sources, and generating suitable explanations from judiciously selected sources. To this end, we retrieve diverse articles about the claim, and model the mutual interaction between: the stance (i.e., support or refute) of the sources, the language style of the articles, the reliability of the sources, and the claim's temporal footprint on the web. Extensive experiments demonstrate the viability of our method and its superiority over prior works. We show that our methods work well for early detection of emerging claims, as well as for claims with limited presence on the web and social media.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1003–1012},
numpages = {10},
keywords = {rumor and hoax detection, text mining, credibility analysis},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055137,
author = {Sajadmanesh, Sina and Jafarzadeh, Sina and Ossia, Seyed Ali and Rabiee, Hamid R. and Haddadi, Hamed and Mejova, Yelena and Musolesi, Mirco and Cristofaro, Emiliano De and Stringhini, Gianluca},
title = {Kissing Cuisines: Exploring Worldwide Culinary Habits on the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055137},
doi = {10.1145/3041021.3055137},
abstract = {As food and nutrition occupy an increasingly prevalent space on the web, dishes and recipes shared online provide an invaluable mirror into culinary cultures and attitudes around the world. More specifically, ingredients, flavors, and nutrition information become strong signals of the taste preferences of individuals and civilizations. However, there is little understanding of these palate varieties. In this paper, we present a large-scale study of recipes published on the web and their content, aiming to understand cuisines and culinary habits around the world. Using a database of more than 157K recipes from over 200 different cuisines, we analyze ingredients, flavors, and nutritional values which distinguish dishes from different regions, and use this knowledge to assess the predictability of recipes from different cuisines. We then use country health statistics to understand the relation between these factors and health indicators of different nations, such as obesity, diabetes, migration, and health expenditure. Our results confirm the strong effects of geographical and cultural similarities on recipes, health indicators, and culinary preferences between countries around the world.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1013–1021},
numpages = {9},
keywords = {ingredients, health statistics, cuisines, nutrition values, recipes},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252701,
author = {Perozzi, Bryan},
title = {Session Details: WebScience Track Session 3: Understanding Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055128,
author = {Goncalves, Jorge and Feldman, Michael and Hu, Subingqian and Kostakos, Vassilis and Bernstein, Abraham},
title = {Task Routing and Assignment in Crowdsourcing Based on Cognitive Abilities},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055128},
doi = {10.1145/3041021.3055128},
abstract = {Appropriate task routing and assignment is an important, but often overlooked, element in crowdsourcing research and practice. In this paper, we explore and evaluate a mechanism that can enable matching crowdsourcing tasks to suitable crowd-workers based on their cognitive abilities. We measure participants' visual and fluency cognitive abilities with the well-established Kit of Factor-Referenced Cognitive Test, and measure crowdsourcing performance with our own set of developed tasks. Our results indicate that participants' cognitive abilities correlate well with their crowdsourcing performance. We also built two predictive models (beta and linear regression) for crowdsourcing task performance based on the performance on cognitive tests as explanatory variables. The model results suggest that it is feasible to predict crowdsourcing performance based on cognitive abilities. Finally, we discuss the benefits and challenges of leveraging workers' cognitive abilities to improve task routing and assignment in crowdsourcing environments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1023–1031},
numpages = {9},
keywords = {crowdsourcing, task assignment, worker performance, cognitive abilities, kit of factor-referenced cognitive tests., visual tasks, fluency tasks, task routing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055132,
author = {Zhang, Yating and Jatowt, Adam and Tanaka, Katsumi},
title = {Is Tofu the Cheese of Asia? Searching for Corresponding Objects across Geographical Areas},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055132},
doi = {10.1145/3041021.3055132},
abstract = {Keyword-based search engines are widely used nowadays for content retrieval. Creating queries is relatively easy when users wish to retrieve content in familiar domains (e.g., information about things within their own country). However, they often struggle when searching in unfamiliar domains (e.g., searching for information related to a foreign country). In this paper, we approach the vocabulary gap problem by allowing users to search by analogical examples, that is, by letting them utilize information in familiar domains to perform search in domains unfamiliar to them. In particular, we focus on geographical domains. We propose to build connections between two different spaces (e.g., USA and Japan) by mapping the distributed word representations in one space with the ones in the other space. We first introduce an effective technique for automatically constructing seed pairs of terms to be used for finding the optimal mapping function. Then we propose general and topic-based transformations of terms from one space to another. We test the performance of the proposed approaches on datasets derived from Wikipedia which are related to two quite diverse countries: Japan and USA.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1033–1042},
numpages = {10},
keywords = {spatial transformation, object search, spatial counterpart},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055136,
author = {Lecuyer, Mathias and Tucker, Max and Chaintreau, Augustin},
title = {Improving the Transparency of the Sharing Economy},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055136},
doi = {10.1145/3041021.3055136},
abstract = {The idealistic beginnings of the sharing economy made ways to an entrenched battle to win over the public opinion and for law makers to appreciate its benefits and its risks. The stakes are high as the success of services like Airbnb reveals that under-utilized assets (e.g. spare rooms or apartments left vacant) can be efficiently matched to individual demands to generate a significant surplus to their owners. Rules and regulation, which are increasingly felt as necessary by many communities, also create friction over the best way to leverage these opportunities for growth. To make things worse, the sharing economy is complex and poorly documented: Three recent reports from public institutions and lobbying groups arrived at opposite conclusions with seemingly contradictory facts about the occupancy distribution.In this paper, we show how to overcome this opacity by offering the first large-scale, reproducible study of Airbnb's supply and transactions. We devised and deployed frequently repeated crawls using no proprietary data. We show that these can be used to accurately estimate not only the supply of available rooms, but the effective transactions, occupancy, and revenue of hosts. Our results provide the first complete view of the occupancy and the distribution of revenue, revealing important trends that generalize previous observations. In particular we found that previous observations that seemed at odds are all explained by a variant of the "inspection paradox". We also found from our detailed data that enforcing a maximum occupancy of 90 nights a year would greatly reduce most concerns raised by various advocacy groups, while affecting only marginally the justifying claims that Airbnb quotes to argue for its beneficial impact.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1043–1051},
numpages = {9},
keywords = {measurement, sharing economy, transparency, airbnb},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252702,
author = {Rabiee, Hamid R.},
title = {Session Details: WebScience Track Session 4: Health},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055129,
author = {Luo, Ling and Li, Bin and Berkovsky, Shlomo and Koprinska, Irena and Chen, Fang},
title = {Online Engagement for a Healthier You: A Case Study of Web-Based Supermarket Health Program},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055129},
doi = {10.1145/3041021.3055129},
abstract = {Obesity is a growing problem affecting millions of people. Various behavior change programs have been designed to reduce its prevalence. An Australian supermarket has recently run a web-based health program to motivate people to eat healthily and do more physical activity. The program offered discounts on fresh products and a website, HealthierU, providing interactive support tools for participants. The stakeholders desire to evaluate if the program is effective and if the supporting website is useful to facilitate behavior changes. To answer these questions, in this work we propose a method to: (1) model individual purchase rate from sparse recorded transactions through a mixture of Non-Homogeneous Poisson Processes (NHPP), (2) design criteria for partitioning participants based on their interactions with the HealthierU website, (3) evaluate the program impact by comparing behavior changes across different groups of participants. Our case study shows that during the program the participants significantly increased their purchases of some fresh products. Both the distribution of behavior patterns and impact scores show that the program imposed relatively strong impact on the participants who logged activities and tracked weights. Our method can facilitate the enhancement of personalized health programs, especially aiming to maximize the program impact and targeting participants through web or mobile applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1053–1061},
numpages = {9},
keywords = {online support, non-homogeneous poisson process, activity logs, supermarket health program, purchase behavior model},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055131,
author = {Cunha, Tiago and Weber, Ingmar and Pappa, Gisele},
title = {A Warm Welcome Matters! The Link Between Social Feedback and Weight Loss in /r/Loseit},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055131},
doi = {10.1145/3041021.3055131},
abstract = {Social feedback has long been recognized as an important element of successful health-related behavior change. How- ever, most of the existing studies look at the effect that offline social feedback has. This paper fills gaps in the literature by proposing a framework to study the causal effect that receiving social support in the form of comments in an online weight loss community has on (i) the probability of the user to return to the forum, and, more importantly, on (ii) the weight loss reported by the user. Using a matching approach for causal inference we observe a difference of 9 lbs lost between users who do or do not receive comments. Surprisingly, this effect is mediated by neither an increase in lifetime in the community nor by an increased activity level of the user. Our results show the importance that a "warm welcome" has when using online support forums to achieve health outcomes.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1063–1072},
numpages = {10},
keywords = {reddit, mediation analysis, causal inference, obesity},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055134,
author = {Zhang, Shaodian and Qiu, Lin and Chen, Frank and Zhang, Weinan and Yu, Yong and Elhadad, No\'{e}mie},
title = {We Make Choices We Think Are Going to Save Us: Debate and Stance Identification for Online Breast Cancer CAM Discussions},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055134},
doi = {10.1145/3041021.3055134},
abstract = {Patients discuss complementary and alternative medicine (CAM) in online health communities. Sometimes, patients' conflicting opinions toward CAM-related issues trigger debates in the community. The objectives of this paper are to identify such debates, identify controversial CAM therapies in a popular online breast cancer community, as well as patients' stances towards them. To scale our analysis, we trained a set of classifiers. We first constructed a supervised classifier based on a long short-term memory neural network (LSTM) stacked over a convolutional neural network (CNN) to detect automatically CAM-related debates from a popular breast cancer forum. Members' stances in these debates were also identified by a CNN-based classifier. Finally, posts automatically flagged as debates by the classifier were analyzed to explore which specific CAM therapies trigger debates more often than others. Our methods are able to detect CAM debates with F score of 77%, and identify stances with F score of 70%. The debate classifier identified about 1/6 of all CAM-related posts as debate. About 60% of CAM-related debate posts represent the supportive stance toward CAM usage. Qualitative analysis shows that some specific therapies, such as Gerson therapy and usage of laetrile, trigger debates frequently among members of the breast cancer community. This study demonstrates that neural networks can effectively locate debates on usage and effectiveness of controversial CAM therapies, and can help make sense of patients' opinions on such issues under dispute. As to CAM for breast cancer, perceptions of their effectiveness vary among patients. Many of the specific therapies trigger debates frequently and are worth more exploration in future work.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1073–1081},
numpages = {9},
keywords = {complementary and alternative medicine (cam), debate identification, online health community},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252703,
author = {Chignell, Mark and Chan, Jonathan H.},
title = {Session Details: AMCH'17: Workshop on Aging Well with Technology for Maintaining Good Mental and Cognitive Health},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {AMCH 2017 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {3},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252704,
author = {Vanijja, Vajirasak},
title = {Session Details: AMCH'17 Invited Talk},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054936,
author = {Fong, Simon and Zhuang, Yan and Hu, Shimin and Song, Wei and Liu, Liansheng and Moutinho, Luiz Abel},
title = {Longitudinal Ambient Mobile Sensor Monitoring for TCM-Oriented Healthcare Assessments: Framework, Challenges and Applications},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054936},
doi = {10.1145/3041021.3054936},
abstract = {Recently healthcare using information technology progressed with the maturity of tele-health monitoring services through Internet, and the emergence of mobile apps on smartphones that are geared towards recording inputs of intakes (e.g. calories, fat, amount of water etc.), as well as monitoring one's activity levels (e.g. number of steps walked) and emotion states, for inferring one's health condition. In this paper, a novel concept of fusing the current mobile app software technology, big data, sensing technology, and machine learning (in decision rule induction, reasoning, and image recognition) into the principles of TCM healthcare is proposed. TCM has developed a set of practical, universal and thorough, and systematic health care system, which is notably characterized by its relations to our daily lifestyles. Currently it lacks of some ubiquitous tools such as mobile smartphone and its sensing apps to embrace this healthcare concept as a personal assistant, monitoring and advising the user regarding his/her health and forewarning of any health risk. The challenges and potential applications are discussed in this paper. The advantage of this project is tapped from the popularity and convenient use of mobile smartphone and EEG sensors for providing ubiquitous personal TCM healthcare},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1087–1094},
numpages = {8},
keywords = {healthcare application, mobile apps, data mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252705,
author = {Wilkinson, Andrea},
title = {Session Details: AMCH'17 Session 1: Technology},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054928,
author = {Kon, Bethany and Lam, Alex and Chan, Jonathan},
title = {Evolution of Smart Homes for the Elderly},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054928},
doi = {10.1145/3041021.3054928},
abstract = {Smart home technology provides benefits for the elderly in six primary categories: safety, health and nutrition, physical activity, personal hygiene and care, social engagement, and leisure. Safety is about detecting and mitigating, if not removing, hazards from the user's environment. Social engagement relates to the smart home functions that allow the elderly to combat social isolation, such as by connecting the elderly with friends and family. Leisure activities are about how a smart home can allow users to spend their free time. Physical Activity relates to the concept of movement from the user, such as having them engage in non-sedentary activities. Nutrition and Health is related to the monitoring of a user's state of health. Personal hygiene and care encompasses the ways that a smart home can improve the user's well-being and assist in his/her daily activities. This workshop paper will present existing technologies in the aforementioned fields and highlight areas where development is lacking. In addition, an evaluation on past smart home designs is conducted to determine whether they fulfill the six proposed primary categories.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1095–1101},
numpages = {7},
keywords = {wireless, smart home, network, elderly},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054933,
author = {Wilkinson, Andrea and Charoenkitkarn, Vishuda and O'Neill, Judy and Kanik, Marc and Chignell, Mark},
title = {Journeys to Engagement: Ambient Activity Technologies for People Living with Dementia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054933},
doi = {10.1145/3041021.3054933},
abstract = {Caring for individuals with dementia living in long-term care environments requires the management of responsive behaviours (e.g., screaming, hitting, wandering), which affect 60-80% of residents with dementia. Responsive behaviours are commonly treated with antipsychotic medications, and they compromise well-being of residents as well as staff. Our multi-disciplinary team seeks to develop technological solutions to minimize agitated and aggressive behaviours by creating familiar and appropriate activities that allow residents with dementia opportunities to self-initiate (trigger), engage and interact with Ambient Activity Technologies (AATs) and Centivizers (reward-based learning). Once engaged, these technologies should provide the resident with individualized and stimulating experiences that are meaningful to the resident, facilitating the development of a calm and engaged state, thereby managing responsive behaviours (e.g., agitation and aggression) and improving quality of life. In this paper, we review the etiology of dementia and responsive behaviours to elucidate the rationale behind the design and development of AATs and Centivizers for individuals with dementia living in long-term care, using a person-centered technological approach. Our goal is to utilize technology to minimize caregiver burden and help to improve well-being related outcomes in residents, staff and family members.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1103–1110},
numpages = {8},
keywords = {person-centered care, caregiver burden, meaningful engagement, alzheimer's disease, ambient technology, dementia, gamification, quality of life, montessori, human factors},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054930,
author = {Tong, Tiffany and Chan, Jonathan H. and Chignell, Mark},
title = {Serious Games for Dementia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054930},
doi = {10.1145/3041021.3054930},
abstract = {With the current phenomenon of aging populations in most parts of the world, there are corresponding increases in age-related conditions associated with impaired cognitive status, such as dementia and delirium. Cognitive status is a key component in carrying out activities of daily living such as walking and bathing, and departures from normal cognitive status may be indicators of acute (e.g., delirium) or chronic (e.g., dementia) conditions. Individuals with cognitive impairments may benefit from playing serious games, which are games designed for a primary purpose other than entertainment. Serious games can potentially assess a variety of factors associated with cognitive decline in dementia, while keeping individuals active and stimulated, thereby potentially slowing down or furthering cognitive decline. In this workshop paper, we discuss the development and use of serious games focusing on cognitive functions that are affected by the progression of dementia.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1111–1115},
numpages = {5},
keywords = {human factors, executive function, cognitive assessments, games, activities of daily living, cognitive screening, instrumental activities of daily living, dementia, gamification, serious games, alzheimer's disease},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054932,
author = {Duangcham, Patricia and Vanijja, Vajirasak and Mizobuchi, Sachi},
title = {The Effect of Aging on Visual Attention Shifting in Collaborative Document Editing},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054932},
doi = {10.1145/3041021.3054932},
abstract = {Many tasks, including driving, require frequent shifts in visual attention. Some visual shifting of attention is due to distraction from a secondary task, or from non-task relevant stimuli in the environment. Older people (e.g. over 60) are generally slower to react to stimuli and less skillful in learning to use new technologies. In this paper we are interested in studying the effect of age on the ability to shift visual attention in a task that involves computer use. An experiment is reported involving 10 participants, five who were over the age of 60 and five who were in their twenties and thirties. A collaborative editing task was carried out where participants, run one at a time, had to edit a document in real-time based on comments made by three research assistants (who were not participants for purposes of data collection). In one condition participants had to constantly shift their visual attention from a desktop computer they were using to a large shared screen where the research assistants made editing suggestions and used a laser pointer to indicate which part of the document (shown on the large shared screen) they were referring to. As expected, time to perform each editing task increased in the two-screen (vs. one screen) condition. However, the amount of slowing due to the use of two screens for the task was considerably greater for the older group. The results are interpreted in terms of the use of redesigned tools and technologies to assist older workers perform more effectively.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1117–1120},
numpages = {4},
keywords = {shifting, executive functioning, collaborative editing, aging effects, visual attention},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252706,
author = {Pasupa, Kitsuchart},
title = {Session Details: AMCH'17 Session 2: Data Analytics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054931,
author = {Pal, Debajyoti and Vanijja, Vajirasak},
title = {A Video Quality Prediction Model for the Elderly},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054931},
doi = {10.1145/3041021.3054931},
abstract = {In the recent times there has been a lot of effort to use the various ICT technologies available to monitor and improve the lifestyle of the older generation. In most of the countries across the globe, these elderly people have to stay alone especially during the daytime, when other family members go out for work. Thus, monitoring their presence and activities remotely through audio/video communications is a widespread practice. However, this group of elderly people generally suffers from various types of vision impairments. Hence, mere installation of surveillance audio/video systems only will not solve the problem, as they need to interact with the system and hear/watch the audio/video communications for their well-being.In this work, we carry out a subjective test on a sample population of 59 people belonging to different age groups and record their Mean Opinion Scores (MOS). Thereafter, we run the VQM algorithm over the same set of videos and observe that the scores obtained are somewhat different for the elderly people compared to the rest. Therefore, we propose a video quality prediction model based upon the Artificial Neural Networks (ANN) that gives a better prediction for our target age group. For this model, we take into consideration the network level Quality of Service (QoS) parameters only as they have a greater impact on the perceived video quality compared to other QoS factors.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1121–1127},
numpages = {7},
keywords = {ann, vqm, quality of service, quality of experience, mean opinion score},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054929,
author = {Fong, Simon and Hu, Shimin and Song, Wei and Cho, Kyungeun and Wong, Raymond K. and Mohammed, Sabah},
title = {On Recognizing Abnormal Human Behaviours by Data Stream Mining with Misclassified Recalls},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054929},
doi = {10.1145/3041021.3054929},
abstract = {Human activity recognition (HAR) has been a popular research topic, because of its importance in security and healthcare contributing to aging societies. One of the emerging applications of HAR is to monitor needy people such as elders, patients of disabled, or undergoing physical rehabilitation, using sensing technology. In this paper, an improved version of Very Fast Decision Tree (VFDT) is proposed which makes use of misclassified results for post-learning. Specifically, a new technique namely Misclassified Recall (MR) which is a post-processing step for relearning a new concept, is formulated. In HAR, most misclassified instances are those belonging to ambiguous movements. For examples, squatting involves actions in between standing and sitting, falling straight down is a sequence of standing, possibly body tiling or curling, bending legs, squatting and crashing down on the floor; and there may be totally new (unseen) actions beyond the training instances when it comes to classifying "abnormal" human behaviours. Think about the extreme postures of how a person collapses and free falling from height. Experiments using wearable sensing data for multi-class HAR is used, to test the efficacy of the new methodology VFDT+MR, in comparison to a classical data stream mining algorithm VFDT alone.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1129–1135},
numpages = {7},
keywords = {human activity recognition, classification, data stream mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054934,
author = {Kongburan, Wutthipong and Chignell, Mark and Chan, Jonathan},
title = {Distillation of Knowledge from the Research Literature on Alzheimer's Dementia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054934},
doi = {10.1145/3041021.3054934},
abstract = {Many countries are aging societies. Since abilities generally deteriorate with age, technologies can assist older adults in their daily life. Loss of cognitive status is particularly severe in cases of dementia, with around 70% (according to Alzheimers.net) of dementia cases involving Alzheimer's Dementia (AD), a progressive and currently incurable disease. There is considerable research on AD with thousands of relevant publications being added to the PubMed online database every year. The knowledge incorporated in this large body of work is spread across hundreds of thousands of pages of text, making it difficult to distill and mobilize that knowledge in terms of treatments and guidelines. Text mining technology may assist in distilling knowledge from the vast corpus of research literature on Alzheimer's dementia. In this paper, we apply the Named Entity Recognition (NER) system, a text mining (TM) method used to group words into classes, in order to extract useful information from free texts. We present findings concerning how well NER can extract information from a corpus of AD research publications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1137–1140},
numpages = {4},
keywords = {aging society, quality of life, alzheimer intervention, pubmed, named entity recognition},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054935,
author = {Kakudi, Habeebah A. and Loo, Chu Kiong and Pasupa, Kitsuchart},
title = {Risk Quantification of Metabolic Syndrome with Quantum Particle Swarm Optimisation},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054935},
doi = {10.1145/3041021.3054935},
abstract = {Metabolic syndrome (MetS) is a combination of interrelated risk factors associated with an increased risk of developing type II diabetes Mellitus (T2DM), stroke and cardiovascular diseases (CVD). The economic, social and medical burden coupled with increased morbidity of the aforementioned diseases makes their prevention an active research area. Currently, the traditional method of MetS diagnosis is based on dichotomised definitions provided by various expert health organisations. However, this method is laced with the indetermination of MetS in individuals with borderline risk factor values due to a binary diagnosis and the assumption of equal weighting for all risk factors during diagnosis. The purpose of this paper is to examine the use of the MetS areal similarity degree risk analysis based on weighted radar charts comprising of diagnostic thresholds and risk factor results of an individual. We further enhance this risk quantification method by applying quantum particle swarm optimization to derive the weights. The proposed risk quantification was carried out using a sample of 528 individuals from an examination survey conducted between 2007 and 2014 in Serbia. The results are evaluated with the traditional dichotomised method of MetS diagnosis, in this case the joint interim statement (JIS). The results obtained showed that the proposed risk quantification method outperformed the dichotomised method at diagnosing MetS even in individuals who present risk factor examination values at the threshold borderlines.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1141–1147},
numpages = {7},
keywords = {areal similarity degree, quantum particle swarm optimisation, metabolic syndrome},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252707,
author = {Anthopoulos, Leonidas and Janssen, Marijn and Weerakkody, Vishanth},
title = {Session Details: AW4City'17: 3rd International Smart City Workshop},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {AW4City'17 3rd International Smart City Workshop Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252708,
author = {Anthopoulos, Leonidas},
title = {Session Details: AW4City'17 Keynote Talk},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054710,
author = {Ishida, Toru},
title = {Digital City, Smart City and Beyond},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054710},
doi = {10.1145/3041021.3054710},
abstract = {This article revisited past digital cities, and discussed smart cities and the future. If we understand digital cities as exploration of cyber space and smart cities as exploitation of physical space, the next stage is to evolve networked society based on cyber physical systems. The current movements suggest two different directions, socialization of commerce and commercialization of society. We can predict the convergence of the two directions in the future.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1151–1152},
numpages = {2},
keywords = {smart city, digital city, cyber-physical system.},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252709,
author = {Anthopoulos, Leonidas},
title = {Session Details: AW4City'17 Session 1: Web Applications and Smart Cities for Urban Livability's Enhancement - Paradigms and Suggestions},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054716,
author = {Gyrard, Amelie and Serrano, Martin and Jares, Joao Bosco and Datta, Soumya Kanti and Ali, Muhammad Intizar},
title = {Sensor-Based Linked Open Rules (S-LOR): An Automated Rule Discovery Approach for IoT Applications and Its Use in Smart Cities},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054716},
doi = {10.1145/3041021.3054716},
abstract = {This paper introduces an automated rule discovery approach for IoT device data (S-LOR: Sensor-based Linked Open Rules) and its use in smart cities. S-LOR is built following Linked Open Data (LOD) standards and provides support for semantics-based mechanisms to share, reuse and execute logical rules for interpreting data produced by IoT systems. S-LOR follows LOD principles for data re-usability, semantics-based reasoning and interoperability. In this paper, S-LOR main capability is demonstrated in the context of enabling semantics-based reasoning mechanisms and tools according to application-demand and user requirements. S-LOR (i) supports an automated interpretation of IoT data by executing rules, and (ii) allows an automated rule discovery interface. The implemented S-LOR mechanism can automatically process and interpret data from IoT devices by using rule-based discovery paradigm. Its extension called Linked Open Reasoning (LOR) enables and encourages re-usability of reasoning mechanisms and tools for different IoT smart city applications. The use cases described in this paper fits in the domain of smart city applications within Internet of Things deployed systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1153–1159},
numpages = {7},
keywords = {internet of things, semantic web technologies, semantic web of things, knowledge, reasoning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054715,
author = {Cohen, Stephen and Money, William},
title = {Establishing Smart City Technical Standards and Guidance: A Way Forward},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054715},
doi = {10.1145/3041021.3054715},
abstract = {Solving technical problems with complex systems and integrating the many technologies employed in these multifaceted structures has been a recurring theme in Smart Cities research. This paper presents an analysis of the reason this problem has been so well explored but persists with no solution widely available. The problem is viewed as a combination of Smart City needs, governance, and increasingly technically difficult decisions. The paper describes the requirements that must be met to develop a framework that can address this seeming intractable and expanding integration concern, identifies the governance processes that can be used to address this problem, and to manage integration in Smart Cities, The solution proposed is a formalized accepted and managed technology regulated environment introduced by governance groups composed of city planners/managers, citizen, stake holders, and technology delivery organizations. The solution requirements dictate the establishment of a standard that would guide the development and usage of automated, autonomous components, integrating dynamically with software agents. All of this working to rapidly optimize shared resources through error handling processes executing largely at no cost except those of processing time, meeting safety guidelines, satisfying operational monitoring needs, and meeting post issue liability guidelines. This technical standard would obligate developers and vendors to meet safety standards and accept liability for malfeasance. As initiating steps, Smart City managers must come together and establish a basic understanding of the goals and regulations, and the methodologies for implementing them.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1161–1166},
numpages = {6},
keywords = {interoperability, mediators and data integration, data exchange, standardization},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054714,
author = {Moustaka, Vaia and Vakali, Athena and Anthopoulos, Leonidas G.},
title = {CityDNA: Smart City Dimensions' Correlations for Identifying Urban Profile},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054714},
doi = {10.1145/3041021.3054714},
abstract = {Smart cities evolve over multiple themes and areas with the development of cyber-physical systems and smart services that address several urban issues regarding economy, mobility, environment, people, living and governance. This evolution has obliged the definition of several conceptualization and evaluation models, which respect alternative smart city perspectives. This work proposes smart city profiling with the introduction of the "CityDNA" model, according which, smart city's dimensions' relevance can be captured and visualized. Based on this model, a smart city's profile can be defined and characterized, under a simple comprehensive view of local needs and challenges. A particular smart city scenario is highlighted as a proof of concept for CityDNA and future design and implementation ideas are identified and justified.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1167–1172},
numpages = {6},
keywords = {city boroughs, smart mobility, city profiles, smart cities, smart economy and mobility, dna structure, greater london areas},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054712,
author = {Vakali, Athena and Dematis, Ioannis and Tolikas, Athanasios},
title = {Vol4All: A Volunteering Platform to Drive Innovation and Citizens Empowerment},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054712},
doi = {10.1145/3041021.3054712},
abstract = {Cities nowadays have embraced the digital era and continuously strive to merge technological advancements with the benefit of their social capital and communities. A major quest is to place humans and their competences at the center of the efforts towards sustainable and smart cities. Citizen societies have widely accepted and practiced volunteering for years now and already a great number of volunteering actions and networks have flourished, in support and aid to several communities in need. Most popular volunteering networks have greatly capitalized on the rapid advance and spread of Internet and Web technologies, which are ideal for coordinating and monitoring of the volunteering tasks. The Vol4All platform advances this trend, by building on extended Internet technologies in its aim to support citizens' activism towards novel urban social innovation. Vol4All enables ideas exchange and crowdsourcing by facilitating citizens' involvement in the realization of community projects. Volunteering actors (initiators, participants, stakeholders) can easily interact via the Vol4All platform which enables volunteering opportunities dynamic sharing, evolution and monitoring. Such opportunities can be initiated by any authorized stakeholders, with a publicly open interface which allows citizens commitment assessment, best practices highlights, and a gamification style of interaction such that volunteering becomes a societal and growth asset.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1173–1178},
numpages = {6},
keywords = {citizens' empowerment, volunteering, social innovation, collective awareness, participation, web and mobile city applications, city platform},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3068853,
author = {Inselberg, Alfred and Anthopoulos, Leonidas G.},
title = {Visual Analytics for High Dimensional Data: Very Late Added Paper},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3068853},
doi = {10.1145/3041021.3068853},
abstract = {A dataset with M items has 2M subsets anyone of which may be the one satisfying our objective. With a good data display and interactivity our fantastic pattern-recognition defeats the combinatorial explosion by extracting insights from the visual patterns. This is the core reason for data visualization. With parallel coordinates, as illustrated here, the search for relations in multivariate data is transformed into a 2-D pattern recognition problem. A geometric classification algorithm yields the classification rule explicitly and visually. The minimal set of variables, features, are found and ordered by their predictive value. A model of a country's economy reveals sensitivities, impact of constraints, trade-offs and economic sectors unknowingly competing for the same resources. A glimpse into this beautiful and powerful multidimensional geometry is shown at the end.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1683–1687},
numpages = {5},
keywords = {multidimensional visualization, parallel coordinates},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252710,
author = {Tang, Jie and Vazirgiannis, Michalis and Tong, Hanghang and Dong, Yuxiao},
title = {Session Details: BigNet'17: 2nd International Workshop on Big Network Analytics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {BigNet'17 Workshop Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252711,
author = {Tang, Jie},
title = {Session Details: BigNet'17 Keynote Talk 1},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055362,
author = {Vazirgiannis, Michalis},
title = {Graph of Words: Boosting Text Mining Tasks with Graphs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055362},
doi = {10.1145/3041021.3055362},
abstract = {The Bag-of-words model has been the dominant approach for IR and Text mining for many years assuming the word independence and the frequencies as the main feature for feature selection and for query to document similarity. Although the long and successful usage, bag- of-words ignores words' order and distance within the document -- weakening thus the expressive power of the distance metrics. We propose graph-of-word, an alternative approach that capitalizes on a graph representation of documents and challenges the word independence assumption by taking into account words' order and distance. We applied graph-of-word in various tasks such as ad-hoc Information Retrieval, Single-Document Keyword Extraction, Text Categorization and Sub-event Detection in Textual Streams. In all cases the the graph of word approach, assisted by degeneracy at times, outperforms the state of the art base lines in all cases.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1181},
numpages = {1},
keywords = {graph degeneracy, text mining, graph mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252712,
author = {Tang, Jie},
title = {Session Details: BigNet'17 Session 1},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055364,
author = {Zhang, Han},
title = {Smart Jump: Automated Navigation Suggestion for Videos in MOOCs},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055364},
doi = {10.1145/3041021.3055364},
abstract = {Statistics show that, on average, each user of Massive Open Online Courses (MOOCs) uses "jump-back" to navigate a course video for 2.6 times. In this work, employing one of the largest Chinese MOOCs, XuetangX.com, as the source for our research, we study the extent to which we can develop a methodology to understand the user intention and help the user alleviate this problem by suggesting the best position for a jump-back. We demonstrate that it is possible to accurately predict 90% of users' jump-back intentions in the real online system. Moreover, our study reveals several interesting patterns, e.g., students in non-science courses tend to jump back from the first half of the course video, and students in science courses tend to replay for longer time.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1183–1184},
numpages = {2},
keywords = {moocs, video navigation, user intention},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252713,
author = {Vazirgiannis, Michalis},
title = {Session Details: BigNet'17 Keynote Talk 3},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055360,
author = {Liu, Wei},
title = {Constructing Knowledge Nets from Real-World Natural Language Texts},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055360},
doi = {10.1145/3041021.3055360},
abstract = {Mining knowledge from textual data has traditionally been applied on web-based publicly available resources, such as Wikipedia, online news, scientific publications and social medial such as Facebook and Twitter. In recent years, the increased maturity and accessibility of natural language processing and text mining algorithms have now raised serious interests beyond academia to uncover the chunk of corporate knowledge buried in hard-to-process natural language descriptions and reports. Such textual data are often in larger volumes and contain more valuable than numerical data.To make unstructured textual data written in natural languages ready for use in downstream data mining tasks, a typical workflow consists of anonymisation, text normalisation, domain entity and relation recognition. Despite intensive research efforts in the past decade, this seemingly simple workflow remains challenging when facing real-world text. The dominant issues are but not limited to: Lack of labelled training data: despite the fact that supervised learning based algorithms are more effective than unsupervised ones, it is often difficult if not impossible to obtain large amount of labelled documents.Not-so-reproducible results: the results of current algorithms are highly dependent on the chosen combination of the pre-processing steps and their ordering. The performance are sensitive to the statistical and linguistic features chosen.Lack of domain-independent representations: there is the lack of assurance that algorithms performing well for one text will also work for another.In this invited talk, we will take constructing knowledge nets as the objective, looking into the methods and techniques ranging from traditional feature-based distributional representation of words and phrases to the more recent deep learning enabled distributed vector representations. A demo Figure 1: A Knowlege Net Constructed from Textual Records of a prototype system (as shown in Figure 1) will showcase how the knowledge net construction workflow could be realised using textual records in real world databases},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1185},
numpages = {1},
keywords = {ontology learning, knowledge nets, text mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252714,
author = {Vazirgiannis, Michalis},
title = {Session Details: BigNet'17 Session 2},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252715,
author = {Xia, Feng and Liu, Huan and King, Irwin and Wang, Kuansan},
title = {Session Details: BigScholar'17: 4th WWW Workshop on Bbig Scholarly Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {BigScholar'17 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053048,
author = {Montgomery, Lucy},
title = {Understanding the Impacts of Open Access: Specialist Scholarly Books and Their Communities},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053048},
doi = {10.1145/3041021.3053048},
abstract = {Specialist scholarly books, the key form of publication in the Humanities and some Social Sciences, are often the forgotten younger-siblings of scholarly big data projects. Humanities disciplines are "peer review" rather than citation-based. Demand for data on how outputs perform from researchers, institutions and funding agencies -- has been lower than in the case of the exactsciences. Like book publishing more generally, large-scaleand timely data about distribution and usage of monographs has been hard to collect (or to access) until recently. No single publisher controls more than 4%. Books have been slower than journals to transition to digital formats[1]. Uniform approaches to DOIs and metadata are taking time to crystallise. Users engage with books in ways that are often difficult to 'see' at scale. Books have a much longer shelf-life than do articles; their impact can be measured in years and sometimes decades[2].In this talk I present an applied, deep-dive case study of efforts to identify and track the uses of Open Access (OA) specialist scholarly books at global scale, through the lens of the Knowledge Unlatched project[3]. Knowledge Unlatched Research is engaging with the data generated by the larger Knowledge Unlatched OA monograph initiative to help libraries, authors, publishers and research funders to understand what happens to their books once they have been made OA; and to explore what changes (and what doesn't) when open access licenses are applied to long form publications. I show that rather than being a disadvantage, many of the factors that make data about books difficult togather at scale are actually strengths. A diverse publishing landscape, a high-proportion of mission driven publishers, and libraries that care deeply about books and the communities that engage with them, are powerful advantages for HSS researchers.Helping communities to tackle challenges of coordination, transparency and trust as they relate to data about scholarly books, rather than simply going after "low hanging fruit", will be vital to ensuring that big-data innovations help rather than harm the Humanities. However, there are signs that this is happening. Because diverse smaller stakeholders hold the data that relates to specialist scholarly books,there are structural incentives for libraries, publishers, research-funders and researchers to work together to make conscious decisions about how data are aggregated, and by whom. Questions arise about whether this is best tackled within commercial or publicspaces,in light of what is now known about the value of being able to look across datasets to tell rich stories about engagement and impact; as well as the dangers of oversimplification of research metrics and the commercialisation of data resources [4]. It may yet turn out that being the forgotten younger sibling will allow a viable alternative system to emerge},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1199–1200},
numpages = {2},
keywords = {knowledge unlatched, open access, humanities, specialist scholarly books},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053049,
author = {Li, Jianxin},
title = {Overview of Influence Maximization in Social Media Data Analytics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053049},
doi = {10.1145/3041021.3053049},
abstract = {Social media has become a new and main platform for organizations to broadcast their policies, for companies to advertise their products, and for people to propagate their opinions. Therefore, social media data analytics has become a timely and significant research topic in recent years. In this talk, Dr. Li will first go through the social media background and the data representation of social media data. And then, he will briefly discuss the main stream research in social data mining and social computing. After that, Dr. Li will mainly introduce how the two most popular influence models are defined in social computing, what the influence maximization problem is defined, how its variants are defined. Finally, Dr. Li will introduce his current social media research project and discuss the interesting collaboration with attendees.This one-hour keynote targets researchers, designers and practitioners interested in social computing, social media data analytics, big data management systems and processing. While the audience with a good background in these areas would benefit most from this keynote, we believe the material to be presented would give general audience and newcomers an introductory pointer to the current work and important research topics in this field of viral marketing and social influence maximization, and inspire them to learn more. Only preliminary knowledge about graph, data mining, algorithms and their applications are needed.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1201},
numpages = {1},
keywords = {social media, social influence, social computing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053060,
author = {Ambite, Jose Luis and Fierro, Lily and Geigl, Florian and Gordon, Jonathan and Burns, Gully APC and Lerman, Kristina and Van Horn, John D.},
title = {BD2K ERuDIte: The Educational Resource Discovery Index for Data Science},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053060},
doi = {10.1145/3041021.3053060},
abstract = {The field of data science has developed over the years to enable the efficient integration and analysis of the increasingly large amounts of data being generated across many domains, ranging from social media, to sensor networks, to scientific experiments. Numerous subfields of biology and medicine, such as genetics, neuroimaging, and mobile health, are witnessing a data explosion that promises to revolutionize biomedical science by yielding novel insights and discoveries. To address the challenges posed by biomedical big data, the National Institutes of Health (NIH) launched the Big Data to Knowledge (BD2K) initiative (datascience.nih.gov). An important component of this effort is the training of biomedical researchers. To this end, the NIH has funded the BD2K Training Coordinating Center (TCC). A core activity of the BD2K TCC is to develop a web portal (bigdatau.org) to provide personalized training in data science to biomedical researchers.In this paper, we describe our approach and initial efforts in constructing ERuDIte, the Educational Resource Discovery Index for Data Science, which powers the BD2K TCC web portal. ERuDIte harvests a wealth of resources available online for learning data science, both for beginners and experts, including massive open online courses (MOOCs), videos of tutorials and research talks presented at conferences, textbooks, blog posts, and standalone web pages. Though the potential volume of resources is exciting, these online learning materials are highly heterogeneous in quality, difficulty, format, and topic. As a result, this mix of content makes the field intimidating to enter and difficult to navigate. Moreover, data science is a rapidly evolving field, so there is a constant influx of new materials and concepts. ERuDIte leverages data science techniques to build the data science index. This paper describes how ERuDIte uses data extraction, data integration, machine learning, information retrieval, and natural language processing techniques to automatically collect, integrate, describe and organize existing online resources for learning data science.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1203–1211},
numpages = {9},
keywords = {information integration, machine learning, online educational resources},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053052,
author = {Wang, Jingbo and Aryani, Amir and Wyborn, Lesley and Evans, Ben},
title = {Providing Research Graph Data in JSON-LD Using Schema.Org},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053052},
doi = {10.1145/3041021.3053052},
abstract = {In this position paper, we describe a pilot project that provides Research Graph records to external web services using JSON-LD. The Research Graph database contains a large-scale graph that links research datasets (i.e., data used to support research) to funding records (i.e. grants), publications and researcher records such as ORCID profiles. This database was derived from the work of the Research Data Alliance Working Group on Data Description Registry Interoperability (DDRI), and curated using the Research Data Switchboard open source software. By being available in Linked Data format, the Research Graph database is more accessible to third-party web services over the Internet, which thus opens the opportunity to connect to the rest of the world in the semantic format.The primary purpose of this pilot project is to evaluate the feasibility of converting registry objects in Research Graph to JSON-LD by accessing widely used vocabularies published at Schema.org. In this paper, we provide examples of publications, datasets and grants from international research institutions such as CERN INSPIREHEP, National Computational Infrastructure (NCI) in Australia, and Australian Research Council (ARC). Furthermore, we show how these Research Graph records are made semantically available as Linked Data through using Schema.org. The mapping between Research Graph schema and Schema.org is available on GitHub repository. We also discuss the potential need for an extension to Schema.org vocabulary for scholarly communication.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1213–1218},
numpages = {6},
keywords = {schema.org, json-ld, linked data, semantic web},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053056,
author = {Chen, Yang and Ding, Cong and Hu, Jiyao and Chen, Ruichuan and Hui, Pan and Fu, Xiaoming},
title = {Building and Analyzing a Global Co-Authorship Network Using Google Scholar Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053056},
doi = {10.1145/3041021.3053056},
abstract = {By publishing papers together, academic authors can form a co-authorship network, modeling the collaboration among them. This paper presents a data-driven study by crawling and analyzing the vast majority of author profiles of Google Scholar. We make the following major contributions: (1) We present a demographic analysis and get an informative overview of the authors from different aspects, such as the distribution of countries, scientific labels, and academic titles. (2) Based on the publication lists of crawled authors, we build a global co-authorship network with 402.39K authors to study the collaboration among authors. With the aid of social network analysis (SNA), we observe several unique features of this network. (3) We explore the relationship between the co-authorship network and citation metrics. We find a strong correlation between PageRank and h-index.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1219–1224},
numpages = {6},
keywords = {social network analysis, co-authorship network, google scholar, citation metrics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053059,
author = {Tao, Shibo and Wang, Xiaorong and Huang, Weijing and Chen, Wei and Wang, Tengjiao and Lei, Kai},
title = {From Citation Network to Study Map: A Novel Model to Reorganize Academic Literatures},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053059},
doi = {10.1145/3041021.3053059},
abstract = {As the number of academic papers and new technologies soars, it has been increasingly difficult for researchers, especially beginners, to enter a new research field. Researchers often need to study a promising paper in depth to keep up with the forefront of technology. Traditional Query-Oriented study method is time-consuming and even tedious. For a given paper, existent academic search engines like Google Scholar tend to recommend relevant papers, failing to reveal the knowledge structure. The state-of-the-art Map-Oriented study methods such as AMiner and AceMap can structure scholar information, but they're too coarse-grained to dig into the underlying principles of a specific paper. To address this problem, we propose a Study-Map Oriented method and a novel model called RIDP (Reference Injection based Double-Damping PageRank) to help researchers study a given paper more efficiently and thoroughly. RIDP integrates newly designed Reference Injection based Topic Analysis method and Double-Damping PageRank algorithm to mine a Study Map out of massive academic papers in order to guide researchers to dig into the underlying principles of a specific paper. Experiment results on real datasets and pilot user studies indicate that our method can help researchers acquire knowledge more efficiently, and grasp knowledge structure systematically.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1225–1232},
numpages = {8},
keywords = {topic analysis, academic papers, reference injection, double-damping pagerank, study map},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053053,
author = {Jin, Jian and Geng, Qian and Zhao, Qian and Zhang, Lixue},
title = {Integrating the Trend of Research Interest for Reviewer Assignment},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053053},
doi = {10.1145/3041021.3053053},
abstract = {Reviewer assignment problem in the research field usually refers to invite experts for comments on the quality of papers, projects, etc. Different factors in conventional approaches are reckoned to choose appropriate reviewers, such as the relevance between reviewer candidates and submissions, the diversity of candidates. However, many studies ignore the temporal changes of reviewer interest and the stability of reviewers' interest trend. Accordingly, in this research, three indispensable aspects are analyzed, including the relevance between reviewer candidates and submissions, the interest trend of candidates as well as the authority of candidates. Next, with extracted aspects, the reviewer assignment is formulated as an integer linear programming problem. Finally, categories of comparative experiments are conducted with two large datasets that are built from WANFANG and ArnetMiner, which shows the availability of the proposed approach in modeling the temporal changes of reviewers' research interest. Also, it demonstrates the effectiveness of the proposed approach for the reviewer assignment problem.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1233–1241},
numpages = {9},
keywords = {expert recommendation, reviewer assignment, research interest trend},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053061,
author = {Bai, Xiaomei and Hou, Jie and Du, Hongzhuang and Kong, Xiangjie and Xia, Feng},
title = {Evaluating the Impact of Articles with Geographical Distances between Institutions},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053061},
doi = {10.1145/3041021.3053061},
abstract = {Evaluating the impact of scholarly papers plays an important role for addressing recruitment decision, funding allocation and promotion, etc. Yet little is known how actual geographic distance influences the impact of scholarly papers. In this paper, we leverage the law of geographic distance and citations between different institutions to weight quantum Pagerank algorithm for objectively measuring the impact of scholarly papers. The results indicate that the weighted quantum PageRank algorithm can better differentiate the impact of scholarly papers compared to PageRank algorithm.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1243–1244},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053064,
author = {Effendy, Suhendry and Yap, Roland H.C.},
title = {Analysing Trends in Computer Science Research: A Preliminary Study Using The Microsoft Academic Graph},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053064},
doi = {10.1145/3041021.3053064},
abstract = {Research in Computer Science (CS) evolves rapidly in a dynamic fashion. New research area may emerge and attract researchers, while older areas may have lesser interest from researchers. Studying how trends evolve in CS can be interesting from several dimensions. Furthermore, it can be used to craft research agendas. In this paper, we present trend analysis on research area in CS. We also look at citation trend analysis. Our analysis is performed using the Microsoft Academic Graph dataset. We propose the FoS score to measure the level of interest in any particular research area or topic. We apply the FoS score to investigate general publication trends, citation trends, evolution of research areas, and relation between research areas in CS.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1245–1250},
numpages = {6},
keywords = {computer science, trend analysis, bibliographic databases},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053051,
author = {Sarkar, Santonu and Lakdawala, Rumana and Datta, Subhajit},
title = {Predicting the Impact of Software Engineering Topics: An Empirical Study},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053051},
doi = {10.1145/3041021.3053051},
abstract = {Predicting the future is hard, more so in active research areas. In this paper, we customize an established model for citation prediction of research papers and apply it on research topics. We argue that research topics, rather than individual publications, have wider relevance in the research ecosystem, for individuals as well as organizations. In this study, topics are extracted from a corpus of software engineering publications covering 55,000+ papers written by more than 70,000 authors across 56 publication venues, over a span of 38 years, using natural language processing techniques. We demonstrate how critical aspects of the original paper-based prediction model are valid for a topic-based approach. Our results indicate the customized model is able to predict citations for many of the topics considered in our study with reasonably high accuracy. Insights from these results indicate the promise of citation of prediction of research topics, and its utility for individual researchers, as well as research groups.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1251–1257},
numpages = {7},
keywords = {topic model, citation prediction, software engineering publication},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053054,
author = {Lee, Ivan and Xia, Feng and Roos, G\"{o}ran},
title = {An Observation of Research Complexity in Top Universities Based on Research Publications},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053054},
doi = {10.1145/3041021.3053054},
abstract = {This paper investigates research specialisation of top ranked universities around the world. The revealed comparative advantage in different research fields are determined according to the number of research articles published. Subsequently, measures of research ubiquity and diversity, and research complexity index of each university, are obtained and discussed. The study is conducted on top-ranked universities according to Shanghai Jiao Tong Academic Ranking of World Universities, with bibliographical details extracted Microsoft Academic Graph data set and research fields of journals labelled with SCImago Journal Classification. Diversity-ubiquity distributions, relevance of RCI and university ranks, and geographical RCI distributions are examined in this paper.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1259–1265},
numpages = {7},
keywords = {complexity modelling, scientometrics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053062,
author = {Gupta, Shashank and Varma, Vasudeva},
title = {Scientific Article Recommendation by Using Distributed Representations of Text and Graph},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053062},
doi = {10.1145/3041021.3053062},
abstract = {Scientific article recommendation problem deals with recommending similar scientific articles given a query article. It can be categorized as a content based similarity system. Recent advancements in representation learning methods have proven to be effective in modeling distributed representations in different modalities like images, languages, speech, networks etc. The distributed representations obtained using such techniques in turn can be used to calculate similarities. In this paper, we address the problem of scientific paper recommendation through a novel method which aims to combine multimodal distributed representations, which in this case are: 1. distributed representations of paper's content, and 2. distributed representation of the graph constructed from the bibliographic network. Through experiments we demonstrate that our method outperforms the state-of-the-art distributed representation methods in text and graph, by 29.6% and 20.4%, both in terms of precision and mean-average-precision respectively.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1267–1268},
numpages = {2},
keywords = {representation learning, deepwalk, recommendation system, cca, doc2vec},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053063,
author = {Zhang, Da and Kabuka, Mansur R.},
title = {Top-K Entity Units Retrieval Over Big Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053063},
doi = {10.1145/3041021.3053063},
abstract = {During the past several years, data size has increased explosively. This data explosion tendency has impacted various fields ranging from biomedical engineering, business consulting to social media and mobile application. Big Data is a two sided sword. While it provides incredibly treasured insights in commercial scope and innovative discovery in the scientific field, Big Data also has many challenges, such as complication in data storage, data processing, data analysis and data visualization. Among all these challenges, keyword searching over a large volume of data prevails as one of the four tasks defined by Bizer et al. at the year of 2012. Keyword searching refers to retrieving the objects relevant to the entities of concern using scientific computational methods. Consequently, efficiently solving the problem of keyword searching can contribute as a foundation to diverse Big Data applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1269–1272},
numpages = {4},
keywords = {keyword searching, information retrieval, big data},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053065,
author = {Howe, Bill and Lee, Po-shen and Grechkin, Maxim and Yang, Sean T. and West, Jevin D.},
title = {Deep Mapping of the Visual Literature},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053065},
doi = {10.1145/3041021.3053065},
abstract = {We consider how patterns of figure use in the scientific literature relate to impact, change over time, and vary across disciplines. We use a convolutional neural network to embed figures as feature vectors in a high-dimensional space, then visualize this space as a 2D heatmap to expose patterns. We consider how these patterns vary with respect to time, impact, and discipline, concluding that high-impact papers tend to include significantly more data-carrying figures (i.e., visualizations), despite a downward trend in such figures overall. We also show how this approach can be used to bootstrap targeted information extraction projects for specific figure types, describing one such project involving phylogenetic trees.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1273–1277},
numpages = {5},
keywords = {viziometrics, deep learning, machine vision, scientometrics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053058,
author = {Portenoy, Jason and West, Jevin D.},
title = {Visualizing Scholarly Publications and Citations to Enhance Author Profiles},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053058},
doi = {10.1145/3041021.3053058},
abstract = {With data on scholarly publications becoming more abundant and accessible, there exist new opportunities for using this information to provide rich author profiles to display and explore scholarly work. We present a pair of linked visualizations connected to the Microsoft Academic Graph that can be used to explore the publications and citations of individual authors. We provide an online application with which a user can manage collections of papers and generate these visualizations.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1279–1282},
numpages = {4},
keywords = {scholarly influence, scholarly data, citation visualization, author profiles, citation networks, science of science, bibliometrics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252716,
author = {Mishra, Shivakant and Blackburn, Jeremy and Huang, Bert and Lv, Qin and Hosseinmardi, Homa},
title = {Session Details: CyberSafety'17: 2nd International Workshop on Computational Methods in CyberSafety},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {CyberSafety 2017 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053890,
author = {Chatzakou, Despoina and Kourtellis, Nicolas and Blackburn, Jeremy and De Cristofaro, Emiliano and Stringhini, Gianluca and Vakali, Athena},
title = {Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053890},
doi = {10.1145/3041021.3053890},
abstract = {Over the past few years, online aggression and abusive behaviors have occurred in many different forms and on a variety of platforms. In extreme cases, these incidents have evolved into hate, discrimination, and bullying, and even materialized into real-world threats and attacks against individuals or groups. In this paper, we study the Gamergate controversy. Started in August 2014 in the online gaming world, it quickly spread across various social networking platforms, ultimately leading to many incidents of cyberbullying and cyberaggression. We focus on Twitter, presenting a measurement study of a dataset of 340k unique users and 1.6M tweets to study the properties of these users, the content they post, and how they differ from random Twitter users. We find that users involved in this ``Twitter war'' tend to have more friends and followers, are generally more engaged and post tweets with negative sentiment, less joy, and more hate than random users. We also perform preliminary measurements on how the Twitter suspension mechanism deals with such abusive behaviors. While we focus on Gamergate, our methodology to collect and analyze tweets related to aggressive and bullying activities is of independent interest.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1285–1290},
numpages = {6},
keywords = {cyberbullying, gamergate, twitter, abusive},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053889,
author = {Edwards, Matthew and Peersman, Claudia and Rashid, Awais},
title = {Scamming the Scammers: Towards Automatic Detection of Persuasion in Advance Fee Frauds},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053889},
doi = {10.1145/3041021.3053889},
abstract = {Advance fee fraud is a significant component of online criminal activity. Fraudsters can often make off with significant sums, and victims will usually find themselves plagued by follow-up scams. Previous studies of how fraudsters persuade their victims have been limited to the initial solicitation emails sent to a broad population of email users. In this paper, we use the lens of scam-baiting -- a vigilante activity whereby members of the public intentionally waste the time of fraudsters -- to move beyond this first contact and examine the persuasive tactics employed by a fraudster once their victim has responded to a scam. We find linguistic patterns in scammer and baiter communications that suggest that the mode of persuasion used by scammers shifts over a conversation, and describe a corresponding stage model of scammer persuasion strategy. We design and evaluate a number of classifiers for identifying scam-baiting conversations amidst regular email, and for separating scammer from baiter messages based on their textual content, achieving high classification accuracy for both tasks. This forms a crucial basis for automated intervention, with a tool for identifying victims and a model for understanding how they are currently being exploited.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1291–1299},
numpages = {9},
keywords = {persuasion, scam-baiting, mass-marketing fraud, cybercrime, advance fee fraud},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053892,
author = {Mba, Gibson and Onaolapo, Jeremiah and Stringhini, Gianluca and Cavallaro, Lorenzo},
title = {Flipping 419 Cybercrime Scams: Targeting the Weak and the Vulnerable},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053892},
doi = {10.1145/3041021.3053892},
abstract = {Most of cyberscam-related studies focus on threats perpetrated against the Western society, with a particular attention to the USA and Europe. Regrettably, no research has been done on scams targeting African countries, especially Nigeria, where the notorious and (in)famous 419 advanced-fee scam, targeted towards other countries, originated. How- ever, as we know, cybercrime is a global problem affecting all parties. In this study, we investigate a form of advance fee fraud scam unique to Nigeria and targeted at Nigerians, but unknown to the Western world. For the study, we rely substantially on almost two years worth of data harvested from an on-line discussion forum used by criminals. We complement this dataset with recent data from three other active forums to consolidate and generalize the research. We apply machine learning to the data to understand the criminals' modus operandi. We show that the criminals exploit the socio-political and economic problems prevalent in the country to craft various fraud schemes to defraud vulnerable groups such as secondary school students and unemployed graduates. The result of our research can help potential victims and policy makers to develop measures to counter the activities of these criminal groups.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1301–1310},
numpages = {10},
keywords = {scam, 419, cybercrime},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053891,
author = {Whitty, Monica and Edwards, Matthew and Levi, Michael and Peersman, Claudia and Rashid, Awais and Sasse, Angela and Sorell, Tom and Stringhini, Gianluca},
title = {Ethical and Social Challenges with Developing Automated Methods to Detect and Warn Potential Victims of Mass-Marketing Fraud (MMF)},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053891},
doi = {10.1145/3041021.3053891},
abstract = {Mass-marketing frauds (MMFs) are on the increase. Given the amount of monies lost and the psychological impact of MMFs there is an urgent need to develop new and effective methods to prevent more of these crimes. This paper reports the early planning of automated methods our interdisciplinary team are developing to prevent and detect MMF. Importantly, the paper presents the ethical and social constraints involved in such a model and suggests concerns others might also consider when developing automated systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1311–1314},
numpages = {4},
keywords = {online scams, cybercrime, mass-marketing fraud, cybersafety},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252717,
author = {Zhang, Rui and Reynolds, Mark and Li, Jianxin and Aamir, Muhammad and Yin, Hongzhi and Chen, Ling},
title = {Session Details: IWSC'17: 1st International Workshop on Social Computing},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {IWSC 2017 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051144,
author = {Sun, Yizhou},
title = {User Stance Prediction via Online Behavior Mining},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051144},
doi = {10.1145/3041021.3051144},
abstract = {Nowadays social media, such as Twitter and all kinds of online forums, becomes a platform where people can express their opinions implicitly or explicitly. For example, in Twitter, people follow people they trust, and retweet the tweets they agree. In online forums, such as PoliticalForum.com, people explicitly express their opinions and interact with each other using text. Our goal is to understand people's stance on some (political) issue according to their online behaviors that can be captured in social media, including links they have issued and content they have generated, which is essential for national security and policy making. Existing attempts in this direction, however, oversimplified the problem in several aspects. First, they usually treat the user stance prediction problem as a binary classification problem, e.g., left or right, or positive or negative, while the extent of people's attitude is very critical. Second, most of the existing work depends heavily on labels, which is unacceptable for large-scale social media data and impossible to label when user stance is modeled as a numerical number. Third, most of the methods do not attempt to understand the rationality behind their online behaviors. In contrast, (1) our proposed methods can predict user stance in terms of numerical values; (2) our methods are unsupervised methods and no labels are required for the analysis; and (3) the models are carefully designed with the consideration of human rationality of their choices. In particular, two specific user stance prediction problems will be included in this keynote: (1) political ideology detection for ordinary twitter users via their heterogeneous types of links; and (2) user stance prediction in news commenting system. These methodologies may benefit more applications ranging across a wide spectrum of domains.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1317},
numpages = {1},
keywords = {social computing, online behavior mining, social media., user stance prediction},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051146,
author = {Li, Yongjun and Peng, You and Zhang, Zhen and Xu, Quanqing and Yin, Hongzhi},
title = {Understanding the User Display Names across Social Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051146},
doi = {10.1145/3041021.3051146},
abstract = {The display names that an individual uses in various online social networks always contain some redundant information because some people tend to use the similar names across different networks to make them easier to remember or to build their online reputation. In this paper, we aim to measure the redundant information between different display names of the same individual. Based on the crosssite linking function, we first develop a specific distributed crawler to extract the display names that individuals select for different social networks, and we give an overview on the display names we extracted. Then we measure and analyze the redundant information in three ways: length similarity, character similarity and letter distribution similarity, comparing with display names of different individuals. We also analyze the evolution of redundant information over time. We find 45% of users tend to use the same display name across OSNs. Our findings also demonstrate that display names of the same individual show high similarity. The evolution analysis results show that redundant information is time-independent. Awareness of the redundant information between the display names can benefit many applications, such as user identification across social networks.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1319–1326},
numpages = {8},
keywords = {soical computing, web computing, complex network, data mining},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051150,
author = {Zhang, Kewei and Arablouei, Reza and Jurdak, Raja},
title = {Predicting Prevalence of Influenza-Like Illness From Geo-Tagged Tweets},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051150},
doi = {10.1145/3041021.3051150},
abstract = {Modeling disease spread and distribution using social media data has become an increasingly popular research area. While Twitter data has recently been investigated for estimating disease spread, the extent to which it is representative of disease spread and distribution in a macro perspective is still an open question. In this paper, we focus on macro-scale modeling of influenza-like illnesses (ILI) using a large dataset containing 8,961,932 tweets from Australia collected in 2015. We first propose modifications of the state-of-the-art ILI-related tweet detection approaches to acquire a more refined dataset. We normalize the number of detected ILI-related tweets with Internet access and Twitter penetration rates in each state. Then, we establish a state-level linear regression model between the number of ILI-related tweets and the number of real influenza notifications. The Pearson correlation coefficient of the model is 0.93. Our results indicate that: 1) a strong positive linear correlation exists between the number of ILI-related tweets and the number of recorded influenza notifications at state scale; 2) Twitter data has promising ability in helping detect influenza outbreaks; 3) taking into account the population, Internet access and Twitter penetration rates in each state enhances the prevalence modeling analysis.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1327–1334},
numpages = {8},
keywords = {twitter, regression analysis, public health monitoring, disease modeling, data mining, classification},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051151,
author = {Shi, Zhenkun and Zuo, Wanli and Chen, Weitong and Yue, Lin and Han, Jiayu and Feng, Lizhou},
title = {User Relation Prediction Based on Matrix Factorization and Hybrid Particle Swarm Optimization},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051151},
doi = {10.1145/3041021.3051151},
abstract = {Many real-world domains are relational in nature, consisting of a set of objects related to each other in complex ways. Matrix factorization is an effective method in relationship prediction, However, traditional matrix factorization link prediction methods can only be used for non-negative matrix. In this paper, a generalized framework, itelliPrediction, is presented that is able to deal with positive and negative matrix. The novel itelliPrediction framework is domain independent and with high precision. We validate our approach using two different data sources, an open data sets and a real-word dataset, the result demonstrated that the quality of our approach is comparable to, if not better than, exiting state of the art relation predication framework.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1335–1341},
numpages = {7},
keywords = {relation prediction, matrix factorization, social networks, machine learning},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051153,
author = {Taheri, Seyed Mohammad and Mahyar, Hamidreza and Firouzi, Mohammad and Ghalebi K., Elahe and Grosu, Radu and Movaghar, Ali},
title = {Extracting Implicit Social Relation for Social Recommendation Techniques in User Rating Prediction},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051153},
doi = {10.1145/3041021.3051153},
abstract = {Recommendation plays an increasingly important role in our daily lives. Recommender systems automatically suggest items to users that might be interesting for them. Recent studies illustrate that incorporating social trust in Matrix Factorization methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics to compute and predict trust scores between users based on their interactions. In this paper, first we present how social relation can be extracted from users' ratings to items by describing Hellinger distance between users in recommender systems. Then, we propose to incorporate the predicted trust scores into social matrix factorization models. By analyzing social relation extraction from three well-known real-world datasets, which both: trust and recommendation data available, we conclude that using the implicit social relation in social recommendation techniques has almost the same performance compared to the actual trust scores explicitly expressed by users. Hence, we build our method, called Hell-TrustSVD, on top of the state-of-the-art social recommendation technique to incorporate both the extracted implicit social relations and ratings given by users on the prediction of items for an active user. To the best of our knowledge, this is the first work to extend TrustSVD with extracted social trust information. The experimental results support the idea of employing implicit trust into matrix factorization whenever explicit trust is not available, can perform much better than the state-of-the-art approaches in user rating prediction.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1343–1351},
numpages = {9},
keywords = {social recommendation techniques, matrix factorization, recommender systems, social networks},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051159,
author = {Chen, Hongxu and Yin, Hongzhi and Li, Xue and Wang, Meng and Chen, Weitong and Chen, Tong},
title = {People Opinion Topic Model: Opinion Based User Clustering in Social Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051159},
doi = {10.1145/3041021.3051159},
abstract = {Mining various hot discussed topics and corresponding opinions from different groups of people in social media (e.g., Twitter) is very useful. For example, a decision maker in a company wants to know how different groups of people (customers, staff, competitors, etc.) think about their services, facilities, and things happened around. In this paper, we are focusing on the problem of finding opinion variations based on different groups of people and introducing the concept of opinion based community detection. Further, we also introduce a generative graphic model, namely People Opinion Topic (POT) model, which detects social communities, associated hot discussed topics, and perform sentiment analysis simultaneously by modelling user's social connections, common interests, and opinions in a unified way. This paper is the first attempt to study community and opinion mining together. Compared with traditional social communities detection, the detected communities by POT model are more interpretable and meaningful. In addition, we further analyse how diverse opinions distributed and propagated among various social communities. Experiments on real twitter dataset indicate our model is effective.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1353–1359},
numpages = {7},
keywords = {opinion, community detection, social network, topic model},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053407,
author = {Li, Jiuyong},
title = {Beyond Understanding and Prediction: Data Mining for Action},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053407},
doi = {10.1145/3041021.3053407},
abstract = {Association analysis and prediction are two major tasks in data mining, and they represent two foremost objectives: data exploration for understanding and model construction for prediction. Data mining is known as a process to convert raw data to useful information --- knowledge. However, what do we do with the knowledge discovered from data? We will need knowledge to enable actions, such as preventing diseases in health care, taking actions to retain customers, and etc.One important attribute of knowledge is actionability. In order to be acted on, the knowledge must encode causal relationships to imply the mechanisms of the systems under consideration. Causal inference is a sophisticated topic that spans multiple disciplines, computer science, statistics, medicine, economics, and social science, to name a few. There are a number of well-established frameworks for causal inference in data with assumptions. Unfortunately, the assumptions are not directly testable in data, and hence there are limited off-the-shelf data mining methods for causal discovery. Many practitioners still use conventional machine learning methods for the tasks which actually requires causal inference [1].It is desirable to have some simple data mining tools to explore causal relationships without or with few assumptions. The discoveries may not be proved causal, but are high quality candidates excluding many non-causal or spurious relationships. This will be a significant step forward in actionable data mining since it is well known that association rule mining generates too many spurious relationships and a classification model often provides a correct prediction based on non-interpretable (or even wrong) evidence. The spurious relationships and non-interpretable or wrong evidence hinder many data mining applications, especially in medical and social science areas.We have been using some well-known causal inference principles to discover causal relationships and building causally interpretable data mining models, such as causal rules [2] and causal decision trees [3], and applying causal discovery methods to real world biological problems [4, 5]. In this talk, I will discuss some of our exploratory work in this promising direction.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1361},
numpages = {1},
keywords = {prediction, data mining, action},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051156,
author = {Jiang, Fang-Zhou and Thilakarathna, Kanchana and Hassan, Mahbub and Ji, Yusheng and Seneviratne, Aruna},
title = {Efficient Content Distribution in DOOH Advertising Networks Exploiting Urban Geo-Social Connectivity},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051156},
doi = {10.1145/3041021.3051156},
abstract = {Digital out-of-home (DOOH) advertising networks, comprised of pervasive distributed digital signages (screens), are rapidly growing. It is reported that more than 70% of DOOH revenue comes from local ads, while it is especially challenging to decide when and where to deliver the most suitable ad due to the spatio-temporal dynamics of human mobility and preferences. Understanding urban geo-social connectivity in terms of people movement would greatly benefit ad content distribution, and could potentially be utilized by a large number of mobile applications and geo-social services. However, existing DOOH ad distribution systems are designed to target individuals, which might not be the best choice in public spaces, and do not consider the preferences of "cohort of users". In this paper, we propose an alternative approach to target cohort of users extracting urban geo-social connectivity through large-scale mobile network data and existing geo-social service data. We construct a dynamic urban geo-social connectivity graph, and formulate the problem of distributing ads for maximum exposure to the "right" users under a constrained budget. Hence, we propose a heuristic algorithm. Simulation results show that our system targeting "cohort of users" achieves a maximum 300% improvement compared to naive distributing method in displaying ads to the "right people" when user preferences are completely known, while a minimum of 25% improvement when the knowledge of user preferences is limited.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1363–1370},
numpages = {8},
keywords = {spatio-temporal dynamics, content distribution, digital out-of-home network},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051154,
author = {Kong, Xiangjie and Jiang, Huizhen and Bekele, Teshome Megersa and Wang, Wei and Xu, Zhenzhen},
title = {Random Walk-Based Beneficial Collaborators Recommendation Exploiting Dynamic Research Interests and Academic Influence},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051154},
doi = {10.1145/3041021.3051154},
abstract = {It is laborious for researchers to find proper collaborators who can provide researching guidance besides collaborating. Beneficial Collaborators (BCs), researchers who have a high academic level and relevant topics, can genuinely help researchers to enrich their research. Though many efforts have made to develop collaborator recommendation, most of existing works have mainly focused on recommending most possible collaborators with no intention to recommend specifically the BCs. In this paper, we propose the Beneficial Collaborator Recommendation (BCR) model that considers the dynamic research interest of researcher's and academic level of collaborators to recommend the BCs. First, we run the LDA model on the abstract of researchers' publications in each year for topic clustering. Second, we fix generated topic distribution matrix by a time function to fit interest dynamic transformation. Third, we compute the similarity between the collaboration candidate's feature matrix and the target researcher. Finally, we combine the similarity and influence in collaborators network to fix rank score and mine the candidates with high academic level and academic social impact. BCR generates the topN BCs recommendation. Extensive experiments on a dataset with citation network demonstrate that BCR performs better in terms of precision, recall, F1 score and the recommendation quality compared to baseline methods.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1371–1377},
numpages = {7},
keywords = {collaborator recommendation, dynamic research interest, academic influence},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051145,
author = {Sohail, Ammar and Taniar, David and Z\"{u}fle, Andreas and Jeong-ho, Park},
title = {Query Processing in Location-Based Social Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051145},
doi = {10.1145/3041021.3051145},
abstract = {The widespread proliferation of location-acquisition techniques and GPS-embedded mobile devices resulted in the generation of geo-tagged data at unprecedented scale and have essentially enhanced the user experience in location-based services associated with social networks. Such location-based social networks allow people to record and share their location and are a rich source of information which can be exploited to study people's various attributes and characteristics and can provide various Geo-Social (GS) services. In this demonstration, we propose a new type of query called Top-k Geo-Social (TGS) query, which enriches the semantics of the conventional spatial query by introducing a social relevance attribute. Similarly, users formulate their TGS queries and view the results through browser-based client side interface. On the server side, three approaches namely, 1) Social-First 2) Spatial-First and 3) Hybrid are proposed to efficiently process TGS queries.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1379–1381},
numpages = {3},
keywords = {geosocial query, geosocial networking, graph database, spatio-social applications, social networks, geographic information systems},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051152,
author = {Greco, Sergio and Molinaro, Cristian and Pulice, Chiara and Quintana, Ximena},
title = {Efficient Maximum Flow Maintenance on Dynamic Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051152},
doi = {10.1145/3041021.3051152},
abstract = {While many efficient algorithms for the maximum flow problem have been proposed over the years, they are designed to work with static networks, and thus they need to recompute a new solution from scratch every time an update occurs. Such approaches are impractical in many current application where updates are frequent. To overcome these limitations, this paper proposes efficient incremental algorithms for maintaining the maximum flow in dynamic networks.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1383–1385},
numpages = {3},
keywords = {maximum flow problem, incremental algorithms},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051147,
author = {Hayashi, Ryota and Shimizu, Nobuyuki and Morishima, Atsuyuki},
title = {Worker Viewpoints: Valuable Feedback for Microtask Designers in Crowdsourcing},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051147},
doi = {10.1145/3041021.3051147},
abstract = {One of the problems a requester faces when crowdsourcing a microtask is that, due to the underspecified or ambiguous task description, workers may misinterpret the microtask at hand. We call a set of such interpretations worker viewpoints. In this paper, we argue that assisting requesters to gather a worker's interpretation of the microtask can help in providing useful feedback to designers, who may restate the task description if necessary. In our method, we create a corpus of viewpoints annotated with the types of viewpoints that reflect the logical structure embedded in them. Our experimental results suggest that the logic-oriented annotation is effective in choosing useful viewpoints from a possibly huge set of collected viewpoints, in the sense that removing viewpoints of particular types did not affect the quality of revised task instructions. We also show that the logic-oriented annotation can perform comparably with an entropy-based method, without several workers performing the same task in parallel.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1387–1393},
numpages = {7},
keywords = {text analysis, data quality, crowdsourcing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051148,
author = {Zhang, Menghao and Hu, Binbin and Shi, Chuan and Wang, Bai},
title = {Local Low-Rank Matrix Approximation with Preference Selection of Anchor Points},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051148},
doi = {10.1145/3041021.3051148},
abstract = {Matrix factorization is widely used in personalized recommender systems, text mining, and computer vision. A general assumption to construct matrix approximation is that the original matrix is of global low rank, while Joonseok Lee et al. proposed that many real matrices may be not globally low rank, and thus a locally low-rank matrix approximation method has been proposed.[11] However, this kind of matrix approximation method still leaves some important issues unsolved, for example, the randomly selecting anchor nodes. In this paper, we study the problem of the selection of anchor nodes to enhance locally low-rank matrix approximation. We propose a new model for local low-rank matrix approximation which selects anchor-points using a heuristic method. Our experiments indicate that the proposed method outperforms many state-of-the-art recommendation methods. Moreover, the proposed method can significantly improve algorithm efficiency, and it is easy to parallelize. These traits make it potential for large scale real-world recommender systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1395–1403},
numpages = {9},
keywords = {matrix approximation, clustering, recommender systems, low-rank},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inbook{10.1145/3041021.3051149,
author = {Zhang, Limeng and Zhou, Rui and Jiang, Haixin and Wang, Hua and Zhang, Yanchun},
title = {Item Group Recommendation: A Method Based on Game Theory},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051149},
abstract = {In this paper, we focus on recommending an item set to multiple users. Group recommender systems are designed to deal with the issue of recommending items for a user group. However, in some scenarios such as gift set promotion (different items are packed together as a gift set), album promotion, we need to focus on consumers' preference to multiple items rather than to some specific item. To deal with this issue, we pioneer a Nash equilibrium based Item Group Recommendation approach (NIGR). Specifically, we evaluate each consumer's preference to an item group in two perspectives, interest part from the customer herself and social affection from her friends. Then, we model the recommending process as a game to achieve Nash equilibrium. Finally, we demonstrate the effectiveness of our approach with extensive experiments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1405–1411},
numpages = {7}
}

@inproceedings{10.1145/3041021.3051155,
author = {Avvenuti, Marco and Bellomo, Salvatore and Cresci, Stefano and La Polla, Mariantonietta Noemi and Tesconi, Maurizio},
title = {Hybrid Crowdsensing: A Novel Paradigm to Combine the Strengths of Opportunistic and Participatory Crowdsensing},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051155},
doi = {10.1145/3041021.3051155},
abstract = {Crowdsensing systems can be either participatory or opportunistic, depending on whether the user intentionally contributes data, or she simply acts as the bearer of a sensing device from which data is transparently collected. In this paper, we propose hybrid crowdsensing, a social media-based paradigm which aims at combining the strengths of both participatory and opportunistic crowdsensing. With hybrid crowdsensing, possibly relevant data is collected via an opportunistic approach. Then, users that spontaneously contributed are directly contacted and asked to provide additional information following a participatory approach. To demonstrate its feasibility and usefulness, we experimented the proposed paradigm for involving Twitter users in an emergency relief scenario. For each of the two real-world experiments we analyze the answer ratio to our questions, their time distribution, and responders' willingness to collaborate. Results support the adoption of hybrid crowdsensing, especially in those practical scenarios where users are emotionally involved.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1413–1421},
numpages = {9},
keywords = {collective intelligence, twitter, crowdsensing, online question answering},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051157,
author = {Wandabwa, Herman and Naeem, M. Asif and Mirza, Farhaan},
title = {Aspect of Blame in Tweets: A Deep Recurrent Neural Network Approach},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051157},
doi = {10.1145/3041021.3051157},
abstract = {Twitter as an information dissemination tool has proved to be instrumental in generating user curated content in short spans of time. Tweeting usually occurs when reacting to events, speeches, about a service or product. This in some cases comes with its fair share of blame on varied aspects in reference to say an event. Our work in progress details how we plan to collect the informal texts, clean them and extract features for blame detection. We are interested in augmenting Recurrent Neural Networks (RNN) with self-developed association rules in getting the most out of the data for training and evaluation. We aim to test the performance of our approach using human-induced terror-related tweets corpus. It is possible tailoring the model to fit natural disaster scenarios.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1423–1424},
numpages = {2},
keywords = {deep learning, aspect extraction, recurrent neural networks, nlp},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051158,
author = {Hu, Pengwei and Chan, Keith C.C. and He, Tiantian},
title = {Deep Graph Clustering in Social Network},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051158},
doi = {10.1145/3041021.3051158},
abstract = {In this paper, we present deep attributes residue graph algorithm (DARG), a novel model for learning deep representations of graph. The algorithm can discover clusters by taking into consideration node relevance. DARG does so by first learns attributes relevance and cluster deep representations of vertices appearing in a graph, unlike existing work, integrates content interactions of the nodes into the graph learning process. First, the relevance of contents between each node pair within the network is abstracted. Then we turn the problem of computing the first k eigenvectors in spectral clustering into a computing deep representations task. This model just need learns content information to represent vertices appearing in a graph and without the need for considering topological information. Such content information is much easier to obtain than topological links in the real world. We conduct an experiment on SNAP Facebook dataset, empirical results demonstrate that proposed approach significantly outperforms other state-of-the-art methods in such task.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1425–1426},
numpages = {2},
keywords = {community detection, attributes association, graph clustering},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252718,
author = {Simperl, Elena and Domingue, John and Gandon, Fabien and Ib\'{a}\~{n}ez, Luis-Daniel},
title = {Session Details: LD-DL'17: 1st Workshop on Linked Data and Distributed Ledgers},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {1st International Workshop on Linked Data and Distributed Ledgers (LD-DL) Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053899,
author = {Sporny, Manu},
title = {LD-DL'17 Workshop Keynote Talk By Many Sporny: Building Better Blockchains Via Linked Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053899},
doi = {10.1145/3041021.3053899},
abstract = {This presentation explores the current state of Blockchain research as it relates to Linked Data. The topics covered by the presentation include: 1) a basic definition of a blockchain, 2) an analysis of current blockchain capabilities, 3) compelling blockchain use cases where Linked Data would provide compelling benefits, 4) how Linked Data may be used to enhance blockchain capabilities, 5) a list of unresolved research and standardization needs as it relates to the expression of blockchains using Linked Data, and 6) possible venues where future work may be coordinated.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1429},
numpages = {1},
keywords = {digital signatures, domain modeling, blockchain, json-ld, semantics, graph normalization, http},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053895,
author = {Third, Allan and Domingue, John},
title = {Linked Data Indexing of Distributed Ledgers},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053895},
doi = {10.1145/3041021.3053895},
abstract = {Searching for information in distributed ledgers is currently not an easy task, as information relating to an entity may be scattered throughout the ledger with no index. As distributed ledger technologies become more established, they will increasingly be used to represent real world transactions involving many parties and the search requirements will grow. An index providing the ability to search using domain specific terms across multiple ledgers will greatly enhance to power, usability and scope of these systems.We have implemented a semantic index to the Ethereum blockchain platform, to expose distributed ledger data as Linked Data. As well as indexing block- and transaction-level data according to the BLONDiE ontology, we have mapped smart contracts to the Minimal Service Model ontology, to take the first steps towards connecting smart contracts with Semantic Web Services.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1431–1436},
numpages = {6},
keywords = {distributed ledgers, semantic indexing, blockchains, linked data},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053896,
author = {Lemieux, Victoria L. and Sporny, Manu},
title = {Preserving the Archival Bond in Distributed Ledgers: A Data Model and Syntax},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053896},
doi = {10.1145/3041021.3053896},
abstract = {Distributed cryptographic ledgers, such as the blockchain, are now being used in recordkeeping. However, they lack a key feature of more traditional recordkeeping systems needed to establish the authenticity of records and enable reliance on them for trustworthy recordkeeping. The missing feature is known in archival science as the archival bond -- the mutual relationship that exists among documents by virtue of the actions in which they participate. In this paper, we propose a novel data model and syntax using core web principles that can be used to address this shortcoming in distributed ledgers as recordkeeping systems.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1437–1443},
numpages = {7},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053897,
author = {Xu, Lei and Chen, Lin and Shah, Nolan and Gao, Zhimin and Lu, Yang and Shi, Weidong},
title = {DL-BAC: Distributed Ledger Based Access Control for Web Applications},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053897},
doi = {10.1145/3041021.3053897},
abstract = {Since Internet based applications have become the norm for most users, security has become a bigger concern than ever before, especially for applications like social networking and cloud based storage. Access control is one of the key techniques that can mitigate security concerns for web based applications. However, most existing access control mechanisms require a trusted party, which are vulnerable to many threats including malicious insiders and single point failure. In response to these challenges, we propose DL-BAC, a novel access control system based on the distributed ledger. DL-BAC robustly enforces access control policies without depending on a single trusted party. We also provide an extension of DL-BAC that is privacy respecting and evaluate the performance of DL-BAC to show its practicability.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1445–1450},
numpages = {6},
keywords = {distributed ledger, web application, security},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053898,
author = {Evans-Greenwood, Peter},
title = {Distributed Ledgers &amp; Linked Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053898},
doi = {10.1145/3041021.3053898},
abstract = {Distributed are increasing being thought of as a platform for decentralised applications -- DApps -- and the the focus for many is shifting from Bitcoin to Smart Contracts. It's thought that encoding contracts and putting them "on the blockchain" will result in a new generation of organisations that are leaner and more efficient than their forebears ("CApps"?"), disrupting these forebears in the process.However, the most interesting aspect of Bitcoin and blockchain is that it involved no new technology, no new math. Their emergence was due to changes in the environment: the price-performance and penetration of broadband networks reached a point that it was economically viable for a decentralised solution, such as Bitcoin to compete with traditional payment (international remittance) networks. This is combining with another trend -- the shift from monolithic firms to multi-sided markets such as AirBnb et al and the rise of "platform businesses" -- to enable a new class of solution to emerge. These new solutions enable firms to interact directly, without the need for a facilitator such as a market, exchange, or even a blockchain. In the past these facilitators were firms. More recently they have been "platform businesses". In the future they may not exist at all.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1451},
numpages = {1},
keywords = {distributed ai, distributed ledgers, blockchain, linked data},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252719,
author = {Ahlers, Dirk and Wilde, Erik},
title = {Session Details: LocWeb'17: 7th International Workshop on Location &amp; the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051697,
author = {Tomko, Martin},
title = {Understanding Indoor Behavior: Where, What, with Whom?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051697},
doi = {10.1145/3041021.3051697},
abstract = {Capturing and understanding users' context is key to the success of applications such as computational advertising and recommender systems. Currently, context is usually inferred from a user's interaction history with Web content. As an ever-increasing portion of Web interaction occurs in a mobile context, the physical and social environment in which the interaction occurs is a key factor of user context and holds additional signals of user intent. In this talk, I will discuss recent work on understanding user behavior based on recorded traces of the cyber, social and physical component of users interaction with the in indoor environment (i.e., shopping malls), based on an extensive dataset of Wi-Fi logs. We will draw lessons for the future of indoor recommender services and context-aware mobile applications.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1455–1456},
numpages = {2},
keywords = {information behaviour, movement, indoor behaviour, contextual services},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051698,
author = {Brambilla, Marco and Ceri, Stefano and Daniel, Florian and Donetti, Gianmarco},
title = {Spatial Analysis of Social Media Response to Live Events: The Case of the Milano Fashion Week},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051698},
doi = {10.1145/3041021.3051698},
abstract = {Social media response to catastrophic events, such as natural disasters or terrorist attacks, has received a lot of attention. However, social media are also extremely important in the context of planned events, such as fairs, exhibits, festivals, as they play an essential role in communicating them to fans, interest groups, and the general population. These kinds of events are geo-localized within a city or territory and are scheduled within a public calendar. We consider a specific scenario, the Milano Fashion Week (MFW), which is an important event in our city.We focus our attention on the coverage of social content in space, measuring the propagation of the event in the territory. We build different clusters of fashion brands, we characterize several features of propagation in space and we correlate them to the popularity of involved actors. We show that the clusters along space and popularity dimensions are loosely correlated, and that domain experts are typically able to understand and identify only popularity aspects, while they are completely unaware of spatial dynamics of social media response to the events.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1457–1462},
numpages = {6},
keywords = {social media analysis, live events},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051700,
author = {Smarzaro, Rodrigo and Lima, Tiago Fran\c{c}a de Melo and Davis, Clodoveu A.},
title = {Could Data from Location-Based Social Networks Be Used to Support Urban Planning?},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051700},
doi = {10.1145/3041021.3051700},
abstract = {A great quantity of information is required to support urban planning. Usually there are many (not integrated) data sources, originating from different government bodies, in distinct formats and variable properties (e.g. reliability, completeness). The effort to handle these data, integrate and analyze them is high, taking to much time for the information to be available to help decision making. We argue that data from location-based social networks (LBSN) could be used to provide useful information in reasonable time, despite several limitations they have. To asses this, as a case study, we used data from different LBSN to calculate the Local Availability Index (IOL) for a Brazilian city. This index is part of a methodology to estimate quality of urban life inside cities and is used to support urban planning. The results suggest that data from LBSN are useful and could be used to provide insights for local governments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1463–1468},
numpages = {6},
keywords = {lbsn, urban planning, urban informatics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051699,
author = {Vandewiele, Gilles and Colpaert, Pieter and Janssens, Olivier and Van Herwegen, Joachim and Verborgh, Ruben and Mannens, Erik and Ongenae, Femke and De Turck, Filip},
title = {Predicting Train Occupancies Based on Query Logs and External Data Sources},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051699},
doi = {10.1145/3041021.3051699},
abstract = {On dense railway networks "such as in Belgium" train travelers are frequently confronted with overly occupied trains, especially during peak hours. Crowdedness on trains leads to a deterioration in the quality of service and has a negative impact on the well-being of the passenger. In order to stimulate travelers to consider less crowded trains, the iRail project wants to show an occupancy indicator in their route planning applications by the means of predictive modeling. As there is no official occupancy data available, training data is obtained by crowd-sourcing using the iRail web app and the mobile Railer application for iPhone. Users can indicate their departure &amp; arrival station, at what time they took a train and classify the occupancy of that train into the classes: low, medium or high. While preliminary results on a limited dataset conclude that the models do not yet perform sufficiently well, we are convinced that with further research and a larger amount of data, our predictive model will be able to achieve higher predictive performances. All datasets used in the current research are, for that purpose, made publicly available under an open license on the iRail website and in the form of a Kaggle competition. Moreover, an infrastructure is set up that automatically processes new logs submitted by users in order for our model to continuously learn. Occupancy predictions for future trains are made available through an api.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1469–1474},
numpages = {6},
keywords = {linked data, predictive modeling, public transport},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252720,
author = {Atzmueller, Martin and Berkovsky, Shlomo and Chin, Alvin and Li, Jianxin and Trattner, Christoph},
title = {Session Details: MSM'17: 8th International Workshop on Modeling Social Media},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {MSM'17 Workshop Chairs' Welcome Message},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053901,
author = {Jia, Adele Lu and Shen, Siqi and Chen, Shengling and Li, Dongsheng and Iosup, Alexandru},
title = {An Analysis on a YouTube-like UGC Site with Enhanced Social Features},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053901},
doi = {10.1145/3041021.3053901},
abstract = {YouTube-like User Generated Content (UGC) sites are nowadays entertaining over a billion people. Resource provision is essential for these giant UGC sites as they allow users to request videos from a potentially unlimited selection in an asynchronous fashion. Still, the UGC sites are seeking to create new viewing patterns and social interactions that would engage and attract more users and complicate the already rigorous resource provision problem. In this paper, we seek to combine these two tasks by leveraging social features to provide the reference for resource provision.To this end, we conduct an extensive measurement and analysis of BiliBili, a YouTube-like UGC site with enhanced social features including user following, chat replay, and virtual money donation. Based on datasets that capture the complete view of BiliBili---containing over 2 million videos and over 28 million users---we characterize its video repository and user activities, we demonstrate the positive reinforcement between on-line social behavior and upload behavior, we propose graph models that reveal user relationships and high-level social structures, and we successfully apply our findings to build machine-learnt classifiers to identify videos that will need priority in resource provision.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1477–1483},
numpages = {7},
keywords = {social features, graph model, prediction, user generated content sites},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053904,
author = {Kurka, David Burth and Godoy, Alan and Von Zuben, Fernando J.},
title = {Using Retweet Information as a Feature to Classify Messages Contents},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053904},
doi = {10.1145/3041021.3053904},
abstract = {We investigate the use of machine learning algorithms to classify content published in Online Social Networks using as input solely user interaction data, instead of the actual message content. During a period of six months, we monitored and gathered data from users interacting with news messages on Twitter, creating thousands of information diffusion processes. The data set presented regular patterns on how messages were spread over the network by users, depending on its content, so we could build classifiers to predict the topic of a message using as input only information of how it was diffused. Thus, we demonstrate the explanatory power of user behavior data on identifying content present in Social Networks, proposing techniques for topic classification that can be used to assist traditional content identification strategies (such as natural language or image processing) in challenging contexts, or be applied in scenarios with limited information access.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1485–1491},
numpages = {7},
keywords = {network feature extraction, twitter, topic classification, online social networks},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053903,
author = {Mathews, Peter and Mitchell, Lewis and Nguyen, Giang and Bean, Nigel},
title = {The Nature and Origin of Heavy Tails in Retweet Activity},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053903},
doi = {10.1145/3041021.3053903},
abstract = {Modern social media platforms facilitate the rapid spread of information online. Modelling phenomena such as social contagion and information diffusion are contingent upon a detailed understanding of the information-sharing processes. In Twitter, an important aspect of this occurs with retweets, where users rebroadcast the tweets of other users. To improve our understanding of how these distributions arise, we analyse the distribution of retweet times. We show that a power law with exponential cutoff provides a better fit than the power laws previously suggested. We explain this fit through the burstiness of human behaviour and the priorities individuals place on different tasks.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1493–1498},
numpages = {6},
keywords = {power law, twitter, retweet, power law with exponential cutoff},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053905,
author = {Sakamoto, Shohei and Eguchi, Koji},
title = {Particle Filter Inference Based on Activities for Overlapping Community Models},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053905},
doi = {10.1145/3041021.3053905},
abstract = {Various kinds of data such as social media can be represented as a network or graph. Latent variable models using Bayesian statistical inference are powerful tools to represent such networks. One such latent variable network model is a Mixed Membership Stochastic Blockmodel (MMSB), which can discover overlapping communities in a network and has high predictive power. Previous inference methods estimate the latent variables and unknown parameters of the MMSB on the basis of the whole observed network. Therefore, dynamic changes in network structure over time are hard to track. Thus, we present a particle filter based on node activities with various term lengths for online sequential estimation of the MMSB. For instance, in an e-mail communication network, each particle only considers e-mail accounts that sent or received a message within a specific term length, where the length may be different from those of other particles. We show through experiments that our proposed methods achieve both high prediction performance and computational efficiency.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1499–1504},
numpages = {6},
keywords = {latent variable models, sequential inference, particle filter, network analysis},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053906,
author = {Taxidou, Io and Fischer, Peter M.},
title = {Structural Aspects of User Roles in Information Cascades},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053906},
doi = {10.1145/3041021.3053906},
abstract = {Social media plays an important role for the exchange and dissemination of information among its users. In turn, online users shape social media by their interactions, status and online behaviour in general. These aspects differ massively from user to user, which has an impact on the outcome of information diffusion. Users on social media have been categorised to user roles according to their online behaviour. While there has been a lot of research on user roles and information diffusion in isolation, their combination has not been researched much. In this paper, we study their correlation in particular whether particular user roles occur in specific structural positions in information cascades. By testing several hypotheses we could confirm that there is indeed a correlation of these two aspects. However, some user roles demonstrate diverse behaviour with regard to their activity patterns and need further investigation.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1505–1509},
numpages = {5},
keywords = {structural positions, information diffusion, information cascades, user roles},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252721,
author = {De Francisci Morales, Gianmarco and Aiello, Luca Maria and Papadopoulos, Symeon and Kwak, Haewoon},
title = {Session Details: SNOW'17: 4th Workshop on Social News on the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054760,
author = {Gomez-Rodriguez, Manuel},
title = {Distilling Information Reliability and Source Trustworthiness from Digital Traces},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054760},
doi = {10.1145/3041021.3054760},
abstract = {Online knowledge repositories typically rely on their users or dedicated editors to evaluate the reliability of their content. These evaluations can be viewed as noisy measurements of both information reliability and information source trustworthiness. Can we leverage these noisy evaluations, often biased, to distill a robust, unbiased and interpretable measure of both notions?In this talk, I will first argue that the temporal traces left by these noisy evaluations give cues on the reliability of the information and the trustworthiness of the sources. Then, I will introduce a temporal point process modeling framework that links these temporal traces to robust, unbiased and interpretable notions of information reliability and source trustworthiness. Finally, I will elaborate on large-scale experiments on real-world data gathered from Wikipedia and Stack Overflow and show that our modeling framework accurately predicts evaluation events, provides an interpretable measure of information reliability and source trustworthiness, and yields interesting insights about real-world events.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1513},
numpages = {1},
keywords = {data-driven models, information reliability, temporal point processes},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054763,
author = {Chen, Fuxiang and Lim, Ee-Peng},
title = {Now You See It, Now You Don't! A Study of Content Modification Behavior in Facebook},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054763},
doi = {10.1145/3041021.3054763},
abstract = {Social media, as a major platform to disseminate information, has changed the way users and communities contribute content. In this paper, we aim to study content modifications on public Facebook pages operated by news media, community groups, and bloggers. We also study the possible reasons behind them, and their effects on user interaction. We conducted a detailed study of Content Censorship (CC) and Content Edit (CE) in Facebook using a detailed longitudinal dataset consisting of 57 public Facebook pages over 3 weeks covering 145,955 posts and 9,379,200 comments. We detected many CC and CE activities between 28% and 56% of these pages (in both Facebook Posts and Comments). Manual judgements on these post/comment removals and edits show that majority of the content censorship is related to negative reports on events and personal grouses, and content edit is mainly performed to improve content quality and correctness. Furthermore, recency effect is also observed as part of Facebook content modification behavior.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1515–1520},
numpages = {6},
keywords = {content censorship, facebook, user interaction, content edit, content modification},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054762,
author = {Lim, Hongjun and Chung, Choongho and Kim, Jihee and Kim, Juho and Moon, Sue and Cha, Meeyoung},
title = {Changing News Media Landscape in South Korea},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054762},
doi = {10.1145/3041021.3054762},
abstract = {A recent disclosure of a presidential scandal and the following development of subsequent events have been a major news topic in South Korea. We conducted a data-driven study to examine public reactions to the scandal and their effect on the Korean media landscape. Our analysis is based on 59,224 news articles published by five popular newsrooms that received a total of 47,906,770 Likes on Facebook. The data reveal notable changes in media ranks throughout the scandal, where a relatively young TV news network outgrew its audience over other half-a-century old established newspapers in less than a month. Topical similarity of news headlines also remained high over an extended period of time, despite the varying political stance of each newsroom. The topical similarity further shows a gradual divergence, indicating re-positioning of media stance takes place over time. Implications of these findings and suggestions for future directions are discussed based on data analysis of this extraordinary event.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1521–1526},
numpages = {6},
keywords = {media bias, social media, data-driven journalism},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252722,
author = {Issa, Tomayess and Nau, S. Zaung and Chanchaichuijt, Janya and Issa, Theodora},
title = {Session Details: SST'17: Sustainability and Smart Technology Workshop 2017},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {SST 2017 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252723,
author = {Zaung, Nau},
title = {Session Details: SST'17 Keynote Talk},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054767,
author = {Marinova, Dora},
title = {Sustainability and Smart Technology},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054767},
doi = {10.1145/3041021.3054767},
abstract = {Today's cities have attracted the largest share of the global human population and have become symbols of advancements in knowledge and technology. They have however also begun to represent a lifestyle detached from nature and geared towards a high level of consumption. To make cities sustainable, they need to provide better living conditions for everybody, access to resource availability and security -- water, energy, food, better opportunities and respond to climate change. Smart technologies can be a tool assisting in achieving sustainability in the city. In line with the UN Sustainable Development Goals, the presentation defines the link between sustainability and smart technologies by putting community livability at its centre. The concepts of (1) community self-governance and self-organisation; and (2) ethical economics and sustainometrics are developed as the principles which can underpin success in improving the livability of urban environments for its current and future inhabitants. The example of working with the community in Geraldton, Western Australia is used to showcase the application of smart technologies for improving the livability of the city.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1529},
numpages = {1},
keywords = {smart technology, sustainability, sustainable development goals, livability, participatory governance, cities},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252724,
author = {Issa, Theodora},
title = {Session Details: SST'17 Session 1: Sustainable Strategy},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054768,
author = {Gong, Xiaoxue and Guo, Lei and Ning, Zhaolong},
title = {Green Virtual Network Embedding for Collaborative Edge Computing in Environment-Friendly Optical-Wireless Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054768},
doi = {10.1145/3041021.3054768},
abstract = {To reduce the cost and delay caused by transferring data to the remote cloud, the trend is to design an intelligent Edge Device (ED) for preliminary data processing, i.e., edge computing. Some EDs usually form a group where they wirelessly communicate with each other. Different ED groups are interconnected by optical fiber cables. Through coordinating the use of ED groups, we can perform a collaborative edge computing in a hybrid network where a cost-efficient optical-wireless convergence is achieved by virtualization. In this paper, we use the virtual network to describe one computing-application's requirement for the substrate resource, and we investigate how embed multiple virtual networks onto the common network infrastructure. In our approach, a graph-cutting algorithm is firstly utilized to embed as many virtual networks as possible onto the specified EDs within the same group. However, a single ED group cannot handle all computing applications competing for limited wireless and computing resources. To solve this challenging problem, we transform the virtual networks-impossibly embedded onto the same ED group into new ones processed by ED groups. Simulations results demonstrate the green feature of our solution: 1) the total transmitting power assigned for EDs is effectively reduced using the graph cutting algorithm provided that all of computing applications can be solved by a single ED group; 2) our method accepts more virtual networks with the improvement ratio of 77%, through the coordination of ED groups. In addition, there is a good match between the algorithm result and the optimal number of consumed wavelengths per optical fiber cable.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1531–1536},
numpages = {6},
keywords = {green virtual network embedding, collaborative edge computing, environment-friendly opticalwireless network},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054769,
author = {Nimmagadda, Shastri L. and Zhu, Dengya and Rudra, Amit},
title = {Knowledge Base Smarter Articulations for the Open Directory Project in a Sustainable Digital Ecosystem},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054769},
doi = {10.1145/3041021.3054769},
abstract = {We examine the volumes and varieties of data sources of the Open Directory Project (ODP), which can endure, regenerate and flourish with new knowledge. The ODP motivates us in building a knowledge base smarter multidimensional data constructs and models. We articulate the models with new artefacts, addressing the heterogeneity and multidimensionality of the data. The conceptualization and contextualization of various entities and dimensions have emerged with innovation that led us to develop a digital ecosystem-based inventory. The ODP based domain ontologies support the warehouse repository, which accommodates multidimensional data relationships. The concept of a digital ecosystem in the ODP context is to bring the dimensions together and unite with multidimensional schemas. We explore the Big Data, incorporating their characteristics in the ODP constructs and models. The volumes and varieties of the ODP data are logically organized and integrated in the warehouse repositories. The multidimensional data modelling makes the ODP more smart and flexible in an environment, where varieties of business rules and constraints change rapidly. The visualization and interpretation are the other artefacts of the Big Data facilitating us use, reuse, test the interoperability and effectiveness of the data models for sustainable ODP digital ecosystem. We compute the polynomial regressions, based on the data fluctuations of the ODP as observed in the scatter plots, providing new data mining models for knowledge interpretation.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1537–1545},
numpages = {9},
keywords = {multidimensional data modelling, digital ecosystem, domain ontologies, the open directory project (odp)},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252725,
author = {Issa, Tomayess},
title = {Session Details: SST'17 Session 2: Sustainble Design},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054770,
author = {Hou, Weigang and Ning, Zhaolong and Guo, Lei},
title = {Sustainable Strategy for Recycling Edge Devices in Internet of Everything Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054770},
doi = {10.1145/3041021.3054770},
abstract = {Internet of Everything (IoE) devices have different operation principles, which weakens the network scalability and data interoperability. Virtualization is an economic way of solving this problem. The data-collected by different vendors' sensors-can share the same computing program encapsulated by the Virtual Machine (VM), thus neglecting the physical-layer difference. To eliminate the extreme cost and long delay of transferring VMs to the remote cloud, the Edge Device (ED) preliminary processes its running VMs. Currently, the recycling of IoE devices become a major dilemma for individuals, since it is not simply a matter of concern for environmental damage or a solution to an environmental problem. Therefore, the sustainable strategy for recycling EDs is an important way to safeguard the network sustainability. To improve the recycling efficiency, most of the EDs should be upgraded simultaneously during one batch by migrating their running VMs to others for the service continuity. We investigate the least upgrade batch for recycling EDs in IoE networks. A two-step algorithm called MSBP (Minimized upgrade batch VM Scheduling and Bandwidth Planning) is designed to minimize the number of upgrade batches. Because migrating VM brings the bandwidth consumption along trajectories, MSBP has two strategies-Shortest Trajectory First (STF) and Least Bandwidth Utilization First (LBUF)-of allocating bandwidth and trajectories. The simulation results show that: 1) MSBP has the optimal recycling efficiency (least number of upgrade batches) for EDs; 2) LBUF more effectively mitigates the phenomenon where VM migration trajectories compete for the common link bandwidth, thus achieving a lower negative impact of path contention level on the recycling efficiency; 3) the battery power is not exhausted for the ED functioned as the sensor head of data transferring, thus prolonging the network lifetime. In summary, our solution well improves the network, social, economic and ecological sustainability.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1547–1552},
numpages = {6},
keywords = {ioe network sustainability, edge devices recycling},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3054771,
author = {De Los Rios Perez, Claudia and McMeekin, David A. and Falkmer, Marita and Tan, Tele},
title = {Holistic Approach for Sustainable Adaptable User Interfaces for People with Autism Spectrum Disorder},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054771},
doi = {10.1145/3041021.3054771},
abstract = {Understanding the needs of individuals with Autism Spectrum Disorder (ASD) enables the design of adaptable user interfaces addressing multiple sources of heterogeneity such as personal skills, work environments and context of use given their interaction with system and technology. Applying the human-centered design approach places the needs and limitations at a higher priority, creating a multi-disciplinary analysis to build sustainable adaptable technology solutions, contributing towards a viable world using fewer materials and energy consumption.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1553–1556},
numpages = {4},
keywords = {asd, user interfaces, web accessibility initiative, sustainable design, ui., wai, autism spectrum disorder},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252726,
author = {Spaniol, Marc and Baeza-Yates, Ricardo and Masan\`{e}s, Julien},
title = {Session Details: TempWeb'17: The 7th Temporal Web Analytics Workshop},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {TempWeb 2017 Chairs' Welcome Message},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252727,
author = {Spaniol, Marc},
title = {Session Details: TempWeb'17 Session 1: (Alternative) Facts},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051120,
author = {Weikum, Gerhard},
title = {What Computers Should Know, Shouldn't Know, and Shouldn't Believe},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051120},
doi = {10.1145/3041021.3051120},
abstract = {Automatically constructed knowledge bases (KB's) are a powerful asset for search, analytics, recommendations and data integration, with intensive use at big industrial stake-holders. Examples are the knowledge graphs for search engines (e.g., Google, Bing, Baidu) and social networks (e.g., Facebook), as well as domain-specific KB's (e.g., Bloomberg, Walmart). These achievements are rooted in academic research and community projects. The largest general-purpose KB's with publicly accessible contents are BabelNet, DBpedia, Wikidata, and Yago. They contain millions of entities, organized in hundreds to hundred thousands of semantic classes, and billions of relational facts on entities. These and other knowledge and data resources are interlinked at the entity level, forming the Web of Linked Open Data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1559–1560},
numpages = {2},
keywords = {digital knowledge, user privacy, information trust},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051118,
author = {Yom-Tov, Elad and Fischer, Shira H.},
title = {The Werther Effect Revisited: Measuring the Effect of News Items on User Behavior},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051118},
doi = {10.1145/3041021.3051118},
abstract = {People are moved to act following exposure to media coverage of specific events. For example, the ``Werther Effect" is the popular term for the observed increase in suicides following media coverage of suicides. Here we develop a fine-grained method for assessing the effect of news stories on the intentions of internet users. Our method assesses the likelihood that a person was exposed to a given news story via the temporal and spatial distances between the location of the person and the location of the news story and/or the website where it was published. This analysis of likelihoods allows us to estimate the contribution of a particular news story to a person's intent, as manifested in specific, intent-driven, search engine queries.Data were gathered over a ten-month period and cover both the search engine queries of a large population and the news stories to which this population was exposed. We estimated the contribution of news stories to negative effects (i.e. media coverage of suicides and their effect on queries indicating suicidal intention), and positive effects (e.g. media coverage of disease prompting queries into disease screening). We demonstrate that the contribution of news stories can be assessed at the level of individual users, and we analyzed titles and phrases therein for their effect. Finally, we propose a predictive model to be utilized by media outlets to predict the likely effect of specific stories prior to their publication.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1561–1566},
numpages = {6},
keywords = {news, query intent, temporal correlates},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252728,
author = {Str\"{o}tgen, Jannik},
title = {Session Details: TempWeb'17 Session 2: Dynamics},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051117,
author = {Santos, Tiago and Walk, Simon and Helic, Denis},
title = {Nonlinear Characterization of Activity Dynamics in Online Collaboration Websites},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051117},
doi = {10.1145/3041021.3051117},
abstract = {Modeling activity in online collaboration websites, such as StackExchange Question and Answering portals, is becoming increasingly important, as the success of these websites critically depends on the content contributed by its users. In this paper, we represent user activity as time series and perform an initial analysis of these time series to obtain a better understanding of the underlying mechanisms that govern their creation. In particular, we are interested in identifying latent nonlinear behavior in online user activity as opposed to a simpler linear operating mode. To that end, we apply a set of statistical tests for nonlinearity as a means to characterize activity time series derived from $16$ different online collaboration websites. We validate our approach by comparing activity forecast performance from linear and nonlinear models, and study the underlying dynamical systems we derive with nonlinear time series analysis. Our results show that nonlinear characterizations of activity time series help to (i) improve our understanding of activity dynamics in online collaboration websites, and (ii) increase the accuracy of forecasting experiments.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1567–1572},
numpages = {6},
keywords = {nonlinear time series analysis, q&amp;a online communities},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051116,
author = {Koncar, Philipp and Walk, Simon and Helic, Denis and Strohmaier, Markus},
title = {Exploring the Impact of Trolls on Activity Dynamics in Real-World Collaboration Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051116},
doi = {10.1145/3041021.3051116},
abstract = {When new users join social networking websites, they often form collaboration ties with existing users, which in turn may result in some level of activity on the site. However, for various reasons, new users often fail to create such ties and their contributions to the system's overall activity remain insignificant. For example, on Question and Answering portals, such as the StackExchange network, users collaborate to find the best answers for a given set of questions. However, the intentions of new users are highly diverse. While the contributions of most users positively impact the evolution of a community, other participants might just try to steer discussions off-topic or purposely generate discord. To better understand such malicious behavior, it is important to model and quantify the impact of such users on the overall activity in collaboration networks. In this paper we simulate and investigate the influence of trolls---users who intentionally contribute detrimental content---on the total activity of several different StackExchange instances, Semantic MediaWikis and Subreddits. The contributions of this paper are three-fold. First, we simulate activity dynamics in the context of trolls in online collaboration networks. Second, we analyze and quantify the impact of trolls on the levels of activity in these networks. Third, we discuss our results and put them into a real-world context.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1573–1578},
numpages = {6},
keywords = {activity dynamics, dynamical systems, collaboration networks},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051113,
author = {Van Canneyt, Steven and Bron, Marc and Haines, Andy and Lalmas, Mounia},
title = {Describing Patterns and Disruptions in Large Scale Mobile App Usage Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051113},
doi = {10.1145/3041021.3051113},
abstract = {The advertising industry is seeking to use the unique data provided by the increasing usage of mobile devices and mobile applications (apps) to improve targeting and the experience with apps. As a consequence, understanding user behaviours with apps has gained increased interests from both academia and industry. In this paper we study user app engagement patterns and disruptions of those patterns in a data set unique in its scale and coverage of user activity. First, we provide a detailed account of temporal user activity patterns with apps and compare these to previous studies on app usage behavior. Then, in the second part, and the main contribution of this work, we take advantage of the scale and coverage of our sample and show how app usage behavior is disrupted through major political, social, and sports events.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1579–1584},
numpages = {6},
keywords = {app usage, disruption of patterns, user behavior},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252729,
author = {Walk, Simon},
title = {Session Details: TempWeb'17 Session 3: Temporality &amp; Intelligence},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {1},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051115,
author = {Jeong, Jiwan and Moon, Sue},
title = {Interval Signature: Persistence and Distinctiveness of Inter-Event Time Distributions in Online Human Behavior},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051115},
doi = {10.1145/3041021.3051115},
abstract = {Interval patterns, or inter-event time distributions that occur in human activity, have long been an interest of many researchers studying human dynamics. While previous studies have mostly focused on characterizing the aggregated inter-arrival patterns or finding universal patterns across all individuals, we focus on the diversity among the patterns of different individuals; the goal of this paper is to understand how persistent an individual's interval pattern is and how distinctive it is from those of the others. We use Wikipedia, me2DAY, Twitter, and Enron email data to study the interval patterns of online human behavior. Our analysis reveals that individuals have robust and unique interval signatures. The interval pattern of a user tends to persist over years, even after coming back from a long hiatus of inactivity, despite considerable change in circadian rhythms. Furthermore, the interval patterns of individuals are highly distinct from that of others. We put our new findings in practical use of identifying users.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1585–1593},
numpages = {9},
keywords = {interval signature, human behavior, personal characteristic, inter-event time, behavioral signature},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051112,
author = {Agarwal, Prabal and Str\"{o}tgen, Jannik},
title = {Tiwiki: Searching Wikipedia with Temporal Constraints},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051112},
doi = {10.1145/3041021.3051112},
abstract = {Temporal information retrieval received a lot of attention during the last years and it is, in the meantime, widely accepted in the IR community that temporal information needs are important to tackle. A particular type of temporal queries are those with explicit temporal constraints, which make almost 15% of today's Web search queries. Although several approaches to allow textual search combined with temporal constraints regarding the content of the documents have been suggested, there are no publicly available search engines allowing for a time-centric search experience.In this paper, we suggest TIWIKI, a time-aware search engine for Wikipedia. Relying on steadily updated Wikipedia dumps annotated with temporal expressions, queries with textual and temporal components can be formulated and are served by ranking the search results based on aggregated values of temporal and textual relevance. As the search results directly link to the original Wikipedia pages, the Tiwiki search engine can be considered as slightly delayed, yet timely access to Wikipedia.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1595–1600},
numpages = {6},
keywords = {wikipedia, tiwiki, temporal information retrieval},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051114,
author = {Chavoshi, Nikan and Hamooni, Hossein and Mueen, Abdullah},
title = {Temporal Patterns in Bot Activities},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051114},
doi = {10.1145/3041021.3051114},
abstract = {Correlated or synchronized bots commonly exist in social media sites such as Twitter. Bots work towards gaining human followers, participating in campaigns, and engaging in unethical activities such as spamming and false click generation. In this paper, we perform temporal pattern mining on bot activities in Twitter. We discover motifs (repeating behavior), discords (anomalous behavior), joins, bursts and dynamic clusters in activities of Twitter bots, and explain the significance of these temporal patterns in gaining competitive advantage over humans. Our analysis identifies a small set of indicators that separates bots from humans with high precision.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1601–1606},
numpages = {6},
keywords = {bot, time series mining, pattern mining, social media},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252730,
author = {West, Robert and Zia, Leila and Taraborelli, Dario and Leskovec, Jure},
title = {Session Details: Wiki Workshop @ WWW 2017},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {Wiki Workshop 2017 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053362,
author = {Arnold, Thomas and Daxenberger, Johannes and Gurevych, Iryna and Weihe, Karsten},
title = {Is Interaction More Important than Individual Performance? A Study of Motifs in Wikia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053362},
doi = {10.1145/3041021.3053362},
abstract = {Recent research has discovered the importance of informal roles in peer online collaboration. These roles reflect prototypical activity patterns of contributors such as different editing activities in writing communities. While previous work has analyzed the dynamics of contributors within single communities, so far, the relationship between individuals' roles and interaction among contributors remains unclear. This is a severe drawback given that collaboration is one of the driving forces in online communities. In this study, we use a network-based approach to combine information about individuals' roles and their interaction over time. We measure the impact of recurring subgraphs in co-author networks, so called motifs, on the overall quality of the resulting collaborative product. Doing so allows us to measure the effect of collaboration over mere isolated contributions by individuals. Our findings indicate that indeed there are consistent positive implications of certain patterns that cannot be detected when looking at contributions in isolation, e.g. we found shared positive effects of contributors that specialize on content quality over of quantity. The empirical results presented in this work are based on a study of several online writing communities, namely wikis from Wikia and Wikipedia.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1609–1617},
numpages = {9},
keywords = {online collaboration, motifs, online communities, co-author networks, wikia, informal roles},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053364,
author = {Harder, Reed H. and Velasco, Alfredo and Evans, Michael and An, Chuankai and Rockmore, Daniel},
title = {Wikipedia Verification Check: A Chrome Browser Extension},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053364},
doi = {10.1145/3041021.3053364},
abstract = {In this paper we present Version 1.0 of an implementation of a Wiki reference parser with a light-weight plugin in the form of a Google Chrome Extension with Javascript. The output of the parser is a "verification score" for any Wikipedia page, constructed from a combination of scores derived from reference accessibility and quality. The extension presented herein works from a pre-stored database of DOI and reference checks. Future versions working in real-time are also discussed. This work suggests generalizations to real-time verification checkers for arbitrary webpages and possibly even a real-time fact-checker for news platforms.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1619–1625},
numpages = {7},
keywords = {references, wikipedia, sources, verifiability, measurement},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053363,
author = {Dahm, Erik and Schubotz, Moritz and Meuschke, Norman and Gipp, Bela},
title = {A Vision for Performing Social and Economic Data Analysis Using Wikipedia's Edit History},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053363},
doi = {10.1145/3041021.3053363},
abstract = {In this vision paper, we suggest combining two lines of research to study the collective behavior of Wikipedia contributors. The first line of research analyzes Wikipedia's edit history to quantify the quality of individual contributions and the resulting reputation of the contributor. The second line of research surveys Wikipedia contributors to gain insights, e.g., on their personal and professional background, socioeconomic status, or motives to contribute toWikipedia. While both lines of research are valuable on their own, we argue that the combination of both approaches could yield insights that exceed the sum of the individual parts. Linking survey data to contributor reputation and content-based quality metrics could provide a large-scale, public domain data set to perform user modeling, i.e. deducing interest profiles of user groups. User profiles can, among other applications, help to improve recommender systems. The resulting dataset can also enable a better understanding and improved prediction of high quality Wikipedia content and successfulWikipedia contributors. Furthermore, the dataset can enable novel research approaches to investigate team composition and collective behavior as well as help to identify domain experts and young talents. We report on the status of implementing our large-scale, content-based analysis of the Wikipedia edit history using the big data processing framework Apache Flink. Additionally, we describe our plans to conduct a survey among Wikipedia contributors to enhance the content-based quality metrics.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1627–1634},
numpages = {8},
keywords = {social and economic data analysis, data science, open data, user model, wikipedia, economics},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053365,
author = {Pantaleo, Ester and Anelli, Vito Walter and Di Noia, Tommaso and S\'{e}rasset, Gilles},
title = {Etytree: A Graphical and Interactive Etymology Dictionary Based on Wiktionary},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053365},
doi = {10.1145/3041021.3053365},
abstract = {We present etytree (from etymology + family tree): a new on-line multilingual tool to extract and visualize etymological relationships between words from the English Wiktionary. A first version of etytree is available at http://tools.wmflabs.org/etytree/.With etytree users can search a word and interactively explore etymologically related words (ancestors, descendants, cognates) in many languages using a graphical interface. The data is synchronised with the English Wiktionary dump at every new release, and can be queried via SPARQL from a Virtuoso endpoint.Etytree is the first graphical etymology dictionary, which could be used to search specific etymological definitions as well as to discover new relations among words. Moreover, it can be effectively adopted by Wiktionary editors to identify inconsistencies or missing information in the data. Etytree is a valuable tool for all those users interested in specific etymological definitions as well as for discovering new relations among words. Moreover, it can be effectively adopted by Wiktionary editors to identify inconsistencies or missing information in the data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1635–1640},
numpages = {6},
keywords = {etymology, wiktionary, natural language processing, d3.js},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053361,
author = {Pochampally, Yashaswi and Karlapalem, Kamalakar},
title = {Notability Determination for Wikipedia},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053361},
doi = {10.1145/3041021.3053361},
abstract = {Being the ever-growing online encyclopedia, Wikipedia requires a keen investigation about which articles are to be included for it to maintain its indispensability. To prevent unnecessary articles from being included, official guidelines of Wikipedia demand these named entities to meet "notability" standards for their article inclusion. In this paper, we evaluate named entities for their notability by using reliability and entity salience features. Evaluations of our system provide evidence for the viability of our solution as an alternative to the manual decisions made by the reviewers for inclusion of an article using the notability rules.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1641–1646},
numpages = {6},
keywords = {wikipedia, entity salience, reliability, notability},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053366,
author = {Sarabadani, Amir and Halfaker, Aaron and Taraborelli, Dario},
title = {Building Automated Vandalism Detection Tools for Wikidata},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053366},
doi = {10.1145/3041021.3053366},
abstract = {Wikidata, like Wikipedia, is a knowledge base that anyone can edit. This open collaboration model is powerful in that it reduces barriers to participation and allows a large number of people to contribute. However, it exposes the knowledge base to the risk of vandalism and low-quality contributions. In this work, we build on past work detecting vandalism in Wikipedia to detect vandalism in Wikidata. This work is novel in that identifying damaging changes in a structured knowledge-base requires substantially different feature engineering work than in a text-based wiki like Wikipedia. We also discuss the utility of these classifiers for reducing the overall workload of vandalism patrollers in Wikidata. We describe a machine classification strategy that is able to catch 89% of vandalism while reducing patrollers' workload by 98%, by drawing lightly from contextual features of an edit and heavily from the characteristics of the user making the edit.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1647–1654},
numpages = {8},
keywords = {vandalism, quality control, wikidata, knowledge bases},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3053367,
author = {Spasojevic, Nemanja and Bhargava, Preeti and Hu, Guoning},
title = {DAWT: Densely Annotated Wikipedia Texts Across Multiple Languages},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3053367},
doi = {10.1145/3041021.3053367},
abstract = {In this work, we open up the DAWT dataset - Densely Annotated Wikipedia Texts across multiple languages. The annotations include labeled text mentions mapping to entities (represented by their Freebase machine ids) as well as the type of the entity. The data set contains total of 13.6M articles, 5.0B tokens, 13.8M mention entity co-occurrences. DAWT contains 4.8 times more anchor text to entity links than originally present in the Wikipedia markup. Moreover, it spans several languages including English, Spanish, Italian, German, French and Arabic. We also present the methodology used to generate the dataset which enriches Wikipedia markup in order to increase number of links. In addition to the main dataset, we open up several derived datasets including mention entity co-occurrence counts and entity embeddings, as well as mappings between Freebase ids and Wikidata item ids. We also discuss two applications of these datasets and hope that opening them up would prove useful for the Natural Language Processing and Information Retrieval communities, as well as facilitate multi-lingual research.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1655–1662},
numpages = {8},
keywords = {freebase, freebase annotations, named entity recognition, wiki, wikification, wikipedia, entity disambiguation, wikipedia annotations, entity linking},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/3041021.3252731,
author = {De Roure, David and Sandhu, Ravi},
title = {Session Details: WOW'17: Web Observatory Workshop 2017},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
abstract = {WOW 2017 Chairs' Welcome},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
numpages = {2},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051691,
author = {Price, Simon and Hall, Wendy and Earl, Graeme and Tiropanis, Thanassis and Tinati, Ramine and Wang, Xin and Gandolfi, Eleonora and Gatewood, Jane and Boateng, Richard and Denemark, David and Groflin, Alexander and Loader, Brian and Schmidt, Maxine and Billings, Marilyn and Spanakis, Gerasimos and Suleman, Hussein and Tsoi, Kelvin and Wessels, Bridgette and Xu, Jie and Birkin, Mark},
title = {Worldwide Universities Network (WUN) Web Observatory: Applying Lessons from the Web to Transform the Research Data Ecosystem},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051691},
doi = {10.1145/3041021.3051691},
abstract = {The ongoing growth in research data publication supports global intra-disciplinary and inter-disciplinary research collaboration but the current generation of archive-centric research data repositories do not address some of the key practical obstacles to research data sharing and re-use, specifically: discovering relevant data on a global scale is time-consuming; sharing `live' and streaming data is non-trivial; managing secure access to sensitive data is overly complicated; and, researchers are not guaranteed attribution for re-use of their own research data. These issues are keenly felt in an international network like the Worldwide Universities Network (WUN) as it seeks to address major global challenges. In this paper we outline the WUN Web Observatory project's plan to overcome these obstacles and, given that these obstacles are not unique to WUN, we also propose an ambitious, longer-term route to their solution at Web-scale by applying lessons from the Web itself.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1665–1667},
numpages = {3},
keywords = {social machines, research data management, data science},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051693,
author = {Tinati, Ramine and Madaan, Aastha and Hall, Wendy},
title = {The Role of Crowdsourcing in the Emerging Internet-Of-Things},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051693},
doi = {10.1145/3041021.3051693},
abstract = {In this position paper we wish to propose and discuss several open research questions associated with the IoT. In particular, we wish to consider how crowdsourcing can be used as a scalable, reliable, and sustainable approach to support various computationally difficult and ambiguous tasks recognised in IoT research. We illustrate our work by examining a number of use cases related to healthcare and smart cities, and finally consider the future development of the IoT eco-system with respect to the socio-technical philosophy and implementation of the Web Observatory.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1669–1672},
numpages = {4},
keywords = {crowdsourcing, web observatory, iot, internet-of-things},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051694,
author = {Wang, Xin and Madaan, Aastha and Siow, Eugene and Tiropanis, Thanassis},
title = {Sharing Databases on the Web with Porter Proxy},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051694},
doi = {10.1145/3041021.3051694},
abstract = {With large number of datasets now available through the Web, data-sharing ecosystems such as the Web Observatory have emerged. The Web Observatory provides an active decentralised ecosystem for datasets and applications based on a number Web Observatory sites, each of which can run in a different administrative domain. On a Web Observatory site users can publish and securely access datasets across domains via a harmonised API and reverse proxies for access control. However, that API provides a different interface to that of the databases on which datasets are stored and, consequently, existing applications that consume data from specific databases require major modification to be added to the Web Observatory ecosystem. In this paper we propose a lightweight architecture called Porter Proxy to address this concern. Porter Proxy exposes the same interfaces as databases as requested by the users while enforcing access control. Characteristics of the proposed Porter Proxy architecture are evaluated based on adversarial scenario-handling in Web Observatory eco-system.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1673–1676},
numpages = {4},
keywords = {proxy, web observatory, security, data sharing, access control},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3051692,
author = {Zhang, Rongxin},
title = {Alienated Digital Identities},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3051692},
doi = {10.1145/3041021.3051692},
abstract = {Digital identities allow friends to like us, governments to analyze us and media platforms to monetize us. As the internet has evolved, so has the creation, storage and access to digital identities. This paper presents the notion that modern digital identities are no longer natural extensions of the user, but alienated entities that exist outside of their control. To justify this claim, this research analyses the externalized storage of digital identities and how this lessens the user's inherent rights and access to them. It introduces concepts such as 'derivative' digital identities and how the over-valuation of company stocks contributes to this alienation. The goal of the research is to justify the need for users to reclaim the ownership, storage, and access to their digital identities. This paper proposes a technical guideline and discusses the benefits and challenges of developing such a system.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1677–1678},
numpages = {2},
keywords = {human factors, verification, decentralization, digital-self, security, digital-identities, experimentation, theory, alienation},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055510,
author = {Lehmann, Jens and Auer, S\"{o}ren and Capadisli, Sarven and Janowicz, Krzysztof and Bizer, Christian and Heath, Tom and Hogan, Aidan and Berners-Lee, Tim},
title = {LDOW2017: 10th Workshop on Linked Data on the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055510},
doi = {10.1145/3041021.3055510},
abstract = {The 10th Linked Data on the Web workshop (LDOW2017) was held in Perth, Western Australia on April 3, 2017, co-located with the 26th International World Wide Web Conference (WWW2017). In its 10th anniversary edition, the LDOW workshop aims to stimulate discussion and further research into the challenges of publishing, consuming, and integrating structured data on the Web as well as mining knowledge from said data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1679–1680},
numpages = {2},
keywords = {linked data, semantic web},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3041021.3055257,
author = {Gonzalez-Beltran, Alejandra and Osborne, Francesco and Peroni, Silvio and Vahdati, Sahar},
title = {SAVE-SD 2017: Third Workshop on Semantics, Analytics and Visualisation: Enhancing Scholarly Data},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055257},
doi = {10.1145/3041021.3055257},
abstract = {The third edition of the Workshop on Semantics, Analytics and Visualisation: Enhancing Scholarly Data (SAVE-SD 2017) is taking place in Perth, Australia on the 3rd of April 2017, co-located with the 26th International World Wide Web Conference. The main goal of the workshop is to provide a venue for researchers, publishers and other companies to engage in discussions about semantics, analytics and visualisations on scholarly data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1681–1682},
numpages = {2},
keywords = {www'17 co-located workshop},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

