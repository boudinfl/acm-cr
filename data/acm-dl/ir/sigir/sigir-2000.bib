@inproceedings{10.1145/345508.344658,
author = {Robertson, Stephen},
title = {Salton Award Lecture: On Theoretical Argument in Information Retrieval (Summary Only): On Theoretical Argument in Information Retrieval},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.344658},
doi = {10.1145/345508.344658},
abstract = {The last winner of the Salton Award, Tefko Saracevic, gave an acceptance address at SIGIR in Philadelphia in 1997. Previous winners were William Cooper (1994), Cyril Cleverdon (1991), Karen Sparck Jones (1988) and Gerard Salton himself (1985).In this talk, I plan to follow the tradition of acceptance addresses, and present a personal view of and retrospective on some of the areas in which I work. However, I will not be saying much about what are perhaps the two most obvious parts of my work: the probabilistic approach to retrieval and evaluation of retrieval systems. Rather I will attempt to get under the skin of my take on IR, by discussing the nature of theoretical argument in the field, partly through examples. This talk is about the place of theory in the study of information retrieval (in some sense following Bill Cooper's 1994 topic), but not so much Theory with a capital T — rather what might be described as small-t theory.The field has a very strong pragmatic orientation, reflected both in the attitudes of the commercial participants and in the emphasis on formal evaluation in the academic environment. Nevertheless, there are many theoretical ideas buried in, or implied by, the ways we talk about the field — the language we use to discuss it. I will be discussing two areas to illustrate these low-level theoretical ideas: precision devices, and the apparent symmetry between retrieval and filtering.The phrase `precision device' used to have a rather clear meaning in IR, in the days of set-based retrieval systems. In that context, a precision device was a device to enable the restriction of the retrieved set to those most likely (out of the documents originally included) to be useful. These days, with the ubiquitous scoring and ranking methods largely replacing set-based retrieval, the idea has lost its meaning It is worth exploring the formal relationships involved to understand the change a little better.My second area is to do with the relation between filtering and the more traditional type of adhoc information retrieval. There is a tendency and a temptation to see these as the same kind of thing, sometimes with a more specific assumption of duality, based on the inversion of the roles of documents and queries. It is important to see how far this parallel extends, and where it breaks down. I explore the nature of the duality and the kinds of reasons why it does break down.These examples reflect my interest in the basic logical structure of information retrieval systems and the situations in which such systems may be found. I argue for a certain level of logical argument in information retrieval, which might be taken as small-t theory, though not as capital-T Theory. I believe there are reasons to think a Grand Theory of IR to be an unattainable goal — such a theory would have to encompass so many different aspects of retrieval, having to do for example with human cognition and behaviour and the structure of knowledge, as well as with the statistical concepts that inform the probabilistic approach.However, accepting the unattainability of a Grand Theory does not preclude the development of further and more useful models based on particular aspects and lower-level logic The low-level logic is important not only in its own right, but as the basis for linking together more sophisticated theories concerned with more restricted domains. The most elaborate and complete theory of (say) user behaviour is of no use at all without a strong linkage between the parts of that theory and the entities relevant to IR that fall outside its scope. The glue that provides that linkage has to be low-level logic.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1},
numpages = {1},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345512,
author = {Vakkari, Pertti},
title = {Relevance and Contributing Information Types of Searched Documents in Task Performance},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345512},
doi = {10.1145/345508.345512},
abstract = {End-users base the relevance judgements of the searched documents on the expected contribution to their task of the information contained in the documents. There is a shortage of studies analyzing the relationships between the experienced contribution, relevance assessments and type of information initially sought. This study categorizes the types of information in documents being used in writing a research proposal for a master's thesis by eleven students throughout the various stages of the proposal writing process. The role of the specificity of the searched information in influencing its contribution is analyzed. The results demonstrate that different types of information are sought at different stages of the writing process and thus the contribution of the information also differs at the different stages. The categories of the contributing information can be understood of topicality.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2–9},
numpages = {8},
keywords = {situational relevance, embedding search within larger tasks, cognitive models and IR, field/empirical studies of the information seeking, process},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345538,
author = {Iwayama, Makoto},
title = {Relevance Feedback with a Small Number of Relevance Judgements: Incremental Relevance Feedback vs. Document Clustering},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345538},
doi = {10.1145/345508.345538},
abstract = {The use of incremental relevance feedback and document clustering were investigated in an relevance feedback environment in which the number of relevance judgements was quite small. Through experiments on the TREC collection, the incremental relevance feedback approach was found not to improve the overall search effectiveness. The clustering approach was found to be promising, although it sometimes over-focuses on a particular topic in a query and ignores the others. To overcome this problem, a query-biased clustering algorithm was developed and shown to be effective.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {10–16},
numpages = {7},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345539,
author = {Hersh, William and Turpin, Andrew and Price, Susan and Chan, Benjamin and Kramer, Dale and Sacherek, Lynetta and Olson, Daniel},
title = {Do Batch and User Evaluations Give the Same Results?},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345539},
doi = {10.1145/345508.345539},
abstract = {Do improvements in system performance demonstrated by batch evaluations confer the same benefit for real users? We carried out experiments designed to investigate this question. After identifying a weighting scheme that gave maximum improvement over the baseline in a non-interactive evaluation, we used it with real users searching on an instance recall task. Our results showed the weighting scheme giving beneficial results in batch studies did not do so with real users. Further analysis did identify other factors predictive of instance recall, including number of documents saved by the user, document recall, and number of documents seen by the user.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {17–24},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345541,
author = {Sormunen, Eero},
title = {A Novel Method for the Evaluation of Boolean Query Effectiveness across a Wide Operational Range},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345541},
doi = {10.1145/345508.345541},
abstract = {Traditional methods for the system-oriented evaluation of Boolean IR system suffer from validity and reliability problems. Laboratory-based research neglects the searcher and studies suboptimal queries. Research on operational systems fails to make a distinction between searcher performance and system performance. This approach is neither capable of measuring performance at standard points of operation (e.g. across R0.0-R1.0).A new laboratory-based evaluation method for Boolean IR systems is proposed. It is based on a controlled formulation of inclusive query plans, on an automatic conversion of query plans into elementary queries, and on combining elementary queries into optimal queries at standard points of operation. Major results of a large case experiment are reported. The validity, reliability, and efficiency of the method are considered in the light of empirical and analytical test data.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {25–32},
numpages = {8},
keywords = {test collections, structured queries, testing methodology, evaluation (general)},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345543,
author = {Buckley, Chris and Voorhees, Ellen M.},
title = {Evaluating Evaluation Measure Stability},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345543},
doi = {10.1145/345508.345543},
abstract = {This paper presents a novel way of examining the accuracy of the evaluation measures commonly used in information retrieval experiments. It validates several of the rules-of-thumb experimenters use, such as the number of queries needed for a good experiment is at least 25 and 50 is better, while challenging other beliefs, such as the common evaluation measures are equally reliable. As an example, we show that Precision at 30 documents has about twice the average error rate as Average Precision has. These results can help information retrieval researchers design experiments that provide a desired level of confidence in their results. In particular, we suggest researchers using Web measures such as Precision at 10 documents will need to use many more than 50 queries or will have to require two methods to have a very large difference in evaluation scores before concluding that the two methods are actually different.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {33–40},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345545,
author = {J\"{a}rvelin, Kalervo and Kek\"{a}l\"{a}inen, Jaana},
title = {IR Evaluation Methods for Retrieving Highly Relevant Documents},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345545},
doi = {10.1145/345508.345545},
abstract = {This paper proposes evaluation methods based on the use of non-dichotomous relevance judgements in IR experiments. It is argued that evaluation methods should credit IR methods for their ability to retrieve highly relevant documents. This is desirable from the user point of view in modern large IR environments. The proposed methods are (1) a novel application of P-R curves and average precision computations based on separate recall bases for documents of different degrees of relevance, and (2) two novel measures computing the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. We then demonstrate the use of these evaluation methods in a case study on the effectiveness of query types, based on combinations of query structures and expansion, in retrieving documents of various degrees of relevance. The test was run with a best match retrieval system (In-Query1) in a text database consisting of newspaper articles. The results indicate that the tested strong query structures are most effective in retrieving highly relevant documents. The differences between the query types are practically essential and statistically significant. More generally, the novel evaluation methods and the case demonstrate that non-dichotomous relevance assessments are applicable in IR experiments, may reveal interesting phenomena, and allow harder testing of IR methods.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {41–48},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345546,
author = {Swan, Russell and Allan, James},
title = {Automatic Generation of Overview Timelines},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345546},
doi = {10.1145/345508.345546},
abstract = {We present a statistical model of feature occurrence over time, and develop tests based on classical hypothesis testing for significance of term appearance on a given date. Using additional classical hypothesis testing we are able to combine these terms to generate “topics” as defined by the Topic Detection and Tracking study. The groupings of terms obtained can be used to automatically generate an interactive timeline displaying the major events and topics covered by the corpus. To test the validity of our technique we extracted a large number of these topics from a test corpus and had human evaluators judge how well the selected features captured the gist of the topics, and how they overlapped with a set of known topics from the corpus. The resulting topics were highly rated by evaluators who compared them to known topics.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {49–56},
numpages = {8},
keywords = {event detection and tracking, text data mining, UIs/visualization for collection overviews, statistical/probabilistic models},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345548,
author = {Fukumoto, Fumiyo and Suzuki, Yoshimi},
title = {Event Tracking Based on Domain Dependency},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345548},
doi = {10.1145/345508.345548},
abstract = {This paper proposes a method for event tracking on broadcast news stories based on distinction between a topic and an event. A topic and an event are identified using a simple criterion called domain dependency of words: how greatly a word features a given set of data. The method was tested on the TDT corpus which has been developed by the TDT Pilot Study and the result can be regarded as promising the usefulness of the method.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {57–64},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345550,
author = {Yang, Yiming and Ault, Tom and Pierce, Thomas and Lattimer, Charles W.},
title = {Improving Text Categorization Methods for Event Tracking},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345550},
doi = {10.1145/345508.345550},
abstract = {Automated tracking of events from chronologically ordered document streams is a new challenge for statistical text classification. Existing learning techniques must be adapted or improved in order to effectively handle difficult situations where the number of positive training instances per event is extremely small, the majority of training documents are unlabelled, and most of the events have a short duration in time. We adapted several supervised text categorization methods, specifically several new variants of the k-Nearest Neighbor (kNN) algorithm and a Rocchio approach, to track events. All of these methods showed significant improvement (up to 71% reduction in weighted error rates) over the performance of the original kNN algorithm on TDT benchmark collections, making kNN among the top-performing systems in the recent TDT3 official evaluation. Furthermore, by combining these methods, we significantly reduced the variance in performance of our event tracking system over different data collections, suggesting a robust solution for parameter optimization.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {65–72},
numpages = {8},
keywords = {event detection and tracking, evaluation, text categorization, machine learning and IR, statistical/probabilistic models},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345551,
author = {Downie, Stephen and Nelson, Michael},
title = {Evaluation of a Simple and Effective Music Information Retrieval Method},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345551},
doi = {10.1145/345508.345551},
abstract = {We developed, and then evaluated, a music information retrieval (MIR) system based upon the intervals found within the melodies of a collection of 9354 folksongs. The songs were converted to an interval-only representation of monophonic melodies and then fragmented t into length-n subsections called n-grams. The length of these n-grams and the degree to which we precisely represent the intervals are variables analyzed in this paper. We constructed a collection of “musical word” databases using the text-based, SMART information retrieval system. A group of simulated queries, some of which contained simulated errors, was run against these databases. The results were evaluated using the normalized precision and normalized recall measures. Our concept of “musical words” shows great merit thus implying that useful MIR systems can be constructed simply and efficiently using pre-existing text-based information retrieval software. Second, this study is a formal and comprehensive evaluation of a MIR system using rigorous statistical analyses to determine retrieval effectiveness.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {73–80},
numpages = {8},
keywords = {results analysis and presentation for MMIR, efficient search over non-textual information},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345552,
author = {Srinivasan, Savitha and Petkovic, Dragutin},
title = {Phonetic Confusion Matrix Based Spoken Document Retrieval},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345552},
doi = {10.1145/345508.345552},
abstract = {Combined word-based index and phonetic indexes have been used to improve the performance of spoken document retrieval systems primarily by addressing the out-of-vocabulary retrieval problem. However, a known problem with phonetic recognition is its limited accuracy in comparison with word level recognition. We propose a novel method for phonetic retrieval in the CueVideo system based on the probabilistic formulation of term weighting using phone confusion data in a Bayesian framework. We evaluate this method of spoken document retrieval against word-based retrieval for the search levels identified in a realistic video-based distributed learning setting. Using our test data, we achieved an average recall of 0.88 with an average precision of 0.69 for retrieval of out-of-vocabulary words on phonetic transcripts with 35% word error rate. For in-vocabulary words, we achieved a 17% improvement in recall over word-based retrieval with a 17% loss in precision for word error rites ranging from 35 to 65%.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {81–87},
numpages = {7},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345553,
author = {Aslandogan, Y. Alp and Yu, Clement T.},
title = {Multiple Evidence Combination in Image Retrieval: Diogenes Searches for People on the Web},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345553},
doi = {10.1145/345508.345553},
abstract = {In this work, we examine evidence combination mechanisms for classifying multimedia information. In particular, we examine linear and Dempster-Shafer methods of evidence combination in the context of identifying personal images on the World Wide Web. An automatic web search engine named Diogenes1 searches the web for personal images and combines different pieces of evidence for identification. The sources of evidence consist of input from face detection/recognition and text/HTML analysis modules. A degree of uncertainty is involved with both of these sources. Diogenes automatically determines the uncertainty locally for each retrieval and uses this information to set a relative significance for each evidence. To our knowledge, Diogenes is the first image search engine using Dempster-Shafer evidence combination based on automatic object recognition and dynamic local uncertainty assessment. In our experiments Diogenes comfortably outperformed some well known commercial and research prototype image search engines for celebrity image queries.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {88–95},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345554,
author = {Silva, Ilm\'{e}rio and Ribeiro-Neto, Berthier and Calado, P\'{a}vel and Moura, Edleno and Ziviani, N\'{\i}vio},
title = {Link-Based and Content-Based Evidential Information in a Belief Network Model},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345554},
doi = {10.1145/345508.345554},
abstract = {This work presents an information retrieval model developed to deal with hyperlinked environments. The model is based on belief networks and provides a framework for combining information extracted from the content of the documents with information derived from cross-references among the documents. The information extracted from the content of the documents is based on statistics regarding the keywords in the collection and is one of the basis for traditional information retrieval (IR) ranking algorithms. The information derived from cross-references among the documents is based on link references in a hyperlinked environment and has received increased attention lately due to the success of the Web. We discuss a set of strategies for combining these two types of sources of evidential information and experiment with them using a reference collection extracted from the Web. The results show that this type of combination can improve the retrieval performance without requiring any extra information from the users at query time. In our experiments, the improvements reach up to 59% in terms of average precision figures.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {96–103},
numpages = {8},
keywords = {exploiting hyperlinked structure, IR models, content-based retrieval},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345556,
author = {Aizawa, Akiko},
title = {The Feature Quantity: An Information Theoretic Perspective of Tfidf-like Measures},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345556},
doi = {10.1145/345508.345556},
abstract = {The feature quantity, a quantitative representation of specificity introduced in this paper, is based on an information theoretic perspective of co-occurrence events between terms and documents. Mathematically, the feature quantity is defined as a product of probability and information, and maintains a good correspondence with the tfidf-like measures popularly used in today's IR systems. In this paper, we present a formal description of the feature quantity, as well as some illustrative examples of applying such a quantity to different types of information retrieval tasks: representative term selection and text categorization.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {104–111},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345559,
author = {Reiterer, Harald and Mu\ss{}ler, Gabriela and Mann, Thomas M. and Handschuh, Siegfried},
title = {INSYDER — an Information Assistant for Business Intelligence},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345559},
doi = {10.1145/345508.345559},
abstract = {The WWW is the most important resource for external business information. This paper presents a tool called INSYDER, an information assistant for finding and analysis business information from the WWW. INSYDER is a system using different agents for crawling the Web, evaluating and visualising the results. These agents, the used visualisations, and a first summary of user studies are presented.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {112–119},
numpages = {8},
keywords = {(semi) automated search assistants, UIs/visualization organizing and displaying retieval, user studies, results},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345562,
author = {Sperer, Ruth and Oard, Douglas W.},
title = {Structured Translation for Cross-Language Information Retrieval},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345562},
doi = {10.1145/345508.345562},
abstract = {The paper introduces a query translation model that reflects the structure of the cross-language information retrieval task. The model is based on a structured bilingual dictionary in which the translations of each term are clustered into groups with distinct meanings. Query translation is modeled as a two-stage process, with the system first determining the intended meaning of a query term and then selecting translations appropriate to that meaning that might appear in the document collection. An implementation of structured translation based on automatic dictionary clustering is described and evaluated by using Chinese queries to retrieve English documents. Structured translation achieved an average precision that was statistically indistinguishable from Pirkola's technique for very short queries, but Pirkola's technique outperformed structured translation on long queries. The paper concludes with some observations on future work to improve retrieval effectiveness and on other potential uses of structured translation in interactive cross-language retrieval applications.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {120–127},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345563,
author = {Petasis, Georgios and Cucchiarelli, Alessandro and Velardi, Paola and Paliouras, Georgios and Karkaletsis, Vangelis and Spyropoulos, Constantine D.},
title = {Automatic Adaptation of Proper Noun Dictionaries through Cooperation of Machine Learning and Probabilistic Methods},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345563},
doi = {10.1145/345508.345563},
abstract = {The recognition of Proper Nouns (PNs) is considered an important task in the area of Information Retrieval and Extraction. However the high performance of most existing PN classifiers heavily depends upon the availability of large dictionaries of domain-specific Proper Nouns, and a certain amount of manual work for rule writing or manual tagging. Though it is not a heavy requirement to rely on some existing PN dictionary (often these resources are available on the web), its coverage of a domain corpus may be rather low, in absence of manual updating. In this paper we propose a technique for the automatic updating of an PN Dictionary through the cooperation of an inductive and a probabilistic classifier. In our experiments we show that, whenever an existing PN Dictionary allows the identification of 50% of the proper nouns within a corpus, our technique allows, without additional manual effort, the successful recognition of about 90% of the remaining 50%.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {128–135},
numpages = {8},
keywords = {natural language processing for IR, information extraction, text data mining, machine learning and IR},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345564,
author = {Mikheev, Andrei},
title = {Document Centered Approach to Text Normalization},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345564},
doi = {10.1145/345508.345564},
abstract = {In this paper we present an approach to tackle three important problems of text normalization: sentence boundary disambiguation, disambiguation of capitalized words when they are used in positions where capitalization is expected, and identification of abbreviations. The main feature of our approach is that it uses a minimum of pre-built resources, instead dynamically inferring disambiguation clues from the entire document itself. This makes it domain independent, closely targeted to each individual document and portable to other languages. We thoroughly evaluated this approach on several corpora and it showed high accuracy.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {136–143},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345565,
author = {Berger, Adam L. and Mittal, Vibhu O.},
title = {OCELOT: A System for Summarizing Web Pages},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345565},
doi = {10.1145/345508.345565},
abstract = {We introduce OCELOT, a prototype system for automatically generating the “gist” of a web page by summarizing it. Although most text summarization research to date has focused on the task of news articles, web pages are quite different in both structure and content. Instead of coherent text with a well-defined discourse structure, they are more often likely to be a chaotic jumble of phrases, links, graphics and formatting commands. Such text provides little foothold for extractive summarization techniques, which attempt to generate a summary of a document by excerpting a contiguous, coherent span of text from it. This paper builds upon recent work in non-extractive summarization, producing the gist of a web page by “translating” it into a more concise representation rather than attempting to extract a text span verbatim. OCELOT uses probabilistic models to guide it in selecting and ordering words into a gist. This paper describes a technique for learning these models automatically from a collection of human-summarized web pages.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {144–151},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345566,
author = {Chuang, Wesley T. and Yang, Jihoon},
title = {Extracting Sentence Segments for Text Summarization: A Machine Learning Approach},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345566},
doi = {10.1145/345508.345566},
abstract = {With the proliferation of the Internet and the huge amount of data it transfers, text summarization is becoming more important. We present an approach to the design of an automatic text summarizer that generates a summary by extracting sentence segments. First, sentences are broken into segments by special cue markers. Each segment is represented by a set of predefined features (e.g. location of the segment, average term frequencies of the words occurring in the segment, number of title words in the segment, and the like). Then a supervised learning algorithm is used to train the summarizer to extract important sentence segments, based on the feature vector. Results of experiments on U.S. patents indicate that the performance of the proposed approach compares very favorably with other approaches (including Microsoft Word summarizer) in terms of precision, recall, and classification accuracy.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {152–159},
numpages = {8},
keywords = {text summarization, machine learning, sentence segment extraction},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345569,
author = {Androutsopoulos, Ion and Koutsias, John and Chandrinos, Konstantinos V. and Spyropoulos, Constantine D.},
title = {An Experimental Comparison of Naive Bayesian and Keyword-Based Anti-Spam Filtering with Personal e-Mail Messages},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345569},
doi = {10.1145/345508.345569},
abstract = {The growing problem of unsolicited bulk e-mail, also known as “spam”, has generated a need for reliable anti-spam e-mail filters. Filters of this type have so far been based mostly on manually constructed keyword patterns. An alternative approach has recently been proposed, whereby a Naive Bayesian classifier is trained automatically to detect spam messages. We test this approach on a large collection of personal e-mail messages, which we make publicly available in “encrypted” form contributing towards standard benchmarks. We introduce appropriate cost-sensitive measures, investigating at the same time the effect of attribute-set size, training-corpus size, lemmatization, and stop lists, issues that have not been explored in previous experiments. Finally, the Naive Bayesian filter is compared, in terms of performance, to a filter that uses keyword patterns, and which is part of a widely used e-mail reader.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {160–167},
numpages = {8},
keywords = {test collections, text categorization, filtering/routing, evaluation (general), machine learning and IR},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345572,
author = {Kim, Yu-Hwan and Hahn, Shang-Yoon and Zhang, Byoung-Tak},
title = {Text Filtering by Boosting Naive Bayes Classifiers},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345572},
doi = {10.1145/345508.345572},
abstract = {Several machine learning algorithms have recently been used for text categorization and filtering. In particular, boosting methods such as AdaBoost have shown good performance applied to real text data. However, most of existing boosting algorithms are based on classifiers that use binary-valued features. Thus, they do not fully make use of the weight information provided by standard term weighting methods. In this paper, we present a boosting-based learning method for text filtering that uses naive Bayes classifiers as a weak learner. The use of naive Bayes allows the boosting algorithm to utilize term frequency information while maintaining probabilistically accurate confidence ratio. Applied to TREC-7 and TREC-8 filtering track documents, the proposed method obtained a significant improvement in LF1, LF2, F1 and F3 measures compared to the best results submitted by other TREC entries.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {168–175},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345573,
author = {Hoashi, Keiichiro and Matsumoto, Kazunori and Inoue, Naomi and Hashimoto, Kazuo},
title = {Document Filtering Method Using Non-Relevant Information Profile},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345573},
doi = {10.1145/345508.345573},
abstract = {Document filtering is a task to retrieve documents relevant to a user's profile from a flow of documents. Generally, filtering systems calculate the similarity between the profile and each incoming document, and retrieve documents with similarity higher than a threshold. However, many systems set a relatively high threshold to reduce retrieval of non-relevant documents, which results in the ignorance of many relevant documents. In this paper, we propose the use of a non-relevant information profile to reduce the mistaken retrieval of non-relevant documents. Results from experiments show that this filter has successfully rejected a sufficient number of non-relevant documents, resulting in an improvement of filtering performance.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {176–183},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345574,
author = {Prager, John and Brown, Eric and Coden, Anni and Radev, Dragomir},
title = {Question-Answering by Predictive Annotation},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345574},
doi = {10.1145/345508.345574},
abstract = {We present a new technique for question answering called Predictive Annotation. Predictive Annotation identifies potential answers to questions in text, annotates them accordingly and indexes them. This technique, along with a complementary analysis of questions, passage-level ranking and answer selection, produces a system effective at answering natural-language fact-seeking questions posed against large document collections. Experimental results show the effects of different parameter settings and lead to a number of general observations about the question-answering problem.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {184–191},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345576,
author = {Berger, Adam and Caruana, Rich and Cohn, David and Freitag, Dayne and Mittal, Vibhu},
title = {Bridging the Lexical Chasm: Statistical Approaches to Answer-Finding},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345576},
doi = {10.1145/345508.345576},
abstract = {This paper investigates whether a machine can automatically learn the task of finding, within a large collection of candidate responses, the answers to questions. The learning process consists of inspecting a collection of answered questions and characterizing the relation between question and answer with a statistical model. For the purpose of learning this relation, we propose two sources of data: Usenet FAQ documents and customer service call-center dialogues from a large retail company. We will show that the task of “answer-finding” differs from both document retrieval and tradition question-answering, presenting challenges different from those found in these problems. The central aim of this work is to discover, through theoretical and empirical investigation, those statistical techniques best suited to the answer-finding problem.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {192–199},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345577,
author = {Voorhees, Ellen M. and Tice, Dawn M.},
title = {Building a Question Answering Test Collection},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345577},
doi = {10.1145/345508.345577},
abstract = {The TREC-8 Question Answering (QA) Track was the first large-scale evaluation of domain-independent question answering systems. In addition to fostering research on the QA task, the track was used to investigate whether the evaluation methodology used for document retrieval is appropriate for a different natural language processing task. As with document relevance judging, assessors had legitimate differences of opinions as to whether a response actually answers a question, but comparative evaluation of QA systems was stable despite these differences. Creating a reusable QA test collection is fundamentally more difficult than creating a document retrieval test collection since the QA task has no equivalent to document identifiers.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {200–207},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345578,
author = {Slonim, Noam and Tishby, Naftali},
title = {Document Clustering Using Word Clusters via the Information Bottleneck Method},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345578},
doi = {10.1145/345508.345578},
abstract = {We present a novel implementation of the recently introduced information bottleneck method for unsupervised document clustering. Given a joint empirical distribution of words and documents, p(x, y), we first cluster the words, Y, so that the obtained word clusters, Ytilde;, maximally preserve the information on the documents. The resulting joint distribution. p(X, Ytilde;), contains most of the original information about the documents, I(X; Ytilde;) ≈ I(X; Y), but it is much less sparse and noisy. Using the same procedure we then cluster the documents, X, so that the information about the word-clusters is preserved. Thus, we first find word-clusters that capture most of the mutual information about to set of documents, and then find document clusters, that preserve the information about the word clusters. We tested this procedure over several document collections based on subsets taken from the standard 20Newsgroups corpus. The results were assessed by calculating the correlation between the document clusters and the correct labels for these documents. Finding from our experiments show that this double clustering procedure, which uses the information bottleneck method, yields significantly superior performance compared to other common document distributional clustering algorithms. Moreover, the double clustering procedure improves all the distributional clustering methods examined here.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {208–215},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345579,
author = {Ando, Rie Kubota},
title = {Latent Semantic Space: Iterative Scaling Improves Precision of Inter-Document Similarity Measurement},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345579},
doi = {10.1145/345508.345579},
abstract = {We present a novel algorithm that creates document vectors with reduced dimensionality. This work was motivated by an application characterizing relationships among documents in a collection. Our algorithm yielded inter-document similarities with an average precision up to 17.8% higher than that of singular value decomposition (SVD) used for Latent Semantic Indexing. The best performance was achieved with dimensional reduction rates that were 43% higher than SVD on average. Our algorithm creates basis vectors for a reduced space by iteratively “scaling” vectors and computing eigenvectors. Unlike SVD, it breaks the symmetry of documents and terms to capture information more evenly across documents. We also discuss correlation with a probabilistic model and evaluate a method for selecting the dimensionality using log-likelihood estimation.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {216–223},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

@inproceedings{10.1145/345508.345582,
author = {Hatzivassiloglou, Vasileios and Gravano, Luis and Maganti, Ankineedu},
title = {An Investigation of Linguistic Features and Clustering Algorithms for Topical Document Clustering},
year = {2000},
isbn = {1581132263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/345508.345582},
doi = {10.1145/345508.345582},
abstract = {We investigate four hierarchical clustering methods (single-link, complete-link, groupwise-average, and single-pass) and two linguistically motivated text features (noun phrase heads and proper names) in the context of document clustering. A statistical model for combining similarity information from multiple sources is described and applied to DARPA's Topic Detection and Tracking phase 2 (TDT2) data. This model, based on log-linear regression, alleviates the need for extensive search in order to determine optimal weights for combining input features. Through an extensive series of experiments with more than 40,000 documents from multiple news sources and modalities, we establish that both the choice of clustering algorithm and the introduction of the additional features have an impact on clustering performance. We apply our optimal combination of features to the TDT2 test data, obtaining partitions of the documents that compare favorably with the results obtained by participants in the official TDT2 competition.},
booktitle = {Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {224–231},
numpages = {8},
location = {Athens, Greece},
series = {SIGIR '00}
}

