@inproceedings{10.1145/3015157.3015158,
author = {Ziemer, Tim and Yu, Yi and Tang, Suhua},
title = {Using Psychoacoustic Models for Sound Analysis in Music},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015158},
doi = {10.1145/3015157.3015158},
abstract = {Overall sound perception of a song is an important attribute of music. Several psychoacoustic models have been studied to extract perceptual sound qualities from audio signals. By means of listening tests, we investigate whether these sound models successfully reflect (inter-)subjective perception of sound resemblance in music. Preliminary results shows that psychoacoustic descriptors are in better accordance with subjective judgments than low-level features. As the psychoacoustic descriptors model auditory perception, we can assume causal relationships and directly draw conclusions on perception from the listening test results. We observed that roughness is the most crucial sound resemblance criteria, followed by sharpness, loudness, spaciousness and tonalness. The findings indicate that these psychoacoustic models may be suitable for music data mining, music browsing, automatic playlist generation and music recommendation tasks.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {1–7},
numpages = {7},
keywords = {sound analysis, music perception, psychoacoustics, music recommendation},
location = {Kolkata, India},
series = {FIRE '16}
}

@inproceedings{10.1145/3015157.3015159,
author = {Srivastava, Rajiv and Hingmire, Swapnil and Palshikar, Girish K. and Chaurasia, Saheb and Dixit, Arati},
title = {CSRS: A Context and Sequence Aware Recommendation System},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015159},
doi = {10.1145/3015157.3015159},
abstract = {The effectiveness of recommendation systems is improving with the incorporation of richer context. The frequentist recommendation methods such as Markov models are not efficient in simultaneous use of context and preference sequences over items due to state space explosion. On the other end, abstractionist models such as Matrix Factorization where each item or user is represented as a set of abstract features are difficult to explain. An example in this case is, recommending Web Based Trainings (WBTs) to employees, similar to Massively Open Online Courses (MOOCs), wherein use of the sequence information in the recommendation of WBTs would help the user to gradually build expertise in their area of interest. For training recommendation, it is important to identify the held expertise level in technical area, that represents a state and possible sequences of trainings that represent transitions in terms of real world entities such as trainings and associated features. Alternatively the model can estimate expertise as a mixture over a tractable set of latent interests in terms of trainings completed, contextual features such as the training sequences, keywords and user profile. To the best of our knowledge, the state-of-the-art recommendation methods do not consider both explicit context and sequence information in a single model. In this paper, we propose a Context and Sequence Aware Recommendation System (CSRS) based on latent topic modelling framework, identifying topic-memberships for items, contextual features as well as for user interests. We demonstrate benefits of incorporating both context and sequence of items for recommendation on three real world datasets.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {8–15},
numpages = {8},
location = {Kolkata, India},
series = {FIRE '16}
}

@inproceedings{10.1145/3015157.3015160,
author = {Chavula, Catherine and Suleman, Hussein},
title = {Assessing the Impact of Vocabulary Similarity on Multilingual Information Retrieval for Bantu Languages},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015160},
doi = {10.1145/3015157.3015160},
abstract = {Despite the availability of massive open information and efforts to promote multilingualism on the Web, content in Bantu languages remains negligible. Additionally, Information Retrieval (IR) systems, such as the Google search engine, use algorithms that work well with languages that have the most content. Similarities across related languages such as vocabulary overlap can potentially be exploited to provide more opportunities for information access for languages with limited digital content. This study investigates how vocabulary similarity impacts on the quality of search results in Multilingual Information Retrieval (MLIR) environments. More specifically, the study evaluates indexing strategies for MLIR and their effect on the quality of retrieval for related languages. A multilingual test collection consisting of two Bantu languages, Citumbuka and Chichewa, and English was developed and used in the evaluation. The results show that when comparing related and unrelated language pairs, MLIR indexing strategies result in comparable or worse retrieval performance.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {16–23},
numpages = {8},
keywords = {Information Retrieval Evaluation, Multilingual Information Retrieval, Test Collection},
location = {Kolkata, India},
series = {FIRE '16}
}

@inproceedings{10.1145/3015157.3015161,
author = {Modaresi, Pashutan and Conrad, Stefan},
title = {Simurg: An Extendable Multilingual Corpus for Abstractive Single Document Summarization},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015161},
doi = {10.1145/3015157.3015161},
abstract = {Abstractive single document summarization is considered as a challenging problem in the field of artificial intelligence and natural language processing. Meanwhile and specifically in the last two years, several deep learning summarization approaches were proposed that once again attracted the attention of researchers to this field.It is a well-known issue that deep learning approaches do not work well with small amounts of data. With some exceptions, this is, unfortunately, the case for most of the datasets available for the summarization task. Besides this problem, it should be considered that phonetic, morphological, semantic and syntactic features of the language are constantly changing over the time and unfortunately most of the summarization corpora are constructed from old resources. Another problem is the language of the corpora. Not only in the summarization field, but also in other fields of natural language processing, most of the corpora are only available in English. In addition to the above problems, license terms, and fees of the corpora are obstacles that prevent many academics and specifically non-academics from accessing these data.This work describes an open source framework to create an extendable multilingual corpus for abstractive single document summarization that addresses the above-mentioned problems. We describe a tool consisted of a scalable crawler and a centralized key-value store database to construct a corpus of an arbitrary size using a news aggregator service.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {24–27},
numpages = {4},
keywords = {single document summarization, Abstractive text summarization, extendable corpora, multilingual corpora},
location = {Kolkata, India},
series = {FIRE '16}
}

@inproceedings{10.1145/3015157.3015163,
author = {Modaresi, Pashutan and Liebeck, Matthias and Conrad, Stefan},
title = {Neural Classification of Linguistic Coherence Using Long Short-Term Memories},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015163},
doi = {10.1145/3015157.3015163},
abstract = {Given a set of sentences, a sentence orderer permutes the sentences in a way that the final text is linguistically coherent and semantically understandable. In this work, we focus on the binary and ternary tasks of ordering a pair of sentences regarding their linguistic coherence. We propose a methodology to automatically collect and annotate sentence ordering corpora in the news domain for English and German documents. Furthermore, we introduce a data-driven end-to-end neural architecture to learn the order of a pair of sentences and also recognize the cases where no ordering can be determined due to missing context.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {28–31},
numpages = {4},
keywords = {Sentence ordering, neural coherence classification, long short-term memory},
location = {Kolkata, India},
series = {FIRE '16}
}

@inproceedings{10.1145/3015157.3015164,
author = {Phani, Shanta and Lahiri, Shibamouli and Dutta, Sudipta and Biswas, Arindam},
title = {An Indic Language N-Gram Viewer},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015164},
doi = {10.1145/3015157.3015164},
abstract = {In this paper, we introduce culturomic studies on diachronic corpora for three languages -- Hindi, Bengali, and English, in the same spirit as that of the Google Culturomics Project [13]. Based on Hindi, Bengali, and English text from news blogs and newspapers, we are able to extract trajectories of salient words that are of importance in contemporary India. We also propose an n-gram viewer which produces the time-series plots for the corpora. To the best of our knowledge, this is the first time an n-gram viewer has been proposed for Indic languages. As a result of our analysis, we obtain interesting insights into word usage and cultural shift in contemporary India.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {32–36},
numpages = {5},
location = {Kolkata, India},
series = {FIRE '16}
}

@inproceedings{10.1145/3015157.3015165,
author = {Roul, Rajendra Kumar and Bhalla, Aditya and Srivastava, Abhishek},
title = {Commonality-Rarity Score Computation: A Novel Feature Selection Technique Using Extended Feature Space of ELM for Text Classification},
year = {2016},
isbn = {9781450348386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015157.3015165},
doi = {10.1145/3015157.3015165},
abstract = {The number of digital documents, which are a collection of a huge volume of features on the Web, is increasing day-by-day. Hence, selection of important features relevant to the classification process, and consequently discarding irrelevant ones, is the need of the hour. Aiming in this direction, this paper highlights two important aspects of Information Retrieval:- proposes a new feature selection technique called Commonality-Rarity Score Computation (CRSC) to find the important features from a large corpus.- shows the importance of extended feature space of Extreme Learning Machine (ELM) in the field of text categorization.Empirical results on two established datasets show that the proposed approach is more promising compared to the standard feature selection techniques and the performance of ELM outperforms other prominent classifiers.},
booktitle = {Proceedings of the 8th Annual Meeting of the Forum on Information Retrieval Evaluation},
pages = {37–41},
numpages = {5},
keywords = {Text classification, Extreme learning machine, Rarity, Commonality, Feature selection},
location = {Kolkata, India},
series = {FIRE '16}
}

