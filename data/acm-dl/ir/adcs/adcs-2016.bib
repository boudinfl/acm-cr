@inbook{10.1145/3015022.3015023,
author = {Trotman, Andrew and Lin, Jimmy},
title = {In Vacuo and In Situ Evaluation of SIMD Codecs},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015023},
abstract = {The size of a search engine index and the time to search are inextricably related through the compression codec. This investigation examines this tradeoff using several relatively unexplored SIMD-based codecs including QMX, TurboPackV, and TurboPFor. It uses (the non-SIMD) OPTPFor as a baseline. Four new variants of QMX are introduced and also compared. Those variants include optimizations for space and for time. Experiments were conducted on the TREC .gov2 collection using topics 701-850, in crawl order and in URL order. The results suggest that there is very little difference between these codecs, but that the reference implementation of QMX performs well.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/3015022.3015024,
author = {Potvin, Benoit and Villemaire, Roger and Le, Ngoc-Tan},
title = {A Position-Based Method for the Extraction of Financial Information in PDF Documents},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015024},
doi = {10.1145/3015022.3015024},
abstract = {Financial documents are omnipresent and necessitate extensive human efforts in order to extract, validate and export their content. Considering the high importance of such data for effective business decisions, the need for accuracy goes beyond any attempt to accelerate the process or save resources. While many methods have been suggested in the literature, the problem to automatically extract reliable financial data remains difficult to solve in practice and even more challenging to implement in a real life context. This difficulty is driven by the specific nature of financial text where relevant information is principally contained in tables of varying formats. Table Extraction (TE) is considered as an essential but difficult step for restructuring data in a handleable format by identifying and decomposing table components. In this paper, we present a novel method for extracting financial information by the means of two simple heuristics. Our approach is based on the idea that the position of information, in unstructured but visually rich documents - as it is the case for the Portable Document Format (PDF) - is an indicator of semantic relatedness. This solution has been developed in partnership with the Caisse de Depot et Placement du Qu\'{e}bec. We present here our method and its evaluation on a corpus of 600 financial documents, where an F-measure of 91% is reached.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {9–16},
numpages = {8},
keywords = {semantic relatedness, industrial system, PDF documents, Financial information retrieval},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015026,
author = {Culpepper, J. Shane and Clarke, Charles L. A. and Lin, Jimmy},
title = {Dynamic Cutoff Prediction in Multi-Stage Retrieval Systems},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015026},
doi = {10.1145/3015022.3015026},
abstract = {Modern multi-stage retrieval systems are comprised of a candidate generation stage followed by one or more reranking stages. In such an architecture, the quality of the final ranked list may not be sensitive to the quality of the initial candidate pool, especially in terms of early precision. This provides several opportunities to increase retrieval efficiency without significantly sacrificing effectiveness. In this paper, we explore a new approach to dynamically predicting the size of an initial result set in the candidate generation stage, which can directly affect the overall efficiency and effectiveness of the entire system. Previous work exploring this tradeoff has focused on global parameter settings that apply to all queries, even though optimal settings vary across queries. In contrast, we propose a technique that makes a parameter prediction to maximize efficiency within an effectiveness envelope on a per query basis, using only static pre-retrieval features. Experimental results show that substantial efficiency gains are achievable. In addition, our framework provides a versatile tool that can be used to estimate the effectiveness-efficiency tradeoffs that are possible before selecting and tuning algorithms to make machine-learned predictions.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {17–24},
numpages = {8},
keywords = {Query Prediction, Multi-Stage Retrieval, Measurement, Experimentation},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015028,
author = {Jimmy and Zuccon, Guido and Koopman, Bevan},
title = {Boosting Titles Does Not Generally Improve Retrieval Effectiveness},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015028},
doi = {10.1145/3015022.3015028},
abstract = {The fields that compose structured documents such as web pages have been exploited to improve the effectiveness of information retrieval systems. Field-based retrieval methods assign different levels of importance (weights) to different fields, e.g., by boosting the score of a document when query terms are found in a specific field. An important question is how to decide which field should be boosted? It has been speculated that the title field should receive a higher weight. In this paper, we investigate whether boosting the title field of structured documents actually does improve retrieval effectiveness. Our results show that, on average, boosting titles does not improve retrieval effectiveness for field-based retrieval; this is both for ad-hoc web search and exploratory-based web search tasks. However, we do find that the boosting of titles does generally improve retrieval effectiveness for navigational queries and a small subset of ad-hoc queries. This result advocates for adaptive methods that selectively adjust boosting of specific fields based on the query.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {25–32},
numpages = {8},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015032,
author = {Lim, Wern Han and Carman, Mark James and Wong, Sze-Meng Jojo},
title = {Estimating Domain-Specific User Expertise for Answer Retrieval in Community Question-Answering Platforms},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015032},
doi = {10.1145/3015022.3015032},
abstract = {Community Question-Answering (CQA) platforms leverage the inherent wisdom of the crowd - enabling users to retrieve quality information from domain experts through natural language. An important and challenging task is to identify reliable and trusted experts on large popular CQA platforms. State-of-the-art graph-based approaches to expertise estimation consider only user-user interactions without taking the relative contribution of individual answers into account, while pairwise-comparison approaches consider only pairs involving the best-answerer of each question. This research argues that there is a need to account for the user's relative contribution towards solving the question when estimating user expertise and proposes a content-agnostic measure of user contributions. This addition is incorporated into a competition-based approach for ranking users' question answering ability. The paper analyses how improvements in user expertise estimation impact on applications in expert search and answer quality prediction. Experiments using the Yahoo! Chiebukuro data show encouraging performance improvements and robustness over state-of-the-art approaches.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {33–40},
numpages = {8},
keywords = {Pairwise Comparison, Community Question-Answering (CQA), User Expertise, Answer Quality, Knowledge Mining},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015033,
author = {Damessie, Tadele T. and Scholer, Falk and Culpepper, J. Shane},
title = {The Influence of Topic Difficulty, Relevance Level, and Document Ordering on Relevance Judging},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015033},
doi = {10.1145/3015022.3015033},
abstract = {Judging the relevance of documents for an information need is an activity that underpins the most widely-used approach in the evaluation of information retrieval systems. In this study we investigate the relationship between how long it takes an assessor to judge document relevance, and three key factors that may influence the judging scenario: the difficulty of the search topic for which relevance is being assessed; the degree to which the documents are relevant to the search topic; and, the order in which the documents are presented for judging. Two potential confounding influences on judgment speed are differences in individual reading ability, and the length of documents that are being assessed. We therefore propose two measures to investigate the above factors: normalized processing speed (NPS), which adjusts the number of words that were processed per minute by taking into account differences in reading speed between judges, and normalized dwell time (NDT), which adjusts the duration that a judge spent reading a document relative to document length. Note that these two measures have different relationships with overall judgment speed: a direct relationship for NPS, and an inverse relationship for NDT.The results of a small-scale user study show a statistically significant relationship between judgment speed and topic difficulty: for easier topics, assessors process more quickly (higher NPS), and spend less time overall (lower NDT). There is also a statistically significant relationship between the level of relevance of the document being assessed and overall judgment speed, with assessors taking less time for non-relevant documents. Finally, our results suggest that the presentation order of documents can also affect overall judgment speed, with assessors spending less time (smaller NDT) when documents are presented in relevance order than docID order. However, these ordering effects are not significant when also accounting for document length variance (NPS).},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {41–48},
numpages = {8},
keywords = {order effects, query difficulty, dwell time, user studies},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015034,
author = {Uluwitige, Dinesha Chathurani Nanayakkara Wasam and Geva, Shlomo and Zuccon, Guido and Chandran, Vinod and Chappell, Timothy},
title = {Effective User Relevance Feedback for Image Retrieval with Image Signatures},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015034},
doi = {10.1145/3015022.3015034},
abstract = {Content-based image retrieval (CBIR) has attracted much attention due to the exponential growth of digital image collections that have become available in recent years. Relevance feedback (RF) in the context of search engines is a query expansion technique, which is based on relevance judgments about the top results that are initially returned for a given query. RF can be obtained directly from end users, inferred indirectly from user interactions with a result list, or even assumed (aka pseudo relevance feedback). RF information is used to generate a new query, aiming to re-focus the query towards more relevant results.This paper presents a methodology for use of signature based image retrieval with a user in the loop to improve retrieval performance. The significance of this study is twofold. First, it shows how to effectively use explicit RF with signature based image retrieval to improve retrieval quality and efficiency. Second, this approach provides a mechanism for end users to refine their image queries. This is an important contribution because, to date, there is no effective way to reformulate an image query; our approach provides a solution to this problem.Empirical experiments have been carried out to study the behaviour and optimal parameter settings of this approach. Empirical evaluations based on standard benchmarks demonstrate the effectiveness of the proposed approach in improving the performance of CBIR in terms of recall, precision, speed and scalability.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {49–56},
numpages = {8},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015036,
author = {Kim, Sunghwan Mac and Wan, Stephen and Paris, C\'{e}cile},
title = {Occupational Representativeness in Twitter},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015036},
doi = {10.1145/3015022.3015036},
abstract = {This paper describes an approach to detect one particular demographic characteristic, occupation (or profession) in Twitter user profiles. In this paper, we show how effective the approach is for estimating occupational population statistics in Australian Twitter by correlating them with real-world population obtained from 2011 Australian census data. We also demonstrate that we can gain more reliable social media insights in the context of occupational representativeness in Twitter if a non-standard occupation name is mapped into a standard occupation name. To our knowledge, this is the first attempt to build a machine learning model that automatically identifies linguistically noisy or open-ended occupations in Twitter, resulting in more reliable occupational population.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {57–64},
numpages = {8},
keywords = {Census, Conditional Random Fields, Twitter, Occupation},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015025,
author = {Moffat, Alistair},
title = {Judgment Pool Effects Caused by Query Variations},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015025},
doi = {10.1145/3015022.3015025},
abstract = {Batch-mode retrieval evaluation relies on suitable relevance judgments being available. Here we explore the implications on pool size of adopting a "query variations" approach to collection construction. Using the resources provided as part of the UQV100 collection [Bailey et al., SIGIR 2016] and a total of five different systems, we show that pool size is as much affected by the number of query variations involved as it is by the number of contributing systems, and that systems and users are independent effects. That is, if both system and query variation are to be accommodated in retrieval experimentation, the cost of performing the required judgments compounds.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {65–68},
numpages = {4},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015027,
author = {Au, Vincent and Thomas, Paul and Jayasinghe, Gaya K.},
title = {Query-Biased Summaries for Tabular Data},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015027},
doi = {10.1145/3015022.3015027},
abstract = {Government, research, and academic data portals publish a large amount of public data, but present tools make discovery difficult. In particular, search results do not support a user's decision whether or not to commit to a download of what might be a large data set.We describe a method for producing query-biased summaries of tabular data, which aims to support a user's download decision-or even to answer the question on the spot, with no further interaction. The method infers simple types in the data and query; automatically refines queries, where that makes sense; extracts relevant subsets of the complete table; and generates both graphical and tabular summaries of what remains. A small-scale user study suggests this both helps users identify useful results (fewer false negatives), and reduces wasted downloads (fewer false positives).},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {69–72},
numpages = {4},
keywords = {tables, data portals, information retrieval},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015029,
author = {Park, Laurence A. F.},
title = {Uncertainty in Rank-Biased Precision},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015029},
doi = {10.1145/3015022.3015029},
abstract = {Information retrieval metrics that provide uncertainty intervals when faced with unjudged documents, such as Rank-Biased Precision (RBP), provide us with an indication of the upper and lower bound of the system score. Unfortunately, the uncertainty is disregarded when examining the mean over a set of queries. In this article, we examine the distribution of the uncertainty per query and averaged over all queries, under the assumption that each unjudged document has the same probability of being relevant. We also derive equations for the mean, variance, and distribution of Mean RBP uncertainty. Finally, the impact of our assumption is assessed using simulation. We find that by removing the assumption of equal probability of relevance, we obtain a scaled form of the previously defined mean and standard deviation for the distribution of Mean RBP uncertainty.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {73–76},
numpages = {4},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015030,
author = {Wang, Sheng and Bao, Zhifeng and Culpepper, J. Shane and Sellis, Timos and Sanderson, Mark and Yadamjav, Munkh-Erdene},
title = {Interactive Trip Planning Using Activity Trajectories},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015030},
doi = {10.1145/3015022.3015030},
abstract = {We present an interactive trip planning system called @FINDER which uses an exemplar trajectory query to find the most related top-k spatial-textual trajectories. @FINDER is implemented to support various degrees of user information needs for trip planning. For users with zero knowledge about places to travel, @FINDER provides a heatmap of popular points of interest (POIs) as well as popular activities from a trajectory database. The system helps users quickly explore the places, and helps formulate an exemplar trajectory query, which specifies preferred places to go and activities of interest. Then @FINDER provides efficient query processing of the top-k related spatial-textual trajectories using a new approach to spatial-textual trajectory indexing recently developed at RMIT University. For each of the top-k results found in the form of a set of POIs and activities, @FINDER further computes the optimal route (in term of the travel time) covering all of the POIs, and returns an album to the user. Lastly, users can further interact with @FINDER by adding or deleting POIs/activities in the original exemplar query, and the system will update the results in a timely manner.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {77–80},
numpages = {4},
keywords = {Interactive Exploration, Trip Planning, Activity Trajectory Search},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015031,
author = {Yulianti, Evi and Chen, Ruey-Cheng and Scholer, Falk and Sanderson, Mark},
title = {Using Semantic and Context Features for Answer Summary Extraction},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015031},
doi = {10.1145/3015022.3015031},
abstract = {We investigate the effectiveness of using semantic and context features for extracting document summaries that are designed to contain answers for non-factoid queries. The summarization methods are compared against state-of-the-art factoid question answering and query-biased summarization techniques. The accuracy of generated answer summaries are evaluated using ROUGE as well as sentence ranking measures, and the relationship between these measures are further analyzed. The results show that semantic and context features give significant improvement to the state-of-the-art techniques.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {81–84},
numpages = {4},
keywords = {answer summaries, summarization, non-factoid queries},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

@inproceedings{10.1145/3015022.3015035,
author = {Jayasinghe, Gaya K. and Karimi, Sarvnaz and Ayre, Melanie},
title = {Evaluation of Retrieval Algorithms for Expertise Search},
year = {2016},
isbn = {9781450348652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015022.3015035},
doi = {10.1145/3015022.3015035},
abstract = {Evaluation of expertise search systems is a non-trivial task. While in a typical search engine the responses to user queries are documents, the search results for an expertise retrieval system are people. The relevancy scores indicate how knowledgeable they are on a given topic. Within an organisation, such a ranking of employees could potentially be difficult as well as controversial. We introduce an in-house capability search system built for an organisation with a diverse range of disciplines. We report on two attempts of evaluating six different ranking algorithms implemented for this system. Evaluating the system using relevance judgements produced in each of the two attempts leads to an understanding of how different methods of collecting judgements on people's expertise can lead to different effectiveness of algorithms.},
booktitle = {Proceedings of the 21st Australasian Document Computing Symposium},
pages = {85–88},
numpages = {4},
keywords = {Expertise search, Evaluation, People ranking, Capability discovery},
location = {Caulfield, VIC, Australia},
series = {ADCS '16}
}

