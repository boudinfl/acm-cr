@inproceedings{10.1145/3245145,
author = {Caragea, Cornelia},
title = {Session Details: Paper Session I},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245145},
doi = {10.1145/3245145},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
numpages = {1},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/2508497.2508498,
author = {Han, Shuguang and Jiang, Jiepu and Yue, Zhen and He, Daqing},
title = {Recommending Program Committee Candidates for Academic Conferences},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508497.2508498},
doi = {10.1145/2508497.2508498},
abstract = {Establishing a respectful and well-functional program committee (PC) consisting of capable PC members is one of the most important tasks for conference organizers. However, little research has been done for automatic recommendation of PC candidates. PC member finding is a complex task, which could be influenced by many factors such as the candidates' research interests' match with conference topics, the candidates' social closeness with PC chairs, the candidates' authoritativeness, as well as the candidates' publication history in the conference. To examine the importance of each feature, we build a dataset that consists of papers from four conferences: KDD, SIGIR, JCDL and GIS (2007-2011) and split it into the training and testing subsets based on the temporal information. The results show that: i) the publication history is the strongest indicator of being PC members; ii) recommendations based on the social closeness also produce reasonable good results; iii) recommend high authority researchers as PC members fails to predict the real PC because there are a large proportion of PC members who actually only have low authority values (we use the PageRank value in coauthor networks to simulate researcher's authority); and iv) applying simple linear combination of different features can make reasonable improvements.},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
pages = {1–6},
numpages = {6},
keywords = {social network analysis, entity recommendation, expert finding},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/2508497.2508499,
author = {Parada, Gustavo A. and Ceballos, Hector G. and Cantu, Francisco J. and Rodriguez-Aceves, Lucia},
title = {Recommending Intra-Institutional Scientific Collaboration through Coauthorship Network Visualization},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508497.2508499},
doi = {10.1145/2508497.2508499},
abstract = {For improving research productivity, quality and dissemination, we propose the development of a visual recommendation tool summing up scientific collaboration best-practices found in literature. Social Network Analysis are applied to a coauthorship network for generating a Potential Collaboration Index (PCI) based on productivity, connectivity, similarity and expertise. This work is evaluated by recommending intra-institutional collaboration in a comprehensive university. The accuracy of PCI is documented, along with suggestions and comments from 27 interviewed researchers.},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
pages = {7–12},
numpages = {6},
keywords = {network visualization, coauthorship networks, social network analysis, scientific collaboration, potential collaboration index},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/2508497.2508500,
author = {Cormode, Graham and Muthukrishnan, S. and Yan, Jinyun},
title = {First Author Advantage: Citation Labeling in Research},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508497.2508500},
doi = {10.1145/2508497.2508500},
abstract = {Citations among research papers, and the networks they form, are the primary object of study in scientometrics. The act of making a citation reflects the citer's knowledge of the related literature, and of the work being cited. We aim to gain insight into this process by studying citation keys: user-chosen labels to identify a cited work. Our main observation is that the first listed author is disproportionately represented in such labels, implying a strong mental bias towards the first author.},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
pages = {13–18},
numpages = {6},
keywords = {citation labeling, first author bias},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/3245146,
author = {Liu, Xiaozhong},
title = {Session Details: Paper Session II},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245146},
doi = {10.1145/3245146},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
numpages = {1},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/2508497.2508501,
author = {Bordea, Georgeta and Bogers, Toine and Buitelaar, Paul},
title = {Benchmarking Domain-Specific Expert Search Using Workshop Program Committees},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508497.2508501},
doi = {10.1145/2508497.2508501},
abstract = {Traditionally, relevance assessments for expert search have been gathered through self-assessment or based on the opinions of co-workers. We introduce three benchmark datasets for expert search that use conference workshops for relevance assessment. Our data sets cover entire research domains as opposed to single institutions. In addition, they provide a larger number of topic-person associations and allow a more objective and fine-grained evaluation of expertise than existing data sets do. We present and discuss baseline results for a language modelling and a topic-centric approach to expert search. We find that the topic-centric approach achieves the best results on domain-specific datasets.},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
pages = {19–24},
numpages = {6},
keywords = {expert finding, workshop dataset, expertise search},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/2508497.2508502,
author = {Abdullatif, Mohammad and Koh, Yun Sing and Dobbie, Gillian and Alam, Shafiq},
title = {Verb Selection Using Semantic Role Labeling for Citation Classification},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508497.2508502},
doi = {10.1145/2508497.2508502},
abstract = {Citation classification is the task of assigning a category to a reference or citation. The current sets of categories or classes proposed in the literature vary in size and they are based on the analysis of a small sample of citation sentences. We are developing a process to automatically generate such categories and base them on the analysis of a large corpus of papers. Part of the generation process involves selecting the main verb relevant to the reference being cited in the sentence. In this paper we present our recently developed technique that automatically identifies the relevant verb in a citation sentence. The technique uses heuristic rules, which are dependent on the results of a semantic role labeler. Four test sets were collected, and the common annotations of the test sets annotated by three people were used to assess the accuracy of the rules. Through experimentation we show that the average accuracy achieved using our technique that automatically extracts verbs from citation sentences across the four test sets is reasonable at 75%.},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
pages = {25–30},
numpages = {6},
keywords = {verb extraction, citation analysis, verb selection, NLP, citation classification},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

@inproceedings{10.1145/2508497.2508503,
author = {Guevara, Miguel and Mendoza, Marcelo},
title = {Revealing Comparative Advantages in the Backbone of Science},
year = {2013},
isbn = {9781450324144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508497.2508503},
doi = {10.1145/2508497.2508503},
abstract = {Mapping Science across countries is a challenging task in the field of Scientometrics. A number of efforts trying to cope with this task has been discussed in the state of the art, addressing this challenge by processing collections of scientific digital libraries and visualizing author-based measures (for instance, the h-index) or document-based measures (for instance, the averaged number of citations per document). A major drawback of these approaches is related to the presence of bias. The bigger the country, the higher the measure value. We explore the use of an econometric index to tackle this limitation, known as the Revealed Comparative Advantage measure (RCA). Using RCA, the diversity and ubiquity of each field of knowledge is mapped across countries. Then, a RCA-based proximity function is explored to visualize citation and h-index ubiquity. Science maps relating 27 knowledge areas and 237 countries are introduced using data crawled from Scimago that ranges from 1996 to 2011. Our results shows that the proposal is feasible and can be extended to ellaborate a global scientific production characterization.},
booktitle = {Proceedings of the 2013 Workshop on Computational Scientometrics: Theory &amp; Applications},
pages = {31–36},
numpages = {6},
keywords = {scientometrics, maps of science},
location = {San Francisco, California, USA},
series = {CompSci '13}
}

