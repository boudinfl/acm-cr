@inproceedings{10.1145/191246.191249,
author = {Al-Anzi, Fawaz S. and Spooner, David L.},
title = {Modeling Behavior, a Step towards Defining Functionally Correct Views of Complex Objects in Concurrent Engineering},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191249},
doi = {10.1145/191246.191249},
abstract = {Multidisciplinary concurrent engineering needs to model and manage different views of complex designs. Previous attempts to address the problem of creating views of complex objects in object oriented database systems focus on the structure of complex objects; little attention is paid to how complex object behavior is effected when creating views. We believe that designing functionally correct behavior for a complex object should be a major consideration when defining a view to guarantee correctness of the derived classes.In this paper, we study the problem for designing functionally correct views of complex objects in concurrent engineering. View behavioral modeling requirements are presented. A behavior model that satisfies these requirements is presented. This model is demonstrated on an example complex object that represents process management.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {1–9},
numpages = {9},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191252,
author = {Halper, Michael and Geller, James and Perl, Yehoshua and Klas, Wolfgang},
title = {Integrating a Part Relationship into an Open OODB System Using Metaclasses},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191252},
doi = {10.1145/191246.191252},
abstract = {The part-whole semantic relationship (the part relationship, for short) is an important modeling primitive in many advanced application domains such as manufacturing, design, and document processing. In this paper, we examine the problem of integrating such a construct into an OODB system. Specifically, two questions are addressed in this regard. This first is: Can a part relationship be made an intrinsic construct of an existing OODB system without having to rewrite a substantial portion of the system? The second: Can an “open” OODB system which claims to support such an integration really do so, and, more specifically, can the integration be done using a metaclass mechanism which purports to bring extensibility to the VODAK Model Language (VML)?To demonstrate that both questions can be answered “yes,” we introduce and discuss the details of a custom VML metaclass—the “HolonymicMeronymic” metaclass—which we have built. This metaclass comprises two items, an “instance” type and an “instance-instance” type. Together, the two endow the classes of a part hierarchy and their instances with structure and behavior consistent with our comprehensive part relationship model and the notions of “part” and “whole.” Complete descriptions of each of these two aspects of the metaclass are presented and their effect on schema construction and database usage is discussed.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {10–17},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191254,
author = {Rundensteiner, Elke Angelika},
title = {A Classification Algorithm for Supporting Object-Oriented Views},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191254},
doi = {10.1145/191246.191254},
abstract = {In recent years, object-oriented (OO) views have been recognized as a powerful mechanism for customizing the structural as well as behavioral aspects of interfaces to object-oriented databases (OODBs) for diverse users. In this context, classification is concerned with the integration of virtual classes derived using an OO query into one unifying schema. Existing approaches either require the user to explicitly specify the relationship between a virtual class and existing base classes, or they relate a virtual class directly with its source class(es) or with the root of the schema. In this paper, we propose a solution to this classification problem that accomplishes the following goals: (1) generate maximally informative, and thus comprehensible, schemas that explicitly model the subclass relationships between base and virtual classes, and (2) support efficient type resolution for shared property functions by supporting upwards inheritance for both base and virtual classes. Correctness and complexity of the classification algorithm are also discussed.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {18–25},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191256,
author = {B\"{o}hm, Klemens and Aberer, Karl},
title = {Storing HyTime Documents in an Object-Oriented Databases},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191256},
doi = {10.1145/191246.191256},
abstract = {An open hypermedia-document storage system has to meet requirements that are not satisfied by existing systems: it has to support non-generic hypermedia document types, i.e. document types enriched with application-specific semantics. It has to provide hypermedia-document access methods. Finally, it has to allow the exchange of hypermedia documents with other systems. On a technical level, an object-oriented database-management system, on a logical level, a well established ISO standard, namely HyTime, is used to satisfy the requirements mentioned above. By means of the example of documents incorporating hypertext structures we discuss the impact of taking such an approach on representation and processing within the database system.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {26–33},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191257,
author = {Chen, Yangjun and H\"{a}rder, Theo},
title = {An Optimal Graph Traversal Algorithm for Evaluating Linear Binary-Chain Programs},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191257},
doi = {10.1145/191246.191257},
abstract = {Grahne et al. have presented a graph algorithm for a subset of recursive queries. This method consists of two phases. In the first phase, the method transforms a linear binary-chain program into a set of equations over expressions containing predicate symbols. In the second phase, a graph is constructed from the equations and the answers are produced by traversing the relevant paths. Here we describe a new algorithm which requires less time than the algorithm of Grahne et al. The key idea of the improvement is to reduce the search space that will be traversed when a query is invoked. Further, we speed up the evaluation of cyclic data by generating most answers directly in terms of the answers already found and the associated “path information” instead of traversing the corresponding paths as usual. In this way, our algorithm achieves a linear time complexity for both cyclic and non-cyclic data.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {34–41},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191258,
author = {Marek, Robert and Rahm, Erhard},
title = {TID Hash Joins},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191258},
doi = {10.1145/191246.191258},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {42–49},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191259,
author = {Ambrosio, Ana Paula},
title = {Introducing Semantics in Conceptual Schema Reuse},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191259},
doi = {10.1145/191246.191259},
abstract = {Although standard components' manufacture and reuse is common practice in many engineering domains (e.g. electrical and mechanical engineering), this is not yet the case with respect to software development. Ironically, in such a highly “automated” domain, users still fail to find available components that match their needs faster than developing them again. The gap between what designers expect from reuse (and how it should be offered), and the actual reuse attempts remains the main barrier. This paper deals with conceptual schema construction in terms of reuse and the respective semantic requirements. It proposes a semantic retrieval mechanism based on imprecise queries for the reuse of conceptual schema components.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {50–56},
numpages = {7},
keywords = {imprecise querying, reuse, conceptual modeling, semantic retrieval},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191261,
author = {Woods, W. A. and Moser, H. D. and Frieder, O. and Kantor, Paul B.},
title = {A Case for Reconfigurable Parallel Architectures for Information Retrieval},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191261},
doi = {10.1145/191246.191261},
abstract = {As the volume of data and computational requirements of modern information retrieval systems continue to expand, it is inevitable that parallel systems will be necessary to meet these demands. In this research, we provide a conceptual model of a reconfigurable parallel information retrieval system in a multicomputer environment. We develop strategies for scheduling queries in such systems, provide simulation results for implementing these strategies under various different theoretical situations, and present an analytical model of the system behavior.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {57–63},
numpages = {7},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191260,
author = {Lee, Dik L. and Lee, Wang-chien},
title = {Using Path Information for Query Processing in Object-Oriented Database Systems},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191260},
doi = {10.1145/191246.191260},
abstract = {This paper argues that most queries in object-oriented databases require traversing from one object to another in the aggregation hierarchy. Thus, the connections between objects through object identifiers are essential to the efficiency of query processing and should be represented separately from the database. We introduce the concept of path dictionary and describe how it supports queries of different types. We evaluate the storage overhead, query and update costs of the path dictionary. Compared to the path index, the path dictionary has better overall query and update performance and lower storage overhead.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {64–71},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191262,
author = {Alhajj, Reda and Polat, Faruk},
title = {Closure Maintenance in an Object-Oriented Query Model},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191262},
doi = {10.1145/191246.191262},
abstract = {An object-algebra is presented as a formal query model for object-oriented data models. The algebra serves not only to access and manipulate the structure and behavior of objects, but it also supports the creation of new objects and the introduction of new relationships into the schema. It provides a more powerful and flexible tool than messages for effectively dealing with complex situations and meeting associative access requirements. Operands as well as the results of operations in the proposed algebra are formally characterized as a pair of sets—a set of objects capturing the states and a set of message expressions comprised of sequences of messages modeling the object behavior. The closure property is achieved in a natural way by letting the results of operations possess the same characteristics as the operands in an algebra expression. Some operators of the algebra resemble those of the relational algebra but with different syntax and semantics. Additional operators are introduced to complement them. A class is shown to posses the properties of an operand by defining a set of objects and deriving a set of message expressions for it. Furthermore, the result of an object algebra expression is shown to have the characteristics of a class whose superclass/subclass relationships with its operand class(es) can be established providing a mechanism to properly and persistently place it in the class lattice (schema).},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {72–79},
numpages = {8},
keywords = {object algebra expression, message expression, total instances, database system, object-oriented query language, closure, query model, object-oriented data model},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191263,
author = {Shrufi, Adel},
title = {Performances of Clustering Policies in Object Bases},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191263},
doi = {10.1145/191246.191263},
abstract = {In this paper, we address the problem of clustering graphs in object-oriented databases. Unlike previous studies which focused only on a workload consisting of a single operation, this study tackles the problem when the workload is a set of operations (method and queries) that occur with a certain probability. Thus, the goal is to minimize the expected cost of an operation in the workload, while maintaining a similarly low cost for each individual operation class.To this end, we present a new clustering policy based on the nearest-neighbor graph partitioning algorithm. We then demonstrate that this policy provides considerable gains when compared to a suite of well-known clustering policies proposed in the literature. Our results are based on two widely referenced object-oriented database benchmarks; namely, the Tektronix HyperModel and OO7.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {80–87},
numpages = {8},
keywords = {storage techniques, performance analysis, object-oriented database systems, graph partitioning},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191264,
author = {Chen, Weimin and Turau, Volker},
title = {An Optimized Implementation for VML Based on Pattern Matching and Dynamic Programming},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191264},
doi = {10.1145/191246.191264},
abstract = {In an object-oriented database system (OODBS), objects exist persistently and object I/O is transparent to the programmer. Therefore, some mechanism in the system must initiate I/O as the program runs. In this paper we present an approach based on pattern matching and dynamic programming that allows a program to interact efficiently with the runtime storage layer. We are interested in allowing programs to manipulate very large objects without necessarily reading them entirely. If a program touches only a small part of a large object, the problem is how to determine the part of the object needed. In this paper, we present an approach based on pattern matching and dynamic programming to resolve this problem.We discuss and solve this problem in the context of VML, a modeling language of an open object-oriented database language. The VML compiler translates VML programs into C++ programs which contain calls to the object manager. We provide a detailed description of our implementation with the hope that our approach will foster the development of object-oriented database systems based on C++.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {88–96},
numpages = {9},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191265,
author = {Karp, Peter D. and Paley, Suzanne M. and Greenberg, Ira},
title = {A Storage System for Scalable Knowledge Representation},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191265},
doi = {10.1145/191246.191265},
abstract = {Twenty years of AI research in knowledge representation has produced frame knowledge representation systems (FRSs) that incorporate a number of important advances. However, FRSs lack two important capabilities that prevent them from scaling up to realistic applications: they cannot provide high-speed access to large knowledge bases (KBs), and they do not support shared, concurrent KB access by multiple users. Our research investigates the hypothesis that one can employ an existing database management system (DBMS) as a storage subsystem for an FRS, to provide high-speed access to large, shared KBs. We describe the design and implementation of a general storage system that incrementally loads referenced frames from a DBMS, and saves modified frames back to the DBMS, for two different FRSs: LOOM and THEO. We also present experimental results showing that the performance of our prototype storage subsystem exceeds that of flat files for simulated applications that reference or update up to one third of the frames from a large LOOM KB.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {97–104},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191266,
author = {Lee, Eric and Whalen, Thom},
title = {Computer Image Retrieval by Features: Selecting the Best Facial Features for Suspect Identification Systems},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191266},
doi = {10.1145/191246.191266},
abstract = {Correct suspect identification of known offenders by witnesses deteriorates rapidly as more are examined in mugshot albums. Feature approaches, where mugshots are displayed in order of similarity to witnesses' descriptions, increase identification success by reducing this number. System performance depends on selection of system features. Four methods of selecting features are evaluated empirically: theory, random, hill-climbing algorithm, and hybrid. The theory asserts success depends on five properties of system features: informativeness, orthogonality, sufficiency, consistency, and observability. Comparing system performance on the best 10 features selected (from a pool of 90) by each method supports our contention. In four experimental tests of a system with 1000 official mugshots, over 90% of witness searches resulted in photos of target suspects retrieved in the first ten mugshots displayed for examination (using all 90 system features). On average, suspects were retrieved in the first 54, 7, 22, and 70 mugshots when using only the best 10 model features. Hybrid and hill-climbing algorithms did not improve on this performance, and performance of randomly selected sets of 10 features was poor.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {105–111},
numpages = {7},
keywords = {computer image retrieval, information retrieval, suspect identification, feature retrieval},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191267,
author = {de Ferreira Rezende, Fernando and H\"{a}rder, Theo},
title = {A Lock Method for KBMSs Using Abstraction Relationships' Semantics},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191267},
doi = {10.1145/191246.191267},
abstract = {Knowledge Base Management Systems (KBMSs) are a growing research area finding applicability in different domains. As a consequence, the demand for ever-larger knowledge bases (KBs) is growing more and more. Inside this context, knowledge sharing turns out to be a crucial point to be supported by KBMSs. In this paper, we propose a way of controlling knowledge sharing. We show how we obtain serializability of transactions providing many different locking granules, which are based on the semantics of the abstraction relationships. The main benefit of our technique is the high degree of potential concurrency, to be obtained through a logical partitioning of the KB graph and the provision of lock types used for each referenced partition. By this way, we capture more of the semantics contained in a KB graph, through an interpretation of its edges grounded in the abstraction relationships, and make feasible a full exploitation of all inherent parallelism in a knowledge representation approach.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {112–121},
numpages = {10},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191268,
author = {Chaudhri, Vinay K. and Hadzilacos, Vassos and Mylopoulos, John and Sevcik, Kenneth C.},
title = {Quantitative Evaluation of a Transaction Facility for Knowledge Base Management System},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191268},
doi = {10.1145/191246.191268},
abstract = {Large knowledge bases that are intended for applications such as CAD, corporate repositories or process control will have to be shared by multiple users. For these systems to scale up, to give acceptable performance and to exhibit consistent behavior, it is mandatory to synchronize user transactions using a concurrency control algorithm. In this paper, we examine a novel concurrency control policy called Dynamic Directed Graph (or DDG) policy that effectively exploits the rich semantic structure of a knowledge base.Our analysis is carried out in the context of a real knowledge based system application from which knowledge base structure and workload parameters are computed. These serve as a basis for studying the implementation alternatives that arise as a result of knowledge base characteristics. The implementation alternatives that we consider include selection of portions of the knowledge base structure to be exploited for concurrency control, and also the dependence of concurrency on the traversal strategy used to search through the knowledge base. We analyze the effects of various workload parameters and conclude that the DDG policy improves substantially the response time for short transactions when there is heavy data contention.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {122–131},
numpages = {10},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191269,
author = {Dattolo, Antonina and Gisolfi, Antonio},
title = {Analytical Version Control Management in a Hypertext System},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191269},
doi = {10.1145/191246.191269},
abstract = {In this paper it is shown how structural and cognitive versioning issues can be efficiently managed in a Petri nets based hypertextual model. The advantages of this formalism are enhanced by modular and structured modeling; modularity allows to focus the attention only on some modules, while giving the abstraction of the others. Each module owns metaknowledge that is useful in defining new layers and contexts.The central point of the data model is the formulation and resolution of three recurrence equations, effective in describing both the versioning and the derivation history; these equations permit to express in precise terms both the structural evolution (changes operated on specific nodes of the net) and the behavioral one (changes concerning browsing).},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {132–139},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191270,
author = {Kwon, Oh-Woog and Kim, Myoung-Cheol and Choi, Key-Sun},
title = {Query Expansion Using Domain-Adapted, Weighted Thesaurus in an Extended Boolean Model},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191270},
doi = {10.1145/191246.191270},
abstract = {In this paper, we address there important issues with query expansion using a thesaurus; how to give weights to the terms in expanded queries, how to select additional search terms in the thesaurus, and how to enrich the terms in the manual thesaurus (namely, thesaurus reconstruction). To weight the terms in expanded queries, we construct the weighted thesaurus that has a similarity value between the terms in the thesaurus, using statistical co-occurrence in a corpus. To enrich the terms in the manual thesaurus, domain dependent terms which occur in a corpus are inserted into the weighted thesaurus using the co-occurrence information. In this paper, the reconstructed thesaurus with weights is defined as a domain-adapted, weighted thesaurus. Then we explain query expansion using the domain-adapted, weighted thesaurus in an extended Boolean retrieval model. To select additional search terms during query expansion, our model uses semi-automatic query expansion and a restriction method. In the experiments, our system had almost twice the recall of the boolean retrieval system not using the thesaurus or the query expansion retrieval system using the original thesaurus. And also, the precision of our system was almost the same precision as the other systems.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {140–146},
numpages = {7},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191271,
author = {B\"{o}hm, Klemens and M\'{u}ller, Adrian and Neuhold, Erich},
title = {Structured Document Handling—a Case for Integrating Databases and Information Retrieval},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191271},
doi = {10.1145/191246.191271},
abstract = {In this paper we discuss the structured multimedia documents that will be, or already are, to some degree the communication backbone of the so-called superhighways. It will be shown that storage and retrieval of such documents will best be handled by an integration of database and information retrieval technologies. We assume documents to be structured with the help of standards like SGML/HyTime and represented by the multitude of formats currently used for multimedia data.Starting with an approach based on object-oriented database technology we extend both their functionality on the cost models for query evaluation on one side with multimedia features and on the other with logic-based models of information retrieval to truly combine structure and content information about the documents in question.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {147–154},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191272,
author = {Lamirel, Jean-Charles and Crehange, Marion},
title = {Application of a Symbolic-Connectionist Approach for the Design of a Highly Interactive Documentary Database Interrogation System with on-Line Learning Capabilities},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191272},
doi = {10.1145/191246.191272},
abstract = {The NOMAD system is a documentary database interrogration system based on a symbolico-connectionist approach.NOMAD makes use of the synthesis capabilities and flexibility inherent in this type of approach to increase its processing power as compared as compared to existing systems while proposing new operating modes directly accessible to a large number of users:•NOMAD manages multiple synthetic type views on its documentary contents in the form of neural topographies acting as case-memories as well as elaborated thematic browsing tools.•NOMAD manages a session memory based on the neural model of the novelty detector with the following three functions: cumulative recording of user need, managing user contradictions and proposing new orientations.•NOMAD also has extended learning capabilities, enabling it to improve its performance in the long term.In the introduction of this article, we justify the modelling choices made for NOMAD. The system will then be described in detailed, stressing the new possibilities regarding help in query formulation and improvement in retrieval performance. The evaluation campaign and the numerous evolution perspectives provided by the model are described in the final section.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {155–163},
numpages = {9},
keywords = {case-based reasoning, symbolico-connectionist model, hypertext generation, unsupervised learning, novelty detection, document classification, thematic browsing, information retrieval},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191273,
author = {Syu, Inien and Lang, S. D.},
title = {A Competition-Based Connectionist Model for Information Retrieval Using a Merged Thesaurus},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191273},
doi = {10.1145/191246.191273},
abstract = {This paper investigates a network-based information retrieval model using diagnostic inferencing techniques. A basic inference network in information retrieval consists of two component networks: the document component and the query component. In our approach, there is a layer of nodes corresponding to the documents, and a layer of nodes corresponding to the index terms extracted from the document set, with links connecting documents to the related index terms 1. A thesaurus is used to provide concept categories; these categories are represented by another layer of nodes, with links connecting the index terms and the related categories 2. The query component uses a symmetric structure. Each query causes markings of category nodes, hence markings of the related index term nodes, in the document component of the network. In our previous work, we adapted a competition-based connectionist model for diagnostic problem solving to information retrieval. In this model, documents are treated as “disorders” and user information needs, represented by the marked index term nodes, as “manifestations”. A competitive activation mechanism is then used which converges to a set of disorders that best explain the given manifestations. Our experiments showed that the retrieval performance of this model is comparable to or better than that of various information retrieval models reported in the literature. In this paper, we report further enhancements of the model by using a merged thesaurus.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {164–170},
numpages = {7},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191274,
author = {Chu, S. Iris and Winslett, Marianne},
title = {Minipage Locking Support for Object-Oriented Page-Server DBMS},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191274},
doi = {10.1145/191246.191274},
abstract = {Many object-oriented database systems are implemented using a page-server architecture for its performance advantages. Since the applications envisioned for object-oriented DBMSes typically spend a great deal of time processing data already in memory, fast in-memory access is very important. A page-server architecture will permit an implementation where most routine reference following (i.e., where the referenced data is in memory and appropriately locked) is handled by virtual memory hardware to eliminate expensive software overhead. One of the major drawbacks of this approach is that locking and authorization must be handled on a per-page basis, causing unacceptable low concurrency for high-contention data pages and difficulties in supporting fine-grained authorization. With hardware support on the client side for locks on minipages (subdivisions of a page), however, it is possible to have good improvements in concurrency for high-contention areas of the database, along with the ability to do fine-grained authorization. This paper presents a callback-read locking scheme that makes use of hardware-assisted locking of minipages and compares its performance with one that uses page protection under four different workloads. Minipages are already available in several commonly used platforms, but only at the internal levels of the operating system. We conclude that minipages improve performance significantly in high-contention workloads, with minimal performance impact under low-contention workloads, and that minipage facilities should be made visible to client DBMS code. We also discuss the application of our locking algorithms to page servers that supporting object-level locking.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {171–178},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191275,
author = {Pal, Shankar and Lanka, Sitaram},
title = {Isolation of Transaction Aborts in Object-Oriented Database Systems},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191275},
doi = {10.1145/191246.191275},
abstract = {We address the problem of recovery in object-oriented data-bases from considerations of the semantics of committed transactions and the efficiency of recovery procedures. The recovery strategy used is update-in-place. We show that efficient recovery procedures should allow transactions to abort independently of one another by executing inverse operations. We refer to these requirements collectively as the recovery isolation property. We present a formal definition of recovery isolation and prove that schedules possessing this property do not suffer from rollback dependencies. Recovery isolation is useful in constructing concurrency control protocols that go beyond commutativity, and in parallel and high performance database systems. We define the notion of strict schedules for object-oriented databases as an extension of the analogous definition for read and write operations. We show that strict schedules possess the recovery isolation property.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {179–186},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191276,
author = {Soparkar, Nandit and Levy, Eliezer and Korth, Henry F. and Silberschatz, Avi},
title = {Adaptive Commitment for Distributed Real-Time Transactions},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191276},
doi = {10.1145/191246.191276},
abstract = {Distributed real-time transaction systems are useful for both real-time and high-performance database applications. Standard transaction management approaches that use the two-phase commit protocol suffer from its high costs and blocking behavior which is problematic in real-time computing environments. Our approach in this paper is to identify ways in which a commit protocol can be made adaptive in the sense that under situations that demand it, such as a transient local overload, the system can dynamically change to a different commitment strategy. The decision to do so can be taken autonomously at any site. The different commitment strategies exploit a trade-off between the cost of commitment and the obtained degree of atomicity. Our protocols are based on optimistic  commitment strategies, and they rely on local compensatory actions to recover from non-atomic executions. We provide the necessary framework to study the logical and temporal correctness criteria, and we describe examples to illustrate the use of our strategies.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {187–194},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191278,
author = {Pu, Calton and Tsang, Miu K. and Wu, Kun-Lung and Yu, Philip S.},
title = {Multiversion Divergence Control of Time Fuzziness},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191278},
doi = {10.1145/191246.191278},
abstract = {Epsilon Serializability (ESR) has been proposed to manage and control inconsistency in extending the classic transaction processing. ESR increases system concurrency by tolerating a bounded amount of inconsistency. In this paper, we present multiversion divergence control (mvDC) algorithms that support ESR with not only value but also time fuzziness in multiversion databases. Unlike value fuzziness, accumulating time fuzziness is semantically different. A simple summation of the length of two time intervals may either underestimate the total time fuzziness, resulting in incorrect execution, or overestimate the total time fuzziness, unnecessarily degrading the effectiveness of mvESR. We present a new operation, called TimeUnion, to accurately accumulate the total time fuzziness. Because of the accurate control of time and value fuzziness by the mvDC algorithm, mvESR is very suitable for the use of multiversion databases for real-time applications that may tolerate a limited degree of data inconsistency but prefer more data recency.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {195–202},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191280,
author = {Jain, Neel K.},
title = {Group Formation Mechanisms for Transactions in Isis},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191280},
doi = {10.1145/191246.191280},
abstract = {Distributed toolkits like Isis provide means of replicating data but not means for making it persistent. This makes the use of transactions desirable, even in non-database applications. Using Isis can alleviate the programming cost of distributed transaction processing the multi-phase commit protocols. Using the Isis transaction tool, however, imposes additional cost, and we examine the effect of group formation strategies on the overhead. The paper presents three different group formation mechanisms in Isis and compares the costs associated with them.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {203–210},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191281,
author = {Helal, Abdelsalam and Ku, Tung-Hui and Fortner, Jud},
title = {Quasi-Dynamic Two-Phase Locking},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191281},
doi = {10.1145/191246.191281},
abstract = {Among the plethora of concurrency control algorithms that have been proposed and analyzed, two-phase locking (2PL) has been adapted as the industry de facto standard concurrency control. In accord, current research in concurrency control is focusing on enhancing the scalability of 2PL performance in highly concurrent and contentious environments. This is especially needed in future on-line transaction processing systems, where thousand Transaction Per Second performance will be required.Static locking (SL) and dynamic locking (DL) are two famous adaptations of 2PL that are used under different degrees of data contention. In this paper, we offer our observation that 2PL is indeed a family of methods, of which SL and DL are extreme case members. Further, we argue for and verify the existence of other 2PL member methods that, under variable conditions, outperform SL and DL. We propose two novel schemes which we categorize as quasi-dynamic two-phase locking on account of their behavior in comparison with dynamic/static two-phase locking. We present a simulation study of the performance of the proposed schemes and their comparison to dynamic and static locking methods.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {211–218},
numpages = {8},
keywords = {data contention, two-phase locking, pre-declaration, resource contention, adaptability},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191283,
author = {Borgida, Alex},
title = {On the Relationship between Description Logic and Predicate Logic Queries},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191283},
doi = {10.1145/191246.191283},
abstract = {Description languages form the basis of several object-centered knowledge base management systems developed in recent years, including ones in industrial use. Originally used for conceptual modeling (to define views), DLs are seeing increased use as query languages for retrieving information. This paper, aimed at a general audience that includes database researchers, considers the relationship between the expressive power of DLs and that of query languages based on Predicate Calculus.We show that all descriptions built using constructors currently considered in the literature can be expressed as formulae of the First Order Predicate Calculus (FOPC) with at most three variable symbols, though we have to allow numeric quantifiers and infinitary disjunction in order to handle some special constructors. Conversely, we show that all first-order queries (formulae with one free variable) built up from unary and binary predicates using at most three variables can be expressed as descriptions. We conclude by exhibiting queries that cannot be expressed as DL concepts, and reflecting briefly on consequences.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {219–225},
numpages = {7},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191285,
author = {Han, Jiawei and Liu, Ling and Xie, Zhaohui},
title = {LogicBase: A Deductive Database System Prototype},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191285},
doi = {10.1145/191246.191285},
abstract = {A deductive database system prototype, LogicBase, has been developed, with an emphasis on efficient compilation and query evaluation of application-oriented recursions in deductive databases. The system identifies different classes of recursions and compiles recursions into chain or psuedo-chain forms when appropriate. Queries posed to the compiled recursions are analyzed systematically with efficient evaluation plans generated and executed, mainly based on a chained-based query evaluation method. The system has been tested using sophisticated recursions and queries with satisfactory performance. This paper introduces the general design principles and implementation techniques of the system and discusses its strength and limitations.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {226–233},
numpages = {8},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

@inproceedings{10.1145/191246.191287,
author = {Liu, Hong-Chen and Ramamohanarao, K.},
title = {Algebraic Equivalences among Nested Relational Expressions},
year = {1994},
isbn = {0897916743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/191246.191287},
doi = {10.1145/191246.191287},
abstract = {Algebraic optimization is both theoretically and practically important for query processing in (nested) relational databases. In this paper, we consider this issue and investigate some algebraic properties concerning the nested relational operators. We also outline a heuristic optimization algorithm for nested relational expressions by adopting algebraic transformation rules developed in this paper and previous related work.},
booktitle = {Proceedings of the Third International Conference on Information and Knowledge Management},
pages = {234–243},
numpages = {10},
location = {Gaithersburg, Maryland, USA},
series = {CIKM '94}
}

