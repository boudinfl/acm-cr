@inproceedings{10.1145/1851600.1851605,
author = {Buttussi, Fabio and Chittaro, Luca and Carchietti, Elio and Coppo, Marco},
title = {Using Mobile Devices to Support Communication between Emergency Medical Responders and Deaf People},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851605},
doi = {10.1145/1851600.1851605},
abstract = {Fast and effective communication is crucial during medical emergencies, but patients' disabilities can make it a challenging task for emergency medical responders. This paper proposes a mobile system to deal with the communication barrier between medical responders and deaf patients. The system allows medical responders to quickly browse a collection of emergency-related sentences, and show videos of the corresponding translations in sign language to the deaf patients. The design process involved experts in emergency medicine as well as experts from the deaf community. The evaluation carried out on ten emergency medical responders and ten deaf subjects showed that the system is useful to support communication with deaf people during medical emergencies.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {7–16},
numpages = {10},
keywords = {sign languages, deaf people, mobile devices, computer-mediated communication, first responders, medical emergencies},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851606,
author = {Su, Jing and Rosenzweig, Alyssa and Goel, Ashvin and de Lara, Eyal and Truong, Khai N.},
title = {Timbremap: Enabling the Visually-Impaired to Use Maps on Touch-Enabled Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851606},
doi = {10.1145/1851600.1851606},
abstract = {Mapping applications on mobile devices have gained widespread popularity as a means for enhancing user mobility and ability to explore new locations and venues. Visually impaired users currently rely on computer text-to-speech or human-spoken descriptions of maps and indoor spaces. Unfortunately, speech-based descriptions are limited in their ability to succinctly convey complex layouts or spacial positioning.This paper presents Timbremap, a sonification interface enabling visually impaired users to explore complex indoor layouts using off-the-shelf touch-screen mobile devices. This is achieved using audio feedback to guide the user's finger on the device's touch interface to convey geometry. Our user-study evaluation shows Timbremap is effective in conveying non-trivial geometry and enabling visually impaired users to explore indoor layouts.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {17–26},
numpages = {10},
keywords = {sonification, user interface, assistive, touch device},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851607,
author = {Chittaro, Luca and Marassi, Alessandro},
title = {Supporting Blind Users in Selecting from Very Long Lists of Items on Mobile Phones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851607},
doi = {10.1145/1851600.1851607},
abstract = {Searching for an item in a long ordered list that does not fit the screen is a frequent task when using mobile devices. This paper explores four different interfaces to support blind users in carrying out this task. Two of them are based on the idea of tree-augmentation of a list, proposed by Furnas [3], and differ in their depth versus breadth ratio. The other two interfaces adopt the more traditional technique of list scrolling based respectively on standard multitap and T9 keyboard entry. The paper reports also on the results of a pilot study of the four interfaces conducted on two blind users.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {27–30},
numpages = {4},
keywords = {blind users, mobile devices, long lists, menu selection},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851608,
author = {Guerreiro, Tiago Jo\~{a}o Vieira and Nicolau, Hugo and Jorge, Joaquim and Gon\c{c}alves, Daniel},
title = {Assessing Mobile Touch Interfaces for Tetraplegics},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851608},
doi = {10.1145/1851600.1851608},
abstract = {Mobile touch-screen interfaces and tetraplegic people have a controversial connection. While users with residual capacities in their upper extremities could benefit immensely from a device which does not require strength to operate, the precision needed to effectively select a target bars these people access to countless communication, leisure and productivity opportunities. Insightful projects attempted to bridge this gap via either special hardware or particular interface tweaks. Still, we need further insight into the challenges and the frontiers separating failure from success for such applications to take hold. This paper discusses an evaluation conducted with 15 tetraplegic people to learn the limits to their performance within a comprehensive set of interaction methods. We then present the results concerning a particular interaction technique: Tapping. Results show that performance varies across different areas of the screen whose distribution changes with target size.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {31–34},
numpages = {4},
keywords = {evaluation, tapping, mobile device, touch-screen, interaction, tetraplegic},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851610,
author = {Juhlin, Oskar and Engstr\"{o}m, Arvid and Reponen, Erika},
title = {Mobile Broadcasting: The Whats and Hows of Live Video as a Social Medium},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851610},
doi = {10.1145/1851600.1851610},
abstract = {A new type of social medium, which allows users to broadcast live video from mobile devices to websites on the internet, is becoming increasingly popular. We provide a qualitative content analysis of a sample from four such services. The analysis specifically focuses on the topics presented, camerawork, and coordination, in order to investigate the possibilities and barriers to wider adoption of this new social medium. Although the services are growing in numbers of users, the study reveals an immature application area. People struggle to find interesting topics to broadcast and to manage the camera in a way that presents them in an appealing form. But there are also examples of topics such as artistic performances and tours, as well as ways to conduct live transitions and coordination, that point to a more medium-specific way of using these services. The results indicate that providing the opportunity to broadcast live video is not enough, and that there is now a need to design for amateurs' appropriation of camera handling techniques.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {35–44},
numpages = {10},
keywords = {social media, mobile, video, live broadcast, webcast, content analysis},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851611,
author = {Cui, Yanqing and Honkala, Mikko and Pihkala, Kari and Kinnunen, Kimmo and Grassel, Guido},
title = {Linked Internet UI: A Mobile User Interface Optimized for Social Networking},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851611},
doi = {10.1145/1851600.1851611},
abstract = {This paper presents the Linked Internet UI Concept, or LinkedUI for short, as a holistic user interface concept to facilitate social interaction on mobile devices. It aggregates social events from social networking services and communication channels and uses hypertext navigation for presentation and interaction. We describe the concept design principles, highlights of the design, and the prototype implementation. We conducted a user study to compare LinkedUI with the benchmark of web applications running in a web browser to follow their friends' activities in Twitter and Flickr and two other optional services on mobile devices. The study results reveal that the users performed tasks faster in LinkedUI and also liked it more than the benchmark. These findings support the design principles of LinkedUI in facilitating social interaction via mobile devices.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {45–54},
numpages = {10},
keywords = {social networking services, LinkedUI, web, browser, hypertext navigation, mobile, service aggregation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851612,
author = {Wagner, Daniel and Lopez, Mariana and Doria, Andre and Pavlyshak, Iryna and Kostakos, Vassilis and Oakley, Ian and Spiliotopoulos, Tasos},
title = {Hide and Seek: Location Sharing Practices with Social Media},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851612},
doi = {10.1145/1851600.1851612},
abstract = {This paper presents a multi-pronged study of users' location-sharing practices in the context of online social networks. The contribution of this study is two-fold: first it presents a series of insights relating to location-sharing practices, and second it highlights the use of third-person scenarios as a useful method for eliciting privacy concerns and potentially educating users.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {55–58},
numpages = {4},
keywords = {privacy, social network, location sharing},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851613,
author = {Lang, Xueming and Oreglia, Elisa and Thomas, Suzanne},
title = {Social Practices and Mobile Phone Use of Young Migrant Workers},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851613},
doi = {10.1145/1851600.1851613},
abstract = {To explore opportunities for technology adoption in emerging markets, we conducted ethnographic studies to understand the social practices and technology use of young migrant workers in China. In total twenty-six young migrant workers, aged 19-28, were interviewed and/or shadowed in three cities (Beijing, Hangzhou, and Xi'an). We found that social practices play a significant role in the life of the research participants, who live in stressful and "unfriendly" urban environments and have a lower social status than urban residents. Moreover, we found that these social practices act as a primary driver for mobile phones adoption and use. Personal mobile phones were quickly adopted and frequently used to initiate, maintain and enhance social connections, as well as the quality of social practices. Based on the research findings, we discuss several design directions for making mobile phones play a greater role in social practices.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {59–62},
numpages = {4},
keywords = {young migrant workers, mobile phone, social practices, emerging markets},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851615,
author = {Kratz, Sven and Brodien, Ivo and Rohs, Michael},
title = {Semi-Automatic Zooming for Mobile Map Navigation},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851615},
doi = {10.1145/1851600.1851615},
abstract = {In this paper we present a novel interface for mobile map navigation based on Semi-Automatic Zooming (SAZ). SAZ gives the user the ability to manually control the zoom level of an SDAZ interface, while retaining the automatic zooming characteristics of that interface at times when the user is not explicitly controlling the zoom level. In a user study conducted using a realistic mobile map with a wide scale space, we compare SAZ with existing map interface techniques, multi-touch and Speed-Dependent Automatic Zooming (SDAZ). We extend a dynamic state-space model for Speed-Dependent Automatic Zooming (SDAZ) to accept 2D tilt input for scroll rate and zoom level control and implement a dynamically zoomable map view with access to high-resolution map material for use in our study. The study reveals that SAZ performs significantly better than SDAZ and that SAZ is comparable in performance and usability to a standard multi-touch map interface. Furthermore, the study shows that SAZ could serve as an alternative to multi-touch as input technique for mobile map interfaces.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {63–72},
numpages = {10},
keywords = {SDAZ, mobile devices, tilt input, zooming-scrolling ui, automatic zoom, dynamics},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851616,
author = {Brush, A.J. Bernheim and Karlson, Amy K. and Scott, James and Sarin, Raman and Jacobs, Andy and Bond, Barry and Murillo, Oscar and Hunt, Galen and Sinclair, Mike and Hammil, Kerry and Levi, Steven},
title = {User Experiences with Activity-Based Navigation on Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851616},
doi = {10.1145/1851600.1851616},
abstract = {We introduce activity-based navigation, which uses human activities derived from sensor data to help people navigate, in particular to retrace a "trail" previously taken by that person or another person. Such trails may include step counts, walking up/down stairs or taking elevators, compass directions, and photos taken along a user's path, in addition to absolute positioning (GPS and maps) when available. To explore the user experience of activity-based navigation, we built Greenfield, a mobile device interface for finding a car. We conducted a ten participant user study comparing users' ability to find cars across three different presentations of activity-based information as well as verbal instructions. Our results show that activity-based navigation can be used for car finding and suggest its promise more generally for supporting navigation tasks. We present lessons for future activity-based navigation interfaces, and motivate further work in this space, particularly in the area of robust activity inference.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {73–82},
numpages = {10},
keywords = {mobile applications, sensor fusion, navigation, activity inference, mobile user interfaces},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851617,
author = {Schmid, Falko and Kuntzsch, Colin and Winter, Stephan and Kazerani, Aisan and Preisig, Benjamin},
title = {Situated Local and Global Orientation in Mobile You-Are-Here Maps},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851617},
doi = {10.1145/1851600.1851617},
abstract = {This paper presents a novel solution to the focus-and-context problem of mobile maps provided for local and global orientation. Our solution is inspired by the design principles of static You-Are-Here maps and realizes principles of human spatial cognition to enable efficient communication of location information. We further propose selective interaction with the presented information to improve the speed and accuracy of interpretation of the geographic information. Tests show strong evidence for the cognitive and interaction efficiency of the resulting maps, as users were faster and more accurate than with conventional mobile maps.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {83–92},
numpages = {10},
keywords = {you-are-here maps, detail-in-context, location-based services, spatial cognition, localization, spatial awareness, focus and context},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851619,
author = {Schildbach, Bastian and Rukzio, Enrico},
title = {Investigating Selection and Reading Performance on a Mobile Phone While Walking},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851619},
doi = {10.1145/1851600.1851619},
abstract = {More and more people interact with their mobile phone while walking. The presented research analyzes; firstly, the negative effect of walking when considering reading and target selection tasks, such as weaker performance and higher workload. Here, we focused on one-handed interaction with a touch screen whereby the thumb is used as the input device. Secondly, we analyze how these negative effects can be compensated by increasing the text size and the size of the targets to select on the mobile phone. A comparative user study was conducted with 16 participants who performed target acquisition and reading tasks while standing and walking. The results show that whilst performance decreases, cognitive load increases significantly when reading and selecting targets when walking. Furthermore, the results show that the negative effect regarding target selection can be compensated by increasing the target size, but the text reading task did not yield better performance results for a larger text size due to the increased demand for scrolling. These results can be used to inform future designs of mobile user interfaces which might provide a dedicated walking mode.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {93–102},
numpages = {10},
keywords = {reading, mobile interaction, walking, target selection},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851620,
author = {Fischer, Joel E. and Yee, Nick and Bellotti, Victoria and Good, Nathan and Benford, Steve and Greenhalgh, Chris},
title = {Effects of Content and Time of Delivery on Receptivity to Mobile Interruptions},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851620},
doi = {10.1145/1851600.1851620},
abstract = {In this paper we investigate effects of the content of interruptions and of the time of interruption delivery on mobile phones. We review related work and report on a naturalistic quasi-experiment using experience-sampling that showed that the receptivity to an interruption is influenced by its content rather than by its time of delivery in the employed modality of delivery - SMS. We also examined the underlying variables that increase the perceived quality of content and found that the factors interest, entertainment, relevance and actionability influence people's receptivity significantly. Our findings inform system design that seeks to provide context-sensitive information or to predict interruptibility and suggest the consideration of receptivity as an extension to the way we think and reason about interruptibility.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {103–112},
numpages = {10},
keywords = {mobile, content, push vs. pull, experience-sampling, receptivity, interruption, empirical study, sms, context, quasi-experiment},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851621,
author = {Weinberg, Garrett and Harsham, Bret and Forlines, Clifton and Medenica, Zeljko},
title = {Contextual Push-to-Talk: Shortening Voice Dialogs to Improve Driving Performance},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851621},
doi = {10.1145/1851600.1851621},
abstract = {We present a driving simulator-based evaluation of a new technique for simplifying in-vehicle device interactions and thereby improving driver safety. We show that the use of multiple, contextually linked push-to-talk buttons (Multi-PTT) shortens voice dialog duration versus the use of a conventional, single push-to-talk button (Single-PTT). This benefit comes without detriment to driving performance or visual attention to the forward roadway. Test subjects also preferred the Multi-PTT approach over the conventional approach, and reported that it imposed a lower cognitive workload.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {113–122},
numpages = {10},
keywords = {voice dialogs, driving simulation, speech recognition, push-to-talk, multimodality, listen button},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851623,
author = {Hardy, Robert and Rukzio, Enrico and Holleis, Paul and Wagner, Matthias},
title = {Mobile Interaction with Static and Dynamic NFC-Based Displays},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851623},
doi = {10.1145/1851600.1851623},
abstract = {This paper reports on a development framework, two prototypes, and a comparative study in the area of multi-tag Near-Field Communication (NFC) interaction. By combining NFC with static and dynamic displays, such as posters and projections, services are made more visible and allow users to interact with them easily by interacting directly with the display with their phone. In this paper, we explore such interactions, in particular, the combination of the phone display and large NFC displays. We also compare static displays and dynamic displays, and present a list of deciding factors for a particular deployment situation. We discuss one prototype for each display type and developed a corresponding framework which can be used to accelerate the development of such prototypes whilst supporting a high level of versatility. The findings of a controlled comparative study indicate, among other things, that all participants preferred the dynamic display, although the static display has advantages, e.g. with respect to privacy and portability.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {123–132},
numpages = {10},
keywords = {static display, near field communication (NFC), mobile interaction, dynamic display},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851624,
author = {Broll, Gregor and Hausen, Doris},
title = {Mobile and Physical User Interfaces for NFC-Based Mobile Interaction with Multiple Tags},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851624},
doi = {10.1145/1851600.1851624},
abstract = {Near Field Communication (NFC) is an emerging technology for mobile interaction with everyday objects and associated digital resources. Apart from simple interactions with single tags, NFC has the potential for more elaborate interactions with physical objects that comprise multiple tags and serve as physical user interfaces (UI). This paper investigates the design of mobile and physical UIs for the interaction with multiple NFC-tags. It focuses on three basic interactions that qualify for multi-tag interaction - the navigation between parts of an application, the selection of items and the combination of items. Two user studies compare different configurations of mobile and physical UIs for these interactions in order to evaluate the allocation of application features and UI elements to mobile devices and tagged objects. The results advocate the continuous interaction on the latter, instead of splitting interactions between mobile and physical UIs.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {133–142},
numpages = {10},
keywords = {evaluation, usability, near field communication, single-tag interaction, multi-tag interaction, physical user interface, NFC},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851625,
author = {McAdam, Christopher and Pinkerton, Craig and Brewster, Stephen A.},
title = {Novel Interfaces for Digital Cameras and Camera Phones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851625},
doi = {10.1145/1851600.1851625},
abstract = {Camera phones are now very common but there are some usability issues that affect their use. These can occur because the users look through the LCD to frame the image and can often miss the icons displayed around the edges that present important information about the status of the camera. This may lead to shots being missed or poorly exposed. Most camera phones do not take full advantage of the features of the underlying phone platform to enhance their interfaces. We created a camera application for the Nokia N95 that featured novel interface elements and made use of the features of the platform to provide a rich variety of information in more usable forms, such as: sonifications of the luminance histogram to ensure better exposure before a picture is taken; phone orientation to give a level indicator to ensure the camera is straight; measuring phone movement to ensure the phone is being held steady; and the detection of image motion to support panning We also present a scenario for how these features could be used in conjunction with each other during the photo taking process.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {143–152},
numpages = {10},
keywords = {panning, sonification, camera phone, tactile, luminance histogram, orientation, motion},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851626,
author = {Ketabdar, Hamed and Roshandel, Mehran and Y\"{u}ksel, Kamer Ali},
title = {Towards Using Embedded Magnetic Field Sensor for around Mobile Device 3D Interaction},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851626},
doi = {10.1145/1851600.1851626},
abstract = {We present a new technique based on using embedded compass (magnetic) sensor for efficient use of 3D space around a mobile device for interaction with the device. Around Device Interaction (ADI) enables extending interaction space of small mobile and tangible devices beyond their physical boundary. Our proposed method is based on using compass (magnetic field) sensor integrated in new mobile devices (e.g. iPhone 3GS, G1/2 Android). In this method, a properly shaped permanent magnet (e.g. a rod, pen or a ring) is used for interaction. The user makes coarse gestures in 3D space around the device using the magnet. Movement of the magnet affects magnetic field sensed by the compass sensor integrated in the device. The temporal pattern of the gesture is then used as a basis for sending different interaction commands to the mobile device. The proposed method does not impose changes in hardware and physical specifications of the mobile device, and unlike optical methods is not limited by occlusion problems. Therefore, it allows for efficient use of 3D space around device, including back of device. Zooming, turning pages, accepting/rejecting calls, clicking items, controlling a music player, and mobile game interaction are some example use cases. Initial evaluation of our algorithm using a prototype application developed for iPhone shows convincing gesture classification results.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {153–156},
numpages = {4},
keywords = {embedded compass (magnetic) sensor, around device 3D interaction, movement-based gestures, properly shaped magnet, mobile devices},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851627,
author = {Kawsar, Fahim and Rukzio, Enrico and Kortuem, Gerd},
title = {An Explorative Comparison of Magic Lens and Personal Projection for Interacting with Smart Objects},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851627},
doi = {10.1145/1851600.1851627},
abstract = {One shortcoming of self-describing smart objects augmented with digital resources is the limitation of output modalities due to their long established physical appearances. To overcome this drawback intangible representations e.g., sound, video projection etc. are usually coupled with the tangible representations of smart objects that enable access and interaction with their value added features. In this paper, we explore two mobile interaction techniques that associate such intangible representation to smart objects using a pico projector augmented camera phone. The first technique utilizes a Magic Lens metaphor applying mobile augmented reality (contextual information is overlaid while looking at a smart object through camera) to uncover and interact with smart objects. The second technique, Personal Projection follows similar mechanisms in discovery and interaction, except information is projected onto the nearest surface. We report the implementation of these two techniques and a comparative qualitative study with three prototype smart object applications. The findings give us deeper insights on the positive and negative aspects of these two techniques and open up a range of stimulating research issues that we discuss in the paper.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {157–160},
numpages = {4},
keywords = {smart object, projected interface, mobile interaction},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851629,
author = {Mulloni, Alessandro and D\"{u}nser, Andreas and Schmalstieg, Dieter},
title = {Zooming Interfaces for Augmented Reality Browsers},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851629},
doi = {10.1145/1851600.1851629},
abstract = {Augmented Reality combines real world and virtual information in interactive visualizations. Since phones started integrating GPS, compass and accelerometer, several Augmented Reality browsers for phones have hit the market. These are applications that access large amounts of geo-referenced information from online sources and present it at corresponding physical locations, superimposed onto a live video stream. However, Augmented Reality is constrained by the camera's field of view and restricted to first- person views, limiting the amount of overview that users can gain. We present two zooming interfaces that compensate for these constraints by enabling users to smoothly zoom between the Augmented Reality view and (1) an egocentric panoramic view of 360°, and (2) an exocentric top-down view. We present the results from two studies that show how in most search tasks our zooming interfaces are faster and require less panning than an overlay- based tool, scaling better as the amount of information grows.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {161–170},
numpages = {10},
keywords = {zooming interfaces, mobile augmented reality},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851630,
author = {Scott, James and Izadi, Shahram and Rezai, Leila Sadat and Ruszkowski, Dominika and Bi, Xiaojun and Balakrishnan, Ravin},
title = {RearType: Text Entry Using Keys on the Back of a Device},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851630},
doi = {10.1145/1851600.1851630},
abstract = {RearType is a text input system for mobile devices such as Tablet PCs, using normal keyboard keys but on the reverse side of the device. The standard QWERTY layout is split and rotated so that hands gripping the device from either side have the usual keys under the fingers. This frees up the front of the device, maximizing the use of the display for visual output, eliminating the need for an onscreen keyboard and the resulting hand occlusion, and providing tactile and multi-finger text entry - with potential for knowledge transfer from QWERTY. Using a prototype implementation which includes software visualization of the keys to assist with learning, we conducted a study to explore the initial learning curve for RearType. With one hour's training, RearType typing speed was an average 15 WPM, and was not statistically different to a touchscreen keyboard.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {171–180},
numpages = {10},
keywords = {tablet pc, text entry, keyboard, mobile devices},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851631,
author = {Wilson, Graham and Stewart, Craig and Brewster, Stephen A.},
title = {Pressure-Based Menu Selection for Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851631},
doi = {10.1145/1851600.1851631},
abstract = {Despite many successes in desktop applications, little work has looked at the use of pressure input on mobile devices and the different issues associated with mobile interactions e.g. non-visual feedback. This study examined pressure input on a mobile device using a single Force Sensing Resistor (FSR) with linearised output as a means of target selection within a menu, where target menu items varied in size and location along the z-axis. Comparing visual and audio feedback, results showed that, overall, eyes-free pressure interaction reached a mean level of 74% accuracy. With visual feedback mean accuracy reached 85%. Participants could accurately distinguish up to 10 pressure levels when given adequate feedback indicating a high level of control.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {181–190},
numpages = {10},
keywords = {mobile interaction, pressure input, non-visual feedback},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851632,
author = {Henze, Niels and Boll, Susanne},
title = {Evaluation of an Off-Screen Visualization for Magic Lens and Dynamic Peephole Interfaces},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851632},
doi = {10.1145/1851600.1851632},
abstract = {Map navigation is often limited due to the inherent size restrictions of mobile devices' displays. Using a magic lens to interact with physical objects has been proposed as a way to reduce this limitation. The dynamic peephole interface is an alternative approach where a device is moved across a virtual surface. In this paper we study the effect of an additional visualization of objects beyond the screen on magic lens and dynamic peephole interfaces. In the conducted experiment the participants had to select points of interest shown on a map. We show that an additional visualization of off-screen objects decreases the task completion time and reduces the perceived task load. The advantage of an off-screen visualization is much higher than the difference between using a magic lens instead of a dynamic peephole interface.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {191–194},
numpages = {4},
keywords = {augmented reality, dynamic peephole, map navigation, mobile interaction, magic lens},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851633,
author = {B\"{o}hmer, Matthias and Bauer, Gernot},
title = {Exploiting the Icon Arrangement on Mobile Devices as Information Source for Context-Awareness},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851633},
doi = {10.1145/1851600.1851633},
abstract = {The contextual relevance of a service can only be determined by the human himself. However, a measure for relevance is required for context-aware service delivery. In this paper, we draw attention to icon arrangement on mobile devices as a new source of information for adaptive menus. We conducted contextual inquiries to investigate how people arrange icons on a grid-based menu. Our results show that context has an impact on how users arrange their menus: during different activities they prefer different icons to be placed at specific positions. We discuss layout options for icon menus and argue how the relevance can be approximated by observing the icon arrangement. Our results informed the design of a context-aware client for mobile services, which is presented as a prototype.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {195–198},
numpages = {4},
keywords = {implicit feedback, icon arrangement, context awareness},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851635,
author = {von Reischach, Felix and Dubach, Erica and Michahelles, Florian and Schmidt, Albrecht},
title = {An Evaluation of Product Review Modalities for Mobile Phones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851635},
doi = {10.1145/1851600.1851635},
abstract = {Research has shown that product reviews on the Internet not only support consumers when shopping, but also lead to increased sales for retailers. Recent approaches successfully use smart phones to directly relate products (e.g. via barcode or RFID) to corresponding reviews, making these available to consumers on the go. However, it is unknown what modality (star ratings/text/video) users consider useful for creating reviews and using reviews on their mobile phone, and how the preferred modalities are different from those on the Web. To shed light on this we conduct two experiments, one of them in a quasi-realistic shopping environment. The results indicate that, in contrast to the known approaches, stars and pre-structured text blocks should be implemented on mobile phones rather than long texts and videos. Users prefer less and rather well-aggregated product information while on the go. This accounts both for entering and, surprisingly, also for using product reviews.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {199–208},
numpages = {10},
keywords = {mobile applications, user interfaces, product ratings, product reviews, mobile interaction, product recommendations},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@dataset{10.1145/review-1851600.1851635_R45884,
author = {Hazeltine, Barrett},
title = {Review ID:R45884 for DOI: 10.1145/1851600.1851635},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1851600.1851635_R45884}
}

@inproceedings{10.1145/1851600.1851636,
author = {Tintarev, Nava and Flores, Ana and Amatriain, Xavier},
title = {Off the Beaten Track: A Mobile Field Study Exploring the Long Tail of Tourist Recommendations},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851636},
doi = {10.1145/1851600.1851636},
abstract = {This paper presents a field study of a framework for personalized mobile recommendations in the tourism domain, of sight-seeing Points of Interest (POI). We evaluate the effectiveness, satisfaction and divergence from popularity of a knowledge-based personalization strategy comparing it to recommending most popular sites. We found that participants visited more of the recommended POIs for lists with popular but non-personalized recommendations. In contrast, the personalized recommendations led participants to visit more POIs overall and visit places "off the beaten track". The level of satisfaction between the two conditions was comparable and high, suggesting that our participants were just as happy with the rarer, "off the beaten track" recommendations and their overall experience. We conclude that personalized recommendations set tourists into a discovery mode with an increased chance for serendipitous findings, in particular for returning tourists.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {209–218},
numpages = {10},
keywords = {recommender systems, field studies, user-centered design, mobile applications},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851637,
author = {W\"{a}ljas, Minna and Segerst\r{a}hl, Katarina and V\"{a}\"{a}n\"{a}nen-Vainio-Mattila, Kaisa and Oinas-Kukkonen, Harri},
title = {Cross-Platform Service User Experience: A Field Study and an Initial Framework},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851637},
doi = {10.1145/1851600.1851637},
abstract = {Many web-based services utilize both desktop and mobile terminals in delivering content and functionality to their users. In terms of user experience (UX), the overall chain of interactions, including mobile and non-mobile settings, becomes a central design target. The aim of this study was to investigate, what are the key elements of user experience associated with these, cross-platform interactions. This paper presents the findings from a four week long field study with three web-based cross-platform services. During the study, participants used the services on both their PCs and mobile devices. Diaries and interviews were used for gathering users' experiences with the services. Based on our findings and reflection with related work, we argue that central elements of cross-platform service UX include fit for cross-contextual activities, flow of interactions and content, and perceived service coherence. We propose an initial conceptual framework of cross-platform user experience. The framework can be used to guide the design of cross-platform web services, as it draws attention to elements of user experience that are essentially influenced by the characteristics of cross-platform settings.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {219–228},
numpages = {10},
keywords = {cross-platform web services, user experience (UX), crossmedial interactions, conceptual framework, field study},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851638,
author = {Battestini, Agathe and Setlur, Vidya and Sohn, Timothy},
title = {A Large Scale Study of Text-Messaging Use},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851638},
doi = {10.1145/1851600.1851638},
abstract = {Text messaging has become a popular form of communication with mobile phones worldwide. We present findings from a large scale text messaging study of 70 university students in the United States. We collected almost 60, 000 text messages over a period of 4 months using a custom logging tool on our participants' phones. Our re- sults suggest that students communicate with a large number of contacts for extended periods of time, engage in simultaneous conversations with as many as 9 contacts, and often use text messaging as a method to switch between a variety of communication mediums. We also explore the content of text messages, and ways text message habits have changed over the last decade as it has become more popular. Finally, we offer design suggestions for future mobile communication tools.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {229–238},
numpages = {10},
keywords = {texting, text messaging, sms, large-scale study, short message service, mobile device},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851640,
author = {Kray, Christian and Nesbitt, Daniel and Dawson, John and Rohs, Michael},
title = {User-Defined Gestures for Connecting Mobile Phones, Public Displays, and Tabletops},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851640},
doi = {10.1145/1851600.1851640},
abstract = {Gestures can offer an intuitive way to interact with a computer. In this paper, we investigate the question whether gesturing with a mobile phone can help to perform complex tasks involving two devices. We present results from a user study, where we asked participants to spontaneously produce gestures with their phone to trigger a set of different activities. We investigated three conditions (device configurations): phone-to-phone, phone-to-tabletop, and phone to public display. We report on the kinds of gestures we observed as well as on feedback from the participants, and provide an initial assessment of which sensors might facilitate gesture recognition in a phone. The results suggest that phone gestures have the potential to be easily understood by end users and that certain device configurations and activities may be well suited for gesture control.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {239–248},
numpages = {10},
keywords = {gesture, multi-device interaction, tabletop, mobile phone, device pairing, user-defined gesture, large display},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851641,
author = {Bergman, Janne and Vainio, Janne},
title = {Interacting with the Flow},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851641},
doi = {10.1145/1851600.1851641},
abstract = {Mobile devices offer challenges for UI design. Limited screen space leads to deep menus, complex navigation and loss of position. We introduce a new user interface concept that reverses the traditional navigation paradigm. By utilizing context awareness and allowing the user to control the UI via filters, objects of interest navigate past the user instead of the user navigating to the object. The user operates on a single view without the need for deep menu navigation. The new UI is also easy to configure. We implemented the concept on the Nokia S60 5th edition touch platform and conducted user testing with 16 users. Initially, users felt confused because of new ways of accessing things. However, after a short period of usage, majority of the users found it easy to use. Most of the users felt the system to be fun and playful.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {249–252},
numpages = {4},
keywords = {mobile user interfaces, context awareness, flowing objects, content agnostic, new user interface concept},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851642,
author = {Vazquez Alvarez, Yolanda and Brewster, Stephen A.},
title = {Designing Spatial Audio Interfaces to Support Multiple Audio Streams},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851642},
doi = {10.1145/1851600.1851642},
abstract = {Auditory interfaces offer a solution to the problem of effective eyes-free mobile interactions. However, a problem with audio, as opposed to visual displays, is dealing with multiple simultaneous outputs. Any audio interface needs to consider: 1) simultaneous versus sequential presentation of multiple audio streams, 2) 3D audio techniques to place sounds in different spatial locations versus a single point of presentation, 3) dynamic movement versus fixed locations of audio sources. We present an experiment using a divided-attention task where a continuous podcast and an audio menu compete for attention. A sequential presentation baseline assessed the impact of cognitive load, and as expected, dividing attention had a significant effect on overall performance. However, spatial audio still increased the users' ability to attend to two streams, while dynamic movement of streams led to higher perceived workload. These results will provide guidelines for designers when building eyes-free auditory interfaces for mobile applications.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {253–256},
numpages = {4},
keywords = {multiple audio streams, spatial audio, divided-attention task, mobile systems, auditory interfaces},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851643,
author = {Ryu, Jonghyun and Lee, Chil-Woo and Choi, Seungmoon},
title = {Improving Vibrotactile Pattern Identification for Mobile Devices Using Perceptually Transparent Rendering},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851643},
doi = {10.1145/1851600.1851643},
abstract = {At present, vibration feedback is widely used to improve the limited user interface of a mobile device. Despite recent advances of miniature actuator technology, a vibration motor is still a dominant actuator for commercial mobile devices. In this paper, we present a new vibration rendering method which can enhance the identification of mobile device vibrations produced by a vibration motor. Whereas the traditional method separates vibrations in voltage applied to the motor, we partition vibrations in their perceived intensity using perceptually transparent rendering. An empirical evaluation using absolute identification showed that our rendering method can improve perception performance in terms of correct identification rate and the amount of information transfer. The results suggest that perceptually transparent rendering can contribute to increasing the number of discrete vibrations that can be used for information delivery via a mobile device, e.g., for the priorities of phone calls.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {257–260},
numpages = {4},
keywords = {identification, vibration, perceived intensity, mobile device},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851644,
author = {Chong, Ming Ki and Marsden, Gary and Gellersen, Hans},
title = {GesturePIN: Using Discrete Gestures for Associating Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851644},
doi = {10.1145/1851600.1851644},
abstract = {Mobile devices with wireless network capabilities can be associated to form ad hoc networks to share resources; however, such an association of devices requires authentication. At present, PIN is the common authentication method, but in many cases, small devices may not have input interfaces to accommodate PIN entry. We therefore design a gesture-based authentication scheme, called GesturePIN, for associating multiple mobile devices; our solution provides the advantage of being adaptable to any PIN authentication systems. We have also conducted a quantitative user study to understand the speed and accuracy of people using our gesture-based system compared to using PIN.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {261–264},
numpages = {4},
keywords = {gesture password, device association, spontaneous interaction, device authentication},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851646,
author = {Petersen, Marianne Graves and Lynggaard, Aviaja Borup and Krogh, Peter Gall and Winther, Ida Wentzel},
title = {Tactics for Homing in Mobile Life: A Fieldwalk Study of Extremely Mobile People},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851646},
doi = {10.1145/1851600.1851646},
abstract = {For many people home making is an activity, which extends beyond a single house. We introduce the terminology of Homing as the act of home making, when in a primary home, secondary home or more temporary spaces. By point of departure in existing literature on home making and through ethnographic studies of extremely mobile people we identify general tactics for homing. We present the identified tactics and show how people deploy not only one but several tactics in their intention of making a homely feeling despite not being in their primary home.We review the mobile technologies currently in use and argue that several of the tactics identified are currently not well supported. We discuss how technology design can learn from this study through pointing to the potential in designing mobile technologies to better support these unsupported tactics.We consider the tactics as a tool for deeper understanding of mobile practices and thus informing the design of more relevant future technologies for people engaged in a mobile lifestyle.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {265–274},
numpages = {10},
keywords = {tactics, ethnography, home, mobility, design, making home, deleuze},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851647,
author = {Montero, Calkin S. and Alexander, Jason and Marshall, Mark T. and Subramanian, Sriram},
title = {Would You Do That? Understanding Social Acceptance of Gestural Interfaces},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851647},
doi = {10.1145/1851600.1851647},
abstract = {With gesture-based interactions in mobile settings becoming more popular, there is a growing concern regarding the social acceptance of these interaction techniques. In this paper we begin by examining the various definitions of social acceptance that have been proposed in the literature to synthesize a definition that is based on how the user feels about performing a particular interaction as well as how the bystanders perceive the user during this interaction. We then present the main factors that influence gestures' social acceptance including culture, time, interaction type and the user's position on the innovation adoption curve. Through a user study we show that an important factor in determining social acceptance of gesture-based interaction techniques is the user's perception of others ability to interpret the potential effect of a manipulation.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {275–278},
numpages = {4},
keywords = {gestural interfaces, social acceptance, gestures' design},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851648,
author = {Vihavainen, Sami and Kuula, Timo and Federley, Maija},
title = {Cross-Use of Smart Phones and Printed Books in Primary School Education},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851648},
doi = {10.1145/1851600.1851648},
abstract = {The adoption of new technologies in primary schools has fallen behind in terms of children's everyday use of technology. The use of mobile phones has been proposed as a promising field for learning. To date, the mobile learning technologies have rarely been integrated with current educational practices, however. Here, we present the results of our intervention study in which a mobile hybrid media system that combines the use of the traditional printed book with the mobile phone was used in English as foreign language (EFL) education in primary school. The results revealed an increase in learning motivation but also some conflicts when the boundaries of the school world and everyday life were blurred through the use of new technology.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {279–282},
numpages = {4},
keywords = {intervention, print, education, english as foreign language, EFL, mobile, user experience},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851649,
author = {Reitmaier, Thomas and Bidwell, Nicola J. and Marsden, Gary},
title = {Field Testing Mobile Digital Storytelling Software in Rural Kenya},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851649},
doi = {10.1145/1851600.1851649},
abstract = {We describe and reflect on a method we used to evaluate usability and give insights on situated use of a mobile digital storytelling prototype. We report on rich data we gained by implementing this method and argue that we were able to learn more about our prototype, users, their needs, and their context, than we would have through other evaluation methods. We look at the usability problems we uncovered and discuss how our flexibility in field-testing allowed us to observe unanticipated usage, from which we were able to motivate future design directions. Finally, we reflect on the importance of spending time in-situ during all stages of design, especially when designing across cultures.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {283–286},
numpages = {4},
keywords = {evaluation, digital storytelling, HCI4D, probe, rural},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851650,
author = {Liu, Ning and Liu, Ying and Wang, Xia},
title = {Data Logging plus E-Diary: Towards an Online Evaluation Approach of Mobile Service Field Trial},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851650},
doi = {10.1145/1851600.1851650},
abstract = {Many field study methods such as usability test in fields, contextual inquiry, and ethnographic interview can be applied to evaluate user experience of concepts in trials; however, most of such traditional field study methods suffer from weaknesses like resource demanding, time consuming, lack of measurement for longitudinal usage or lack of channels to collect user feedbacks in real time. In this paper, we propose an approach to combine data logging with e-diary for user experience evaluation in field trials. An evaluation case on a mobile service concept is also presented to show this approach.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {287–290},
numpages = {4},
keywords = {field trial, evaluation, data log, diary},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851652,
author = {Kaufmann, Bonifaz and Buechley, Leah},
title = {Amarino: A Toolkit for the Rapid Prototyping of Mobile Ubiquitous Computing},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851652},
doi = {10.1145/1851600.1851652},
abstract = {Ubicomp applications increasingly involve smart phones that control or communicate with embedded systems. Compelling examples in this space include tangible interfaces, environmental sensor networks, game controllers and automated homes. Across research, design, and hobbyist communities there is clearly a desire to build applications that involve combinations of mobile and non-mobile technologies. However, constructing these applications is a laborious process that requires considerable breadth and depth of expertise in programming, electronics, industrial and interaction design.Amarino is a toolkit that enables the rapid prototyping of such applications by connecting the Android operating system to the Arduino microcontroller platform. It consists of an Android application, an Arduino library, and a collection of documentation and examples. This suite of tools allows users to: 1) access Android events (ie: compass orientation, accelerometer data, and text messages received) and send them to Arduino microcontrollers without doing any Android programming, and 2) quickly develop Android applications that receive data (ie: environmental sensor data) from (and send data to) Arduino microcontrollers. This paper introduces Amarino and presents the results of a preliminary user study.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {291–298},
numpages = {8},
keywords = {tangible, smart phones, mobile computing, mobile phones, microcontroller, mobile devices, Arduino, interfaces, communication, android, wearables, toolkit},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851653,
author = {Ghiani, Giuseppe and Patern\`{o}, Fabio and Santoro, Carmen},
title = {On-Demand Cross-Device Interface Components Migration},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851653},
doi = {10.1145/1851600.1851653},
abstract = {Ubiquitous environments call for innovative uses of existing applications. In this paper we present our solution for partial Web migration: it allows users to interactively select parts of existing interfaces and have them migrate to a target device. The underlying supporting platform exploits logical user interface descriptions and a set of transformations. This environment is particularly useful for supporting mobile users accessing complex Web applications, such as various emerging mash-ups. We also show an example of use of our solution in a widespread Web application, and report on a user test.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {299–308},
numpages = {10},
keywords = {partial migration, ubiquitous environments, migratory interfaces},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851654,
author = {Music, Josip and Murray-Smith, Roderick},
title = {Virtual Hooping: Teaching a Phone about Hula-Hooping for Fitness, Fun and Rehabilitation},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851654},
doi = {10.1145/1851600.1851654},
abstract = {The paper demonstrates the feasibility of using mobile phones for fitness and rehabilitation purposes by training them to recognise a user's hula-hooping movements. It also proposes several parameters which can be used as a measure of rhythmic movement quality. Experimental measurements were achieved with two test subjects performing two sets of steady hula-hooping. The paper compares algorithm performance with accelerometer, gyroscope and magnetometer sensor readings. Analysis of the recorded data indicated that magnetometers had some advantages over accelerometers for reliable phase extraction. Hilbert transforms were used to extract the phase information, and a Dynamic Rhythmic Primitive Model was identified for the hula-hooping movement. Together these tools allow the creation of hula-hooping performance metrics which can be used in wellness, rehabilitation or entertainment applications for mobile devices. We outline open technical challenges and possible future research directions.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {309–312},
numpages = {4},
keywords = {fitness, hula hoop, magnetometer, dynamic movement primitives, phase angle, hilbert transform},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851655,
author = {Schinke, Torben and Henze, Niels and Boll, Susanne},
title = {Visualization of Off-Screen Objects in Mobile Augmented Reality},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851655},
doi = {10.1145/1851600.1851655},
abstract = {An emerging technology for tourism information systems is mobile Augmented Reality using the position and orientation sensors of recent smartphones. State-of-the-art mobile Augmented Reality application accompanies the Augmented Reality visualization with a small mini-map to provide an overview of nearby points of interest (POIs). In this paper we develop an alternative visualization for nearby POIs based on off-screen visualization techniques for digital maps. The off-screen visualization uses arrows directly embedded into the Augmented Reality scene which point at the POIs. In the conducted study 26 participants explored nearby POIs and had to interpret their position. We show that participants are faster and can interpret the position of POIs more precisely with the developed visualization technique.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {313–316},
numpages = {4},
keywords = {augmented reality, mobile phone, orientation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851657,
author = {Kauko, Jarmo and H\"{a}kkil\"{a}, Jonna},
title = {Shared-Screen Social Gaming with Portable Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851657},
doi = {10.1145/1851600.1851657},
abstract = {Mobile phones are designed as personal devices, and thus mobile games often lack the social element present in other game platforms, e.g., in console games. In this paper, we present an interaction method for social gaming with portable devices. The interaction method combines displays of multiple devices to form a shared screen visible to all players. We conducted an experiment with 40 participants to compare the social setting between our method and a typical console game environment. The results show that the amount of oral communication was significantly higher in the mobile device setup. The results on subjective experience were inconclusive, but revealed that players' perceptions of a social situation were affected by various factors such as ergonomics, distance, support for spectators, and symbolic meanings of the seating arrangement. Our findings help to understand the design space of social co-located gaming, and show that mobile phones are a potential platform for such games.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {317–326},
numpages = {10},
keywords = {social interaction, game experience, mobile games},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851658,
author = {Hinze, Annika M. and Chang, Carole and Nichols, David M.},
title = {Contextual Queries Express Mobile Information Needs},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851658},
doi = {10.1145/1851600.1851658},
abstract = {The users of mobile devices increasingly use networked services to address their information needs. Questions asked by mobile users are strongly influenced by contextual factors such as location, conversation and activity. We report on a diary study performed to better understand mobile information needs. We find that the type of questions recorded by participants varies across their locations, with differences between home, shopping and in-car contexts. These variations occur both in the query terms and in the form of desired answers. Both the location of queries and the participants' activities affected participants' questions. When information needs were affected by both location and activity, they tended to be strongly affected by both factors. The overall picture that emerges is one of multiple contextual influences interacting to shape mobile information needs. Mobile devices that attempt to adapt to users' context will need to account for a rich variety of situational factors.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {327–336},
numpages = {10},
keywords = {user requirements, mobile information needs, location, diary study, context},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851659,
author = {Lucero, Andr\'{e}s and Ker\"{a}nen, Jaakko and Korhonen, Hannu},
title = {Collaborative Use of Mobile Phones for Brainstorming},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851659},
doi = {10.1145/1851600.1851659},
abstract = {Mobile phones have traditionally been utilized for personal and individual use. In this paper we explore shared co-located interactions with mobile phones. We introduce a phone-based application that supports ad hoc brainstorming sessions. The prototype allows a workgroup to create, edit and view virtual mind-map notes on any table surface. The prototype encourages people to use the devices interchangeably and thus engage in social interactions. Evaluations show that participants were able to easily create mind maps and that the prototype supports different strategies in mind-map creation.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {337–340},
numpages = {4},
keywords = {mobile devices, tangible user interface, co-located interaction},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851660,
author = {Robinson, Simon and Jones, Matt and Eslambolchilar, Parisa and Murray-Smith, Roderick and Lindborg, Mads},
title = {"I Did It My Way": Moving Away from the Tyranny of Turn-by-Turn Pedestrian Navigation},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851660},
doi = {10.1145/1851600.1851660},
abstract = {In this article we describe a novel approach to pedestrian navigation using bearing-based haptic feedback. People are guided in the general direction of their destination via vibration, but additional exploratory navigation is stimulated by varying feedback based on the potential for taking alternative routes. We describe two mobile prototypes that were created to examine the possible benefits of the approach. The successful use of this exploratory navigation method is demonstrated in a realistic field trial, and we discuss the results and interesting participant behaviours that were recorded.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {341–344},
numpages = {4},
keywords = {GPS, navigation, mobile, bearing-based, vibrotactile},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851662,
author = {Lee, Young Seok and Basapur, Santosh and Zhang, Harry and Guerrero, Claudia and Massey, Noel},
title = {Usability Evaluation of Beep-to-the-Box},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851662},
doi = {10.1145/1851600.1851662},
abstract = {Radio Frequency Identification (RFID) provides various opportunities to increase the productivity of retail business. In this paper, we describe a usability evaluation study for an RFID-based location tracking application, called Beep-To-The-Box (BTTB). The experiment was conducted in a simulated retail store to gain in-depth understanding of the usefulness and usability of the prototype in determining visual and audio user interface features. We describe the features of the BTTB, report the experimental results, and discuss insights gained to provide design recommendations for the final product design.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {345–348},
numpages = {4},
keywords = {visual and auditory UI design, usability, indoor location tracking, RFID},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851663,
author = {White, Brent-Kaan and Rice, Sean and Chen, Chun-Yi},
title = {Designing Enterprise Applications That Connect Employees on the Go},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851663},
doi = {10.1145/1851600.1851663},
abstract = {This paper describes the process of designing an enterprise application that connects employees, the unique interface challenges, research activities, and subsequent changes to the design. The user-centered design process was driven by three research activities that informed the design in stages. Focus group sessions enabled us to understand requirements, wireframe usability evaluations helped us to validate macro level design decisions, and live prototype testing provided feedback that helped refine the design and validate the interactions. The collective research activities contributed to improved usability for navigation, actions, search, and a hierarchical organization chart. In addition, social networking within the work context was better understood and important concerns were identified. Key changes to the design included a streamlined three-level organization chart, the reduction of icons, and a new layout for search.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {349–352},
numpages = {4},
keywords = {social networking, mobile HCI, mobile browsers, iterative design, enterprise applications, usability testing},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851664,
author = {Vartiainen, Elina},
title = {Designing a Photo Sharing Service for Mobile: A Phone Number as the Key Enabler},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851664},
doi = {10.1145/1851600.1851664},
abstract = {Internet services are becoming essential in people's daily lives. They offer functionality and content that are also relevant for mobile use, as mobile devices of today are technologically sophisticated enabling online access anytime, anywhere. Unfortunately, Internet services specifically designed for mobiles utilizing their capabilities to the fullest are largely still missing. In this paper, we introduce Image Exchange, a photo sharing Internet service, that exploits two essential things that a mobile device has to offer: a personal identifier (a user's phone number) and social network (phonebook contacts). We evaluated Image Exchange in a field study and the results show that the current design is a good starting point but needs to be extended to enable a truly social photo sharing service.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {353–356},
numpages = {4},
keywords = {phonebook, photo sharing, internet services},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851665,
author = {Zhang, Rui and North, Stephen and Koutsofios, Eleftherios},
title = {A Comparison of Speech and GUI Input for Navigation in Complex Visualizations on Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851665},
doi = {10.1145/1851600.1851665},
abstract = {Mobile devices are ubiquitously used to access web applications. Multimodal mobile interfaces can offer advantages over less flexible approaches, in both usability and range of features. In this study we consider applying speech input to a web-based network management service. The key issue we are interested in is how to perform suitable multidimensional search through web-based interface on mobile devices. We present results from a pilot user evaluation, focusing on the comparison of a novel speech input method with the existing manual (GUI, Graphical User Interface) input for AT&amp;T's Visualizer management service, on an iPhone. Speech input was experimentally shown to be as effective, more efficient, and preferred over GUI input by most users. We foresee that a multimodal approach may be preferable for many applications on mobile devices.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {357–360},
numpages = {4},
keywords = {speech input, multimodal, web service, modality, visualizer},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851666,
author = {Sohn, Timothy and Setlur, Vidya and Mori, Koichi and Kaye, Joseph 'Jofish' and Horii, Horishi and Battestini, Agathe and Ballagas, Rafael and Paretti, Christopher and Spasojevic, Mirjana},
title = {Addressing Mobile Information Overload in the Universal Inbox through Lenses},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851666},
doi = {10.1145/1851600.1851666},
abstract = {Increasingly, smartphones are being used to access all manner of information: email messages, Facebook status updates, tweets, RSS feeds, photographs and more. Approaches to dealing with this multi-faceted information stream developed on the desktop, such as switching between multiple applications or multiple browser windows, are unwieldy and scale poorly for mobile devices. In this paper, we propose the combination of the universal inbox and a system called 'Lenses' for extracting information of interest as part of a solution to this problem. These mechanisms allow the user to easily specify ways to sort, filter and manage their universal inbox in an intuitive way. We culminate with a discussion of implications for mobile phone interface design.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {361–364},
numpages = {4},
keywords = {mobile messaging, information overload, mobile interfaces, lenses, mobile email, entity resolution},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851667,
author = {Paek, Tim and Chang, Kenghao and Almog, Itai and Badger, Eric and Sengupta, Tirthankar},
title = {A Practical Examination of Multimodal Feedback and Guidance Signals for Mobile Touchscreen Keyboards},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851667},
doi = {10.1145/1851600.1851667},
abstract = {Mobile devices with touch capabilities often utilize touchscreen keyboards. However, due to the lack of tactile feedback, users often have to switch their focus of attention between the keyboard area, where they must locate and click the correct keys, and the text area, where they must verify the typed output. This can impair user experience and performance. In this paper, we examine multimodal feedback and guidance signals that keep users' focus of attention in the keyboard area but also provide the kind of information users would normally receive in the text area. We evaluated whether combinations of multimodal signals could improve typing performance in a controlled experiment. One combination reduced keystrokes-per-character by 8% and correction backspaces by 28%.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {365–368},
numpages = {4},
keywords = {mobile device, touchscreen, multimodal feedback, soft keyboard},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851669,
author = {Feige, Sebastian and Wenig, Dirk and Pantel, Christoph and Malaka, Rainer},
title = {Image-Based Cycle Route Generation on Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851669},
doi = {10.1145/1851600.1851669},
abstract = {Current planning tools for cycling trips do not sufficiently support the often explorative, spontaneous nature of cycling as route creation is not provided in a way suitable for usage on typical mobile devices in situ. In close cooperation with the target group, we developed and evaluated an approach where cycling routes based on selected images of points of interest can be generated on-the-fly.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {369–370},
numpages = {2},
keywords = {cycling, mobile applications, route generation, trip planning},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851670,
author = {Nicolau, Hugo and Nunes, Renato and Jorge, Joaquim},
title = {Personal Mobile Controller for Blind People},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851670},
doi = {10.1145/1851600.1851670},
abstract = {We are moving towards a future where people will be ever more surrounded by technology and multiple appliances, bringing about the promise of truly intelligent environments. However, this multitude of devices raises several issues to HCI practitioners. Indeed, our preliminary studies confirm that blind people experience difficulties with most appliances, due to inadequate interfaces. The research described here approaches this problem by moving the user interface away from appliances to an intermediary device, which blind people are familiar with and can fully control. Additionally, we propose an automatic generation algorithm, which provides a consistent user interface to all appliances in the environment.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {371–372},
numpages = {2},
keywords = {mobile device, blind, controller, interface generation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851671,
author = {Henze, Niels and Boll, Susanne},
title = {Push the Study to the App Store: Evaluating off-Screen Visualizations for Maps in the Android Market},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851671},
doi = {10.1145/1851600.1851671},
abstract = {The introduction of publicly available application stores for mobile devices enables to publish research prototypes to a wide audience. This distribution channel can be used to conduct studies with participants from all over the world and diverse backgrounds. We report from a study that compares three visualization techniques for off-screen objects on digital maps. Usage data from 362 persons was collected and 105 persons completed an interactive tutorial. Significant differences between the three conditions were found. The results support previous findings but we conjecture that the results are affected by unintended influences.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {373–374},
numpages = {2},
keywords = {android market, map navigation, evaluation, off-screen},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851672,
author = {Pombinho, Paulo and Carmo, Maria Beatriz and Afonso, Ana Paula and Aguiar, Hugo},
title = {Location and Orientation Based Point of Interest Search Interface},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851672},
doi = {10.1145/1851600.1851672},
abstract = {In this paper we present an interactive point of interest query interface, based on the location and orientation of the user. This interface gives clues about the position, relative to the user, of all the points of interest in the vicinity. The interaction provided can also be used to complement the presentation of points of interest on a map, helping identify the association between the icons drawn on a map, and the corresponding real world objects in the neighbourhood of the user.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {375–376},
numpages = {2},
keywords = {location and orientation services, mobile devices, geo referenced information visualization},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851673,
author = {Wenig, Dirk and Malaka, Rainer},
title = {Interaction with Combinations of Maps and Images for Pedestrian Navigation and Virtual Exploration},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851673},
doi = {10.1145/1851600.1851673},
abstract = {While studies have shown the advantages of map-image-combinations for pedestrian navigation, none of them concentrated on interaction. We suggest to combine an intuitive pitch gesture with the natural peephole metaphor not only for pedestrian navigation but also for virtual exploration with mobile devices and present a first prototype implementing our ideas.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {377–378},
numpages = {2},
keywords = {maps, pedestrian navigation, image-based navigation, mobile devices, virtual exploration},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851674,
author = {Benedito, Jo\~{a}o and Guerreiro, Tiago and Nicolau, Hugo and Gon\c{c}alves, Daniel},
title = {The Key Role of Touch in Non-Visual Mobile Interaction},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851674},
doi = {10.1145/1851600.1851674},
abstract = {Mobile devices are designed mostly to fit users with no particular disability. Tactile affordances are neglected at the expense of more attractive stylish interfaces and assistive solutions are stereotypical, also facing disabilities with a narrow perspective. A blind user is presented with screen reading software to overcome the inability to receive feedback from the device. However, these solutions go only half-way. In the absence of sight other capabilities stand up. Above all, the sense of touch plays an essential role while interacting with physical keypads. To empower these users, a deeper understanding of their capabilities and how they relate with technology is mandatory. We propose a user-product compatibility approach, taking in account that blind users have different tactile attributes. We expect to correlate the user's tactile sensitivity and keypad demands, enabling informed keypad design and selection.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {379–380},
numpages = {2},
keywords = {blind, tactile sensitivity, assessment, mobile accessibility},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851675,
author = {Niu, Jianwei and Zhu, Like and Yan, Qifeng and Liu, Yingfei and Wang, Kongqiao},
title = {Stroke++: A Hybrid Chinese Input Method for Touch Screen Mobile Phones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851675},
doi = {10.1145/1851600.1851675},
abstract = {In this paper we present Stroke++, a novel hybrid Chinese input method for touch screen mobile phones that leverages hieroglyphic properties of Chinese characters to enable faster and easier input of Chinese characters on mobile phones. By using a special keypad layout, a friendly user interface and an adaptive radical selection algorithm, we achieved a competitive inputting performance compared with currently prevalent mobile Chinese input methods, while keeping a low entry barrier for Chineseinput novices. An extensive evaluation results show that Stroke++ out-performs the state-of-the-art keystroke-based or handwriting recognition-based Chinese character inputting methods, as far as the input speed and convenience are concerned.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {381–382},
numpages = {2},
keywords = {chinese radicals, touch screen, virtual keyboard, chinese input, mobile devices},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851676,
author = {Ahmet, Zeynep and Holmquist, Lars-Erik},
title = {Sharing Mobile Services: Beyond the App Store Model},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851676},
doi = {10.1145/1851600.1851676},
abstract = {The app store model used by Apple's iPhone has presented a successful model for installing new applications; however, only a fraction of current mobile phones have access to a dedicated app store. Thus there is need to investigate alternative ways of discovering and installing mobile services and applications. We performed studies on two services, focusing on the social aspects of sharing mobile apps between users. The services were a portrait sharing application prototype called Portrait Catalog, and a commercially available chat application called Hanashi. They differ not only by functionality and design, but also by their availability to the public as well as the means of distribution they offer. We present initial insights in how users share mobile services between each other, when using a phone that doesn't include mobile application distribution as part of the user experience. We found that factors such as users' habits of downloading and testing new applications, their understandings of the service they are using and the means of distribution the services offer, all affected how the services were shared.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {383–384},
numpages = {2},
keywords = {App stores, factors, distribution channels, sharing, mobile services},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851677,
author = {Guerreiro, Jo\~{a}o and Guerreiro, Tiago and Gon\c{c}alves, Daniel},
title = {Surpassing Farley Files: Opportunities and Challenges on Obtaining Personally Relevant Information},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851677},
doi = {10.1145/1851600.1851677},
abstract = {The proliferation of personal devices and their constant awareness of our interactions have generated an enormous amount of data that can be useful to help the user obtaining relevant information when needed. Our approach uses the personal information on users' devices, together with public online sources, to provide relevant information from the user point of view. The information from the users' devices, due to its personal and credible character, works as a filter to the retrieved from other less trustable and structured sources. A preliminary evaluation, suggested that we can provide the user with inter-connected relevant information from heterogeneous sources. However, we found some limitations that led us to our current research challenges.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {385–386},
numpages = {2},
keywords = {public information, mobile, information filtering, personal information},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851678,
author = {Nguyen, Trung Van and Oh, Alice Hae Yun},
title = {Users' Needs for Social Tagging and Sharing on Mobile Contacts},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851678},
doi = {10.1145/1851600.1851678},
abstract = {In this paper we describe our research toward improving the current mobile contacts applications, which we found to lack important features that are essential to a fully satisfactory user experience. We identify the needs for a better user experience for organizing and searching, as well as looking for information from one's social network. We present the results of a user study that identified the problems with the current mobile contacts applications and propose tagging contacts and social network information sharing as the mechanism for improving their usability and usefulness.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {387–388},
numpages = {2},
keywords = {mobile recommendation system, user study, mobile tagging, mobile contacts application design},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851679,
author = {Rebaque-Rivas, Pablo and Gil-Rodr\'{\i}guez, Eva Patricia and Manresa-Mallol, Irene},
title = {Mobile Learning Scenarios from a UCD Perspective},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851679},
doi = {10.1145/1851600.1851679},
abstract = {This article presents a study carried out from a user-centered design (UCD) perspective to define mobile learning scenarios. Student user profiles were defined and personas created. There were 4 focus groups with 7 students. 7 in-depth interviews with commuting students were carried out. The information collected allowed for the definition of 2 potential scenarios for mobile learning. These 2 scenarios helped identify specific devices, functionalities and applications. They highlighted the enormous potential for m-learning by commuting students. These 2 scenarios can act as the basis for the design and development of new applications linked to m-learning.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {389–390},
numpages = {2},
keywords = {contextual inquiry, m-learning, UCD, focus group, commuting, scenarios, personas, user studies},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851680,
author = {Al Mahmud, Abdullah and Braun, Jeffrey and Martens, Jean-Bernard},
title = {Designing to Capture and Share Life Experiences for Persons with Aphasia},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851680},
doi = {10.1145/1851600.1851680},
abstract = {In this paper we present the design of an image capturing device for persons with aphasia. The early concepts were validated with one speech therapist and the usability of the camera was tested with one aphasic person. Our semi-autonomous hand-held camera, tapered to meet specific interaction and ergonomic needs of expressive aphasics. This camera is able to capture daily experiences by creating photographs that receives significant, automatically added tags. We present the design case study with early evaluation results by proxy users.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {391–392},
numpages = {2},
keywords = {aphasia, life-logging, capturing, prototyping},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851681,
author = {Dekel, Amnon and Schiller, Elad},
title = {DRec: Exploring Indoor Navigation with an Un-Augmented Smart Phone},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851681},
doi = {10.1145/1851600.1851681},
abstract = {We present an ongoing series of tests that explore the capabilities of un-augmented smart phones to serve as indoor navigation devices. We developed and tested a dead reckoning navigation application on an IPhone 3GS. It was found that the DRec application can count steps with more than 97% accuracy. This parameter, when multiplied with the user's personal step distance can be used to compute distance traveled. In initial tests DRec was able to compute the distance traveled with more than 90% accuracy. A dead reckoning test was also run, and initial results are promising.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {393–394},
numpages = {2},
keywords = {accelerometer, navigation, compass, dead reckoning},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851682,
author = {Ladstaetter, Stefan and Luley, Patrick and Almer, Alexander and Paletta, Lucas},
title = {Multisensor Data Fusion for High Accuracy Positioning on Mobile Phones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851682},
doi = {10.1145/1851600.1851682},
abstract = {Analysis of human geographical orientation is a crucial issue to understand the user's actual demand on context based information. As the limitations in accuracy of satellite based positioning especially in urban environments and network based positioning are well known, a novel framework concept based on data fusion of multiple sensors build-in handsets will enable to characterize the user's situation and allow automated analysis with semantic mapping functionality. In this paper, the first approach for high accuracy multi sensor orientation tracking by the use of a mobile phone is discussed.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {395–396},
numpages = {2},
keywords = {data fusion, pedestrian navigation, inertial measurement, kalman filter, dead reckoning, multisensor positioning},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851683,
author = {Serra, Alberto and Carboni, Davide and Marotto, Valentina},
title = {Indoor Pedestrian Navigation System Using a Modern Smartphone},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851683},
doi = {10.1145/1851600.1851683},
abstract = {In this work we present a pedestrian navigation system for indoor environments based on the dead reckoning positioning method, 2D barcodes, and data from accelerometers and magnetometers. All the sensing and computing technologies of our solution are available in common smart phones. The need to create indoor navigation systems arises from the inaccessibility of the classic navigation systems, such as GPS, in indoor environments.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {397–398},
numpages = {2},
keywords = {compass, indoor navigation, map, accelerometer, dead reckoning},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851684,
author = {Magnusson, Charlotte and Rassmus-Gr\"{o}hn, Kirsten and Szymczak, Delphine},
title = {Scanning Angles for Directional Pointing},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851684},
doi = {10.1145/1851600.1851684},
abstract = {The present study was performed in order to get a better understanding of the influence of the scanning angle interval on navigation performance, gestures and strategies in a more realistic outdoor setting. Results indicate that users are able to handle a wide range of angle intervals. We observe different gestures and strategies and provide recommendations for suitable angle intervals. Our observations also support the notion that using this type of pointing gesture for navigation is intuitive and easy to use.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {399–400},
numpages = {2},
keywords = {angle, non-visual, audio, pointing, gesture, navigation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851685,
author = {Naumann, Anja and Hurtienne, J\"{o}rn},
title = {Benchmarks for Intuitive Interaction with Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851685},
doi = {10.1145/1851600.1851685},
abstract = {The QUESI (Questionnaire for the subjective consequences of intuitive use), a specific measure of the satisfaction of users interacting with a product, is presented. In addition, first benchmark values for mobile devices and applications are provided.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {401–402},
numpages = {2},
keywords = {design for intuitive use, usability, questionnaire, evaluation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851686,
author = {Mangold, Benjamin},
title = {Spatiotemporal Visualization of Mobile User Experience},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851686},
doi = {10.1145/1851600.1851686},
abstract = {The paper presents and discusses a prototype for the tracking and visualization of mobile user experience using the example of emergency management and response. The tracking prototype consists of GPS-devices and mini video cameras. The approach is based on time-geographic methods of visualization. It represents user interactions, mobile communication and media use in its locative and temporal dimensions. Using a spatiotemporal approach to mobile communities allows insights about the structure of mobile interactions, mobile communities and mobile user contexts.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {403–404},
numpages = {2},
keywords = {time geography, spatiotemporal dynamics, visualization, mobile user experience, mobile social networks, tracking, mobile communities, human centered design},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851687,
author = {Kriesten, Bastian and T\"{u}nnermann, Ren\'{e} and Mertes, Christian and Hermann, Thomas},
title = {Controlling Ambient Information Flow between Smart Objects with a Mobile Mixed-Reality Interface},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851687},
doi = {10.1145/1851600.1851687},
abstract = {In this work we present a method to intuitively issue control over devices in smart environments, to display data that smart objects and sensors provide, and to create and manipulate flows of information in smart environments. This makes it easy to customize smart environments by linking arbitrary data sources to various display modalities on the fly. Touchscreen smartphones - as readily available multi-purpose devices - are used to overlay real objects with virtual controls. We evaluated this system with a first qualitative user study.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {405–406},
numpages = {2},
keywords = {home automation, ambient data streams, mixed reality, mobile devices, augmented reality, mobile interaction},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851688,
author = {Acharya, Karthikeya and Mikkonen, Jussi},
title = {Energy Usage Responsive Space and Personal Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851688},
doi = {10.1145/1851600.1851688},
abstract = {Energy consumption that takes place because of industrial sheltered living through amenities such as lighting, heat, ventilation and air conditioning is not fully deciphered by the users when in use, especially in shared public spaces. Here we describe a design intervention, where users in a shared workspace are made aware of the energy consumption and its pattern of use due to ambient lighting through text messages on their personal mobile devices. The text messages contained specially treated information about the energy consumption. This poster describes the design intervention through the prototype description of a 'Usage Responsive Space'.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {407–408},
numpages = {2},
keywords = {physical resource usage, shared spaces, collective feedback, usage responsive environment, design intervention, energy 2.0},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851689,
author = {Setlur, Vidya},
title = {SemantiLynx: Context Based Icons for Mobile Web Navigation and Directed Search Tasks},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851689},
doi = {10.1145/1851600.1851689},
abstract = {Typical web navigation techniques tend to support undirected web browsing, a depth-first search of information pages. This search strategy often results in the unintentional behavior of 'web surfing', where a user starts in search of information, but is sidetracked by tangential links. A mobile user in particular, would prefer to extract the desired information quickly and with minimal mental effort. In this paper, we introduce 'SemantiLynx' to visually augment hyperlinks on web pages for better supporting the task of directed searches on small-screen ubiquitous platforms. Our algorithm comprises four parts: establishing the context of information related to a hyperlink, retrieving relevant imagery based on this context, applying image simplification, and finally compositing a visual icon for the given hyperlink.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {409–410},
numpages = {2},
keywords = {mobile device, directed search, hyperlinks, ubiquitous web, icons},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851690,
author = {Jedrzejczyk, Lukasz and Price, Blaine A. and Bandara, Arosha and Nuseibeh, Bashar},
title = {"Privacy-Shake",: A Haptic Interface for Managing Privacy Settings in Mobile Location Sharing Applications},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851690},
doi = {10.1145/1851600.1851690},
abstract = {We describe the "Privacy-Shake", a novel interface for managing coarse grained privacy settings. We built a prototype that enables users of Buddy Tracker, an example location sharing application, to change their privacy preferences by shaking their phone. Users can enable or disable location sharing and change the level of granularity of disclosed location by shaking and sweeping their phone. In this poster we present and motivate our work on Privacy-Shake and report on a lab-based evaluation of the interface with 16 participants.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {411–412},
numpages = {2},
keywords = {privacy management, haptics, location sharing, mobile computing},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851691,
author = {Sarmento, Teresa and Patr\'{\i}cio, Lia},
title = {Mobile Service Experiences: Qualitative Study with a Broader Perspective},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851691},
doi = {10.1145/1851600.1851691},
abstract = {The increasing usage of mobile technologies for service provision has created the need to understand customer mobile service experiences and to integrate designer's and technology's perspectives for the design of successful mobile services. This paper presents the results of a qualitative study with 44 mobile service customers, providing an in-depth understanding of the experience factors that contribute to design improved mobile services. The study' results indicate that traditional interface factors, such as usefulness and ease of use, continue to be important. However, the study reveals that contextual factors, such as the social environment and service atmosphere, are very important for the mobile service experience. These results reinforce the need to adopt a broader view of the experience factors for the effective design of mobile services.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {413–414},
numpages = {2},
keywords = {service innovation, service experience, mobile services},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851692,
author = {Vyas, Dhaval and Nijholt, Anton and Kr\"{o}ner, Alexander},
title = {CAM: A Collaborative Object Memory System},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851692},
doi = {10.1145/1851600.1851692},
abstract = {Physical design objects such as sketches, drawings, collages, storyboards and models play an important role in supporting communication and coordination in design studios. CAM (Cooperative Artefact Memory) is a mobile-tagging based messaging system that allows designers to collaboratively store relevant information onto their design objects in the form of messages, annotations and external web links. We studied the use of CAM in a Product Design studio over three weeks, involving three different design teams. In this paper, we briefly describe CAM and show how it serves as 'object memory'.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {415–416},
numpages = {2},
keywords = {design objects, object memory, design studio, mobile-tagging},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851693,
author = {de S\'{a}, Marco and Carri\c{c}o, Lu\'{\i}s and Faria, Jo\~{a}o and S\'{a}, Isabel and Baloian, Nelson and Zurita, Gustavo},
title = {Geo-Referenced Collaborative Psychotherapy: Design and Evaluation of a Low-Fidelity Prototype},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851693},
doi = {10.1145/1851600.1851693},
abstract = {Social competency training, as part of psychotherapy, for children and teenagers, requires them to engage on outdoor activities in which they have to complete tasks such as talking to someone or visiting a specific place. Currently, the inability for therapists to monitor their patients, to promote collaborative efforts and to reinforce positive attitudes is a major issue that affects both the therapy process and its results.In this paper we present an evaluation experience of a mobile prototype for a geo-referenced collaborative system that supports in-situ group therapy. We describe the concept, our initial low-fi prototypes and the experiments that were undertaken to validate them. Initial results are discussed and future work is defined.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {417–418},
numpages = {2},
keywords = {mobile devices, geo-referenced collaboration, psychotherapy},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851695,
author = {Ouilhet, Hector},
title = {Google Sky Map: Using Your Phone as an Interface},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851695},
doi = {10.1145/1851600.1851695},
abstract = {Google Sky Map, an application for Android mobile phones, allows the user to discover and browse the sky by simply pointing the phone to space. Using the Android phone's orientation sensors, Sky Map shows a particular stellar map specific for each user's location. This paper describes the design principle used for Sky Map: the use of the mobile device as the main interface and the GUI as a secondary guidance. The GUI in Google Sky Map is kept as minimal as possible. The search GUI is an example of how an on-screen GUI and the physical movement of the phone can work in harmony to provide an accurate user experience. Google Sky Map was developed by five Google Engineers and one User Experience Designer.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {419–422},
numpages = {4},
keywords = {space, planetarium, sensors, mobile, GUI, interaction style},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851696,
author = {Pielot, Martin and Poppinga, Benjamin and Boll, Susanne},
title = {PocketNavigator: Vibro-Tactile Waypoint Navigation for Everyday Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851696},
doi = {10.1145/1851600.1851696},
abstract = {Pedestrian navigation systems are becoming popular but the currently dominant audio-visual interaction can have drawbacks. Tactile feedback is studied as a solution, but currently only available as research prototypes. With the PocketNavigator we propose a demonstrator that adds tactile feedback to a simple but robust map-based navigation system that runs on any Android Smartphone. Users can leave the device in the pocket, while being guided non-visually through vibration cues. Like a compass we "point at" the next waypoint by encoding its direction and distance in vibration patterns. As an advantage over previous approaches it allows giving continuous feedback instead of isolated turning instructions and it can be realized without custom-built tactile displays. Preliminary results from a field study show that pedestrian can effectively use this Tactile Compass to reach a destination without turn-by-turn instructions. Integrated into the PocketNavigator we can now deploy it at the Android Market to evaluate the Tactile Compass with a wide range of users.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {423–426},
numpages = {4},
keywords = {tactile displays, pedestrian navigation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851697,
author = {Munteanu, Cosmin and Lumsden, Joanna and Fournier, H\'{e}l\`{e}ne and Leung, Rock and D'Amours, Danny and McDonald, Daniel and Maitland, Julie},
title = {ALEX: Mobile Language Assistant for Low-Literacy Adults},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851697},
doi = {10.1145/1851600.1851697},
abstract = {Basic literacy skills are fundamental building blocks of education, yet for a very large number of adults tasks such as understanding and using everyday items is a challenge. While research, industry, and policy-making is looking at improving access to textual information for low-literacy adults, the literacy-based demands of today's society are continually increasing. Although many community-based organizations offer resources and support to adults with limited literacy skills, current programs have difficulties reaching and retaining those that would benefit most from them. To address these challenges, the National Research Council of Canada is proposing a technological solution to support literacy programs and to assist low-literacy adults in today's information-centric society: ALEX© - Adult Literacy support application for EXperiential learning. ALEX© has been created together with low-literacy adults, following guidelines for inclusive design of mobile assistive tools. It is a mobile language assistant that is designed to be used both in the classroom and in daily life, in order to help low-literacy adults become increasingly literate and independent.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {427–430},
numpages = {4},
keywords = {assistive technology, educational interfaces, interface design, mobile computing, mobile learning},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851698,
author = {Girardello, Andrea and Michahelles, Florian},
title = {AppAware: Which Mobile Applications Are Hot?},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851698},
doi = {10.1145/1851600.1851698},
abstract = {Today most mobile operating systems provide users with an application portal where they can search for applications published by third-party developers. However, finding new apps is not an easy task and requires either to know what to look for or to go through an endless list of applications. In this paper we present work in progress of a platform that allows its users to discover mobile applications in a serendipitous manner. AppAware is a mobile application that captures and shares installations, updates, and removals of Android programs in real time. Accordingly, AppAware allows its users to see what applications are being installed right now or around their position by other people, thus introducing a new way of interaction with application portals and other mobile users.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {431–434},
numpages = {4},
keywords = {applications, application portal, market, AppAware, mobile, android, social network},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851699,
author = {Villanueva, Pedro Gonz\'{a}lez and Tesoriero, Ricardo and Gallud, Jose A.},
title = {Multi-Pointer and Collaborative System for Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851699},
doi = {10.1145/1851600.1851699},
abstract = {We introduce a new system to improve the collaboration possibilities among the participants in face-to-face meetings and working groups, called WallShare. WallShare is a new interaction device and a new platform to develop collaborative applications. The proposed system provides a shared zone that is displayed by a projector over a wall. Users can collaborate through the shared zone using their own mobile devices, such as mobile phones, PDAs, laptops and so on. To use the shared zone, users have their own cursors that allow them to share any kind of files, such as images, or documents. WallShare has been proved helpful to support distributed user interfaces. The usability evaluation also showed us that WallShare users' can perform a set of tasks with effectiveness, productivity and satisfaction.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {435–438},
numpages = {4},
keywords = {interaction resources, UI distribution, mobile devices, HCI},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851700,
author = {Koskela, Joakim and Karvonen, Kristiina and Kilinkaridis, Theofanis and Gurtov, Andrei},
title = {Secure and Usable P2P VoIP for Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851700},
doi = {10.1145/1851600.1851700},
abstract = {The use of Voice over IP (VoIP) applications involves a number of security threats and usability issues, leading to possible breaches of security and privacy. With the adoption of future peer-to-peer communication systems, the challenges grow even more as we rely on untrusted peers to access the service. We are developing a peer-to-peer VoIP system which features techniques for improving the security and privacy of users in future networks. However, as the threats are seldom well understood, presenting them in a usable manner is problematic. Implemented on a mobile device, the small user interface provides additional challenges for the end user. Via interviews, a questionnaire and usability testing, we seek to improve both the usability of managing and understanding the additional security, as well as the overall user experience of the emerging application.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {439–442},
numpages = {4},
keywords = {peer-to-peer, usable security, VoIP, user study},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851701,
author = {Ketabdar, Hamed and Roshandel, Mehran and Y\"{u}ksel, Kamer Ali},
title = {MagiWrite: Towards Touchless Digit Entry Using 3D Space around Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851701},
doi = {10.1145/1851600.1851701},
abstract = {In this work, we present a new approach for text (mainly digit) entry based on digit shaped gestures created in 3D space around a mobile device. Some new mobile devices such as Apple iPhone 3GS and Google Android are equipped with magnetic (compass) sensor. The main idea is to influence the magnetic sensor using a magnet taken in hand. The user draws (writes) digits in the 3D space around the device using the magnet taken in hand. Movement of the magnet changes temporal pattern of magnetic field around the device which is sensed and registered by the magnetic (compass) sensor. The registered pattern is then compared against already recorded templates for different digits. Such a text (digit) entry approach can be especially useful for small mobile devices in which it is hard to operate small buttons or touch screen. Using our technique, the text entry space extends beyond physical boundaries of the device. A demonstrator for this approach is implemented on Apple iPhone 3GS platform. It demonstrates registering a few templates for different digits, and recognizing digits written in the space around the device},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {443–446},
numpages = {4},
keywords = {mobile devices, touchless text (digit) entry, embedded compass (magnetic) sensor, around device 3D interaction, properly shaped magnet},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851702,
author = {de la Gu\'{\i}a, Elena and Gallud, Jose A. A. and Tesoriero, Ricardo and Lozano, Mar\'{\i}a D. and Penichet, V\'{\i}ctor},
title = {Co-Interactive Table: A New Facility to Improve Collaborative Meetings},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851702},
doi = {10.1145/1851600.1851702},
abstract = {Co-Interactive Table is a client-server system designed to facilitate collaborative tasks in any kind of meeting such as sharing information and files among the participants using simple, natural and intuitive gestures. We have used technology based on mobile devices and RFID to implement the system. The system is composed of panels (one per user) forming the interactive table. A projector connected to a PC updates instantly the information generated in the meeting such as notes, ideas and the specific information of each participant. All devices used in the meeting room are connected via Wi-Fi to the Co-Interactive Table server. This server is responsible for providing important web services that coordinate and control the system performance. Besides, the system offers the possibility of performing remote meetings without losing functionality. The Co-interactive table client application runs on mobile devices with RFID reader. The system can recognize the service required by the user with a gesture as simple and natural as bringing the mobile device near the interactive table to select the desired action.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {447–450},
numpages = {4},
keywords = {collaboration, interactive meetings, interactive table, RFID, mobile devices},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851704,
author = {Caballero, Mar\'{\i}a Luz and Chang, Ting-Ray and Men\'{e}ndez, Mar\'{\i}a and Occhialini, Valentina},
title = {Behand: Augmented Virtuality Gestural Interaction for Mobile Phones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851704},
doi = {10.1145/1851600.1851704},
abstract = {This paper introduces Behand. Behand is a new way of interaction that allows a mobile phone user to manipulate virtual three-dimensional objects inside the phone by gesturing with his hand. Behand provides a straightforward 3D interface, something current mobile phones do not offer, and extends the phone's input and display space. The 3D direct manipulation paradigm makes it intuitive for people of all cultural backgrounds. It is ergonomically appropriate and technically feasible. A user evaluation of the concept was carried out, showing that users find the concept "useful", "innovative" and "fun" and there are no acceptability issues. Please refer to the video accompanying this paper for a video prototype of Behand.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {451–454},
numpages = {4},
keywords = {3D, gestural interfaces, mixed reality, augmented virtuality, manipulation, mobile devices, interaction strategies},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851705,
author = {Dicke, Christina and Wolf, Katrin and Tal, Yaroslav},
title = {Foogue: Eyes-Free Interaction for Smartphones},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851705},
doi = {10.1145/1851600.1851705},
abstract = {Graphical user interfaces for mobile devices have several drawbacks in mobile situations. In this paper, we present Foogue, an eyes-free interface that utilizes spatial audio and gesture input. Foogue does not require visual attention and hence does not divert visual attention from the task at hand. Foogue has two modes, which are designed to fit the usage patterns of mobile users. For user input we designed a gesture language build of a limited number of simple but also easy to differentiate gesture elements.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {455–458},
numpages = {4},
keywords = {spatial audio, auditory interface, mobile, gesture interaction, 3D},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851706,
author = {Broll, Gregor and Graebsch, Roman and Holleis, Paul and Wagner, Matthias},
title = {Touch to Play: Mobile Gaming with Dynamic, NFC-Based Physical User Interfaces},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851706},
doi = {10.1145/1851600.1851706},
abstract = {Mobile devices can take advantage of physical interaction with their environment and its objects to compensate their constrained input and output capabilities. For that purpose, dynamic NFC-displays combine the physical interaction with NFC-tagged user interfaces and the output capabilities of public displays. We have adopted this technology for the Whack-a-Mole game to show how it can improve the accessibility and usability of mobile games. This paper describes the design of the game and explores how physical interaction with dynamic NFC-displays can compensate the constraints of mobile games and enrich their gameplay.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {459–462},
numpages = {4},
keywords = {near field communication (NFC), physical user interfaces, mobile gaming, dynamic NFC-displays},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851707,
author = {Wu, Chia-Hsin and Wu, Tsai-Fang and Chou, Yu-Hong and Huang, Ko-Hsun and Wuang, Chen-Hao and Chen, Mon-Chu and Deng, Yi-Shin},
title = {HappyFeet! Influencing at the Turning Points: Walking or Scooter Ride for Short-Distance Journey?},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851707},
doi = {10.1145/1851600.1851707},
abstract = {Modern transportation has changed our lifestyle and allowed for many more options for the daily commute. Particularly in Taiwan, a unique regional phenomenon is that people tend to travel to almost anywhere by scooter. With the intention of replacing the scooter ride for short-distance journeys with walking, we introduce a system called "HappyFeet", which encourages users to walk more with various interactive ways. The user testing demonstrated that the users were enthusiastic about our design and they provided positive feedback as well as some comments for ways to improve.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {463–466},
numpages = {4},
keywords = {turning point, walk, user experience, short-distance journey, user-centered design},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851708,
author = {Verma, Namrata and Shetye, Priyanka and Gangopadhyay, Diya and Bisht, Mukul and Pavlyshak, Iryna},
title = {Find It: Information at Hand},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851708},
doi = {10.1145/1851600.1851708},
abstract = {We propose "Find It," a set of two features to improve the browsing experience for screen reader users, particularly individuals living with vision loss or blindness. The two features, Tagging and Quick Scrolling, enable users to organize information and focus on relevant details to efficiently and rapidly access their element of interest in lists. Tagging allows users to annotate any message, contact, or file using either a typed or a spoken word for efficient retrieval. Quick Scrolling is a touch-screen based feature that allows users to listen to selected fields of a list at a time and skip sections irrelevant to the search. This combination of tagging and scrolling has the potential to expedite list searching when using screen readers with mobile devices.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {467–470},
numpages = {4},
keywords = {mobile search, visually impaired, information search and retrieval, tagging, multi-scrolling, assistive technologies, screen readers},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851710,
author = {Gupta, Gaurang},
title = {Pulse: Tangible Touch},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851710},
doi = {10.1145/1851600.1851710},
abstract = {Pulse Tangible Touch is a concept demonstrating the possibilities with touch-based interfaces. The concept can be universally applied to any product that uses a touch-based interface as the input method. The interface is made up of a screen that is flexible in nature. This flexible screen rises in the form of a button when it senses the proximity of a finger},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {471–472},
numpages = {2},
keywords = {tactile, tactile feedback},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851711,
author = {Blommaert, Anne and Philippart, Pieter and Rassaerts, Chris and Theunissen, Erik and Widdershoven, Svenja and Shahid, Suleman},
title = {Day Pad: A Daily Life Assistant for Autistic Children},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851711},
doi = {10.1145/1851600.1851711},
abstract = {Most people suffering from autism have a desperate need for clarity and structure in their lives. There are various applications (agendas, daily planners, pictograms, etc.) that support autistic individuals in their living. However, not many applications out there make it possible for a person with autism to live a structured life on his own, in a variety of contexts, with minimum human guidance. Day Pad is an application that helps individuals, especially children and early teenagers, to organize their lives independently. This application can support the lives of individuals in a variety of contexts (home, daycare, market, school, etc.) and run on variety of mobile devices (PDA, tablet PC, etc.) depending on the context.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {473–474},
numpages = {2},
keywords = {children, contextual user interface, autism, design},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851713,
author = {Patel, Nirmal J.},
title = {Many Tabs Make a Light Board},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851713},
doi = {10.1145/1851600.1851713},
abstract = {My research examines challenges inherent in the design of mobile groupware systems. For my thesis work I am designing interfaces and interaction techniques that can be used to augment face-to-face communication within groups of collocated mobile users. In my initial research, which explored collocated mobile photo capture and sharing, I uncovered three fundamental challenges to designing mobile groupware. In this paper I discuss these challenges as well as my proposed research agenda to addresses the challenges.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {475–476},
numpages = {2},
keywords = {mobile, groupware, collocated},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851714,
author = {Orzechowski, Pawel M.},
title = {Interactive Mobile Presentation of Textiles},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851714},
doi = {10.1145/1851600.1851714},
abstract = {While shopping online for textiles from a mobile device, we face the perceptual gap between qualities we can perceive via the interface and those we sense when handling the real textile product. In this research I first investigate the qualities that people look for when interacting with textiles. Further, I examine the gestures people commonly use to handle fabrics, and I propose a way to imitate them on a mobile device. Finally, I prototype touch-screen interactive-video interfaces and assess best practice.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {477–478},
numpages = {2},
keywords = {textiles, interactive video, gestures, perception, mobile interface},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851715,
author = {Girardello, Andrea},
title = {AppAware: Serendipity in Mobile Applications},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851715},
doi = {10.1145/1851600.1851715},
abstract = {Most mobile operating systems provide users with an application portal where they can search for applications published by third-party developers. However, finding new apps is not an easy task and requires either to know what to look for or to go through an endless list of applications. In this short paper we present work in progress of a platform that allows its users to discover mobile applications in a serendipitous manner. AppAware is a mobile application that captures and shares installations, updates, and removals of Android programs in real time. Accordingly, AppAware allows its users to see what applications are being installed right now or around their position by other people, thus introducing a new way of interaction with application portals and other mobile users.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {479–480},
numpages = {2},
keywords = {market, application portal, android, AppAware, social network, mobile},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851716,
author = {Vazquez-Alvarez, Yolanda},
title = {Designing Spatial Audio Interfaces for Mobile Devices: Supporting Multitasking and Context Information},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851716},
doi = {10.1145/1851600.1851716},
abstract = {Audio interfaces are becoming more important due to the increasing functionality of today's mobile devices. As a result, more complex audio-driven eyes-free interactions are required when mobile. The aim of my work is to evaluate 3D audio techniques used to implement auditory displays that support multitasking and access to context information in interactive mobile environments.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {481–482},
numpages = {2},
keywords = {mobile devices, context information, multitasking, audio interfaces, 3D audio},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851717,
author = {Seebode, Julia},
title = {Influence of Feedback on the Quality of Multimodal Systems},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851717},
doi = {10.1145/1851600.1851717},
abstract = {Aim of this research is to investigate the influence of system feedback in different modalities like nonverbal auditory information as well as speech, tactile and graphical feedback on perceived quality. As a first step experiments are conducted for different kinds of unimodal feedback to establish a suitable experimental paradigm. Based on these experiments certain feedback messages are selected and implemented in a multimodal mobile prototype to study the influence of those feedback messages on the interaction and the perceived quality. The developed approach will serve as a generic experimental set-up to collect user ratings and interaction data. These measures can than be used to evaluate the quality and usability of multimodal systems in mobile contexts and for quality prediction.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {483–484},
numpages = {2},
keywords = {multimodal interaction, visual, tactile feedback, auditory},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851718,
author = {Guerreiro, Tiago},
title = {Assessing Mobile-Wise Individual Differences in the Blind},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851718},
doi = {10.1145/1851600.1851718},
abstract = {Every human is different. This diversity has not been given enough attention in mobile UI design. Disabled groups, with specific individual differences, face difficulties with traditional or stereotypical interfaces. My goal is to identify the individual features that influence mobile interaction, considering the blind, and match them with mobile interaction modalities in a comprehensive and extensible design space.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {485–486},
numpages = {2},
keywords = {assessment, individual differences, mobile accessibility, blind},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851719,
author = {Bayro Kaiser, Esteban Tobias},
title = {Indoor Simultaneous Localization and Mapping for Pedestrian with Wearable Computing},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851719},
doi = {10.1145/1851600.1851719},
abstract = {Mobile human computer interaction by Wearable Computing is to improve and support humans in their daily tasks [1, 2]. Wearable computers are easily to wear or can be incorporated in the human's clothes. Wearable computers intend compared to smart phones to minimize the cognitive effort and manual computer interaction. Another important feature of this technology is the interaction with its environment by distributed sensors. This is called context awareness providing the user with relevant environmental information like: location, activity, identity, time, temperature, etc.This research project, at its initial phase, has the objective to provide indoor localization in known and unknown environments for pedestrians equipped with wearable computers. This information is useful in many applications.At the moment there are various methods for indoor and outdoor localization such as GPS, pre-installed indoor communication infrastructures, field strength measurements (WLAN, GSM, Bluetooth, etc), laser, radar, sonar, camera, motion sensors, etc. For a precise indoor localization the best strategy is to use laser, camera or motion sensors [3]. I intend to apply Simultaneous Localization and Mapping (SLAM) using a short range laser scanner as known from mobile robots [4]. Fusing the laser scanner data with data of accelerometers, gyroscope and magnetometer will increase the precision.SLAM is well known problem from robotic map building and localization, it is solved, but probably needs some algorithm improvements. The most popular algorithms are based on the Extended Kalman filter and the Rao-Blackwellized Particle Filters to solve the problem [4]. Basically a map is built and estimated and a position estimated using the odometry data of the robot, where distance and direction obtained from a laser scanner with respect to land mark data and position. Landmarks are basically features in an environment that can be used as reference, to make different measurements from different positions. For example in an indoor environment landmarks could be lines, walls, corners, edges or more specific obstacles.The implementation of SLAM for pedestrians based on [5] is one of the objectives; where the pedestrian was equipped with head worn sensors. Pedestrians have a much more complex odometry than mobile robots; they differ in the type of movements and degrees of freedom. The laser scanner position with mobile robots is stable compared to the surface. This cannot be guaranteed for humans. Furthermore the human build is specific for each person as is motion. Thus the challenge is the odometry to be extracted for each human. To solve the odometry extraction, I intend to use inertial measurement units (IMU) as motion sensors to indentify walking and change of direction filtering noise due to irregular movements of the pedestrian.In this dissertation project the pedestrian will be equipped with a short range laser scanner and an inertial measurement unit. The positioning of the sensors is crucial to reduce noise or incorrect measurements. In mobile robots the laser scanner is implemented on top of it and is able to scan a horizontal plane. The most stable positions on the human body are the shoulders and hips to place the sensors. To obtain horizontal laser scans, the raw data requires processing with the IMU data and projection into the horizontal plane. Additionally to reduce false laser scan readings we will regulate the scanner with a servo motor stabilizer so its measurements are always taking horizontally. Mapping will be achieved with occupancy grid mapping. The entire data should be processed using a wearable computer. The pedestrian should not have to interact with it or enter any kind of preexisting knowledge. I intend to achieve a precise pedestrian slam in a real time environment with persons and moving objects for a specific application.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {487–488},
numpages = {2},
keywords = {wearable computing, slam, pedestrian},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851720,
author = {Lynggaard, Aviaja Borup},
title = {On the Move: Creating Domesticity through Experience Design},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851720},
doi = {10.1145/1851600.1851720},
abstract = {This paper is a summary of the Ph.D. project about home and mobility. The project concerns design for mobile life and through various prototypes it is an investigation of how to support the act of home making away from the primary home.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {489–490},
numpages = {2},
keywords = {design research, mobility, home, interaction design, modern nomads},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851721,
author = {Duarte, Lu\'{\i}s},
title = {Interaction Assessment through Physiological Interfaces in Collaborative &amp; Mobile Environments},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851721},
doi = {10.1145/1851600.1851721},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {491–492},
numpages = {2},
keywords = {usability assessment, physiological interaction, mobile environments},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851722,
author = {Pombinho, Paulo},
title = {Information Visualization on Mobile Environments},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851722},
doi = {10.1145/1851600.1851722},
abstract = {The reduced display size of handheld mobile devices imposes severe usability and visualization problems. Adaptation to specific usage context is a key feature to overcome usability and display limitations on mobile devices. I intend to explore adaptive mobile visualization and develop a framework that can efficiently manage the adaptation methods used in the adaptation objects, according to the different contexts dimensions present.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {493–494},
numpages = {2},
keywords = {geo referenced information visualization, mobile devices},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851723,
author = {Reis, Tiago Alexandre Cust\'{o}dio},
title = {Improving Mobile Interaction with Context-Awareness, Multimodality, and Adaptive Interfaces.},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851723},
doi = {10.1145/1851600.1851723},
abstract = {Mobile devices are used by a wide range of users, both on-the-go and in stationary fashions, for several purposes, and in a broad variety of scenarios, characterized by constantly mutating environmental and privacy settings. Such contextual complexity introduces significant interaction limitations, which often force the users to adapt to both the interfaces and usage contexts. My PhD research intends to mitigate these limitations. I hypothesize that adaptive context-aware multimodal interfaces improve daily mobile activities in terms of the performance, usability, and user experience. The validation of this hypothesis focuses communication, media manipulation, and personal organization activities.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {495–496},
numpages = {2},
keywords = {contextual evaluation, mobile interaction, multimodal interaction, context-awareness},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851725,
author = {von Niman, Bruno and Fonseca, Jos\'{e} Manuel Cantera},
title = {The Gurus' Views 2010},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851725},
doi = {10.1145/1851600.1851725},
abstract = {Gurus' Views 2010 is the sixth edition of the expert panel, addressing some of the hottest, most current and important user experience topics in an open interaction between experts and with the conference audience. The previous panels held at Mobile HCI 2003 in Udine, CHI 2004 in Vienna, Mobile HCI 2005 in Salzburg, HFT 2006 in Sophia Antipolis, and HFT 2008 in Kuala Lumpur, organized by Bruno von Niman in collaboration with and always populated by senior, professional authorities have provided useful insight into some areas and have been appreciated by a global audience.Some topics addressed by the experts are identified and prepared well ahead of the event, while others may be added late or even brought up during the panel, even by the audience.Some experts are pre-invited, while others may be added late, in order to provide the most relevant coverage of the issues discussed.Not all opinions expressed by the experts during the panel debate will necessarily reflect corporate positions but may be consisting of individual viewpoints based on experience, best practices or any other empirical evidence or gut feeling.The following pages may provide some further insight.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {497–498},
numpages = {2},
keywords = {user experience, mobile, user interfaces, accessibility, ICT, usability},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851727,
author = {Aslan, Ilhan and Leichtenstern, Karin and Holleis, Paul and Wasinger, Rainer and Stahl, Christoph},
title = {Tool-Support for Mobile and Pervasive Application Development - Issues and Challenges},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851727},
doi = {10.1145/1851600.1851727},
abstract = {We are interested in all sorts of tool-support, which help the designer of a pervasive application in different stages of the development process, such as task and requirements analysis, conceptual design, prototyping and evaluation. We are looking for contributions that will help to address the following questions: What are the past experiences and future expectations of designers and developers that use tools for support?; What exactly are the benefits and the shortcomings of available tools?; What are the open issues and challenges for the next few years?The workshop will feature presentations of research results, experiences of past and ongoing work, and a forum for participants to address a predefined set of focus questions.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {499–502},
numpages = {4},
keywords = {tool-support, design process, pervasive application, mobile application},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851728,
author = {Ashbrook, Daninel and Lyons, Kent},
title = {Ensembles of On-Body Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851728},
doi = {10.1145/1851600.1851728},
abstract = {With the continuing miniaturization of powerful computation into mobile devices, there exists an opportunity for re-envisioning how we interact with our personal technology.In addition to a core computational/interaction component such as a mobile phone, there could be substantial benefit to a user by offering an ensemble of multiple mobile devices that can be used together. Such devices could provide novel input or output capabilities, or distribute user interactions in a more effective way. Our goal with this proposed workshop is to foster discussion about what possibilities such collections of devices might offer.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {503–504},
numpages = {2},
keywords = {ensembles, ecologies, systems, mobile, wearables},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851729,
author = {Fernaeus, Ylva and Cramer, Henriette and Korhonen, Hannu and Kaye, Jofish},
title = {Please Enjoy! Workshop on Playful Experiences in Mobile HCI},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851729},
doi = {10.1145/1851600.1851729},
abstract = {This workshop aims to explore different approaches and challenges in studying playfulness as a mode of interacting with mobile technology. Researchers, designers and developers with interest in this theme are welcome to participate in a full day activity of demos, presentations and discussions. In particular, our emphasis is on how to introduce, explore and understand playful interaction in mobile applications used in the wild.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {505–508},
numpages = {4},
keywords = {playful interaction, mobile interaction},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851730,
author = {Church, Karen and Pujol, Josep M. and Smyth, Barry and Contractor, Noshir},
title = {MobileHCI'10 Workshop Summary: Social Mobile Web},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851730},
doi = {10.1145/1851600.1851730},
abstract = {The mobile space is evolving at an astonishing rate with over 4.1 billion subscribers in existence. The world is also witnessing an explosion in social web services with more users seeking novel ways of interacting with friends and family. We are interested in the combination of these two exciting research spaces: the social web and the mobile web. We believe that the social mobile web is going to be a highly influential research area in the near future and given the huge growth that both these fields have experienced in recent times we feel that now is an excellent time to discuss this nascent research space. This workshop continues the successful social mobile web workshop held as part of SocialCom in 2009. The workshop explores the current state of the social mobile web and combines technical presentations, demos and position papers to drive interaction and discussion among participants.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {509–512},
numpages = {4},
keywords = {social search, mobile content distribution, social web, interfaces, mobile content sharing, mobile context, mobile web, HCI, social browsing, collaboration, social networks},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851731,
author = {Vinciarelli, Alessandro and Murray-Smith, Roderick and Bourlard, Herv\'{e}},
title = {Mobile Social Signal Processing: Vision and Research Issues},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851731},
doi = {10.1145/1851600.1851731},
abstract = {This paper introduces the First International Workshop on Mobile Social Signal Processing (SSP). The Workshop aims at bringing together the Mobile HCI and Social Signal Processing research communities. The former investigates approaches for effective interaction with mobile and wearable devices, while the latter focuses on modeling, analysis and synthesis of nonverbal behavior in human-human and human-machine interactions. While dealing with similar problems, the two domains have different goals and methodologies. However, mutual exchange of expertise is likely to raise new research questions as well as to improve approaches in both domains. After providing a brief survey of Mobile HCI and SSP, the paper introduces general aspects of the workshop (including topics, keynote speakers and dissemination means).},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {513–516},
numpages = {4},
keywords = {mobile HCI, social signal processing},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851732,
author = {D\"{o}rflinger, J\"{o}rg and Gross, Tom},
title = {Mobile HCI and Technical ICTD: A Methodological Perspective},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851732},
doi = {10.1145/1851600.1851732},
abstract = {Technical Information and Communication Technologies for Development (ICTD) research lacks appropriate research methods along the entire development lifecycle spanning design, development, deployment, evaluation and monitoring. Mobile HCI has a great set of research methods that have proven their suitability in mobile research. However, applying Mobile HCI research methods unchanged in technical ICTD will fail due to the specific cultural, infrastructural and governmental context of developing countries. In this workshop we want to bring together people who are active in Mobile HCI and ICTD research to elaborate on Mobile HCI methods and discuss their application for technical ICTD.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {517–520},
numpages = {4},
keywords = {mobile human computer interaction, technical ICTD, research methodologies},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851733,
author = {Nanavati, Amit Anil and Rajput, Nitendra and Rudnicky, Alexandar I. and Turunen, Markku and Kun, Andrew L. and Paek, Tim and Tashev, Ivan},
title = {SiMPE: 5th Workshop on Speech in Mobile and Pervasive Environments},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851733},
doi = {10.1145/1851600.1851733},
abstract = {With the proliferation of pervasive devices and the increase in their processing capabilities, client-side speech processing has been emerging as a viable alternative. The SiMPE workshop series started in 2006 [5] with the goal of enabling speech processing on mobile and embedded devices to meet the challenges of pervasive environments (such as noise) and leveraging the context they offer (such as location).SiMPE 2010, the 5th in the series, will continue to explore issues, possibilities, and approaches for enabling speech processing as well as convenient and effective speech and multimodal user interfaces. Over the years, SiMPE has been evolving too, and since last year, one of our major goals has been to increase the participation of speech/multimodal HCI designers, and increase their interactions with speech processing experts.Multimodality got more attention in SiMPE 2008 than it has received in the previous years. In SiMPE 2007 [4], the focus was on developing regions. Given the importance of speech in developing regions, SiMPE 2008 had "SiMPE for developing regions" as a topic of interest. Speech User interaction in cars was a focus area in 2009 [2].Given the multi-disciplinary nature of our goal, we hope that SiMPE will become the prime meeting ground for experts in these varied fields to bring to fruition, novel, useful and usable mobile speech applications.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {521–524},
numpages = {4},
keywords = {speech processing, pervasive computing, mobile computing},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851734,
author = {Anastassova, Margarita and Magnusson, Charlotte and Pielot, Martin and Randall, Gary and Claassen, Ginger B.},
title = {Using Audio and Haptics for Delivering Spatial Information via Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851734},
doi = {10.1145/1851600.1851734},
abstract = {The goal of this full-day workshop is to initiate a discussion on the design and presentation of audio and haptic spatial information on mobile devices. We would like to invite researchers working in the fields of human-computer interaction, computer science, cognitive sciences, psychology, psychophysics, and mechatronics to submit a position paper and/or a demo presentation dealing with topics such as methodologies for representing multisensory spatial information on mobile devices, new interaction techniques, specific evaluation methods.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {525–526},
numpages = {2},
keywords = {design, metaphors, audio, geospatial information, haptics, evaluation},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

@inproceedings{10.1145/1851600.1851735,
author = {Eslambolchilar, Parisa and Wilson, Max L. and Komninos, Andreas},
title = {Nudge &amp; Influence through Mobile Devices},
year = {2010},
isbn = {9781605588353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851600.1851735},
doi = {10.1145/1851600.1851735},
abstract = {The aim of this workshop is to provide a focal point for research and technology dedicated to persuasion and influence on mobile platforms. We aspire to establish a scientific network and community dedicated to emerging technologies for persuasion using mobile devices. This workshop would be a unique opportunity for interaction designers and researchers in this area to share their latest research and technologies on 'nudge' methods with the scientific communities. Patterns of consumption such as drinking and smoking are shaped by the taken-for-granted practices of everyday life. However, these practices are not fixed and 'immensely malleable'. Consequently, it is important to understand how the habits of everyday life change and evolve. Our decisions are inevitably influenced by how the choices are presented. Therefore, it is legitimate to deliberately 'nudge' people's behaviour in order to improve their lives. Mobile devices can play a significant role in shaping normal practices in three distinct ways: (1) they facilitate the capture of information at the right time and place; (2) they provide non-invasive and cost effective methods for communicating personalised data that compare individual performance with relevant social group performance; and (3) social network sites running on the device facilitate communication of personalised data that relate to the participant's self-defined community. Among the issues the workshop will take on are:(a) What opportunities do mobile interventions provide? (b) How far the intervention should go? (c) Is persuasion ethical? and (d) How can we extend the scale of intervention in a society using mobile devices? Participants will contribute to the workshop with examples of nudge and persuasive technologies, and we will work together to create novel ideas, interactive applications on the phone, and discuss future opportunities.},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
pages = {527–530},
numpages = {4},
keywords = {nudge, influence, social norms, mobile devices, mobile phones, behavioral wedge},
location = {Lisbon, Portugal},
series = {MobileHCI '10}
}

